[
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-05 04:52:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-03 06:57:54-08:00",
    "text": "This is a tiny point, but I think it needs fixing for clarity: 5.2.\u00a0 The AlertMsg-Error Header Field \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 1*3DIGIT The text below makes it clear that the error-code is 3 digits: \u00a0  The ErrorValue contains a 3-digit error code indicating what was \u00a0  wrong with the alert in the request. What you have above allows for 1, 2 or 3 digits. I think you meant: \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 3DIGIT",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-10 04:14:31-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-05 04:52:20-08:00",
    "text": "(Updated, see the extra review comments) I have a few a tiny point, but I think they need fixing for clarity: 1)  5.2.\u00a0 The AlertMsg-Error Header Field \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 1*3DIGIT The text below makes it clear that the error-code is 3 digits: \u00a0  The ErrorValue contains a 3-digit error code indicating what was \u00a0  wrong with the alert in the request. What you have above allows for 1, 2 or 3 digits. I think you meant: \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 3DIGIT 2) As per Francesca's review: \"/=\" is illegal in ABNF, it should be \"=/\"",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-02-23 16:48:48-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-23 12:05:30-08:00",
    "text": "Thanks for this document.\u00a0 I have a very small ABNF issue I'd like to discuss, and which should be very easy to sort out one way or another: \u2014 Section 5.2 \u2014 \u00a0 \u00a0 \u00a0 ErrorValue\u00a0 \u00a0 \u00a0  =\u00a0 error-code \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *(SEMI error-params) \u2026 \u00a0  The ErrorValue contains a 3-digit error code indicating what was \u00a0  wrong with the alert in the request.\u00a0 This error code has a \u00a0  corresponding quoted error text string that is human readable.\u00a0 The \u00a0  text string is OPTIONAL, but RECOMMENDED for human readability, \u2026 \u00a0  Similar to how  RFC \u00a0  3261  specifies, there MUST NOT be more than one string per error \u00a0  code. Two things about this: 1. The ABNF makes the text string optional only by allowing zero or more of them (so zero is allowed). 2. The ABNF allows multiple text strings, but the text says that there MUST NOT be more than one. So, shouldn\u2019t the ABNF be this (and if not, why not)?: NEW \u00a0 \u00a0 \u00a0 ErrorValue\u00a0 \u00a0 \u00a0  =\u00a0 error-code [SEMI error-params] END (Also, and not part of the DISCUSS, \u201cSimilar to how  RFC 3261  specifies,\u201d is not good English; maybe, \u201cSimilar to the specification in  RFC 3261 ,\u201d or \u201cAs similarly specified in  RFC 3261 ,\u201d.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-10 10:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 17:16:30-08:00",
    "text": "I support Roman's Discuss (and comment) and will expound on his first point some more. The use of URIs to refer to remote content, potentially hosted on a third party, has numerous security considerations, some better known than others.\u00a0 We need to reference the security considerations of  RFC 3986  to get some coverage of these, such as the \"reliability and consistency\" point. One of the more subtle security considerations of using a URI to a remote resource as part of a request in cases such as this, is that the binding between the identity of the entity referring to the remote URI and the identity of the site providing the corresponding resource (i.e., the authority compoent of the URI) is not always clear.\u00a0 Although  RFC 7852  requires TLS mutual authentication and HTTPS transport for information provided by reference, it makes no statement requiring the TLS server certificate to correspond to the SIP initiator, or any other indication of authorization that the indicated resource makes sense as part of the indicated request. I also have two other Discuss-level points: We discuss the use of timestamps in protocol elements for detecting replay; this requires that all participants have (secure and) accurate time.\u00a0 We need to document this dependency on accurate time, and optionally point out that common internet time protocols such as NTP are not particularly secure at present. I'm also not sure where there's existing treatment of using SIP MESSAGEs as a DoS attack vector; that seems particularly pronounced in the emergency-services case since emergency messages may receive preferential treatment from the network.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-10 11:02:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 13:35:36-08:00",
    "text": "Section 9.\u00a0 Since CAPs can be included by reference (via URI) and the senders may be unknown to the ESRP/PSAP, please include language on the security considerations for untrusted URIs per Section 7 of  RFC3986 Section 9.\u00a0 Per \u201cTo provide protection of the entire SIP message exchange between neighboring SIP entities, the usage of TLS is REQUIRED.\u201d, can you please provide guidance on how to use TLS.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-07 02:38:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-12-12 09:22:21-08:00",
    "text": "This is generally a well written document and I enjoyed reading it. I have a small set of questions which I would like to discuss before recommending approval of this document: 1) In 10.4.\u00a0 Peer Offer Signal \u00a0  A Peer Offer Signal MUST be sent by a DLEP modem in response to a \u00a0  properly formatted and addressed Peer Discovery Signal \u00a0  (Section 10.3). \u00a0  A Peer Offer Signal MUST be encoded within a UDP packet.\u00a0 The IP \u00a0  destination MUST be set to the IP address and port number received in \u00a0  the corresponding Peer Discovery Signal.\u00a0 The source IP address MUST \u00a0  be set to the modem's IP address associated with the DLEP interface. \u00a0  The source port number MUST be set to the DLEP well-known port \u00a0  number. The port number can be omitted to signal that the well-known port number is to be used (as per 11.2 and 11.3). It looks like requiring that the source port is always a well-known port is an error here. 2) In 10.17: \u00a0  If metrics are supplied with the Message (e.g., Resources), these \u00a0  metrics are MUST be applied to all destinations identified in the \u00a0  Message. Nit: extra \"are\" before \"MUST\". Question: how can multiple destinations be specified? \u00a0  Note that this may overwrite metrics provided in a \u00a0  previously received Session or Destination Up Messages. 3) 12.\u00a0 Security Considerations \u00a0  At the transport layer, implementations of DLEP SHOULD implement, and \u00a0  use, TLS [ RFC5246 ] to protect the TCP session.\u00a0 Deployments that are \u00a0  protected by strong physical security (e.g., deployments where the \u00a0  DLEP router and modem are the only devices on a physical Layer 2 \u00a0  segment) may consider use of DLEP without TLS.\u00a0 When TLS is in use, \u00a0  each peer SHOULD check the validity of credentials presented by the \u00a0  other peer during TLS session extablishment.\u00a0 Refer to [ RFC7525 ] for \u00a0  additional details. How can credentials presented by the other peer can be validated? RFC 7525  is referencing  RFC 6125 , which talks about hostname validation, which is something which might not apply to DLEP deployments?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-12 11:22:27-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-07 02:38:59-08:00",
    "text": "This is generally a well written document and I enjoyed reading it. I have one remaining question which I would like to discuss before recommending approval of this document: 3) 14.\u00a0 Security Considerations \u00a0  At the transport layer, implementations of DLEP SHOULD implement, and \u00a0  use, TLS [ RFC5246 ] to protect the TCP session.\u00a0 Deployments that are \u00a0  protected by strong physical security (e.g., deployments where the \u00a0  DLEP router and modem are the only devices on a physical Layer 2 \u00a0  segment) may consider use of DLEP without TLS.\u00a0 When TLS is in use, \u00a0  each peer SHOULD check the validity of credentials presented by the \u00a0  other peer during TLS session extablishment.\u00a0 Refer to [ RFC7525 ] for \u00a0  additional details. How can credentials presented by the other peer can be validated? RFC 7525  is referencing  RFC 6125 , which talks about hostname validation, which is something which might not apply to DLEP deployments?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-27 15:15:47-07:00",
    "end_reason": "position_updated",
    "start": "2017-02-12 11:22:27-08:00",
    "text": "This is generally a well written document and I enjoyed reading it. I have one remaining question which I would like to quickly discuss before recommending approval of this document: Section 14 (Security Considerations) now says: \u00a0  When TLS is in use, each peer SHOULD check the validity of \u00a0  credentials presented by the other peer during TLS session \u00a0  establishment.\u00a0 Mobile implementations MAY need to consider use of \u00a0  pre-shared keys for credentials; implementations following the \u00a0  \"networked deployment\" model described in Implementation Scenarios \u00a0  SHOULD refer to [ RFC7525 ] for additional details. RFC 7525  that you are referencing contains recommendations on version of TLS and ciphersuites to use. Section 6.1 of  RFC 7525  talks about \"Host Name Validation\". I don't think this section applies to DLEP. So can you elaborate on how server identity is going to be verified using pre-shared keys and which parts of  RFC 7525  do you think apply to DLEP?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-12-15 06:45:08-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-14 09:12:32-08:00",
    "text": "Am I missing something or does the doc not specify which policy/policies should be used for registration of new values in these new registries? (Also previously mentioned by the tsv-art reviewer - thx!)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-01-31 02:08:57-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-13 21:22:46-08:00",
    "text": "* Section 11.7 The MAC address encoding on the wire seems to be wrong. Instead of using 6 bytes for MAC-48 the document seems to using 8 bytes. Similarly for EUI-64 the document seems to be using 12 bytes instead of 8. Please fix this (Also Note that the length values specified under the format of the data item seem to be correct i.e. 6 & 8 - it is the data item format that is wrong)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-10-22 10:39:57-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-12 07:39:35-07:00",
    "text": "This is generally a well written document, but I have a small list of issues (which should be easy to address) I would like to discuss before recommending its approval for publication: 1) In 5.2: is there upper limit on the TTL? The ABNF doesn't restrict the value, but it is important for interoperability 2) In 5.3: urgency is defined as a list of one or more values. The description says that it defines the lowest value allowed. There is also a sentence prohibiting multiple values. Why is this a set and how would multiple values be interpreted? 3) In 6: I don't know where the \":link\" Pseudo-Header field came from. Can you clarify where it is defined?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-14 08:03:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-13 04:32:11-07:00",
    "text": "Apologies if some of this is a bit wrong, I had to review this while not at a keyboard so I might make a booboo or two mapping my mental notes to text:-) Apologies also if some of the earlier discussion affects these, I didn't get a chance to check the PRs created as a result of other IESG comments.  (1) This might just me being confused (in which case, sorry) but I'm not quite clear on how with works with the SOP.\u00a0 Given you (reasonably) recommend a different port (which is a different origin than 443) are you saying here that the SOP doesn't apply to the client? (Well, actually you don't say, so I'm not sure:-) If the SOP applies, how is the port change handled? If the SOP does not apply, then what does? (Given that I assume some UAs at least will not change their handling of the SOP no matter what we say here.) (2) So-called \"capability URLs\" (is that a new term here? seems like it could be the topic for a useful informational rfc) are clearly weak, but also clearly as good as we'll get for some things.\u00a0 However, those also become known over time, (in which case they are toast;-) so why don't you need to provide a way for a push service to say \"hey, instead of\u00a0 in future you'll need to use \"? If that could be done as an extension later, then I'd be ok with that in terms of clearing the discuss, but then I think you'd need to mention it, so that applications and UAs don't build in an assumption that these URLs are fixed for all time (while also needing to be kept \"secret\" as with other bearer tokens). (3) Why is it not correct to encourage mutual-auth TLS for the application to push-service connections?\u00a0 I'm not arguing to make that mandatory, but it's not that hard in many cases and is very useful, esp since without some client auth just knowing the URL will often enable a sender to send a crap load of updates to possibly many bandwidth/power-challenged UAs. (This is only a discuss because of that potential DoS vector.) (4) Is it really honest to say that the W3C Push API, webpush encryption and vapid are only informative references? The first seems easy to make normative, the second I think really needs to exist before we ought recommend this all get out into the wild and I'm not clear if one could sensibly make a service for this without the 3rd. Yes that might add some delay to the RFC being issued, but that might be the right thing to do. Why is it right to not wait on those two IDs and the w3c rec? This is mainly a discuss in case the answer is \"we know nobody's gonna do webpush-encryption ever\" in which case I'd like to be convinced that implementing and deploying based on this draft without reading those references defines a good standard. I'm not saying that it does not, I'm saying I'm not yet convinced.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-20 04:54:55-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-14 08:03:56-07:00",
    "text": "(1) This might just me being confused (in which case, sorry) but I'm not quite clear on how with works with the SOP.\u00a0 Given you (reasonably) recommend a different port (which is a different origin than 443) are you saying here that the SOP doesn't apply to the client? (Well, actually you don't say, so I'm not sure:-) If the SOP applies, how is the port change handled? If the SOP does not apply, then what does? (Given that I assume some UAs at least will not change their handling of the SOP no matter what we say here.) (Discuss points 2-4 cleared)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-04-19 02:35:23-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-15 21:09:53-07:00",
    "text": "I plan to ballot \"Yes\" for this, but there is an issue I think needs discussion first. Hopefully this will be easy to address: \u00a73 says \"Report submitters MAY ignore certificate validation errors when submitting reports via https.\" Yet the security considerations mention how an attacker than can subvert SMTP security might also be able to subvert the TLSRTP TXT records. It seems like one potential result of that could be to redirect the reports to a hostile destination, or at least away from the intended destination. Ignoring certificate validation errors\u00a0 removes a check against that sort of thing. I'm sure there are good reasons to allow that; I can even guess at a few. But I think allowing that sort of behavior needs explicit motivation, and I failed to find text that did that.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-04-16 11:25:45-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-16 10:58:05-07:00",
    "text": "I'm guessing that I'm simply misunderstanding / not understanding (reformatted for clarity): 1: If multiple TXT records for \"_smtp._tls\" are returned by the resolver, records which do not begin with \"v=TLSRPTv1;\" are discarded. 2: If the number of resulting records is not one, senders MUST assume the recipient domain does not implement TLSRPT. 3: If the resulting TXT record contains multiple strings, then the record MUST be treated as if those strings are concatenated together without adding spaces. So, if I query for '_smtp._tls.example.com' and get back: \"v=TLSRPTv1;rua=mailto: foo@example.com \" \"v=TLSRPTv3;rua=mailto: bar@example.com \" I throw away the one that contains 'bar', fair enough, got it. What I don't understand is what a record would look like which is a single record (#2), but that contains multiple strings (#3). Can you provide an example of a TXT record with multiple strings? I don't *think* that this is just me being dense, and so I think that the document needs to better explain this / include the example.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2015-11-24 21:57:51-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-22 05:36:06-07:00",
    "text": "From my perspective some of the things that Robert raises in the Gen-ART review are very valid questions. I'm raising one of those items in this Discuss. The particular item that I\u2019m interested in is the text in Section 3.2, which seems like explaining what happens in an example, but it also uses normative language and keywords to say what various entities should do. Yet, the example is just one example. Is there a need to lift the keyword statements out of this paragraph and generalise them to make sure that the specification is about the general case and not about the example? Alternatively, maybe I misunderstood the purpose of the keyword statements.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-10-31 04:02:41-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 09:00:00-07:00",
    "text": "This document needs to incorporate the boilerplate about normative keywords from  RFC 8174  as well as references to  RFC 8174  and  RFC 2119 .",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-26 17:30:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-24 16:02:45-07:00",
    "text": "I'm concerned that this normative statement is ambiguous (2nd paragraph of section 4), and that the ambiguity around allowed values may lead to interop issues: \u00a0  AdvDefaultLifetime \u00a0  MUST either be zero (the router is not to be used as a default \u00a0  router) or be a value between MaxRtrAdvInterval and 65535. From the text in section 3, I infer that MaxRtrAdvInterval is *not* an allowed value. From the \"no greater than 65535\" language, I infer that 65535 *is* an allowed value. Please ensure that your normative statement here is very clear about whether \"between\" is intended to include its high and low limits as acceptable values.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-11-29 16:55:24-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-26 17:30:24-07:00",
    "text": "Lacking a formal definition of \"between,\" the following normative statement is ambiguous: \"AdvDefaultLifetime MUST either be zero (the router is not to be used as a default router) or be a value between MaxRtrAdvInterval and 65535.\" Normative statements cannot be ambiguous. Please clarify whether this is an inclusive \"between\" or an exclusive \"between.\"",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-04-22 00:31:16-07:00",
    "end_reason": "position_updated",
    "start": "2015-12-17 05:30:40-08:00",
    "text": "As mentioned in Sue Hares' OPS DIR, 3 major concerns. The last one is actually for the security ADs. Status: Not ready,\u00a0 three major concerns and two editorial nits:\u00a0  Major concerns: 1)\u00a0 \u00a0 \u00a0 Specification of the Extranet Source Extended Community and Extra Source extended Community Please provide the type of detail as show in  RFC 4360  sections 3.1, 3.2, and 3.3.\u00a0  2)\u00a0 \u00a0 \u00a0 Why is there no Deployment considerations section?  The whole draft is a set of rules for handling policy, BGP A-D routes, tunnel set-up, and PIM Join/leaves in the case of an intra net.\u00a0 Unless these rules are followed exactly, traffic may flow into a VPN it is not suppose to. If the customer and the SP must coordinate on setting up filters, the procedure is outside the document. An error in any of these set-ups is considered a \u201csecurity violation\u201d.  Milo Medin stated \u201cwith enough trust\u201d a rock can fly to the moon.\u00a0 However, the NASA flights were fragile and risky.\u00a0 In the journey to the moon, there was no other choice.\u00a0 Instrumentation has 4-5 backups. In this set-up, one has to ask \u201cis there another choice\u201d to this whole design that seem fragile addition of extranets to an intra-AS multicast design.\u00a0 If the design is not fragile, then there should be a deployment section indicating how to manage the RTs, RDs, and policy set-up.\u00a0 Perhaps experience with the Intra-As has shown deployment tips that would make this less fragile.\u00a0 If so,\u00a0 it would be good to include an operations consideration section. If a new class of tools provides monitoring or provisioning, mentioning these would be useful.\u00a0 If yang modules are being developed, that would be useful. Places that indicate issues with violated constraint: p. 11, 12, 19 (2.3.2 \u2013 a priori knowledge, inability to detect), , p. 25 last paragraph (violation of constraints will cause things to not work.\u00a0 However, only policy can control), p. 27 4.2.2 (1st paragraph, Route Reflector must not change), p. 31 (5.1, first paragraph), 3)\u00a0 \u00a0 \u00a0 Is security section really a security section? It seems more like \u201cdo this policy\u201d or this will fail.\u00a0 It should get a stronger review from the security directorate",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2016-04-22 13:32:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-02-28 08:37:00-08:00",
    "text": "fter further discussion related to the ops dir review, I'm going to have to echo Benoit and the Opsdir reviewers concern.",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2016-04-22 13:33:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-22 13:32:33-07:00",
    "text": "Thank you for the frank discussion in buenos Aires and the proposed edits.  I think they address the concerns raised in the opsdir review.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-12-22 07:25:11-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-17 17:47:06-08:00",
    "text": "I just have one question/request to improve the security consideration section.\u00a0 The only security mentioned in this draft is what's called a \"security violation\", where traffic may go to the incorrect \"VPN\" endpoint.\u00a0 If you are worried about traffic winding up in the wrong place, why is there no consideration for observing this traffic on the wire?\u00a0 Since there is no encryption, wouldn't this also be a security consideration to call out specifically?  Mention of the possibility of active attacks that could alter or tamper with the traffic or passive attacks that could observe the traffic as a risk due to lack of encryption (confidentiality protection) would help or a reason why this doesn't matter. Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-11-29 14:15:14-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-11-29 14:14:49-08:00",
    "text": "to discuss before the document is published. It's possible that I'm mistaken about the way this is intended to work -- don't be shy about telling me I'm wrong. \u00a74.2: >\u00a0 To use a DNS server as a source of bootstrapping data, a device MAY >\u00a0 perform a multicast DNS [ RFC6762 ] query searching for the service >\u00a0 \"_zerotouch._tcp.local.\".\u00a0 Alternatively the device MAY perform DNS- >\u00a0 SD [ RFC6763 ] via normal DNS operation, using the domain returned to >\u00a0 it from the DHCP server; for example, searching for the service >\u00a0 \"_zerotouch._tcp.example.com\". RFC 6763  \u00a74.1.2 defers to  RFC 2782  for the structure of DNS-SD records; and  RFC 2782  indicates that these are of the format \"_service._proto.name\". In this case, \"service\" is one of the services registered with IANA at https://www.iana.org/assignments/service-names-port-numbers/ The service \"zerotouch\" is not registered in that registry, nor does this document register it there. Unless I'm confused about the way SRV records are intended to work, this document needs to register \"zerotouch\" in the service name table indicated above.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-12-20 12:15:13-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-29 14:15:14-08:00",
    "text": "Thanks to everyone who worked on this document. I have one concern that I'd like to discuss before the document is published. It's possible that I'm mistaken about the way this is intended to work -- don't be shy about telling me I'm wrong. \u00a74.2: >\u00a0 To use a DNS server as a source of bootstrapping data, a device MAY >\u00a0 perform a multicast DNS [ RFC6762 ] query searching for the service >\u00a0 \"_zerotouch._tcp.local.\".\u00a0 Alternatively the device MAY perform DNS- >\u00a0 SD [ RFC6763 ] via normal DNS operation, using the domain returned to >\u00a0 it from the DHCP server; for example, searching for the service >\u00a0 \"_zerotouch._tcp.example.com\". RFC 6763  \u00a74.1.2 defers to  RFC 2782  for the structure of DNS-SD records; and  RFC 2782  indicates that these are of the format \"_service._proto.name\". In this case, \"service\" is one of the services registered with IANA at https://www.iana.org/assignments/service-names-port-numbers/ The service \"zerotouch\" is not registered in that registry, nor does this document register it there. Unless I'm confused about the way SRV records are intended to work, this document needs to register \"zerotouch\" in the service name table indicated above.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-12-21 02:36:38-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-05 10:21:31-08:00",
    "text": "Thank you for a well written document, it was a pleasure to read. I have a small list of issues that I would like to discuss before recommending approval of this document: In Section 5.3: \u00a0  If the zero touch information artifact contains redirect information, \u00a0  the device MUST, within limits of how many recursive loops the device \u00a0  allows, process the redirect information as described in Section 5.5. \u00a0  This is the recursion step, it will cause the device to reenter this \u00a0  algorithm, but this time the data source will definitely be a \u00a0  bootstrap server, as that is all redirect information is able to \u00a0  redirect a device to. I think you need to specify a \"max redirect\" value in order to prevent intentional or unintentional misconfigurations. Without such limit it is trivial to introduce denial-of-service attack on naive device implementations. 2)  10.3.\u00a0 The SMI Security for S/MIME CMS Content Type Registry \u00a0  IANA is kindly requested to add two entries in the \"SMI Security for \u00a0  S/MIME CMS Content Type\" registry (1.2.840.113549.1.9.16.1), with \u00a0  values as follows: \u00a0  Decimal\u00a0 Description\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  References \u00a0  -------\u00a0 --------------------------------------\u00a0 ---------- \u00a0  TBD1\u00a0 \u00a0 \u00a0 id-ct-zerotouchInformationXML\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [RFCXXXX] \u00a0  TBD2\u00a0 \u00a0 \u00a0 id-ct-zerotouchInformationJSON\u00a0 \u00a0 \u00a0 \u00a0  [RFCXXXX] \u00a0  id-ct-zerotouchInformationXML indicates that the \"zerotouch- \u00a0  information\" is encoded using XML.\u00a0 id-ct-zerotouchInformationJSON \u00a0  indicates that the \"zerotouch-information\" is encoded using JSON. You define these values, but they are not used anywhere in the document. It looks like you intended for this to be used in several places, for example: 3.1.\u00a0 Zero Touch Information \u00a0  When the zero touch information artifact is unsigned, as it might be \u00a0  when communicated over trusted channels, the CMS structure's top-most \u00a0  content type MUST be one of the OIDs described in Section 10.3, or \u00a0  the OID id-data (1.2.840.113549.1.7.1), in which case the encoding \u00a0  (JSON, XML, etc.)\u00a0 SHOULD be communicated externally.\u00a0 In either Did you intend to use the above OIDs here? \u00a0  case, the associated content is an octet string containing \u00a0  \"zerotouch-information\" data in the expected encoding.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-12-29 16:33:42-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-12-03 22:28:37-08:00",
    "text": "First off, thanks for this clear and considered document and design; it really lays out the scenario of applicability and the functionality quite well.\u00a0 I just have a couple lingering places that we might want to nail down a little bit tighter... (1) SSH key formats The module in Section 7.3 says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  leaf-list ssh-host-key { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type binary; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"The binary public key data for this SSH key, as \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 specified by  RFC 4253 , Section 6.6, i.e.: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 string\u00a0 \u00a0 certificate or public key format \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 identifier \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 byte[n]\u00a0  key/certificate data.\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"RFC 4253: The Secure Shell (SSH) Transport Layer \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Protocol\"; but  RFC 4523  Section 6.6 says: \u00a0  The key type MUST always be explicitly known (from algorithm \u00a0  negotiation or some other source).\u00a0 It is not normally included in \u00a0  the key blob. \u00a0  Certificates and public keys are encoded as follows: \u00a0 \u00a0 \u00a0 string\u00a0 \u00a0 certificate or public key format identifier \u00a0 \u00a0 \u00a0 byte[n]\u00a0  key/certificate data How is the key type known for the SZTP usage? (2) Privilege escalation by design There's text in Section 2.1 (and, really, throughout) that indicates that a device being boostrap should allow a trusted bootstrap server to behave as (i.e., supply) a trust anchor for verifying a different service.\u00a0 In some sense this is elevating an EE cert to a CA cert, and I had hoped to see some discussion of this escalation in the security considerations.\u00a0 (Same for the owner cert, though there's a stronger argument that the owner should be considered fully privileged here.) (3) Nonce length Section 7.3 describes the nonce leaf: \u00a0 \u00a0 \u00a0 \u00a0  leaf nonce { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type binary { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  length \"8..32\"; There is probably some discussion to be had about the minimum nonce length (not necessarily in the document itself).\u00a0 Do you have a pointer handy to previous disucsions or do we need to have it now? (I do see that this is just following  RFC 8366 , so hopefully this is an easy question.) (4) OPTION_V4_ZEROTOUCH_REDIRECT repeated instances (In Section 8.1.) I think I may just be misunderstanding things here, but aren't \u00a0  As the list of URIs may exceed the maximum allowed length of a single \u00a0  DHCPv4 option (255 octets), the client MUST implement [ RFC3396 ], \u00a0  allowing the URI list to be split across a number of \u00a0  OPTION_V4_ZEROTOUCH_REDIRECT option instances. and \u00a0  The DHCPv4 server MAY include a single instance of Option \u00a0  OPTION_V4_ZEROTOUCH_REDIRECT in DHCP messages it sends.\u00a0 Servers MUST \u00a0  NOT send more than one instance of the OPTION_V4_ZEROTOUCH_REDIRECT \u00a0  option. in conflict about sending more than one instance of OPTION_V4_ZEROTOUCH_REDIRECT?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-05 20:33:34-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-29 16:33:42-08:00",
    "text": "[editing to reflect changes in the -26] First off, thanks for this clear and considered document and design; it really lays out the scenario of applicability and the functionality quite well.\u00a0 I just have a couple lingering places that we might want to nail down a little bit tighter... (2) Privilege escalation by design There's text in Section 2.1 (and, really, throughout) that indicates that a device being boostrap should allow a trusted bootstrap server to behave as (i.e., supply) a trust anchor for verifying a different service.\u00a0 In some sense this is elevating an EE cert to a CA cert, and I had hoped to see some discussion of this escalation in the security considerations.\u00a0 (Same for the owner cert, though there's a stronger argument that the owner should be considered fully privileged here.) (3) Nonce length Section 7.3 describes the nonce leaf: \u00a0 \u00a0 \u00a0 \u00a0  leaf nonce { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type binary { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  length \"8..32\"; There is probably some discussion to be had about the minimum nonce length (not necessarily in the document itself).\u00a0 That is, is a 64-bit nonce actually secure for what we are asking of it, or do we need 128 bits?\u00a0 Do you have a pointer handy to previous discussions or do we need to have it now? (I do see that this is just following  RFC 8366 , so hopefully this is an easy question.)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-12-21 09:28:25-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-05 21:51:18-08:00",
    "text": "* Section 8.1 This should be easy to fix but this text about the cardinality of the option  \"Servers MUST NOT send more than one instance of the OPTION_V4_ZEROTOUCH_REDIRECT option.\" is contradictory to the following recommendation to use  RFC3396  for long URLs *which will certainly result* in multiple options being sent. I would like personally like this to be a qualified MUST NOT (e.g. MUST NOT except for the long URL case) but I leave it up to the authors and the sponsoring AD to figure out the best way forward.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2014-01-09 05:01:15-08:00",
    "end_reason": "position_updated",
    "start": "2013-12-18 21:11:40-08:00",
    "text": "This is a trivial Discuss to fix, but it seems important because a reader who believes the references would miss parts of key BCPs. I'll be a Yes when it's resolved. In section 3.2.1.\u00a0 IETF Process and Publication, \u00a0  It is very important to note and understand the IETF Intellectual \u00a0  Property Rights (IPR) policy that requires early disclosures based on \u00a0  personal knowledge from anyone contributing in IETF.\u00a0 The IETF \u00a0  policies associated with IPR are documented in  BCP 78  [ RFC5378 ] \u00a0  (related to copyright, including software copyright for example code) \u00a0  and  BCP 79  [ RFC3979 ] (related to patent rights). BCP 78  is a single-RFC BCP, so that's correct now, but the base RFC could be reissued or updated in other RFCs included in the BCP, and  BCP 79  is a multi-RFC BCP, so citing it as [ RFC3979 ] isn't quite right. A bit further in the same section, in \u00a0  The main part of the IETF process is formally defined in  RFC 2026 \u00a0  [ RFC2026 ].\u00a0  RFC 2418  [ RFC2418 ] describes the WG process, the relation \u00a0  between the IESG and the WG, and the responsibilities of WG chairs \u00a0  and participants. both  RFC 2026  and  RFC 2418  are part of multi-RFC BCPs ( BCP 9  and  BCP 25 , respectively). My suggestion would be cite all of these by BCP numbers.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2014-01-08 17:59:30-08:00",
    "end_reason": "position_updated",
    "start": "2013-12-19 07:05:52-08:00",
    "text": "3.2.1 says: \"Note: These IPR rules applies on what is specified in the RTP Payload format Internet Draft (and later RFC), IPRs that relates to a codec specification from an external body does not require IETF IPR disclosure.\" That is the subject of a current thread on rtcweb and  ipr@ietf.org  so I want to check that the IESG agree that the above is correct before we put this out in a new RFC. (I'm not sure myself, but don't want us to contradict what could be an emerging consensus that's different from this, in the unlikely event that such a consensus emerges in the short-term.) Note that this discuss is also slightly different from the apt-x thing, in which case I believe that the codec is not openly published.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-02-01 06:33:08-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-31 08:08:15-08:00",
    "text": "I've two (or 4 depending how you count:-) things I'd like to check here. Should be pretty easy to handle. (1) section 5: I'm wondering if we have the right set of hash functions here. Deprecating md2 and md5 is great, but I have a bunch of questions about the others: (1.1) why not also say that sha-1 MUST NOT be used for new things (or similar)? (1.2) do you really need sha-224 and 384? I think nobody uses those at all. (1.3) I'm a bit surprised you didn't add sha3 (and maybe remove sha-512 if that's not needed) Even if you don't encourage use of sha3, it might be good to include it in the abnf now in case it gets popular. (2) Wouldn't it be a good plan to say that TLS as-used MUST conform to  BCP195 ? If not, why not?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-30 17:05:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 08:01:48-07:00",
    "text": "Probably an easy thing to fix, I see an identity defined as \"rcs-rfc8724\". Using RFC numbers as names can be confusing if such and RFC is obsoleted for another RFC. Couldn't this entry be called \"rcs-crc32\" ?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-10-06 05:52:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 04:44:33-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I would like to discuss whether it is possible/appropriate to add an instance data example (as per my comment 1 below) to this document, or if that is inappropriate or unhelpful for some reason.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-29 14:47:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-24 11:21:07-07:00",
    "text": "** Section 8. An attacker by changing a rule content may block the \u00a0  communication or intercept the traffic.\u00a0  ... The full tree is sensitive, since it represents all the elements that \u00a0  can be managed.\u00a0 This module aims to be encapsulated into a YANG \u00a0  module including access control and identities. Thanks for calling out the entire tree as \u201csensitive.\u201d\u00a0 Please be more specific.\u00a0 There is mention of write sensitivity (i.e., re-writing the rules).\u00a0 Please also discuss any issues with reading the tree. Consider following the template of  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines  to distinguish between write and read access.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-28 06:26:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-29 14:47:29-07:00",
    "text": "** Section 8. An attacker by changing a rule content may block the \u00a0  communication or intercept the traffic.\u00a0  ... The full tree is sensitive, since it represents all the elements that \u00a0  can be managed.\u00a0 This module aims to be encapsulated into a YANG \u00a0  module including access control and identities. [ballot for -15 text] Thanks for calling out the entire tree as \u201csensitive.\u201d\u00a0 Please be more specific.\u00a0 There is mention of write sensitivity (i.e., re-writing the rules).\u00a0 Please also discuss any issues with reading the tree. Consider following the template of  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines  to distinguish between write and read access. [ballot for -17 text] Thanks for the additional words about write sensitivity.\u00a0 What is the impact of an attacker reading the module?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-09-10 06:23:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-08 08:08:49-07:00",
    "text": "I like to thank the TSV-ART reviewer for helping me consider one aspect of the issue I see needing some discussion for this document. This relates to Section 4.2.2.2. and 4.2.2.3.  So both of these section discuss the use of the sequence number for removing packet duplicates and handling reorder. As the text discusses there can be a configured limit for how deep the buffer and state are for performing these operations. We all know that the implementation of this will have a practical limit in both buffer space for reordering as well as state for tracking which sequence numbers that have been forwarded. I think that should be more clearly expressed in the document that these practical limits exists. Thus, the implementations will have tracking and determination of what are new packets (increasing sequence number within a window higher than previous largest seen. And consider sequence number form currently highest seen and a bit backwards as older packets. Thus how this is implemented will impact how this acts in cases of disruptions of the packet flow. Thus, I wonder if there is actually need to be\u00a0 a bit more specific in how classification should be done. Especially if the wrap-around of the sequence number space approaches a small multiple of round trip times for the path which is likely for the 16-bit space.  Then\u00a0 sections fails to discuss how the duplication removal, the reordering buffering and bound latency interacts and affet each other.\u00a0 So if the latency is bounded then the reordering has an hard time limit for the maximum delay. If there is a boundary for reordering then there are no point in de-duplicating packets that will not be forwarded due to the reordering. And even if there are no bounded latency the reordering buffer size will still impact the depth of de-duplication. These practical limits will also be limitations on the guarantees that can be provided.  Thus, from my perspective there is need for more text on the requirements of the implementation of these functions and their interactions of creating limitations.  Another point on 4.2.2.2: When configured, the \u00a0  implementation MUST track the sequence number contained in received \u00a0  d-CWs and MUST ensure that duplicate (replicated) instances of a \u00a0  particular sequence number are discarded. That second MUST I think is possible to meet given that one discard all packets outside of the current window where one have information if a packet sequence number have been forwarded or not. Given that a very late packet beyond the amount of state for the flow likely anyway have little utility that is likely the right choice. However, I think it needs to be made explicit that this is okay.  In Section 4.2.2.3:  When configured, the \u00a0  implementation MUST track the sequence number contained in received \u00a0  d-CWs and MUST ensure that packets are processed in the order \u00a0  indicated in the received d-CW sequence number field, which may not \u00a0  be in the order the packets are received.  I think this part needs to be explicit that packets that are to fare out of order for the implementation to handle will/shall be dropped. \u00a0  Note that an implementation MAY wish to constrain the maximum number \u00a0  of out of order packets that can be processed, on platform-wide or \u00a0  per flow basis.\u00a0 Some implementations MAY support the provisioning of \u00a0  this number on either a platform-wide or per flow basis.\u00a0 The number \u00a0  of out of order packets that can be processed also impacts the \u00a0  latency of a flow. If there exists a latency requirement then that will interact with this when it comes to reordering. In fact a significant issue here is that if the packet flow is not periodic at a steady pace the maximum latency in the reordering buffers based on packet sequence numbers can not be ensured. Instead some form of time limit needs to exist also. If that time limit is only local then there exists a risk that over multiple reordering buffers if multiple independent service labels are used the jitter and latency becomes cumulative. If the goal is to avoid this then the individual packets would need to carry a time stamp to ensure that from ingress of the service label path until the egress a maximum latency is added.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-10-12 01:41:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-10 06:23:38-07:00",
    "text": "I like to thank\u00a0 TSV-ART reviewer Michael T\u00fcxen for helping me consider one aspect of the issue I see needing some discussion for this document. Updated and extended discuss to clarify the issues I see. Please note that D below is new and a consequence in my trying to clarify C. why it matters.  A. The need for latency bounding the POF to enable the MPLS S-Label path to be bounded if reordering protection service is needed. To my understanding in an MPLS network the controller can determine an upper bound of the latency for a path by adding together the path latencies, the packet buffer depths based on the forwarding behavior applied, and the POF buffer depth. However, as currently described it is not made clear that the POF needs to have a configuration for an upper bound of how long a packet may maximum remain in the buffer since arrival. This requirement is somewhat discussed in  So  https://datatracker.ietf.org/doc/draft-ietf-detnet-data-plane-framework/: 3.5.2.2.\u00a0 Path Differential Delay \u00a0  In the preceding example, proper working of duplicate elimination and \u00a0  reordering of packets are dependent on the number of out-of-order \u00a0  packets that can be buffered and the delay difference of arriving \u00a0  packets.\u00a0 DetNet uses flow-specific requirements (e.g., maximum \u00a0  number of out-of-order packets, maximum latency of the flow) for \u00a0  configuration of POF-related buffers.\u00a0 If the differential delay \u00a0  between paths is excessively large or there is excessive mis-ordering \u00a0  of the packets, then packets may be dropped instead of being \u00a0  reordered.\u00a0 Likewise, PEF uses the sequence number to identify \u00a0  duplicate packets, and large differential delays combined with high \u00a0  numbers of packets may exceed the ability of the PEF to work \u00a0  properly. So this configuration needs to be required on the MPLS POF implementation to enable the controller to bound the latency between ingress and egress when POF is used. And it needs to be done in time, per the below paragraph. So given that the buffer is specified in either bytes or simply packets to be buffered will result in that the POF buffering time becomes packet flow dependent and not bounded in time. So if you make the calculation for a DETNET flow thinking it will send 500 packets per second evenly spaced. Then the a buffer of 5 packets would represent an upper limit 1/100th of second. If then the flow sends only 100 packet per second then suddendly the 5-packet buffering would represent 1/20th of a second. Thus defining it in packets or size doesn't work, the upper buffering time needs to be defined in time to provide a bounded latency.  I would note that soley configuring an upper bound between arrival in POF buffer until latest release is more fragile than actually having actual timestamp applied at egress to each packet. But, it can ensure bounded delay as long as the other functions do keep to their boundary.  However, I think the solution here is to clarify the configuration requirement on the POF in Section 4.2.2.3. B. On the relation of the PEF to the POF.  The document does not discuss this, and maybe this is fairly obvious but a relation ship exists. The PEF state needs to be deeper than the POFs when both are used. Otherwise duplicates may be forwarded. If the PEF is at least as deep as the POF, then any duplicate that is more out of order than what the POF allows will be discarded. However, as the POF is not that explicitly specified, even if the information document do define that is what should be done.  I would recommend that the text is made more clear on this relationship and also are explicit about the discard of out of order in the POF.  C. On the implementation details of the PEF and POF in regards to how they accept packets.  So the PEF is likely implemented with a basic data structure which tracks the N latest received packets and keep state if these packets have been seen or not. However, an important implementation detail for this is how this handles when a packet received are significantly higher than previous seen. So does that result in that highest seen are advanced forward to this value? So the 16-bit and 28-bit sequence numbers define a circular space. I assume one tracks the highest sequence number received (H_SN). Based on that one usually consider packets in the range [(H_SN-2^15) MOD 2^16, HSN-1] as older packets not updating the H_SN (for 16-bit sequence numbers) and can consider packets in the range [H_SN+1, H_SN + 2^15-1] as newer. However as N (number of actually tracked packets) are only a sub-set of the fully sequence number the PEF will consider a packet that falls into the range of older packets but outside of the N packets where one have state as to old, and will discard as one lack information about if it is a duplicate or not.  As you may seen this implementation would cause packet loss in the event that packets for this S-Label has passed the ingress and the PRF have put in sequence number and duplicating them and then the packet have been lost due to failure in forwarding the traffic. Then when the network have recovered from this failure there are a significant risk that the packets are outside of the window of validity that would trigger the H_SN to be updated and instead cause all packets to be dropped.  Thus in case of failures there appear to exist a need to be able to reset this state and require the sequence number that is current. And if the details of how these filters are impelementation specific and do not use the ranges I specify the controller would have to potentially cause a reset of the functions for any disturbance as the impact is unknown.  Maybe this is a minor risk in this environment, but the need to reset the POF and PEF state appears necessary for recovery.  D. Denial of service risk with attacker modifying sequence number or performing packet injection between ingress and egrees. Based on what is written in C I would also note that there exist a serious Denial of Service attack on the Detnet flow. If the attacker is capable of either periodically modify the sequence number of an MPLS packet for a particular S-label or inject a MPLS packet into the system that will traverse to the S-Labels PEF or POF at egress with a crafted sequence number. In either of these cases the attacker can advance the acceptance window periodically so that the actual traffic falls into the range that is discarded by the PEF and POF. Thus, cheaply accomplishing a total denial of service. I think this risk due to the PEF and POF should be made explicit in the security considerations. Mitigations needs to be in place to prevent packet modification or injection inside the MPLS network. Some of these appears to be already discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-10 05:56:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-10 03:06:55-07:00",
    "text": "Hi, Thank you for this document. Hopefully a trivial discuss to resolve ... 4.2.1.\u00a0 DetNet Control Word and the DetNet Sequence Number Does this section need to specify the initial value for the sequence number for a new flow? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-12 08:33:54-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-08 11:10:47-07:00",
    "text": "** (Discuss-discuss) Section 6.\u00a0 Per \u201cTo prevent DetNet packets from being delayed by an entity external to a DetNet domain, DetNet technology definition can allow for the mitigation of MiTM attacks, for example through the use of authentication and authorization of devices within the DetNet domain\u201d, can this attack scenario or the appropriate mitigation be clarified.\u00a0 If packets are coming from or going across the DetNet boundary how can any assurances be made?\u00a0 What is architecture element is the \u201cMiTM\u201d (relay? transit? per Figure 2)?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-12-14 16:23:57-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-21 06:53:26-07:00",
    "text": "Section 2.1 & 3.1 Why is authentication limited to server-side authentication?\u00a0 It seems that this really should be mutual authentication to ensure the server is also connecting to the correct client and there was no attack prior to the callback. 3.1 S3 - Why is client-side authentication optional? Without this must, there should be a security consideration that the call back could go to a malicious client.\u00a0 The types of authentication matter as well, but that's covered in Stephen's discuss points along with the SecDir review questions on TLS-PSK.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-24 05:25:22-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-19 01:36:01-07:00",
    "text": "I have three points to discuss, I think these may be fairly easy to resolve, or maybe not, but I'd like to chat about 'em. (1) HTTP Auth: is it ok for a client to send it's e.g. basic auth credential to any of the servers that the client can validate? I.e., is an additional level of pinning needed for this? That would be a new form of pinning and is not defined for either TLS or SSH afaik. That could also be done in various ways and I'm not sure if those might have interoperability consequences. Or perhaps if not doing that, this draft should say something about a need for stronger credentials esp. for basic auth. Did the WG consider this? (2) The secdir review [1] calls out issues related to TLS-PSK and (I guess also) bare keys. I think it'd be good to be speific as to wheher or how those are to be supported here. If you are going to say those are supported, then I suspect some additional text is needed. Kent's answer to that (which was \"see  RFC7589 \" as I read it) doesn't quite do it here I think. that says that certificates must be supported (which is fine)  but doesn't say that TLS-PSK or bare keys can or cannot be  supported. \u00a0  [1]  https://www.ietf.org/mail-archive/web/secdir/current/msg06087.html (3) Consider zmap. When this is deployed, what'll be the effect of surveys that fingerprint all of the devices on the visible Internet who implement this protocol? Did the WG consider that? I'm not sure of the impact, if any, but it could be good if there's a way to help deployments end up less vulnerable to fingerprinting (and the ensuing exposure to unpatched vulns).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-10-04 09:16:05-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 12:10:48-07:00",
    "text": "= Section 4 = \"However, modifying the check list \u00a0  directly can lead to uncoordinated local and remote check lists that \u00a0  result in ICE taking longer to complete or in the worst case scenario \u00a0  fail.\u00a0 The best approach is to modify the formula for calculating the \u00a0  candidate priority value described in ICE [ I-D.ietf-ice-rfc5245bis ] \u00a0  section \"4.1.2.1 Recommended Formula\".\" ICEbis section 4.1.2.1 then says: \"If a host is \u00a0  multihomed because it is dual-stack, the local preference should be \u00a0  set according to the current best practice described in \u00a0  [ I-D.ietf-ice-dualstack-fairness ].\" So, there is a circular reference, and nowhere is it specified how the formula should actually change. I think it's fine to put this in ICEbis, but if this draft is going to reference it then it actually needs to be specified there. Alternatively, if this text is meant to reference the discussion further down in Section 5, I wouldn't call that modifying the formula, but rather providing guidance about how to set local preferences within the formula.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-09-01 07:27:17-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 11:37:33-07:00",
    "text": "This should be very easy to resolve:\u00a0 The Intended RFC status on the datatracker, the Last Call, Shepherd write-up, etc. says Informational, but the header in the document says Best Current Practice.\u00a0 Please update.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-12-22 13:12:10-08:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 12:53:40-07:00",
    "text": "The draft is intended as a BCP, but we ran the IETF Last Call as an informational. This is entirely my fault. I'm entering a \"process\" discuss to hold approval until we can re-run the last call. Let's complete resolve any other issues that come up in IESG evaluation, then I will re-run an abbreviated last call focusing on the status change.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-08-31 05:31:21-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-31 05:30:18-07:00",
    "text": "I'm willing to resolve my discuss quickly but I would like to start some discussion: To me the recommenations given in this doc are not very clear. To my understanding are there two recommenations: 1) intermingle IPv4 and IPv6 addresses, and 2) put lower priority for adresses that are know to have connectivity problem. However, that leaves tons of open questions to the implementor, e.g. - How many IPv6 addresses should I have before the first IPv4? - How do I measure/track that an interface has connectitivy problem? Connectivity failed once, or twice, or X-times? How long do I keep this track: 1h, one day, one week, forever? Would it be possible to be more specific and give further guidance? E.g. how are these points implemented in the existing implementations?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-11-02 03:08:48-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 05:31:21-07:00",
    "text": "I'm willing to resolve my discuss quickly but I would like to start some discussion: To me the recommenations given in this doc are not very clear. To my understanding are there two recommenations: 1) intermingle IPv4 and IPv6 addresses, and 2) put lower priority for adresses that are know to have connectivity problem. However, that leaves tons of open questions to the implementor, e.g. - How many IPv6 addresses should I have before the first IPv4? - How do I measure/track that an interface has connectitivy problems: connectivity failed once, or twice, or X-times? How long do I keep this track: 1h, one day, one week, forever? Would it be possible to be more specific and give further guidance? E.g. how are these points implemented in the existing implementations?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-09-21 22:10:38-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 22:18:54-07:00",
    "text": "* Section 4 I am trying to see if there is any background for the following statement \"It is worth noting that the timing recommendations in [ RFC6555 ] are not optimal for ICE usage.\" Why is it not optimal? Do you want smaller or larger timings? Some explanations here would be good. Additionally, it might be worthwhile for this document to provide alternate timing recommendations that *are* optimal.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-01 20:55:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 19:29:32-07:00",
    "text": "I support Roman's discusses and am happy to see the ongoing discussion thereof. (1) I think there's a conflict between this document and  RFC 8762  with respect to the behavior of pure  RFC 8762  implementations that receive packets longer than the base packet for the given operational mode. RFC 8762  says (Section 4.3): % The Session-Reflector receives the STAMP-Test packet and verifies it. If % the base STAMP-Test packet is validated, the Session-Reflector that % supports this specification prepares and transmits the reflected test % packet symmetric to the packet received from the Session-Sender copying % the content beyond the size of the base STAMP packet (see Section 4.2). But Section 4 of this document says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  A Session-Reflector \u00a0  that does not support STAMP extensions is not expected to compare the \u00a0  value in the Length field of the UDP header and the length of the \u00a0  STAMP base packet.\u00a0 Hence the Session-Reflector will transmit the \u00a0  base STAMP packet.\u00a0 [...] Does \"will transmit the base STAMP packet\" mean something other than \"with the exact length of the base packet [for the given operational mode]\"? (2) As I remarked on (then-)  draft-ietf-ippm-stamp , I think we need to require some level of cryptographic protection whenever control information is included in a Session-Sender's test packet.\u00a0 That is, that a Session-Reflector MUST NOT act on control information received in unauthenticated packets, and specifically, that the HMAC TLV must be used, since the base authenticated STAMP packet's HMAC does not cover the options. (3) The secdir reviewer's question about dealing with 6-to-4 gateways seems to have not gotten a response.\u00a0 Specifically, the requirement that \"[t]he Session-Reflector MUST validate the Length value against the address family of the transport encapsulating the STAMP test packet\" seems to require the protocol to fail when sender and reflector use different address families, or perhaps to require the sender to use trial and error to determine which address family is used by the reflector.\u00a0 Some clarification on the intended operation in such scenarios seems appropriate. (4) The ability for a Session-Sender to (MUST-level!) control the DSCP codepoint used by packets generated by a Session-Reflector feels like it opens up significant risk in site-local (security-relevant) policy.\u00a0 That is, the interpretation of the DSCP codepoints is to large extent site-specific, and allowing a nominally external system to set any/all possible values, without a chance for site policy to be applied and block the use of potentially disruptive DSCP values.\u00a0 So I think we need to modify the \"MUST set\", perhaps requiring that either the requested DSCP value is used or the entire TLV/packet/whatever is rejected. (5) If we're not going to remedy the severability of authenticated options from authenticated base packets (which would be my preferred resolution), we need to document that weakness in the security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-15 17:46:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-01 20:55:05-07:00",
    "text": "Thanks for all the updates; we've made good progress. I think we're still not converged on the DSCP handling, though.\u00a0 I have a bit more exposition in the COMMENT section, but in short, my understanding is that we're setting up a session-reflector to incur unbounded levels of risk with hard protocol requirements.\u00a0 I think we need to provide a way to bound that risk, for example by allowing the Session-Reflector to selectively choose to treat the CoS TLV as unimplemented (set the U flag in its reflected packet) or some other mechanism for local policy to filter what DSCP codepoints are set in reflected packets (ideally, indicating that the policy made a change). Also, there's a bit of fallout from the flags reworking that's left to cleanup in Section 4: we now have the Session-Sender set the U flag to 1, so this text no longer makes sense: % A STAMP system, i.e., either a Session-Sender or a Session-Reflector, % that has received a STAMP test packet with extension TLVs MUST % validate each TLV: % %\u00a0 \u00a0 If the U flag is set, the STAMP system MUST skip the processing of %\u00a0 \u00a0 the TLV. I think it should just apply to the Session-Sender for this case -- the Session-Reflector doesn't need to check the received U flag, since the Session-Sender will not be generating TLVs it does not understand. (Whether or not to keep the behavior for the M and I flags as applying to both Session-Sender and Session-Reflector vs. just Session-Sender does not immediately seem to be of much consequence.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-08-13 17:13:24-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-13 23:25:17-07:00",
    "text": "[ general ] * Please clarify whether the Length is in network byte order or not for all \u00a0 multibyte fields.\u00a0 A single statement, perhaps around 2.0 or something, \u00a0 declaring the convention would suffice (assuming all multibyte integers \u00a0 share the same encoding). * Should there be an IANA registry for the access ID field as well? [ sections 4.2,4.3 ] * I think the L-bit error case guidance may not conform to the guidance \u00a0 in section 4(.0)?\u00a0 Specifically, 4(.0) says if the Length field is funky \u00a0 the copy the rest of the packet into the reponse and set L=1 (yes?). \u00a0 Whereas, 4.2,3 says it MUST zero out the fields (rather than just copy \u00a0 the remainder of the packet).\u00a0 I may have misunderstood something, \u00a0 though.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-08-05 07:09:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-13 10:08:19-07:00",
    "text": "Section 4 says: \"Detected error events MUST be logged.\u00a0 Note that rate of logging MUST be controlled.\" This seems to be incomplete.\u00a0 Why is it a MUST?\u00a0 It doesn't seem to have anything to do with interoperability; if I don't log, nothing breaks.\u00a0 If it's MUST for security reasons, other questions arise: Logged where?\u00a0 What data specifically needs to be logged?\u00a0 How long should they be retained?\u00a0 Do any privacy concerns arise?\u00a0 Do the logs need to be protected at rest? etc.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-08-21 13:50:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-13 10:12:37-07:00",
    "text": "** Section 4.2.\u00a0 The Location TLV is explicitly trying to extract network configuration information that would be elided by the first hop router (MAC) or a NAT (real IP address).\u00a0  RFC8762  helpfully notes that \u201cWhen using STAMP over the Internet \u2026 impact of the STAMP-Test packets MUST be thoroughly analyzed.\u201d\u00a0 Please provide a bit of text describing the privacy implications here (or bound this with an applicability statement). ** Section 4.8.\u00a0 Is the key used for the HMAC TLV the same as the one in the HMAC in the STAMP authenticated packet?\u00a0 Could one use different keys?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-15 19:05:00-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-13 12:10:43-07:00",
    "text": "Two fairly minor points that should be easy to resolve, but seem to be worth some time: I think we need to be a bit more clear about what exactly the contents of the signature OCTET STRING are.\u00a0 Section 3 has a fairly abstract note about including enough information to be self-describing (within the HSS/LMS variants), and Section 5 does better with \"the single HSS signature value resulting from the signing operation as specified in [HASHSIG]\", but it doesn't seem too burdensome to say something like \"the string returned from Algorithm 3 in [ RFC8554 ]\" or even refer back to the description language at the end of Section 2 and avoid any confusion. Section 5 has a \"MUST\" for using the same hash for the CMS digestAlgorithm and the HSS/LMS tree, but Section 6 only has a \"SHOULD\" for the message-digest attribute's digest and the signed attributes digest (the latter of which MUST be the HSS/LMS hash per the previous); should these two requirements be at the same level of normativity?\u00a0 I'm not sure why the one would be more important for correct operation than the other.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:07:14-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-06 11:55:15-08:00",
    "text": "Section 8: Are there plans for the IETF community to develop the guidelines mentioned? I'm wary of publishing an RFC that says the IETF should do something if there are in fact no plans for the IETF to do the thing. RFCs are not necessarily good motivators. Overall this is an interesting document, but it seems to be written in an overly casual way and assumes readers have a lot of context that is not included in the document itself. The Gen-ART review pointed out a number of bits of text that left this impression. It was posted in October and never responded to. I've picked out some bits of the review and added a few more of my own -- collectively addressing these would get the document into publishable shape for a wider audience I think.  General:\u00a0 (1) On first use, please add citations for all the protocols mentioned in the document, as well as a few words to describe what each protocol does. For IETF readers, this will help them understand the implications of various 802 specifications without having to go look them up right away. (2) The IETF meeting network may be interesting as an example to contemplate, but to make this document broadly valuable it would be better to generalize the problem descriptions than to focus on the IETF meeting network. Section 3.1.4 seems a little thin to this non-expert. It is certainly true that \"every station has to be configured to wake up to receive the multicast\", but it seems like only a poorly designed protocol would create the situation where \"the received packet may ultimately be discarded\" on any kind of regular basis. If there are a class of packets that the receiver will ultimately discard, that sounds like they should be on a separate multicast address, or the sender should be determining if the packet will be discarded before sending it. Perhaps what this section is driving at is that multicast protocols are often designed without taking power-saving considerations into account, but then *that's* what this section should probably talk about. As it is, it sounds like the old joke about saying to the doctor, \"My arm hurts when I do this\" and the doctor replying, \"The stop doing that\". In section 3.2.1, the last paragraph is missing a bunch of information: \"It's often the first service that operators drop\": What is \"it\"? \"Multicast snooping\" is not defined. In what scenario are devices \"registering\"? Section 5.1: \"...and sometimes the daemons just seem to stop, requiring a restart of the daemon and causing disruption.\" What a strange thing to say. Does this simply mean \"and the current implementations are buggy\"? Also section 5.1: \"The distribution of users on wireless networks / subnets changes from one IETF meeting to the next\". This document doesn't seem to be about the IETF meeting network. This sentence seems inappropriately specific. The \"NAT\" and \"Stateful firewalls\" sections are also overly specific to the IETF meeting network. Generalizing would help. Section 8: The first paragraph has too little useful comment. There is no reference for 802.1ak, the reference to 802.1Q is inline instead of in the references section, and the content of neither of these standards is explained in this document. The paragraph doesn't really lay out what the topic of discussion is, at least for someone like myself who is not versed in the topic.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-18 18:45:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-01-08 14:19:36-08:00",
    "text": "Section 9 says that \"[ RFC4601 ], for instance, mandates the use of IPsec to ensure authentication of the link-local messages in the Protocol Independent Multicast - Sparse Mode (PIM-SM) routing protocol\" but I could not find where such use of IPsec was mandated.\u00a0 (I do recognize that a similar statement appears almost verbatim in  RFC 5796 , but  RFC 5796  seems focused on extending PIM-SM to support ESP in additon to the AH usage that was the main focus of the  RFC 4601  descriptions, and does not help clarify the  RFC 4601  requirements for me.)\u00a0 The closest I found was in Section 6.3.1 of  RFC 4601 : \"The network administrator defines an SA and SPI that are to be used to authenticate all link-local PIM protocol messages (Hello, Join/Prune, and Assert) on each link in a PIM domain\" but I do not think that applies to all usage of PIM-SM.\u00a0 Am I missing something obvious?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-28 18:50:52-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-18 18:45:30-07:00",
    "text": "Many thanks for all the updates from -11 to -14; the preponderance are good and improve the document. I especially appreciate the change in section 9 to claim only that the use of IPsec is specified, rather than mandated, by the referenced document.\u00a0 Unfortunately, the reference document was changed as well, from  RFC 4601  to  RFC 7761 , but  RFC 7761  calls out as one of the changes from  RFC 4601  that \"authentication using IPsec\" was removed.\u00a0 So the current claim in the -14, that \"[ RFC7761 ] [...] specifies the use of IPsec to ensure authentication of the link-local messages in [PIM-SM]\" is not correct, though for a different reason than what I noted in my ballot position on the -11.\u00a0 It may be most expedient to just restore the reference to the obsolete document, though of course there are other possibilities.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-02-05 11:50:50-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-07 09:54:57-08:00",
    "text": "** Section 9.\u00a0 Section 7 appears to recommend using an ARP sponge per Section 5.1.\u00a0 Please provide some general caution about ARP poisoning/false advertising that could undermine (DoS) this approach (that is being deployed to save battery power).",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-10 03:27:29-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 08:21:10-07:00",
    "text": "I'd like to check if there's a small hole in the security/privacy properties here. If there is I hope that a little re-wording will handle it. You say: (1) \"In RTP sessions where any type of confidentiality protection is enabled for RTCP, the SDES item header extensions MUST also be protected.\" And then you say: (2) \"The security level that is applied to RTCP packets carrying SDES items SHOULD also be applied to SDES items carried as RTP header extensions.\"  My concerns are that the SHOULD in (2) isn't really well motivated (for me) - you just seem to say that someone who doesn't follow the SHOULD has to say why, but I don't think that's likely a run-time concept.\u00a0 Secondly, (1) doesn't say that the new stuff has to be protected in the same way, e.g. with the same endpoints having the keys, and not e.g. where the RTCP data has e2e protection but the new header field just has hop-by-hop protection. Are my concerns justified? (If not, that's fine you'll tell me and we're done:-)  If these are justified concerns, I think we can easily get around them by (a) closing that potential loophole in (1) and (b) s/SHOULD/MUST/ in (2) or else (c) better specify an exception to the SHOULD that makes sense at coding time or at run time.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-10-26 07:30:00-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-25 10:43:56-07:00",
    "text": "1) on p. 19: \"\u00a0 \u00a0 \u00a0 \u00a0 leaf status-code { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type identityref{ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 base status-code; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mandatory true; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Error code for continuity-check message, that is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 relevant to the protocol under use for CC. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 For example if ICMP is the protocol under use, the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 error codes are as defined in [ RFC4443 ].\"; \u00a0 \u00a0 \u00a0 \u00a0 }\" I am quite unclear on how this could technically be used??\u00a0  RFC4443  defines integer error codes or types and sub-codes that are also integers. Is the expectation that an ICMPv6-specific YANG module will define those codes as identityrefs??? Clarification in at least the description is needed, since I don't see how it could be used as currently defined.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-03-09 11:26:08-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-30 08:32:57-08:00",
    "text": "Section 12 says: \"For this reason, it is RECOMMENDED that a different (but stable) IID be \u00a0  generated for each globally scoped address in use according to, for \u00a0  example, [ RFC3315 ], [ RFC3972 ], [ RFC4941 ], [ RFC5535 ], or [ RFC7217 ].\" I have a couple of questions about this recommendation that should be easy to clear up. First, do you really mean \"different\" IID? EUI-64 identifiers are different from each other, but embedding one in an IID still leaves you susceptible to address scanning attacks. Maybe what is meant here is \"semantically opaque\" or \"with maximum supportable entropy\" or something along those lines? Second, what is meant by the word \"stable\" here? The mechanisms cited offer a variety of different \"stability\" spans -- DHCP lease lifetime, temporary address lifetime, lifetime of connection to a link, etc. So it's not clear what is actually being recommended or if the cited mechanisms all provide the desired property.",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-07-24 10:02:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 23:42:39-07:00",
    "text": "Hi, Thanks for the work on this document. While I am supporting the other discusses on this document, I would also like to discuss some of the language in section 8. Specifically:  In order to mitigate the performance-related attacks described above, \u00a0  as described in Section 7 it should be possible for IOAM-enabled \u00a0  devices to selectively apply the mechanisms that use the flags \u00a0  defined in this document to a subset of the traffic, and to limit the \u00a0  performance of synthetically generated packets to a configurable \u00a0  rate.\u00a0 Specifically, IOAM nodes should be able to: Considering the serious security considerations in play here - can we consider making the should here a MUST in both the second and final lines of the above.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-22 00:22:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 22:42:01-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-ioam-flags-09 CC @evyncke Thank you for the work put into this document.  Please find below some blocking DISCUSS points (easy to address as it is about clarifications), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Thanks to Pascal Thubert for his internet directorate review at: https://datatracker.ietf.org/doc/review-ietf-ippm-ioam-flags-09-intdir-telechat-thubert-2022-06-28/  (please consider Pascal's comments as mine). Special thanks to Tommy Pauly for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 4.2 which address `The address of the node performing the copy operation` is confusing in the case of multiple interfaces (typical for a transit device BTW)... Which address should be used ? If the packet was received through an interface with a global address, then this should be the obvious choice or a loopback interface or ??? ### Section 4.2 just truncation ? ``` \u00a0  The copy is also truncated, i.e., any payload that \u00a0  resides after the IOAM option(s) is removed before transmitting the \u00a0  looped back packet back towards the encapsulating node. ``` It is unclear what happens to the IPv6 Next header field... Should the IP header length field be modified ? ### Section 4.2 forwarding ? It is unclear whether the packet is sent back to the source via the received interface or whether the packet is forwarded based on the FIB. ### IANA considerations conflicting text ? In section 4.1: ``` \u00a0  An IOAM trace option that has the Loopback flag set MUST have the \u00a0  value '1' in the most significant bit of IOAM-Trace-Type, and '0' in \u00a0  the rest of the bits of IOAM-Trace-Type.  ``` but in section 6: ``` \u00a0  IANA is requested to allocate the following bits in the \"IOAM Trace \u00a0  Flags Registry\" as follows: \u00a0  Bit 1\u00a0 \"Loopback\" (L-bit) \u00a0  Bit 2\u00a0 \"Active\" (A-bit) \u00a0  Note that bit 0 is the most significant bit in the Flags Registry. ``` Is it bit 0 or bit 1 ?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-18 12:08:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 10:40:25-07:00",
    "text": "Thanks for this document. I have one issue I'd like to be sure we clear up. 1. In \u00a74.1.1, \u00a0  The loopback flag MUST NOT be set if it is not guaranteed that there \u00a0  is a return path from each of the IOAM transit and IOAM decapsulating \u00a0  nodes,  \u00a0   This is heartwarming but I can\u2019t see how you could guarantee this property at all times in any network using dynamic routing or even subject to dynamic conditions (and that would be all networks), and for that matter I\u2019m not sure how to write code to even determine this in any general way. Is it your intention that this MUST NOT is directed to the operator and not to the code implementor? Or perhaps is it for very small values of \u201cguarantee\u201d? That is, is this an aspirational MUST and not a MUST MUST? In general it's a little problematic when we use  RFC 2119  keywords in a protocol document, to express desires about how a protocol's operator should deploy it. They are at their best when used to express requirements for how a coder should implement the protocol. Please consider creating an operational considerations section, and grouping operational requirements and advice there, at least in that case it becomes clear to whom the  RFC 2119  keywords are speaking.  Alternately, please qualify the keywords appropriately in-line, e.g. in the above text you could say something like \u00a0  The domain MUST be configured such that there is expected to be a return \u00a0  path from each of the IOAM transit and IOAM decapsulating nodes; if this \u00a0  expectation does not apply then configuration MUST NOT enable the loopback \u00a0  flag to be set, \u00a0   To me it seems as though it might be less painful to group these into an operational considerations section, but whatever works for you, as long as it's clear. I did a cursory check over the document with this in mind, the other place I identified what looks like operational guidance to me is also in \u00a74.1.1, the paragraph about how you \"SHOULD NOT exceed 1/N of the interface capacity\". At first blush that looks like something that could be computed automatically by inspection of the router's hardware, but by the time we get to the end of the paragraph we see that \"prior knowledge about the network topology or size\" is needed, so it must really be operational guidance. (Possibly this applies to the 1/N paragraphs in \u00a74.2 and \u00a75 also, although it's less clearly the case.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-07-14 20:31:51-07:00",
    "text": "It seems that we accumulated some factual errors by letting this draft sit mostly idle since 2018, as the world evolved around us.\u00a0 Hopefully these are easy to remedy... Section 3.4.1.2 claims to have a list of options that have been specified as Hop-by-Hop options, and Section 3.4.6.2 a list of options that have been specified as Destination Options, each respectively \"at the time of this writing\".\u00a0 IANA has a single registry for both Destination and Hop-by-Hop options, and assessing which ones are defined as Hop-by-Hop vs Destinationmay require following each reference, but it seems that the PDM option from  RFC 8250  has been allocated and is in neither list, and the early allocations for IOAM and Path MTU Record may need to be considered as well.\u00a0 I suppose that we do attempt to go into the individual optiosn in detail in Section 4.3, so perhaps this is not quite so simple to remedy after all. (Note: while it is not the preferred outcome, merely changing the statement from \"time of this writing\" and \"so far been specified\" to \"as of 2018\" ought to be sufficient to resolve the discuss, as would Lars' suggestion of just referring to the IANA registry without incorporating the registry contents.) Section 3.4.8.1 refers to HIP as an \"experimental protocol\", but as of RFC 7401 , HIP is on the standards track. Also, there seems to be some skew between Table 1 and Section 3.4.10.5 regarding the recommended filtering policy for the experimental/testing EH types (drop vs [no recommendation])",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-16 12:26:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-07-13 06:23:29-07:00",
    "text": "Can the principled approach to making these recommendations be more clearly explained and documented?\u00a0 Section 3 primarily establishes a two-option filtering regime (drop vs. permit), but Section 4 seems to provide more nuance with a three-option filtering regime which considers the needs of the network (drop vs. drop if functionality not needed vs. permit).\u00a0 As an aside, a fourth filtering action of removing the options is presented in Section 4.3.9.4.\u00a0 Additionally, see the comment below which has a summary table for recommendations in Section 4 analogous to Table 1 of Section 3 to allow side-by-side comparisons. Was the three-option filtering regime considered for all recommendations?\u00a0 For example, Section 4.3.7.5 , Router Alert (Type=0x05) recommends permitting this option \u201cin environments where support for RSVP, multicast routing, or similar protocols is desired.\u201d (i.e., \u201cdrop if functionality is not needed\u201d).\u00a0 However, Section 3.4.8, HIP (Protocol Number=139) recommend categorically permitted these packets. If an operator knows that HIP is not a technology they have a desire to use in an environment, why shouldn\u2019t they block it (just like was suggested for Router Alerts)? Consideration for conditional discard based on local needs seems appropriate for Shim6, Mobility Header, HIP, ILNP Nonce, Tunnel Encapsulation, and all RPL options if the goal is to minimize traffic which has to go on the slow path. I read in the shepherd\u2019s write-up that trade-offs were made to minimize ossification.\u00a0 However, that rationale is not apparent in the text.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-06-16 14:37:12-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-16 12:26:46-07:00",
    "text": "Can the principled approach to making these recommendations be more clearly explained and documented?\u00a0 Section 3 primarily establishes a two-option filtering regime (drop vs. permit), but Section 4 seems to provide more nuance with a three-option filtering regime which considers the needs of the network (drop vs. drop if functionality not needed vs. permit).\u00a0 As an aside, a fourth filtering action of removing the options is presented in Section 4.3.9.4.\u00a0 Additionally, see the comment below which has a summary table for recommendations in Section 4 analogous to Table 1 of Section 3 to allow side-by-side comparisons. Was the three-option filtering regime considered for all recommendations?\u00a0 For example, Section 4.3.7.5 , Router Alert (Type=0x05) recommends permitting this option \u201cin environments where support for RSVP, multicast routing, or similar protocols is desired.\u201d (i.e., \u201cdrop if functionality is not needed\u201d).\u00a0 However, Section 3.4.8, HIP (Protocol Number=139) recommend categorically permitted these packets. If an operator knows that HIP is not a technology they have a desire to use in an environment, why shouldn\u2019t they block it (just like was suggested for Router Alerts)? Consideration for conditional discard based on local needs seems appropriate for Shim6, Mobility Header, HIP, ILNP Nonce, Tunnel Encapsulation, and all RPL options if the goal is to minimize traffic which has to go on the slow path. I read in the shepherd\u2019s write-up that trade-offs were made to minimize ossification.\u00a0 However, that rationale is not apparent in the text. See also the text from Ben Kaduk's DISCUSSes which I am taking on.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-30 10:29:55-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-29 16:01:17-07:00",
    "text": "Not so much an objection, but a question: What would happen if, in response to a DHCPDISCOVER with the IPv6-only offer, an attacker spoofed a DHCPOFFER with this option and a V6ONLY_WAIT value of UINT32_MAX, when in fact there was no NAT64, or v6 capability, at all? Would the very long timeout amplify existing DoS attacks on DHCP?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-15 18:57:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 15:01:52-07:00",
    "text": "This is essentially a process discuss, and hopefully easy to resolve. In Section 4, we say: \u00a0  The meaning of the absence of both Node and Link MSD advertisements \u00a0  for a given MSD type is specific to the MSD type.\u00a0 Generally it can \u00a0  only be inferred that the advertising node does not support \u00a0  advertisement of that MSD type.\u00a0 However, in some cases the lack of \u00a0  advertisement might imply that the functionality associated with the \u00a0  MSD type is not supported.\u00a0 The correct interpretation MUST be \u00a0  specified when an MSD type is defined. I don't think we can make this sort of normative requirement on a registry  created by a different document, at least not without updating the registry to also point to this document.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-03-18 07:08:36-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-17 02:18:22-07:00",
    "text": "Thanks for writing this document. Before recommending its approval, I need to have a discussion with you about one aspect. Joel Halpern raised a question in his Gen-ART review: As per the pointer in this document to  RFC 3406  section 4.3, this document is required to have a Namespace Considerations section which \"outlines the perceived need for a new namespace (i.e., where existing namespaces fall short of the proposer's requirements).\"\u00a0 While there is a section called Namespace Considerations, what it lists is the envisioned usages, not the reasons existing name spaces are insufficient. Is there an answer, or an update?  I cannot imagine adding the requested rationale is difficult to add in this case, but it probably should be added. Thoughts?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-12-24 11:02:13-08:00",
    "end_reason": "position_updated",
    "start": "2017-11-10 19:12:04-08:00",
    "text": "https://mozphab-ietf.devsvcdev.mozaws.net/D3970 \u00a0  2^64 bytes in the underlying TCP datastream (which would cause the \u00a0  \"offset\" field to wrap) before re-keying. \u00a0   In TLS and other WGs, we have adopted the practice of salting the nonce with a secret per-connection value to avoid large-scale surveillance attacks. Why did you opt to use a weaker construction. See: https://tlswg.github.io/tls13-spec/draft-ietf-tls-tls13.html#security-record-layer and  https://eprint.iacr.org/2016/564 . \u00a0  FIN flag set, it MUST immediately send a frame (with empty \u00a0  application data if necessary) with \"rekey = 1\". \u00a0   I don't think that the algorithm in this section necessarily works properly, because you have to handle rekeys in sequence: Frame 1 [0:999] Frame 2 [1000:1999, rekey=1] Frame 3 [2000:2999, rekey=1] Now what happens if the frames are re-ordered so you get Frame 3 and then Frame 2. You will try to decrypt Frame 3 with generation 2 and Frame 2 with generation 3, neither of which will work (though you might be able to interpret the text loosely to have you try to decrypt Frame 2 with generation 2). Note that if you were to resequence before processing, this wouldn't happen. At minimum I think some clarification is needed here. Given that you are allowing P-256 and point reuse, you should be requiring point validation. See: https://tlswg.github.io/tls13-spec/draft-ietf-tls-tls13.html#rfc.section.4.2.8.2 https://tlswg.github.io/tls13-spec/draft-ietf-tls-tls13.html#elliptic-curve-diffie-hellman You should probably also be requiring Curve25519 output validation. You still seem to need to specify an MTI symmetric algorithm.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-05 04:07:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-30 17:46:10-07:00",
    "text": "I have two things I'd like to discuss about this draft: (1) section 3: Are there any potential security issues with namedest as a parameter? E.g. has any PDF reader or MIME handler followed an absolute URL for the value there perhaps? If so, is there a warning it'd be useful to give?\u00a0 Are there any other similarly known potential vulnerabilities for other parameters? (Maybe fdf or ef?) (This is also related to discuss-point-2 below) (2) section 6: It's a pity there's no ISO document to reference in this section as PDF files have been the vector for various threats over the years. Can't you find some reference (from ISO or not) that a viewer or author developer would find helpful? That section seems pretty vague to me as-is. (In particular the last clause of the last sentence in this section is not useful.) And I see from the discussion of the secdir review ([1], did any authors respond to that? If so I didn't see it, sorry).\u00a0 The discuss point here is that we seem to have less good security considerations compared with  RFC3778 , and I think that ought be justified if it's the right thing to do. (Not necessarily in the document if that's not correct, but at least as part of the record, e.g. in response to this.) \u00a0  [1]  https://www.ietf.org/mail-archive/web/secdir/current/msg06674.html comments",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-02-27 01:22:37-08:00",
    "end_reason": "position_updated",
    "start": "2016-09-05 04:07:25-07:00",
    "text": "I have one remaining thing I'd like to discuss about this draft that I don't think was answered in Larry's earlier response. [2] \u00a0 [2]\u00a0  https://mailarchive.ietf.org/arch/msg/ietf/yKbjLYUcxHHdj63PbrWbte12jBE (1) section 3: Are there any potential security issues with namedest as a parameter? E.g. has any PDF reader or MIME handler followed an absolute URL for the value there perhaps? If so, is there a warning it'd be useful to give?\u00a0 Are there any other similarly known potential vulnerabilities for other parameters? (Maybe fdf or ef?) (This is also related to discuss-point-2 below) I don't think this was answered in [2]. To try rephrase it: \"What (if any) security considerations text is needed about  the parameters of application/pdf?\"",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-10-26 13:23:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-10-26 13:23:11-07:00",
    "text": "### Clarity about scope of the document As I understand it, this document isn't intended to be an implementable protocol specification on its own; rather, \"specification details for these different echo request/reply protocols are outside the scope of this document\". I'm not crazy about this approach, but if it's to be followed there are some changes needed. Below I provide some suggested text -- please know that I'm just supplying this as a straw man to illustrate my thinking; while you're welcome to use the text I've provided, I don't necessarily expect that. The Abstract says that \"This document describes an extension to the echo request/reply mechanisms\". It does not. Here's an example of how it might be changed to be clearer. OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including Segment Routing with IPv6 data \u00a0  plane (SRv6)), MPLS (including Segment Routing with MPLS data plane \u00a0  (SR-MPLS)), Service Function Chain (SFC) and Bit Index Explicit \u00a0  Replication (BIER) environments, which can be used within the In situ \u00a0  Operations, Administration, and Maintenance (IOAM) domain, allowing \u00a0  the IOAM encapsulating node to discover the enabled IOAM capabilities \u00a0  of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  There is a need to extend echo request/reply mechanisms used in IPv6 \u00a0  (including Segment Routing with IPv6 data plane (SRv6)), MPLS \u00a0  (including Segment Routing with MPLS data plane (SR-MPLS)), Service \u00a0  Function Chain (SFC) and Bit Index Explicit Replication (BIER) \u00a0  environments, for use within the In situ Operations, Administration, \u00a0  and Maintenance (IOAM) domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. \u00a0  Although this document does not itself specify the necessary \u00a0  extensions, it specifies formats and objects that can be used in such \u00a0  specifications, and provides guidelines and requirements for their \u00a0  development. I think the Introduction also needs to be cleaned up. Saying that \"specification details... are outside the scope\" undersells the scope of what's needed. For example, maybe these changes would work in the Introduction: OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including SRv6), MPLS (including SR-MPLS), \u00a0  SFC and BIER environments, which can be used within the IOAM domain, \u00a0  allowing the IOAM encapsulating node to discover the enabled IOAM \u00a0  capabilities of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  This document specifies formats and objects that can be used in the \u00a0  extension of echo request/reply mechanisms used in IPv6 (including \u00a0  SRv6), MPLS (including SR-MPLS), SFC and BIER environments, which can \u00a0  be used within the IOAM domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. OLD: \u00a0  Note that specification details for these different echo request/ \u00a0  reply protocols are outside the scope of this document.\u00a0 It is \u00a0  expected that each such protocol extension would be specified by an \u00a0  RFC and jointly designed by the working group that develops or \u00a0  maintains the echo request/reply protocol and the IETF IP Performance \u00a0  Measurement (IPPM) Working Group. NEW: \u00a0  It is expected that the specification of the instantiation of each of \u00a0  these extensions will be done in the form of an RFC jointly designed \u00a0  by the working group that develops or maintains the echo \u00a0  request/reply protocol and the IETF IP Performance Measurement (IPPM) \u00a0  Working Group. \u00a0   ### Clarity of formats Because this document is specifying things (or trying to) in absence of any concrete instantiation, it's very difficult for me to evaluate if the formats as specified are complete and unambiguous. For now I've left my detailed discussion of this in my COMMENT section, and am optimistic that we can sort it out. However, I'm putting a placeholder here in case that problem turns out to be thornier than hoped.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-10-26 13:25:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-10-26 13:23:56-07:00",
    "text": "### Clarity about scope of the document As I understand it, this document isn't intended to be an implementable protocol specification on its own; rather, \"specification details for these different echo request/reply protocols are outside the scope of this document\". If this approach is to be followed there are some changes needed. Below I provide some suggested text -- please know that I'm just supplying this as a straw man to illustrate my thinking; while you're welcome to use the text I've provided, I don't necessarily expect that. The Abstract says that \"This document describes an extension to the echo request/reply mechanisms\". It does not. Here's an example of how it might be changed to be clearer. OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including Segment Routing with IPv6 data \u00a0  plane (SRv6)), MPLS (including Segment Routing with MPLS data plane \u00a0  (SR-MPLS)), Service Function Chain (SFC) and Bit Index Explicit \u00a0  Replication (BIER) environments, which can be used within the In situ \u00a0  Operations, Administration, and Maintenance (IOAM) domain, allowing \u00a0  the IOAM encapsulating node to discover the enabled IOAM capabilities \u00a0  of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  There is a need to extend echo request/reply mechanisms used in IPv6 \u00a0  (including Segment Routing with IPv6 data plane (SRv6)), MPLS \u00a0  (including Segment Routing with MPLS data plane (SR-MPLS)), Service \u00a0  Function Chain (SFC) and Bit Index Explicit Replication (BIER) \u00a0  environments, for use within the In situ Operations, Administration, \u00a0  and Maintenance (IOAM) domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. \u00a0  Although this document does not itself specify the necessary \u00a0  extensions, it specifies formats and objects that can be used in such \u00a0  specifications, and provides guidelines and requirements for their \u00a0  development. I think the Introduction also needs to be cleaned up. Saying that \"specification details... are outside the scope\" undersells the scope of what's needed. For example, maybe these changes would work in the Introduction: OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including SRv6), MPLS (including SR-MPLS), \u00a0  SFC and BIER environments, which can be used within the IOAM domain, \u00a0  allowing the IOAM encapsulating node to discover the enabled IOAM \u00a0  capabilities of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  This document specifies formats and objects that can be used in the \u00a0  extension of echo request/reply mechanisms used in IPv6 (including \u00a0  SRv6), MPLS (including SR-MPLS), SFC and BIER environments, which can \u00a0  be used within the IOAM domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. OLD: \u00a0  Note that specification details for these different echo request/ \u00a0  reply protocols are outside the scope of this document.\u00a0 It is \u00a0  expected that each such protocol extension would be specified by an \u00a0  RFC and jointly designed by the working group that develops or \u00a0  maintains the echo request/reply protocol and the IETF IP Performance \u00a0  Measurement (IPPM) Working Group. NEW: \u00a0  It is expected that the specification of the instantiation of each of \u00a0  these extensions will be done in the form of an RFC jointly designed \u00a0  by the working group that develops or maintains the echo \u00a0  request/reply protocol and the IETF IP Performance Measurement (IPPM) \u00a0  Working Group. \u00a0   ### Clarity of formats Because this document is specifying things (or trying to) in absence of any concrete instantiation, it's very difficult for me to evaluate if the formats as specified are complete and unambiguous. For now I've left my detailed discussion of this in my COMMENT section, and am optimistic that we can sort it out. However, I'm putting a placeholder here in case that problem turns out to be thornier than hoped.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-21 13:44:06-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 13:25:26-07:00",
    "text": "### Clarity about scope of the document As I understand it, this document isn't intended to be an implementable protocol specification on its own; rather, \"specification details for these different echo request/reply protocols are outside the scope of this document\". If this approach is to be followed there are some changes needed. Below I provide some suggested text -- please know that I'm just supplying this as a straw man to illustrate my thinking; while you're welcome to use the text I've provided, I don't necessarily expect that. The Abstract says that \"This document describes an extension to the echo request/reply mechanisms\". It does not. Here's an example of how it might be changed to be clearer. OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including Segment Routing with IPv6 data \u00a0  plane (SRv6)), MPLS (including Segment Routing with MPLS data plane \u00a0  (SR-MPLS)), Service Function Chain (SFC) and Bit Index Explicit \u00a0  Replication (BIER) environments, which can be used within the In situ \u00a0  Operations, Administration, and Maintenance (IOAM) domain, allowing \u00a0  the IOAM encapsulating node to discover the enabled IOAM capabilities \u00a0  of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  There is a need to extend echo request/reply mechanisms used in IPv6 \u00a0  (including Segment Routing with IPv6 data plane (SRv6)), MPLS \u00a0  (including Segment Routing with MPLS data plane (SR-MPLS)), Service \u00a0  Function Chain (SFC) and Bit Index Explicit Replication (BIER) \u00a0  environments, for use within the In situ Operations, Administration, \u00a0  and Maintenance (IOAM) domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. \u00a0  Although this document does not itself specify the necessary \u00a0  extensions, it specifies formats and objects that can be used in such \u00a0  specifications, and provides guidelines and requirements for their \u00a0  development. I think the Introduction also needs to be cleaned up. Saying that \"specification details... are outside the scope\" undersells the scope of what's needed. For example, maybe these changes would work in the Introduction: OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including SRv6), MPLS (including SR-MPLS), \u00a0  SFC and BIER environments, which can be used within the IOAM domain, \u00a0  allowing the IOAM encapsulating node to discover the enabled IOAM \u00a0  capabilities of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  This document specifies formats and objects that can be used in the \u00a0  extension of echo request/reply mechanisms used in IPv6 (including \u00a0  SRv6), MPLS (including SR-MPLS), SFC and BIER environments, which can \u00a0  be used within the IOAM domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. OLD: \u00a0  Note that specification details for these different echo request/ \u00a0  reply protocols are outside the scope of this document.\u00a0 It is \u00a0  expected that each such protocol extension would be specified by an \u00a0  RFC and jointly designed by the working group that develops or \u00a0  maintains the echo request/reply protocol and the IETF IP Performance \u00a0  Measurement (IPPM) Working Group. NEW: \u00a0  It is expected that the specification of the instantiation of each of \u00a0  these extensions will be done in the form of an RFC jointly designed \u00a0  by the working group that develops or maintains the echo \u00a0  request/reply protocol and the IETF IP Performance Measurement (IPPM) \u00a0  Working Group. \u00a0   ### Clarity of formats Because this document is specifying things (or trying to) in absence of any concrete instantiation, it's difficult for me to evaluate if the formats as specified are complete and unambiguous. For now I've left my detailed discussion of this in my COMMENT section, and am optimistic that we can sort it out. However, I'm putting a placeholder here in case that problem turns out to be thornier than hoped.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-11-06 23:21:56-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-27 00:22:33-07:00",
    "text": "Hi, I support Roman and Warren's discuss, and again, I have a similar, but slightly separate concern: (1) p 14, sec 6.\u00a0 Security Considerations \u00a0  To protect against unauthorized sources using echo request messages \u00a0  to obtain IOAM Capabilities information, it is RECOMMENDED that \u00a0  implementations provide a means of checking the source addresses of \u00a0  echo request messages against an access list before accepting the \u00a0  message. I'm concerned that performing a source address filtering isn't necessarily that secure, compared with use NETCONF or RESTCONF that can provide AAA access controls.\u00a0 Hence, I think that the security considerations should REQUIRE that IOAM daemons do not respond to these capability requests unless explicitly configured to do so, specifically to avoid implementations potentially leaking information if they are not aware of this functionality (e.g., if it was enabled by default).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-11-07 01:52:59-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-25 19:20:58-07:00",
    "text": "Section 6. \u00a0  A deployment can increase security by using border filtering of \u00a0  incoming and outgoing echo requests/replies. Thanks for calling out the security impact of echo request/replies.\u00a0 Since the cited  RFC9197  reminds the reader that a \u201cnetwork operator is expected to enforce policies that prevent IOAM traffic from leaking outside of the IOAM-Domain\u201d, why is this guidance not mandatory? Would the following text be more appropriate? NEW A deployment MUST ensure that border filtering drops inbound echo requests with a IOAM Capabilities Container Header from outside of the domain, and drops outbound echo request/replies with IOAM Capabilities Headers leaving the domain.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-10-27 06:46:17-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 13:14:55-07:00",
    "text": "Thank you very much for writing this document. Please see:  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ My concerns are closely related to Roman's DISCUSS point: The document says: \"A deployment can increase security by using border filtering of incoming and outgoing echo requests/replies.\" I'm unclear why this is just a \"can increase security\", and not something much much stronger -- but, also, I'm unclear how exactly an operator would be expected to filter these. The Abstract says: \"This document describes an extension to the echo request/reply mechanisms used in [...]\", but from what I can tell, it is more \"here are some containers that you could use in some other protocols\". It seems like, instead of only relying on the network for filtering (which doesn't yet seem to be implemented), the: \"To protect against unauthorized sources using echo request messages to obtain IOAM Capabilities information, it is RECOMMENDED that implementations provide a means of checking the source addresses of echo request messages against an access list before accepting the message.\" should be made stronger. Implementations need to be created to understand IOAM, and so requiring that they have the capability to only accept configured source addresses seems simple.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-08-30 15:28:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-20 09:40:29-07:00",
    "text": "I may be missing something, but I don't see anything that says whether the preference field introduced in Section 3.2.3 uses larger values or smaller values for more-preferred SRMSes. The introduction of the SRMS is also introducing a new way for a protocol participant to make claims about route prefixes directed at \"third parties\" (non-MS, non-MC routers).\u00a0 While routing protocols in general do require high levels of trust in all participants in order for proper routing to occur, this addition seems to create a \"first among equals\" situation that could be called out more clearly in the security considerations.\u00a0 (I do appreciate that the requirement for preferring SIDs advertised in prefix reachability advertisements over those advertised in mapping server advertisements does help alleviate some of the risk.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-09-02 14:33:24-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-30 15:28:49-07:00",
    "text": "addressed, but before I go clear that I was hoping you could help me\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  remember why the following text was removed when going from -13 to -14:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [...] Because this document recognizes that\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   miscofiguration and/or programming may result in false or conflicting\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   label binding advertisements, thereby compromising traffic\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  forwarding, the document recommends strict configuration/\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   programmability control as well as montoring the SID advertised and\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   log/error messages by the operator to avoid or at least significantly\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   minimize the possibility of such risk.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  I couldn't find anything in my email history that helped jog my memory.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-03-15 00:39:44-07:00",
    "end_reason": "position_updated",
    "start": "2023-01-31 01:01:47-08:00",
    "text": "# GEN AD review of  draft-ietf-mls-protocol-17 CC @larseggert ## Discuss ### Section 17.1, paragraph 11 ``` \u00a0 \u00a0  *\u00a0 Recommended: Whether support for this ciphersuite is recommended \u00a0 \u00a0 \u00a0 \u00a0 by the IETF MLS WG.\u00a0 Valid values are \"Y\", \"N\", and \"D\", as \u00a0 \u00a0 \u00a0 \u00a0 described below.\u00a0 The default value of the \"Recommended\" column is \u00a0 \u00a0 \u00a0 \u00a0 \"N\".\u00a0 Setting the Recommended item to \"Y\" or \"D\", or changing a \u00a0 \u00a0 \u00a0 \u00a0 item whose current value is \"Y\" or \"D\", requires Standards Action \u00a0 \u00a0 \u00a0 \u00a0 [ RFC8126 ]. ``` The IETF MLS WG may (should) close at some future point. I think the text should talk about the IETF recommending a ciphersuite, not the MLS WG. ### Unclear RFC status Intended RFC status in datatracker is \"Proposed Standard\", but document says \"Informational\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-04 10:14:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-03 18:16:27-08:00",
    "text": "[This is a preliminary Discuss placed before a full document review is complete, to give the authors additional time to consider and respond] The YANG doctor last call review of the -06 notes that these modules are in violation of the expectations of  RFC 8349  (at least w.r.t. defining a new identity for the control-plane protocol and probably also w.r.t. augmenting the \"control-plane-protocol\" under \"/routing\").\u00a0 This document should either be brought into compliance or explain why it diverges. The YANG doctor's comments about the default values for the \"local\" graceful-restart configuration causing the global configuration to never take effect also should be addressed. The YANG doctor also noted that the \"md5-key\" leaf does not specify its semantics, and is presumably sensitive (so that a crypto-type would be more appropriate).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 13:55:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-04 10:14:30-08:00",
    "text": "The YANG doctor last call review of the -06 notes that these modules are in violation of the expectations of  RFC 8349  (at least w.r.t. defining a new identity for the control-plane protocol and possibly more).\u00a0 This document should either be brought into compliance or explain why it diverges. The YANG doctor's comments about default values for \"local\" configuration (e.g., graceful-restart configuration) causing the global configuration to never take effect should also be addressed. Please include some justification for why LDP IPv6 is considered an \"extended feature\" (which is particularly surprising given that Section 2 classifies \"IP\" to refer to both IPv4 and IPv6 together). We need to define the format/semantics of the md5-key string (e.g., is it hex? base64{url,}?) either directly or by reference (as the YANG doctor notes).\u00a0 Using a crypto-type would probably be appropriate, as would adding a note that tcp-md5 is obsoleted by TCP-AO. In the peer-af-policy-container grouping's label-policy/advertise/prefix-list, we need to say if the filter is for inclusion or exclusion of outgoing label advertisements. Similarly for the incoming label advertisements in the 'accept' container (and most of the -list-ref usages?). In the policy-container grouping's label-policy/assign/independent-mode/prefix-list, the description suggests that the contents will provide not just a list of prefixes that act as a filter, but also a map from prefix to label.\u00a0 This is a qualitatively different usage than the previous occurrences of prefix-list-ref, and it seems like a different type may be needed for it.\u00a0 Similarly for ordered-mode. (pro-forma) This document has 6 authors, and per  RFC 7322 , as this is more than five, we are supposed to consider whether that's appropriate. Seeing nothing in the shepherd writeup or similar, I mention it here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 09:14:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-17 13:55:47-07:00",
    "text": "[updating Discuss to reflect points addressed by the -08; COMMENT unchanged from -07] Please include some justification for why LDP IPv6 is considered an \"extended feature\" (which is particularly surprising given that Section 2 classifies \"IP\" to refer to both IPv4 and IPv6 together). We need to define the format/semantics of the md5-key string (e.g., is it hex? base64{url,}?) either directly or by reference (as the YANG doctor notes).\u00a0 Using a crypto-type in the base model as opposed to only as an extension would probably be appropriate, as would adding a note that tcp-md5 is obsoleted by TCP-AO.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-03-23 01:31:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-18 04:02:44-07:00",
    "text": "Thank you for addressing my previous comments (especially around the IPv6 support). But, I am now balloting a DISCUSS because  I-D.ietf-rtgwg-policy-model \u00a0 MUST be a normative reference as it is referenced by the YANG modules of this document. I.e., this document cannot be published _BEFORE_  I-D.ietf-rtgwg-policy-model  ... Else, it will be useless. Regards -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-28 06:16:28-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 05:26:40-08:00",
    "text": "Thank you for using the YANG Security Considerations template.\u00a0 Could you please provide more details on which nodes are sensitive to write and read issues; and the RPC operations of concern.\u00a0 For example, see  draft-ietf-isis-yang-isis-cfg  or draft-ietf-ospf-yang.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-07-05 19:30:35-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-20 15:58:34-07:00",
    "text": "The RespTransCnt mechanism seems to be a bit fragile and error prone possibly leading to wrong conclusions on the client (please see my example below). If you agree with my assessment, it is probably useful to evaluate whether the added complexity of this RespTransCnt mechanism is worth it for the potentially unreliable results it produces.  Consider the following two cases (copy paste with a monospace font for better readability) Case 1: Upstream loss of first \"re\"transmission |\u00a0 Upstream loss\u00a0 | |\u00a0 Client\u00a0 Server | +-+-+-+-+-+-+-+-+-+ |\u00a0 1\u00a0 \u00a0 \u00a0 \u00a0  x\u00a0 \u00a0 | |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | |\u00a0 2\u00a0 \u00a0 \u00a0 \u00a0  2,1\u00a0 | |\u00a0 \u00a0 2,1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Case 2: Downstream loss of response to first \"re\"transmission with re-ordering | Downstream loss | |\u00a0 Client\u00a0 Server | +-+-+-+-+-+-+-+-+-+ |\u00a0 1\u00a0 \u00a0 \u00a0 \u00a0  1,2\u00a0 | |\u00a0 \u00a0 x\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | |\u00a0 2\u00a0 \u00a0 \u00a0 \u00a0  2,1\u00a0 | |\u00a0 \u00a0 2,1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | How does the client differentiate between these two cases?",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2016-01-05 10:02:52-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-04 10:18:12-08:00",
    "text": "I support the publication of this document, but I have a point I want to discuss to help with the clarity of the spec. Section 3.2.1 says that clients send this option with the first query sent on a TCP connection and Section 3.2.2 says it should honor the timeout provided by the server and close the socket when appropriate. What is not discussed is how the client should manage the timer with respect to the reception of multiple query responses that may, or may not, include edns-tcp-keepalive option. Section 3.3.2 says the server MAY send the option, so it is up to the server to decide when to include the option and the corresponding timeout value. Should the client's timer simply reflect the value sent in the latest response? The smallest remaining time? I think a few sentences on client timer management would be beneficial.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-07 07:18:56-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-06 12:57:48-08:00",
    "text": "Before I ballot yes on this I have a question to ask. Most likely the answer will be the obvious one and we'll be done, but I want to check and if the answer is not the obvious one then holding the discuss as we fix stuff would be correct I think. The question: how does this option play with DNS over DTLS? [1]  The reason I ask is that there may be a need in that case for some similar option (or a TLS extension maybe) though for the DTLS session lifetime and not a TCP session lifetime. At present you are saying that this option is not it. And that's a fine answer but you could also have said that this could also be used for DTLS session lifetime handling. And that last might make sense for operational reasons (not sure really, but could be).\u00a0  \u00a0  [1]  https://tools.ietf.org/html/draft-ietf-dprive-dnsodtls-03",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-11-09 12:33:47-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-14 10:50:59-07:00",
    "text": "I'm balloting DISCUSS because the specification in \u00a79.1.1 is not clear, and it is not in sync with draft-ietf-idr-tunnel-encaps.\u00a0 [Some of the points below are not DISCUSS-worthy, but I'm including them here because they are related to the larger point.] \u00a79.1.1 talks about using the Encapsulation Extended Community *and* the Router's MAC Extended Community.\u00a0 However, the requirement for these communities to appear together is not explicit anywhere.\u00a0 What are the implications for only one of them being present? The Router's MAC Extended Community \"is only required when Ethernet NVO tunnel type is used\".\u00a0 It seems to me that normatively requiring the extended community is important in this case. What exactly is the \"Ethernet NVO tunnel type\"?\u00a0 \u00a71 (Terminology) says that \"Examples of this type of tunnels are VXLAN or GENEVE.\"\u00a0 A standards track document should be specific about when something is required.\u00a0 For example, I assume that it would also be required when using NVGRE.\u00a0 The tunnel types are a finite number, so please be specific. Where is the GENEVE tunnel type (to be used in the Encapsulation Extended Community) defined?\u00a0 BTW, the [GENEVE] reference is also missing. \u00a74 has this text: \"the tunnel connecting these IP-VRFs can be either IP-only tunnel (in case of MPLS or GENEVE encapsulation) or Ethernet NVO tunnel (in case of VxLAN encapsulation).\"\u00a0 It confuses me because of the apparent contradiction between GENEVE being an example of an Ethernet NVO tunnel type, but also (?) an IP-only tunnel in this case. \u00a74.2/draft-ietf-idr-tunnel-encaps mentions possible conflicts created by the Router's MAC Extended Community and how it may be ignored, but this document doesn't mention using the Encapsulation Sub-TLVs (also from  draft-ietf-idr-tunnel-encaps ) for the same function.\u00a0 Can the same function be achieved with the Encapsulation Sub-TLVs? \"section 4.5 of [TUNNEL-ENCAP]\" is mentioned a couple of times, but there is no \u00a74.5 in  draft-ietf-idr-tunnel-encaps , and there's no reference either.\u00a0 Please remove the specific section number (to avoid becoming out of sync), and instead mention the Encapsulation Extended Community by name.\u00a0 Add a Normative reference to draft-ietf-idr-tunnel-encaps.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-14 14:00:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-13 22:20:07-07:00",
    "text": "ection 7 appears to reference (in a normative fashion) an[IRB-EXT-MOBILITY] document but there is no such reference listed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-29 17:28:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 14:00:01-07:00",
    "text": "(1) Possibly a \"discuss discuss\", but ... if I'm understanding correctly, the symmetric IRB case over an Ethernet NVO tunnel (not MPLS or IP NVO) described in this document is introducing a new scenario where traffic using router (PE) MAC addresses as source and destination is comingled on the same tunnel with traffic using tenant system MAC addresses as source and destination.\u00a0 This places an obligation on the tunnel endpoints to properly isolate and process such \"internal\" tunnel traffic without hampering the ability of tenans systems to communicate.\u00a0 In a world where tenant systems can appear at any time, using previously unknown MAC addresses, this represents a rather challenging problem: how will the PEs be able to pick (and avertise) MAC addresses that they know will not conflict with any present or future customer systems?\u00a0 (A similar dilemma led to quite a delay in the processing of  draft-ietf-bfd-vxlan , which in that case was resolved by limiting the BFD operation to just the \"management VNI\" which is not subject to MAC address conflict with customer systems.)\u00a0 In this docuement's case, we seem to be using a \"well-known\"/reserved MAC address range from  RFC 5798 ; in principle, this should be enough to avoid conflicts, if customer systems are known to not squat on this reserved range.\u00a0 However, this document has some text in Section 4.1 that indicates that there must be external knowledge that auto-derived MAC addresses in the  RFC 5798  ranges \"[do] not collide with any customer MAC address\".\u00a0 So I'm left uncertain whether or not this potential problem is addressed or not.\u00a0 (Also, I don't know if the limit on 255 distinct such MAC addresses presents a scaling issue.) Also, is there any risk that the EVPN IRB setup might also want to use VRRPv3, and thus collide on the MAC addresses in a different manner? (1.1) I'm less sure whether there's a similar collision risk for IP addresses -- we assign IP addresses to NVEs (e.g., for use as BGP Next Hop addresses) and these are used as VTEP addresses when encapsulating packets that are going inter-subnet.\u00a0 I think that at this point in the packet processing we may already know that we're in the the \"IRB tunnel\" scope and that may be enough to de-conflict any potential IP address collision between NVE and customer addresses. (2) Section 7 appears to reference (in a normative fashion) [IRB-EXT-MOBILITY] but there is no such reference. Similarly (as Murray notes), there are a couple apparent references to [TUNNEL-ENCAP] that are also arguably normative, but the target of the reference is not forthcoming (and the IANA registry does not show a \"BGP Encapsulation Extended Community\" that is supposedly defined by [TUNNEL-ENCAP]). There is also not a listed reference for [EVPN-PREFIX], though one could perhaps surmise that it is intended to be [ I-D.ietf-bess-evpn-prefix-advertisement ] (given that the latter does allocate EVPN route type 5 for carrying IP Prefix routes, etx.). However, given that this document has text like \"MUST advertise local subnet routes as RT-5\", this needs to be a normative (not informative) reference.\u00a0 (We may also want to explicitly reference [EVPN-PREFIX] where those normative requirements are made.) (3) I'm not sure whether we are modifying the error-handling semantics for RT-2 from what is specified in  RFC 7432  (and, furthermore, whether the changes are backwards-compatible).\u00a0 If so, it seems like we may need an Updates: relationship.\u00a0 The text in question is in Section 9.1.1 (which itself seems problematic, since this section is advertised as an (example) operational model/scenario): \u00a0  If the receiving NVE receives a RT-2 with only Label-1 and only a \u00a0  single Route Target corresponding to IP-VRF, or if it receives a RT-2 \u00a0  with only a single Route Target corresponding to MAC-VRF but with \u00a0  both Label-1 and Label-2, or if it receives a RT-2 with MAC Address \u00a0  Length of zero, then it MUST treat the route as withdraw [ RFC7606 ] \u00a0  and log an error message. Are all of these treat-as-withdraw behaviors specified in  RFC 7432 ? (4) Let's discuss whether we need more generally a \"backwards compatibility\" section (I mention a couple other places where this might come into play, in the COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-27 16:07:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-29 17:28:45-07:00",
    "text": "I think draft-ietf-bess-evpn-irb-extended mobility needs to be a normative reference, since \"the procedures in [it] must be exercised\" incorporates its procedures by reference.\u00a0 Similarly, draft-ietf-idr-tunnel-encaps  seems like a normative reference since we require the RT-2 route used by this document to be advertised along with the EC that indicates the tunnel type. I still think we need to discuss whether this document Updates: 7432. RFC 7432  specifies the layout and interpretation of the RT-2 (MAC-IP Advertisement Route) EVPN NRLI, but we extend it in several ways (e.g., the Label1 and Label2 (which we spell \"Label-1\" and \"Label-2\", unfortunately) are only MPLS labels in 7432, but we expand that to also allow VNI values in those fields; likewise, 7432 gives no semantics at  all for Label2, but we define some).\u00a0 I understand that 7432 only covers the L2 case but this document adds mixed L2/L3 (IRB), and furthermore  that the IRB case can be inferred based on the contets of the fields in the advertisement, *if you know how to look for them*.\u00a0 But I still can't shake the feeling that this document should either be added as an additional reference for EVPN Route Type 2, or listed as Updating 7432, in order to indicate that we provide more details for the interpretation and contents of the RT-2 NLRI.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-10 11:24:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-02-27 16:07:30-08:00",
    "text": "This document provides semantics for the EVPN RT-2 \"MPLS Label2\" field allocated in but undocumented by  RFC 7432 .\u00a0 I believe that we need to provide some \"trail of breadcrumbs\" from the IANA registry to this document so that the semantics of the protocol field are discoverable.\u00a0 This could take the form of a direct reference from the IANA registry to this document, or by marking this document as Updating  RFC 7432 , or some other mechanism that provides the needed discoverability.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-23 23:11:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-14 23:21:41-07:00",
    "text": "[ general ] * Can you give an example of what happens to non-IPv4/IPv6 Ethernet packets \u00a0 received at the NVE/PE?\u00a0 Do they get bridged, and if so how far?\u00a0 What \u00a0 happens if a host in BT1 ARPs for IPv4 address associated with a TS in \u00a0 a different BT? * Where there are multiple prefixes in an IP-VRF, is there a constraint that \u00a0 any other IP-VRF that contains one of the prefixes must contain all of them? \u00a0 Perhaps that's in 7432...? [ sections 4, 5.4, 5.4, 6.3, 6.4, 9.1.2, 9.2.2 ] * Please document what happens to IPv4 TTL/IPv6 Hop Limit values as they \u00a0 cross various NVEs/PEs. [ section 7 ] * Is there a reference for IRB-EXT-MOBILITY? * The two statements: \u00a0 (1) \"Although the language used in this section is for IPv4 ARP, \u00a0 \u00a0 \u00a0 it equally applies to IPv6 ND.\" \u00a0 (2) \"If there is [a] many-to-one relationship such that there are many host \u00a0 \u00a0 \u00a0 IP addresses correspond[ing] to a single host MAC address ..., then to \u00a0 \u00a0 \u00a0 detect host mobility, the procedures in [IRB-EXT-MOBILITY] must be \u00a0 \u00a0 \u00a0 exercised...\" \u00a0 are in direct conflict.\u00a0 All IPv6 hosts having at least one non-link-local \u00a0 unicast address will have more than one IP address per MAC and this section, \u00a0 or even this document, would not apply?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-07-08 12:34:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-07-08 12:34:13-07:00",
    "text": "I found this document difficult to review. Some of this might be due to the fact that I'm not an expert on EVPN, but I think some of the reason is that the document could be structured better and expressed more clearly. The only reason I'm not opposing the progression of the document on the grounds that it's too unclear to implement is that I've been told, and accept on faith, that implementations *have* been successfully written starting from the spec, which implies it's implementable -- I guess by people who are expert in EVPN already, it wouldn't be implementable by me. In any case, I do have some points I would like to discuss, that are more actionable. 1. I agree with Robert Wilton's comment on -09: ``` One question I have is whether it is possible to have a deployment where some devices support synchronous mode and others support asynchronous mode.\u00a0 Am I right in presuming that this is not supported and if so is this capability signaled in any way? Or is the expectation that this would be controlled via deployment choice of network device, or though configuration management? ``` This issue still exists in -14. I think it should be addressed in the document. Similarly, I agree with Warren Kumari's comment, also on -09: ``` I would strongly recommend that the authors read the OpsDir review at:  https://datatracker.ietf.org/doc/review-ietf-bess-evpn-inter-subnet-forwarding-09-opsdir-lc-jaeggli-2020-07-06/  , especially the: \"it would be helpful if section 4 would be more explicit for non-implementors on when symetric or asymetric modules would be chosen, as it stands the variation basically reads like the enumeration of the features of various implementations.\" comment (which I fully agree with). ``` It seems both of these comments could -- and should! -- be addressed by adding a few paragraphs talking about these topics. This could be done either in \u00a74, as Warren suggests, or in some other section (e.g. you could add an \"operational considerations\" section). 2. Section 7.1 I\u2019m guessing this question isn\u2019t unique to this document, but since this is where I encountered it, I\u2019ll ask: it seems as though the described mobility procedures are vulnerable to a condition where a particular (IP, MAC) appears at two different NVEs at the same time. If this condition exists (either innocently, or maliciously) what prevents the source and target NVEs from continually attempting to claim the (IP, MAC) from one another, flooding the network with updates all the while? (This applies to 7.2 as well.) Since this seems like a potential security issue, I'm including it in my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-07-14 16:21:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-08 12:34:51-07:00",
    "text": "I found this document difficult to review. Some of this might be due to the fact that I'm not an expert on EVPN, but I think some of the reason is that the document could be structured better and expressed more clearly. The only reason I'm not opposing progression of the document on the grounds that it's too unclear to implement is that I've been told, and accept on faith, that implementations *have* been successfully written starting from the spec, which implies it's implementable -- I guess by people who are expert in EVPN already, it wouldn't be implementable by me. In any case, I do have some points I would like to discuss, that are more actionable. 1. I agree with Robert Wilton's comment on -09: ``` One question I have is whether it is possible to have a deployment where some devices support synchronous mode and others support asynchronous mode.\u00a0 Am I right in presuming that this is not supported and if so is this capability signaled in any way? Or is the expectation that this would be controlled via deployment choice of network device, or though configuration management? ``` This issue still exists in -14. I think it should be addressed in the document. Similarly, I agree with Warren Kumari's comment, also on -09: ``` I would strongly recommend that the authors read the OpsDir review at:  https://datatracker.ietf.org/doc/review-ietf-bess-evpn-inter-subnet-forwarding-09-opsdir-lc-jaeggli-2020-07-06/  , especially the: \"it would be helpful if section 4 would be more explicit for non-implementors on when symetric or asymetric modules would be chosen, as it stands the variation basically reads like the enumeration of the features of various implementations.\" comment (which I fully agree with). ``` It seems both of these comments could -- and should! -- be addressed by adding a few paragraphs talking about these topics. This could be done either in \u00a74, as Warren suggests, or in some other section (e.g. you could add an \"operational considerations\" section). 2. Section 7.1 I\u2019m guessing this question isn\u2019t unique to this document, but since this is where I encountered it, I\u2019ll ask: it seems as though the described mobility procedures are vulnerable to a condition where a particular (IP, MAC) appears at two different NVEs at the same time. If this condition exists (either innocently, or maliciously) what prevents the source and target NVEs from continually attempting to claim the (IP, MAC) from one another, flooding the network with updates all the while? (This applies to 7.2 as well.) Since this seems like a potential security issue, I'm including it in my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-11-01 15:39:21-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-21 10:21:30-07:00",
    "text": "I wavered a lot about whether to ballot Discuss or No Objection; there are a lot of important technical and clarity-of-writing points that remain in the Comment section, but only a few points seemed to merit elevating to the Discuss level.\u00a0 That said, this remains a generally clear and useful document, so I'm looking forward to seeing it further improved. (1) I'm concerned about Section 8.2.4's recommendation for the use of a sequential counter: \u00a0 \u00a0 \u00a0 A sequence counter that is incremented for each new fragmented \u00a0 \u00a0 \u00a0 SCHC Packet, counting from 0 to up to (2^T)-1 and wrapping back to \u00a0 \u00a0 \u00a0 0 is RECOMMENDED for maximum traceability and avoidance of \u00a0 \u00a0 \u00a0 ambiguity. It seems like there may be substantial privacy and security considerations, here --  draft-gont-numeric-ids-history  has some background about similar cases in the past and links to other documents with analysis and guidance for future protocols.\u00a0 Shall we discuss to what extent those concerns apply here? (2) In Section 8.3.1.2, does the use of the All-1 fragment to signify the end of the packet, combined with the lack of an explicit \"number of fragments\" field, imply that the RCS value is the only thing (at this protocol level) preventing an attacker from inserting, from off-path, additional fragments between the penultimate \"legitimate\" fragment and the final fragment?\u00a0 (I understand that the LPWAN radio technologies generally do have some physical-layer cryptographic mechanisms, though they sometimes involve shared symmetric keys.)\u00a0 If the RCS is to play this pivotal a role, we need to at least document that, and arguably give stronger guidance about how it should be computed. (3) There are several places (noted, for the most part, in the Comment section) where we say that some field is optional.\u00a0 I think this means \"optional at the profile level\" as opposed to \"optional at runtime\", but we should be clear in the document about that. (4) There's an internal inconsistency in Section 8.4.3: \u00a0  In ACK-on-Error mode, windows are used.\u00a0 All tiles MUST be of equal \u00a0  size, except for the last one, which MUST be of the same size or \u00a0  smaller than the regular ones.\u00a0 If allowed in a Profile, the \u00a0  penultimate tile MAY be exactly one L2 Word smaller than the regular \u00a0  tile size. We need to reword this, as the subsequent text contradicts the initial \"MUST\".",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-08-21 06:46:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-21 06:17:41-07:00",
    "text": "Thank you for the hard work put into this extensive document. I have a couple of DISCUSSes and COMMENTs, all easy to be fixed except perhaps the DISCUSS around secrion 10.7.2. Regards, -\u00e9ric == DISCUSS == -- Section 3.2 -- What is the expected behavior when the \"link identifier data item\" does not match the length of this field? -- Section 10.3 -- I am not a transport expert but I wonder whether the text \"ECN functionality depends on both bits of the ECN field,...\" is at the right place? Section 10.2 would appear better to me but again I am not an transport/ECN expert.  -- Section 10.7.2 -- It is unclear to me how the gateway and the device can share the required 'shared secret' and especially the 'DAD counter' of  RFC 7217 ... This render the 2 paragraph confusing at best and possibly impossible to implement.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-08-22 14:47:27-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-21 06:46:05-07:00",
    "text": "Thank you for the hard work put into this extensive document. I have a couple of DISCUSSes and COMMENTs, all easy to be fixed except perhaps the DISCUSS around secrion 10.7.2. Regards, -\u00e9ric == DISCUSS == -- Section 10.7.2 -- It is unclear to me how the gateway and the device can share the required 'shared secret' and especially the 'DAD counter' of  RFC 7217 ... This render the 2 paragraph confusing at best and possibly impossible to implement.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-11 07:33:31-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-20 10:52:24-07:00",
    "text": "(1) Section 12.\u00a0 The introductory text needs a bit more precision. Specifically: -- Per \u201cWireless networks are subjects to various sorts of attacks , which are not specific to SCHC.\u201d, which other security considerations are being cited here?\u00a0 An alternative construct would be to state that \u201cSCHC Packets rely on the security mechanisms of \u2026 [insert relevant references]\u201d -- Section 12.\u00a0 \u201c[W]e\u2019ll assume that an attacker was able to break into the network\u201d, what is that precisely?\u00a0 Is this simply join the network? -- Section 12.\u00a0 Per \u201cOur analysis equally applies to legitimate nodes \u2018going crazy\u2019\u201d, what does that mean \u2013 compromised nodes? unexplained behavior?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-07-28 10:25:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-09 06:48:19-07:00",
    "text": "I support Benjamin's DISCUSS and Roman's last DISCUSS point. Regarding Section 11, there are often legal agreements in place that govern all sorts of things about how protocols transfer data between parties, but those are not the main thing to document in an RFC. Section 11 should be documenting the technical considerations for how to protect the data that may be escrowed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-01 17:22:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-08 09:01:06-07:00",
    "text": "Let's have a discussion about the overall plans for providing guidance on mechanisms for (e.g.) cryptographic confidentiality and integrity protection of data both in transit and at-rest, authentication/authorization requirements, etc..\u00a0 In particular, what it's appropriate and necessary to include in this document vs. other documents, and how to provide some specific general baseline guidance that can be used in the absence of conflictinc scenario-specific deployment requirements.\u00a0 Some further details in the COMMENT section, but in general, it seems like there should be some \"off-the-shelf\" mechanism that can be used without a need for every deployment to do a custom thing, for cases where there are not custom requirements.\u00a0 It may not need to be part of this document, but we should have a plan for where it will be. Also, it's not clear to me whether we expect escrow of credentials/verifiers used to authenticate/authorize fourth parties that perform operations (e.g., registrations) at the registry (see comment on Section 3), and that is pretty important for knowing what security requirements to place on the escrow'd data.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-04-29 01:07:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 05:39:36-07:00",
    "text": "Section 8. As this document will be an IETF proposed standard I think the registrant for the RDE and XML schema shall follow the recommendation in  RFC 3688 :  \u00a0  Registrant Contact \u00a0 \u00a0 \u00a0 The individual/organization that is the registration contact for \u00a0 \u00a0 \u00a0 the component being registered.\u00a0 Ideally, this will be the name \u00a0 \u00a0 \u00a0 and pertinent physical and network contact information.\u00a0 In the \u00a0 \u00a0 \u00a0 case of IETF developed standards, the Registrant will be the IESG. So please change that registrant to follow the above. The purpose of this is to prevent any issues over who has change control of the registered entries.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-04-28 13:14:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-08 20:06:44-07:00",
    "text": "I had originally included these just as comments, but since another AD brought up the same point I'd like to discuss them: Section 5.1.3: \"This element SHOULD be present in deposits of type Incremental or Differential.\"\u00a0 This makes it sound like a deposit of those two types not using this element might be non-compliant.\u00a0 I suggest instead \"This element is only used in Incremental and Differential deposits.\"\u00a0 (Or instead of \"used\", maybe \"meaningful\".) Section 5.1.4: \" It SHOULD be present in all type of deposits.\"\u00a0 Same issue.\u00a0 Maybe \"It is valid for use in all types of deposits.\"",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-05-13 08:07:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-08 10:03:46-07:00",
    "text": "Hi, I spotted some issues with the terminology and the description of the algorithm that I would like you to please address. Section 2: Terminology The definitions provided for \"Differential\" vs \"Incremental\" are the opposite to their standard meaning in backups.\u00a0 The term definitions should be reversed to align with the common vernacular.\u00a0 I.e. differential is the diff against the last full backup, incremental is the backup since the backup (of any type) was performed. 5.1.3.\u00a0 Child\u00a0 element \u00a0  The specification for each object to be escrowed MUST declare the \u00a0  identifier to be used to reference the object to be deleted. An identifier is equally important in the add/update case as well to know which object needs to be updated.\u00a0 I would suggest pulling this sentence out of this subsection and adding a new subsection under 5 to briefly describe the requirement on object identifiers and how they are used both in the delete and contents cases. 5.1.4.\u00a0 Child\u00a0 element \u00a0  When applying Incremental or Differential Deposits (when rebuilding \u00a0  the registry from data escrow deposits) the relative order of the \u00a0 \u00a0 elements is important, as is the relative order of the \u00a0 \u00a0 elements.\u00a0 All the\u00a0 elements MUST be applied \u00a0  first, in the order that they appear.\u00a0 All the\u00a0 elements \u00a0  MUST be applied next, in the order that they appear. I think that the text for processing deposits would be better outside of section 5.1.4, since some of the text is referring to section 5.1.3, and isn't specific to the\u00a0 element. Why does the relative order of\u00a0 elements matter?\u00a0 Is this because of potential dependencies between the elements, if so, it would be useful if that was explicitly stated.\u00a0 If not, then I don't understand why the order of deletes would matter. Also, should there be a statement that an object SHOULD NOT exist multiple times (either in the\u00a0 or\u00a0 elements in a single deposit)? \u00a0  If an object is present in the\u00a0 section of several deposits \u00a0  (e.g.\u00a0 Full and Differential) the registry data from the latest \u00a0  deposit (as defined by the Timeline Watermark) SHOULD be used when \u00a0  rebuilding the registry. This doesn't just apply to objects in the\u00a0 section, but equally applies if the object is present in any\u00a0 or\u00a0 section.\u00a0 I.e. the status of whether an object exists and its contents must be taken from the latest deposit.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-13 05:40:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-08 15:35:29-07:00",
    "text": "** Section 6.1.\u00a0 Please provide a normative reference to XML Schema. ** Section 6.1. The schema defines types \u201cclIDType\u201d and \u201crrType\u201d but their use isn\u2019t explained in the text and they don\u2019t appear to be used in the definition of . ** Section 11.\u00a0 Was a requirement to secure the deposit data at rest considered?\u00a0 The text here suggests that such details needed to be worked out individually.\u00a0 However, Section 9 notes that the whole deposit is likely to be confidential.\u00a0 It would seem best practice to store such sensitive information encrypted.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-03-06 09:08:12-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-06 00:28:47-08:00",
    "text": "Thanks to everyone who has worked on this over the past several years. I have one \"discuss DISCUSS\" that I suspect may be a misunderstanding on my part about how Kerberos deals with OIDs in general. If so, please bear with my ignorance.\u00a0 I just want to make sure something important isn't being overlooked. I can see in https://www.iana.org/assignments/smi-numbers/smi-numbers.xml#smi-numbers-26 that the OID 1.3.6.1.5.2 has been reserved for Kerberos v5 objects (a reservation that appears to have been copied out of  RFC 1700 ). I also see that RFC 4556  uses 1.3.6.1.5.2.3 and defines three nodes (.1, .2, and .3) underneath it. Try as I might, I can't find any plausibly authoritative registry that tracks the reservation of 1.3.6.1.5.2.3, or of its children 1.3.6.1.5.2.3.1, 1.3.6.1.5.2.3.2, and 1.3.6.1.5.2.3.3. This document then defines the use of 1.3.6.1.5.2.3.6. How do we know that \"6\" is free? How will future specifications know that \"6\" is no longer available? This document also defines 1.3.6.1.5.2.3.6.1, 1.3.6.1.5.2.3.6.2, 1.3.6.1.5.2.3.6.3, and 1.3.6.1.5.2.3.6.4 for the various hash algorithms. Assuming this list continues to be added to, how will future specifications avoid collisions? I have a similar question about 1.3.6.1.5.2.4.5.1. I think my confusion stems from the fact that I was under the impression that everything under 1.3.6.1 was managed by IANA -- at least, that's my reading of RFC 1155 . To be clear: if I understand the situation correctly, I recognize that there may be a bigger problem here that is beyond the remit of this document to solve; however, I think it would be reasonable to not make the existing problem worse. In particular -- and again, I may simply be confused here -- I would expect this document to at least ask IANA to create a table at https://www.iana.org/assignments/smi-numbers/smi-numbers.xhtml  that keeps track of the children of 1.3.6.1.5.2.3.6.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-05-10 13:16:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-08 21:50:46-07:00",
    "text": "- Part of the document is outside the scope of the charter of the WG which requested its publication While I understand that this document requires a WebSockets mechanism for .well-known, and that such a mechanism doesn\u2019t yet exist, it seems pretty far out of scope for the CORE working group to take on defining this itself (unless I missed something in its charter, which is entirely possible: it\u2019s quite long). Specifically, I fear that this venue is unlikely to bring such a change to the attention of those people best positioned to comment on whether .well-known is appropriate for WebSockets. Even if this is in scope for CORE, it really needs to be its own document. If some future document comes along at a later point and wants to make use of its own .well-known path with WebSockets, it would be really quite strange to require it to reference this document in describing .well-known for WS.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-05-22 13:48:13-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-10 13:16:33-07:00",
    "text": "ISSUE 1: WebSockets and .well-known - Part of the document is outside the scope of the charter of the WG which requested its publication While I understand that this document requires a WebSockets mechanism for .well-known, and that such a mechanism doesn\u2019t yet exist, it seems pretty far out of scope for the CORE working group to take on defining this itself (unless I missed something in its charter, which is entirely possible: it\u2019s quite long). Specifically, I fear that this venue is unlikely to bring such a change to the attention of those people best positioned to comment on whether .well-known is appropriate for WebSockets. Even if this is in scope for CORE, it really needs to be its own document. If some future document comes along at a later point and wants to make use of its own .well-known path with WebSockets, it would be really quite strange to require it to reference this document in describing .well-known for WS. ================================================== ISSUE 2: Assignment of port 443 as default - Widespread deployment would be damaging to the Internet or an enterprise network for reasons of congestion control, scalability, or the like.  I'd like to thank the authors for helping me to understand the intention with the use of port 443 more clearly. Based on their clarifications, I need to move my issue about assigning a default of port 443 to coaps+tcp from my Comment into the Discuss, as it does have implications for the Internet at large that will have long-term damaging effects. The rationale being offered for the using the already-assigned port 443 as a default is that it tends to go through firewalls that other ports may not, and that doing so is fine because ALPN makes it possible. These arguments, if we accept them, are manifestly true for all future TLS-using protocols. Allowing CoAP to re-use an assigned port on this basis established precedent for pretty much all future protocols to do so, effectively moving the protocol demux point for future protocols from port numbers to ALPN IDs (all over port 443). It is hard to imagine an outcome *other* *than* firewall manufacturers starting to whitelist desired ALPN IDs, which effectively ossifies the available set of IDs to whatever is defined at that moment, destroying the future utility of the mechanism. There are other issues having to do with software architecture, protocol demultiplexing in user space rather than kernel space, and operational considerations that come into play as well, but they don't technically fall under discuss criteria.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-05-09 19:26:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-09 19:25:48-07:00",
    "text": "1) This draft removes the reliability and ordering features COAP when used over reliable transports, under the assumption that the transport will provide. But the draft also includes the assumption that COAP proxies exist. This has the potential for creating a problem, since the transport can only provide guaranty reliable delivery and ordering to the next hop. Once you have a proxy in play, you loose that guaranty end to end. This is further complicated because this draft contemplates cross-transport proxies, where one side may be over WebSocket (and I assume might be over TCP) and the other side over UDP. If the client sends via TCP but a proxy changes it to UDP, the client has no way to specify the reliability properties to be used on the UDP connection. If one imagines a client that uses UDP to a forward proxy, which speaks TCP to a reverse-proxy, which then switches back to UDP, any reliability properties specified by the client will get lost. Also, a proxy can potentially reorder messages, even if it uses TCP on both sides. If one leaves ordering to the transport, then one needs to add rules about proxies maintaining that order. 2) It seems problematic to encode the transport choice in the URI scheme. Since the draft specifies that each scheme. Section 7 says \"They are hosted in distinct namespaces because each URI scheme implies a distinct origin server.\" IIUC, this means any given resource can only be reached over a specific transport. That seems to break the idea of cross-transport proxies as discussed in section 7. It also does not seem to fit with a primary motivation for this draft. That is, one might want to use TCP because of local NAT/FW issues. But if there is a resource with a \"coap\" scheme, I cannot switch to TCP when I'm behind a problematic middlebox, and have an expectation of reaching the same resource.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-05-11 08:14:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-09 19:26:50-07:00",
    "text": "1) This draft removes the reliability and ordering features COAP when used over reliable transports, under the assumption that the transport will provide. But the draft also includes the assumption that COAP proxies exist. This has the potential for creating a problem, since the transport can only provide guaranty reliable delivery and ordering to the next hop. Once you have a proxy in play, you loose that guaranty end to end. This is further complicated because this draft contemplates cross-transport proxies, where one side may be over WebSocket (and I assume might be over TCP) and the other side over UDP. If the client sends via TCP but a proxy changes it to UDP, the client has no way to specify the reliability properties to be used on the UDP connection. If one imagines a client that uses UDP to a forward proxy, which speaks TCP to a reverse-proxy, which then switches back to UDP, any reliability properties specified by the client will get lost. Also, a proxy can potentially reorder messages, even if it uses TCP on both sides. If one leaves ordering to the transport, then one needs to add rules about proxies maintaining that order. 2) It seems problematic to encode the transport choice in the URI scheme.  Section 7 says \"They are hosted in distinct namespaces because each URI scheme implies a distinct origin server.\" IIUC, this means any given resource can only be reached over a specific transport. That seems to break the idea of cross-transport proxies as discussed in section 7. It also does not seem to fit with a primary motivation for this draft. That is, one might want to use TCP because of local NAT/FW issues. But if there is a resource with a \"coap\" scheme, I cannot switch to TCP when I'm behind a problematic middlebox, and have an expectation of reaching the same resource.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-05-22 13:09:21-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-11 08:14:24-07:00",
    "text": "1) [removed, please see update in comments] 2) It seems problematic to encode the transport choice in the URI scheme.  Section 7 says \"They are hosted in distinct namespaces because each URI scheme implies a distinct origin server.\" IIUC, this means any given resource can only be reached over a specific transport. That seems to break the idea of cross-transport proxies as discussed in section 7. It also does not seem to fit with a primary motivation for this draft. That is, one might want to use TCP because of local NAT/FW issues. But if there is a resource with a \"coap\" scheme, I cannot switch to TCP when I'm behind a problematic middlebox, and have an expectation of reaching the same resource.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-06-09 08:24:19-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-06 15:59:13-07:00",
    "text": "fter reading Mark Nottingham's review, I'm persuaded we should at least discuss the relationship of this work to the parallel work in HTTP.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-12-18 09:32:34-08:00",
    "end_reason": "position_updated",
    "start": "2017-05-10 06:40:26-07:00",
    "text": "1) My general concern is that, while I don't necessarily want to block the proposed format, I would like to understand further before publication why this approach was chosen. Similar to Ben's discuss, I don't understand why the format was chosen so differently. You could just use the format (plus a new length option) as defined for UPD and just never have any retransmission or reordering but be more flexible on the lower layer transport to use. However, if you actually prefer a new format (to save space), than that sounds like a new version for me, while the draft says: \"CoAP is defined in [ RFC7252 ] with a version number of 1.\u00a0 At this time, there is no known reason to support version numbers different from 1.\" However, in this case it could even have made sense to define a new format/version that could be used for both underlying protocols and either have a length option or a message type and IP option. Further I also don't understand why on the other hand the TCP COAP framing is re-used for websockets because websockets already provides message framing and a length field. Also inline with Ben's discuss, the use of the Block option for CAOP/TCP is not very clear to me. The draft says: \"a UDP-to-TCP gateway may simply not have the context to convert a \u00a0 \u00a0 \u00a0 message with a Block Option into the equivalent exchange without \u00a0 \u00a0 \u00a0 any use of a Block Option (it would need to convert the entire \u00a0 \u00a0 \u00a0 blockwise exchange from start to end into a single exchange)\" However, given that the COAP/TCP and COAP/UDP format are so different, it's anyway a more complex conversion than just sticking another transport underneath. The argument for HOL blocking due to e.g. upgrades is also not clear to me because you should probably better just use a different TCP connection for that as it really seems to be a different use case. For me this draft looks like you are defining basically a new protocol version and not just COAP over TCP. Again, I don't necessarily want to block this but I would like to understand why the proposed approach was chosen. 2) Comments from the tsv-art review needs to be addressed as well (Thanks to Yoshi Nishida for the review!). Here is the review text for your connivence: \"Summary: This document is well-written. It is almost ready to be published as a PS draft once the following points are addressed. 1: It is not clear how the protocol reacts the errors from transport layers (e.g. connection failure). \u00a0  The protocol will just inform apps of the events and the app will decide what to do or the protocol itself will do something? 2: There will be situations where the app layer is freezing while the transport layer is still working. Since transport layers cannot detect this type of failures, there should be some mechanisms for it somewhere in the protocol or in the app layer.\u00a0 The doc needs to address this point. For example, what will happen when a PONG message is not returned for a certain amount of time? 3: Since this draft defines new SZX value, I think the doc needs to update RFC7959 . This point should be clarified more in the doc.\u201c 3) And inline with Yoshi's comment, I don't think this part in section 3.3 is well specified; especially I don't understand how these two thing fit together: \"To avoid unnecessary latency, a Connection Initiator MAY send \u00a0  additional messages without waiting to receive the Connection \u00a0  Acceptor's CSM; ...\" and \u00a0  \"Endpoints MUST treat a missing or invalid CSM as a connection error \u00a0  and abort the connection (see Section 5.6).\" Also how long should I wait until I abort the connection?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-08-19 14:47:33-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-12 23:36:16-07:00",
    "text": "Thanks to everyone who worked on updating this protocol to reflect experience gathered from the initial CT protocol. I have one blocking comment, and a small number of editorial suggestions. --------------------------------------------------------------------------- \u00a75: >\u00a0 Clients are configured with a base URL for a log and construct URLs >\u00a0 for requests by appending suffixes to this base URL.\u00a0 This structure >\u00a0 places some degree of restriction on how log operators can deploy >\u00a0 these services, as noted in [ RFC7320 ].\u00a0 However, operational >\u00a0 experience with version 1 of this protocol has not indicated that >\u00a0 these restrictions are a problem in practice. The synthesis of URLs by a protocol in this fashion is prohibited by  BCP 190 : \u00a0  Scheme definitions define the presence, format, and semantics of a \u00a0  path component in URIs; all other specifications MUST NOT constrain, \u00a0  or define the structure or the semantics for any path component. Unless the intention of this document is to update  BCP 190  to change this normative requirement, we can't publish it in its current form. Note that doing so would require a change of venue, as updates to  BCP 190  would not be covered by the current TRANS charter. Please see  BCP 190  section 3 for alternate approaches. All three approaches could be made to work for CT, and I would be happy to explain how to do so if clarification is desired.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-03-14 06:09:00-07:00",
    "text": "I think this is an important document and I am looking forward to seeing it as a Proposed Standard in the future. However, it has a good number of editorial issues that make the document hard to read and implement. 5.\u00a0 Log Client Messages \u00a0  type:\u00a0 A URN reference identifying the problem.\u00a0 To facilitate \u00a0 \u00a0 \u00a0 automated response to errors, this document defines a set of \u00a0 \u00a0 \u00a0 standard tokens for use in the \"type\" field, within the URN \u00a0 \u00a0 \u00a0 namespace of: \"urn:ietf:params:trans:error:\". I think you need to register this in  Also, can you clarify whether error need an IANA registry?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-09-27 10:44:07-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 09:34:18-07:00",
    "text": "Glad to see this revision of the protocol. My comments and questions should be easy to address. = Section 10.2, 10.4, 10.5 = A Specification Required registry policy implies expert review. So a registry policy of \"Specification Required and Expert Review\" is duplicative; it should just say \"Specification Required.\" I know this seems trivial but there has been so much confusion about this through the years that it is important to be precise. = Section 10.3 = This section needs to state what the registry policy is for the code points not already registered (presumably Expert Review given 10.3.1, but it needs to be explicit). = Section 10.6.1 = Using the term \"Parameters Required\" as a capitalized term is confusing. FCFS registries by definition can require additional information to be provided in order to get something registered. For avoidance of confusion I think the assignment policy should be listed as First Come First Served and the requirement that parameters be included in the application can use a normative MUST in the last paragraph if there is concern that the parameters won't be supplied. However, I also wonder what will be done with the parameters that are supplied. Is IANA expected to just maintain them privately, or to publish them? What is expected to appear in the 'Log' column in the registry?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-30 19:02:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-14 07:09:22-07:00",
    "text": "First off, thanks for this well-written document!\u00a0 I intend to ballot Yes, but there are a few issues that need to be resolved first. Sections 4.11 and 4.12 have arrays of NodeHash to carry consistency and inclusion proofs, respectively, with minimum array size of 1.\u00a0 However, Sections 2.1.4.1 and 2.1.3.1 (respectively) seem to admit the possibility of zero-length proofs in degenerate cases, which the aforementioned protocol description language forbids the conveyance of. (Section 5.3 explicitly requires the use of an empty consistency proof.) Do those minimum array sizes need to be (implicit) zero? (If they do not, it seems that a minimum size of 32 would have the same effect as that of one, since a NodeHash has minimum size 32.) I support Alexey's Discuss regarding the registration of a \"urn:ietf:params:trans:error\" URN namespace. In Section 6: \u00a0  o\u00a0 An Online Certificate Status Protocol (OCSP) [ RFC6960 ] response \u00a0 \u00a0 \u00a0 extension (see Section 7.1.1), where the OCSP response is provided \u00a0 \u00a0 \u00a0 in the \"CertificateStatus\" message, provided that the TLS client \u00a0 \u00a0 \u00a0 included the \"status_request\" extension in the (extended) \u00a0 \u00a0 \u00a0 \"ClientHello\" (Section 8 of [ RFC6066 ]).\u00a0 [...] This is not quite a TLS 1.3-compliant formulation -- TLS 1.3 does not use the \"CertificateStatus message\", but rather uses the encoding of that structure in a status_request extension in the CertificateEntry. I also think we need greater clarity on the (non-)usage of CT for TLS client certificates; see COMMENT I also support Alissa's Discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-25 02:03:16-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-14 06:49:58-07:00",
    "text": "There was a presentation at maprg IETF 103 about the question if CT helps attackers to find new domains. I think this risk should at least be mentioned in the security considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-05-13 10:53:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-05 22:56:23-07:00",
    "text": "reserving Alexey's DISCUSS position...",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-05-14 21:55:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-13 10:53:49-07:00",
    "text": "Thanks for addressing Alexey's DISCUSS position.\u00a0 In -36, a few important IANA-related issues remain, all easy fixes: * Section 10.4 has some messed up markdown around its Specification Required guidance. * Section 10.7 needs to name the sub-registry it's creating.\u00a0 (If it's the title of the section, that should be made clear; the prose doesn't say.) * It should be clear that all of these are sub-registries of \"Transport Layer Security (TLS) Extensions\".\u00a0 Either say that in each section (i.e., refer to the XYZ sub-registry of the \"Transport Layer Security (TLS) Extensions\" registry), or say in Section 10 that everything below is a sub-registry of that one.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-18 10:59:43-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 08:16:03-07:00",
    "text": "Thanks for preparing this document and mechanism; it is good to have more data about the expected impact of the root KSK roll.\u00a0 That said, I have two Discuss-worthy points, albeit both fairly minor. The first one may just be something that I missed, but does this document actually say anywhere that there needs to be a real zone with real configured A and/or AAAA records for the query names used for these tests? The Appendix sort-of-mentions it, but I feel like there needs to be a mention in the main body text. The other point basically is a procedural one, in that we are in effect claiming a couple of leaf name prefixes in all domains to exhibit \"weird and surprising behavior\" (that is, for parties unaware of this specification).\u00a0 We generally try to avoid this sort of namespace squatting, preferring (e.g.) /.well-known for HTTP requests, various underscore-prefixed tricks for the DNS, etc.\u00a0 I see in the changelog that initial attempts did use an underscore prefix but ran into implementation difficulty, and acknowledge that using a \"magic\" name is much easier to get deployed than (e.g.) a new RR type.\u00a0 But I do not want the IESG to implicitly approve a namespace claim like this; it's better to be explicit about it if this is the best way to go.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-11-02 21:04:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-11-02 21:04:02-07:00",
    "text": "* Section 5 I am having a hard time seeing how fragmentation is supposed to work  \u00a0  It is NOT RECOMMENDED for routers implementing this specification to \u00a0  enable IPv6 fragmentation (as defined in section 4.5 of  RFC2460 ) for \u00a0  keyed IP tunnels.\u00a0 IP fragmentation issues for L2TPv3 are discussed \u00a0  in section 4.1.4 of  RFC3931 . And that specific section of  RFC3931  recommends using  RFC2473  to tunnel the packets which again ends up using the  RFC2460  fragment header that this draft is trying to forbid. So, can you please clarify exactly what happens when the size of the packet to be tunneled exceeds the MTU?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-03-17 15:13:03-07:00",
    "end_reason": "position_updated",
    "start": "2016-11-02 21:04:23-07:00",
    "text": "* Section 5 I am having a hard time seeing how fragmentation is expected to work  \u00a0  It is NOT RECOMMENDED for routers implementing this specification to \u00a0  enable IPv6 fragmentation (as defined in section 4.5 of  RFC2460 ) for \u00a0  keyed IP tunnels.\u00a0 IP fragmentation issues for L2TPv3 are discussed \u00a0  in section 4.1.4 of  RFC3931 . And that specific section of  RFC3931  recommends using  RFC2473  to tunnel the packets which again ends up using the  RFC2460  fragment header that this draft is trying to forbid. So, can you please clarify exactly what happens when the size of the packet to be tunneled exceeds the MTU?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-02-20 22:03:41-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-20 22:03:08-08:00",
    "text": "Thanks to the authors for a well-laid-out and easy-to-read document. Thanks also to everyone who contributed to the completion of this work. I have three DISCUSS-level items, and a handful of other suggestions that are largely editorial --------------------------------------------------------------------------- \u00a77.3: >\u00a0 The client may add a query parameter called \"types\", with the value ... >\u00a0 The client may add a query parameter called \"closeafter\" with value ... >\u00a0 The client may add a query parameter called \"ping\", with a positive This form of specification of URI parameters is not allowed -- it contravenes the basic thesis of  BCP 190 , section 2.4 of which stipulates: >\u00a0 Applications MUST NOT directly specify the syntax of queries, as this >\u00a0 can cause operational difficulties for deployments that do not >\u00a0 support a particular form of a query. ... >\u00a0 Extensions MUST NOT constrain the format or semantics of queries. Given that the base resource used to bootstrap the JMAP infrastructure already uses URI templates, it seems that they would be a good candidate for specifying a means of adding these parameters in a way that respects the basic principle that URI design ownership belongs to the domain administrator. --------------------------------------------------------------------------- \u00a78.3: >\u00a0 If this is not feasible, servers MUST ensure this path cannot be >\u00a0 controlled by an attacker, as again it may be used to steal >\u00a0 credentials. This seems problematic, as it would need to be honored by *all* web servers everywhere on the entire Internet to be effective. One cannot really presume that all website operators will be aware of JMAP. I think the only really sensible thing to do here is to forbid clients from using \"/.well-known/jmap\" on a server until they have received some external positive indication that the server supports JMAP (via SRV or some other mechanism). --------------------------------------------------------------------------- The reference for Server-Sent events normatively points to the WHATWG HTML spec, which changes on a continuing basis. I don't think we've really worked out the mechanics of citing this kind of reference normatively; and JMAP takes the especially dangerous step of citing a specific *section* of the document, which may well change at arbitrary and potentially frequent intervals. There is, in fact, no guarantee that the cited \"text/event-stream\" mechanism will continue to exist in future versions of the WHATWG document (cf. the  element). In this particular case, I think we want to reference https://www.w3.org/TR/eventsource/  instead.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-02-25 13:38:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-20 22:03:41-08:00",
    "text": "Thanks to the authors for a well-laid-out and easy-to-read document. Thanks also to everyone who contributed to the completion of this work. I have three DISCUSS-level items, and a handful of other suggestions that are largely editorial --------------------------------------------------------------------------- \u00a77.3: >\u00a0 The client may add a query parameter called \"types\", with the value ... >\u00a0 The client may add a query parameter called \"closeafter\" with value ... >\u00a0 The client may add a query parameter called \"ping\", with a positive This form of specification of URI parameters is not allowed -- it contravenes the basic thesis of  BCP 190 ; section 2.4 of which stipulates: >\u00a0 Applications MUST NOT directly specify the syntax of queries, as this >\u00a0 can cause operational difficulties for deployments that do not >\u00a0 support a particular form of a query. ... >\u00a0 Extensions MUST NOT constrain the format or semantics of queries. Given that the base resource used to bootstrap the JMAP infrastructure already uses URI templates, it seems that they would be a good candidate for specifying a means of adding these parameters in a way that respects the basic principle that URI design ownership belongs to the domain administrator. --------------------------------------------------------------------------- \u00a78.3: >\u00a0 If this is not feasible, servers MUST ensure this path cannot be >\u00a0 controlled by an attacker, as again it may be used to steal >\u00a0 credentials. This seems problematic, as it would need to be honored by *all* web servers everywhere on the entire Internet to be effective. One cannot really presume that all website operators will be aware of JMAP. I think the only really sensible thing to do here is to forbid clients from using \"/.well-known/jmap\" on a server until they have received some external positive indication that the server supports JMAP (via SRV or some other mechanism). --------------------------------------------------------------------------- The reference for Server-Sent events normatively points to the WHATWG HTML spec, which changes on a continuing basis. I don't think we've really worked out the mechanics of citing this kind of reference normatively; and JMAP takes the especially dangerous step of citing a specific *section* of the document, which may well change at arbitrary and potentially frequent intervals. There is, in fact, no guarantee that the cited \"text/event-stream\" mechanism will continue to exist in future versions of the WHATWG document (cf. the  element). In this particular case, I think we want to reference https://www.w3.org/TR/eventsource/  instead.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-03-01 11:53:40-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-25 13:38:30-08:00",
    "text": "[After consultation with a security AD, I have removed one of my three DISCUSS items, as I now believe it pertains more broadly to the use of .well-known and is not specific to this document] Thanks to the authors for a well-laid-out and easy-to-read document. Thanks also to everyone who contributed to the completion of this work. I have three DISCUSS-level items, and a handful of other suggestions that are largely editorial --------------------------------------------------------------------------- \u00a77.3: >\u00a0 The client may add a query parameter called \"types\", with the value ... >\u00a0 The client may add a query parameter called \"closeafter\" with value ... >\u00a0 The client may add a query parameter called \"ping\", with a positive This form of specification of URI parameters is not allowed -- it contravenes the basic thesis of  BCP 190 ; section 2.4 of which stipulates: >\u00a0 Applications MUST NOT directly specify the syntax of queries, as this >\u00a0 can cause operational difficulties for deployments that do not >\u00a0 support a particular form of a query. ... >\u00a0 Extensions MUST NOT constrain the format or semantics of queries. Given that the base resource used to bootstrap the JMAP infrastructure already uses URI templates, it seems that they would be a good candidate for specifying a means of adding these parameters in a way that respects the basic principle that URI design ownership belongs to the domain administrator. --------------------------------------------------------------------------- The reference for Server-Sent events normatively points to the WHATWG HTML spec, which changes on a continuing basis. I don't think we've really worked out the mechanics of citing this kind of reference normatively; and JMAP takes the especially dangerous step of citing a specific *section* of the document, which may well change at arbitrary and potentially frequent intervals. There is, in fact, no guarantee that the cited \"text/event-stream\" mechanism will continue to exist in future versions of the WHATWG document (cf. the  element). In this particular case, I think we want to reference https://www.w3.org/TR/eventsource/  instead.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-03-04 12:23:53-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 11:37:52-08:00",
    "text": "= Section 7.2 = There is something I'm not understanding about this: *deviceClientId*: \"String\" (immutable) An id that uniquely \u00a0 \u00a0 \u00a0 identifies the client + device it is running on.\u00a0 The purpose of \u00a0 \u00a0 \u00a0 this is to allow clients to identify which PushSubscription \u00a0 \u00a0 \u00a0 objects they created even if they lose their local state, so they \u00a0 \u00a0 \u00a0 can revoke or update them.\u00a0 This string MUST be different on \u00a0 \u00a0 \u00a0 different devices, and be different from other vendors.\u00a0 It SHOULD \u00a0 \u00a0 \u00a0 be easy to re-generate, not depend on persisted state.\u00a0 A secure \u00a0 \u00a0 \u00a0 hash that includes both a device id and vendor id is one way this \u00a0 \u00a0 \u00a0 could be achieved. \u00a0 \u00a0  I don't understand why device ID needs to be incorporated in order to achieve uniqueness here. Really it seems like what is needed is a unique ID per client, full stop. Even if you have the unlikely scenario of two clients running on the same device from the same vendor (say, one for mail and one for calendar), you would still want to support the ability for each client independently to be able to recover its push subscriptions, right? Some JMAP servers may have device IDs for other reasons anyway, but setting this up this way seems like it opens the door for clients to unnecessarily share device IDs with JMAP servers in other cases. Related to this, I don't understand the \"SHOULD ... not depend on persisted state.\" Why? I presume it would be straightforward to produce a unique client ID that did not have the device ID embedded if this requirement were not there.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-01 12:26:23-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-20 21:27:43-08:00",
    "text": "There's a lot here, and I was not reading in the best of environments, so it's quite possible that I am just confused or missed something while reading.\u00a0 On the whole, this document is well-written and gives me a good picture of how things work.\u00a0 That said, there are still some places where it looks like we may need to have some discussions... This document (twice) has a MUST requirement for HTTP over TLS, which seems to exclude any future usage of HTTP/3 over QUIC.\u00a0 (It's also probably not needed to repeat the normative requirement in two places; I noted both in the COMMENT section.) Section 1.6.2 asserts that \"all data belong to a single account\".\u00a0 And yet, we seem to have PushSubscription objects in Sections 7.2.1 and 7.2.2 that disclaim any relationship to an account, which seems internally inconsistent.\u00a0 It's also unclear to me from the text in the latter sections what mechanism is used to determine whether a given request is authorized to see a given PushSubscription object.\u00a0 Is it supposed to be based on the authentication credentials to the API service directly, or a user abstraction, or something else? Section 5.3 \u00a0  Some records may hold references to other records (foreign keys). \u00a0  That reference may be set (via create or update) in the same request \u00a0  as the referenced record is created.\u00a0 To do this, the client refers \u00a0  to the new record using its creation id prefixed with a \"#\".\u00a0 The \u00a0  order of the method calls in the request by the client MUST be such \u00a0  that the record being referenced is created in the same or an earlier \u00a0  call.\u00a0 The server thus never has to look ahead.\u00a0 Instead, while I think this means you need to specify what order the server does the create, update, and destroy lists in -- that is, that all creates are done before all updates, etc.. Section 5.5 The Unicode Collation Algorithm ( is not listed in the IANA collation registry for internet application protocols; since the session object limits the collationAlgorithms to those in the registry, at present, it is not permitted to use that collation algorithm.\u00a0 It would seem that this document should stimulate the registration of that collation algorithm in some fashion (whether by explicitly doing so in its IANA Considerations or otherwise). Section 7.1 \u00a0  o\u00a0 *changed*: \"Id[TypeState]\" A map of _account id_ to an object \u00a0 \u00a0 \u00a0 encoding the state of data types that have changed for that \u00a0 \u00a0 \u00a0 account since the last StateChange object was pushed, for each of I don't see how these semantics provide the properties stated in Section 7, \"[i]t doesn't matter if some push events are dropped before they reach the client; it will still get all changes next time it syncs.\"\u00a0 In particular, if the client misses a state change for the CalendarEvent type, and then no other changes that affect CalendarEvents occur, the client will remain unaware of the changes to CalendarEvents, even if other push notifications for other types come in.\u00a0 Am I misunderstanding one or more of the behavior or stated guarantees? Section 7.2 \u00a0  As a push subscription causes the JMAP server to make a number of \u00a0  requests to a previously unknown endpoint, it can be used as a vector \u00a0  for launching a denial of service attack.\u00a0 To prevent this, when a \u00a0  subscription is created the JMAP server immediately sends a \u00a0  PushVerification object to that URL (see section 7.2.2).\u00a0 The JMAP \u00a0  server MUST NOT make any further requests to the URL until the client \u00a0  receives the push and updates the subscription with the correct \u00a0  verification code. I think the JMAP server also needs to rate-limit even the initial PushVerification generation, per-user(?), in order to close the DoS and annoyance-vector risks. \u00a0  o\u00a0 *keys*: \"Object|null\" (immutable) Client-generated encryption \u00a0 \u00a0 \u00a0 keys.\u00a0 If supplied the server MUST use them as specified in \u00a0 \u00a0 \u00a0 [ RFC8291 ] to encrypt all data sent to the push subscription.\u00a0 The \u00a0 \u00a0 \u00a0 object MUST have the following properties: \u00a0 \u00a0 \u00a0 *\u00a0 *p256dh*: the P-256 ECDH Diffie-Hellman public key as described \u00a0 \u00a0 \u00a0 \u00a0  in [ RFC8291 ], encoded in URL-safe Base64 representation as What's the crypto agility story for these web push encryption keys? (See  BCP 201 .) Also, when these expirations fire (e.g., for Basic Authentication credentials), we need a normative requirement to actually destroy the private credentials; there's a lot going on here so maybe I missed it, but I don't think I saw one.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-08 11:44:14-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-01 12:26:23-08:00",
    "text": "Trimming down for things fixed in the -15... Section 5.3 \u00a0  Some records may hold references to other records (foreign keys). \u00a0  That reference may be set (via create or update) in the same request \u00a0  as the referenced record is created.\u00a0 To do this, the client refers \u00a0  to the new record using its creation id prefixed with a \"#\".\u00a0 The \u00a0  order of the method calls in the request by the client MUST be such \u00a0  that the record being referenced is created in the same or an earlier \u00a0  call.\u00a0 The server thus never has to look ahead.\u00a0 Instead, while I think this means you need to specify what order the server does the create, update, and destroy lists in -- that is, that all creates are done before all updates, etc.. Section 7.1 \u00a0  o\u00a0 *changed*: \"Id[TypeState]\" A map of _account id_ to an object \u00a0 \u00a0 \u00a0 encoding the state of data types that have changed for that \u00a0 \u00a0 \u00a0 account since the last StateChange object was pushed, for each of I don't see how these semantics provide the properties stated in Section 7, \"[i]t doesn't matter if some push events are dropped before they reach the client; it will still get all changes next time it syncs.\"\u00a0 In particular, if the client misses a state change for the CalendarEvent type, and then no other changes that affect CalendarEvents occur, the client will remain unaware of the changes to CalendarEvents, even if other push notifications for other types come in.\u00a0 Am I misunderstanding one or more of the behavior or stated guarantees? Section 7.2 \u00a0  o\u00a0 *keys*: \"Object|null\" (immutable) Client-generated encryption \u00a0 \u00a0 \u00a0 keys.\u00a0 If supplied the server MUST use them as specified in \u00a0 \u00a0 \u00a0 [ RFC8291 ] to encrypt all data sent to the push subscription.\u00a0 The \u00a0 \u00a0 \u00a0 object MUST have the following properties: \u00a0 \u00a0 \u00a0 *\u00a0 *p256dh*: the P-256 ECDH Diffie-Hellman public key as described \u00a0 \u00a0 \u00a0 \u00a0  in [ RFC8291 ], encoded in URL-safe Base64 representation as What's the crypto agility story for these web push encryption keys? (See  BCP 201 .) Also, when these expirations fire (e.g., for Basic Authentication credentials), we need a normative requirement to actually destroy the private credentials; there's a lot going on here so maybe I missed it, but I don't think I saw one.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-06 20:43:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-16 16:17:32-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4155 I believe I have found a security issue, noted below. In addition, I have noted a potential interop issue. DETAIL S 2. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"urn:ietf:params:jmap:contacts\", while the second account would >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 just have the last of these.\u00a0 Attempts to use the methods >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 defined in a specification with one of the accounts that does >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 not contain those data types are rejected with an >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 _accountNotSupportedByMethod_ error (see section 3.5.2: method- >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 level errors). What happens if this changes after the user has logged in. So, for instance, I log in and am told that account X has contacts, but later calendars get added. Do requests have to fail? S 7.2.2. >\u00a0 \u00a0 \u00a0 o\u00a0 *pushSubscriptionId*: \"String\" The id of the push subscription >\u00a0 \u00a0 \u00a0 \u00a0  that was created. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 *verificationCode*: \"String\" The verification code to add to the >\u00a0 \u00a0 \u00a0 \u00a0  push subscription.\u00a0 This MUST contain sufficient entropy to avoid >\u00a0 \u00a0 \u00a0 \u00a0  the client being able to brute force guess the code. This doesn't actually guarantee permission. Consider the case where the client provides a push URL for some sort of open server upload endpoint. The client could then read the verification code off that endpoint and confirm the push subscription. Off the top of my head, requiring the push endpoint to respond in-band with a function of the code would be better.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-03-23 09:07:57-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-21 05:24:37-08:00",
    "text": "Sorry, I earlier forgot one point I would like to quickly discuss: The jmap service name registration only requests registration for tcp while H/3 could be used as well which will work over udp. Maybe it would be more future-proof to also add an entry for udp? Further, there is a note that says that this registration will change an existing entry. Please note that for removing the existing entry, IANA might still need to contact the original assignee to ask for approval. However, this is just a processing issue and shouldn't lead to a real problem. And finally a comment related to my above note about H/3, the document talks two times about \"keeping the TCP connection open\". To be future proof, I would maybe recommend to change the wording to \"keeping the transport connection open\".",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-07-26 07:42:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 14:04:08-07:00",
    "text": "# GEN AD review of  draft-ietf-add-svcb-dns-06 CC @larseggert Thanks to Peter E. Yee for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/T4D0gKTp6m_TFw0C26Ib-7PqttY ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS for IANA, so we can determine next steps during the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-12-05 14:54:23-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 15:10:17-07:00",
    "text": "Thanks to everyone who invested their time in this document. I have one blocking comment that I believe should be easy to resolve, and one fairly major comment that should be trivial to fix. \u00a78.1.1: >\u00a0 o\u00a0 The Uri-Path option is set to \"j\". COAP URIs are generally subject to  BCP 190  restrictions, which would require the path to either be provisioned, discovered, or under the \".well-known\" tree. The use of a reserved domain name here may change the rationale; but for the sake of not establishing a precedent for path squatting in CoAP, this document needs to clearly explain the rationale of why  BCP 190  should not apply in this case. Alternately, the implied URI can be changed to something like \"coap:// 6tisch.arpa/.well-known/j \"",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-11-01 15:04:57-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 07:32:08-07:00",
    "text": "I have some issues with the references here, which should be resolvable simply by making some normative. RFC 8505  provides terminology as well as neighbor discovery (in Sections 4.2 and 6), so it seems to me that it should be a normative reference. As  draft-ietf-6tisch-architecture  is used for both necessary terminology and concepts, I can\u2019t see how it isn\u2019t normative.\u00a0 I did find that I had to check it during my review. In Section 5: \u00a0  In an operational 6TiSCH network, all frames MUST use link-layer \u00a0  frame security [ RFC8180 ]. This would seem to be a MUST referring to 8180, making that a normative reference as well.\u00a0 But possibly this might not really be a MUST imposed here, and is instead citing a requirement from elsewhere.\u00a0 In that case, I would simply remove the word \u201cMUST\u201d, so it is stating a fact, rather than a new requirement.\u00a0 You might similarly consider the subsequent sentence.\u00a0 In any case, I do wonder whether\u00a0 7554 and 8180 should be normative.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-09 10:27:48-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 23:24:32-07:00",
    "text": "Thanks for this generally well-written document!\u00a0 It does a great job at making these fairly difficult topics accessible to the reader.\u00a0 I have a few points that should be fairly easy to address, but do need to be addressed before the document should advance. My comment on Section 8.4.4 tries to walk through some scenarios involving a finite lease time on a short address; as a result of that I think it's necessary to direct the 6LN to interpret the time in units of ASN as opposed to wall-clock time. The \"parameter_addinfo\" field in Unsupported_Parameter (Section 8.4.5) feels underspecified to me.\u00a0 The inline text says that only a subset of the link-layer key set from the Configuration could be included here, but how is that formally specified? The string COJP_MAX_JOIN_ATTEMPTS appears only twice in the text, once in Section 8.3.1 and again in the table in Section 8.5.\u00a0 The former text leaves me confused as to what counts as a \"join attempt\" for this purpose, and in particular how it differs from the MAX_RETRANSMIT timer mentioned in the previous sentence. I couldn't find a clear statement that any node sending EBs needs to be prepared to act as a join proxy; Section 4.1 notes that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 During the remainder of the join process, the node \u00a0  that has sent the EB to the pledge acts as the JP. but I couldn't find where that was enforced. I think we may need to say more about how a JP knows that \"secExempt\" is in effect (see comment in Section 5), since that affects a critical piece of the security posture of the network. Finally, can we discuss whether a 32-bit MIC is the most appropriate default for the key usage?\u00a0 I lack the domain background to know how much impact there is in going to an ENC-MIC64 or ENC-MIC128 scheme.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-29 09:43:04-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-29 04:12:49-07:00",
    "text": "1) I hope this point can be resolved quickly as it seems to only need a bit more specifics but I think this part is not sufficient: Sec 6.1: \"The Join Proxy implements a data cap on outgoing \u00a0  join traffic through CoAP's congestion control mechanism.\" I think this needs an normative requirement here. Congestion control is supposed to avoid network overload but also to make use available resources. The congestion control as currently defined\u00a0 for CoAP would probably limit the join traffic appropriately (to something like one packet per RTT likely) but CoAP could in theory use any time a different more aggrieve congestion and therefore just relying on congestion control generically doesn't seem to be sufficient. I recommend to define a hard limit, e.g. 1 packet per RTT or 1 packet per 3 seconds if RTT is unknown (as recommended in  RFC8085 ) and say that this can be achieved by congestion control as specified in the base CoAP spec. 2) Also, not\u00a0 sure if this editorial or a real issue but I'm not sure I fully understand this sentence: Sec 6.1.1: \"A Join Proxy that does not set the DSCP on traffic \u00a0  forwarded should set it to zero so that it is compressed out.\" If the proxy does NOT SET DSCP, why should it SET it to zero? I would think it either sets it to AF43 or it does nothing about it because DSCP is not really used in that network. I guess it's not a big issue and setting to zero seems fine as well but I'm afraid I don't understand the intent here and when exactly the Proxy is supposed to set to AF43 or bleach. 3) This may also be mostly editorial but just to be sure. Section 7.2 provide default value for some of the CoAP transport parameter (where 2 or 3 are the same as defined in  RFC7252 ) but not for all. Why is that? And then finally on reference again: Given that use of  I-D.ietf-core-stateless  is recommend, I believe it should be normative (and wait for publication of that doc).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-30 07:10:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-29 09:43:04-07:00",
    "text": "1) I hope this point can be resolved quickly as it seems to only need a bit more specifics but I think this part is not sufficient: Sec 6.1: \"The Join Proxy implements a data cap on outgoing \u00a0  join traffic through CoAP's congestion control mechanism.\" I think this needs an normative requirement here. Congestion control is supposed to avoid network overload but also to make use available resources. The congestion control as currently defined\u00a0 for CoAP would probably limit the join traffic appropriately (to something like one packet per RTT likely) but CoAP could in theory use any time a different more aggrieve congestion and therefore just relying on congestion control generically doesn't seem to be sufficient. I recommend to define a hard limit, e.g. 1 packet per RTT or 1 packet per 3 seconds if RTT is unknown (as recommended in  RFC8085 ) and say that this can be achieved by congestion control as specified in the base CoAP spec.  Further there seems to be an implicit requirement that the JP MUST implement rate limit using the PROBING_RATE parameter, however that is never explicitly spelled out as a normative requirement. However, if this rate is not provided by the JRC, it doesn't seem that any rate limiting has to enforced. So maybe it would be good to be more strict here. 2) Also, not\u00a0 sure if this editorial or a real issue but I'm not sure I fully understand this sentence: Sec 6.1.1: \"A Join Proxy that does not set the DSCP on traffic \u00a0  forwarded should set it to zero so that it is compressed out.\" If the proxy does NOT SET DSCP, why should it SET it to zero? I would think it either sets it to AF43 or it does nothing about it because DSCP is not really used in that network. I guess it's not a big issue and setting to zero seems fine as well but I'm afraid I don't understand the intent here and when exactly the Proxy is supposed to set to AF43 or bleach. 3) This may also be mostly editorial but just to be sure. Section 7.2 provide default value for some of the CoAP transport parameter (where 2 or 3 are the same as defined in  RFC7252 ) but not for all. Why is that? 4 ) And then finally on references (again): Given that use of  I-D.ietf-core-stateless  is recommend, I believe it should be normative (and wait for publication of that doc).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-05 06:29:59-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 07:10:17-07:00",
    "text": "1) I hope this point can be resolved quickly as it seems to only need a bit more specifics but I think this part is not sufficient: Sec 6.1: \"The Join Proxy implements a data cap on outgoing \u00a0  join traffic through CoAP's congestion control mechanism.\" I think this needs an normative requirement here. Congestion control is supposed to avoid network overload but also to make use available resources. The congestion control as currently defined\u00a0 for CoAP would probably limit the join traffic appropriately (to something like one packet per RTT likely) but CoAP could in theory use any time a different more aggrieve congestion and therefore just relying on congestion control generically doesn't seem to be sufficient. I recommend to define a hard limit, e.g. 1 packet per RTT or 1 packet per 3 seconds if RTT is unknown (as recommended in  RFC8085 ) and say that this can be achieved by congestion control as specified in the base CoAP spec.  Further on there seems to be an implicit requirement that the JP MUST implement rate limit using the PROBING_RATE parameter, however, that is never explicitly spelled out as a normative requirement. However, if this rate is not provided by the JRC, it doesn't seem that any rate limiting has to be enforced. So maybe it would be good to be more strict here. 2) Also, not\u00a0 sure if this editorial or a real issue but I'm not sure I fully understand this sentence: Sec 6.1.1: \"A Join Proxy that does not set the DSCP on traffic \u00a0  forwarded should set it to zero so that it is compressed out.\" If the proxy does NOT SET DSCP, why should it SET it to zero? I would think it either sets it to AF43 or it does nothing about it because DSCP is not really used in that network. I guess it's not a big issue and setting to zero seems fine as well but I'm afraid I don't understand the intent here and when exactly the Proxy is supposed to set to AF43 or bleach. 3) This may also be mostly editorial but just to be sure: Section 7.2 provides default values for some of the CoAP transport parameter (where 2 of 3 are the same as defined in  RFC7252 ) but not for all. Why is that? 4 ) And then finally on references (again): Given that use of  I-D.ietf-core-stateless  is recommend, I believe it should be normative (and wait for publication of that doc).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-30 18:57:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-19 14:45:35-08:00",
    "text": "In Section 4.2 we say that \"If an entity is capable of [...] TLS 1.2 or any successors [...], the CAN_TLS flag within its contanct [sic] header SHALL be set to 1.\"\u00a0 I don't understand why we should allow in the spec for an entity to not be capable of TLS 1.2+.\u00a0 Can you give me some examples of situations when you would want to use a TCPCL but cannot use TLS with it?\u00a0 A new major version of TCPCL would be the least-bad time to make a clean break and mandate TLS... There's some good discussion in Section 4.4.2 of the mechanics of TLS X.509 certificate authentication; thanks for that!\u00a0 I do think that there's a fairly critical omission, though, namely that the BP agent needs to provide to the TCPCL Entity the Node ID of the expected next hop from the routing decision (in addition to the hostname/IP address to which to initiate a TCP connection), and this Node ID must also be validated against the TLS certificate and the SESS_INIT from the peer. Otherwise we are in effect falling back to an authorization policy of \"anyone with a cert with a uniformResourceIdentifier SAN of the expected scheme is authorized to do anything\", which is a pretty weak policy. (In some sense, if we require this, then the Node ID in the SESS_INIT becomes redundant, though I think there are some edge cases where it would still be needed in order for both endpoints to agree on the communicating identities.) I also think we need to discuss the TLS X.509 authentication model that will be used, i.e., \"what PKI is being used?\".\u00a0 (To be clear, I don't know that any changes to the text will be required, but do think we should be sure we have a clear picture of what the expected deployment strategies are.) The usage of SNI to pick a cert and the DNS-ID ( RFC 6125 ) to authenticate a hostname might imply that the typical \"Web PKI\" (that deals in hostnames) is intended, but the URIs we need to authenticate Node IDs are not commonly certified by that PKI.\u00a0 Since the server has to present a single certificate even if it is attempting to authenticate as both DNS-ID and the NodeID URI, it seems like it would be challenging to use this scheme in practice against the Web PKI roots. This hybrid of hostname and Node-ID authentication also suffers from an awkward ordering issue when the TLS handshake occurs before the SESS_INIT messages that convey what Node ID is intended to be authenticated -- this requires implementations to use a TLS stack that preserves the peer's certificate and perform name validation after a completed TLS handshake, which is moving more of the complications out of the TLS stack and into the application logic (which introduces risk of security-relevant bugs).\u00a0 It also means that certificate selection must be based solely on SNI hostname and cannot involve the requested Node ID.\u00a0 [There is in theory the selectable name_type field in the TLS server_name extension, but in practice that joint has rusted shut and it seems unlikely that there would be much implementation traction to define a name type for DTN Node ID;  RFC 6066  also fails to give a clear indication of the intended semantics when multiple name types are present.] Please double-check for lingering text that assumes the  RFC 7242 behaviors where all parameters are in the contact header (vs. SESS_INIT) and use of SDNV encoding vs. fixed-lengths.\u00a0 I noted several instances in the COMMENT section, but do not claim to have made an exhaustive review.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-02 22:47:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-30 18:57:11-07:00",
    "text": "[This is essentially a restatement of the comments at https://mailarchive.ietf.org/arch/msg/dtn/jnafmsDt0OXUhYlBwT_U9PuNV5c/ but rephrased to be a standalone review rather than continuation of an existing conversation.] I'm really impressed by the new text about PKIX environments/CA policy, and entity identification; thank you! I suspect that, with one exception, we have similar understandings of what is supposed to happen, but may need to wrangle the actual text on the page a little more to get to the right place. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The one exception relates to the security properties of having the certificate validation procedure be a prioritized list of steps with which steps to use being dependent on the contents of the received certificate.\u00a0 Specifically, if we will end up letting a peer with a DNS-ID cert authenticate as any node ID, then there is no security gain from having the node ID in the cert in the first place, since the attacker will just skip that step.\u00a0 The value of NODE-ID comes into play when we know, before we go into the validation procedure, that the legitimate peer will have the expected NODE-ID in their certificate. Obviously we cannot expect that to always be the case, given that we aim to be compatible with DTN-Ignorant CAs, so we will need to specify some granularity for when we do or do not require the NODE-ID to be present. There are a number of possibilities here and I don't know which is going to be best for the broadest group of deployments.\u00a0 Some simple ideas for consideration include: (a) any given node either always or never requires NODE-ID (b) any given interface either always or never requires NODE-ID (c) push it to the discovery protocol/\"out of band configuration\" (d) a trust-on-first-use-like option of \"once you've seen a NODE-ID for \u00a0 a given node ID, always require NODE-ID in the future for that node \u00a0 ID.\u00a0 (This has pretty significant risks without a way to \"undo the \u00a0 latch\" but if generating a new node ID is cheap they may be \u00a0 tolerable.) (e) define new URI scheme(s) that have similar semantics to the current \u00a0 ones but require NODE-ID for authentication. (f) similar to (e), apply additional granularity based on URI scheme or \u00a0 scheme-specific structure (e.g., certain prefixes/suffixes of names \u00a0 but not others In theory there are similar considerations between DNS-ID and NETWORK-ID (see below for comment about the \"NETWORK-ID\" name), but since they are both expected to be coming from the Web PKI and both have similarly weak models for node authentication it's not clear to me that we should spend much effort on a complicated procedure for there.\u00a0 Something simple like \"if you have a (stable) name for the peer, expect DNS-ID; if you only have an IP address, use NETWORK-ID\" should work quite well (and may even be what you intended anyway). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The main place where I'm still seeing a need for wordsmithing is in the authentication procedures in Section 4.4.3.\u00a0 I see from the previous discussion that the intent of \"SHALL attempt to authenticate [...] If  and security policy disallows an unauthenticated , the entity SHALL terminate the session\" is for security policy to be able to say \"yes, there's no -ID and I'm fine with that (or potentially even \"the -ID that is present failed validation and I'm fine with that\"), which is a surprising wording to me but I guess technically okay.\u00a0 (The current wording strongly implies, to me, that  if validation fails, the session gets terminated; maybe it's something about the double negative in \"disallows an unauthenticated\" that makes the \"security policy\" aspect feel very weak.)\u00a0 What seems significantly problematic to me, though, is the requirement as-written to attempt validation of all three types of ID (NODE-ID, DNS-ID, and NETWORK-ID). In the expected case where a peer's certificate contains only one of the three (or, perhaps, a NODE-ID and one other name type), this means that security policy would have to be some complex matrix with interdependencies between the various types (allow unauthenticated host by DNS-ID if NETWORK-ID present and valid, etc.) that prevents validation of each type of name being performed independently. In particular, this \"must attempt all three types\" logic seems at odds with the first paragraph of the section that says that attempting host name validation is optional. So, I would have expected the text to flow more along the lines of (but written less hastily) \"security policy determines, for a given connection, which identity type(s) is expected, and validation is attempted for those specific type(s).\u00a0 Failed authentication results in session termination.\" It is okay with me for security policy to allow continuing with the connection even when validation is attempted but fails, but I'm not sure that we currently have a fully consistent picture about how/when this happens.\u00a0 In particular, I see a note in Section 8.10.1 that using TLS in a way which does not authenticate both peers is out of scope of this document\" along with a mention of similarities to opportunistic security, yet letting security policy proceed with an unauthenticated peer seems at odds with that \"out of scope\".\u00a0 We should have a clearer picture of whether opportunistic security with no or failed authentication of one or both peers is permitted by this document. I think we can also wordsmith the setting of CAN_TLS a little more; previous discussion indicated a desire to (e.g.) not require TLS when operating over IPsec, but that's a different criterion than \"capable of exchanging messages [with TLS]\".\u00a0 It's also inconsistent with a desire to make TLS support mandatory to implement (but not mandatory to use), since mandatory to implement implies mandatory to be \"capable of exchanging messages with TLS\", thus mandatory to use.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-27 21:03:31-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-02 22:47:59-08:00",
    "text": "[retaining discuss section unchanged from the -21 in order to update the comment section, even though much progress has been made on this front at IETF 109 and via email.\u00a0 IIRC we have a thread open with the PKIX extended key purpose DE for how to modify the TLS certificate validation procedures.] ========================== discuss section from -21 below ==================== [This is essentially a restatement of the comments at https://mailarchive.ietf.org/arch/msg/dtn/jnafmsDt0OXUhYlBwT_U9PuNV5c/ but rephrased to be a standalone review rather than continuation of an existing conversation.] I'm really impressed by the new text about PKIX environments/CA policy, and entity identification; thank you! I suspect that, with one exception, we have similar understandings of what is supposed to happen, but may need to wrangle the actual text on the page a little more to get to the right place. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The one exception relates to the security properties of having the certificate validation procedure be a prioritized list of steps with which steps to use being dependent on the contents of the received certificate.\u00a0 Specifically, if we will end up letting a peer with a DNS-ID cert authenticate as any node ID, then there is no security gain from having the node ID in the cert in the first place, since the attacker will just skip that step.\u00a0 The value of NODE-ID comes into play when we know, before we go into the validation procedure, that the legitimate peer will have the expected NODE-ID in their certificate. Obviously we cannot expect that to always be the case, given that we aim to be compatible with DTN-Ignorant CAs, so we will need to specify some granularity for when we do or do not require the NODE-ID to be present. There are a number of possibilities here and I don't know which is going to be best for the broadest group of deployments.\u00a0 Some simple ideas for consideration include: (a) any given node either always or never requires NODE-ID (b) any given interface either always or never requires NODE-ID (c) push it to the discovery protocol/\"out of band configuration\" (d) a trust-on-first-use-like option of \"once you've seen a NODE-ID for \u00a0 a given node ID, always require NODE-ID in the future for that node \u00a0 ID.\u00a0 (This has pretty significant risks without a way to \"undo the \u00a0 latch\" but if generating a new node ID is cheap they may be \u00a0 tolerable.) (e) define new URI scheme(s) that have similar semantics to the current \u00a0 ones but require NODE-ID for authentication. (f) similar to (e), apply additional granularity based on URI scheme or \u00a0 scheme-specific structure (e.g., certain prefixes/suffixes of names \u00a0 but not others In theory there are similar considerations between DNS-ID and NETWORK-ID (see below for comment about the \"NETWORK-ID\" name), but since they are both expected to be coming from the Web PKI and both have similarly weak models for node authentication it's not clear to me that we should spend much effort on a complicated procedure for there.\u00a0 Something simple like \"if you have a (stable) name for the peer, expect DNS-ID; if you only have an IP address, use NETWORK-ID\" should work quite well (and may even be what you intended anyway). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The main place where I'm still seeing a need for wordsmithing is in the authentication procedures in Section 4.4.3.\u00a0 I see from the previous discussion that the intent of \"SHALL attempt to authenticate [...] If  and security policy disallows an unauthenticated , the entity SHALL terminate the session\" is for security policy to be able to say \"yes, there's no -ID and I'm fine with that (or potentially even \"the -ID that is present failed validation and I'm fine with that\"), which is a surprising wording to me but I guess technically okay.\u00a0 (The current wording strongly implies, to me, that  if validation fails, the session gets terminated; maybe it's something about the double negative in \"disallows an unauthenticated\" that makes the \"security policy\" aspect feel very weak.)\u00a0 What seems significantly problematic to me, though, is the requirement as-written to attempt validation of all three types of ID (NODE-ID, DNS-ID, and NETWORK-ID). In the expected case where a peer's certificate contains only one of the three (or, perhaps, a NODE-ID and one other name type), this means that security policy would have to be some complex matrix with interdependencies between the various types (allow unauthenticated host by DNS-ID if NETWORK-ID present and valid, etc.) that prevents validation of each type of name being performed independently. In particular, this \"must attempt all three types\" logic seems at odds with the first paragraph of the section that says that attempting host name validation is optional. So, I would have expected the text to flow more along the lines of (but written less hastily) \"security policy determines, for a given connection, which identity type(s) is expected, and validation is attempted for those specific type(s).\u00a0 Failed authentication results in session termination.\" It is okay with me for security policy to allow continuing with the connection even when validation is attempted but fails, but I'm not sure that we currently have a fully consistent picture about how/when this happens.\u00a0 In particular, I see a note in Section 8.10.1 that using TLS in a way which does not authenticate both peers is out of scope of this document\" along with a mention of similarities to opportunistic security, yet letting security policy proceed with an unauthenticated peer seems at odds with that \"out of scope\".\u00a0 We should have a clearer picture of whether opportunistic security with no or failed authentication of one or both peers is permitted by this document. I think we can also wordsmith the setting of CAN_TLS a little more; previous discussion indicated a desire to (e.g.) not require TLS when operating over IPsec, but that's a different criterion than \"capable of exchanging messages [with TLS]\".\u00a0 It's also inconsistent with a desire to make TLS support mandatory to implement (but not mandatory to use), since mandatory to implement implies mandatory to be \"capable of exchanging messages with TLS\", thus mandatory to use.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-02-25 00:38:21-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-20 06:48:15-08:00",
    "text": "eed to confirm that reassigning the TCP Port 4556 is okay with the official assigne Simon Perreault.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-23 01:52:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 06:50:57-08:00",
    "text": "eed to resolve Mirja's discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-23 06:56:13-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-23 01:52:34-07:00",
    "text": "irja's discuss is now resolved except for a single item regarding the aspect of session policies for TCPclv4.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-11-23 10:28:02-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-07 16:41:31-08:00",
    "text": "Sec 6.1. I read this sentence several times and could not figure out what it is saying, and fear there could be interoperability problems. \"When performing an unclean termination, a \u00a0  transmitting node SHALL treat either sending or receiving a SESS_TERM \u00a0  message (i.e., before the final acknowledgment) as a failure of the \u00a0  transfer.\u00a0 Any delay between request to close the TCP connection and \u00a0  actual closing of the connection (a \"half-closed\" state) MAY be \u00a0  ignored by the TCPCL entity.\" First of all, \"failure of the transfer\" is ambiguous because there may be two transfers going on, one in each direction. Second, I would like further clarity on what it means that nodes \"SHALL\" consider it \"a failure of the transfer\". What is actionable if it's a failure? If nothing is actionable, it shouldn't be a SHALL. Does this mean that in subsequent sessions I must resend the whole bundle? Can you list some reasons why an endpoint would choose to close uncleanly? Some motivation might provide helpful context. Moreover the \"sending or receiving\" bit is confusing. - So one option is that I'm a session that has decided to do an unclean termination rather than a clean one. So I send SESS_TERM and then close (FIN? RST?) the TCP connection. So if it's a FIN, I might very well get the last XFER_ACK.\u00a0 If I RST or don't get that ACK, then I do think it's clear that the transfer is a failure, whatever that means. - But as a receiver, how do I know that the termination is unclean? Have I made an independent decision to close uncleanly? Am I to take the receipt of a SESS_TERM without my having sent XFER_ACK as an unclean close? If I sent XFER_ACK, how do I know that the sender sent it? And what does it mean, as a receiver, that the transfer \"failed\" if I have all the data?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-02-20 05:06:19-08:00",
    "text": "Thanks for this well-written document. I have a couple of thing in the comment section below that should be clarified. But there is one point which does not seem correct to me and therefore I'm raising it at thee discuss level: Sec 5.1.1: \"Both sides SHALL send a KEEPALIVE message whenever the negotiated interval \u00a0  has elapsed with no transmission of any message (KEEPALIVE or other). \u00a0  If no message (KEEPALIVE or other) has been received in a session \u00a0  after some implementation-defined time duration, then the node SHALL \u00a0  terminate the session by transmitting a SESS_TERM message (as \u00a0  described in Section 6.1) with reason code \"Idle Timeout\". \" It is not necessary that both endpoints send keepalives when TCP is used underneath as data is transmitted reliably. If one end sends keepalives and transmission fails it will close the TCP connection no matter what. Therefore the case where no keepalive is received, can only happen if no keepalive was send by the application, however, if the own keepalives are send successfully it is also received and the TCP connection is alive. If this is only to test liveness of the TCP connection, why don't you use TCP keepalives instead? Further what happens when a keepalive fails? Should one endpoint try to reconnect, immediately or later when new data is available? And one more small thing: sec 6.1: \"However, an entity MUST always send \u00a0  the contact header to its peer before sending a SESS_TERM message.\" This normative requirement seems contradicting the way version failures are handled earlier on in the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-02-18 19:35:28-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-18 19:34:45-08:00",
    "text": "* Section 4.2: \" TLS 1.2 [ RFC5246 ] or any successors [ RFC8446 ] that are compatible with TLS 1.2\" Hopefully this is easy to resolve but I am not sure what exactly you intended to say with this phrase \"that are compatible with TLS 1.2\". Can you please clarify? (I think going through Appendix D of  RFC8446  may bring up specific things you might be looking for). A similar construct is also used in Section 4.4.1.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-13 11:48:37-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-18 19:35:28-08:00",
    "text": "* Section 4.2: \" TLS 1.2 [ RFC5246 ] or any successors [ RFC8446 ] that are compatible with TLS 1.2\" Hopefully this is easy to resolve but I am not sure what exactly you intended to say with this phrase \"that are compatible with TLS 1.2\". Can you please expand and clarify? (I think going through Appendix D of  RFC8446  may bring up specific things you might be looking for). A similar construct is also used in Section 4.4.1.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-12-13 13:54:07-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-12-13 13:53:48-08:00",
    "text": "This is, I believe a minor DISCUSS, and I'll happily clear it once a commitment is made that it will be addressed (AKA, I'm not going to hold up the document, but there isn't a \"Comment\" and \"Very important comment\" in the datatracker). Stefan Winter's OpsDir review contains: \"* Introduction states \"[...] if it appears in the IPv4 Address Resolution Protocol (ARP) table [ RFC0826 ] or IPv6 Neighbor Cache [ RFC4861 ].\" \"Appears\" is a rather loose word, as entries in those tables can have multiple states. E.g. for IPv6, which of the states DELAY, STALE, REACHABLE do you mean? All? Or only a subset? In IPv4, do you mean the \"C\" flag exclusively? Also, when the proxy operates remotely (i.e. bases the reply on ARP/Neighbor Cache rather than ifOperStatus), does it actively ping the interface in question itself? If not, how does it handle an interface address which is not in the ARP/Neighbour table simply because the entry has timed out? The interface might be up and active nontheless. In such a case, reporting \"does not exist\" is false.\" Ron Bonica's suggested solution in:  https://www.ietf.org/mail-archive/web/int-area/current/msg06136.html  works for me, but I do not see it in the version being discussed. This would make a substantive change to the document, I wanted to draw attention to it.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-12-14 07:13:36-08:00",
    "end_reason": "position_updated",
    "start": "2017-12-13 13:54:07-08:00",
    "text": "This is, I believe a minor DISCUSS, and I'll happily clear it once a commitment is made that it will be addressed / on the call (AKA, I'm not going to hold up the document, but there isn't a \"Comment\" and \"Very important comment\" in the datatracker). Stefan Winter's OpsDir review contains: \"* Introduction states \"[...] if it appears in the IPv4 Address Resolution Protocol (ARP) table [ RFC0826 ] or IPv6 Neighbor Cache [ RFC4861 ].\" \"Appears\" is a rather loose word, as entries in those tables can have multiple states. E.g. for IPv6, which of the states DELAY, STALE, REACHABLE do you mean? All? Or only a subset? In IPv4, do you mean the \"C\" flag exclusively? Also, when the proxy operates remotely (i.e. bases the reply on ARP/Neighbor Cache rather than ifOperStatus), does it actively ping the interface in question itself? If not, how does it handle an interface address which is not in the ARP/Neighbour table simply because the entry has timed out? The interface might be up and active nontheless. In such a case, reporting \"does not exist\" is false.\" Ron Bonica's suggested solution in:  https://www.ietf.org/mail-archive/web/int-area/current/msg06136.html  works for me, but I do not see it in the version being discussed. This would make a substantive change to the document, I wanted to draw attention to it.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-10-12 05:07:27-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 08:45:10-07:00",
    "text": "Hi, Thanks for writing this document.\u00a0 I have a few points that I believe are worthy of discussion. Disclaimer: I'm not familiar with IEEE 802.1CQ, nor am I a DHCPv6 expert ...\u00a0 Some of these questions/comments may have been answered there. My first question relates to process:\u00a0 Have members of the IEEE 802.1WG had an opportunity to review and provide input into this document?\u00a0 If not, then I think that it would be good for them to be given the opportunity to do so.\u00a0 In particular, they might question whether it is appropriate for a client to be able to request MAC addresses to be assigned from the SAI or \"reserved for future use\" address pools.\u00a0 It is worth noting that there is an IETF-IEEE liaison meeting on Mon 15th, that may help.  I'm not sure that I really like how the algorithm is defined in this document (relative to  draft-ietf-dhc-mac-assign ).\u00a0 In  draft-ietf-dhc-mac-assign , the client makes a request, and the server can respond with a completely different smaller MAC address range, i.e. the client is just providing hints/suggestions to the server.\u00a0 I would be much happier if the QUAD option specified in this document behaved similarly.\u00a0 I.e. the QUAD option is used by a client to specify an ordered preference of quads to use, but otherwise the server is allow to offer up an address, or block of addresses, outside the preferred quads, which the client could choose to not accept, or release.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-11 00:36:58-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-17 06:29:20-08:00",
    "text": "Section 7.1: Port request for DOTS signal for home. I think the WG has failed to take the assignment principles in  RFC 6335  to heart: From Section 7:  \u00a0  \"The basic principle of service name and port number registry \u00a0  management is to conserve use of the port space where possible.\" \u00a0  o\u00a0 IANA strives to assign only one assigned port number per service \u00a0 \u00a0 \u00a0 or application. \u00a0 \u00a0 \u00a0 Note: At the time of writing of this document, there is no IETF \u00a0 \u00a0 \u00a0 consensus on when it is appropriate to use a second port for an \u00a0 \u00a0 \u00a0 insecure version of a protocol. \u00a0  o\u00a0 IANA strives to assign only one assigned port number for all \u00a0 \u00a0 \u00a0 variants of a service (e.g., for updated versions of a service). \u00a0  o\u00a0 IANA strives to encourage the deployment of secure protocols. \u00a0  o\u00a0 IANA strives to assign only one assigned port number for all \u00a0 \u00a0 \u00a0 different types of devices using or participating in the same \u00a0 \u00a0 \u00a0 service. \u00a0  o\u00a0 IANA strives to assign port numbers only for the transport \u00a0 \u00a0 \u00a0 protocol(s) explicitly named in an assignment request. \u00a0  o\u00a0 IANA may recover unused port numbers, via the new procedures of \u00a0 \u00a0 \u00a0 de-assignment, revocation, and transfer. After having reviewed Appendix A I think the WG has made the wrong choice and also not considered all the available choices for enabling DOTS signal and call home to be colocated on the same port. Several options exists: \t- URI name space so that it is the same protocol just making requests with different URIs depending on mode \t- Use the already existing settings negotiation to determine the mode of operation. \t- Using ALPN on (D)TLS connection establishment From my perspective the DOTS WG have multiple choices that are quite simple to solve there colocation issue that would not incur significnat cost or overhead. Using an additional port do incur a cost of consuming a resource that is endless and not easily recoverable. I do share the IANA port experts team's verdict that this port assignment should be denied and alternative solution found as the motivation appears very weak.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-07 14:08:27-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 12:00:35-08:00",
    "text": "It seems to me there is a missing operational guidance or undocumented deployment assumptions.\u00a0 Since the motivational use case seems to be home networks (per Section 1.1), I assumed that the call home servers are running primarily consumer grade routers not managed by professional IT expertise.\u00a0 If that assumption is true (and it should be documented if that is the case), then I find many of the operational recommendations not congruent with that environment.\u00a0 Specifically, the degree of interaction and tuning seems outside the realm of expertise of someone without IT training and capabilities of home network ecosystem.\u00a0 In particular: -- Section 1.2  The Call Home DOTS server uses the DDoS attack traffic information to \u00a0  identify the compromised device in its domain that is responsible for \u00a0  launching the DDoS attack, optionally notifies a network \u00a0  administrator, and takes appropriate mitigation action(s).  How would such notification work? -- Section 1.2 and 5.1.\u00a0 Leaves credentials configuration as out of scope.\u00a0 Section 1.2 references [ I-D.ietf-dots-server-discovery ] for provisioning.\u00a0 In turn, Section 1 of [I-D.ietf.server-discovery] also declares this problem out of scope by saying \u201cThis document assumes that security credentials to authenticate DOTS server(s) are pre-provisioned to a DOTS client using a mechanism such as (but not limited to) those discussed in [ RFC8572 ] or [ I-D.ietf-anima-bootstrapping-keyinfra ]\u201d.\u00a0 However,  RFC8572  seems to rely on NETCONF and RESTCONF which seems like a rather uncommon feature of home routers.\u00a0 BRKSI relies on a manufacturer supplied/contracted infrastructure and keystores that also seem uncommon for consumer grade equipment.  -- Section 5.3.1. The Call Home DOTS server domain administrator consent MAY be \u00a0  required to block the traffic from the compromised device to the \u00a0  attack target.\u00a0 An implementation MAY have a configuration knob to \u00a0  block the traffic from the compromised device to the attack target \u00a0  with or without DOTS server domain administrator consent. The suggestion here seems to be that consumers are acquiring devices that can be remotely reconfigured with out a defined trust model?\u00a0 Some policy or operational context seems appropriate here. -- Section 5.3.1 ... notifies the CPE \u00a0  administrator about the compromised device Notify how? -- Section 8.  Appropriate \u00a0  filters (e.g., access control lists) can be installed on the Call \u00a0  Home DOTS server and network between the Call Home DOTS agents so \u00a0  that only communications from a trusted Call Home DOTS client to the \u00a0  Call Home DOTS server are allowed. This seems like a level of sophistication beyond your average home router user and a place where implementations should consider a secure defaults. -- Section 8. Call Home DOTS servers can also seek the consent of DOTS \u00a0  server domain administrator to block the traffic from the potentially \u00a0  compromised device to the target (see Section 5.3.1). What would be the means to gain such consent? -- Section 9. Note that a Call Home DOTS server can seek an administrator's \u00a0  consent, validate the request by inspecting the relevant traffic for \u00a0  attack signatures, or proceed with both courses of action. As above. -- Section 9. \u00a0 \u00a0 The DOTS Call Home is only advisory in nature.\u00a0 Concretely, the DOTS \u00a0  Call Home does not impose any action to be enforced within the \u00a0  network hosting an attack source; it is up to the Call Home DOTS \u00a0  server (and/or network administrator) to decide whether and which \u00a0  actions are required. Such a decisions seems out beyond the ability of your average home router user. -- Section 8\u00a0 \u201c... explicit policy (e.g., the Call Home DOTS client and server are managed by the same administrative entity), Is there an underlying assumption that the ISP is managing the device?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-07-05 16:20:51-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-23 23:21:29-07:00",
    "text": "The security considerations of this document seem unacceptably incomplete, as they basically just point to other documents. \u00a0  The RPS protocol defined in this document is carried in the G-ACh \u00a0  [ RFC5586 ], which is a generalization of the Associated Channel \u00a0  defined in [ RFC4385 ].\u00a0 The security considerations specified in these \u00a0  documents apply to the proposed RPS mechanism. The security considerations of those documents don't seem that great either. However, I believe that they miss a new security issue raised by the mechanism in this draft, which is that a member of the ring appears to be able to forge reports of errors at other parts of the ring. Specifically, S 5.1.3.3 says: \u00a0  When a node is in a pass-through state, it MUST transfer the received \u00a0  RPS Request in the same direction. \u00a0  When a node is in a pass-through state, it MUST enable the traffic \u00a0  flow on protection ring tunnels in both directions. This seems not to involve any filtering, which suggests that node B can send a forged SF from C->D and from D->C, which at least potentially temporarily breaks the link there, causing traffic diversion. More generally, this system assumes that every node trusts every other node completely. That must at least be stated. Incidentally, the text above appears to contain a bug in that it doesn't talk about processing incoming RPS requests intended for the receiving node, but I may just have missed the section where it says that.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2017-06-20 14:14:05-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-24 13:07:32-07:00",
    "text": "I want to thank the authors for a very readable draft. It was a pleasure to review, and that's a high bar for the subject. I have loads of questions, but my first set of questions is an expansion of Alvaro's comment that I think rises to the level of a Discuss. Please note that I'm asking questions, not proposing text changes, so I really do want to discuss it. ---------- my first set of questions In this text, \u00a0  Three typical ring protection mechanisms are described in this \u00a0  section: wrapping, short wrapping and steering.\u00a0 All nodes on the \u00a0  same ring MUST use the same protection mechanism. I would like to understand what happens if they aren't - and I'm asking, mostly as a way of encouraging guidance for operators in debugging cases where they're not all using the same mechanism. I'm not asking for a full mesh of possible misconfigurations, only for a sentence or two (\"If they aren't all using the same protection mechanism, the following things may happen\"). More broadly, I'd like to understand why wrapping and short wrapping are both defined. It seems like the only functional difference is that short wrapping doesn't give you as much latency. Is that right?  24 pages in, I see this: \u00a0  o\u00a0 In rings utilizing the wrapping protection, each node detects the \u00a0 \u00a0 \u00a0 failure or receives the RPS request as the destination node MUST \u00a0 \u00a0 \u00a0 perform the switch from/to the working ring tunnels to/from the \u00a0 \u00a0 \u00a0 protection ring tunnels if it has no higher priority active RPS \u00a0 \u00a0 \u00a0 request. \u00a0  o\u00a0 In rings utilizing the short wrapping protection, each node \u00a0 \u00a0 \u00a0 detects the failure or receives the RPS request as the destination \u00a0 \u00a0 \u00a0 node MUST perform the switch only from the working ring tunnels to \u00a0 \u00a0 \u00a0 the protection ring tunnels. so I'm pretty sure there are differences beyond what I was seeing, earlier in the document. And, of course, I'm not sure what the effect of choosing steering over wrapping/short wrapping would be, for my users, but that can wait until we talk about wrapping and short wrapping ... At a minimum, I'd like to see guidance for operators in choosing among the three protection mechanisms. Why would they choose any one of the three? I also note that this MUST seems to be repeated using different words in section 5.1, as \u00a0  All nodes in the same ring MUST use the same protection mechanism, \u00a0  Wrapping, steering or short-wrapping. If that's saying the same thing, one MUST is all you need.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 10:20:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-24 13:18:03-07:00",
    "text": "\"The IESG is considered to be the owner of all these key exchange \u00a0  methods; this does NOT imply that the IESG is considered to be the \u00a0  owner of the underlying GSS-API mechanism.\" I don't understand this text. What does it mean for the IESG to be the owner of a method?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-31 12:08:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-19 15:43:43-07:00",
    "text": "I have a question about the scope of some normative language, which may or may not be problematic but I'm too ignorant of OSPF details to be able to answer myself.\u00a0 In Section 3 we say that: \u00a0  When an OSPF Area Border Router (ABR) distributes information between \u00a0  connected areas it MUST preserve the ELC setting. My undesrtanding is that it's normal operation for an ABR to distribution information about prefixes and such between areas, and in particular that an ABR does not necessarily need to know the semantic details of every bit of information being distributed in that fashion. So, I am imagining a scenario where some routers in both areas advertise/understand the ELC flag but the ABR between them does not implement this spec.\u00a0 What would happen in such a scenario?\u00a0 If the ABR is still expected to distribute the ELC setting without change, isn't that just a core requirement from the respective OSPF specs, as opposed to a new requirement imposed by this spec (which, in this scenario, the ABR is not claiming to adhere to anyway)? There is perhaps a similar question about the ASBR guidance, though when doing cross-protocol signalling there is a more clear need for the ASBR to understand the semantics of the flags it is redistributing (and it's only a \"SHOULD\").",
    "type": "Discuss"
  },
  {
    "ad": "Adrian Farrel",
    "end": "2014-10-30 07:55:26-07:00",
    "end_reason": "position_updated",
    "start": "2014-10-29 10:34:44-07:00",
    "text": "I'm entering this as a Discuss as input to the debate the IESG will have on this document. I do not expect any action from the document authors at this stage. I will either update the Discuss to show the appropriate actions, or will remove it. It is clear to me that a number of people working across a broad set of network operators have driven this work, and also that there is consensus in the WG as reported by the chairs. Also I see the consensus called by the AD for IETF last call. The document doesn't use  RFC 2119  language (although the first paragraph of Section 1.3 was a surprise to me, if just weird IMHO, and would probably best be removed). But I agree that it is unfortunate to have developed this document in isolation from 3GPP. That is not to say that the IETF should not publish such a document. But to do so without even notifying 3GPP of the work in progress and giving them the chance to comment seems to be regrettable. While it is clear that there is a perceived need for a profile that is different from what the 3GPP previously developed, it would have been good to hear from 3GPP what concerns they have with this new profiles.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2014-10-29 07:58:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2014-10-29 07:03:58-07:00",
    "text": "This is a DISCUSS for the IESG for the time being.\u00a0 No need for author/chair actions at this time... I believe that this document will be harmful if it is published.\u00a0 It portrays itself as a viable product profile for 3GPP networks. However, this was done without interactions with 3GPP and creates a situation where user-equipment vendors may be confused as to what profiles are valid for their 3GPP devices.\u00a0 Despite referring to itself as a set of recommendations, it uses 2119 keywords to turn these recommendations into requirements.\u00a0 Given that  RFC 7066  exists and device profiles have been developed by other SDOs, I don't believe we should be publishing this document.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2014-10-30 03:55:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2014-10-29 07:58:10-07:00",
    "text": "* Clarified my statement based on private feedback * This is a DISCUSS for the IESG for the time being.\u00a0 No need for author/chair actions at this time... I believe that this document will be harmful if it is published.\u00a0 It portrays itself as a viable product profile for 3GPP networks. However, this was done without interactions with 3GPP and creates a situation where user-equipment vendors may be confused as to what profiles are valid for their 3GPP devices.\u00a0 Despite referring to itself as a set of recommendations, it uses 2119 keywords to turn these recommendations into requirements.\u00a0 Given that  RFC 7066  exists and that this type of profile should be developed within the GSM Association, I don't believe we should be publishing this document.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2014-10-31 07:18:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2014-10-30 03:55:38-07:00",
    "text": "* Updated text based on feedback on other ballot positions and private e-mail from the authors * This is a DISCUSS for the IESG for the time being.\u00a0 No need for author/chair actions at this time... I believe that this document will be harmful if it is published.\u00a0 It portrays itself as a viable product profile for 3GPP networks. However, this was done without interactions with 3GPP and creates a situation where user-equipment vendors may be confused as to what profiles are valid for their 3GPP devices.\u00a0 Despite referring to itself as a set of recommendations, it uses 2119 keywords to turn these recommendations into requirements.\u00a0 Given that  RFC 7066  exists and that this type of profile should be developed within the GSM Association, I don't believe we should be publishing this document. The following was sent to me from one of the authors: I can eventually understand the resistance to see a profile document published, but I thought this first sentence from the draft would softened that: \u00a0  This document defines an IPv6 profile that a number of operators \u00a0  recommend in order to connect 3GPP mobile devices to an IPv6-only or \u00a0  dual-stack wireless network (including 3GPP cellular network and IEEE \u00a0  802.11 network). The above text clearly illustrates why this document is a problem.\u00a0 How broad is this \"number of operators\"?\u00a0 Does it go beyond the 4 operators listed as document authors?\u00a0 If a vendor implements this profile, will they be capable of operating on a 3G/4G/WLAN network managed by some other operator?\u00a0 As Adrian noted, the convoluted use of 2119 keywords is troubling and having them couched in an Informational profile document is dubious at best. I support Adrian's notion that 3GPP should at least be notified of this work formally.\u00a0 The previous work, like  RFC 3314 , was driven by a partnership between 3GPP and the IETF ( https://datatracker.ietf.org/documents/LIAISON/file725.txt ) and we should continue that partnership *if* the consensus is to publish this document as a consensus-based RFC. It is also unclear if the people who raised earlier concerns feel that their concerns were addressed.\u00a0 I spoke with several of them and they do not think their concerns were addressed, but were tired of fighting over fundamental differences. If a group of operators wants to document a profile that highlights what they want vendors to implement, that should be documented somewhere else besides the IETF. At best, I could see this documented as an ISE document (with all the appropriate warnings).",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2016-04-08 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2014-10-31 07:18:18-07:00",
    "text": "* Updated based on the discussion during the 2014-10-30 IESG Telechat * This document, in its current form, will be harmful if it is published.\u00a0 There are several issues that need to be addressed in order to make this a viable IETF consensus-based document. 1. This draft portrays itself as a viable alternative product profile to  RFC 7066 . This document should clearly state that the profile described in this document is a super set of the one defined in 7066. 2. The use of 2119 keywords should be stricken from the document. Their use (regardless of their capitalization) leads to confusion as to whether these are recommendations or requirements. 3. The recommendations in this draft are overly broad. It suffers from some of the problems that led to the re-publication of the IPv6 Node Requirements document, namely trying to provide guidance/requirements that go beyond the base specifications being referenced. Justification needs to be documented for functions that go above and beyond those described in 7066. 4. Given that this document is aimed at devices intended for use in 3GPP networks, 3GPP should be made aware of this work in order to facilitate collaboration on its development. This is a task for the WG chairs and sponsoring AD to work with our 3GPP liaison manager. 5. The addition of extended functionality will need to consider the implications for interoperability with legacy systems developed using  RFC 7066 . Consideration, guidance, or caveats need to be documented for interoperability issues.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-18 17:46:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-21 11:23:44-07:00",
    "text": "(1)  RFC 4086  does not state that \"a high-security password must have at least 49 bits of randomness or entropy\" as is claimed in Section 4.1 of this document.\u00a0 It merely says that so much entropy is needed to have a one-in-a-billion chance of success for successfully guessing in the model laid out, and makes no statement about (absolute) \"high\" security. I don't think we need to spend as much time on what  RFC 4086  says as we currently do, and could probably get to the \"use at least 128 bits of entropy\" advice much sooner. (2) There's also some text in Section 5.3 that I'd like to discuss briefly: \u00a0  The registry MUST NOT return any indication of whether the \u00a0  authorization information is set or unset to the non-sponsoring \u00a0  registrar by not returning the authorization information element in \u00a0  the response.\u00a0 The registry MAY return an indication to the \u00a0  sponsoring registrar that the authorization information is set by \u00a0  using an empty authorization information value.\u00a0 The registry MAY \u00a0  return an indication to the sponsoring registrar that the \u00a0  authorization information is unset by not returning the authorization \u00a0  information element. This seems to be assigning semantics to both absent-authinfo and empty-authinfo in the\u00a0 response, but is giving *different* semantics to the response-to-sponsoring-registrar and response-to-non-sponsoring-registrar cases.\u00a0 Is there precedent for changing the semantics of the response based on the identity of the client like this (not just changing the content of the response)?\u00a0 Can we come up with a scheme that provides consistent semantics to all clients, perhaps based on\u00a0 vs empty\u00a0 for unset/set, leaving \"element is absent\" for the deliberately ambiguous case? (3) We may also need to discuss the efficacy of the transition plan, per my comments in Sections 6.1 and 6.3 -- my current understanding is that the proposed plan will break some existing workflows.\u00a0 I am not sure if that is intended, desirable, and/or tolerable, and welcome further insight.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-12-02 14:51:42-08:00",
    "end_reason": "position_updated",
    "start": "2017-09-24 17:37:43-07:00",
    "text": "The proper use of HMAC as a KDF is to have the secret value be used as the key and the public value used as the value, not the other way around. Even then, it would be better to use HKDF.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-26 17:51:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-17 16:44:31-07:00",
    "text": "(1)  draft-ietf-pce-association-group  notes that \"PCEP extensions that define a new association type should clarify the relationship between the SVEC object and the association type, if any\".\u00a0 Where do we do so for the path protection association type? (2) Section 3.2 says: \u00a0 \u00a0 \u00a0 Protection Type (PT): 6 bits - This field is as defined in \u00a0 \u00a0 \u00a0 Section 14.1 of [ RFC4872 ] to indicate the LSP protection type in \u00a0 \u00a0 \u00a0 use. There doesn't seem to be a registry created by  RFC 4872  to track these PT values, so I assume that the way to allocate a new value is \"standards-track RFC that Updates:  RFC 4872 \".\u00a0 Is that also the way to allocate new PT values for PPAG usage?\u00a0 How would someone updating  RFC 4872  to allocate a new type know to consider/document whether it applies for PPAG usage? (3) In Section 4.3: \u00a0  A PCE can create/update working and protection LSPs independently. \u00a0  As specified in [ I-D.ietf-pce-association-group ], Association Groups \u00a0  can be created by both the PCE and the PCC.\u00a0 Further, a PCE can The requirement that source, destination, and tunnel ID of all LSPs within a PPAG MUST be the same is new to this document, so I think we need to specify error handling for when attempts to update LSPs independently would violate that invariant (presumably in Section 4.5). (4) In Section 6.3: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 IANA is requested to allocate new \u00a0  error values within the \"PCEP-ERROR Object Error Types and Values\" \u00a0  sub-registry of the PCEP Numbers registry, as follows: The following table only lists Error-values.\u00a0 What Error-type(s) should they be associated with? (5) We don't say which objects the PPAG TLV can appear in.\u00a0 (Section 3.2 says \"[t]he Path Protection Association TLV is an optional TLV for use with the Path Protection Association Type\", but it's hard to interpret that as meaning \"for use [only] with the ASSOCIATION object defined in draft-ietf-pce-association-group \", especially since there is a \"path protection association type\" already (and it's a codepoint in the \"ASSOCIATION Type Field\" registry). (6) I'm not sure if a change to the document is needed here, but perhaps some discussion is in order: we say that a given LSP can belong to more than one PPAG, but only allow one PPAG TLV per [some context that remains unclear; see (5)].\u00a0 I don't have a good handle for whether these two requirements are potentially in conflict: that is, whether a single PPAG TLV would have to specify the flags that apply for both PPAGs that a given LSP is a member of, or if the containing objects serve to scope the PPAG TLV flags' interpretation. (7) Do the Protection Type fields of the PPAG TLV in the various LSPs that are members of the same PPAG need to match, in the same way that the source/destination/tunnel-ID do?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-06-08 06:55:40-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-11 12:07:23-07:00",
    "text": "* Section 3.2.1. \u00a0 The option length seems to be wrong here. This will make the parser parse incorrectly onto a following option or worse. I think this MUST be set to 10 instead of 16 (Or some field is missing from the description of the option) \u00a0  8-bit unsigned integer. Length of the option, in octets, excluding \u00a0  the Option Type and Option Length fields. This field MUST be set to \u00a0  16. * Section 3.2.1. \u00a0 The option does not seem to state an alignment requirement, but I think one is required to properly align the multi-byte PSN and Delta fields. Can you please specify one. * Section 5 The IANA considerations section needs to be more specific as you are requesting a specific type of option. e.g. This draft requests an Destination Option Type assignment with \u00a0  the act bits set to 00 and the chg bit set to 0 from the ...",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-05-05 08:28:36-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-08 10:01:17-07:00",
    "text": "The document says that packet sequence number are optional (\"measurements based on optional sequence numbers and timing may be embedded in each packet\"), but doesn't say what should be put in the PSNTP field if I'm not using them. It also doesn't say what I should put in the PSNLR field if I haven't received any PDM packets (the exmaple just has a dash). This means that I cannot create an interoperable implementation from this document alone.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-01-22 19:14:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-01-22 19:13:50-08:00",
    "text": "Hi, thanks for the readable approach to this. I like the plain English approach to the security considerations, in particular. But I do have some comments, including one I think needs to be resolved before progressing the draft: 1) I was surprised not to see a discussion of the \"never-meet\" problem. That is, what happens if a provider and a consumer never connect with the controller at the same time. Is the controller expected to store-and-forward items submitted to a topic prior to when the consumer connects? IIRC (and I apologize that I did not have time to refresh my memory on the referenced XEPs), that sort of behavior is optional under XEP-0060. Is it required for this use case? Is support for delayed delivery (xep-0203) or something similar required? Or perhaps platforms are expected to keep long-lived connections? 2) The security considerations suggest that the use of TLS mitigates\u00a0 all of the \"network attacks\". However, the potential or eavesdropping or data modification are only mentioned in terms of such \"network attacks\". It is also possible for the controller (aka XMPP server) to do those things unless some sort of e2e protection is used. This is not discussed in the sections about how the controller is trusted, nor is it discussed in the countermeasures sections. There is a mention of e2e protection in the privacy considerations, but I think that really needs treatment under the security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-25 06:40:02-07:00",
    "end_reason": "position_updated",
    "start": "2019-01-22 19:14:20-08:00",
    "text": "Hi, thanks for the readable approach to this. I like the plain English approach to the security considerations, in particular. But I do have some comments, including a couple that I think needs to be resolved before progressing the draft: 1) I was surprised not to see a discussion of the \"never-meet\" problem. That is, what happens if a provider and a consumer never connect with the controller at the same time. Is the controller expected to store-and-forward items submitted to a topic prior to when the consumer connects? IIRC (and I apologize that I did not have time to refresh my memory on the referenced XEPs), that sort of behavior is optional under XEP-0060. Is it required for this use case? Is support for delayed delivery (xep-0203) or something similar required? Or perhaps platforms are expected to keep long-lived connections? 2) The security considerations suggest that the use of TLS mitigates\u00a0 all of the \"network attacks\". However, the potential or eavesdropping or data modification are only mentioned in terms of such \"network attacks\". It is also possible for the controller (aka XMPP server) to do those things unless some sort of e2e protection is used. This is not discussed in the sections about how the controller is trusted, nor is it discussed in the countermeasures sections. There is a mention of e2e protection in the privacy considerations, but I think that really needs treatment under the security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-25 14:40:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-01-23 19:59:16-08:00",
    "text": "In the vein of Alissa's comments, I think this document does not adequately present the normative requirements for an implementation of the \"XMPP Grid\".\u00a0 As far as I can tell, these requirements are just relating to the communications security measures used to protect XMPP traffic, per Section 8.3.\u00a0 (Adhering to the MTI and MTN requirements of  RFC 6120  does not seem like a new requirement.)\u00a0 The main bulk of the document consists of examples that show how to use standard XMPP functionality to discover pubsub streams that convey data (types) that are of relevance for the types of behavior that MILE is interested in (e.g., security incident reporting and discovery), with inline mention of which XMPP features are used to negotiate and discover the streams in question.\u00a0 (Several of my comments are related to this Discuss point.) I also think this document does not adequately justify restricting to just the EXTERNAL and SCRAM families of SASL mechanisms; there are other mechanisms in use that provide equivalent or better security properties, and this sort of unjustified restriction is detrimental to the evolution of the Internet. The current requirements on SASL mechanisms also seem inconsistent with the claims in the threat model that the controller can obtain credentials to allow impersonation of platforms;  RFC 5802  (SCRAM) is quite explicit that \"The server does not gain the ability to impersonate the client to other servers\", and my understanding is that usage of EXTERNAL is generally not susceptible to this threat.\u00a0 (A bit more discussion in the COMMENT section.) The secdir reviewer rightly points out that this document does not discuss the implications of (non-) use of XMPP pubsub message persistence, which affect either availability of historic data or the privacy/security requirements properties of the controller and the system as a whole. (This relates to Ben's discuss point (1).) The secdir review also notes that the full implications of the participants' access to plaintext data are not covered.\u00a0 (This also relates  to Ben's discuss point (2).) Some of them are covered by existing text, e.g., the trust model's instistence that the platforms preserve the confidentiality of sensitive data, but others are not.\u00a0 (I attempt to note these cases in the COMMENT section.)  Section 6 notes that \"Depending on security requirements, the Provider might need to request a non-default configuration for the node; see [XEP-0060] for detailed examples.\" I think you need to either list out some of the examples or give a section reference from XEP-0060; the obvious places about creating or configuring a node don't seem to have this sort of discussion of security requirements and implications.\u00a0 The secdir reviewer's note about an example that demonstrates the recommended configuration is quite apt as well.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-26 05:20:12-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-25 14:40:26-07:00",
    "text": "Thank you for updating to describe this document as essentially an  RFC206 -style applicability statement; that helps a lot to frame what it is intending to deliver, and the other updates are improvements as well. That said, I think a couple of my DISCUSS\u00a0 points remain applicable: Section 8.2.3 still has text about how an XMPP Grid Controller could obtain XMPP-Grid Platform credentials and impersonate the XMPP Grid Platform even after the breach of the XMPP Grid Controller is repaired.\u00a0 The current MTI SASL mechanisms\u00a0 do not give the controller that ability, and it's only bad mechanisms like PLAIN that involve sending cleartext passwords/bearer tokens to the server that give an attacker that compromises the controller this ability.\u00a0 I think we need to clarify that this depends on the SASL mechanism used, and that the MTI mechanisms are not vulnerable to this attack.\u00a0 Suggested change: OLD: \u00a0  o\u00a0 Obtain and cache XMPP-Grid Platform credentials so they can be \u00a0 \u00a0 \u00a0 used to impersonate XMPP-Grid Platforms even after a breach of the \u00a0 \u00a0 \u00a0 XMPP-Grid Controller is repaired NEW: \u00a0  o\u00a0 Obtain and cache XMPP-Grid Platform credentials so they can be \u00a0 \u00a0 \u00a0 used to impersonate XMPP-Grid Platforms even after a breach of the \u00a0 \u00a0 \u00a0 XMPP-Grid Controller is repaired.\u00a0 Some SASL mechanisms (including \u00a0 \u00a0 \u00a0 the mandatory-to-implement SCRAM and EXTERNAL with TLS mutual \u00a0 \u00a0 \u00a0 certificate-based authentication) do not admit this class of attack, but \u00a0 \u00a0 \u00a0 others (such as PLAIN) are susceptible. The secdir review notes that the full implications of the participants' access to plaintext data are not covered.\u00a0 (This also relates  to Ben's discuss point (2).) Some of them are covered by existing text, e.g., the trust model's instistence that the platforms preserve the confidentiality of sensitive data, but others are not.\u00a0 I repeat here the portions of the COMMENT section that seem relevant: Section 8.1.3 The controller is also trusted to preserve the integrity (and confidentiality against unauthorized parties) of the data flowing through it. Section 8.2.2 The authorized platform could advertise data that is incorrect with the intent to lead to incorrect actions by the recipients, without needing to exploit vulnerabilities in other systems or compromising them. Suggested additions: Section 8.1.3: \u00a0  o Preserve the integrity (and confidentiality against unauthorized parties) \u00a0 \u00a0  of the data flowing through it. Section 8.2.2 \u00a0  Advertise false data that leads to incorrect (e.g., potentially attacker-controlled \u00a0  or -induced) behavior of XMPP-Grid Platforms, by virtue of applying correct procdeures \u00a0  to the falsified input.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-20 14:35:11-07:00",
    "end_reason": "position_updated",
    "start": "2019-01-24 05:48:27-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4730 I have marked a number of places where I do not consider this fully specified. DETAIL S 4. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Request Topic Creation\u00a0 | >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | (XEP-0060)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |<------------------------| >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Topic Creation Success\u00a0 | >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | (XEP-0060)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |------------------------>| Why Isn't XEP-0060 a normative reference? S 5. >\u00a0 \u00a0 \u00a0  >\u00a0   >\u00a0 \u00a0 \u00a0 The Broker responds with the \"disco#info\" description, which SHOULD >\u00a0 \u00a0 \u00a0 include an XMPP Data Form [XEP-0004] including a 'pubsub#type' field >\u00a0 \u00a0 \u00a0 that specifies the supported namespace (in this example, the IODEF >\u00a0 \u00a0 \u00a0 namespace defined in [ RFC7970 ]): This seems underspecified.\u00a0 What does the consumer look at to \"determine the exact nature of each topic\"? This text implies it's the 'pubsub#type' but doesn't quite say so. I am imagining changing this SHOULD to a MUST and then stating how the consumer behaves. S 8.3.1. >\u00a0 \u00a0 \u00a0 mechanism [ RFC4422 ] or using the SASL SCRAM mechanism (with the >\u00a0 \u00a0 \u00a0 SCRAM-SHA-256-PLUS variant being preferred over the SCRAM-SHA-256 >\u00a0 \u00a0 \u00a0 variant and SHA-256 variants [ RFC7677 ] being preferred over SHA-1 >\u00a0 \u00a0 \u00a0 varients [ RFC5802 ]).\u00a0 XMPP-Grid Platforms and XMPP-Grid Controllers >\u00a0 \u00a0 \u00a0 using mutual certificate-based authentication SHOULD each verify the >\u00a0 \u00a0 \u00a0 revocation status of the other party's certificate.\u00a0 All XMPP-Grid I am having trouble reading these two sentences together. Is the implication that I must use SCRAM and may also use mutual certificate auth?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-02 04:11:11-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-03-01 05:15:19-08:00",
    "text": "I have two things I'd like to chat about. Hopefully neither will take too much time... (1) section 1: \"For example, the presentations made by invited speakers at IETF plenary sessions to discuss advances in Internet technology generally, or to describe their existing products or technologies, are not Contributions.\" For saag presentations, (that are also sometimes invited), we (sec ADs) have tended to consider those as contributions, in the sense that we've asked presenters to be specific about IPR and to make IPR declarations if needed. I think the example in the document is a bad one, don't recall it being discussed (though it may have been on the IPR list) and would prefer we not try to make a distinction between some technical presentations and other technical presentations at IETF meetings.\u00a0 I'd say deleting the sentence is a good enough change. If not, then I'd like to understand how this affects invited presentations in area meetings and other meetings (e.g. RGs) and what is expected of folks chairing such or inviting the invitees. (2) 5.5: We've had two recent cases of WGs that were DoS'd by a declaration that said \"will add license terms later\" but where the declaration was never updated and the IPR holder went radio-silent. It was the same IPR holder in both cases. The entity in question has employees who participate frequently and have for an extended period (so this is not a \"new\" entity by any means). I would like if we could say that that's bad form, but can we? If so, how? And would we need to re-do LC for such an addition?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-02 07:25:41-08:00",
    "end_reason": "position_updated",
    "start": "2017-03-02 04:11:11-08:00",
    "text": "(moving discuss-point#2 to a comment, I accept we can't get  that substantively addressed at this point, discussion is  ongoing about point#1, so I've left that as-is. there are no other changes) (1) section 1: \"For example, the presentations made by invited speakers at IETF plenary sessions to discuss advances in Internet technology generally, or to describe their existing products or technologies, are not Contributions.\" For saag presentations, (that are also sometimes invited), we (sec ADs) have tended to consider those as contributions, in the sense that we've asked presenters to be specific about IPR and to make IPR declarations if needed. I think the example in the document is a bad one, don't recall it being discussed (though it may have been on the IPR list) and would prefer we not try to make a distinction between some technical presentations and other technical presentations at IETF meetings.\u00a0 I'd say deleting the sentence is a good enough change. If not, then I'd like to understand how this affects invited presentations in area meetings and other meetings (e.g. RGs) and what is expected of folks chairing such or inviting the invitees.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-10-01 07:40:16-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-30 13:32:02-07:00",
    "text": "I expect the following is just a matter of word smithing or my own comprehension, in which case I can quickly convert to a yes. I am concerned about some text that repeats several times in section 5 for different responsible bodies/persons: \u00a0 \u00a0  \"the Recall Committee is expected to \u00a0 \u00a0 \u00a0 understand that their investigation as described in [ RFC7437 ] is \u00a0 \u00a0 \u00a0 not to re-evaluate the events of the harassment, and that they are \u00a0 \u00a0 \u00a0 not qualified in handling issues of harassment.\" That can be construed to say that the responsible body cannot disagree with the recommendations of the ombudsteam. How can the body disagree without evaluating things? I don't think that is the intent. If the point is that they are not to re-investigate the facts of the matter, but may make their own decisions about the recommendations of the ombudsteam, I am fine with it--I'm just not sure the text supports that. (For the record, I do not object to the related expectation that responsible bodies take ombudsteam recommendations seriously.) Along those lines, there is a several-times repeated expectation that responsible bodies/persons will follow the recommendations of the ombudsteam. I would prefer not to presume the actions of such bodies. This could be taken as an expectation to rubber-stamp things.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-11-04 05:03:03-08:00",
    "end_reason": "position_updated",
    "start": "2015-09-30 03:27:35-07:00",
    "text": "I reviewed the version 9. One point I want to discuss before moving back to a YES. - \u00a0 \u00a0 \u00a0 It \u00a0 \u00a0 \u00a0 is not the intent that the AD re-evaluate the events, and the AD \u00a0 \u00a0 \u00a0 is expected to understand that they are not qualified in handling \u00a0 \u00a0 \u00a0 issues of harassment and they must preserve confidentiality.\u00a0 The \u00a0 \u00a0 \u00a0 AD is strongly encouraged to discuss with the Ombudsteam in the \u00a0 \u00a0 \u00a0 event that the AD feels removal from position is not the correct \u00a0 \u00a0 \u00a0 remedy. Btw, a nit: they -> he It seems that the two sentences contradict each other. \"Strongly encouraged to discuss with the Ombudsteam in the event that the AD feels removal from position is not the correct remedy \" but, at the same time, \"is not the intent that the AD re-evaluate the events\" If the Ombudsteam is really in charge, if \"The Ombudsteam is expected to strive for confidentiality\" (so basically the AD shouldn't know all the details),\u00a0 and if the \"AD should not re-evaluate the events\", should we remove this sentence? \u00a0 \u00a0 \u00a0 \"The AD is strongly encouraged to discuss with the Ombudsteam in the \u00a0 \u00a0 \u00a0 event that the AD feels removal from position is not the correct \u00a0 \u00a0 \u00a0 remedy.\" Same remark for: \u00a0 \u00a0 \u00a0 It is not the intent \u00a0 \u00a0 \u00a0 that the AD or WG chairs re-evaluate the events, and the AD and WG \u00a0 \u00a0 \u00a0 chairs are expected to understand that they are not qualified in \u00a0 \u00a0 \u00a0 handling issues of harassment and that they must preserve \u00a0 \u00a0 \u00a0 confidentiality.\u00a0 The AD is strongly encouraged to discuss with \u00a0 \u00a0 \u00a0 the Ombudsteam in the event that they or the WG chairs feel \u00a0 \u00a0 \u00a0 removal from position is not the correct remedy. - There is also an issue with the second part of this sentence that contradicts \"is not the intent that the AD re-evaluate the events\" : \u00a0 \u00a0 \u00a0 In the event that an AD declines to follow the recommendation of \u00a0 \u00a0 \u00a0 the Ombudsteam as described in the previous bullets, and if the AD \u00a0 \u00a0 \u00a0 fails to convince the Ombudsteam of the reasons for this",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2015-03-05 10:28:56-08:00",
    "end_reason": "position_updated",
    "start": "2015-02-17 12:28:45-08:00",
    "text": "dditional round of discussion needed with the legal review team.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-09-30 09:59:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-29 16:13:57-07:00",
    "text": "I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this (which was -05). I'm unsure if I'll be moving from discuss back to yes or to abstain.\u00a0 Other than as noted, my comments (and all discuss points) are only on text changed since -05. (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated. I think you need to strike the text about \"creating an environment that would be intimidating.\" (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. (3) 5.1: The recall ctte can't re-evaluate? That is plain odd.\u00a0 Once matters are public to that extent I think that forces a re-evaluation for the sake of fairness.\u00a0 In cases where e.g.\u00a0 the IESG can quietly ask a chair to step aside that's not an issue, but it certainly would be with a public recall. A claim that the recall ctte aren't qualified is not enough to justify a potentially unfair public process like that IMO. (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.\u00a0 \"make sure\" and \"ensure\" in the 2nd para are also overstated.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 03:50:37-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-30 09:59:30-07:00",
    "text": "(Minor addition to discuss#2 below, otherwise no change) I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this (which was -05). I'm unsure if I'll be moving from discuss back to yes or to abstain.\u00a0 Other than as noted, my comments (and all discuss points) are only on text changed since -05. (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated. I think you need to strike the text about \"creating an environment that would be intimidating.\"  In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" If we got that result, I'd be fine with that rationale for doing the right thing:-) (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. (3) 5.1: The recall ctte can't re-evaluate? That is plain odd.\u00a0 Once matters are public to that extent I think that forces a re-evaluation for the sake of fairness.\u00a0 In cases where e.g.\u00a0 the IESG can quietly ask a chair to step aside that's not an issue, but it certainly would be with a public recall. A claim that the recall ctte aren't qualified is not enough to justify a potentially unfair public process like that IMO. (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.\u00a0 \"make sure\" and \"ensure\" in the 2nd para are also overstated.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 03:51:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-09 03:50:37-08:00",
    "text": "(Minor addition to discuss#2 below, otherwise no change) I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this (which was -05). I'm unsure if I'll be moving from discuss back to yes or to abstain.\u00a0 Other than as noted, my comments (and all discuss points) are only on text changed since -05. (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated. I think you need to strike the text about \"creating an environment that would be intimidating.\"  IM with Pete suggested this OLD/NEW which'd work for me if the authors are ok with it: OLD: \u00a0 This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or of creating an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive in such a situation. NEW: \u00a0  This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or harassment which creates an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive. In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" If we got that result, I'd be fine with that rationale for doing the right thing:-) (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. (3) 5.1: The recall ctte can't re-evaluate? That is plain odd.\u00a0 Once matters are public to that extent I think that forces a re-evaluation for the sake of fairness.\u00a0 In cases where e.g.\u00a0 the IESG can quietly ask a chair to step aside that's not an issue, but it certainly would be with a public recall. A claim that the recall ctte aren't qualified is not enough to justify a potentially unfair public process like that IMO. (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.\u00a0 \"make sure\" and \"ensure\" in the 2nd para are also overstated.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 04:04:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-09 03:51:04-08:00",
    "text": "(Minor addition to discuss#2 below, otherwise no change) I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this (which was -05). I'm unsure if I'll be moving from discuss back to yes or to abstain.\u00a0 Other than as noted, my comments (and all discuss points) are only on text changed since -05. (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated. I think you need to strike the text about \"creating an environment that would be intimidating.\"  IM with Pete suggested this OLD/NEW which'd work for me if the authors are ok with it: OLD: \u00a0 This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or of creating an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive in such a situation. NEW: \u00a0  This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or harassment which creates an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive. (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" If we got that result, I'd be fine with that rationale for doing the right thing:-) (3) 5.1: The recall ctte can't re-evaluate? That is plain odd.\u00a0 Once matters are public to that extent I think that forces a re-evaluation for the sake of fairness.\u00a0 In cases where e.g.\u00a0 the IESG can quietly ask a chair to step aside that's not an issue, but it certainly would be with a public recall. A claim that the recall ctte aren't qualified is not enough to justify a potentially unfair public process like that IMO. (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.\u00a0 \"make sure\" and \"ensure\" in the 2nd para are also overstated.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 04:20:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-09 04:04:40-08:00",
    "text": "(Minor addition to discuss#2 below, otherwise no change) I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this (which was -05). I'm unsure if I'll be moving from discuss back to yes or to abstain.\u00a0 Other than as noted, my comments (and all discuss points) are only on text changed since -05. (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated. I think you need to strike the text about \"creating an environment that would be intimidating.\"  IM with Pete suggested this OLD/NEW which'd work for me if the authors are ok with it: OLD: \u00a0 This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or of creating an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive in such a situation. NEW: \u00a0  This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or harassment which creates an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive. (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" If we got that result, I'd be fine with that rationale for doing the right thing:-) So this one is now for Jari to ask Laywer: given the above interpretation, wouldn't it be better to remove the sentence? (3) cleared (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. A suggested OLD/NEW: OLD: \u00a0  It should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. NEW \u00a0 \u00a0 As the Ombudsteam function is seen to be improving the IETF  \u00a0  and gains the respect of participants over time,  \u00a0  it should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.\u00a0 \"make sure\" and \"ensure\" in the 2nd para are also overstated.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 04:30:18-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-09 04:20:40-08:00",
    "text": "(Minor addition to discuss#2 below, otherwise no change) I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this (which was -05). I'm unsure if I'll be moving from discuss back to yes or to abstain.\u00a0 Other than as noted, my comments (and all discuss points) are only on text changed since -05. (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated. I think you need to strike the text about \"creating an environment that would be intimidating.\"  IM with Pete suggested this OLD/NEW which'd work for me if the authors are ok with it: OLD: \u00a0 This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or of creating an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive in such a situation. NEW: \u00a0  This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or harassment which creates an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive. (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" If we got that result, I'd be fine with that rationale for doing the right thing:-) So this one is now for Jari to ask Lawyer: given the above interpretation, wouldn't it be better to remove the sentence? (3) cleared (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. A suggested OLD/NEW: OLD: \u00a0  It should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. NEW \u00a0 \u00a0 As the Ombudsteam function is seen to be improving the IETF  \u00a0  and gains the respect of participants over time,  \u00a0  it should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.  The following change would however fix this: OLD is to prevent all NEW is to deal with and discourage",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 04:33:53-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-09 04:30:18-08:00",
    "text": "I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this a while back for -05.  I've chatted (via IM) with Pete about the -10 version and I cleared point 3, we agreed that point 2 is for Jari to go and check with the lawyers, (or to decide to not do that) and we developed a set of OLD/NEW changes for points 1, 4 and 5. My plan is to move to a yes if all of those go my way, but to an abstain if not (with the relevant remaining discuss points  turned into comments).  (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated.  IM with Pete suggested this OLD/NEW which'd work for me if the authors are ok with it: OLD: \u00a0 This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or of creating an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive in such a situation. NEW: \u00a0  This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or harassment which creates an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive. (2) section 2, last para: I do not want the IETF to be subject to the laws of all countries. This seems to do that. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those. This sentence should go, or should say something else. Put another way: I read this as saying that we're asserting that the IETF has consensus on every applicable law everywhere. I do not think such an IETF consensus exists. In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" So this one is now for Jari to ask Lawyer: given the above interpretation, wouldn't it be better to remove the sentence since it could do harm and not match IETF consensus if included? (3) cleared (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. A suggested OLD/NEW: OLD: \u00a0  It should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. NEW \u00a0 \u00a0 As the Ombudsteam function is seen to be improving the IETF  \u00a0  and gains the respect of participants over time,  \u00a0  it should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.  The following change would however fix this: OLD is to prevent all NEW is to deal with and discourage",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-10 05:06:58-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-09 04:33:53-08:00",
    "text": "I'm sorry to move from a yes ballot to a discuss on this one but I think the text has disimproved and some problematic changes have been made since I last reviewed this a while back for -05.  I've chatted (via IM) with Pete about the -10 version and I cleared point 3, we agreed that point 2 is for Jari to go and check with the lawyers, (or to decide to not do that) and we developed a set of OLD/NEW changes for points 1, 4 and 5. My plan is to move to a yes if all of those go my way, but to an abstain if not (with the relevant remaining discuss points  turned into comments).  (1) section 2: calling out creating an environment that is intimidating as a form of harassment goes too far I think. It is in the nature of the IETF to be intimidating to non engineers or to less qualified engineers. Feeling intimidated because one is ignorant and where nobody is trying to do harm is something that is ok. Trying to intimidate is not ok, attempting to intimidate because someone is young, old, etc. is not ok, but that was already stated.  IM with Pete suggested this OLD/NEW which'd work for me if the authors are ok with it: OLD: \u00a0 This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or of creating an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive in such a situation. NEW: \u00a0  This document concerns itself with harassment that has the purpose or \u00a0  effect of unreasonably interfering with an individual's participation \u00a0  in IETF activities or harassment which creates an environment within the IETF that \u00a0  would be intimidating, hostile, or offensive. (2) section 2, last para: I do not want the IETF to be subject to all the laws of all countries all at once.  This seems to assert that and that there is IETF consensus for that assertion. I don't believe either is true and believe this sentence should be deleted. There are some possibly relevant laws in some countries that are such that the IETF can't reasonably ask me to agree with those.\u00a0 Put another way: I read this as saying that we're asserting that at any given time the IETF will have consensus on the  relevance of every applicable law everywhere. I do not think  such an IETF consensus exists or can exist. In an IM chat with Pete, we ended up figuring expressing this point like this might help \"We don\u2019t want the ombuds to have  to figure out which of all possible laws in the world are applicable,  and this sentence doesn\u2019t add anything really, since the ombuds  get to decide how to handle any complaint, whether it falls  under any definition or not. So let\u2019s just strike the sentence.\" So this one is now for Jari to ask Lawyer: given the above interpretation, wouldn't it be better to remove the sentence since it could do harm and not match IETF consensus if included? (3) cleared (4) 5.1, 2nd last para: respect has to be earned it's not ok to  just say \"ombudsteam => correct\" for such a new construct. I  think this kind of text might be enough to be problematic  if/when someone goes to court and claims these are unfair  procedures. A suggested OLD/NEW: OLD: \u00a0  It should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. NEW \u00a0 \u00a0 As the Ombudsteam function is seen to be improving the IETF  \u00a0  and gains the respect of participants over time,  \u00a0  it should be enough that the Ombudsteam explains \u00a0  the severity of the situation, that they have considered other lesser\u00a0 \u00a0  \u00a0  remedies, and that they deem the recommended remedy to be\u00a0 \u00a0  \u00a0  appropriate. (5) 5.2: purpose \"is to prevent all\" - that's nonsense, there is no point in setting an impossible purpose.\u00a0 The purpose surely is to minimise harassment and the impact if harassment has occurred? If this BCP makes such impossible claims, and if someone does ever end up in court, I would expect that this BCP could not be defended. That seems like a bad plan to me.  The following change would however fix this: OLD is to prevent all NEW is to deal with and discourage",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-09-08 06:42:02-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-07 10:27:16-07:00",
    "text": "# GEN AD review of  draft-ietf-cose-countersign-09 CC @larseggert Thanks to Elwyn Davies for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/jrTPQpNSafEhkpyMYn3r250_ghM ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS for IANA, so we can determine next steps during the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-09-20 12:58:25-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-07 19:14:53-07:00",
    "text": "\u00a0 \u00a0 \u00a0 \u00a0 gem install cbor-diag I am concerned about adding install commands for \"programs from the internet\" within an RFC. If the rubygem for some reason becomes malicious, we cannot pull it from the RFC (even if we pull it from the datatracker link, it would still live on in copies of the RFC elsewhere and malicious people could point to copies of those original RFCs to point people to downlod the malicious rubygem. I would be okay with an  iet.org  download location of a ruby gem.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-06-16 07:41:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 23:40:22-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-httpbis-binary-message-05 cc @evyncke Thank you for the work put into this document. And I really mean it even when balloting a blocking DISCUSS because it will be useful. BTW, I sincerely hate to be process-focused and I hope to stand corrected quickly. Please find below one blocking DISCUSS points, which may be resolved during the IESG formal telechat. Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Does it fit HTTPBIS charter ? While I think that this document is useful (even if I have doubts about standards track rather than informational as for the expired PCAP I-D in OPSAWG), I fail to see how this document fits the HTTPBIS charter. The only potential way is at the end of the charter: ``` # Other HTTP-Related Work The Working Group may define extensions and other documents related to HTTP as work items, provided that: * They are generic; i.e., not specific to one application using HTTP. Note that Web browsing by definition is a generic use. * The Working Group Chairs judge that there is consensus to take on the item and believe that it will not interfere with the work described above, and * The Area Director approves the addition and add corresponding milestones. ``` But I do not see any related milestone to this document. Moving this document to AD sponsored is probably the right way. ## Notes This review is in the [\"IETF Comments\" Markdown format][ICMF], You can use the [`ietf-comments` tool][ICT] to automatically convert this review into individual GitHub issues.  [ICMF]:  https://github.com/mnot/ietf-comments/blob/main/format.md [ICT]:  https://github.com/mnot/ietf-comments",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-11 08:05:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-10 11:21:08-08:00",
    "text": "Hello, Thanks for your work on this draft.\u00a0 I'm a little confused with some text in the draft and have a few questions. 1. The introductions says,  \"This architectural framework identifies a set of conceptual datastores but \u00a0  it does not mandate that all network management protocols expose all \u00a0  these conceptual datastores.\u00a0 This architecture is agnostic with \u00a0  regard to the encoding used by network management protocols.\" As such, the data stores could be exposed for some implementations, using whatever network management protocol (likely NetCONF or RESTCONF).\u00a0 If this is the case, why doesn't at least some of the security considerations template apply for at least secure transport? 2. Section 5.3.4 - Is there any integrity protection on the origin information?\u00a0 If not, can it be added or is there a good reason why it\u2019s not possible?\u00a0 I realize these are conceptual models that may or may not be exposed, but if exposed and used, wouldn\u2019t some integrity protection on this be helpful? Thanks in advance!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-08 22:05:12-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-04 21:43:57-07:00",
    "text": "My understanding is that this point is essentially overtaken by events, as a similar concern was raised already by Martin D, John, and Roman, and there is a commitment to update the text already made.\u00a0 I'm putting it in at the Discuss level to make sure that I follow-up on the revised text when it appears. But, for concreteness: the text in Sections 8.4, 10.4, and 11 treat cryptographic mTLS, TSIG, and SIG(0) authentication as providing an equivalent level of protection to the (non-cryptographic) IP ACL.\u00a0 My understanding is that IETF consensus is to prefer cryptographic mechanisms for authentication and authorization, when available. Relatedly, the text in Section 8.4 says that TSIG/SIG(0) are \"not sufficient to authenticate the client or server\", which is technically true, but also seems misleading.\u00a0 In XFR scenarios it's not clear that specific identification (authentication) of the counterparty is necessary for secure operation, if authorization to receive/send the zone can be established without specific identification.\u00a0 My undersatnding is that, when combined with a strict TLS profile for server authentication and appropriate trust policy on TLS clients, TSIG and SIG(0) both serve to provide proof of authorization for the exchange even though they only provide authentication in the form of group membership (the relevant key material is typically available to multiple machines).\u00a0 As such, don't they provide strong enough cryptographic protection (and end-to-end, no less!) to be a superior authorization mechanism than an IP ACL?\u00a0 (Any resulting text changes may bleed into Sections 11 and 12 in addition to 8.4, per my COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-06-03 09:56:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-03 11:37:36-07:00",
    "text": "In further discussions it became clear that the authors do not intend for XoT traffic to use an ALPN code at all. I'm afraid this may be a misunderstanding of previous guidance from TLS that XoT did not need its own ALPN code, but could simply use the DoT ALPN since the messages are distinguishable on the wire. To not use an ALPN at all violates best TLS practice. The reasoning given in Appendix A, that this creates difficulty for proxies, doesn't make sense to me. We can talk about it in the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-09 08:54:14-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-02 16:08:33-08:00",
    "text": "Section 2 says that the \"DTLS certificate values\" are required to return no value when read, but this property seems to be intended for private data such as DTLS private key values, not the certificates themselves (which are public). While I appreciate that IPv6 is the current version of the internet protocol, I do see that 6126bis allows for Babel to run over both IPv6 and IPv4, yet this document in multiple places implicitly assumes that Babel runs over IPv6, to the exclusion of IPv4.\u00a0 Such a restriction from the core protocol spec should only be undertaken by an information model with clear reasoning and loud disclaimer. Similarly (as Roman notes), we are putting requirements on the key length for MAC keys (relative to the block size of the underlying hash function) that have were once present in  draft-ietf-babel-hmac  but have been removed as of draft-ietf-babel-hmac-10.\u00a0 I assume that the intent is not to impose additional restrictions compared to the protocol spec, thus we need to catch up to those changes. The description of the babel-mac-key-test and babel-cert-test operations need to be tightened up, as the secdir reviewer noted.\u00a0 (See COMMENT.) We seem to be using terminology from the Network Management Datastore Architecture without reference or otherwise introducing the concepts. This is a Discuss point because the only candidate reference I know of, RFC 8342 , is specific to YANG and data models, so it's applicability for use in an information model may be subject to discussion.\u00a0 (Hopefully this only reflects my ignorance and not a fundamental lack of datastore architecture for information models.)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2023-01-27 08:53:23-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-18 08:18:05-08:00",
    "text": "I am balloting DISCUSS because I believe that the expected actions resulting from this document are not specific enough: (1) \u00a77 reads: \u00a0  This document formally updates [ RFC3552 ] such that a vulnerability  \u00a0  assessment of transient numeric identifiers is performed when writing  \u00a0  the \"Security Considerations\" section of future RFCs. Is the assessment a requirement or a recommendation (when defining transient numeric identifiers)?\u00a0  The Abstract says that \"this document updates  RFC 3552 , requiring future RFCs to contain a vulnerability assessment of their transient numeric identifiers.\"\u00a0 The update itself doesn't result in a requirement. Please be explicit (SHOULD/MUST ?) in \u00a77. (2) The requirements of the assessment itself (\u00a75) can also be more explicit: [Line numbers from idnits.] 289\t5.\u00a0 Vulnerability Assessment Requirements for Transient Numeric 290\t\u00a0 \u00a0 Identifiers 292\t\u00a0  Protocol specifications that employ transient numeric identifiers 293\t\u00a0  SHOULD: (2a) The points to be covered in the assessment are only recommended and not required.\u00a0 When is it ok to not include any, or all, of the points mentioned?\u00a0 Why is this not a requirement?\u00a0 Are some parts optional? 295\t\u00a0  1.\u00a0 Clearly specify the interoperability requirements for the 296\t\u00a0 \u00a0 \u00a0  aforementioned transient numeric identifiers (e.g., required 297\t\u00a0 \u00a0 \u00a0  properties such as uniqueness, along with the failure severity if 298\t\u00a0 \u00a0 \u00a0  such properties are not met). (2b) \"Clearly specify the interoperability requirements...\"\u00a0 Clarity can be subjective.\u00a0 s/.../Specify the interoperability requirements... 300\t\u00a0  2.\u00a0 Provide a vulnerability assessment of the aforementioned 301\t\u00a0 \u00a0 \u00a0  identifiers. 303\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Note: Section 8 and Section 9 of 304\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ I-D.irtf-pearg-numeric-ids-generation ] provide a general 305\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 vulnerability assessment of transient numeric identifiers, 306\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 along with a vulnerability assessment of common algorithms for 307\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 generating transient numeric identifiers. (2c) Going back to (1), is this the only part that is intended to be performed as a result of the update to  rfc3552 ? (2d) What should be included in the vulnerability assessment?\u00a0 Given that this bullet talks about identifiers, are the considerations from \u00a78/I-D.irtf-pearg-numeric-ids-generation (correlation, leakage, fingerprinting, etc.) expected to be included? (2e) The reference to \u00a79 seems not to be needed at this point, or are you also expecting an assessment of the algorithm? 309\t\u00a0  3.\u00a0 Recommend an algorithm for generating the aforementioned 310\t\u00a0 \u00a0 \u00a0  transient numeric identifiers that mitigates the vulnerabilities 311\t\u00a0 \u00a0 \u00a0  identified in the previous step, such as those discussed in 312\t\u00a0 \u00a0 \u00a0  [ I-D.irtf-pearg-numeric-ids-generation ]. (2f) Is the expectation that this recommendation will result in a normative requirement, recommendation, or just an option? 314\t\u00a0  Note: 315\t\u00a0 \u00a0 \u00a0 As discussed in Section 1, use of cryptographic techniques for 316\t\u00a0 \u00a0 \u00a0 confidentiality and authentication might not eliminate all the 317\t\u00a0 \u00a0 \u00a0 issues associated with predictable transient numeric identifiers. 318\t\u00a0 \u00a0 \u00a0 Therefore, the advice from this section SHOULD still be applied 319\t\u00a0 \u00a0 \u00a0 for cases where cryptographic techniques are employed for 320\t\u00a0 \u00a0 \u00a0 confidentiality or authentication of the associated 321\t\u00a0 \u00a0 \u00a0 transientnumeric identifiers. (2g) \"SHOULD still be applied\" Given that \u00a71 doesn't exclude protocols using cryptographic techniques for confidentiality and authentication from the considerations in this document, the \"SHOULD\" above reinforces that and indicates a fact, vs a normative recommendation.\u00a0  s/SHOULD/should [nit] s/transientnumeric/transient numeric",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-01-30 00:48:09-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-16 05:06:25-08:00",
    "text": "# GEN AD review of  draft-gont-numeric-ids-sec-considerations-10 CC @larseggert Thanks to Gyan S. Mishra for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/sQeXJs6ZU4ga80XkFYFCGKo_u0w ). ## Discuss ### Paragraph 0 ``` \u00a0 Network Working Group\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 F. Gont \u00a0 Internet-Draft\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SI6 Networks \u00a0 Updates: 3552 (if approved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 I. Arce ``` RFC3552  is a BCP on the IAB stream that was approved by the IESG. Can it be updated by a document on the IETF stream without the update also being explicitly approved by the IAB? ### \"Abstract\", paragraph 1 ``` \u00a0 \u00a0  Poor selection of transient numerical identifiers in protocols such \u00a0 \u00a0  as the TCP/IP suite has historically led to a number of attacks on \u00a0 \u00a0  implementations, ranging from Denial of Service (DoS) to data \u00a0 \u00a0  injection and information leakage that can be exploited by pervasive \u00a0 \u00a0  monitoring.\u00a0 To prevent such flaws in future protocols and \u00a0 \u00a0  implementations, this document updates  RFC 3552 , requiring future \u00a0 \u00a0  RFCs to contain a vulnerability assessment of their transient numeric \u00a0 \u00a0  identifiers. ``` Does this document intend to make requirements for all numeric identifiers used by a protocol, or only those that are observable in plaintext? All motivational text is AFAICT based on flaws that arose because such identifiers were transmitted in plaintext, so does the document intend to limit its guidance to those (and not to other identifiers that are for example always transmitted in encrypted form)? If the document does intend to give guidance on identifiers that are transmitted in encrypted form, it would be good to give some examples why that is necessary. In any event, please be more precise about the applicability of the guidance given here.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-05-30 12:27:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-26 08:01:47-07:00",
    "text": "\u2014 Section 4 \u2014 \u00a0  If appropriate non-ACME identifiers are not present in the \u00a0  ACME Validation Methods IANA registry, the CA MUST use identifiers \u00a0  beginning with the string \"ca-\", which are defined to have CA- \u00a0  specific meaning. Was the working group aware of  BCP 178  ( RFC 6648 ), and did they consider the \u201cca-\u201c prefix in that context?\u00a0 If so, how does the working group propose to avoid the problems outlined by  BCP 178 ? \u2014 Section 5.4 \u2014 \u00a0  CAs MUST satisfy this requirement by using URIs which include an \u00a0  authority: \u00a0  \" https://a.example.com/account/1234 \" First (this is not the DISCUSS part), readers who are not extremely familiar with how URIs are constructed \u2014 and given that \u201cauthority\u201d is a normal English word with a meaning outside the URI world \u2014 might not really understand what you mean here.\u00a0 A reference will help, and I suggest it\u201d \u201c\u2026include an authority (see Section 3.2 of [ RFC3986 ])\u201d. Second (this is the DISCUSS part), does this mean that all CAs MUST use URIs that include an authority?\u00a0 Or does it only apply to those with the sort of situation you describe in this section?\u00a0 If the latter, it seems odd that you\u2019re prescribing, at MUST level, a particular solution, where there are certainly others (such as ensuring that the account numbers are unique in the first place). \u2014 Section 6 \u2014 I have no idea what you\u2019re trying to say here.\u00a0 This is a Proposed Standard, right?\u00a0 It defines two new parameters.\u00a0 Are you now trying to say that we have not really defined anything?\u00a0 I don\u2019t understand.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-18 19:09:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-27 16:26:56-07:00",
    "text": "I think we need to have some privacy considerations text about how this mechanism exposes ACME account URLs, which are otherwise intended to be unguessable, in the public DNS view.\u00a0 While ACME is generally intended to remain secure in the face of such information disclosure, it does have potential to enable some forms of correlation attacks, and could lead to DoS attempts specific to a given account or accounts.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-05-30 15:47:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 12:40:37-07:00",
    "text": "Firstly, thank you for writing this -- I do however have some concerns around Section \"5.6.\u00a0 Use with and without DNSSEC\" 1: \"Where a domain chooses to secure its nameservers using DNSSEC, the authenticity of its DNS data can be assured, providing that a given CA makes all DNS resolutions via an appropriate, trusted DNSSEC-validating resolver.\" A: DNSSEC does *not* secure nameservers, it secures the DNS data itself (think object security vs channel security) -- I'd suggest \"When a domain is signed using DNSSEC, the authenticity...\"  B: I'm confused what\"appropriate\" means in \"appropriate, trusted DNSSEC validating resolver\" -- if it is trusted I'd assume it is appropriate? Please explain. C: The way that a resolver signals to a client that it has performed validation (and that the answer validated) is to set a single bit (AD) in the response - this is obviously something which should not be relied upon for security sensitive stuff - I'd strongly suggest that i) there be some text around getting the responses from the resolver to the CA machine securely (e.g over DNS-over-TLS), or better yet ii) that the CA machine itself do the DNSSEC validation - there are many libraries / systems to make this easy, e.g Stubby, libunbound, etc.  2: \"A domain can use this property to protect itself from the threat posed by a global adversary capable of performing man-in-the-middle attacks, ...\" A: What is the purpose of \"global\" in \"global adversary\" -- I'm assuming it is trying to communicate something important here, but how is this different to a \"local\" adversary capable of performing man-in-the-middle attacks? 3: \" Use of the \"accounturi\" or \"validationmethods\" parameters does not confer additional security against an attacker capable of performing a man-in-the-middle attack against all validation attempts made by a given CA which is authorized by CAA where: \u00a0  1.\u00a0 A domain does not secure its nameservers using DNSSEC, or \u00a0  2.\u00a0 That CA does not perform CAA validation using a trusted DNSSEC-validating resolver. Moreover, use of the \"accounturi\" or \"validationmethods\" parameters does not mitigate against man-in-the-middle attacks against CAs which do not validate CAA records, or which do not do so using a trusted DNSSEC-validating resolver, ...\" Can this document simply say: \"When using this method, CA's MUST use a DNSSEC-validating resolver\"? -- it will a: make the protocol more secure and b: simplify a bunch of the document and c: isn't a large burden.  During the so-called \"DNSpionage\" incident, it seems that a specific CA was chosen because it didn't do DNSSEC validation (or, perhaps would try validate, but would still issue if DNSSEC validation failed) -- see:  https://mailman.nanog.org/pipermail/nanog/2019-March/099852.html",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-03-16 21:26:08-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-14 19:18:24-07:00",
    "text": "I expect to ballot \"yes\" for this, but I have one item that I think needs discussion first (as well as some non-blocking comments in the comment section.): The rule 18 \"out of band\" section says loss of control messages SHOULD NOT trigger the CB.\u00a0 But rule 1 said \"The CB MUST trigger if there is a failure of the \u00a0 \u00a0 \u00a0 \u00a0 communication path used for the control messages.\" These seem to be contradictory normative requirements.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2016-03-15 05:11:44-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-14 07:05:53-07:00",
    "text": "This is a \"let's talk about it\" DISCUSS (i.e., may not require any document changes) to make sure I understand what is being recommended... 1. Rules 12 and 13 in section 4 seem more pertinent to sender-based flows than to tunnels. Is it best current practice to terminate all tunnel traffic in the face of long-term congestion rather than attempt to terminate/regulate the worst offenders within the tunnel? If the circuit breaker capability is implemented within the tunnel ingress point (as is recommended), it would seem straightforward to penalize the flow(s) causing the congestion rather than all the flows. Or am I misinterpreting the rules 12 and 13? 2. Does the need for these types of circuit breakers imply that raw UDP (and UDP-Lite) is no longer sufficiently functional and that DCCP (or an equivalent) needs to be used? 3. If this BCP is expecting to influence the implementation of traffic sources and sinks, should there be some guidance on what should be used (e.g., ECN) prior to invoking circuit breaker logic? The text says numerous times that CBs are a last resort, but I don't see much in the way of what should be used prior to this last resort.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-09 16:27:30-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-23 17:03:20-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4892 DETAIL S 4.2. >\u00a0 \u00a0 \u00a0 When generating an encrypted message, sending UAs MUST follow the >\u00a0 \u00a0 \u00a0 conventions specified in [ RFC5751 ] for the application/pkcs7-mime >\u00a0 \u00a0 \u00a0 media type with smime-type=enveloped-data.\u00a0 When decrypting a >\u00a0 \u00a0 \u00a0 received message, receiving UAs MUST follow the conventions specified >\u00a0 \u00a0 \u00a0 in [ RFC5751 ] for the application/pkcs7-mime media type with smime- >\u00a0 \u00a0 \u00a0 type=enveloped-data. I don't think we should be recommending encryption without integrity at this point.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-14 08:35:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 14:29:29-07:00",
    "text": "I support Roman's Discuss point (1) (and basically cover the same as his (2) below). Let's have a discussion about (DTLS) identity. Section 2.1 says that we use mutual authentication and that implementations \"MUST support authenticating peers against a local store of credentials\"; also that \"if a node receives a new DTLS connection from a neighbour to whom it already has a connection, the node MUST NOT discard the older connection until it has completed the handshake of the new one and validated the identity of the peer\".\u00a0 But how does this authentication occur, and what constitutes the identity of the peer.\u00a0 We will frequently have (D)TLS consumers cite  RFC 6125  and say that (e.g.) DNS-ID or SRV-ID must match the name obtained in some fashion.\u00a0 But for Babel, we are authenticating routers -- router identity is usually in the form of just an IP address on a loopback interface!\u00a0 Are we expected to get certificates that certify IP addresses as identity, or use some sort of PSK or password-based TLS authentication?\u00a0 (The last two are not really compatible with the \"MUST send a CertificateRequest\", BTW.)\u00a0 Raw public keys?\u00a0 I think we can give a more clear picture of how to build a secure system. Relatedly, once DTLS authenticates an identity, what level of authorization checks are performed?\u00a0 Are we still in a single authorization domain, where any router that authenticates as being part of a given domain is implictily authorized to be a babel peer and convey any and all routing information? We should also give some guidance on ciphers and algorithms where we discuss the DTLS details ( BCP 195  is probably the safest bet here, even if it's a little in need of an update).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-14 07:54:21-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 05:40:29-07:00",
    "text": "Unfortunately I need to discuss the port request again.  First of all I would like to comment on the shepherd write-up which says: \"The document requires only the allocation of a port number for Babel over DTLS. Having such a second port for the secured version of a protocol is a fairly common practice. This is shown in the IANA Considerations section.\" This is not correct. Having a second port for the secured version of a protocol WAS common practice. However  RFC6335  say now \"The use of separate \u00a0  service name or port number assignments for secure and insecure \u00a0  variants of the same service is to be avoided in order to discourage \u00a0  the deployment of insecure services.\" Anyway, in this case I understand that a different port is desired because unencrypted HELLO messages are still received over the default babel port. However, it is not clear to me why a fixed/default port is needed. The neighbour needs to be discovered in some why, no matter what, before a DTLS connection can be established and this discovery procedure could indicate a dynamic port number that the peer is listening on for babel over DTLS. E.g. the multicast HELLO could have a new TLV with this port information. Please clarify why this option is not suitable! Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-27 10:57:45-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 12:25:53-07:00",
    "text": "(1) Section 1. These are different than the ones listed in Section 6 of  draft-ietf-babel-rfc6126bis  and Section 1 of draft-ietf-babel-dtls.\u00a0 As DTLS and HMAC are mitigations for attacks in  draft-ietf-babel-rfc6126bis , they really should be harmonized. (2) Section 2.1.\u00a0 Per \u201cImplementations MUST support authenticating peers against a local store of credentials\u201d, what does that credentialing look like?\u00a0 Is it certificates, PSK, etc?\u00a0 What validation procedure is being used for this authentication?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-09 15:59:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-07 21:46:51-07:00",
    "text": "This document requires the use of per-delegation-object URLs in the order request object but does not provide a way to obtain such URLs (only a URL for a list of delegations associated to an account is available, not per-delegation URLs). I agree with Francesca and the DE that attaching the \"delegation\" attribute to the identifier makes less sense than attaching it to the order; accordingly, I support Francesca's Discuss. Similarly (and relatedly), there seems to be an object structure mismatch while using a CSR to finalize an order, that may merit some discussion.\u00a0 Each delegation can have its own CSR template, but if a single order is to have the possibility to incorporate multiple identifiers, and each identifier has its own delegation, then there's no reason to expect that a single CSR can be compatible with the templates from the disparate delegations invoked in a single order.\u00a0 We could in principle just require that the CSR templates must be \"consistent\" (and define what that means) in scenarios with multiple identifiers in a single order, but it seems better if we can restructure the object model so things are more naturally aligned.\u00a0 Taken to an extreme, this would entirely divorce CSR template objects from delegation objects, with a URL for the associated CSR template object being an attribute of a delegation.\u00a0 Then we could have something like multiple identifiers and multiple delegations in an order, provided that they all refer to the same CSR template object. I also don't think I understand the need for having \"allow-certificate-get\" in the Order Object (nor its semantics) -- what do we gain from having it in the Object itself that is not achieved by the existing newOrder request payload?\u00a0 As far as I can tell the we only talk about writing to it in the rest of the document, and never have to read or consult its value.\u00a0 If it is necessary, it seems like the document needs to be more clear about why.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-04-07 00:43:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-04-06 10:08:38-07:00",
    "text": "EDIT (06-04-2021): Thank you very much to Carsten Bormann for the CDDL review:  https://mailarchive.ietf.org/arch/msg/cbor/23A-PFhRY-pdkg2-Kgcd4jqySVo/  Authors - please make sure to answer Carsten's comments (and keep me in cc so I can clear my DISCUSS).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-12 14:12:41-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-07 00:43:07-07:00",
    "text": "EDIT (06-04-2021): Thank you very much to Carsten Bormann for the CDDL review:  https://mailarchive.ietf.org/arch/msg/cbor/23A-PFhRY-pdkg2-Kgcd4jqySVo/  Authors - please make sure to answer Carsten's comments (and keep me in cc so I can clear my DISCUSS). EDIT (07-04-2021): Also wanted to point out the IANA Designated Expert review to make sure it is addressed (found in the datatracker, but which I report here for simplicity as well) - thank you to Richard Barnes for it:   1. The \"delegation\" field is currently attached to the \"identifier\" object, which is a bad semantic fit in a few ways. ACME orders can have multiple identifiers, and delegations can describe multiple SAN values, yet this design assumes singularity on both sides. This field should be moved to the order object; in fact, if you wanted to be more radical, you could even use it to replace the \"identifiers\" field in the newOrder request. 2. The \"allow-certificate-get\" field is listed as configurable. It seems like this is a matter of CA policy, so it should either be non-configurable, or if you allow the client to request a value for it, there should be a clear specification that the server is allowed to ignore the client's preference.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-10 12:02:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-06 05:41:09-07:00",
    "text": "Section 5.1, paragraph 4, discuss: >\u00a0 \u00a0 This document requests that IANA create the following new registry >\u00a0 \u00a0 under the Automated Certificate Management Environment (ACME) >\u00a0 \u00a0 Protocol: > >\u00a0 \u00a0 *\u00a0 ACME Identifier Object Fields > >\u00a0 \u00a0 This registry is administered under a Specification Required policy >\u00a0 \u00a0 [ RFC8126 ]. RFC8126  strongly suggests that guidance needs to be given to expert reviewers that are supposed to review and approve requests for \"Expert Review\" and \"Specification Required\" registries. This guidance is missing here. What's also missing are designated contact persons and a change controller. Section 5.6, paragraph 2, discuss: > 5.6.\u00a0 CSR Template Extensions > >\u00a0 \u00a0 IANA is requested to establish a registry \"STAR Delegation CSR >\u00a0 \u00a0 Template Extensions\", with \"Expert Review\" as its registration >\u00a0 \u00a0 procedure. Same as above.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-08-30 12:41:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-16 15:01:17-07:00",
    "text": "I have significant concerns about the recommendation (in \u00a73.7) to use Algorithm A.\u00a0 I think that the considerations to select an Algorithm are not clear and potentially impossible to verify.\u00a0 Also, the selection of Algorithm A creates a vulnerability that could result in legitimate traffic dropped. \u00a73.7 (Summary of Recommendations) says that \"if the scenario does not involve complexity...(see Section 3.3, Figure 4), then...Algorithm A...SHOULD be applied on customer interfaces.\"\u00a0  From Figure 4, how does the operator of ISP4 know that it is not in a \"challenging scenario\" (\u00a73.3)?\u00a0 How can ISP4 tell the difference between ISP2 not propagating routes vs it not even being connected to AS1?\u00a0 By definition, each autonomous system can have its own set of policies, which may not be known by any of their upstreams.\u00a0 In short, I find the guidance provided in the document to select an algorithm not clear enough to really be actionable -- specially in a document tagged to be a BCP. Still looking at Figure 4, if the operator of ISP4 uses Algorithm A (because he/she thinks they may not be in a \"challenging scenario\"), then it opens the door to ISP2 changing its policy so that the uRPF check in ISP4 fails, as shown in Figure 4.\u00a0 IOW, an attacker in ISP2 could stop advertising reachability to some prefixes and cause ISP4 to fail the uRPF check and drop the traffic.\u00a0 The victim in this case could be AS1, whose traffic (through ISP2 to ISP4) was flowing fine and then it stopped. I am balloting DISCUSS because the guidance provided for the selection of an Algorithm is not clear enough to be certain that the selection is the correct one; and the election of Algorithm A creates a vulnerability (as explained in the text) that is not mentioned.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-02 03:05:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 02:56:26-07:00",
    "text": "YANG validation reports the following errors: yanglint 0.14.80: yanglint --verbose -p {rfclib} -p {draftlib} -p {tmplib} {model} -i: err : The leafref leaf is config but refers to a non-config leaf. (/ietf-subscribed-notifications:subscriptions/subscription/target/stream/stream) err : The leafref leaf is config but refers to a non-config leaf. (/ietf-subscribed-notifications:subscriptions/subscription/target/stream/stream) err : Invalid value \"subscription-policy\" of \"uses\". (/ietf-subscribed-notifications:subscriptions/subscription/subscription-policy) err : Copying data from grouping failed. (/ietf-subscribed-notifications:subscriptions/subscription/subscription-policy) err : Module \"ietf-subscribed-notifications\" parsing failed. err : Importing \"ietf-subscribed-notifications\" module into \"ietf-yang-push\" failed. err : Module \"ietf-yang-push\" parsing failed. Are these real problems or are these errors in the validation tool?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-23 10:01:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 12:08:18-07:00",
    "text": "Note that I reviewed the -22 and the current version is -23.\u00a0 Briefly skimming the diff, it seems that some changes touch on points I make in my review, but there is probably still discussion to have on them. (pro-forma) I see the GenArt reviewer noted the author count (seven) already, but I couldn't find a response or note in the ballot or shephert writeup acknowledging this.\u00a0 So failing that, I'll put up a discuss point until the responsible AD says it's fine. [See also discussion on draft-ietf-netconf-subscribed notifications about the pre-RFC5378 boilerplate and whether or not it can be removed from this document] Section 3.3 states: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 In order for a subscriber to determine whether objects \u00a0  support on-change subscriptions, objects are marked accordingly on a \u00a0  publisher.\u00a0 Accordingly, when subscribing, it is the responsibility \u00a0  of the subscriber to ensure it is aware of which objects support on- \u00a0  change and which do not.\u00a0 For more on how objects are so marked, see \u00a0  Section 3.10. Chasing the reference, we see that this marking is left for future work or implementation-specific usage.\u00a0 I'm not very comfortable with the way we are describing this situation, as it seems pretty fragile in the face of different implementations trying to interoperate.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-15 08:00:11-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-15 07:29:27-08:00",
    "text": "I'll keep this as brief as possible: Since this is Informational, I suggest not using  BCP 14 .\u00a0 But it sounds like the WG wanted this to be binding, which means it should be going for BCP status. Let's sort this out.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-03-02 07:48:13-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-25 07:04:46-08:00",
    "text": "Thank you for the work put into this document. I have not had time to review in details though :( but I appreciated the detailed description as well as the useful time diagrams. Please find below one blocking DISCUSS point (which may be my bad understanding), some non-blocking COMMENT points (but replies would be appreciated). I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 7.3.1 -- LINKLOCAL-IPV6-ID-ADDRESS TLV: I fail to understand why there are two addresses in this TLV while others have one one ? Also is 'local' and 'remote' really global addresses ?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-24 17:58:00-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 16:37:43-08:00",
    "text": "[ section 7.3.1 ] * This intended handling of the LINKLOCAL-IPV6-ID-ADDRESS TLV does not seem \u00a0 to be discussed anywhere in this document.\u00a0 Should there be some text \u00a0 about it, or is this TLV left over from previous iterations of the document? * Saying that the LINKLOCAL-IPV6-ID-ADDRESS TLV holds a pair of global IPv6 \u00a0 addresses seems confusing to me. \u00a0 If the pair of global IPv6 addresses is to be considered \"on link\" in the \u00a0 sense that IPv6 ND can be successfully be performed on the link for both \u00a0 of these addresses, then \"ONLINK\" might be better than LINKLOCAL. * Also, why are two interface IDs required?\u00a0 I would have expected that only \u00a0 the outgoing interface name/ID would be of relevance to the recipient of \u00a0 a message with TLV in it?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-01-05 00:25:16-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-04 06:52:17-08:00",
    "text": "I see from the abstract: \"The attribute is suitable for use with four-octet ASNs.\" I also see this text, which doesn't mention four-octet ASNs \u00a0  The Global Administrator field is intended to allow different \u00a0  Autonomous Systems to define BGP Large Communities without collision. \u00a0  This field SHOULD be an Autonomous System Number (ASN), in which case \u00a0  the Local Data Parts are to be interpreted as defined by the owner of \u00a0  the ASN.\u00a0 The use of Reserved ASNs (0 [ RFC7607 ], 65535 and 4294967295 \u00a0  [ RFC7300 ]) is NOT RECOMMENDED. What if the ASN is two bytes, we use padding? How? Even if we would say: \"This field SHOULD be an four-octet Autonomous System Number (ASN)\", it doesn't preclude inserting a two-octet ASN in the Global Administrator field. Isn't it better to specify how?  From  RFC 6793 : \u00a0  Currently assigned two-octet AS numbers are converted into four-octet \u00a0  AS numbers by setting the two high-order octets of the four-octet \u00a0  field to zero.\u00a0 Such a four-octet AS number is said to be mappable to \u00a0  a two-octet AS number.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-01 09:04:04-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-09 11:17:37-08:00",
    "text": "First off, thanks for the work on this document; it's important to get this behavior clarified and functional even for NFSv4.0. That said, this document (along with the pieces of 7530 and 7931 that I read along the way) still leave me uncertain about how some things are supposed to work.\u00a0 (If it's clarified in parts of those documents that I didn't read, I'll happily clear and apologize for the disruption, of course.) To start with, I'm still lacking a clear high-level picture of why a client needs to care about trunking detection vs. just treating all listed addresses as replicas.\u00a0 There are some parts in the body where we talk about, e.g., lock state and similar maintenance, but I don't have a clear picture of what the risks and benefits of (not) tracking trunking are, and this would be a fine opportunity to add some text.\u00a0 Specifically, in Section 5.2.1, we just say that \"[a] client may use file system location elements simultaneously to provide higher-performance access to the target file system\"; most of the focus of this document makes me think that this statement was intended to apply only to trunking, but I also think there are supposed to be replication-only scenarios that provide performance gains.\u00a0 I'm not sure if we need to clarify the distinction in that location as well as the high-level overview. It's also unclear to me what parts of migration flows are under the control of the client vs. the server.\u00a0 It's clear that the server has to initiate migration via NFS4ERR_MOVED, but my current understanding is just that this prompts the client to look at fs_locations, and the client has control over which alternate location to move to.\u00a0 But there's also a lot of discussion in all three documents about the servers migrating state along with migration, so it seems like the server should be controlling where the client goes.\u00a0 Is this just supposed to be by limiting the fs_locations data to the specific migration target chosen by the server?\u00a0 (If so, this would probably have potential for poor interaction with the implicit filesystem discovery described in Section 5.3.)\u00a0 On the other hand, Section 5.2.6 talks about the server putting entries \"that represent addresses usable with the current server or a migration target before those associated with replicas\", which seems to imply that there is some other way to know what the migration target is. Section 5.2.6 also tells the client to rely on that ordering: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  To keep this process as short as \u00a0  possible, Servers are REQUIRED to place file system location entries \u00a0  that represent addresses usable with the current server or a \u00a0  migration target before those associated with replicas.\u00a0 A client can \u00a0  then cease scanning for trunkable file system location entries once \u00a0  it encounters a file system location element whose fs_name differs but I don't think a client actually can do so, since the client has no way to know that the server implements this document as opposed to stock 7530+7931 (at least, no way that I saw). Finally, removing the last paragraph of Section 8.5 of  RFC 7530  could have negative operational impact if updated clients interact with non-updated servers/environments that are misconfigured in the described fashion.\u00a0 It's probably worth stating in the top-level Section 5 that such misconfigured servers are believed to no longer exist (if that's in fact true, of course; if not, we'd need to reconsider the change).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-10-15 10:50:46-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-18 12:33:35-07:00",
    "text": "The document says:  \"proper review will require a team of experts that has both \u00a0  broad and specific skills in reviewing Unicode characters and their \u00a0  properties in relation to both the written standards and operational \u00a0  needs.\u00a0 The IESG will need to appoint experts who can draw on the \u00a0  broader community to obtain the necessary skills for particular \u00a0  situations.\" And then later in Section 8 it calls on the IESG to setup a designated expert team. I have a couple of questions and concerns about this: 1) I don't fully understand the expected interaction between the team and the broader community. If the team is expected to draw on the broader community, why must it be a team? That is, why can't one DE be on the hook for completing the review, as long as the instructions to the DE say that the person must consult with experts to ensure that the breadth of expertise necessary is filtered into the review? 2) My understanding is that the number of people available to be on the envisioned DE team can be counted on one hand and that number is dwindling. Do we really expect to be able to build a team with \"broad and specific skills\" given this reality? I'd rather we not setup a process that we are unlikely to be able to fulfill at the time when a review is needed. 3) What is the decisionmaking process for the DE team? What happens if the DEs on the team can't agree with each other? Do we just not do the review?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-09-08 23:06:48-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-12 06:20:53-07:00",
    "text": "his document seems to have unresolved IANA issues, so I am holding a DISCUSSfor IANA until the issues are resolved.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-31 10:16:45-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-05 14:04:28-07:00",
    "text": "This should be quite easy to resolve; I'm just not sure yet which direction the resolution will be. I think we should be a little more clear about whether the client can override the finalRecipient calculation (or just provide a suggestion to do so, or not give any input at all, etc.): the description of the finalRecipient property of an MDN object says that \"if set, it overrides the value that would be calculated by the server from the Identity\", which to me suggests that the client could set something to override the server (if the server sua sponte did something different that would typically be an \"exception\", not an \"override\"), but later on in Section 2.1 we say that \"[w]hen sending the MDN, the server is in charge of generating the \"originalRecipient\", \"finalRecipient\" and \"originalMessageId\" fields according to the [ RFC8098 ] specification.\u00a0 I do not see discussion in  RFC 8098  of client intput into the server's populating of this field, so I'm unsure whether/where the client has input.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-11 10:56:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-05 10:25:53-07:00",
    "text": "Thanks for this document; it's good to improve the clarity and precision of how various pieces of the ecosystem interact.\u00a0 That said, I do have a couple of potential issues that need to be addressed prior to publication: I'm not sure I fully understand the security consequences of causing the SPF macros %{s} and %{l} to never match when the local-part contains non-ASCII characters, but they seem potentially quite bad.\u00a0 That is, if the policy is intending to limit allowed senders to a specific list (or block specific senders), would an attacker be able to avoid the restriction by using a non-ASCII local-part? I'd also like to discuss whether we need greater specificity in the nature of the updates applied to the Updates:'d documents.\u00a0 For example, Section 6 (of this document) says that Xection X [of  RFC7489 ] is updated \"to say that all U-labels in domains are converted to A-labels before further processing\", but most of those referenced sections contain step-by-step listings of a procedure to follow.\u00a0 It doesn't seem like much of a burden for us to say \"between steps X and X+1, insert the following step: \"[convert domain from U-label to A-label]\", and that has a potentially significant gain in clarity to the reader (and thus, interoperability).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-17 21:42:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-11 10:56:07-07:00",
    "text": "Thanks for this document; it's good to improve the clarity and precision of how various pieces of the ecosystem interact.\u00a0 That said, I do have an issue that needs to be addressed prior to publication: We need to properly document the consequences of causing the %{s} and %{l} macros to never match when the local-part contains non-ASCII characters. I understand that they are quite rare in practice, and this rarity justifies not going to great lengths to provide a technical solution, but that doesn't mean that we can silently ignore the issues. [discussion of specificity of Updates\u00a0 removed, as the discussion happened]",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-05-22 22:09:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 22:50:38-07:00",
    "text": "## Discuss ### S5.1 *  RFC 6724  source address selection is not sufficient.\u00a0 Many complexities \u00a0 are captured in  RFC 8678 .\u00a0 As  RFC 8475  notes, what's really required to \u00a0 make this work for some nodes is proper next-hop selection in conjunction \u00a0 with source address selection.\u00a0 Either that, or some kind of source-aware \u00a0 routing for forwarding nodes. \u00a0 For originating packets, depending on the topology, the following options \u00a0 can in theory be made to work: \u00a0 \u00a0 * implementing  RFC 6724  rule 5.5, but it's not currently mandatory \u00a0 \u00a0 * implementing  RFC 6724  section 4 recommendation \"that the candidate \u00a0 \u00a0 \u00a0 source addresses be the set of unicast addresses assigned to the \u00a0 \u00a0 \u00a0 interface that will be used to send to the destination (the \"outgoing\" \u00a0 \u00a0 \u00a0 interface)\" -- but this is highly dependent upon interface config \u00a0 \u00a0 * use of PVD Options ( RFC 8801 ) throughout the interior (and, ideally, an \u00a0 \u00a0 \u00a0 IETF-defined PVD End System model) \u00a0 I'm don't think that it's worth going into all this detail in this document, \u00a0 necessarily.\u00a0 You might see if a mix of references to and/or quotations from \u00a0 8678, 8475, and/or mention of the issue of next-hop selection in conjunction \u00a0 with source address selection yields sufficiently concise text to warn the \u00a0 IPv6-multihoming-unfamiliar reader: \"here be dragons (hic sunt dracones)\".",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-04-21 06:22:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 18:23:46-07:00",
    "text": "Thanks for a clear document and thanks to Kathleen for the SecDir review. I have one minor DISCUSS item that can probably be resolved easily by adding a sentence or two. [1] \u00a0  The DOTS client SHOULD use the certificate \u00a0  provided by a provisioning domain to authenticate itself to the DOTS \u00a0  server(s) provided by the same provisioning domain. This sentence suggests there is either another authentication method, or it allows for unauthenticated DOTS clients. If the latter, than I would expect a significant Security Considerations section on how to avoid/reduce malicious clients impact of such a setup. eg I could envision a compromised device from falsely reporting a DDOS attack from a certain network to block the compromised device/network from receiving traffic from certain remote networks.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-08-31 16:17:02-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-15 09:01:16-07:00",
    "text": "(I agree with Ekr's DISCUSS about these being bearer tokens and am happy to see the discussion on improving the text there.) There are a couple of other things that I seek discussion on: The document itself does very little to motivate the addition of the allocation token, from a security point of view.\u00a0 In what security model is there a security advantage from having this sort of single-use authorization token as opposed to using existing authentication and authorization methods?\u00a0 The use case of a premium domain-name auction that came up in Ekr's ballot thread is actually quite enlightening, in that the token allows for the authorization to be granted to the winner of an auction even in the case where the winning bidder and the current registration owner do not have any common authentication or authorization infrastructure (other than for the auction and its payment itself).\u00a0 Some generalization of these considerations into a model that matches the generalized functionality in the draft would be a quite helpful addition. This could also be leveraged in the discussion of why the allocation token is not needed in the various commands for which its usage is not provided (mentioned in my COMMENT). I also request changes to the examples (or the discussion surrounding them). Using \"abc123\" as the example allocation token is probably unwise, as that value provides none of the properties we desire from allocation tokens. If you don't want to use an actual random-looking (e.g., self-encrypted server-generated) or signed value because it makes the examples too long, at least provide some text indicating that \"abc123\" is a placeholder and real tokens should have a different structure. Similarly, the passwords used in the examples hardly have enough entropy to be considered secure by modern standards.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-08-22 17:05:43-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-15 07:02:27-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3061 These are bearer tokens and therefore I believe transport encryption needs to be required in S 7, not just listed as should (which isn't even normative in this context).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-03-21 09:10:42-07:00",
    "end_reason": "position_updated",
    "start": "2017-02-13 14:52:41-08:00",
    "text": "I agree with Mirja's comments about the use of Normative Language and believe that for a BCP document its use is not clear enough such that it could result in different \"compliant\" implementations that may not interoperate properly.\u00a0 So I am making the issue a DISCUSS. As Mirja mentioned, this statement in the Introduction opens the door for other configurations: \"Any 6TiSCH compliant device SHOULD implement this mode of operation.\"\u00a0 The question to answer for this \"SHOULD\" (and others) is what are the particular circumstances when ignoring this recommendation is ok.\u00a0 The document doesn't elaborate at all on details. I understand that there are in fact other posible configurations, but if this document is describing the Best Current Practice then I think it should be explicit as to what that BCP is. Another example of the lack of clarity (besides those already mentioned by Mirja) is the use of RPL:\u00a0 The Introduction mentions that \"RPL is specified to provide the framework for time synchronization in an 802.15.4 TSCH network.\", but Section 5 (RPL Settings) makes it optional: \"In a multi-hop topology, the RPL routing protocol [ RFC6550 ] MAY be used.\"",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-03-17 18:23:56-07:00",
    "end_reason": "position_updated",
    "start": "2017-02-14 08:46:03-08:00",
    "text": "Thanks for responding to the SecDir review, it looks like the updates needed are planned for the next version.\u00a0 There were a number of significant findings, so this placeholder is to make sure those happen (protocol and security). https://www.ietf.org/mail-archive/web/secdir/current/msg07162.html For some reason, the SecDir review isn't linked off of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-22 14:24:58-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-17 15:21:25-08:00",
    "text": "Thanks for this -- it was a good read.\u00a0 I just have a few super-boring poitns of apparent internal inconsistency to fix before publication. There seems to be an internal inconsistency relating to the handling of link-local addresses by a Bridging Proxy: Section 8 descriptively says that such addresses are (always) registered (\"[t]he Bridging Proxy registers any Binding including for a Link-Local address to the 6LBR\"), but Section 9 has this behavior as optional (\"[a] Bridging Proxy MAY register Link Local addresses at the 6BBR and proxy ND for these addresses over the backbone\"). Similarly, I see Section 6 saying that when a 6BBR generates an NA in response to an NS(DAD), it \"MUST have the Override flag set\", but Section 9.2 says \"MUST be answered ... the Override flag not set\" (for the \"different registration\" case, i.e., second bullet) and nothing at all about the Override flag for the \"not as fresh\"/\"Moved\" case (i.e., the third bullet).\u00a0 Am I misreading something? Continuing the theme, Section 10 notes that a \"Registering Node SHOULD register all of its IPv6 Addresses to its 6LR, which is the 6BBR when they are connected at Layer 2\", but Appendix B states the stronger condition that \"[t]he 6BBR assumes that if a node registers at least one IPv6 Address to it, then the node registers all of its Addresses to the 6BBR.\"",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-21 17:58:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 15:32:28-08:00",
    "text": "Section 11.\u00a0 Can assumptions of the about the security properties of the links be clarified.  This specification applies to LLNs and a backbone in which the \u00a0  individual links are protected against rogue access, e.g., by \u00a0  authenticating a node that attaches to the network and encrypting at \u00a0  the MAC layer the transmissions that may be overheard.\u00a0 In \u00a0  particular, the LLN MAC is required to provide secure unicast to/from \u00a0  the Backbone Router and secure Broadcast from the Backbone Router in \u00a0  a way that prevents tampering with or replaying the RA messages. -- what are the specific assumptions about the protections that will be on the link.\u00a0 Is the list of properties in the \u201ce.g.\u201d the full list? -- As the second sentence references the only the LLN MAC, using Figure 1 and 2 as a reference (realizing they are non-normative), what\u2019s expected properties of the links between the router-and-6BBR or IPv6 node-and-6BBR (i.e., the links connecting to the \u201cbackbone side\u201d)?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-19 07:01:16-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-09 09:15:14-07:00",
    "text": "he intended status needs to be changed to Proposed Standard before approval.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 14:57:32-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-09 16:42:55-07:00",
    "text": "I recognize that this document is trying to take the track of \"we recognize that some implementations/deployments violate  RFC 8200 , and while we don't condone that behavior, we want to provide diagnostics to try to mitigate the fallout from them\", but I'm not sure it succeeds in all cases.\u00a0 The discussion in Section 5.1 that is quite clear about \"does not advocate behaviors that might be considered nonconformant\", but there is another usage in Section 2.2 (\"[t]his code SHOULD be sent by an intermediate node that discards a packet because it encounters a Next Header type that is unknown in its examination\") that seems worth revisiting.\u00a0 Perhaps we can reword to be more clear that this is the recommended behavior subject to the predicate that an  RFC 8200  violation has occurred, which is not itself a recommended behavior. In light of the updated usage described in Section 2.2, should we direct IANA to make the \"Reference\" column for the \"unrecognized Next Header type encountered\" parameter problem list both this document and  RFC 4443 ?\u00a0 (It currently does not list any reference, as is the case for many entries on the containing page...) This codepoint is not currently mentioned in the IANA Considerations at all",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-06-17 13:56:56-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 11:11:02-07:00",
    "text": "The normative portion of this document is the machine code in section 3.1. There is no definition or citation for the formal language used in this document. The document needs to either define or normatively cite the definition of this language. I suspect that the citation you want is ISO/IEC 9899:1999 (or a newer document in that same series).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-13 09:01:16-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 17:50:08-07:00",
    "text": "(1) Section 1.\u00a0 Per \u201cThe TinyMT32 PRNG initialization depends, among other things, on a parameter set -- namely (mat1, mat2, tmat) -- that needs to be well chosen (pre-calculated values are available in the official web site).\u201d, why is there a reference to an external website when Section 3.1 explicitly lists the constant and mandates their usage?\u00a0 I\u2019m elevating this to a discuss as there should be no ambiguity on the location of these constants. (2) Section 3.1.\u00a0 A comment in tinymt32_next_state() notes code changes made to the \u201coriginal code \u2026 [so it is] not depend on the representation of negative integers by 2's complements.\u201d\u00a0 The following code in tinymt32_temper() appears to suffer from this same, original portability issue:  t0 ^= -((int32_t)(t1 & 1)) & s->tmat;",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-27 02:24:55-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-27 02:15:09-08:00",
    "text": "Thank you for the work done in this document. I have only a single blocking DISCUSS that it trivial to fix: absence of  BCP 14  boilerplate for a standards track document ;-) Suggestion to the authors: add the  BCP14  boilter plate and re-upload a revised version before other IESG members' evaluations. -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-02-21 20:53:41-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-02-21 20:52:30-08:00",
    "text": "I think we have a process problem here. This document (Standards Track) makes normative references to  RFC 8279  (Experimental) and  RFC 8296  (Experimental), neither of which appear in the downref registry. My understanding of the rules defined in  RFC 3967  is that these downreferences need to be explicitly called out in the IETF last call announcement so that the community can discuss whether such downreferences are acceptable. Unless the last call text in the datatracker doesn't match the text sent to the IETF discussion list, this document needs to run through IETF LC again before it can move forward. This also raises the question of whether *this* document should be Experimental rather than Standards Track, as it appears to be defining an extension that is used exclusively for enabling experimental specifications.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-03-09 14:48:01-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 20:53:41-08:00",
    "text": "I think we have a process problem here. This document (Standards Track) makes normative references to  RFC 8279  (Experimental) and  RFC 8296  (Experimental), neither of which appear in the downref registry. My understanding of the rules defined in  RFC 3967  is that these downreferences need to be explicitly called out in the IETF last call announcement so that the community can discuss whether such downreferences are acceptable. Unless the last call text in the datatracker doesn't match the text sent to the IETF discussion list, this document needs to run through IETF LC again with these downrefs explicitly called out before it can move forward. This also raises the question of whether *this* document should be Experimental rather than Standards Track, as it appears to be defining an extension that is used exclusively for enabling experimental specifications. This would fix the downref problem, but I'm not sure whether it requires another Last Call.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-04-01 11:14:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 09:15:09-08:00",
    "text": "Document:  draft-ietf-bier-isis-extensions-00.txt \u00a0  Implementations must assure that malformed TLV and Sub-TLV \u00a0  permutations do not result in errors which cause hard protocol \u00a0  failures. This is not an adequate security considerations section. What is your threat model? What attacks are possible? What are not? It may be the case that this is all covered in other documents, and you just need to point to them, but the reader doesn't know that, so this needs to be documented. Off the top of my head, what happens if I send a BIER Info sub-TLV with someone else's BFR-Id and a bogus BIER MPLS encapsulation sub-sub-TLV?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-03-12 11:48:10-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 17:37:28-08:00",
    "text": "* Section 6.2.\u00a0 BIER MPLS Encapsulation sub-sub-TLV This should be straightforward to fix but it is not clear if the label range is allowed to wrap around (overflow) or not past the 20 bit space. e.g. is a Label=2^20-X with a MSI of X or larger legal? I was hoping that  RFC8296  would have covered this but unfortunately it leaves it to this document (and the OSPF document) to specify.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-14 16:37:57-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 22:30:06-07:00",
    "text": "(1) and (2) should be easy to fix; (3) may well be \"fixed\" by telling me I'm too naive :) (1) Given that section 1 describes other options, the abstract should not limit to just DHCP and RA as options for provisioning the API URL. (2) Section 4.1 says that: \u00a0  5.\u00a0 The Captive Portal API server indicates to the Enforcement Device \u00a0 \u00a0 \u00a0  that the User Equipment is allowed to access the external \u00a0 \u00a0 \u00a0  network. but I believe this should be the \"Captive Portal Server\" (or, as the previous point has it, the \"web portal\"). (3) Probably a \"discuss discuss\", but ... in Section 1 we have: \u00a0  *\u00a0 Solutions SHOULD NOT require the forging of responses from DNS or \u00a0 \u00a0 \u00a0 HTTP servers, or any other protocol.\u00a0 In particular, solutions \u00a0 \u00a0 \u00a0 SHOULD NOT require man-in-the-middle proxy of TLS traffic. I'd like to understand the motivation for this one a little better. Naively, it seems like we could get away with \"MUST NOT require\" while still allowing it to be done.\u00a0 Am I missing something obvious?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-08 11:58:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-06-08 08:06:12-07:00",
    "text": "Sec 2.3\u00a0 says: At minimum, the API MUST provide: (1) the state of captivity and (2) a URI for the Captive Portal Server. But in section 5 of capport-api, user-portal-url is an optional field. Both a capport-api author and a WG chair agreed that the architecture doc should be fixed, so I'm moving the DISCUSS here.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-08 23:05:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-08 11:58:07-07:00",
    "text": "AFAICT this Discuss still applies to draft-09. Sec 2.3\u00a0 says: At minimum, the API MUST provide: (1) the state of captivity and (2) a URI for the Captive Portal Server. But in section 5 of capport-api, user-portal-url is an optional field. Both a capport-api author and a WG chair agreed that the architecture doc should be fixed, so I'm moving the DISCUSS here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-24 11:28:59-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-25 15:51:00-07:00",
    "text": "(1) This should be pretty easy to resolve, but this text from \u00a74.4 does not seem to match up with the referenced document: \u00a0  The use of TLS places even stronger operational burdens on DNS \u00a0  clients and servers.\u00a0 Cryptographic functions for authentication and \u00a0  encryption requires additional processing.\u00a0 Unoptimized connection \u00a0  setup takes two additional round-trips compared to TCP, but can be \u00a0  reduced with TCP Fast Open, TLS session resumption [ RFC8446 ] and TLS \u00a0  False Start [ RFC7918 ]. Two additional round trips was true of TLS 1.2 and prior versions, but as of TLS 1.3 the application data from the client can be sent after only 1 round trip, accompanying the client Finished (and authentication messages, if in use).\u00a0 Given the nature of the rest of the sentence, we might want to specifically mention TLS 1.3 as an improvement over TLS 1.2, but there are probably a number of ways that we could fix it.\u00a0 Note additionally that for TLS 1.3, session resumption is not a reduction in the number of round trips unless 0-RTT data is used (but AFAIK there is not a published application profile specifying acceptable DNS content for TLS 0-RTT data, so use of TLS 0-RTT data for DNS is forbidden), but is still an efficiency gain due to the reduced number of cryptographic operations (including certificate validation). (2) Trivial to address, but the section heading for Appendix A.8 references  RFC 3326  (The Reason Header Field for the Session Initiation Protocol (SIP)), not  RFC 3226  (DNSSEC and IPv6 A6 aware server/resolver message size requirements)",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-12-17 01:04:46-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-26 04:35:38-07:00",
    "text": "Section 4.2. , paragraph 3, discuss: >\u00a0 \u00a0 Since host memory for TCP state is a finite resource, DNS clients and >\u00a0 \u00a0 servers MUST actively manage their connections.\u00a0 Applications that do >\u00a0 \u00a0 not actively manage their connections can encounter resource >\u00a0 \u00a0 exhaustion leading to denial of service.\u00a0 For DNS, as in other >\u00a0 \u00a0 protocols, there is a tradeoff between keeping connections open for >\u00a0 \u00a0 potential future use and the need to free up resources for new >\u00a0 \u00a0 connections that will arrive. For it to contain a MUST-level requirement, this section needs to give a lot more concrete guidance on what it means to \"actively\" manage connections. Most operating systems by default impose some application limits that usually effectively prevent DOS or other resource exhaustion issues. Is the intent here that DNS implementations need to do more? If so, what?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-05 13:49:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-25 15:01:46-07:00",
    "text": "This document has a dedicated section for DNS over TLS, makes a number of configuration recommendations for DoT, and notes it in the Privacy Considerations.\u00a0 However, there is no mention of DNS over HTTPS (DoH).\u00a0 It seems like DoH should get similar treatment.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-10 11:00:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-02 19:39:38-07:00",
    "text": "I support Magnus' point about the time-ordering of adjacent frames in a packet. Additionally, I am not sure that there's quite enough here to be interoperably implementable.\u00a0 Specifically, we seem to be lacking a description of how an encoder or decoder knows which TSVCIS parameters, and in what order, to byte-pack or unpack, respectively.\u00a0 One might surmise that there is a canonical listing in [TSVCIS], but this document does not say that, and furthermore [TSVCIS] is only listed as an informative reference.\u00a0 (I couldn't get my hands on my copy, at least on short notice.)\u00a0 If we limited ourselves to treating the TSVCIS parameters as an entirely opaque blob (codec, convey these N octets to the peer with the appropriate one- or two-byte trailer for payload type identification and framing), that would be interoperably implementable, since the black-box bits are up to some other codec to interpret. In a similar vein, we mention but do not completely specify the potential for using CODB as an end-to-end framing bit, in Section 3.1 (see Comment), which is not interoperably implementable without further details.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-10-29 04:21:44-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-30 07:18:32-07:00",
    "text": "1. Section 3.3:  \t\u00a0  A TSVCIS RTP packet consists of zero or more TSVCIS coder frames \u00a0  (each consisting of MELPe and TSVCIS coder data) followed by zero or \u00a0  one MELPe comfort noise frame.\u00a0 The presence of a comfort noise frame \u00a0  can be determined by its rate code bits in its last octet.   I am missing a quite important word in this paragraph. Because I assume that the frame actually are required to be consecuitive frames in time order from oldest to newest?    2. Section 4.1: \t\u00a0  Change controller: IETF Payload working group delegated from the \u00a0 \u00a0 \u00a0 IESG.   IESG should we adjust this immediately to say IETF, although this is the currently recommended text in  RFC 8088 . Or are we only adjusting the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-11-29 19:07:09-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-23 12:13:34-07:00",
    "text": "I have two points that I would like to discuss.\u00a0 It is more likely than not that at least one of them merely reflects my confusion and is a non-issue, but I would like to get these at least clarified. First, the examples throughout the document use organization identifiers like \"myreseller\" or \"myproxy\".\u00a0 This seems to me to be highly confusing, since these IDs are supposed to be server-unique values per organization, and are highly unlikely to be \"my\" reseller/proxy/etc. for all the entries in the registry.\u00a0 If I understand things correctly, the example IDs should instead be company-name-like values or \"random\" numbers or similar (or combination thereof). Second, I am unsure of the semantics relating to role types, especially as they interact with the\u00a0 command.\u00a0 Various aspects of the examples seem to imply that it is only permitted to have at most one organization mapping of a given role type (i.e., one reseller, one proxy, etc.).\u00a0 In particular, the\u00a0 element seems to be using the\u00a0 role attribute to determine which\u00a0 is being changed (with the new value being provided in the element body), and the\u00a0 element is providing\u00a0 with only the role attribute and no body to identify a specific organization to remove.\u00a0 If this reading of the document is correct, then I would expect the limitation to be called out more clearly, especially as it would seem to prevent a domain owner from (e.g.) using multiple DNS service operators.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-03-10 14:31:29-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 00:01:17-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of concerns that I think make this specification ambiguous in some very important ways that will prevent interoperation. These should be pretty simple to fix. Section 3.2 talks about patching operations. One of the things it indicates is: \u00a0 \"The \u00a0  names and times of the Patch Records are given and matched in same \u00a0  way as for the Fetch Records, except each Patch Record can match at \u00a0  most one Target Record.\" I kept waiting for text that tells the recipient of a patch what to do if a Patch Record matches more than one SenML Record (e.g., if the Patch Record contains no time value and so matches several different SenML Records), but I couldn't find any. Presumably, this is an error, and an error should be sent to the client. The ability for one Patch Record to raise an error, in turn, raises the question about how to handle other Patch Records in the same Patch Pack. For example, if I send a Patch Pack with two Patch Records that can be successfully applied, and one that cannot (because it matches multiple SenML Records), does the server apply the two that it can, but not the one that cannot? If so, how does it communicate to the client which records succeeded, and which failed? Relevant to the above points, we also need to clearly specify in this document whether the Patch Records are considered to be applied in sequence. For example, consider a SenML database containing: \u00a0  [ \u00a0 \u00a0  {\"n\":\"urn:dev:ow:10e2073a01080063\",\"u\":\"%RH\",\"t\":1.320067464e+09, \u00a0 \u00a0 \u00a0 \"v\":20}, \u00a0 \u00a0  {\"n\":\"urn:dev:ow:10e2073a01080063\",\"u\":\"%RH\",\"t\":1.320067524e+09, \u00a0 \u00a0 \u00a0 \"v\":20.3} \u00a0  ] Now, I send a Patch Pack like: \u00a0  [ \u00a0 \u00a0  {\"n\":\"urn:dev:ow:10e2073a01080063\",\"u\":\"%RH\",\"t\":1.320067464e+09, \u00a0 \u00a0 \u00a0 \"v\":null}, \u00a0 \u00a0  {\"n\":\"urn:dev:ow:10e2073a01080063\",\"u\":\"%RH\", \"v\":21} \u00a0  ] Does this succeed, or does it fail? If executed in sequence, this succeeds, since the first Patch Record will remove the first SenML record, and the second Patch Record will unambiguously match the second SenML record (and update it). On the other hand, if we don't specify that records are processed in order, then this might be rejected due to the second Patch Record being ambiguous. Note that this rejection could also arise if an implementation naively attempted to validate records prior to executing them, without taking into account the impact of the preceding record on the state of the SenML record database. There are other ways of handling this, but my strawman for how to address these issues would be to add language that specifies: - Any Patch Record that matches more than one SenML record results \u00a0 in an error that is sent to the client. - If an error is sent to a client for a Patch Pack, then the final \u00a0 state of the SenML records on the client must not be changed. \u00a0 In other words, either the Patch Pack works in its entirety, or \u00a0 it fails in its entirety. - Patch Records in a Patch Pack are processed sequentially. In order \u00a0 to implement both this and the preceding bullet, the implementation \u00a0 will need some ability to roll-back any already-applied changes if \u00a0 an error is encountered.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-10 11:07:00-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 11:45:38-07:00",
    "text": "(1) Section 5.\u00a0 It\u2019s helpful that this document notes the relevance of SenML\u2019s security and privacy considerations (i.e., Section 13 of  RFC8428 ).\u00a0 However, this references seems circular.\u00a0  RFC8428  says, \u201cSenML formats alone do not provide any security and instead rely on the protocol that carries them to provide security.\u201d\u00a0 This document seems to be that \u201cprotocol that carries them\u201d implying it\u00a0 should cover the security mechanisms.\u00a0 Is it not appropriate to suggest that CoAPs can address the (per  RFC8428 ) \u201cconfidentiality, data integrity, and authentication as appropriate for the usage.\u201d? If not, what additional guidance can be provided? (2) Section 5.\u00a0 It seems like it would be appropriate for the server to support access control to restrict the client\u2019s ability access and modify a resource with FETCH and (i)PATCH.\u00a0 My read of \u201cPer \u201cIn FETCH and (i)PATCH requests, the client can pass arbitrary names to the target resource for manipulation.\u00a0 The resource implementer must take care to only allow access to names that are actually part of (or accessible through) the target resource\u201d, doesn\u2019t suggest that type of access control.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-09-23 07:17:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-21 08:21:19-07:00",
    "text": "I would like to discuss the extensibility of the model as described in section 3 regarding 'qos-classification-policy' when UDP is used as substrate. See more in my comments bellow.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-06-21 06:10:25-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-19 17:33:58-07:00",
    "text": "Why are you allowing this extension to be \"normal\" in BUNDLE? If you're bundling, you should be modern enough to handle mixed, no? Why not make life simple?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-07-09 08:29:22-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-07-07 04:43:02-07:00",
    "text": "I will need to re-Last Call the document due to 2 DownRefs: RFC 5861  (HTTP Cache-Control Extensions for Stale Content). RFC6707  (terminology). In regards to Spencer's comment: \u00a0  A server implementation of the \u00a0  CDNI metadata interface MUST reject all methods other than GET and \u00a0  HEAD. I think this text needs to be deleted, because it puts extra requirements on generic HTTP servers that might be used to serve CDNI Metadata, which I think is a wrong thing to do.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-03 06:18:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-07-09 08:29:22-07:00",
    "text": "IANA Auth type registry no longer created? Has this been moved to another draft? RFC 3490  is an obsoleted RFC, need to reference the latest IDNA RFC. Some outstanding issues in 6.8 (Versionning) Check remaining AD review comments reported earlier. In regards to Spencer's comment: \u00a0  A server implementation of the \u00a0  CDNI metadata interface MUST reject all methods other than GET and \u00a0  HEAD. I think this text needs to be deleted, because it puts extra requirements on generic HTTP servers that might be used to serve CDNI Metadata, which I think is a wrong thing to do.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-28 10:21:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-03 06:18:59-07:00",
    "text": "RFC 3490  is an obsoleted RFC, need to reference the latest IDNA RFC. -- You updated description in the document to read (in 2 places): Internationalized Domain Names (IDN) must first be\t transformed to the IDNA encoding as per [ RFC5891 ]. However this is not clear enough, because you are not saying whether you want to use A-labels or U-labels. I think the former. IANA Auth type registry no longer created? Has this been moved to another draft? Issues from my earlier review (these might be already fixed): In 4.1.2: hostname need to have defined syntax (at least by reference). You also need to say whether IDN domain names are allowed here. In 8.3: \u00a0 An implementation of the CDNI metadata interface MUST use strong \u00a0 encryption and mutual authentication to prevent undetectable Encryption doesn't necessarily provide integrity of data, so I would change \"strong encryption\" to TLS. \u00a0 modification of metadata (see Section 8.5).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-28 10:27:04-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-28 10:21:25-07:00",
    "text": "RFC 3490  is an obsoleted RFC, need to reference the latest IDNA RFC. -- You updated description in the document to read (in 2 places): Internationalized Domain Names (IDN) must first be\t transformed to the IDNA encoding as per [ RFC5891 ]. However this is not clear enough, because you are not saying whether you want to use A-labels or U-labels. I think the former. IANA Auth type registry no longer created? Has this been moved to another draft? Issues from my earlier review (these might be already fixed): In 8.3: \u00a0 An implementation of the CDNI metadata interface MUST use strong \u00a0 encryption and mutual authentication to prevent undetectable Encryption doesn't necessarily provide integrity of data, so I would change \"strong encryption\" to TLS. \u00a0 modification of metadata (see Section 8.5).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-29 03:09:17-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-28 10:27:04-07:00",
    "text": "RFC 3490  is an obsoleted RFC, need to reference the latest IDNA RFC. -- You updated description in the document to read (in 2 places): Internationalized Domain Names (IDN) must first be\t transformed to the IDNA encoding as per [ RFC5891 ]. However this is not clear enough, because you are not saying whether you want to use A-labels or U-labels. I suggest: in 4.1.2, change: \u00a0 \u00a0 \u00a0 \u00a0  Internationalized Domain \u00a0 \u00a0 \u00a0 \u00a0  Names (IDN) must first be transformed to the IDNA encoding as \u00a0 \u00a0 \u00a0 \u00a0  per [ RFC5891 ]. to: \u00a0 \u00a0 \u00a0 \u00a0  Internationalized Domain \u00a0 \u00a0 \u00a0 \u00a0  Names (IDN) must first be transformed to the A-label form as \u00a0 \u00a0 \u00a0 \u00a0  per [ RFC5891 ]. You can also add \"[ RFC5890 ]\" to the end of the sentence (and add it to Normative References), as it defines A-labels. Similarly, in 4.3.3, change: \u00a0  Internationalized Domain Names (IDN) must first be \u00a0  transformed to the IDNA encoding as per [ RFC5891 ]. to: \u00a0  Internationalized Domain Names (IDN) must first be \u00a0  transformed to the A-label form as per [ RFC5891 ].",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-07-06 11:07:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-05 16:23:09-07:00",
    "text": "I have two concerns that I would like to see discussed prior to publication: 1) Section 6.2 cites a normative reference to  RFC 5861 . That's an ISE stream informational RFC. The text as written seems to normatively require implementation of that RFC to enable the \"caching\" feature. Did the working group discuss the implications of that? (I also note that this doesn't appear to have been called out at IETF last call. While there has been some discussion about relaxing that requirement, I'm not sure this is an appropriate place to do so.) 2) Section 8.5 contains the \"In an environment where any such protection is required\" language that has been discussed for several CDNI drafts. But in this particular case, the implication that there may be environments where such protection is _not_ required seems to conflict with the multiple occurrences of \"MUST use strong encryption/mutual authentication\" in sections 8.1-8.4.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-07 06:52:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-07-06 05:10:23-07:00",
    "text": "(1) I don't get the model for telling a dCDN that the user agent has to have authenticated or that some authorization is needed before content is to be delivered. Can you explain?\u00a0 For example, neither 4.2.5 nor 4.2.7 tell me how to do anything but allow open-access, and the relevant IANA registry (section 7.4) is empty, so I'm puzzled.  (2) 6.5: I think you're missing a MUST in the list here. I'd suggest something like: \"5. Describe the security and privacy (for the person/user-agent, not only xCDN) consequences of the extension.\" I'm assuming that we agree that it'd be a bad idea if e.g. some extension were defined that allowed a uCDN tell a dCDN to try to track and report on all of a user's activities. (Or at least, that'd need to be documented/justified.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-09 06:45:24-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-07 06:52:02-07:00",
    "text": "(1) cleared, was just a document split issue (2) 6.5: I think you're missing a MUST in the list here. I'd suggest something like: \"5. Describe the security and privacy (for the person/user-agent, not only xCDN) consequences of the extension.\" I'm assuming that we agree that it'd be a bad idea if e.g. some extension were defined that allowed a uCDN tell a dCDN to try to track and report on all of a user's activities. (Or at least, that'd need to be documented/justified.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-01 12:52:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-01 12:32:07-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required.  When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just vaguely gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-01 12:52:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-01 12:52:11-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required. Furthermore, if triggering Map-Requests is the concern, couldn't the packet still be delivered, without triggering a Map-Request? When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just vaguely gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-01 12:52:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-01 12:52:42-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required. Furthermore, if triggering Map-Requests is the concern, couldn't the packet still be delivered, without triggering a Map-Request? When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-24 14:15:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 12:52:57-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required. Furthermore, if triggering Map-Requests is the concern, couldn't the packet still be delivered, without triggering a Map-Request? When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice, thanks in advance. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-23 19:11:19-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 08:43:15-07:00",
    "text": "Changed my comments to a DISCUSS, as Donald Eastlake also pointed these out in his secdir review, and I am now convinced we need better text to address this. #1\u00a0 map-version rollover is defined (to skip the 0 version) but I also see: The packet arrives with a Dest Map-Version number greater (i.e., \u00a0 \u00a0 \u00a0  newer) than the one stored in the EID-to-RLOC Database.\u00a0 Since \u00a0 \u00a0 \u00a0  the ETR is authoritative on the mapping, meaning that the Map- \u00a0 \u00a0 \u00a0  Version number of its mapping is the correct one This would imply rollover to a smaller number is not expected to occur ? #2 MUST NOT or SHOULD ? Map-Versioning MUST NOT be used over the public Internet and SHOULD only be used in trusted and closed deployments. This sentence seems to contradict itself. I would turn the SHOULD into a MUST",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-07-13 14:04:50-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 11:54:49-07:00",
    "text": "On the -11 document, I initial wrote the following: The SECDIR review by Donald Eastlake asked about handling roll-over/wrap-around of the Map Version Number.\u00a0 Specifically, can a \u201cMap Version Number advance[e] \u2026 so quickly that an old version number is encountered that appears to be newer than or equal to the current version number. Why can't this happen? Or if it can, why doesn't that hurt?\u201d\u00a0 It would appear that a number of the conclusions of the ITR or ETR on arriving packets in Section 7.1 and 7.2 wouldn\u2019t be correct. I then saw the -12 document published on June 1 which added the following text to Section 7: \u00a0  Map Version Number incrementing \u00a0  and mappings' TTL MUST be managed so that an old version number will \u00a0  not be confused as a new version number. Thank you for adding this text.\u00a0 Practically, this identifies the desired intent, but doesn\u2019t seem describe the mechanics.\u00a0 Can more be said about how this confusion will be mitigated at the ITR/ETRs?\u00a0 I also don't follow how to use the TTLs here. Consider the situation that Donald noted where the Map Version advanced so quickly that it wraps around so that: (a) the new Map Version Number value equals the old Map Version Number.\u00a0 If one followed the guidance in Section 7.1 of: \u00a0  1.\u00a0 The packet arrives with the same Dest Map-Version number stored \u00a0 \u00a0 \u00a0  in the EID-to-RLOC Database.\u00a0 This is the regular case.\u00a0 The ITR \u00a0 \u00a0 \u00a0  sending the packet has in its EID-to-RLOC Map-Cache an up-to-date \u00a0 \u00a0 \u00a0  mapping.\u00a0 No further actions are needed. It would seem that the ITR wouldn\u2019t do a Map-Request and would misroute the packet based on the old mapping. (b) the new Map Version Number is now smaller (but in fact fresher/newer)\u00a0 If one followed the guidance of Section 7.1. of: 3.\u00a0 The packets arrive with a Dest Map-Version number smaller (i.e., \u00a0 \u00a0 \u00a0  older) than the one stored in the EID-to-RLOC Database.\u00a0 This \u00a0 \u00a0 \u00a0  means that the ITR sending the packet has an old mapping in its \u00a0 \u00a0 \u00a0  EID-to-RLOC Map-Cache containing stale information. Per bullet #3, if there was wrap-around would the ITR in fact be sending stale mapping information?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-01 15:48:58-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 00:29:46-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of concerns that need to be cleared up before the document can move forward. --------------------------------------------------------------------------- \u00a74.3.4 discusses the interaction of 3PCC with the trickle ICE mechanism. Unfortunately, the diagrams used in this section do not show a 3PCC signaling flow; they show a two-party call flow with an offerless INVITE. A 3PCC call flow would necessarily involve a 3PCC controller sending an offerless INVITE to one party, receiving an offer from that party (typically in a reliable provisional response or in a 200 OK), and then sending an INVITE to the other party containing that offer. The text in this section matches the diagrams, and consequently does not appear to be an analysis of 3PCC behavior. It is an analysis of two-party offerless INVITE behavior. If this section remains, it needs to be substantially re-worked: the diagrams need to show three parties, with a 3PCC controller performing the controlling role as described in  RFC 3725 . While I haven't stepped through the implications for Trickle ICE when a controller is actually involved and is moving offers and answers around between different message types, I suspect that the analysis in here is substantially different once this starts happening. I would personally be okay if the entire section were removed; however, I have no desire to override working group consensus regarding the value of a section dealing with 3PCC considerations. --------------------------------------------------------------------------- The second issue doesn't necessarily pertain to this document per se as much as it does the interaction among this document,  draft-ietf-ice-trickle  (Trickle ICE),  draft-ietf-mmusic-ice-sip-sdp  (ICE SDP), and  draft-ietf-rtcweb-jsep (JSEP). The problem doesn't lie with any single document, but in the overall result of how they're currently structured. JSEP (in the RFC editor queue) refers to the \"a=end-of-candidates\" SDP attribute as appearing in Trickle ICE, section 9.3, which was true at one point in time. Somewhere along the line, this attribute's definition was moved from there into this document. There are several ways to fix this, each with their own drawbacks: 1. Move the SDP syntax for \"a=end-of-candidates\" back into the Trickle ICE \u00a0  draft. Drawback: Trickle ICE does not currently define any normative SDP \u00a0  behavior; and, in fact, could work in a system that doesn't use SDP at all. 2. Move the SDP syntax into the ICE SDP draft. This is pretty elegant from the \u00a0  perspective that ICE SDP defines SDP syntax for ICE in general (for both \u00a0  SIP and JSEP), and such a move aggregates all of the SDP syntax into a \u00a0  single document that is already necessary to reference from any document \u00a0  that uses SDP for Trickle ICE. Drawback: the document doesn't presently \u00a0  discuss Trickle ICE at all, and this would require a somewhat awkward \u00a0  section that basically says \"If you use [Trickle ICE] with SDP, the syntax \u00a0  for the end-of-candidate marker is...\" 3. Change JSEP to normatively depend on this document for the \u00a0  \"a=end-of-candidates\" syntax. Drawback: This document is extremely \u00a0  SIP-specific, while JSEP is based solely on  RFC 4566  syntax and  RFC 3264 \u00a0  behavior, independent of any SIP semantics.\u00a0 Forcing JSEP to normatively \u00a0  depend on a SIP specific document for a simple attribute syntax definition \u00a0  seems to be letting the tail wag the dog. I believe that #2 is the least inelegant option, but I'm open to #1 and #3. However, The *current* situation -- in which JSEP normatively points to a document from which the text is cites has been removed out from under it -- is clearly wrong.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-22 13:43:11-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-01 15:48:58-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of concerns that need to be cleared up before the document can move forward. --------------------------------------------------------------------------- \u00a74.3.4 discusses the interaction of 3PCC with the trickle ICE mechanism. Unfortunately, the diagrams used in this section do not show a 3PCC signaling flow; they show a two-party call flow with an offerless INVITE. A 3PCC call flow would necessarily involve a 3PCC controller sending an offerless INVITE to one party, receiving an offer from that party (typically in a reliable provisional response or in a 200 OK), and then sending an INVITE to the other party containing that offer. The text in this section matches the diagrams, and consequently does not appear to be an analysis of 3PCC behavior. It is an analysis of two-party offerless INVITE behavior. If this section remains, it needs to be substantially re-worked: the diagrams need to show three parties, with a 3PCC controller performing the controlling role as described in  RFC 3725 . While I haven't stepped through the implications for Trickle ICE when a controller is actually involved and is moving offers and answers around between different message types, I suspect that the analysis in here is substantially different once this starts happening. I would personally be okay if the entire section were removed; however, I have no desire to override working group consensus regarding the value of a section dealing with 3PCC considerations. [document reference issue removed -- this document will probably not need to change to address the issue]",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-06-29 14:35:02-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-02 15:54:24-07:00",
    "text": "\u00a0  the Offer (as would be the case when Half Trickle is performed or \u00a0  when new candidates have not been learned since then). IMPORTANT: They must be in order, right? \u00a0  'application/trickle-ice-sdpfrag' bodies do not interfere with the \u00a0  Offer/Answer procedures as specified in [ RFC3264 ]. IMPORTANT: \"pseudo\" m= lines are not defined in 5888 so this is very unclear. \u00a0  sent under the same combination of \"a=ice-pwd:\" and \"a=ice-ufrag:\" in \u00a0  the same order as they were gathered.\u00a0 In other words, the sequence \u00a0  of a previously sent list of candidates MUST NOT change in subsequent IMPORTANT: This appears to conflict with the guidance in Section 6 of the trickle document, which is about reordering candidates from how they were gathered.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-07-02 01:49:55-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-03 07:36:54-07:00",
    "text": "Thanks for the well-written doc and the quick response to the initial tsv review. Also thanks to J\u00f6rg for the thorough and very helpful review! As flagged by the tsv review, there can be an issue with the aggregation of candidates in one INFO message when rate limited and the path MTU/UPD fragmentation. While this is a small point only and I'm sure it can be easily addressed, it important enough that I decided to put a discuss in. I'm sure this can be resolved quickly as well.  Also if the document could give further guidance on an acceptable maximum for the rate of INFO requests that be even better!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-11 15:29:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-03-23 21:43:27-07:00",
    "text": "I think we need some greater clarity on the relationship between IOAM \"layers\" and IOAM-Namespaces.\u00a0 For example, in Section 4 there is a principle of \"Layering\" that seems to indicate that different layers operate entirely independently, such as might occur when traffic from one operator that uses IOAM is conveyed in a tunnel over a different operator's network and both operators use IOAM independently.\u00a0 But in Section 5.3 we seem to see some discussion that IOAM-Namespaces can be used to enforce a separation of layers (\"IOAM-Namespaces provide additional context [...] e.g. if an operator wishes to use different node identifiers for different IOAM layers\"), and that namespace identifiers allow for determination of which IOAM-Option-Types need to be processed \"in case of a layered IOAM deployment\". I think there is also some internal inconsistency relating to the role of IOAM transit nodes.\u00a0 This may be localised in Section 5.2 where we see both that a transit node is one that \"read and/or write or process [the] IOAM data\" and that a transit node \"updates one or more of the IOAM-Data-Fields\" (i.e., always writes), but I did not attempt an exhaustive check for other instances. I don't think the definition of the POSIX epoch is correct -- it seems to be copied (roughly) from the definition of the PTP epoch (i.e., using midnight TAI as the reference) but all the references I consulted indicate that the POSIX epoch started at midnight UTC. As foreshadowed in https://mailarchive.ietf.org/arch/msg/last-call/Ak2NAIKQ7p4Rij9jfv123xeTXQY/ I think we need to have a discussion about the expectations and provisions for cryptographic (e.g., integrity) protection of IOAM data. From my perspective, IOAM is a new (class of) protocols that is seeking publication on the IETF stream as Proposed Standard.\u00a0 While we do make exceptions for modifications to protocols that were developed before we realized how important integrated security mechanisms are, it's generally the case that new protocols are held to the current IETF expectations for what security properties are provided; the default expectation is that a protocol is expected to provide secure operation in the internet threat model of  RFC 3552 .\u00a0 This draft currently only provides a brief note in the security considerations that there exists an individual draft ( draft-brockners-ippm-ioam-data-integrity ) that might provide ways to protect the integrity of IOAM data fields. Shouldn't the security mechanisms be getting developed side-by-side by the protocol mechanisms, to ensure that they are properly integrated and fit for purpose?\u00a0 (This does not necessarily have to be in the same document and could be part of a cluster of related documents, but I don't think that an informative reference to a non-WG draft really qualifies.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-08 14:38:52-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-11 15:29:47-07:00",
    "text": "Thanks for the many updates and email discussion about the relationship between limited (network) domains, IOAM domains, IOAM namespaces, and the like -- I think I do now have a pretty clear picture of how they're expected to interact!\u00a0 However, I think there may still be a couple places in the document that need to get updated in order to match that vision.\u00a0 One point here, and some (more minor) instances in the COMMENT section... Section 5.2 has: \u00a0  The role of an IOAM-encapsulating, IOAM-transit or IOAM-decapsulating \u00a0  node is always performed within a specific IOAM-Namespace.\u00a0 This \u00a0  [...] \u00a0  described above, that is added in a future revision.\u00a0 An IOAM \u00a0  decapsulating node situated at the edge of an IOAM domain MUST remove \u00a0  all IOAM-Option-Types and associated encapsulation headers for all \u00a0  IOAM-Namespaces from the packet. The \"MUST remove [...] for all IOAM-Namespaces\" at the end seems to conflict with the notion of the role of IOAM-decapsulating node being performed within a specific IOAM-Namespace.\u00a0 Indeed, later on in Section 5.3 we see that namespace identifiers \"allow devices which are IOAM capable to determine: [...] o\u00a0 whether IOAM-Option-Type(s) have to be removed from the packet, e.g., at a domain edge or domain boundary.\"\u00a0 If a decapsulating node always had to remove IOAM options from all namespaces, then the namespace identifier is irrelevant to whether option type(s) are removed from the packet. [the following paragraph is retained unchanged from my ballot position on the -12, since the topic seems to still be open.] As foreshadowed in https://mailarchive.ietf.org/arch/msg/last-call/Ak2NAIKQ7p4Rij9jfv123xeTXQY/ I think we need to have a discussion about the expectations and provisions for cryptographic (e.g., integrity) protection of IOAM data. From my perspective, IOAM is a new (class of) protocols that is seeking publication on the IETF stream as Proposed Standard.\u00a0 While we do make exceptions for modifications to protocols that were developed before we realized how important integrated security mechanisms are, it's generally the case that new protocols are held to the current IETF expectations for what security properties are provided; the default expectation is that a protocol is expected to provide secure operation in the internet threat model of  RFC 3552 .\u00a0 This draft currently only provides a brief note in the security considerations that there exists an individual draft ( draft-brockners-ippm-ioam-data-integrity ) that might provide ways to protect the integrity of IOAM data fields. Shouldn't the security mechanisms be getting developed side-by-side by the protocol mechanisms, to ensure that they are properly integrated and fit for purpose?\u00a0 (This does not necessarily have to be in the same document and could be part of a cluster of related documents, but I don't think that an informative reference to a non-WG draft really qualifies.) [new disucssion on this topic as of the -15] The discussion on this topic was over a rather protracted timescale, for which I share much of the blame.\u00a0 I think that the latest message is https://mailarchive.ietf.org/arch/msg/ippm/POycw2NpSl5cIruqSimTa_4WrwI/ where I make a proposal to have some text about how actual use of these data fields in a protocol or encapsulation needs to provide some (possibly optional) mechanism for cryptographic integrity protection, which could be  draft-brockners-ippm-ioam-data-integrity  but could also be native to the encapsulation format.\u00a0 I think that such a construction would allow this document to proceed to RFC without waiting for the other one to be complete.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-03-26 07:28:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-03-24 12:04:41-07:00",
    "text": "Thank you for this document. I think that the discussion on point 5. about referencing normatively IEEE 1588, and 11. about IANA Expert guidelines are worth having, and hope we can get them cleared before the document moves forward. Also, please find some minor comments below.  Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-06-24 11:24:55-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-26 07:28:53-07:00",
    "text": "EDIT(2021-03-26): I removed the question about IEEE1588v2 being normative. I look forward to discussion about 11., i.e. more details about IANA Expert guidelines. ---------- (2021-03-24) Thank you for this document. I think that the discussion on point 5. about referencing normatively IEEE 1588, and 11. about IANA Expert guidelines are worth having, and hope we can get them cleared before the document moves forward. Also, please find some minor comments below.  Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-08-18 23:24:57-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-25 05:29:41-07:00",
    "text": "Section 5.4, paragraph 6, discuss: >\u00a0 \u00a0 A particular implementation of IOAM MAY choose to support only one of >\u00a0 \u00a0 the two trace option types.\u00a0 In the event that both options are Not requiring at least one mandatory-to-implement trace option type is highly problematic, since it creates two incompatible flavors of this standard. Preventing bifurcation seems to trump the desire for allowing (minor?) optimizations.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-03-25 00:47:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-03-25 00:15:03-07:00",
    "text": "I'd also like to discuss what's going on in Section 8. Section 8.1, for instance, says that the registry covers 128 code points.\u00a0 The first seven entries are given, but it's not explicit that a registration comprises a code point and (apparently) a name.\u00a0 It's more typical to include a template that a new registration needs to include.\u00a0 You might require a requested code point number and a name at minimum, but also commonly included in such a template is a reference to the registering RFC.\u00a0 If I were to register a code point here in some later RFC, it would be awfully convenient to have the registry include a reference to that defining document.\u00a0 As it stands, the registry will only ever point to this one.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-08-11 22:07:08-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-25 00:47:57-07:00",
    "text": "I'd also like to discuss what's going on in Section 8. Section 8.1, for instance, says that the registry covers 128 code points.\u00a0 The first seven entries are given, but it's not explicit that a registration comprises a code point and (apparently) a name.\u00a0 It's more typical to include a template that a new registration needs to include.\u00a0 You might require a requested code point number and a name at minimum, but also commonly included in such a template is a reference to the registering RFC.\u00a0 If I were to register a code point here in some later RFC, it would be awfully convenient to have the registry include a reference to that defining document.\u00a0 As it stands, the registry will only ever point to this one. You might want to give  RFC 8126  a once-over, at least Section 2.2.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-10-04 04:56:21-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 08:05:49-07:00",
    "text": "Please clarify what constitutes the edge or boundary of the IOAM domain.\u00a0 Consider: (a) Section 4.\u00a0   IOAM is a \u00a0  network domain focused feature, with \"network domain\" being a set of \u00a0  network devices or entities within a single administration.\u00a0  \u2026 Designers of  \u00a0  protocol encapsulations for IOAM specify mechanisms to ensure that \u00a0  IOAM data stays within an IOAM domain.\u00a0 In addition, the operator of \u00a0  such a domain is expected to put provisions in place to ensure that \u00a0  IOAM data does not leak beyond the edge of an IOAM domain. (b) Section 5.3.\u00a0  Namespace identifiers allow devices which are IOAM capable to \u00a0  determine: \u2026 whether IOAM-Option-Type(s) has to be removed from the packet, \u00a0 \u00a0 \u00a0 e.g. at a domain edge or domain boundary. (a) suggests that the filtering occurs on the basis of the single administrative domain.\u00a0 However, (b) suggests that namespace identifiers are part of the filtering decision; which suggests that sub-domains can be created in a given domain which should be partitioned from each other. The Security Considerations should be clearer on who does the IOAM information filtering, on what criteria and on what boundary.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-01-23 10:31:23-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-20 10:16:11-08:00",
    "text": "The acknowledgement to the authors of  I-D.ietf-pce-lsp-control-request  prompted me to go take a look at that document and refresh my mind on the fact that it defines a new flag called LSP-Control Request Flag (C).\u00a0 I find it hard to resolve in my mind when it would make sense for the R (LSP REMOVE from  rfc8281 ) and C flags to be set at the same time.\u00a0  I couldn't find in  rfc8231 /rfc8281/I-D.ietf-pce-lsp-control-request or this document any discussion about the ability (or not) to set more than one Flag at a time. In line with it's title, I would like to see this document include rules about processing of multiple flags.\u00a0 I know that it is not possible to set out rules for the interaction of yet-to-be-defined flags, but at least adding text to the effect of \"documents defining additional flags MUST discuss how they interact with existing flags\" would go a long way. I am balloting DISCUSS because even though this document is not introducing new issues, the combination of what is defined in  rfc8231 /rfc8281/I-D.ietf-pce-lsp-control-request does...and a document titled \"Updated Rules for Processing Stateful PCE Request Parameters Flags\" is then the optimal place to address them. [Aside: If this DISCUSS is resolved as suggested above, then  I-D.ietf-pce-lsp-control-request , which is on the RFC EDitor's queue, will have to be updated.]",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-12-04 14:02:17-08:00",
    "end_reason": "position_updated",
    "start": "2019-11-25 18:56:21-08:00",
    "text": "ection 5. A typo in the object identifier of the \u201ccbor\u201d entry of \u201cCMS Inner Content Types\u201d \u2013 s/1.2.840.113549.1.9.16.1.TBD/1.2.840.113549.1.9.16.1.TBD1/ (i.e., s/TBD/TBD1/)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-23 14:30:57-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-09 08:57:04-07:00",
    "text": "Based on the feedback provided by the tsv-art review (Thanks Colin!) I would like to see a paragraph or short section that discusses how replication as used in section 3.2 and 3.3 can impact multicast congestion control and also provides a pointer to  draft-ietf-tsvwg-ecn-encap-guidelines-09  in case ECN is supported in the NVO network which can likely be the case in data center scenarios.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-06-20 12:21:57-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-20 12:21:44-07:00",
    "text": "Document:  draft-ietf-pals-p2mp-pw-lsp-ping-03.txt Assuming I am understanding this document correctly, it's just a refinement of MPLS Echo to point out a specific receiver to respond. Is that correct? If so, perhaps you could make that clear in the intro. This document is pretty acronym heavy. Please ensure that every acronym is expanded on first use. Examples include LSP, VPN, VPLS, etc. Similarly, LSP Tail/Bud, etc. need citations. Figure 2 would benefit from some explanations of the packet flow. Where does the echo packet start, where does it stop? Who answers, etc.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-08-10 22:09:54-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-19 11:12:27-07:00",
    "text": "I think the P2MP Pseudowire Sub-TLV in Section 4.1 is a bit under-specified. It is unclear how the address family of the originating router's IP address is communicated. Is this purely derived from the IP Addr Len (i.e. Len is 4 => IPv4, Len is 16 => IPv6)? If so, I think it would be useful to state this explicitly and add some validity checking and error handling for values other than 4 and 16.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-02 03:08:48-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-03-02 03:08:30-08:00",
    "text": "(1) In section 10 you have a MUST for integrity and confid, which is good, but then RECOMMEND S/MIME, which is, I think, mythical. Wouldn't it be better to reflect reality (hop-by-hop TLS) and then say what actual security considerations arise, e.g. who might be on the path and how can be (mis)behave? (2) 6.10: Don't you need to say to use UUID version 4 with random numbers and to not use MAC addresses?\u00a0 IOW, refer to RFC4122 , Section 4.4 for how to generate UUIDs.  Note that issues related to both of the above were part of the discussion that ensued from the secdir review. [1] \u00a0  [1]  https://www.ietf.org/mail-archive/web/secdir/current/msg06370.html",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-19 03:26:26-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-02 03:08:48-08:00",
    "text": "(1) In section 10 you have a MUST for integrity and confid, which is good, but then RECOMMEND S/MIME, which is, I think, mythical. Wouldn't it be better to reflect reality (hop-by-hop TLS) and then say what actual security considerations arise, e.g. who might be on the path and how can they (mis)behave? (2) 6.10: Don't you need to say to use UUID version 4 with random numbers and to not use MAC addresses?\u00a0 IOW, refer to RFC4122 , Section 4.4 for how to generate UUIDs.  Note that issues related to both of the above were part of the discussion that ensued from the secdir review. [1] \u00a0  [1]  https://www.ietf.org/mail-archive/web/secdir/current/msg06370.html",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-08-04 12:17:20-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-02 20:03:40-07:00",
    "text": "I have a couple of items I would like to discuss before this progresses. I think these should be reasonably easy to resolve: - 8.1.1: The first paragraph requires support for MD5 and MD5-sess, and has no discussion of other algorithms.\u00a0 But the reference has been updated to  RFC 7616 , which is not quite compatible with that guidance. 7616 deprecates MD5, but allows it for backwards compatibility. It also makes SHA2-256 MTI. I realize there may be backwards compatibility issues, but I think the text should at least discuss the issue and encourage people to move away from md5. -9 If I read this section correctly, it requires (at SHOULD level) IPP/1.1 implementations to understand and correctly respond to IPP/2.X messages. How is this different from saying they SHOULD implement 2.X, but be backwards compatible with 1.1? ( I think this also applies to 2911bis).",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-08-05 13:16:27-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-01 11:48:22-07:00",
    "text": "Thanks for your work updating this draft.\u00a0 I'd like to discuss the TLS recommendations to either see if we can change them or to improve the text and warnings around why TLS is recommended. Section 8.1.1 #2 \u00a0 I'm not sure why this is a reason why TLS is just a SHOULD.\u00a0 This seems to be a reason for it being a MUST.\u00a0 Is this just a text formatting issue?\u00a0 Should #2 be under a different heading? Sections 8.1.1 & 8.1.2: Preference: Could the text be re-written to have TLS as a MUST unless restrictions of the device make it so it is not possible or feasible?\u00a0 Not having TLS for authentication at least is a really bad idea.\u00a0 If it is just a SHOULD, when it is possible, developers may opt to not use TLS when there is no reason.\u00a0  If TLS stays as a SHOULD, I'd like to see stronger language around why it is recommended for use as the security considerations section only really talks about why it is not a MUST.\u00a0 It would be good to have sufficient motivation for developers and implementers to do the right thing.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-07-02 14:21:45-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-20 21:40:52-07:00",
    "text": "Thanks for the work and thought that everyone involved in this document spent. I find the model well described and easy to understand. I agree with Ben's comments about including more information about the privacy and security properties of specific entities in the module. See https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines  for specific guidance. Since this conflicts with normative language in  RFC 6087  \u00a73.4 (and 6087bis \u00a73.7), it is a blocking defect that needs to be remedied prior to publication.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-06-20 08:50:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-20 08:40:01-07:00",
    "text": "Operational state. Section 2 defines operational aspects of the configured TWAMP mechanisms as being out of scope. How does that relate to the motivation goals in section 1? Having no common machine readable mechanism for retrieving measurement results and verifying the operation of measurement processes does not seem to help in reducing the need for proprietary mechanisms.  If operational aspects are not out of scope, what is the compatibility of this model with NMDA?  Key storage. The document defines its own way of storing keys - while there are multiple existing ways to store keys (routing key-chain model, I2NSF, IPsec model, netconf-keystore). Why yet another key storage mechanism is required?",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-06-26 09:34:06-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-20 08:50:10-07:00",
    "text": "I have three large areas of questions related to this model. They are not related to the contents of the module itself but to the broader scope of where this model can and should fit in the overall context of practical manageability and usability.  1. Operational state. Section 2 defines operational aspects of the configured TWAMP mechanisms as being out of scope. How does that relate to the motivation goals in section 1? Having no common machine readable mechanism for retrieving measurement results and verifying the operation of measurement processes does not seem to help in reducing the need for proprietary mechanisms.  2. What is the compatibility of this model with NMDA?  3. Key storage. The document defines its own way of storing keys - while there are multiple existing ways to store keys (routing key-chain model, I2NSF, IPsec model, netconf-keystore). Why yet another key storage mechanism is required? What could be reused from other existing mechanisms?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-03-11 07:38:26-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-27 10:23:16-07:00",
    "text": "First of all, I am surprised that a document related to IGMP/MLD was not sent to the pim WG for review.\u00a0 I can't find any mention of this draft in the pim WG's archive. \u00a711 says this: \u00a0  This document does not provide any detail about IGMPv1 processing. \u00a0  Multicast working group are in process of deprecating uses of IGMPv1. \u00a0  Implementations MUST only use IGMPv2 and above for IPv4 and MLDv1 and \u00a0  above for IPv6.\u00a0 IGMP V1 routes MUST be considered as invalid and the \u00a0  PE MUST apply the \"treat-as-withdraw\" procedure as per [ RFC7606 ]. \u00a0  Initial version of document did mention use of IGMPv1 and flag had \u00a0  provision to support IGMPv1.\u00a0 There may be an implementation which is \u00a0  deployed as initial version of document, to interop flag has not been \u00a0  changed. Note that the \"Multicast working group\" mentioned above is in fact the pim WG.\u00a0 There's no current WG to deprecate IGMPv1, but  draft-ietf-pim-3376bis  was recently adopted with the intent to progress IGMPv3 to Internet Standard.\u00a0 This text is from  draft-ietf-pim-3376bis  (it is the same text as in  rfc3376 ): \u00a0  IGMPv3 is backward compatible with previous versions of the IGMP \u00a0  protocol.\u00a0 In order to remain backward compatible with older IGMP \u00a0  systems, IGMPv3 multicast routers MUST also implement versions 1 and \u00a0  2 of the protocol (see section Section 7). (Section 7/draft-ietf-pim-3376bis talks about interoperability with older versions.) All this is to say that requiring that IGMPv1 not be used contradicts the IGMPv3 specification, which requires the support.\u00a0 The interoperation between the different versions is already considered in  rfc3376 , so the extra complexity added to this document (tracking the versions in the BGP updates) is not needed from the router side. I am balloting DISCUSS because this document is not in line with other consensus documents (specifically the IGMP specification).\u00a0 To clear, I will want the document reviewed by the pim WG.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-24 18:55:44-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-20 17:48:32-07:00",
    "text": "(1) Apparently each PE is supposed to store version flags for each other PE in the EVI (I guess on a per-route basis?), but this is mentioned just once, in passing, in step 2 of the Leave Group procedures in \u00a74.1.2. Similarly, \u00a76.1 defines, somewhat in passing, some \"local IGMP Membership Request (x,G) state\" that must be maintained in some cases. Let's discuss whether it's appropriate/useful to have a general introductory section that covers what new state PEs are expected to retain as part of supporting IGMP/MLD proxying.\u00a0 Maybe the answer is \"no\", but I would like to have the conversation. (2) I am not sure if the body text is consistent with what is being allocated from IANA.\u00a0 \u00a78 describes PEs that are not using ingress replication as being identifiable as \"\"\"any PE that has advertised an Inclusive Multicast Tag route for the BD without the \"IGMP Proxy Support\" flag\"\"\", but the IANA considerations allocate flags for both IGMP Proxy Support and MLD Proxy Support.\u00a0 Is a PE that advertises MLD Proxy Support but not IGMP Proxy Support to be treated as not using ingress replication, as the literal interpretation of this text would require?\u00a0 Similarly, \u00a79.2.1 and \u00a79.3.1 include restrictions on indication of support for \"IGMP Proxy\" with no mention of \"MLD Proxy\". I do see that there is a generic disclaimer at the end of Section 3 but the way it is written does not actually seem to cover this usage.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-04 03:58:21-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-20 01:28:09-07:00",
    "text": "Thank you for the work put into this document. I have to state that I am neither a EVPN expert not a multicast one. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to St\u00e9phane Litkowski for his shepherd's write-up about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == The text covers in details how to map MLD/IGMP into BGP routes but does not say a word on how to recreate the MLD/IGMP packets. Should there be any such specification ? Are all multicast group address treated as the same ? I would have appreciated some text about link-local multicast as well as global multicast groups addresses. -- Abstract -- While this point is pretty light for a blocking DISCUSS, let's fix it: - the abstract should also mention MLD and not only IGMP - what are 'the above services' ? -- Section 1 -- In the same vein, is it about IGMP only ? Or does it include MLD as well ? It is really unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-04 07:30:25-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-03-04 03:58:21-08:00",
    "text": "As Martin Vigoureux's term is near its end, I took the liberty to re-evaluate the ballot status of this document and clearing parts of my original block DISCUSS points and many of my original non-blocking COMMENT points. See below this line for updated version ---------------------------------------------- Thank you for the work put into this document. I have to state that I am neither a EVPN expert not a multicast one. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to St\u00e9phane Litkowski for his shepherd's write-up about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == The text covers in details how to map MLD/IGMP into BGP routes but does not say a word on how to recreate the MLD/IGMP packets. Should there be any such specification (e.g., in section 4.1) ? -- Section 1 -- In the same vein, is it about IGMP only ? Or does it include MLD as well ? It is really unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-07 23:32:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-04 07:30:25-08:00",
    "text": "As Martin Vigoureux's term is near its end, I took the liberty to re-evaluate the ballot status of this document and clearing parts of my original block DISCUSS points and many of my original non-blocking COMMENT points. See below this line for updated version ---------------------------------------------- Thank you for the work put into this document. I have to state that I am neither a EVPN expert not a multicast one. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to St\u00e9phane Litkowski for his shepherd's write-up about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 1 -- In the same vein, is it about IGMP only ? Or does it include MLD as well ? It is really unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-10-27 23:33:52-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-21 07:22:59-07:00",
    "text": "The IANA Considerations section needs some work: (0) I suggest making each of the actions you want to take (there are four) into their own subsections of this section. (1) \"EVPN Extended Community sub-types registry\" should be \"EVPN Extended Community Sub-Types sub-registry of the BGP Extended Communities registry\", which makes it easier to find. (2) \"Multicast Flags Extended Community\" appears to be a new registry you're creating in the final action here.\u00a0  BCP 26 , for a First Come First Served registry, advises that a change controller column be included.\u00a0 Are you intentionally omitting this here?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-03-22 05:12:25-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-27 23:33:52-07:00",
    "text": "There's an IPR disclosure on this document.\u00a0 In the shepherd writeup, where a summary of the discussion of it is requested, it simply says \"There are 3 IPRs disclosed\".\u00a0 I'd like to hear that summary, or at least confirm the discussion was had and there were no concerns as a result. The IANA Considerations section needs some work: (0) I suggest making each of the actions you want to take (there are four) into their own subsections of this section. (1) \"EVPN Extended Community sub-types registry\" should be \"EVPN Extended Community Sub-Types sub-registry of the BGP Extended Communities registry\", which makes it easier to find. (2) \"Multicast Flags Extended Community\" appears to be a new registry you're creating in the final action here.\u00a0  BCP 26 , for a First Come First Served registry, advises that a change controller column be included.\u00a0 Are you intentionally omitting this here?\u00a0 Or if this is referring to an existing registry, I wasn't able to find it.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-10-24 11:51:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-10-23 20:11:18-07:00",
    "text": "Thanks for the work on this document. I have one item that I want to make sure is discussed prior to publication, thus the DISCUSS position: This document lists all the SDP attributes as having an a Mux Category of \"TBD\".  draft-ietf-mmusic-sdp-mux-attributes  did indeed assign a category of \"TBD\" to all the attributes, save for bfcpver, which didn't exist at the time. But the point of \"TBD\" was to say that  draft-ietf-mmusic-sdp-mux-attributes  did not actually analyze the attributes to determine a \"real\" mux category. It's not intended as free pass to let other attribute definitions skip that analysis.\u00a0  Ideally, I think that this draft should assign a \"real\" mux category for each attribute in it. Failing that, it at least needs to do so for \"bfcpver\". I'm guessing that should be \"caution\" or \"special\". (Perhaps unfortunately,  draft-ietf-mmusic-sdp-mux-attributes  did not define a category of \"nope\" :-) )",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-11-27 14:46:25-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-10-24 11:51:28-07:00",
    "text": "Update: After a bit of discussion and a re-read of  draft-ietf-mmusic-sdp-mux-attributes , I see that, while the use of \"TBD\" does not seem consistent with the definition of TBD, it does seem consistent with the practice in mux-attributes of assigning a category of TBD to attributes associated with non-muxable protocols. I've sent an email to the MMUSIC WG for guidance on the intended use. In the process, I noticed that the category assignments in this draft do not match the existing assignments in mux-attributes, which marks \"floorctrl\" as \"TBD\", and the others as \"NORMAL\". This draft marks all attributes as \"TBD\". I am going to hold the DISCUSS position for now, until discussion of the use of TBD resolves a bit further, and until the assignment mismatch is corrected. Original DISCUSS text: Thanks for the work on this document. I have one item that I want to make sure is discussed prior to publication, thus the DISCUSS position: This document lists all the SDP attributes as having an a Mux Category of \"TBD\".  draft-ietf-mmusic-sdp-mux-attributes  did indeed assign a category of \"TBD\" to all the attributes, save for bfcpver, which didn't exist at the time. But the point of \"TBD\" was to say that  draft-ietf-mmusic-sdp-mux-attributes  did not actually analyze the attributes to determine a \"real\" mux category. It's not intended as free pass to let other attribute definitions skip that analysis.\u00a0  Ideally, I think that this draft should assign a \"real\" mux category for each attribute in it. Failing that, it at least needs to do so for \"bfcpver\". I'm guessing that should be \"caution\" or \"special\". (Perhaps unfortunately,  draft-ietf-mmusic-sdp-mux-attributes  did not define a category of \"nope\" :-) )",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-12-21 12:53:47-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-27 14:46:25-08:00",
    "text": "The category assignments in this draft do not match the existing assignments in mux-attributes, which marks \"floorctrl\" as \"TBD\", and the others as \"NORMAL\". This draft marks all attributes as \"TBD\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-25 04:44:39-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 17:18:36-07:00",
    "text": "I will go ahead and say that we should discuss the \"UDP/TLS/BFCP\" naming. In particular, while I see the previous discussion that there may be existing deployments out there, why can we not give it the same treatment as \"mstrm\", and make the official name \"UDP/DTLS/BFCP\" while documenting that you should accept the old name? We also had a very long discussion about the usage of the term \"initial  offer\" in the context of  draft-ietf-mmusic-sdp-bundle-negotiation ; I do not propose to rehash that discussion, but want to ask whether we should stick to the established precedent with regard to the use of the term (which, IIUC, would involve a change to this document).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-11-21 14:33:29-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 12:23:33-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4457 DETAIL S 9. >\u00a0 \u00a0 \u00a0 transport is used for the default candidate, then the 'm' line proto >\u00a0 \u00a0 \u00a0 value MUST be 'UDP/TLS/BFCP'.\u00a0 If TCP transport is used for the >\u00a0 \u00a0 \u00a0 default candidate, the 'm' line proto value MUST be 'TCP/DTLS/BFCP'. >\u00a0   >\u00a0 \u00a0 \u00a0 \u00a0  Note: Usage of ICE with protocols other than UDP/TLS/BFCP and >\u00a0 \u00a0 \u00a0 \u00a0  TCP/DTLS/BFCP is outside of scope for this specification. this is very different from any other use of ICE, and I'm not sure it's interoperable, unless you require that only TCP or only UDP candidates be offered (which you do not seem to). The reason is that with ICE you can flip between different candidates as part of the negotiation. So what happens if I initially get a UDP candidate and then via aggressive nomination settle on TCP (or vice versa). DTLS and TLS aren't really interoperable in that way. It would be far better to do what WebRTC does and when you do ICE, always do DTLS even if it's over TCP.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-04-07 07:26:19-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 07:29:00-07:00",
    "text": "Thank you for the work on this document. I have noticed one easy to fix error in the examples, and I additionally have two comments I'd like to talk about before the document is approved - these are non blocking, but answers are appreciated. Thanks, Francesca 1. ----- \u00a0  In this case, an interface named \"Bundle-Ether1\" of interface type \u00a0  \"ieee8023adLag\" has a desired transmit interval and required receive \u00a0  interval set to 10 ms. FP: But the example actually uses intervals of 100ms: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  100000 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  100000 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-04-07 06:55:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 09:39:46-07:00",
    "text": "Thanks for this specification. I have noticed couple of potentially normative missing references hence the discuss ballot. * iana-bfd-types is imported from  RFC9127 \u00a0 but missing in the normative reference. * ietf-key-chain is imported from  RFC8177 \u00a0 but missing in the normative reference. I hope a revised ID\u00a0 would solve this.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-10-07 00:13:33-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 08:41:09-07:00",
    "text": "In Section 9: o\u00a0 For certificate-based authentication, a pre-populated trust anchor \u00a0 \u00a0 \u00a0 store [ RFC6024 ] allows a TURN client to perform path validation \u00a0 \u00a0 \u00a0 for the server certificate obtained during the (D)TLS handshake. \u00a0 \u00a0 \u00a0 If the client used a domain name to discover the TURN server, that \u00a0 \u00a0 \u00a0 domain name also provides a mechanism for validation of the TURN \u00a0 \u00a0 \u00a0 server.\u00a0 The client MUST use the rules and guidelines given in \u00a0 \u00a0 \u00a0 section 6 of [ RFC6125 ] to validate the TURN server identity. I am glad that you are referencing  RFC 6125 , but unfortunately you don't provide enough details. Please add details as specified in Section 3 of  RFC 6125  to your document.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-10-11 13:43:08-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 18:24:21-07:00",
    "text": "-9, first paragraph says:  \"Use of Session Traversal Utilities for NAT (STUN) [ RFC5389 ] \u00a0  authentication is OPTIONAL for TURN servers provided by the local \u00a0  network or by the access network.\u00a0 A network provided TURN server MAY \u00a0  be configured to accept Allocation requests without STUN \u00a0  authentication, and a TURN client MAY be configured to accept \u00a0  Allocation success responses without STUN authentication from a \u00a0  network provided TURN server. \" This seems to relax the MUST level requirement in  RFC 5766  that says TURN MUST use STUN long-term credential authentication, or use some other equally strong mechanism. From a purely process perpective, this would either require an update to 5766, or it would require an argument that the local/access network is somehow equally protected. I think the latter would only be true if the access network has some sort of protection beyond just being the access network (e.g. a vpn, ipsec, or physical isolation.)\u00a0 I don't recall seeing text that suggested any of those. But in any case, I think relaxing that requirement needs some discussion about how the server or client can be sure that all communication is in fact constrained to the local network.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-10-07 07:33:22-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-29 06:49:51-07:00",
    "text": "This should be easy to resolve.\u00a0 In reading the draft, it doesn't cover any mechanism for the TURN server to limit what clients can discover it.\u00a0 For the second and third method, it seems like there are possible ways to do this.\u00a0 Could these be added to the security considerations?\u00a0 You'd need to state that this isn't possible with the first method.\u00a0 If there is a reason why it is always okay to discover a TURN server, please let me know why this is not appropriate to add.\u00a0 Thanks.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-10-05 19:35:51-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-31 21:18:23-07:00",
    "text": "* Section 4.1.1. The DHCP procedure is underspecified. I think this can be easily fixed but it requires some work.  Please describe what sort of messages you would be using. i.e. are you going for a stateful exchange to piggy pack with other address and config information or are you going for a stateless Information-request based exchange(Most likely). Is there an ORO? If so, what options are requested in the ORO? Are there multiple request-response round trips as implied by the text?",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2017-02-08 22:39:43-08:00",
    "end_reason": "position_updated",
    "start": "2016-08-30 18:15:43-07:00",
    "text": "in requesting special use assignments, please read the registries and provide guidance on the scope of the allocations i.e. \u00a0  o\u00a0 Source - A boolean value indicating whether an address from the \u00a0 \u00a0 \u00a0 allocated special-purpose address block is valid when used as the \u00a0 \u00a0 \u00a0 source address of an IP datagram that transits two devices. \u00a0  o\u00a0 Destination - A boolean value indicating whether an address from \u00a0 \u00a0 \u00a0 the allocated special-purpose address block is valid when used as \u00a0 \u00a0 \u00a0 the destination address of an IP datagram that transits two \u00a0 \u00a0 \u00a0 devices. \u00a0  o\u00a0 Forwardable - A boolean value indicating whether a router may \u00a0 \u00a0 \u00a0 forward an IP datagram whose destination address is drawn from the \u00a0 \u00a0 \u00a0 allocated special-purpose address block between external \u00a0 \u00a0 \u00a0 interfaces. \u00a0  o\u00a0 Global - A boolean value indicating whether an IP datagram whose \u00a0 \u00a0 \u00a0 destination address is drawn from the allocated special-purpose \u00a0 \u00a0 \u00a0 address block is forwardable beyond a specified administrative \u00a0 \u00a0 \u00a0 domain.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-03-07 07:24:23-08:00",
    "end_reason": "position_updated",
    "start": "2018-03-06 12:24:59-08:00",
    "text": "I'm having trouble understanding what function this specification serves given that the RBridge Channel Protocol registry has a range reserved already for private use and that the document doesn't specify any requirements around vendor-specific protocol semantics. So any implementation of this that needs to interoperate with another implementation will need to do so according to some specification generated by the vendor, and that specification can select a code point from the private use range. What does allocating a single code point for all such vendor-specific protocols achieve, aside from specifying a structured way of conveying the OUI/CID (which seems superfluous anyway for multiple implementations from a single vendor interoperating with each other)?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-08-04 08:33:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-04 05:27:02-07:00",
    "text": "Thanks for making TLS a MUST-use in section 10. However, that makes me wonder why it's ever ok to not use TLS on the other side of the MSRP relay. I assume that's  down to deployments that can't ensure TLS on both sides but that then raises some questions for me that I didn't see answered in the document, so I'd like to briefly check/chat-about those... (and also to ask if you can up the ante as well:-) (1) When both sides of the MSRP relay do want TLS, but the MSRP-relay-as-TLS-client fails to setup the \"righthand\" (referring to the draft's diagrams) TLS session, say because of a bad cert, what does the browser see? (That may be entirely obvious to someone who knows MSRP and need no change in the draft, but it wasn't clear to me.) (2) If the \"righthand\" MSRP session is not protected with TLS, then is that fully under the control of the client/browser? IOW, how does the browser/client express a desire that it really really wants TLS on both sides or else to fail?\u00a0 I think that's down to using msrps URIs but am not sure.\u00a0 Again that might be clear to anyone who knows MSRP but I don't:-) Can you clarify?  (3) The answer is probably \"no\" but would it be feasible to say that a client for this MUST only use msrps: URIs? If it were feasible, that'd be good I think. If it's not feaasible, that's a pity, but I'm not asking that you add pretend statements about security we won't get;-)",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-09 07:24:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 04:44:07-07:00",
    "text": "This is a process discuss.  There apparently have been a failure to coordinate this with IEEE per discussion on the IETF-IEEE mailing list.  Glenn Parsons requested that this was deferred to give IEEE time to review it at their plenary next week. I think this time should be given before approving this document.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-17 09:50:12-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 05:12:36-07:00",
    "text": "I support Magnus's discuss regarding IEEE 802.1Q WG review. I also feel that the YANG model could benefit from another editorial pass:  - In many places the descriptions are very terse, and references are missing.  - The way that auto-neg is defined doesn't really match the 802.3 specification, probably splitting it into two separate leaves (one for whether auto-neg is on/off, and separate one for the duplex setting would be better).  - The use of terminology for VLAN vs QinQ might not be acceptable to IEEE.\u00a0 Finding names that are more closely aligned with the terms in 802.1Q may be helpful (although if I understand it correctly, 802.1Q bridges don't directly expose double VLAN tags).\u00a0 Possibly some of the terminology/description from  draft-ietf-netmod-sub-intf-vlan-model  (which has been reviewed by IEEE 802.1Q WG) may be helpful here.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-10-09 12:38:56-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-08 19:11:52-07:00",
    "text": "I'm glad to see this registry finally being set up, and want to thank everyone who helped get the document ready. I understand that this has been a large archaeological undertaking, and that the relatively small size of the document belies the large amount of actual work that went into it. I have one top-level concern about the registry, a handful of proposed corrections to the initial table, and some very minor editorial nits. I present the following feedback in that order. --------------------------------------------------------------------------- I have some very strong concerns about the handling for the \"URI\" RRTYPE. As far as I can tell, the entries in the initial table were formed by starting with the entries in https://www.iana.org/assignments/enum-services/enum-services.xhtml , adding the most popular entries from https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml , (\"dccp\", \"sctp\", \"tcp\", and \"udp\") and removing \"web\". Please note that it is entirely possible that I've missed an important detail here, and am merely confused. My top-line concern is that, while the table established by this document appears to intend to be a strict superset of the Enumservices table, there are no instructions of any kind to the IANA that would result in these tables remaining in sync -- that is, when a new service is added to the \"Enumservice Registrations\" table, one might presume that it needs to also appear in the new registry established by this document. I would imagine this could be handled either by asking the IANA to add instructions to the \"Enumservice Registrations\" table indicating that a corresponding entry must be added to this one; or simply by including the contents of that table by reference rather than by value into this one. I'm pretty agnostic about which approach is taken.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-01-20 03:19:28-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-19 01:57:16-08:00",
    "text": "This document mentions manageability in his title. Hence my special focus. I'm with Eric Vyncke here. His OPS DIR review is: Not being an expert in LFA, the review focus was only on operation. And, due to the density and specialization of the I-D, I would like to ask the authors whether they read  RFC 5706  about 'ops and mgmt guidelines', i.e., to check whether this I-D considered migration from an existing LFA to the new one, interoperations with previous LFA and how correct operations can be verified. As the core topic is about loop-free alternates, we can assume that fault management and operations are at the core of this I-D. But, I encourage the authors to quickly review their document with  RFC 5706  in mind. After reading the document (and with basic knowledge of RLFA), I'm unable to tell at this point if  RFC 7916  is still valid for this new functionality, if it needs to be updated, or even if  https://tools.ietf.org/html/draft-ietf-rtgwg-rlfa-node-protection-10#section-3  is complete in light of  RFC 5706 . I'll be watching the discussion with interest.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-08-12 07:02:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-11 06:29:05-07:00",
    "text": "Thank you for the work put into this document. Special thanks to Ole Tr\u00f8an for his shepherd's write-up, which contains a good summary of the WG consensus and the SW (?) implementation status. Thanks as well to Bob Halley for his INT directorate review. Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated). I also agree with DISCUSS points by other ADs: - Lars's one about the size and usefulness of FlowMonID (see my very similar point) - Roman's one about the inconsistencies about limited domain (from my point of view, this should not be limited to a single domain) All in all, I strongly suggest to change the intended status of this document to 'experimental' as this document builds on experimental RFCs. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == This discussion already happened in the 6MAN WG but I still have to be convinced that hop-by-hop is a good idea at all. The fate of packets with HbH is unknown at best and, IMHO, this is a wrong use of HbH because the forwarding/processing of packets is NOT influenced at all by the AltMark option. What is required is a simple 'marking/coloring', which could be at any place in a packet (including destination option). The only benefit of HbH is its location just after the IPv6 header. After all, existing devices can measure and generate IPFIX records in hardware/fastpath by inspecting at the bare minimum the 5-tuple and many devices can also parse extension headers in the fast path (of course not processing HbH in this case). I.e., finding the marking in the Dest Option is probably much easier and doable in current hardware rather than using HbH as HbH forces a software processing. -- Section 2 -- \u00a0 \"In the end, [ I-D.fioccola-v6ops-ipv6-alt-mark ] demonstrated that a \u00a0  new Hop-by-Hop or a new Destination Option was the best approach.\" The above draft has not been published and is even expired for 2 years now... so please remove the 'demonstrated' as there is no proof at all ;-) -- Section 4 -- Please remove \"the destination node removes it\" as there is no reason to remove it. Extension headers are usually not presented / used by upper layers anyway.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-10-07 02:25:24-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-12 07:02:20-07:00",
    "text": "Thank you for the work put into this document. As Brian Carpenter kindly reminded me that an Area Director may not put back a previous argument when the WG consensus was to ignore it, I am updating this ballot by moving the generic DISCUSS as a COMMENT. The other two DISCUSS points remains blocking ones but Giuseppe have already addressed them over email, I am clearing the DISCUSS position as soon as the revised I-D is posted. Special thanks to Ole Tr\u00f8an for his shepherd's write-up, which contains a good summary of the WG consensus and the SW (?) implementation status. Thanks as well to Bob Halley for his INT directorate review. Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated). I also agree with DISCUSS points by other ADs: - Lars's one about the size and usefulness of FlowMonID (see my very similar point) - Roman's one about the inconsistencies about limited domain (from my point of view, this should not be limited to a single domain) All in all, I strongly suggest to change the intended status of this document to 'experimental' as this document builds on experimental RFCs. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2 -- \u00a0 \"In the end, [ I-D.fioccola-v6ops-ipv6-alt-mark ] demonstrated that a \u00a0  new Hop-by-Hop or a new Destination Option was the best approach.\" The above draft has not been published and is even expired for 2 years now... so please remove the 'demonstrated' as there is no proof at all ;-) -- Section 4 -- Please remove \"the destination node removes it\" as there is no reason to remove it. Extension headers are usually not presented / used by upper layers anyway.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-25 11:16:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-25 11:15:47-07:00",
    "text": "There are a few points I'd like to DISCUSS before moving this forward. The first should be easy to address: 1. The number of authors (6) exceeds the maximum recommended by the RFC Editor (5), see  RFC 7322  \u00a74.1.1. Has this exception already been cleared with the AD? I see no mention of it in the shepherd writeup. (Speaking of the shepherd writeup, and this is a comment for the shepherd and not the authors and is only an aside, not something that needs to be addressed in the DISCUSS, the writeup answer to question 1 is incomplete. ) The second is substantive rather than administrative, and may require more discussion: 2. From what I understand of the rules about IPv6 extension header insertion (viz, only end nodes can do it), plus the assumptions stated in \u00a72.1.1 about the extent of the \"controlled domain\", it would seem a natural consequence\u00a0 that ipv6-alt-mark is only applicable to networks where user traffic enters and exits a tunnel at the perimeter of the \"controlled domain\". I don't see this stated plainly anywhere in the document. If I'm correct this seems like an important characteristic to spell out. If I'm incorrect, I'd appreciate a discussion of where I went wrong. I touch on various aspects of this overall point in some of my comments as well. Finally, although I haven't placed any of the further comments in the DISCUSS section, I noted that some of them are fairly fundamental so I would appreciate a thorough reply to the comments as well.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-25 11:16:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-25 11:16:11-07:00",
    "text": "There are a few points I'd like to DISCUSS before moving this forward. The first should be easy to address: 1. The number of authors (6) exceeds the maximum recommended by the RFC Editor (5), see  RFC 7322  \u00a74.1.1. Has this exception already been cleared with the AD? I see no mention of it in the shepherd writeup. (Speaking of the shepherd writeup, and this is a comment for the shepherd and not the authors and is only an aside, not something that needs to be addressed in the DISCUSS, the writeup answer to question 1 is incomplete.) The second is substantive rather than administrative, and may require more discussion: 2. From what I understand of the rules about IPv6 extension header insertion (viz, only end nodes can do it), plus the assumptions stated in \u00a72.1.1 about the extent of the \"controlled domain\", it would seem a natural consequence\u00a0 that ipv6-alt-mark is only applicable to networks where user traffic enters and exits a tunnel at the perimeter of the \"controlled domain\". I don't see this stated plainly anywhere in the document. If I'm correct this seems like an important characteristic to spell out. If I'm incorrect, I'd appreciate a discussion of where I went wrong. I touch on various aspects of this overall point in some of my comments as well. Finally, although I haven't placed any of the further comments in the DISCUSS section, I noted that some of them are fairly fundamental so I would appreciate a thorough reply to the comments as well.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-07-12 13:39:30-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-25 11:16:41-07:00",
    "text": "There are a few points I'd like to DISCUSS before moving this forward. The first should be easy to address: 1. The number of authors (6) exceeds the maximum recommended by the RFC Editor (5), see  RFC 7322  \u00a74.1.1. Has this exception already been cleared with the AD? I see no mention of it in the shepherd writeup. (Speaking of the shepherd writeup, and this is a comment for the shepherd and not the authors and is only an aside, not something that needs to be addressed in the DISCUSS, the writeup answer to question 1 is incomplete.) The second is substantive rather than administrative, and may require more discussion: 2. From what I understand of the rules about IPv6 extension header insertion (viz, only end nodes can do it), plus the assumptions stated in \u00a72.1.1 about the extent of the \"controlled domain\", it would seem a natural consequence\u00a0 that ipv6-alt-mark is only applicable to networks where user traffic enters and exits a tunnel at the perimeter of the \"controlled domain\". I don't see this stated plainly anywhere in the document. If I'm correct this seems like an important characteristic to spell out. If I'm incorrect, I'd appreciate a discussion of where I went wrong. I touch on various aspects of this overall point in some of my comments as well. Finally, although I haven't placed any of the further comments in the DISCUSS section, I note that some of them are fairly fundamental so I would appreciate a thorough reply to the comments as well.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-26 07:05:24-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-06 02:36:00-07:00",
    "text": "Section 2.1. , paragraph 4, discuss: >\u00a0 \u00a0 Therefore, the IPv6 application of the Alternate Marking Method MUST >\u00a0 \u00a0 NOT be deployed outside a controlled domain. That's not what Section 6 says, which allows use outside a controlled domain (across the Internet) if protection is applied? Section 2.1. , paragraph 4, discuss: >\u00a0 \u00a0 Some scenarios may imply that the Alternate Marking Method is applied >\u00a0 \u00a0 outside a controlled domain, either intentionally or unintentionally, >\u00a0 \u00a0 but in these cases, IPsec authentication and encryption MUST be used. How can one require use of IPsec for an unintentional use outside of a controlled domain? If the header leaks by accident, surely it's unreasonable to expect that IPsec had been set up to catch any and all such possible leakage? Also (as a comment), if IPsec is required by this document, it needs to be normatively cited. Section 5.3.1. , paragraph 2, discuss: >\u00a0 \u00a0 It is important to note that if the 20 bit FlowMonID is set >\u00a0 \u00a0 independently and pseudo randomly there is a chance of collision. >\u00a0 \u00a0 Indeed, by using the well-known birthday problem in probability >\u00a0 \u00a0 theory, if the 20 bit FlowMonID is set independently and pseudo >\u00a0 \u00a0 randomly without any additional input entropy, there is a 50% chance >\u00a0 \u00a0 of collision for 1206 flows.\u00a0 So, for more entropy, FlowMonID can >\u00a0 \u00a0 either be combined with other identifying flow information in a >\u00a0 \u00a0 packet (e.g. it is possible to consider the hashed 3-tuple Flow >\u00a0 \u00a0 Label, Source and Destination addresses) or the FlowMonID size could >\u00a0 \u00a0 be increased. It seems odd to define a dedicated FlowMonID, but make it so short that it is basically not usable in many realistic scenarios. If other parts of the packet headers need to be inspected to disambiguate FlowMonID collisions, this (1) should at least be more carefully specified in this document (since every node will need to do it in the same way) but (2) probably argues for a much longer FlowMonID - why not make it 64 bits or longer? The IANA review of this document seems to not have concluded yet; I am holding a DISCUSS for IANA until it has.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-08-10 17:01:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-09 17:11:16-07:00",
    "text": "I have some concerns about this approach, plus some points of confusion that hopefully will clear up quickly. I support Lars's first two DISCUSS points. (1) I am unclear about the relationship between limited domains and the prohibition against modifying either option before the destination. Is the intent that (a) this is only used for traffic that begins and ends in the domain; (b) user traffic is encapsulated with an outer IPv6 header that is removed prior to domain exit; or (c) the \"destination\" actually means the egress point from the domain? (2) Relatedly, if the source nodes are\u00a0 user-generated packets, how is this in practice a limited domain? Source nodes have enormous power to degrade the measurement by sending packets that fill the entire FlowMon space with only 1M packets, which not only consumes router resources but also pollutes every single measurement in the domain.   (3) The draft informatively references the (Experimental) RFCs 8321 and 8889 and covers some of the same ground, but as a Proposed Standard. Is part of the purpose here to update these RFCs? For other measurement techniques, we've had a generic measurement draft in IPPM and encapsulations in the appropriate protocol-specific groups like 6man. Why was that approach not taken here? Will future encapsulations of alternate marking refer to this one normatively on how to conduct the measurement? (4) Are there any restrictions on FlowMon IDs? Need these be pseudorandom, or can they encode information in the clear? (5) I don't understand the basic motivation for using HBH options if these can result in the packet being diverted to the slow path on intermediate nodes. This seems like a major drawback for a delay measurement! (6) Sec 5.1: When using timer-based batches, I gather you use times well in excess of potential reordering. If using a counter-based method, how does the measurement account for potential reordering? There could easily be a very large instantaneous burst followed by a path change that lowered the latency.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-31 08:45:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-10 17:01:25-07:00",
    "text": "I have some concerns about this approach, plus some points of confusion that hopefully will clear up quickly. I support Lars's first two DISCUSS points. (edited) (1) The precise use case is unclear to me. An end-user (not in the controlled domain)\u00a0 generates an IPv6 packet, and I gather some sort of middlebox then inserts the header if it meets some criteria (perhaps that the destination IP is also within the domain). If this is correct, I would like to check with the experts if a non-endpoint inserting a header is compliant with  RFC8200 . Also, this should be written down somewhere. If not correct, I have many more questions. (2) The draft informatively references the (Experimental) RFCs 8321 and 8889 and covers some of the same ground, but as a Proposed Standard. Is part of the purpose here to update or obsolete these RFCs?  (3) Are there any restrictions on FlowMon IDs? Need these be pseudorandom, or can they encode information in the clear? (4) Sec 5.1: When using timer-based batches, I gather you use times well in excess of potential reordering. If using a counter-based method, how does the measurement account for potential reordering? There could easily be a very large instantaneous burst followed by a path change that lowered the latency.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-04-28 09:09:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-31 08:45:23-07:00",
    "text": "Thanks for addressing most of my DISCUSS points. I would like an unambiguous statement in Section 3.1 that the FlowMonID MUST appear to be random. There is still language that suggests it might not be: (e.g., \"The disambiguation issue is more visible when the FlowMonID is pseudorandomly generated...\". If it is anything less than a MUST, there needs to be additional Security Considerations to reflect the impact of not doing so.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-08-12 07:28:07-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-11 23:17:36-07:00",
    "text": "A procedural question about the IPR disclosures, which I expect we can clear up during the telechat in a few hours: Though there have been two IPR disclosures on this document, the shepherd writeup conspicuously claims there has been no discussion about either.\u00a0 For at least one of them the licensing terms indicate a fee may apply.\u00a0 As this is seeking Proposed Standard status, I'd like to inquire about this.\u00a0 In particular, Section 4 of  BCP 79  says: \u00a0 \u00a0 \u00a0 A working group may take into \u00a0 \u00a0 \u00a0 consideration the results of this procedure in evaluating the \u00a0 \u00a0 \u00a0 technology, and the IESG may defer approval when a delay may \u00a0 \u00a0 \u00a0 facilitate obtaining such assurances. I note the \"may\", but still it feels like an important step was missed here.\u00a0 So: Was there an implicit conclusion that the IPR claims don't hinder the technology?\u00a0 Or did nobody check it out?\u00a0 Or did the WG decide consciously not to worry about it?\u00a0 Or is it actually fine to just ignore them?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-10 13:03:25-08:00",
    "end_reason": "position_updated",
    "start": "2021-08-09 13:48:45-07:00",
    "text": "Please provide consistent guidance on where this methodology can be used.\u00a0 Consider: (a) Section 2.1. \u201cTherefore, the IPv6 application of the Alternate Marking Method MUST NOT be deployed outside a controlled domain.\u201d (b) Section 2.1.\u00a0 \u201cSome scenarios may imply that the Alternate Marking Method is applied outside a controlled domain, either intentionally or unintentionally, but in these cases, IPsec authentication and encryption MUST be used.\u201d (c) Section 6. \u201cThis document aims to apply a method to perform measurements that does not directly affect Internet security nor applications that run on the Internet.\u201d (d) Section 6. \u201cAs stated above, the precondition for the application of the Alternate Marking is that it MUST be applied in specific controlled domains, thus confining the potential attack vectors within the network domain.\u00a0  (e) Section 6. \u201cIn this case, the user, aware of the kind of risks, may still want to use Alternate Marking for telemetry and test purposes but the inter-domain links need to be secured (e.g., by IPsec) in order to avoid external threats.\u00a0 For these specific scenarios the application of the Alternate Marking Method outside a controlled domain is possible but IPsec through AH\u00a0 \u00a0 (Authentication Header) or ESP (Encapsulating Security Payload) MUST be used.\u201d (a) and (d) seem to very clear that this approach MUST only be used in a controlled domain.\u00a0 However (b) and (d) seem to suggest that this prohibition is at best a \u201cSHOULD\u201d.\u00a0 If (b) and (d) are true, than (c) not affecting applications on the internet might not be true. ** Section 6.\u00a0 Thanks for mentioning \u201cAt the management plane, attacks can be set up by misconfiguring or by maliciously configuring AltMark Option.\u201d\u00a0 Please be clearer on what these attacks could look like.\u00a0 Would these include: -- using the FlowMonId as a tracking identifier? -- (Likely possible at both the data and management plane would be a) covert channel between the sender and an on-path observer?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-05-17 16:01:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-11 14:21:36-07:00",
    "text": "I must be missing something fairly fundamental here. \"As stated above, the precondition for the application of the \u00a0  Alternate Marking is that it MUST be applied in specific controlled \u00a0  domains, thus confining the potential attack vectors within the \u00a0  network domain.\u00a0 [ RFC8799 ] analyzes and discusses the trend towards \u00a0  network behaviors that can be applied only within a limited domain. \u00a0  This is due to the specific set of requirements especially related to \u00a0  security, network management, policies and options supported which \u00a0  may vary between such limited domains.\u00a0 A limited administrative \u00a0  domain provides the network administrator with the means to select, \u00a0  monitor and control the access to the network, making it a trusted \u00a0  domain.\u00a0 In this regard it is expected to enforce policies at the \u00a0  domain boundaries to filter both external packets with AltMark Option \u00a0  entering the domain and internal packets with AltMark Option leaving \u00a0  the domain.\u00a0 Therefore the trusted domain is unlikely subject to \u00a0  hijacking of packets since packets with AltMark Option are processed \u00a0  and used only within the controlled domain.\" The above says that this must only be done in a limited/controlled domain, and that operators are: \"expected to enforce policies at the domain boundaries to filter both external packets with AltMark Option entering the domain and internal packets with AltMark Option leaving the domain.\". The \"only do this in in limited domain\" seems to simply punt on the security concerns / considerations. What is an operator supposed to do if their device doesn't understand this option? Are you really suggesting that everyone needs to do though and update edge firewall filters everywhere to block this? What happens when a filter is unintentionally missed? Or when the device cannot filter N headers deep?  [edit firewall family inet6 filter altmark term demo] wkumari@rtr2.pa o# set from extension-header ? Possible completions: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Range of values \u00a0 [\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Open a set of values \u00a0 ah\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Authentication header \u00a0 any\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Any extension header \u00a0 dstopts\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Destination options \u00a0 esp\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Encapsulating security payload \u00a0 fragment\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Fragment \u00a0 hop-by-hop\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Hop by hop options \u00a0 mobility\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Mobility \u00a0 routing\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Routing Yes, many networks use automation to apply filters, but it is still unreasonable to force operators to have to keep updating and deploying new filters when new protocols are created.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-02-03 09:24:41-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-21 21:26:41-08:00",
    "text": "Thanks to the authors and working group for their work on this document.\u00a0 I have one major concern about the ability for this mechanism to be abused to form DDoS attacks, described below. Unfortunately, while I have identified the attack, I don't have an easy solution to propose that mitigates it satisfactorily. I also have a handful of mostly editorial comments on the document. --------------------------------------------------------------------------- \u00a76: I was expecting to see a discussion of the DDoS attack that may result from a large network (or a rogue host on such a network) sending out a PvD ID containing the hostname of a victim machine, and setting the \"H\" flag. Since the messages used to trigger these HTTP connections are extremely lightweight, unauthenticated UDP messages, and the resulting HTTP connections require the exchange of a significant number of packets in addition to a number of cryptographic operations, this is a very high ratio amplification attack, both in terms of network and CPU resources. Given that the delay setting comes from the network instead of being independently computed by the host, such an attack could be honed to be particularly devastating.\u00a0 Although it isn't a complete mitigation, one approach to consider would be moving computation of the delay upper bound to the host, or specifying a minimum upper bound of several minutes (where a smaller value will cause the host to use this minimum upper bound). Regardless of how this is ultimately handled, I think this is a pretty severe risk that needs addressing in the document prior to publication.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-22 18:48:04-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-21 08:22:23-08:00",
    "text": "This is a nit that should be easy to resolve but I'm confused by it, so I'm flagging it here. The reference for [URN] in Section 10.2 says '[URN] \"URN Namespaces\", n.d..,' which seems like an error. Given the way [URN] is used in 4.3, I'm not sure I understand why organizations with formal URN namespaces\u00a0 would be expected to be using PvDs, if that is what the document intends to convey. In any event, at a minimum the reference needs to be fixed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-03 13:58:22-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-21 16:21:09-08:00",
    "text": "Alexey basically already noted this in his Comment, but I'll elevate it to a Discuss: the usage of TLS for retrieving PvD Additional Information is not really completely specified -- generally in this sort of case where there's a (provisioning) domain name to authenticate we'd expect to require that the server present a certificate with DNS-ID [ RFC6125 ] that matches the expected name.\u00a0 We could also cite  RFC 7525  for TLS best practices and/or make a TLS version recommendation (i.e., 1.3). There seems to be a missing step in the binding of the PvD ID to the actual usage, or rather, we are making stronger statements about authenticity than the technology seems to justify.\u00a0 While we can verify that the TLS certificate used to access the additional information matches with the PvD ID provided, there doesn't seem to be a step to validate that the PvD ID in question is applicable for the current network environment.\u00a0 The prefix match helps some, but (to first order) only for globally-routable prefixes in the absence of NAT.\u00a0 Malicious routers (e.g., coffeeshop wifi) can fairly easily implement NAT66 and circumvent host-side countermeasures; tunneling traffic through to a compromised host actually in the target PvD would allow circumvention of the TLS-server-side countermeasures.\u00a0 I have some suggested rewordings in the Comment section that should bring the claims in line with what is actually provided. (As something of a side note, it seems that the JOSE/signature scheme discussed in the secdir review thread, that does have a tighter binding to the local network with the PvD, could defeat the caching attack discussed there by having the host supply a nonce in the RS and including that in the signed response, but that requires a lot of expensive signatures and has some challenging key-management problems. So it doesn't seem worth pursuing, even though it's attractive to make more use of the network locality.) The IANA Considerations for PvD Option Flags indicates that bits 0 to 15 are managed by IANA, but I think there are only 12 bits available due to the 4-bit Delay field.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-03 07:09:30-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-22 09:52:49-08:00",
    "text": "Section 4.4.\u00a0 Per \u201cWhen a host retrieves the PvD Additional Information, it MUST verify that the TLS server certificate is valid for the performed request (e.g., that the Subject Alternative Name is equal to the PvD ID expressed as an FQDN).\u00a0 This authentication creates a secure binding between the information provided by the trusted Router Advertisement, and the HTTPS server.\u201d, what is the trust anchor the client is supposed to use to valid the server certificate is valid?\u00a0 How is that trust anchor provisioned?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:39:21-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-29 13:21:17-08:00",
    "text": "Thank you for the work on this document. Many thanks to Julian Reschke for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/XfLbtK1eLb7s0Z6e_AqGgkoWny0/ . I have one DISCUSS point that has to do with IANA considerations, and is hopefully easy to resolve. Francesca 1. ----- FP: I am sure the Designated Expert will bring this up, but \"iss\" is already defined as a OAuth Parameter, for authorization requests. I don't think it's a good idea to use the same parameter name, although in a different message of the exchange, for something different, as the registration defined in Section 5.2 seems to imply. I strongly recommend to change the name in this document. Or, if we can agree that the meaning is similar enough to the original \"iss\", merge the two IANA registrations (this would not be my preferred choice).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-02 04:34:45-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:39:21-08:00",
    "text": "Thank you for the work on this document. Many thanks to Julian Reschke for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/XfLbtK1eLb7s0Z6e_AqGgkoWny0/ . I have one DISCUSS point that has to do with IANA considerations, and is hopefully easy to resolve. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- FP: I am sure the Designated Expert will bring this up, but \"iss\" is already defined as a OAuth Parameter, for authorization requests. I don't think it's a good idea to use the same parameter name, although in a different message of the exchange, for something different, as the registration defined in Section 5.2 seems to imply. I strongly recommend to change the name in this document. Or, if we can agree that the meaning is similar enough to the original \"iss\", merge the two IANA registrations (this would not be my preferred choice).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-09 09:30:46-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-04 12:22:38-07:00",
    "text": "Thanks to everyone who worked on this document. The mechanism seems useful. I'm concerned that the document doesn't describe the file format itself; rather, it relies on examples to provide vital, nonsupplemental information such as the names of JSON object members, expected encodings (e.g., strings versus numbers), and distinction between arrays and objects. I'm making this a DISCUSS because I think the ambiguity here -- and, in particular the ambiguity about IP address prefix notation -- will lead to non-interoperable implementations. Using section \u00a73.2 as an example: >\u00a0  A SLURM file consists of: > >\u00a0  o\u00a0 A SLURM Version indication that MUST be 1 > >\u00a0  o\u00a0 A slurmTarget element (Section 3.3) consisting of: > >\u00a0 \u00a0 \u00a0 *\u00a0 Zero or more target elements.\u00a0 In this version of SLURM, there >\u00a0 \u00a0 \u00a0 \u00a0  are two types of values for the target: ASN or Fully Qualified >\u00a0 \u00a0 \u00a0 \u00a0  Domain Name(FQDN).\u00a0 If more than one target line is present, >\u00a0 \u00a0 \u00a0 \u00a0  all targets MUST be acceptable to the RP. > >\u00a0  o\u00a0 Validation Output Filters (Section 3.4), consisting of: > >\u00a0 \u00a0 \u00a0 *\u00a0 An array of zero or more Prefix Filters, described in >\u00a0 \u00a0 \u00a0 \u00a0  Section 3.4.1 > >\u00a0 \u00a0 \u00a0 *\u00a0 An array of zero or more BGPsec Filters, described in >\u00a0 \u00a0 \u00a0 \u00a0  Section 3.4.2 > >\u00a0  o\u00a0 Locally Added Assertions (Section 3.5), consisting of: > >\u00a0 \u00a0 \u00a0 *\u00a0 An array of zero or more Prefix Assertions, described in >\u00a0 \u00a0 \u00a0 \u00a0  Section 3.5.1 > >\u00a0 \u00a0 \u00a0 *\u00a0 An array of zero or more BGPsec Assertions, described in >\u00a0 \u00a0 \u00a0 \u00a0  Section 3.5.2 > As this is the normative description of the structure, I would have expected an indication that the file contains a JSON object (rather than, say, a JSON array), an indication that the version is to be encoded as a number (rather than a string), and clarification of what value members are expected to contain. For example, the following JSON object is in compliance with the preceding normative description (and, as far as I can tell, all other normative text in the document): [\"1\", \u00a0 [\"65536\", \" rpki.example.com \"], \u00a0 [ \u00a0 \u00a0 [\"192.0.2.0/255.255.255.0\", \"All VRPs encompassed by prefix\"], \u00a0 \u00a0 [\"64496\", \"All VPRs maching ASN\"], \u00a0 \u00a0 [\"198.51.100.0/255.255.255.0\", \"64497\", \"All VRPs encompassed by prefix, \u00a0 \u00a0 \u00a0 matching ASN\"] \u00a0 ], \u00a0 [ \u00a0 \u00a0 [\"64496\", \"All keys for ASN\"], \u00a0 \u00a0 [\"Zm9v\", \"Key matching Router SKI\"], \u00a0 \u00a0 [\"64497\", \"YmFy\", \"Key for ASN 64497 matching Router SKI\"], \u00a0 ], \u00a0 [ \u00a0 \u00a0 [\"64496\", \"198.51.100.0/255.255.255.0\", \"My other important route\"], \u00a0 \u00a0 [\"64496\", \"2001:DB8::/FFFF:FFFF::\", \"48\", \u00a0 \u00a0  \"My other important de-aggregated routes\"], \u00a0 ], \u00a0 [ \u00a0 \u00a0 [\"64496\", \"My known key for my important ASN\", \u00a0 \u00a0  \"\", \"\"] \u00a0 ] ] Fixing this should be pretty easy; the document simply needs text added that describes the JSON structure explicitly, with clear indications of how values are to be encoded. For example, the preceding text I quote becomes: \u00a0  A SLURM file consists of a single JSON object containing the following \u00a0  members: \u00a0  o\u00a0 A\u00a0 \"slurmVersion\" member that MUST be set to 1, encoded as a number \u00a0  o\u00a0 A \"slurmTarget\" member (Section 3.3) If more than one target line is \u00a0 \u00a0 \u00a0 present, all targets MUST be acceptable to the RP. The \"slurmTarget\" \u00a0 \u00a0 \u00a0 member is encoded as an array of zero or more objects. Each object in the \u00a0 \u00a0 \u00a0 array contains exactly one member.\u00a0 In this version of SLURM, the member \u00a0 \u00a0 \u00a0 may be named either: \u00a0 \u00a0 \u00a0 * \"asn\", in which case it contains an ASN, or \u00a0 \u00a0 \u00a0 * \"hostname\", in which case it contains a Fully Qualified Domain \u00a0 \u00a0 \u00a0 \u00a0  Name (FQDN). \u00a0  o\u00a0 A \"validationOutputFilters\" member (Section 3.4), whose value is an \u00a0 \u00a0 \u00a0 object. The object MUST contain exactly two members: \u00a0 \u00a0 \u00a0 *\u00a0 A \"prefixFilters\" member, whose value is described in \u00a0 \u00a0 \u00a0 \u00a0  Section 3.4.1 \u00a0 \u00a0 \u00a0 *\u00a0 A \"bgpsecFilters\" member, whose value is described in \u00a0 \u00a0 \u00a0 \u00a0  Section 3.4.2 \u00a0  o\u00a0 A \"locallyAddedAssertions\" member (Section 3.5), whose value is an \u00a0 \u00a0 \u00a0 object. The object MUST contain exactly two members: \u00a0 \u00a0 \u00a0 *\u00a0 A \"prefixAssertions\" member, whose value is described in \u00a0 \u00a0 \u00a0 \u00a0  Section 3.5.1 \u00a0 \u00a0 \u00a0 *\u00a0 A \"bgpsecAssertions\" member, whose value is described in \u00a0 \u00a0 \u00a0 \u00a0  Section 3.5.2 Gotchas to watch out for include:  - If you're using the word \"element\" to describe something in a JSON object, \u00a0  you probably need to find a more specific word. This document, for example, \u00a0  uses \"element\" instead of \"member\" in most places.  - Everywhere you use the word \"structure,\" replace it with either \"array\" or \u00a0  \"object,\" as appropriate.  - When values can be encoded as either a number or a string (e.g., as with \u00a0  \"slurmVersion\" above, or with AS numbers), indicate which encoding is \u00a0  expected.  - For IP prefixes, be clear about acceptable syntax. For example: is \u00a0  the  RFC 950  syntax (\"192.0.2.0/255.255.255.0\") acceptable? My suggestion is \u00a0  to cite  RFC 4632  \u00a73.1 for prefix-length notation (both for IPv4 and IPv6), \u00a0  and  RFC 5952  for the syntax of IPv6 addresses.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-04-30 10:08:42-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-01 14:02:19-07:00",
    "text": "I don't understand the targeting as it related to domain/host names (and suspect that others will have the same issue). From section 3.3: \"\u00a0 If a \"slurmTarget\" element is \u00a0  present, an RP SHOULD verify that the target is an acceptable value, \u00a0  and reject this SLURM file if the \"slurmTarget\" element is not \u00a0  acceptable.... Accordingly, the SLURM file \u00a0  source needs to indicate which RP(s) should make use of the file by \u00a0  adding the domain name(s) of the RP(s) to the SLURM file target... \u00a0 Such a target value is a server name expressed in FQDN. \u00a0  \"slurmTarget\": [ \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0  \"hostname\": \" rpki.example.com \", \u00a0 \u00a0 \u00a0  \"comment\": \"This file is intended for RP server  rpki.example.com \" \u00a0 \u00a0  } ]\u00a0  So, if I want to target multiple RPs ( rpki1.example.com ,  rpki2.example.com ) can I do: \u00a0  \"slurmTarget\": [ \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0  \"hostname\": \" example.com \", \u00a0 \u00a0 \u00a0  \"comment\": \"This file is intended for RP server  rpki.example.com \" \u00a0 \u00a0  } ] ? The \"domain names(s)\" versus \"hostname\" vs \"server name expressed in FQDN\" text is handwavey. I'm assuming that I'd need to do: \u00a0  \"slurmTarget\": [ \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0  \"hostname\": \" rpki1.example.com \", \u00a0 \u00a0 \u00a0  \"comment\": \"This file is intended for RP server  rpki1.example.com \" \u00a0 \u00a0  },  { \u00a0 \u00a0 \u00a0  \"hostname\": \" rpki2.example.com \", \u00a0 \u00a0 \u00a0  \"comment\": \"This file is intended for the RP server,  rpki2.example.com \" \u00a0 \u00a0  },  ]\" Can you please make this clearer, and hopefully add more targets to the examples? This seems like an easy fix / clarification, happy to clear once it is, er, clear.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-11-21 05:22:24-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-10 07:52:44-07:00",
    "text": "I think this document needs to state explicitly which updates apply to which existing RFCs. That is, I would expect to see in sections 2.1,\u00a0 2.2, and 2.3 the list of which documents are updated by each section. I realize this can be intuited, but typically for avoidance of doubt authors specify precisely which updates apply to which documents. This will also clear up the unused references that idnits is pointing out. I would also like to\u00a0 understand why this is going for BCP. There is effectively no shepherd write-up for this draft (it's just a copy of the write-up for  draft-ietf-dnsop-attrleaf  and talks about this document as the \"companion\" document) so there is no explanation there. One effect of this being BCP is that it adds a huge number of documents to the downref registry. It's not clear to me that the upside of that is bigger than the downside.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2018-10-10 15:11:00-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-10 14:33:33-07:00",
    "text": "This is absolutely a \"plea for clue Discuss\", after which I will immediately clear because the right thing will happen. There are three text blocks that follow this form: \u00a0  If a public specification that defines use of a \"TXT\" calls for the \u00a0  use of an underscore-prefixed domain name, the global underscored \u00a0  name -- the one closest to the root -- MUST be entered into this \u00a0  registry, if it is not already registered. ->Here is a template of suggested text for this to appear in the IANA ->Considerations section of the specification: \u00a0 \u00a0 \u00a0 \"Per\" [Attrleaf] \"please add the following entry to the DNS \u00a0 \u00a0 \u00a0 Underscore Global Scoped Entry Registry:\" Do you have a really strong sense that this shouldn't be  \u00a0  If a public specification that defines use of a \"TXT\" calls for the \u00a0  use of an underscore-prefixed domain name, the global underscored \u00a0  name -- the one closest to the root -- MUST be entered into this \u00a0  registry, if it is not already registered, by adding this text to  \u00a0  the IANA Considerations section of the specification: \u00a0 \u00a0 \u00a0 \"Per\" [Attrleaf] \"please add the following entry to the DNS \u00a0 \u00a0 \u00a0 Underscore Global Scoped Entry Registry:\" I may be overreacting to \"MUST do something like this\", which is roughly what I'm reading into \"template of suggested text\", and if I am, I'm almost sure someone will tell me that ... but I'm not seeing an obvious reason to REQUIRE one of an unbounded set of flowers to bloom ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-08-02 13:17:09-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 14:19:06-07:00",
    "text": "\u00a79 (\"Results of the Multipoint Alternate Marking Experiment\") makes several  recommendations about the use of one or two flag bits: \u00a0 \u00a0  One flag: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 6 by applying the network clustering partition described \u00a0 \u00a0 \u00a0 in Section 5.\u00a0 While delay measurement MAY be done according to \u00a0 \u00a0 \u00a0 the Mean delay calculation representative of the multipoint path, \u00a0 \u00a0 \u00a0 as described in Section 7.1.1.\u00a0 Single-marking method based on the \u00a0 \u00a0 \u00a0 first/last packet of the interval cannot be applied, as mentioned \u00a0 \u00a0 \u00a0 in Section 7.2.1. \u00a0 \u00a0 \u00a0 Two flags: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 6 by applying the network clustering partition described \u00a0 \u00a0 \u00a0 in Section 5.\u00a0 While delay measurement SHOULD be done on a single \u00a0 \u00a0 \u00a0 packet basis according to double-marking method Section 7.2.1.\u00a0 In \u00a0 \u00a0 \u00a0 this case the Mean delay calculation (Section 7.1.1) MAY also be \u00a0 \u00a0 \u00a0 used as a representative value of a multipoint path. \u00a0 \u00a0 \u00a0 One flag and hash-based selection: packet loss measurement SHOULD \u00a0 \u00a0 \u00a0 be done as described in Section 6 by applying the network \u00a0 \u00a0 \u00a0 clustering partition described in Section 5.\u00a0 Hash-based selection \u00a0 \u00a0 \u00a0 methodologies, introduced in Section 7.2.2, MAY be used for delay \u00a0 \u00a0 \u00a0 measurement. These recommendations are good, as they are the result of experimentation.\u00a0  However, they don't provide any deployment or operational guidelines of when  it is ok to follow them and when it isn't.\u00a0 For example, for the one flag case,  when it is ok to not measure packet loss as described in \u00a76?\u00a0 Why is the use  of that mechanism only recommended and not required? I have the same questions for all the recommendations and optional indications  in the text above.\u00a0 To clear this DISCUSS I expect deployment or operational  recommendations that can be used as implementation/deployment guidance.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-07-12 08:29:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-07-12 08:28:33-07:00",
    "text": "Thanks for this document. As you may have noticed I had considerable difficulty with the definition of \"cluster\". Once I completed an end-to-end read-through, this was resolved (good!) but because RFCs are often consumed piecemeal (e.g. someone may just dip into a portion of a document rather than settling down with a nice cup of tea to read it end-to-end), I think it's important to fix this problem, on the assumption I'm not the only person who might be thrown off. I'll leave the details in the COMMENT, but I will repeat one observation from my comment #3, which is that I count at least four separate (re-)definitions of \"cluster\" in the document. With so many, it's no wonder that they're inconsistent, and quite likely the cleanest solution would involve cutting the number of definitions down to as close to 1 as possible.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-18 12:27:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 08:29:30-07:00",
    "text": "Thanks for this document. As you may have noticed I had considerable difficulty with the definition of \"cluster\". Once I completed an end-to-end read-through, this was resolved (good!) but because RFCs are often consumed piecemeal (e.g. someone may just dip into a portion of a document rather than settling down with a nice cup of tea to read it end-to-end), I think it's important to fix this problem, on the assumption I'm not the only person who might be thrown off. I'll leave the details in the COMMENT, but I will repeat one observation from my comment #3, which is that I count at least four separate (re-)definitions of \"cluster\" in the document. With so many, it's no wonder that they're inconsistent, and quite possibly the simplest solution would involve cutting the number of definitions down to as close to 1 as possible.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-29 02:11:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 11:37:16-07:00",
    "text": "# GEN AD review of  draft-ietf-ippm-rfc8889bis-02 CC @larseggert Thanks to Russ Housley for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/OTAnYgNGwDIRaQu_9IDo1QN1KHM ). ## Discuss ### Section 1, paragraph 11 ``` \u00a0 \u00a0  Note that the fragmented packets case can be managed with the \u00a0 \u00a0  Alternate-Marking methodology.\u00a0 The same considerations of \u00a0 \u00a0  [ I-D.ietf-ippm-rfc8321bis ] apply also in the case of Multipoint \u00a0 \u00a0  Alternate Marking.\u00a0 As defined in [ I-D.ietf-ippm-rfc8321bis ] the \u00a0 \u00a0  marking node MUST mark all the fragments except in the case of \u00a0 \u00a0  fragmentation within the network domain, in that event it is \u00a0 \u00a0  suggested to mark only the first fragment. ``` \"MUST mark ... except\" is not clear enough. In the case where there is fragmentation, what is the defined behavior? \"Suggest to mark\" leaves a lot open to interpretation. In general, the use of  RFC2119  language in this document should be checked. See comments below.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-05 09:38:54-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 11:19:54-07:00",
    "text": "Please clarify the expected deployment model of this approach. (a) Section 9. \u00a0  The Multipoint Alternate Marking Method is RECOMMENDED only for \u00a0  controlled domains, as per [ I-D.ietf-ippm-rfc8321bis ]. (b) Section 10 \u00a0  This document specifies a method of performing measurements that does \u00a0  not directly affect Internet security or applications that run on the \u00a0  Internet. The text in (a) suggests that deployment can occur on the Internet (although it isn\u2019t recommended).\u00a0 However, (b) suggests that OAM meta-data would not be used on the Internet.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:51:43-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 08:38:27-07:00",
    "text": "A couple of the points from the Gen-ART review warrant discussion I think (quoting directly from the review): (1) 'The relationship of this mechanism with SVEC seems to be important but is not clearly stated.\u00a0 The relevant sections of the text seem to be: section 4 para 2, section 5.3, and section 5.4 from \"[ RFC5440 ] uses SVEC diversity flag\" on.\u00a0 I think that they need to be pulled into one section.\u00a0 Then it will be possible to have a good description of the interaction with SVEC.' (2) 'The path computation effects of the P bit are described in the \"P\" item in section 5.2 and section 5.5.\u00a0 But the descriptions are unclear, or perhaps they presume that there are only two LSPs in the group.\u00a0 I think the intended meaning is that all of the LSPs in the group with P=1 are computed first, and then with those LSPs fixed, the LSPs in the group with P=0 are computed.\u00a0 This will cause shortest-path constraints (and other objective functions) to be optimized on the P=1 LSPs, and those paths will not be de-optimized by competition from the other paths.\u00a0 This should probably be pulled out of the description of the \"P\" in its TLV and put into a separate paragraph.'",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-01-15 21:18:43-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 20:29:44-07:00",
    "text": "* Section 5.3: \u00a0 Given the fairly relaxed handling of multiple OF-codes (\"the receiver MUST consider the first OF-code only and ignore others if included\") I think the error handling as specified in \"the OF-code inside the OF Object MUST include one of the disjoint OFs defined in this document. If this condition is not met, the PCEP speaker MUST...\" needs to be tightened a bit since all the OF-codes but the first are ignored for processing but still considered for error handling. Suggest something like this OLD: the OF-code inside the OF Object MUST include one of the disjoint OFs defined in this document. NEW: the first OF-code inside the OF Object MUST be one of the disjoint OFs defined in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2018-03-08 12:16:28-08:00",
    "end_reason": "position_updated",
    "start": "2018-03-05 11:29:33-08:00",
    "text": "I have significant concerns about this document; as currently written, I believe the technology is underspecified and can cause significant damage to a DC network where it might be deployed.\u00a0 I am then balloting a DISCUSS. The document (including the security considerations) is written assuming that the TRILL-ENs can be trusted (and are not compromised), and that the directory information is accurate.\u00a0 However, I believe there are several cases that have been overlooked. (1) There aren't any basic safeguards specified to at least make sure that a TRILL-EN is doing the right thing (or something sensible).\u00a0 For example, what if the Ingress RBridge Nickname field in the TRILL header doesn't correspond to the first rBridge at the domain boundary?\u00a0 Should that frame be accepted? (2)  rfc8171  talks about issues with incorrect directory mappings.\u00a0 Consider the case where a TRILL-EN uses (on purpose!) an incorrect mapping.\u00a0 That \"can result in data being delivered to the wrong end stations, or set of end stations in the case of multi-destination packets, violating security policy.\" [ rfc8171 ]\u00a0 How can this risk be mitigated? I don't think that there are easy mitigations for these issues, but at least mentioning them so that operators are aware of the risk would be enough to clear this DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-04-06 14:03:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-04-06 14:02:43-07:00",
    "text": "Although the document is largely clear and well-written (thanks for that), I was left with one burning question: what are these sub-TLVs *for*? There\u2019s no specification for what the router is supposed to do with them, only how to originate them. The only clue I get is buried down in Section 5: \u00a0  The identification of the node that is originating a specific prefix \u00a0  in the network may aid in debugging of issues related to prefix \u00a0  reachability within an OSPF network. If their purpose is to act as debugging aids, I think the least you should at least say so briefly in the abstract and introduction. If they have some purpose beyond that, it\u2019s missing from the doc.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-04-07 17:37:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-06 14:03:32-07:00",
    "text": "Although the document is largely clear and well-written (thanks for that), I was left with one burning question: what are these sub-TLVs *for*? There\u2019s no specification for what the router is supposed to do with them, only how to originate them. The only clue I get is buried down in Section 5: \u00a0  The identification of the node that is originating a specific prefix \u00a0  in the network may aid in debugging of issues related to prefix \u00a0  reachability within an OSPF network. If their purpose is to act as debugging aids, I think you should at least say so briefly in the abstract and introduction. If they have some purpose beyond that, it\u2019s missing from the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-04 08:36:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-03 08:31:06-07:00",
    "text": "First, I have to say that I'm pretty ignorant about practical routing operations, so my plan is to briefly discuss this and to then probably move to an abstain position, unless the issues I raise resonate with folks who are expert in this space. (1) I agree with the points raised in IETF LC that the transitive nature of this proposal has dangers that may outweigh its utility. Was there discussion in the WG about potential solutions that do not have the transitivity property? If so, can you point me at those? If not, is there a reason to think no such solution is feasible?\u00a0 (I suspect the answer may be \"no\" which is the main reason I plan to move to an abstain ballot.) (2) IIUC, this proposal envisages BGP speakers commonly telling others to blackhole specific /32's or /128's. And of course as the draft says BGP doesn't provide us with a way to \"prevent the unauthorized modification of information by the forwarding agent.\" Given those two things, this scheme seems to be an ideal new way to cause any service that advertises a fallback to actually fall back, e.g to use a secondary MX or DNS resolver rather than a primary. That seems like a fine way to try and possibly succeed in attacking many possible things.\u00a0 The discuss point here is to ask if this really is a new attack vector, and if so, if the appropriate level of analysis of its impact has been done? If this is new, then I don't see that the security considerations text adequately describe the range of possible attacks that could be mounted using this scheme. (As an aside, I wonder if asking to blackhole /32's and /128's might impact on routing table sizes and if something ought be said about that?) (3) Given that there are dangers associated with this mechanism, why is there no statement in the draft that actions taken based on this scheme ought be logged or otherwise publicised as a possible way to provide some level of accountability, even if only after the fact?",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-08-15 17:44:33-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-03 18:15:50-07:00",
    "text": "Firstly, thank you for documenting operational practice. With regards to section 3.3: \"BGP speakers SHOULD only accept and honor BGP announcements carrying the BLACKHOLE community ..\" I really question why this is a \"SHOULD\" and not a \"MUST\", even in an informational RFC. Is the ability for a transit provider so loose that appropriate route filters from a peer ASN can't be applied so that only a \"SHOULD\" is practical? In which case I do question the sanity of making such a recommendation and thus service available if some other ASN might be able to inject the route and affect another service, even by mistake. Potentially if RPKI is in use, then a peer AS might be able to validate the announcement against a ROA. But it strikes me that this is not the machinery you would want to tack on in this case. The same could be said for section 3.2. I would be rather wary of NOT adding a NO_ADVERTISE (at the very least) and to be honest SHOULD still seems far too loose for me. Almost all of the recipe's that I've gazed upon",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-01-06 11:42:57-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-05 10:39:25-08:00",
    "text": "Regarding Section 4.3.3, do we typically use IETF documents to normatively extend OASIS specs? Wanted to check since we try to keep an eye on this kind of thing when other SDOs extend/alter IETF specs. And relatedly, the document's intended status is listed in the header as Standards Track but the shepherd write-up says:  \"Informational. It could be experimental as well, but since the specification of various SAML constructs lies outside the realm of the IETF and the definition of the 2 RADIUS attributes is not really experimental, informational seems the right classification.\" So I'm wondering what is going on with that.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-10 12:29:36-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 13:25:16-08:00",
    "text": "Thanks for your work on this draft.\u00a0 The current template for the security consideration section was not used, could you please update the draft?\u00a0 I believe this is the current working version: https://tools.ietf.org/html/draft-ietf-netmod-rfc6087bis-10#page-52 If there is a reason for not elaborating on data nodes per the template (too many rw, etc.) a summary would be helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-09-08 02:00:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-04 03:35:23-07:00",
    "text": "I need to re-LC the document, calling out DownRefs to the following documents: \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 1951 Already in the DownRef registry. \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 1952 GZIP \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 1977 PPP BSD Compression Protocol \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 2818 Already in the DownRef registry \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 3196 Internet Printing Protocol/1.1: Implementor's Guide \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 7612 Lightweight Directory Access Protocol (LDAP): Schema for Printer Services \u00a0 -- Obsolete informational reference (is this intentional?):  RFC 2565 \u00a0 \u00a0  (Obsoleted by  RFC 2910 ) \u00a0 -- Obsolete informational reference (is this intentional?):  RFC 2566 \u00a0 \u00a0  (Obsoleted by  RFC 2911 ) These 2 Experimental RFCs are intended references. --- \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 3239 Internet Printing Protocol (IPP): Requirements for Job, Printer, and Device Administrative Operations \u00a0 This can be Informative \u00a0 ** Downref: Normative reference to an Informational RFC:  RFC 3997 Internet Printing Protocol (IPP): Requirements for IPP Notifications \u00a0 This can be Informative",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-08-04 12:18:02-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-02 20:48:59-07:00",
    "text": "I think this should be easy to resolve, but I would like to see discussion before the document progresses. This is closely related to my second discuss point for 2910bis: Section 4.1.8 says \"IPP implementations SHOULD accept any \u00a0  request with the major version \u20191\u2019 or \u20192\u2019, or reject the request if \u00a0  the operation is not supported.\" The SHOULD level requirement for \"forward\" compatibility seems unusual. How is that different than saying implementations SHOULD implement 2.X and be backwards compatible to 1.1? If it's the same thing, then should have text discouraging new implementations of 1.1?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-05 07:09:38-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 06:44:04-08:00",
    "text": "The shepherd writeup (which has a note that it is still in progress and not ready for submission) indicates that the \"IPR questions are pending\". Please confirm that they were affirmatively resolved.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-11 22:32:07-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 12:32:51-08:00",
    "text": "Quite minor points, really, but they do need to be resolved before publication.\u00a0 (Slightly more details/locations in the COMMENT section.) We don't actually provide a definition (whether directly or by reference) for the \"classic calculation for standard deviation of a population\". We don't actually provide a definition (whether directly or by reference) for what the \"time_offset\" calibration value records.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-12-03 10:37:26-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 05:55:49-08:00",
    "text": "Thank you for the work put into this document.  I have a couple of easy and trivial to fix DISCUSS. And a couple of COMMENTs, feel free to ignore the COMMENTs but I would appreciate it if you replied to them. Regards, -\u00e9ric == DISCUSS == -- Section 4.2.2 -- Easy to fix: there is no 'protocol' field in the IPv6 header but a 'next header' one that has the same semantic. -- Section 9.2.2. -- Also easy to fix, 'next header' for ICMPv6 is not 01 but 58 (decimal) and 'ICMPv6 echo request' is 128 (decimal).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-12-12 00:36:25-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 02:10:30-08:00",
    "text": "I think these entries shows well how the registry is intended to extended and the benefit in being clear on what information is needed. I do have a question that I think needs an answer: Regarding Section 4.2.2: \u00a0  o\u00a0 IPv6 header values: \u00a0 \u00a0 \u00a0 *\u00a0 DSCP: set to 0 \u00a0 \u00a0 \u00a0 *\u00a0 Hop Count: set to 255 \u00a0 \u00a0 \u00a0 *\u00a0 Protocol: Set to 17 (UDP) Does anything about the IPv6 flow ID need to be stated here? As this is a path delay measurement, the value of the flow ID field has the potential to change the result. If one would use a new random value for each individual measurement in a sequence one may see different results than from using the same ID for all the measurements. Or is this specified in any of the references? In most case I would expect one use a single value, but likely randomly selected. However, it does depend on what purpose of ones measurement one have, thus I think this do matter.  I think this question applies to all measurements that are multi-packet ones so section 5, 7, 8 and 9 most definitely.  I also wonder if IPv6 Flow ID is an output parameter that needs to be kept?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-09 21:51:44-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 17:46:44-08:00",
    "text": "I have a 0-RTT-related topic that I'd like to discuss, as the current situation isn't entirely clear to me.\u00a0 In particular, TLS 1.3 provides (and QUIC inherits) a mechanism for a server to advertise that it just does not support 0-RTT at all, via the (absence of the) \"early_data\" extension.\u00a0 This meshes nicely with the guidance in  RFC 8446  that 0-RTT is to only be used cautiously, and only with specific request from the application.\u00a0 However, this specificiation diverges from that requirement for application opt-in (per \u00a79.1), and so when I read the directive in \u00a75.5 that \"servers MUST adopt one of the following behaviors\", I am forced to wonder if the absence of a \"abort the connection, because you do not enable early data at all\" option is intended to forbid a server from taking that approach and thus require servers to implement and enable 0-RTT at runtime. I hope that the intent was just for the \u00a75.5 listing to be predicated on the server using 0-RTT at all, but it's hard to reach that conclusion from the existing text, so I have to seek clarification.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-02-08 19:17:51-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 15:40:52-08:00",
    "text": "I plan to ballot \"yes\" for this document, but I have some concerns about the security properties that I think need to be resolved first. I have followed the discussion resulting from Robert's Gen-ART review (and will have comments about that in the \"COMMENTS section\", but I think I see an additional issue that hasn't been covered in that discussion. draft-ietf-bfcpbis-rfc4582bis  (currently in the RFC Editors queue) defines some situations where TLS and client authentication are normatively required. Specifically, section 9 of that draft says that, if the signaling channel is authenticated and has confidentiality and integrity protection, the BFCP client MUST be authenticated. Section 14 additionally says that under those circumstances, BFCP is REQUIRED to use the mandated cryptographic algorithm. But bfcp-websocket only says that WSS and client authentication are RECOMMENDED. I think this could be fixed by requiring WSS, and the web-based client authentication techniques described in this draft whenever the signaling protocol is secured. The simplest way to describe that might be to say that BFCP-websocket must use at least as strong protections as the signaling channel.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-07-16 08:02:59-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-05 05:41:31-07:00",
    "text": "This is a pretty minor point and should be easy to resolve, but there seems to be an internal inconsistency that is introduced with the new section on Constrained Devices.\u00a0 In particular, Section 1.1 has a short note: \u00a0  This document assumes that all IPv6 nodes meet the minimum \u00a0  requirements specified here. but Section 15 says something a bit different: \u00a0  [...] While the requirements of this \u00a0  document are RECOMMENDED for all nodes, including constrained nodes, \u00a0  compromises may need to be made in certain cases.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-10-06 07:46:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-06 07:46:18-07:00",
    "text": "The text contains contradictions on how to handle implementation-time use case that might use the YANG file format. (a) Section 2. \u201cThe file MUST be available already at implementation time, retrievable in a way that does not depend on a live network node.\u00a0 E.g., download from product website.\u201d (b) Section 2. \u201cThe YANG modules specified in this document define a schema for data that is designed to be accessed via network management protocols such as NETCONF [ RFC6241 ] or RESTCONF [ RFC8040 ].\u00a0 \u2026 The Network Configuration Access Control Model (NACM) [ RFC8341 ] provides the means to restrict access for particular NETCONF or RESTCONF users\u201d (c) Section 2.\u00a0 \u201cWhen that data is in file format, data should be protected against modification or unauthorized access using normal file handling mechanisms.\u201d (a) \u2013 (c) cannot all be satisfied at the same time.\u00a0 (b) seems to only apply to the run-time use cases.\u00a0 (a) and (b) seem to apply to the implementation time use cases.\u00a0 Please make this clearer.\u00a0  Per (c), it might be clearer to keep this text, but also noting that using the YANG file format inherits all of the security considerations of  draft-ietf-netmod-yang-instance-file-format  which has additional considerations about read protections; and distinguishing between data at rest and in motion.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-10-14 15:05:51-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 07:46:32-07:00",
    "text": "The text contains contradictions on how to handle implementation-time use case that might use the YANG file format. (a) Section 2. \u201cThe file MUST be available already at implementation time, retrievable in a way that does not depend on a live network node.\u00a0 E.g., download from product website.\u201d (b) Section 2. \u201cThe YANG modules specified in this document define a schema for data that is designed to be accessed via network management protocols such as NETCONF [ RFC6241 ] or RESTCONF [ RFC8040 ].\u00a0 \u2026 The Network Configuration Access Control Model (NACM) [ RFC8341 ] provides the means to restrict access for particular NETCONF or RESTCONF users\u201d (c) Section 2.\u00a0 \u201cWhen that data is in file format, data should be protected against modification or unauthorized access using normal file handling mechanisms.\u201d (a) \u2013 (c) cannot all be satisfied at the same time.\u00a0 (b) seems to only apply to the run-time use cases.\u00a0 (a) and (b) seem to apply to the implementation time use cases.\u00a0 Please make this clearer.\u00a0  Per (c), it might be clearer to keep this text, but also noting that using the YANG file format inherits all of the security considerations of  draft-ietf-netmod-yang-instance-file-format  which has additional considerations about read protections; and distinguishes between data at rest and in motion.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-09-22 20:33:55-07:00",
    "text": "Many thanks for taking on the task of producing a roll-up update for the core TCP specification!\u00a0 I am sure it was a lot of work, but I am happy to see it done. That said, I do have a few points that I would like to have a bit more discussion on before the document is published; I'm happy to see that Warren already linked to https://www.ietf.org/blog/handling-iesg-ballot-positions/  on the topic of what a DISCUSS position can (and cannot) mean. (1) We incorporate some long-standing enhancements that improve the security and robustness of TCP (in particular, random ISN and protection against off-path in-window attacks come to mind), but only at SHOULD or MAY requirements level. For example, we currently say: \u00a0  A TCP implementation MUST use the above type of \"clock\" for clock- \u00a0  driven selection of initial sequence numbers (MUST-8), and SHOULD \u00a0  generate its Initial Sequence Numbers with the expression: \u00a0  ISN = M + F(localip, localport, remoteip, remoteport, secretkey) and: \u00a0 \u00a0 \u00a0 \u00a0  +\u00a0  RFC 5961  [37] section 5 describes a potential blind data \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 injection attack, and mitigation that implementations MAY \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 choose to include (MAY-12).\u00a0 TCP stacks that implement \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  RFC 5961  MUST add an input check that the ACK value is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [...] What prevents us from making a MUST-level requirement for randomized ISNs?\u00a0 Is it just the fact that it was only a SHOULD in  RFC 6528  and a perception that promoting to a MUST would be incompatible with retaining Internet Standard status? Likewise, what prevents using stronger normative language (e.g., MUST) for the  RFC 5961  protections? It seems to me that these mechanisms are of general applicability and provide significant value for use of TCP on the internet, even though they are not fully robust and do not use cryptographic mechanisms.\u00a0 If there are scenarios where their use is harmful or even just not applicable, that seems like an exceptional case that should get documented so as to strengthen the general recommendation for the non-exception cases. (2) I think this is just a process question to ensure that the IESG knows what we are approving at Internet Standard maturity, though it is certainly possible that I misunderstand the situation. In Section 3.7.3 we see the normative statement (SHLD-6) that \"when the when the effective MTU of an interface varies packet-to- packet, TCP implementations SHOULD use the smallest effective MTU of the interface to calculate the value to advertise in the MSS option\".\u00a0 This seems to originate in  RFC 6691  (being obsoleted by this document), but  RFC 6691 is only an Informational document and has not had an opportunity to \"accumulate experience at Proposed Standard before progressing\", to paraphrase  RFC 6410 . Similarly, Section 3.9.2 has (SHLD-23) \"Generally, an application SHOULD NOT change the DiffServ field value during the course of a connection (SHLD-23).\"\u00a0 This is a bit harder to track down, as the DiffServ field was not always known by that name.\u00a0 I actually failed to find a directly analogous previous statement of this guidance (presumably my error), and thus don't know if it had any experience at the PS level or not. RFC 6410  seems pretty clear that some revisions are okay in Internet Standards without such \"bake time\" at PS, but it does seem like something that should be done consciously rather than by accident. (3) This is also a process point for explicit consideration by the IESG. Appendix A.2 appears to discuss a few (rare) scenarios in which the technical mechanisms of this document fail catastrophically (e.g., getting stuck in a SYN|ACK loop and failing to complete the handshake). Does this meet the \"resolved known design choices\" and \"no known technical omission\" bar required by  RFC 2026  even for *proposed* standard? (Note that  RFC 2026  explicitly says that the IESG may waive this requirement, at least for PS.) (AFAICT one such scenario is reported at https://www.rfc-editor.org/errata_search.php?eid=3305  , which the change log for this document calls out as \"not applicable due to other changes\"; I am not sure which \"other changes\" are intended, for this case.) (4) Another point mostly just to get explicit IESG acknowledgment (elevating one of Lars' comments to DISCUSS level, essentially). As the changelog (and gen-art reviewer!) notes: \u00a0  Early in the process of updating  RFC 793 , Scott Brim mentioned that \u00a0  this should include a PERPASS/privacy review.\u00a0 This may be something \u00a0  for the chairs or AD to request during WGLC or IETF LC. I don't see any evidence to suggest that such a review actually occurred.\u00a0 Do we want to seek out such a targeted review before progressing?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-11 02:46:18-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-20 07:18:33-07:00",
    "text": "The IESG needs to approve the following DOWNREFs during the telechat: \u00a0 DOWNREF [10] from this Internet Standard to Proposed Standard  RFC6298 . \u00a0 DOWNREF [2] from this Internet Standard to Draft Standard  RFC1191 . \u00a0 DOWNREF [7] from this Internet Standard to Proposed Standard  RFC3168 . \u00a0 DOWNREF [11] from this Internet Standard to Proposed Standard  RFC6633 . \u00a0 DOWNREF [9] from this Internet Standard to Draft Standard  RFC5681 . \u00a0 DOWNREF [5] from this Internet Standard to Proposed Standard  RFC2675 . \u00a0 DOWNREF [4] from this Internet Standard to Proposed Standard  RFC2474 .",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-09-22 15:52:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-09-22 15:51:13-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-12-16 10:32:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 15:52:37-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS, because I think that it is important enough that it needs addressing: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-02-17 06:37:48-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 13:45:17-07:00",
    "text": "* I found at least one reference that should be normative reference but they are not. Section 3.8.5 : describes -- \u00a0   \u00a0 \u00a0 TCP implementations MUST still include support for the urgent mechanism (MUST-30). Details can be found in  RFC 6093  [38] \u00a0  \u00a0 This to ne makes  RFC6093  a must to read and understand to deploy this specification. Hence it should in the normative references. * (This perhaps more process thing than technical), me and Benjamin Kaduk discussed another issue regarding urgent pointer. This specification specifies - \u00a0 \u00a0 \u00a0  Pointer indicates first non-urgent octet\u00a0 \u00a0 \u00a0  | MUST-62|  \u00a0  \u00a0  RFC1011  rectifies  RFC973  to - \u00a0 \u00a0 \u00a0 The urgent pointer points to the \u00a0 \u00a0 \u00a0 \u00a0  last octet of urgent data (not to the first octet of non-urgent \u00a0 \u00a0 \u00a0 \u00a0  data). \u00a0 So what does happen to  RFC1011  rectification then when 793bis is not bis anymore? Is this a known fact and there is conscious decision not to do anything about it? or was this a unknown fact and that part of  RFC1011  need to be obsoleted (how?)?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-15 10:12:31-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 12:55:17-07:00",
    "text": "The following is a nit, but I think it is important that it gets fixed: In Section 4.1: \u00a0  The example in Figure 3 shows a restriction to the key used in \u00a0  Figure 1.\u00a0 Extra whitespace is added to meet formatting constraints. \u00a0  POST /subscribe/ HTTP/1.1 \u00a0  Host:  push.example.net \u00a0  Content-Type: application/webpush-optjons+json;charset=utf-8 Firstly, \"optjons\" above should be \"options\". Secondly, the MIME type registration of application/webpush-options+json says that the MIME type has no parameters, yet you use charset above. So which is it? \u00a0  Content-Length: 104 \u00a0  { \"vapid\": \"BA1Hxzyi1RUM1b5wjxsn7nGxAszw2u61m164i3MrAIxH \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  F6YK5h4SDYic-dRuU_RCPCfA5aq9ojSwk5Y2EmClBPs\" }",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-08-16 18:05:59-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 19:21:24-07:00",
    "text": "In section 2: \"A push service MAY reject a request with a 403 (Forbidden) status code [ RFC7235 ] if the JWT signature or its claims are invalid.\"  This seems to leave the possibility of simply ignoring an invalid VAPID token or signature. Assuming we are talking about push servers that support VAPID in the first place, that seems dangerous. Wouldn't it be safer in the general case to treat a request with an invalid VAPID token as at least a bit fishy? I don't mean to say that ignoring the token is never the right thing to do. But the MAY seems week without some guidance on what other actions might be reasonable under what circumstances.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-10-11 09:51:18-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 16:42:27-07:00",
    "text": "This design seems to have the unfortunate security property that the JWT is really just a bearer token. The only reason it has to involve public key cryptography at all is to allow the push cient to refer to the public key when it makes a subscription. However, as the Security Considerations acknowledge, this allows a cut-and-paste attack (more than just replay) by an attacker who acquires any JWT, because it does not include the message itself. The primary motivation for this appears to be to minimize CPU cost on the push service. However, there are designs which do this without allowing replay. For instance: - Have the push service have a static public key K_svc which \u00a0 is published to application servers (e.g., via well-known). - In order to form the JWT, have the application server generate \u00a0 a fresh DH key K_app, which is embedded in the JWT. - The message which the app server sends to the push service \u00a0 is then MACed with the DH shared secret Z. This removes the cut-and-paste attack (though of course replay attacks are still possible) unless the push service keeps a replay cache. The replay service can trivially amortize the DH computation (it has to amortize the signature verification in any case to get any computational benefit) but it's soft state, so it can just forget it at any time. Ultimately, this is a WG decision, but given that there are designs with much better security properties, I'd like to know that the WG considered and rejected this kind of design alternative before we advance the weaker design.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-12-22 06:49:02-08:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 12:29:32-07:00",
    "text": "I haven't sen a response to the SecDir review, so please point me to one if there has been a response.\u00a0 I fully agree with Tero that MD5 is not adequate and hasn't been for some time.\u00a0 What is the plan to rectify this and deprecate use of the TCP MD5 signature for LDP?\u00a0  RFC8077 , says that LDP MD5 authentication key option as described in the section 2.9 of  RFC5036  MUST be implemented.\u00a0 I asked on my ballot for  RFC8077  when a deprecation process would start in support of Stephen's abstain and would like an update on that process. https://mailarchive.ietf.org/arch/msg/secdir/ga2pIVcGw9WEgBX5MXA9MCmSs_s",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-11-12 22:34:15-08:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 18:07:25-07:00",
    "text": "* Section 7.3. mLDP Opaque Value Element TLV Type From my reading of  RFC6388 , the \"Value\" in the TLV type is interpreted based on the type and this document does not seem to specify what goes into the value. Additionally, the document requests the type \"0x3\" but it looks like that type has been allocated already to \"Transit IPv4 Source TLV type\" as per https://www.iana.org/assignments/ldp-namespaces/ldp-namespaces.xhtml#ldp-namespaces-11",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-28 15:50:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 16:33:46-07:00",
    "text": "I think we lack sufficient precision (forgive the pun) in how we talk about \"accuracy\" and \"precision\".\u00a0 Are the leafs that claim to specify \"accuracy\" specifying a precision?\u00a0 If so, the precision of a specific measurement, the precision of the measurements that led to the creation of the coordinate frame, or something else?\u00a0 Are they doing so in relative terms (e.g., percentage) or absolute terms (e.g., degrees and meters)?\u00a0 (There are \"units\" directives only for \"height-accuracy\" and not the others.)\u00a0 How can we we say that we'll have 16 fraction-digits of precision for lat/long when the maximum accuracy we can say that a geodetic-system has only gives us 6 fraction-digits for coord-accuracy? When we say that the \"precision of this measurement is indicated by the reference-frame\" is that the same thing as the relevant \"-accuracy\" nodes, or something else?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-06-17 15:09:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 05:13:23-07:00",
    "text": "Thank you for the work on this document, and thank you to the shepherd for a very well-written shepherd write up. I have a couple of DISCUSS points related to the IANA section, and some non blocking question. Francesca 1. ----- \u00a0  The allocation policy for this registry is First Come, First Served, \u00a0  [ RFC8126 ] as the intent is simply to avoid duplicate values. FP:  RFC 8126  specifies: \u00a0  When creating a new registry with First Come First Served as the \u00a0  registration policy, in addition to the contact person field or \u00a0  reference, the registry should contain a field for change controller. \u00a0  Having a change controller for each entry for these types of \u00a0  registrations makes authorization of future modifications more clear. \u00a0  See Section 2.3. The current registry dos not contain contact person, nor reference, nor change controller fields. 2. ----- \u00a0  It should be noted that [ RFC5870 ] also creates a registry for \u00a0  Geodetic Systems (it calls CRS); however, this registry has a very \u00a0  strict modification policy.\u00a0 The authors of [ RFC5870 ] have the stated \u00a0  goal of making CRS registration hard to avoid proliferation of CRS \u00a0  values.\u00a0 As our module defines alternate systems and has a broader \u00a0  (beyond Earth) scope, the registry defined below is meant to be more \u00a0  easily modified. FP: Thanks for bringing this up - I want to confirm that we need this registry, and that we are not creating a way to bypass the CRS registration policies by providing a different registry with a more lenient policy.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-06-22 04:02:09-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-17 02:32:38-07:00",
    "text": "Section 8, paragraph 2, discuss: >\u00a0 \u00a0 [EGM08]\u00a0 \u00a0 Pavlis, N.K., Holmes, S.A., Kenyon, S.C., and J.K. Factor, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"An Earth Gravitational Model to Degree 2160: EGM08.\", >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Presented at the 2008 General Assembly of the European >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Geosciences Union, Vienna, Arpil13-18, 2008, 2008, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 egm08_wgs84.html>. > >\u00a0 \u00a0 [EGM96]\u00a0 \u00a0 Lemoine, F.G., Kenyon, S.C., Factor, J.K., Trimmer, R.G., >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Pavlis, N.K., Chinn, D.S., Cox, C.M., Klosko, S.M., >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Luthcke, S.B., Torrence, M.H., Wang, Y.M., Williamson, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  R.G., Pavlis, E.C., Rapp, R.H., and T.R. Olson, \"The >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Development of the Joint NASA GSFC and the National >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Imagery and Mapping Agency (NIMA) Geopotential Model >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  EGM96.\", Technical Report NASA/TP-1998-206861, NASA, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Greenbelt., 1998, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . I question whether these two can be normatively referenced without an explicit DOWNREF check. First, the URLs of both are broken. Second, the cached versions on  archive.org  seem to be web pages that link to a lot of other material, with no indication that anything on these pages is standards material. Are better references available here?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-07-15 08:35:21-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 15:09:26-07:00",
    "text": "** Section 3.\u00a0 leaf astronomical-body.\u00a0 The content of this field appears to be \"An astronomical body as named by the International Astronomical Union (IAU) or according to the alternate\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 system if specified.\"\u00a0 What\u2019s the normative reference to the IAU\u2019s list of astronomical bodies.\u00a0 Listed here is \u201c https://www.iau.org \u201d which is an unstable reference to a website with changing content.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-04 08:21:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-24 23:17:14-08:00",
    "text": "I support \u00c9ric's and Erik's and Roman's Discusses. We've had similar issues with embedding client IP addresses in security tokens all over the place, e.g., in Kerberos tickets, where it provided negligible security benefit and frequently caused (hard to diagnose!) breakage. I further note based on some of the responses so far that (as I understand it) the issues of multiple client IPs is quite realistic just for making requests to the CSP vs the uCDN, and no amount of time-locality can save us. I expect that the IESG will have some in-person discussion of this topic and what we are willing to put in an IETF-stream RFC.\u00a0 (My own personal opinion is that we have a fair amount of leeway to document \"some people are doing this thing\" accompanied by explanations of the flaws in that practice, but that we have very limited scope to recommend bad practices.) I think we should also discuss the proposed technique of redistributing shared secrets used to generate MACs for signed JWTs.\u00a0 I see a minimal acknowledgment that there is potential cause concern in the penultimate paragraph of the security considerations that \"it is important to know the implications of a compromised shared key\", but in my mind the text there does not really call out the severity of those implications.\u00a0 I would have expected something like \"redistributing the shared key in this manner allows the dCDNs to impersonate the CSP to the uCDN and produce arbitrary signed URLs that are accepted by the uCDN as authentic\".\u00a0 Well, what I *actually* would have expected was to just not define this mechanism at all, as it is too risky to use a group-shared symmetric key in a group where participants are at different trust levels.\u00a0 But perhaps the WG can produce some explanation of why this is acceptable... I also have concerns about our guidance to leave the JWT \"jti\" unchanged when re-signing with different contents, e.g., changing Issuer and/or Audience, etc..\u00a0 We don't seem to mention one way or another whether \"jti\" needs to be preserved while performing Signed Token Renewal, but changing the \"exp\" while preserving \"jti\" seems like it would be problematic as well.\u00a0 The guidance in  RFC 7519  is somewhat vague (basically, that it needs to change if it identifies a \"different data object\"), so we may want to consult the broader OAuth WG (not necessarily just the IANA DE) for further interpretation.\u00a0 I can also add based on the responses so far that the \"jti\" is not solely to be used to prevent replay, and so I am skeptical of reasoning based on such an argument. The combined defaults for the CDNI Metadata Interface for URI Signing seem to be an unsafe combination.\u00a0 Specifically, the default behavior for the \"issuers\" property is to allow any Issuer, and the default for the \"jwt-header\" property is to take the header from the JWT in band. As far as I can tell, this means that the dCDN will just blindly accept anything that is formatted as a JWT and signed by any key nown to the dCDN.\u00a0 The authentication and authorization properties of such behavior are so poor so as to effectively be useless, absent some level of care surrounding key management to isolate keys to given URIs.\u00a0 In fact, the lack of substantive discussion of key management and requirements thereof seems Discuss-worthy in its own right.\u00a0 We need to say something about obtaining a key along with a trust path to what it's authorized to be used for, even if the specific protocol mechanism for doing so is left out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-20 13:28:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-04 08:21:49-08:00",
    "text": "Thanks for the updates in the -22 through -24.\u00a0 I think a couple of my discuss points remain at the discuss level, which I'll expound on a bit more below. I am happy to see the pervasive disclaimers that use of a symmetric shared key is supported but NOT RECOMMENDED, and the note that redistribution of the symmetric shared key to dCDNs (including cascaded CDNs) is included for legacy feature parity and highly discouraged in new implementations. However, I think this does not fully address my original discuss point.\u00a0 As I said then, [[I see a minimal acknowledgment that there is potential cause concern in the penultimate paragraph of the security considerations that \"it is important to know the implications of a compromised shared key\", but in my mind the text there does not really call out the severity of those implications.\u00a0 I would have expected something like \"redistributing the shared key in this manner allows the dCDNs to impersonate the CSP to the uCDN and produce arbitrary signed URLs that are accepted by the uCDN as authentic\".]]\u00a0 In particular, I think it is important to emphasize in some manner that the cryptographc properties of the symmetric shared key are fully symmetric across all participants, even though the administrative and organizational structure here is hierarchical with explicitly more- and less-trusted entities, making the symmetric cryptographic mechanism a mismatch for the desired trust boundaries and inviting abuse.\u00a0 Only contractual controls prevent misuse in this scenario, whereas we have well-understood technologies that allow technical measures to prevent misuse that are preferred. It's also still unclear to me that there's sufficient need to document the symmetric key *redistribution* case in this document at all, if the only use case is for \"legacy feature parity\".\u00a0 Given that it's a fairly simple idea, what is to stop us from leaving it undocumented in this Proposed Standard and letting any implementors that need it do so on their own, or with a separate Informational document mentioning its existence?\u00a0 I am not aware of any preexisting IETF work that we need to retain compatibility with, and the data presented so far does not make a compelling (to me) case that we must include this functionality in order for the IETF offering to be competitive. (To be clear, I do not object to describing the use of symmetric keys for a single-hop scenario, as the risks there are much smaller.) I'd also like to have some additional discussion on this point from my previous Discuss position, reproduced with typo fixed: === The combined defaults for the CDNI Metadata Interface for URI Signing seem to be an unsafe combination.\u00a0 Specifically, the default behavior for the \"issuers\" property is to allow any Issuer, and the default for the \"jwt-header\" property is to take the header from the JWT in band.\u00a0 As far as I can tell, this means that the dCDN will just blindly accept anything that is formatted as a JWT and signed by any key known to the dCDN.\u00a0 The authentication and authorization properties of such behavior are so poor so as to effectively be useless, absent some level of care surrounding key management to isolate keys to given URIs.\u00a0 In fact, the lack of substantive discussion of key management and requirements thereof seems Discuss-worthy in its own right.\u00a0 We need to say something about obtaining a key along with a trust path to what it's authorized to be used for, even if the specific protocol mechanism for doing so is left out of scope. === I do see that \u00a71.3 gained a mention of \"obtain the key in a manner that allows trust to be placed in the assertions made using that key\", apparently per my suggestion in my original COMMENT section.\u00a0 However, I don't think this is sufficient.\u00a0 I strongly encourage a dedicated section on the requirements for key management and how updates (both additions and removals) of the list of trusted Issuer/key pairs are managed.\u00a0 Failing that, at a minimum the default for the \"issuers\" property in the CDNI Metadata Interface needs to be changed to say that an empty list means that any Issuer in the dCDN's trusted key store of issuers is acceptable for signing JWTs for URI signing.\u00a0 This is to be contrasted with \"any Issuer at all\", which does not impose an obligation on the dCDN to maintain a list of Issuer/key pairs trusted for signing JWTs used in signed URIs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 12:59:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-20 13:28:53-07:00",
    "text": "I see that the -25 has demoted discussion of symmetric key redistribution from (paraphrasing) \"a normal thing mentioned in passing\" to a SHOULD NOT action.\u00a0 This is a step in the right direction, but I am not sure that it's far enough.\u00a0 Is there some additional background on why this functionality (of key redistribution from uCDN to dCDN in particular, or group sharing of a single symmetric key from CSP to both uCDN and dCDN) is required to retain that I am failing to find?\u00a0 The latest discussion I see in the WG email archives is https://mailarchive.ietf.org/arch/msg/cdni/iFP6w3z22yQ1s0IJisrsIJN1ikU/ which seemed to suggest that the mechanism would be removed entirely. The security properties of this group key sharing are sufficiently poor that (if we do need to keep it) I think there would need to be explicit discussion in the document about what the use case is and why that use case allows for the weakening of security properties.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-11-15 04:56:10-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-23 05:50:03-08:00",
    "text": "Thank you for the work put into this document. Special thanks for the doc shepherd write-up , which was really useful about the WG history. Please find below one blocking DISCUSS points (which should be solved easily), one non-blocking COMMENT point (but replies would be appreciated), and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2.1.10 -- About \"Client IP (cdniip) claim\", I really wonder whether this could be used in real life as some IPv4 Carrier-Grade NAT (CGN) have a large pool of \"public\" IPv4 addresses that could select different public IPv4 addresses if badly designed. How will it work with dual-stack UAs where some connections could be over IPv4 and some over IPv6 ? Now to mention a dual-home (Wi-Fi & mobile data) UA ? Or what if the dCDN is between the UA and the CGN (assuming that the uCDN or CSP are upstream of the CGN) ? Also, \"If the received signed JWT contains a Client IP claim\" uses singular rather than \"one or several\"  I also noted that Section 7 (security considerations) puts some restrictions on the usefulness of cdniip. I would welcome some applicability statements on the use of cdniip.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-01-03 04:50:17-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-15 04:56:10-08:00",
    "text": "Thank you for the work put into this document. Thank you for fixing all my previous COMMENTs in the -22 revision. I am afraid that I need to keep my DISCUSS about the cdniip even with the addition of a paragraph at the end of section 2.1.10... This paragraph ressembles to an application statement but it it really light. Why did the authors select not to use  RFC 8174  normative language \u201cNOT RECOMMENDED\u201d ? The section 7 (security considerations) is still very light on the IP address sharing. -\u00e9ric == DISCUSS == -- Section 2.1.10 -- About \"Client IP (cdniip) claim\", I really wonder whether this could be used in real life as some IPv4 Carrier-Grade NAT (CGN) have a large pool of \"public\" IPv4 addresses that could select different public IPv4 addresses if badly designed. How will it work with dual-stack UAs where some connections could be over IPv4 and some over IPv6 ? Now to mention a dual-home (Wi-Fi & mobile data) UA ? Or what if the dCDN is between the UA and the CGN (assuming that the uCDN or CSP are upstream of the CGN) ? Also, \"If the received signed JWT contains a Client IP claim\" uses singular rather than \"one or several\"  I also noted that Section 7 (security considerations) puts some restrictions on the usefulness of cdniip. I would welcome some applicability statements on the use of cdniip.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-12-29 21:34:23-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 17:46:53-08:00",
    "text": "Apologies for piling on, but I want to second Eric Vyncke's Discuss.\u00a0 The use of Client IP addresses is more problematic than one might suspect from a reading of this document. RFC 8305  Happy Eyeballs means for a dualstack client and a dualstack CSP or CDN there are no guarantees that the address family will be the same. Furthermore, a client using  RFC 8981  (4941bis) IPv6 temporary addresses might change source address (even with every request) so an exact match would not be recommended. To make matters even more complicated, a mobile client might make the CSP request on Wi-Fi, walk out of range, and complete a subsequent CDN request via its mobile provider network (or vice versa).\u00a0 So, even using a fairly short CIDR length for truncation may not work since the origin network can be completely different between requests. The latter behaviour can also be trigger by connection migration transports, like MPTCP and (soon) QUIC. I think one solution might include relaxing all the MUSTs in section 2.1.10. Instead, perhaps some text that clarifies the presence of reliability issues with Client IPs and recommends that CDNs be develop a more sophisticated policy (or avoid using this altogether and prefer to use other claims). Including the Client IP for logging purposes might be helpful, but being too strict about verifying it can lead to client-visible failures. Alternatively, UAs need to be augmented to know that when a cdniip is part of the claim that it must try to keep the source IP address the same for subsequent requests, recognizing, as section 7 does, that NAT can make this impossible.\u00a0 I'm not sure this is a workable option, though.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-04 08:05:44-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 18:01:03-08:00",
    "text": "** Section 1.3.\u00a0 Per \u201cNote that the signed Redirection URI MUST maintain the same (or higher) level of security as the original Signed URI.\u201d: -- How is this equivalence assessed? -- Can one create an architecture to that cascades a mix of uCDNs whose path will mix both asymmetric and symmetric keys?\u00a0 Assuming that\u2019s possible what\u2019s \u201csame or higher\u201d here? ** Section 2.1.7.\u00a0 The specified use of the jti claim in the URI signing workflow appears to conflict with the underlying definition of this claim in  RFC7519 . (a) Section 1.3. says \u201c\u2026 the CSP needs to allow the uCDN to redistribute shared keys to a subset of their dCDNs.\u201d (b) Section 2.1.7 says \u201cIf the received signed JWT contains a Nonce claim, then any JWT subsequently generated for CDNI redirection MUST also contain a Nonce claim, and the Nonce value MUST be the same as in the received signed JWT.\u201d (c.1) Section 4.1.7 of  RFC7519  says \u201cThe identifier value MUST be assigned in a manner that ensures that there is a negligible probability that the same value will be accidentally assigned to a different data object \u2026 (c.2) Section 4.1.7 of  RFC7519  also says \u201c\u2026 if the application uses multiple issuers, collisions MUST be prevented among values produced by different issuers as well.\u201d The constraints in (b) suggests that the Nonce claim value needs to be the same across every logical hop in the cascading CDN path.\u00a0 My understanding of the architecture is that some of the claims in the JWTs such as the cdniuc or cdnistd claims might changes when there are cascading CDNs.\u00a0 If they change, this seems like that would constitute a different \u201cdata object\u201d who have the same unique (jti claim) identifier which would violate (c.1).\u00a0 One could argue that perhaps the CDNs are at arm-length so they aren\u2019t really an \u201capplication us[ing] multiple issuers\u201d, however, the architectural construct of shared keys suggested by (a) seems to imply otherwise which would suggest that this violated (c.2).\u00a0 If I\u2019ve misunderstood the architecture let me know. The notion of keeping the nonce the same seems like the right design, its just the reuse of this particular claim seems mismatched.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-07 00:02:29-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-06 19:13:05-07:00",
    "text": "Thanks for the work everyone has done on this document. I have a concern about an ambiguity that can potentially lead to interop issues between clients and servers that make different assumptions around \\Important mailbox ordinality. The second example in section 3.2.2 and the use of the singular form \"mailbox\" in this passage from section 5 imply that only one mailbox is allowed to be tagged \"\\Important\": >\u00a0 As noted in  RFC 6154 , it is wise to protect the IMAP channel from >\u00a0 passive eavesdropping, and to defend against unauthorized discernment >\u00a0 of the identity of a user's \"\\Important\" mailbox... However, I find no normative text that indicates whether this is expected to be inherent to the mechanism, or whether servers can exercise discretion about allowing more than one mailbox to be tagged \\Important. In particular, I want to ensure that no one develops a client that assumes that the server will prevent it from having multiple such mailboxes (relying on an error in the case that it tries to create a second one), and then chokes when it happens. Similar issues can arise with a permissive server and two clients with different notions about whether multiple \\Important mailboxes are allowed. Please add normative language that either explicitly disallows this behavior, or explicitly allows this behavior.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-04-29 13:20:48-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-06 11:26:16-08:00",
    "text": "= Section 5.1.8 = Name: staleresourcetime \u00a0 \u00a0 \u00a0 \u00a0  Description: The length of time for which the dCDN guarantees \u00a0 \u00a0 \u00a0 \u00a0  to keep a completed Trigger Status Resource.\u00a0 After this time, \u00a0 \u00a0 \u00a0 \u00a0  the dCDN SHOULD delete the Trigger Status Resource and all \u00a0 \u00a0 \u00a0 \u00a0  references to it from collections. I'm not clear on why this is a SHOULD rather than a MUST. If the dCDN tells the uCDN it's going to delete resources after a specified period of time, why shouldn't it follow through on that? For a uCDN that relies on resources not sticking around after a specified period of time (because of security or competitive concerns), doesn't this need to be a firm requirement so that the uCDN doesn't have to issue purge requests to be sure that its resources get deleted? = Section 8.1 = I had the same confusion as Ben and the secdir reviewer concerning whether TLS is always required to use or not. If there are cases in which TLS is not mandatory to use, then I think this should be phrased as a SHOULD with the exceptions clearly enumerated. For example, it's not clear to me whether the only exception is environments where equivalent protections are afforded by a different protocol, or if just being within a single administrative domain is considered protection enough (not sure I agree with the latter).",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-05-19 07:56:45-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-05 19:40:15-08:00",
    "text": "I've got two concerns that I think\u00a0 leave\u00a0 ambiguity around important normative requirements. Hopefully they will be easy to resolve: - 4.7, 2nd bullet under handling of offline surrogates: I assume I am missing something here. How does a surrogate know that the situation exists in the first place? How would a surrogate know about invalidate commands that happened while it was offline? - 8.1,\u00a0 4th paragraph from the end: The language here is ambiguous about whether the use of TLS is _always_ required, or just when \"such protection is required.\" From context, I assume the latter to be the case. But \"To that end...\" can be interpreted to mean \"In that case, one MUST do X\", or to mean \"In order to make that possible when needed, one MUST _always_ do X\" I propose the following: OLD: \u00a0  In an environment where any such protection is required, mutually \u00a0  authenticated encrypted transport MUST be used to ensure \u00a0  confidentiality of the CI/T information.\u00a0 To that end, TLS MUST be \u00a0  used by CI/T, including authentication of the remote end. NEW: \u00a0  In an environment where any such protection is required, mutually \u00a0  authenticated and encrypted TLS MUST be used to ensure \u00a0  confidentiality of the CI/T information.  END.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-21 09:18:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-21 09:17:54-07:00",
    "text": "Thanks for a well-written document and also for considering other protocols like SCTP. I've put in a discuss beacuse I would really have a quick discussion here and\u00a0 double-check that we do the right thing, however, it might well be that we can resolve this discuss without any changes. My question is: given the model is designed to be generic enough to incoperate other transport protocols, I'm wondering if it would be possible to also define the timers you have there in a more generic way such that they can be reused for other protocols (maybe just changing the name and adding some explanation text).  As a side node: I myself have been working on a model for a protocol-independent state machine a bit (see  draft-trammell-plus-statefulness ; now expired); maybe that's a helpful reference...",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-21 09:19:36-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-21 09:18:43-07:00",
    "text": "Thanks for a well-written document and also for considering other protocols like SCTP. I've put in a discuss because I would really have a quick discussion here and\u00a0 double-check that we do the right thing, however, it might well be that we can resolve this discuss without any changes. My question is: given the model is designed to be generic enough to incorporate other transport protocols, I'm wondering if it would be possible to also define the timers you have there in a more generic way such that they can be reused for other protocols (maybe just changing the name and adding some explanation text).  As a side node: I myself have been working on a model for a protocol-independent state machine a bit (see  draft-trammell-plus-statefulness ; now expired); maybe that's a helpful reference to have a quick look at\u2026",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-24 06:28:24-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-21 09:19:36-07:00",
    "text": "Thanks for a well-written document and also for considering other protocols like SCTP. I've put in a discuss because I would really like have a quick discussion here to double-check that we do the right thing, however, it might well be that we can resolve this discuss without any changes. My question is: given the model is designed to be generic enough to incorporate other transport protocols, I'm wondering if it would be possible to also define the timers you have there in a more generic way such that they can be re-used for other protocols (maybe just changing the name and adding some explanation text).  As a side node: I myself have been working on a model for a protocol-independent state machine a bit (see  draft-trammell-plus-statefulness ; now expired); maybe that's a helpful reference to have a quick look at\u2026",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-14 19:16:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-14 19:08:25-07:00",
    "text": "I generally found this a well-written and pleasant to read document. I do have some additional comments on it and tomorrow I'll update the comments section of my ballot to reflect them, but wanted to post the DISCUSS portion tonight. I would like to understand the motivation behind what seems to me to be a curious inconsistency. I was surprised, when I reached \u00a76.9, to find out that an ITR MUST discard a Map-Reply whose HMAC ID or KDF ID don't match what the ITR sent. As I understand it, this is used as a form of algorithm negotiation. That much I get (although it's surprising there's no text telling the ITR to remember the negotiated algorithm for future reference). What I don't get, is why \u00a76.7 and \u00a76.7.1 tell the Map-Server to go to the trouble of creating a full, properly-formed Map-Reply (quite possibly involving the ETR too in the process) in the case where it doesn't support the HMAC or KDF recommended by the ITR. In such a case the Map-Server *knows* the ITR will discard the Map-Reply. So why waste cycles and bandwidth sending anything other than a bare-bones, \"I don't support your algorithm, here's the one I like\" message?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-15 10:08:05-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-14 19:16:28-07:00",
    "text": "I generally found this a well-written and pleasant to read document. I do have some additional comments on it and tomorrow I'll update the comments section of my ballot to reflect them, but wanted to post the DISCUSS portion tonight. I would like to understand the motivation behind what seems to me to be a curious inconsistency.  On the one hand, \u00a76.7 and \u00a76.7.1 mention that  \u00a0  While processing the Map-Request, the Map-Server can overwrite the \u00a0  KDF ID field if it does not support the KDF ID recommended by the \u00a0  ITR. and similar for the HMAC ID. They then go on to detail all the other work the Map-Server does to create a well-formed Map-Reply (if replying directly) or Map-Request (if sending the message to an ETR to take action). This seemed fine, until I got to \u00a76.9, which told me that after the Map-Server (and often, ETR) went to all that work to create those messages... \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If the KDF ID in the Map-Reply does not match the \u00a0  KDF ID requested in the Map-Request, the ITR MUST discard the Map- \u00a0  Reply and similar for the HMAC ID.  Why did you tell the Map-Server to spend cycles and bandwidth doing the work to produce a fully-formed Map-Reply in this case where you know the ITR is just going to discard the result? Why doesn't the Map-Server simply send a bare-bones \"I don't support your algorithm, here's the one I do like\" message?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-07-01 10:35:19-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 00:29:41-07:00",
    "text": "Sections 8.1 through 8.5 all create registries with \"Specification Required\" rules.\u00a0  RFC 8126  says this about \"Specification Required\": \u00a0  As with Expert Review (Section 4.5), clear guidance to the designated \u00a0  expert should be provided when defining the registry, and thorough \u00a0  understanding of Section 5 is important. Only Section 8.5 includes any such guidance.\u00a0 Is none needed for the other four?\u00a0 Also, I'm having trouble understanding the advice that Section 8.5 does give.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-07-08 05:51:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 06:25:12-07:00",
    "text": "Note I support the DISCUSSes and COMMENTS of Roman and Murray, and John's comments, and I won't repeat those issues in this review. #1 The document keeps talking about generating OTK's which are One Time Key's, and then \"securely transports\" these. If we have such a secure transport, why can't this same mechanism be used by the Map-Server for the Map-Request and Map-Reply message security instead of OTKs? Possibly I am not understanding the full architecture? An ascii art diagram would be useful at the beginning of the document. This all kind of tastes like Kerberos/GSSAPI. Couldn't that be used instead? Why not just use mTLS between all parties and get rid of all the custom crypto with OTK's ? #2 \u00a0  LISP-SEC deployments SHOULD use AUTH-HMAC-SHA- \u00a0  256-128 HMAC function, unless older implementations using AUTH-HMAC- \u00a0  SHA-1-96 are present in the same deployment It makes be sad that 1 older device downgrades the usable algorithm for all nodes. Would it be possible to change the protocol slightly so those with sha2 support could use this and only the sha1-only node uses the old algorithm? #3 \u00a0  or by enabling DTLS [ RFC9147 ] between the ITR and the Map-Resolver. Should this clarify that the DTLS connection should be mutually authenticated? eg both peers must identify themselves to the other, unlike the more common (D)TLS connections where only the client authenticates the server. This applies to multiple locations where it says DTLS can be used. #4 The Registry \"LISP-SEC Authentication Data HMAC ID\" seems to really be conveying a _preference_. Should this be reflected in the name of the registry? Additionally, can we leave value 0 as Reserved, and make NOPREF the value 1, etc. The \"Key Wrap Functions\" registry specifies 0 as Reserved, but then associated a KEY WRAP and KDF with this value. That is, it combines a \"Reserved\" with a \"NULL wrap\" entry. These two should be clearly split - eg reserve 0\u00a0 with Key wrap and KDf set to \"N/A\", and if needed create a \"null-wrap-null if an entry is needed with key wrap and kdf set to \"none\". The \"Key Derivation Functions\" also mixes up NOPREF and Reserved.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-07-13 13:58:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 18:47:40-07:00",
    "text": "** Since originally scheduled for the telechat in version -26, thank you for adding the following text about preferring HMAC-SHA256 for new deployments in -27: \u00a0  The HMAC \u00a0  function AUTH-HMAC-SHA-256-128 [ RFC6234 ] MUST be supported in LISP- \u00a0  SEC implementations.\u00a0 LISP-SEC deployments SHOULD use AUTH-HMAC-SHA- \u00a0  256-128 HMAC function, unless older implementations using AUTH-HMAC- \u00a0  SHA-1-96 are present in the same deployment [ RFC2104 ]. Could this same approach be applied for the algorithms set by KDF ID.\u00a0 Specifically: -- Section 6.9 says: \u00a0  The key derivation function \u00a0  HKDF-SHA1-128 [ RFC5869 ] MUST be supported. ... \u00a0 However, since HKDF-SHA1-128 is mandatory to implement, the process \u00a0  will eventually converge. Could it say something to the effect of: The key derivation function HKDF-SHA256 MUST be supported in LISP-SEC implementations.\u00a0 LISP-SEC deployments SHOULD use the HKDF-SHA256 HKDF function, unless older implementations using HKDF-SHA1-128 are present in the same deployment. However, since HKDF-SHA1-128 and HKDF-SHA256 are supported, the process will eventually converge. -- Section 8.5.\u00a0 Add HKDF-SHA256 to the \"LISP-SEC Authentication Data Key \u00a0  Derivation Function ID\" registry",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-02-16 07:42:14-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-16 03:20:29-08:00",
    "text": "hy is this using TCP/DTLS/SCTP instead of TCP/TLS/SCTP?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-05-29 04:42:54-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-18 06:40:25-07:00",
    "text": "I know this document has long history and I want to get it done as well. Below is a list of small issues that I think need to be addressed: Is version directive value case-insensitive? The IANA registration is in lowercase, but all examples show uppercase. On page 28: SHA-3, AES-GCM and base64 all need normative references. (Use \"Section 4 of [ RFC4648 ]\" for base64, as  RFC 4648  defines 2 base54 encodings). On page 33: where does the \"missing field value is denoted by -\" specified in ABNF? If this is not defined in ABNF, it would be good to have an example record with a field missing.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-03-31 10:20:17-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-25 11:27:15-07:00",
    "text": "I appreciate all the work that has gone into this document. It was originally up for IESG review when I was on leave, so I was not able to review it at that time. The document needs one more ballot to progress, so I told Spencer I would review it. I realize it's probably frustrating to see another DISCUSS at this point but these should be straightforward to resolve I think. (1) I am wondering about a potential inconsistency that I see in Section 3.4.1. I see with the definition of the c-groupid field that there is inherent support for reporting about clients as aggregates, which is great, and even when reporting is done about individual clients there are a bunch of normative recommendations to try to reduce the chances that a logging field will be tied back to an individual user or host. Excellent. But then with the definition of the cs(insert_HTTP_header_name_here) field and discussion about it, there is no equivalent normative guidance given about not including headers that could potentially be used to identify an individual user or host. There is discussion about cookies but none of it is normative, and cookies are not the only headers that could be identifying. In fact, one of the examples given -- User-Agent -- is known to be identifying in some cases. Given the extent to which the specification of c-groupid goes to support masking the identity of the host, I would expect normative guidance about the use of the header field. That is, if an implementation is using c-groupid to represent an aggregate, it would make sense to me that it MUST NOT include header fields that could be uniquely identifying. I also wonder if the recommendations about cookies in 3.4.1 could be made normative. I will say that based on the use cases for these logs listed in 2.2.5 it's hard to understand what a uCDN needs headers like cookies for on a consistent basis; if they're needed for an occasional troubleshoot, logging them consistently seems like overkill. (2) Section 7.1 says: \"In an environment where any such protection is required, mutually \u00a0  authenticated encrypted transport MUST be used to ensure \u00a0  confidentiality of the logging information.\u00a0 To that end, TLS MUST be \u00a0  used (including authentication of the remote end) by the server-side \u00a0  and the client-side of the CDNI Logging feed, as well as the server- \u00a0  side and the client-side of the CDNI Logging File pull mechanism.\" I know this text has been the subject of much discussion and careful editing, and that I raised an issue on this on the redirection draft. What I don't understand from reading this is whether the expectation is that all servers and clients implementing this specification will use TLS. The first sentence seems to indicate that there will be cases when that is not true. The second sentence says MUST use, which means use in every case. Which is it?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2016-03-18 09:21:28-07:00",
    "end_reason": "position_updated",
    "start": "2015-04-20 11:03:56-07:00",
    "text": "Pete has the ABNF issues in hand, and I'm happy to let him take care of that... but I'm picking up the DISCUSS now that he's retired from the IESG.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-06-08 12:39:13-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-18 15:31:04-07:00",
    "text": "While the security and privacy bits are much improved from earlier versions, I think I have found some holes. I assume these are not intentional, and it's entirely possible I have misread some things. But I would like to make sure they are considered prior to progressing. - 3.4.1, c-groupid: The privacy-related guidance about c-groupids indentifying individual clients (in the several bullet list entries with \"-\" bullets) seems contingent on the MAY in the parent (with the \"+\" bullet.) The parent says that you MAY structure the field so that parts identify the aggregate and one part aggregates the individual, with the sub-bullets following an \"In this case...\" clause. I assume the guidance is intended to apply even when an implementation doesn't structure c-groupid that way (or at all.)  - 7.1: This section seems to effectively say that various protections are required when they are required. But it doesn't give advice on when they may be required. (For example, when c-groupid can be mapped to individual client addresses.) - 7.3: \"Making detailed CDNI logging \u00a0  information known to the uCDN does not represent a particular privacy \u00a0  concern because the uCDN is already exposed at request redirection \u00a0  time to most of the information that shows up as CDNI logging \u00a0  information (e.g., enduser IP@, URL, HTTP headers - at least when \u00a0  HTTP redirection is used between uCDN and dCDN).\" I agree this is mostly true for HTTP redirection. But as you mention, the assertion seems to fall down for DNS redirection, where the uCDN may have considerably less information. I think some different guidance for that case may be needed. -- \"Transporting \u00a0  detailed CDNI logging information over the HTTP based CDNI Logging \u00a0  Interface does not represent a particular privacy concern because it \u00a0  is protected by usual IETF privacy-protection mechanism (e.g.,TLS).\" I don't find normative text that says privacy-sensitive information MUST be protected. Just that information that needs to be protected MUST be protected. The reader is left to infer that privacy-sensitive information is covered by that. (See previous comment about 7.1). Without something explicit there, I think it highly likely that some people will rationalize that their deployments don't need protection for one reason or another.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2015-03-05 07:32:08-08:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 03:13:35-08:00",
    "text": "Thanks for working on this very useful specification. I think it is soon ready to move forward, but there are a couple of things that we should try to address before the final approval. Martin raised a number of comments in the Gen-ART review, and I'd like to see the resolution of those. For me, I think the following issues at least deserve a document change: I'm not sure the definition of\u00a0 is correct. I would simply do \u00a0  CDNI-LOG-FILE = 1*(DIRGROUP / RECGROUP) For the reasons that Martin outlined. Also, Section 3.4.1 needs an update, given that HTTP 2 specifications have been approved. I suspect you could simply say that the work applies to both HTTP 1 and 2, and that any new information derived from HTTP 2 specifically is outside the scope of this spec. Security considerations should rather refer to existing mandates in TLS specifications (such as the UTA document that was recently approved) rather than make their own specific crypto requirements.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-04-20 09:50:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-03-03 17:25:18-08:00",
    "text": "Thanks for your work on this draft.\u00a0 I'd like to discuss a few points rom the security considerations section that we should be able to clear up quickly. In order for the following statements to be true, a little more text is needed, so I'll provide a suggestion.\u00a0 I see that you've recommended one of the cipher suites recommended in the new TLS BCP (in the RFC editor queue), so it appears a reference to that would be good to help with the strong statement already offered about TLS protections (true, if configured with best practice recommendations). Old: \u00a0  The use of TLS for transport of the CDNI Logging feed and CDNI \u00a0  Logging File pull allows: \u00a0  o\u00a0 the dCDN and uCDN to authenticate each other (to ensure they are \u00a0 \u00a0 \u00a0 transmitting/receiving CDNI Logging File from an authenticated \u00a0 \u00a0 \u00a0 CDN) \u00a0  o\u00a0 the CDNI Logging information to be transmitted with \u00a0 \u00a0 \u00a0 confidentiality \u00a0  o\u00a0 the integrity of the CDNI Logging information to be protected \u00a0 \u00a0 \u00a0 during the exchange New: The use of mutually authenticated TLS for transport, configured according to best practices [ draft-ietf-uta-tls-bcp ] of the CDNI Logging feed and CDNI \u00a0  Logging File pull allows: \u00a0  o\u00a0 the dCDN and uCDN to authenticate each other (to ensure they are \u00a0 \u00a0 \u00a0 transmitting/receiving CDNI Logging File from an authenticated \u00a0 \u00a0 \u00a0 CDN) \u00a0  o\u00a0 the CDNI Logging information to be transmitted with \u00a0 \u00a0 \u00a0 confidentiality \u00a0  o\u00a0 the integrity of the CDNI Logging information to be protected \u00a0 \u00a0 \u00a0 during the exchange I found the next paragraph a little difficult to read, so I'll offer a suggestion for that text as well. Old: \u00a0  In an environment where any such protection is required, TLS SHOULD \u00a0  be used (including authentication of the remote end) by the server- \u00a0  side and the client-side of the CDNI Logging feed and the CDNI \u00a0  Logging File pull mechanism unless alternate methods are used for \u00a0  ensuring the confidentiality of the information in the logging files \u00a0  (such as setting up an IPsec tunnel between the two CDNs or using a \u00a0  physically secured internal network between two CDNs that are owned \u00a0  by the same corporate entity). New: \u00a0  In an environment where any such protection is required, the use of a  \u00a0  mutually authenticated encrypted transport MUST be used to ensure \u00a0  confidentiality of the log information.\u00a0 TLS SHOULD \u00a0  be used (including authentication of the remote end) by the server- \u00a0  side and the client-side of the CDNI Logging feed as well as by the CDNI \u00a0  Logging File pull mechanism unless alternate methods are used. Alternate \u00a0  methods could include establishing an IPsec tunnel between the two CDNs \u00a0  or using a physically secured internal network between two CDNs that are \u00a0  owned by the same corporate entity). Thanks for also putting thought into the privacy considerations and including anonymization options as that is one of the better options.\u00a0 I'd like to make a suggestion for the second paragraph as TLS is just protecting data in transit. Old: \u00a0 The use of TLS for transport of the CDNI Logging feed and CDNI \u00a0  Logging pull as discussed in Section 7.1 protects the confidentiality \u00a0  of logged information by preventing any other party than the \u00a0  authorised uCDN to gain access to the logging information. New: \u00a0  The use of mutually authenticated TLS to establish a secure session for the transport of the CDNI Logging feed and CDNI Logging pull as discussed in Section 7.1 protects access to the logged information. This provides confidentiality while the logs are in transit and prevents any other party than the authorised uCDN to gain access to the logging information.  Thanks to the SecDir review which raised some of these issues. https://www.ietf.org/mail-archive/web/secdir/current/msg05452.html",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-04-20 11:08:40-07:00",
    "end_reason": "position_updated",
    "start": "2015-04-20 09:50:51-07:00",
    "text": "Thanks for your work on this draft.\u00a0 I'll clear on my prior discusses, for the first one, I would have preferred my suggested text over what you wound up with from the SecDir review after I had provided the suggestion just because I think it covers the points a bit more cleanly. I'm just leaving a discuss here to make sure Pete's points get covered, but I am not an ABNF expert.",
    "type": "Discuss"
  },
  {
    "ad": "Pete Resnick",
    "end": "2015-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2015-03-04 19:06:53-08:00",
    "text": "I am very concerned about the syntax specification here. I'm not convinced it's complete and correct. I am certainly willing to be talked out of my concern, but I think this could use a massive edit by someone who knows ABNF, as well as a discussion about intended contents. Details: 3.1: I always prefer to import the rules you are using simply by reference rather than of copying them. Prevents silly errors. On these, let's see if you really mean what you say you mean: \u00a0 \u00a0 \u00a0 NAMEFORMAT = ALPHANUM *(ALPHANUM / \"_\" / \"-\") \u00a0 \u00a0 \u00a0  So, are you really OK with a NAMEFORMAT of \"1---___---\"? Often what people really want is: \u00a0 \u00a0 \u00a0 NAMEFORMAT = ALPHANUM *([\"_\" / \"-\"] ALPHANUM) \u00a0 \u00a0 \u00a0  Is that what you want? On the next bit: \u00a0 \u00a0 \u00a0 QSTRING = DQUOTE *NDQUOTE DQUOTE ; where \u00a0 \u00a0 \u00a0 \u00a0  NDQUOTE =\u00a0 / 2DQUOTE ; whereby a \u00a0 \u00a0 \u00a0 \u00a0  DQUOTE is conveyed inside a QSTRING unambiguously by repeating \u00a0 \u00a0 \u00a0 \u00a0  it. \u00a0 \u00a0 \u00a0 NHTABSTRING = *NHTAB ; where \u00a0 \u00a0 \u00a0 \u00a0  NHTAB =  (By way of formatting, outdent NDQUOTE and NHTAB, and get rid of \"; where\".) When you say , is that what you really mean? You want to allow control characters? Seems to me that that is going to introduce a whole new set of security considerations. Also, the fact that you call these things xSTRING sends up a flag for me that you maybe want them to be textual. Are you allowing for things outside of US-ASCII? Section 3.2 seems to say only US-ASCII. Finally, do you really want NDQUOTE to allow for CR, LF, and HTAB? That means that parsers have to be a bit smarter, and the line in 3.2 that says, \"Each line ... MUST contain either a directive of a CDNI Logging Record\", and the line in 3.4 that says, \"CDNI Logging Fields MUST be separated by the HTAB character\", both seem bogus. So, assuming you want only US-ASCII and that you don't want CR LF or HTAB in any of these, these should be: \u00a0 \u00a0 \u00a0 QSTRING = DQUOTE *NDQUOTE DQUOTE \u00a0 \u00a0 \u00a0 NDQUOTE = SP / %x21 / %x23-7E / (DQUOTE DQUOTE) \u00a0 \u00a0 \u00a0  ; DQUOTE is conveyed inside a QSTRING unambiguously by repeating \u00a0 \u00a0 \u00a0  ; it. \u00a0 \u00a0 \u00a0 NHTABSTRING = *NHTAB \u00a0 \u00a0 \u00a0 NHTAB = SP / VCHAR or if you like, simply: \u00a0 \u00a0 \u00a0 NHTABSTRING = *( SP / VCHAR ) If you want non-US-ASCII, I'd include UTF-8 and call that out. I can tell you how to do that, but I hope you're not doing that. If you want CR and LF in both QSTRING and NHTABSTRING, and HTAB in QSTRING, you need to fix the lines in 3.2 and 3.4. If don't want them, you're going to have to describe how to unfold and de-tab the HTTP header field values somewhere. 3.2: \u00a0 \u00a0 \u00a0 RECLINE =\u00a0 CRLF \u00a0 \u00a0 \u00a0 RECGROUP = *RECLINE \u00a0 \u00a0 \u00a0  = 1* \u00a0 \u00a0  These seem kind of a cop-out. Seems like you could easily define RECLINE as: \u00a0 \u00a0 \u00a0  RECLINE\u00a0 \u00a0 = date HTAB time HTAB time-taken HTAB ... \u00a0 \u00a0 \u00a0  date\u00a0 \u00a0 \u00a0  = DATE \u00a0 \u00a0 \u00a0  time\u00a0 \u00a0 \u00a0  = TIME \u00a0 \u00a0 \u00a0  time-taken = DEC \u00a0 \u00a0 \u00a0  [...] The last line is nowhere near legitimate ABNF. How about just defining a proper LOGFILE as: \u00a0 \u00a0 \u00a0  LOGFILE\u00a0 \u00a0 = 1*(DIRGROUP RECGROUP) \u00a0 \u00a0  If you're going to bother with ABNF, use ABNF. The explanations can still appear in 3.3 and 3.4.1. 3.3: The top-level ABNF for DIRNAME and DIRVAL give the implementer no help with regard to what is legitimate syntax. You mention the syntax for DIRNAME in 6.1, but that's not where it belongs. At least you should put in: \u00a0 \u00a0 \u00a0  DIRNAME = NAMEFORMAT For DIRVAL, you should probably have at least the most general format of: \u00a0 \u00a0 \u00a0  DIRVAL = NHTABSTRING / QSTRING and then give specifics below. But you could also change 3.2 and say something like: \u00a0 \u00a0 \u00a0 \u00a0 DIRGROUP = version \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  uuid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [claimed-orig] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [established-orig] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1*record-type \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1*fields \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [integrity-hash] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *new-dir Then in 3.3, you could define: \u00a0 \u00a0 \u00a0 \u00a0 version\u00a0  = \"Version:\" HTAB \"CDNI\" \"/\" 1*DIGIT \".\" 1*DIGIT \u00a0 \u00a0 \u00a0 \u00a0 uuid\u00a0 \u00a0 \u00a0 = \"UUID:\" HTAB NHTABSTRING \u00a0 \u00a0 \u00a0 \u00a0 ... \u00a0 \u00a0 \u00a0 \u00a0 new-dir\u00a0  =  and indicate that unknown directives must be ignored, or something like that. This is wrong: \u00a0  o\u00a0 Fields: \u00a0 \u00a0 \u00a0 *\u00a0 format: FIENAME * Angle brackets don't appear like that in ABNF. 3.4: Again, incorrect ABNF, if that's what it's meant to be.",
    "type": "Discuss"
  },
  {
    "ad": "Richard Barnes",
    "end": "2015-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2015-03-04 19:32:49-08:00",
    "text": "I'm concerned that the information model of this log format encourages the sharing of far more granular information than is justified by the use cases.\u00a0 All of the use cases in Section 2 are focused on statistical information, in which case collecting things like individual IP addresses and ports is unnecessary.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-04-14 09:47:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-03-05 06:07:21-08:00",
    "text": "Let me preface the specific discuss points with an overall point - I do not think our job here is to force CDNs to behave well in relation to privacy. However, it is our job to provide an API that encourages and effectively supports behaving well in relation to privacy. So, that said... (1) 2.2.5.5: there's no interoperability need for this section, and even if there are data retention requirements to be met, I don't see how the logging API is relevant to that. For example, a dCDN would not have it's data retention requirements met by a uCDN I think. I think just deleting this is the right action. (2) 3.3: MD5 is no longer good enough for data integrity and 128 bits in 32 ascii-hex is too short for SHA-256, which ought be the MUST alg here. (Some variable length is needed or else put the algorithm name in the field name.) (3) c-ip-anonymizing: guidance is needed that IPv4 and IPv6 aren't the same here. Why isn't the same idea done for c-port and other fields?\u00a0 Has there been any analysis of the effectiveness of this scheme in not allowing identification or re-identification? If not, isn't that really needed if we are serious about defining an API that can protect privacy? If that was discussed on the list, please send some pointers so I can get familiar with the work during the discussion.\u00a0  (4) Why is c-ip MTI but the (hopefully) privacy friendly variant is not? (5) I'm not clear why you need to be able to send HTTP header values or session IDs via this i/f. Why is that needed? (And it seems very dangerous, e.g. \"cs(COOKIE)\" could be a doosy.) (6) Just checking - given relevations of snooping, why not say \"MUST use TLS with mutual-auth\"? In particular if we don't end up with a usefully privacy-friendly version of this, where is the safe-but-cleartext use-case described that justifies the current SHOULD?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-04-14 15:07:40-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-04-14 09:47:47-07:00",
    "text": "DISCUSS points updated for -18, thanks for the changes so far.\u00a0 I suspect for the next step we'll want to chat some. Let me preface the specific discuss points with an overall point - I do not think our job here is to force CDNs to behave well in relation to privacy. However, it is our job to provide an API that encourages and effectively supports behaving well in relation to privacy. So, that said... (1) cleared (2) 3.3: Thanks for changing from MD5->SHA256 but I  think you need the format for the SHA256-Hash thing to be 64HEXDIG don't you? (3) c-ip-anonymizing: guidance is needed that IPv4 and IPv6 aren't the same here. Why isn't the same idea done for c-port and other fields?\u00a0 Has there been any analysis of the effectiveness of this scheme in not allowing identification or re-identification? If not, isn't that really needed if we are serious about defining an API that can protect privacy? If that was discussed on the list, please send some pointers so I can get familiar with the work during the discussion.\u00a0  (4) cleared (take as part of point (3) if need be) but I  think you fixed it (5) I'm not clear why you need to be able to send HTTP header values or session IDs via this i/f. Why is that needed? (And it seems very dangerous, e.g. \"cs(COOKIE)\" could be a doosy.) (6) cleared (7) This is kind of new, but I'd like to adopt Richard's  DISCUSS so that doesn't get lost and it's very related to my point (3) too and I previously noted that I supported him. So that was: \"I'm concerned that the information model of this log format encourages the sharing of far more granular information than is justified by the use cases.  All of the use cases in Section 2 are focused on statistical information, in which case collecting things like individual IP addresses and ports is unnecessary.\"",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-07-13 17:33:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-04-14 15:07:40-07:00",
    "text": "  DISCUSS points updated for -18, thanks for the changes so far.\u00a0 I suspect for the next step we'll want to chat some. Let me preface the specific discuss points with an overall point - I do not think our job here is to force CDNs to behave well in relation to privacy. However, it is our job to provide an API that encourages and effectively supports behaving well in relation to privacy. So, that said... (1) cleared (2) 3.3: Thanks for changing from MD5->SHA256 but I  think you need the format for the SHA256-Hash thing to be 64HEXDIG don't you? (3) c-ip-anonymizing: guidance is needed that IPv4 and IPv6 aren't the same here. Why isn't the same idea done for c-port and other fields?\u00a0 Has there been any analysis of the effectiveness of this scheme in not allowing identification or re-identification? If not, isn't that really needed if we are serious about defining an API that can protect privacy? If that was discussed on the list, please send some pointers so I can get familiar with the work during the discussion.\u00a0  (4) cleared (take as part of point (3) if need be) but I  think you fixed it (5) I'm not clear why you need to be able to send HTTP header values or session IDs via this i/f. Why is that needed? (And it seems very dangerous, e.g. \"cs(COOKIE)\" could be a doosy.) (6) cleared (7) This is kind of new, but I'd like to adopt Richard's  DISCUSS so that doesn't get lost and it's very related to my point (3) too and I previously noted that I supported him. So that was: \"I'm concerned that the information model of this log format encourages the sharing of far more granular information than is justified by the use cases.  All of the use cases in Section 2 are focused on statistical information, in which case collecting things like individual IP addresses and ports is unnecessary.\"",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 07:47:58-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-07-13 17:33:25-07:00",
    "text": "  DISCUSS points updated for -19, I'm not seeing changes that respond to my discuss points, nor do I recall email on the topic. (Apologies if I missed some.) I'd be happy to chat whenever folks are ready. Let me preface the specific discuss points with an overall point - I do not think our job here is to force CDNs to behave well in relation to privacy. However, it is our job to provide an API that encourages and effectively supports behaving well in relation to privacy. So, that said... (1) cleared (2) 3.3: Thanks for changing from MD5->SHA256 but I  think you need the format for the SHA256-Hash thing to be 64HEXDIG don't you? (3) c-ip-anonymizing: guidance is needed that IPv4 and IPv6 aren't the same here. Why isn't the same idea done for c-port and other fields?\u00a0 Has there been any analysis of the effectiveness of this scheme in not allowing identification or re-identification? If not, isn't that really needed if we are serious about defining an API that can protect privacy? If that was discussed on the list, please send some pointers so I can get familiar with the work during the discussion.\u00a0  (4) cleared (take as part of point (3) if need be) but I  think you fixed it (5) I'm not clear why you need to be able to send HTTP header values or session IDs via this i/f. Why is that needed? (And it seems very dangerous, e.g. \"cs(COOKIE)\" could be a doosy.) (6) cleared (7) This is kind of new, but I'd like to adopt Richard's  DISCUSS so that doesn't get lost and it's very related to my point (3) too and I previously noted that I supported him. So that was: \"I'm concerned that the information model of this log format encourages the sharing of far more granular information than is justified by the use cases.  All of the use cases in Section 2 are focused on statistical information, in which case collecting things like individual IP addresses and ports is unnecessary.\"",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 08:51:00-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-09 07:47:58-08:00",
    "text": "  DISCUSS points updated for -21, thanks for the great improvement in the privacy related stuff. I do however have one remaining thing to ask but with a concrete suggested change below. (1) cleared (2) cleated (3) cleared (thanks!) (4) cleared (take as part of point (3) if need be) but I  think you fixed it (5) I'm not clear why you need to be able to send HTTP header values or session IDs via this i/f. Why is that needed? (And it seems very dangerous, e.g. \"cs(COOKIE)\" could be a doosy.) (6) cleared (7) cleared",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-02 06:18:41-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-09 08:51:00-08:00",
    "text": "  DISCUSS points updated for -21, thanks for the great improvement in the privacy related stuff. I do however have one remaining (security related) thing to ask  about but with a concrete suggested change below. (1) cleared (2) cleared (3) cleared (thanks!) (4) cleared (take as part of point (3) if need be) but I  think you fixed it (5) I'm not clear why you need to be able to send HTTP header values or session IDs via this i/f. Why is that needed? And it seems very dangerous, e.g. \"cs(COOKIE)\" could be a doosy. I would suggest adding new text in section 3.4 to cover all  of the log content basically saying that you really need to  know what you're doing or you can break security very easily.  Some suggested text that could be added to the end of 3.4  just before the start of 3.4.1: \"Logging fields from HTTP requests and responses can be very dangerous. For example, cookies will often contain (months) long lived bearer token values that can be used to login to a service as the relevant user. Similar values  may be included in other header fields or within URLs or elsewhere in HTTP requests and responses. Centralising such values in a log can therefore represent a significant increase in risk both for the user and the web service provider, but also for the CDNs involved. Implementations  ought therefore attempt to lower the probability of such  bad outcomes e.g. by only allowing a configured set of  headers to be added to logs, or by not supporting wildcard  selection of HTTP request/response fields to add. Such  mechanisms can reduce the probability that security (or  privacy) sensitive values are centralised in logs.\" I'm sure that can be improved on, and have no problem with any specific better words.  (6) cleared (7) cleared",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-08-10 06:06:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-08-08 18:33:38-07:00",
    "text": "Issue #1 \u00a0 \u00a0 \u00a0 \u00a0 The discovery of such a Relevant RRSet MUST be performed using the \u00a0 \u00a0 \u00a0 \u00a0 algorithm specified in section 3 of [ RFC8659 ]. The input domain to the \u00a0 \u00a0 \u00a0 \u00a0 discovery algorithm SHALL be the domain \"part\" ([ RFC5322 ]) of the email \u00a0 \u00a0 \u00a0 \u00a0 address that is being certified. And  RFC 8659  states: \u00a0 \u00a0 \u00a0 \u00a0 The search for a CAA RRset climbs the DNS name tree from the \u00a0 \u00a0 \u00a0 \u00a0 specified label up to, but not including, the DNS root \".\" until \u00a0 \u00a0 \u00a0 \u00a0 a CAA RRset is found. While this algorithm makes sense for a CAA to restrict issuing, I'm not sure it makes sense for email addresses where the permission might be granted by a parent. eg ig there is a CAA record saying \"no email certs\" at  nohats.ca , and there is a CAA record saying \"sure, issue stuff\" at  toronto.nohats.ca , is it the desired behaviour that  toronto.nohats.ca  can override the  nohats.ca policy and issues certs for  paul@toronto.nohats.ca ?\u00a0 This also brings into question whether Public Suffix List (PSL) type restrains matter. It might very well be the intent, but then perhaps it should be made a little more explicit ? (and then I have to rethink about what I think about subdomains overriding their parents) Issue #2: Section 5.4 contains an example of conflicting records, and the text then describes a process of \"failing open\". From a security point of view, I would argue this should \"fail close\" and not allow issuance. Was this discussed in the WG? What is the rationale behind this \"more vulnerable to mistakes\" interpretation?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-09 10:56:04-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 21:17:56-08:00",
    "text": "Let's discuss whether we need a standalone privacy considerations section.\u00a0 The document obviously does not ignore privacy, and in fact actively seeks privacy improvements in several places (encrypting PASSporTs to the recipient's key, blind-signatures for rate-limiting submission to the CPS, etc.), but it seems like a structured discussion that considers all the actors and the data flows amongst them might add significant value.\u00a0 Given the expected use of TLS and end-to-end PASSporT encryption, the direct leakage of call information to intermediaries/observers seems low, and the main risk is in metadata/correlation attacks that attempt to link submission to the CPS with initiation and reception of calls, with the CPS representing an entirely new potential attack point for learning about call information (in addition to the existing PSTN and SIP infrastructure).\u00a0 Some avenues for this have been closed off in the design/architecture presented, but I don't currently have confidence that all of them have been (to the extent that the cost/benefit tradeoff remains reasonable).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 10:23:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-11 10:13:21-07:00",
    "text": "Further details in the COMMENT, but can we briefly discuss the apparent requirement for the PANID/NID to have a couple bits set to zero (the ones that would be U/L and Individual/Group in the resulting IID)?\u00a0 It seems like (but is not entirely clear to me) this is a new requirement on the layer-2 behavior that is being imposed by the IPv6 adaptation layer, and in particular that this is setting up a scenario where certain existing layer-2 deployments would be unable to utilize the IPv6 adaptation layer, which would be a very surprising behavior for an IETF Proposed Standard.\u00a0 What alternatives were explored and rejected before settling on this approach that introduces new limitations on the underlying PLC deployments? I mention in a few places in the COMMENT scenarios where we pull in part of the functionality from  RFC 6282  and  RFC 4944 , e.g., the IP header compression scheme and the fragmentation format.\u00a0 It seems to me that the intent is that our payload always use the  RFC 4944  \"dispatch\" scheme and that we only use a subset of (and only sometimes?) the particular functionality that  RFC 4944 /6282 can dispatch to.\u00a0 But the current text doesn't mention the dispatch behavior at all, so it's hard for me to be certain that my understanding is correct.\u00a0 It seems that some more explicit treatment in the document of how what we are specifying interacts with/uses the  RFC 4944  dispatch layer would be important in order for someone to be able to implement from this document. I support Roman and \u00c9ric's Discusses.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-01-10 23:04:07-08:00",
    "end_reason": "position_updated",
    "start": "2021-08-09 22:44:25-07:00",
    "text": "Thank you for the work put into this document. Special thanks to Carles Gomez for his shepherd's write-up, which contains a good summary of the WG consensus *BUT* it does not mention that the IEEE normative references are not free. Strange that Carles' email address,  carlesgo@entel.upc.edu , is not in the datatracker status page. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated), and some nits. Please also address Dave Thaler's INT-DIR review at: https://datatracker.ietf.org/doc/review-ietf-6lo-plc-06-intdir-telechat-thaler-2021-08-06/  (some of my DISCUSS points are coming from Dave's review) I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Is there any reason why the IETF Last Call  https://mailarchive.ietf.org/arch/msg/6lo/f59y8rMg-p_aCKYSSEtBzoJK4qQ/  did not mention that the two IEEE normative references were behind a paywall ? It prevented some more detailed reviews and is an important fact. How can a PLC node distinguish between an IPv6 PDU and a non-IPv6 PDU ? I.e., is there the equivalent of a EtherType in a layer-2 PLC PDU ? Then, this should be mentioned in this document else some text explaining why it is not required would be welcome. Especially when the normative IEEE references are not freely available. -- Section 4.1 -- I am repeating here Dave Thaler's point 1) as it is completely unclear to me how the shared secret/version number are shared and provisioned, this could prevent interoperation hence my DISCUSS. While I appreciate that the nodes are constrained, some warnings about having a *single global IPv6 address* should be written or if the spec supports more than one global IPv6 address per node, then the current text must be changed.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-07 14:19:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-09 15:21:14-07:00",
    "text": "** Section 8. A few additional threats should be mentioned.\u00a0 Note that a robust treatment is not needed here (and likely not possible due to the generality of this document).\u00a0 However, they should be acknowledged. -- This section mentions both availability (DoS) and confidentiality (eavesdropping) concerns.\u00a0 Thank you. Wouldn\u2019t there also be the possibility of significant integrity risks given that possible actuators or sensors being controlled?\u00a0  Note if the referenced link layer security mechanisms would be useful. -- Figures 5 \u2013 7 seems to present architectures which connects operational technology to the Internet via the PANC.\u00a0 However, this section doesn\u2019t acknowledgement of that risk outright or by citation. ** Section 8.\u00a0 Per \u201cThus link layer security mechanisms are designed in the PLC technologies mentioned in this document\u201d, which specific mechanisms were being cited is not clear.\u00a0 Is their use required or are they use case dependent?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-22 05:59:15-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-07 14:19:05-08:00",
    "text": "[updated for -09] ** Section 8. A few additional threats should be mentioned.\u00a0 Note that a robust treatment is not needed here (and likely not possible due to the generality of this document).\u00a0 However, they should be acknowledged. -- This section mentions both availability (DoS) and confidentiality (eavesdropping) concerns.\u00a0 Thank you. Wouldn\u2019t there also be the possibility of significant integrity risks given that possible actuators or sensors being controlled?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-02-03 03:05:22-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-31 14:36:16-08:00",
    "text": "* Section 3: How can the ASM_mPrefix64 and SSM_mPrefix64 be (variable) as described in the packet format when the asm-length and the ssm-length MUST be set to 96? Not sure which of these is correct and which is wrong but one of these things (either the fixed length or the variable prefix) needs to be fixed. * Section 4: This section contains a bunch of must and may level requirements but contains the following \"disclaimer\" text. \"This section is not normative but specifies a set of configuration guidelines.\" Not sure what the intent behind this is. Can you clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-03-14 11:45:40-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 18:51:11-08:00",
    "text": "I agree with the SecDir reviewer that a Privacy Considerations section is needed.\u00a0 What user data is potentially exposed?\u00a0 4.3.4 talks about government access, who else has access?\u00a0 What concerns are there about the data that is shared?\u00a0 What if one of the involved systems is compromised and data is stolen? It's a well written draft, this appears to be a gap and I didn't see a response to the SecDir review.\u00a0 Thanks in advance. https://mailarchive.ietf.org/arch/msg/secdir/1WiFmubNoAKo3qAhNu4be35g10w",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2018-02-05 06:27:16-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-23 09:00:21-08:00",
    "text": "This document is defining a MAX-TE-METRIC of 0xfffffffe. But  RFC5817  defined 0xffffffff to be used for graceful shutdown. I noted an email exchange between the author and Acee on this where Acee raised the question why  RFC5817 's value was not used. Shraddha replied \"We can if we have the Working Group Consensus\". There was no further discussion. This document was not shared with teas which is responsible for TE (or ccamp which was originally responsible for  RFC5817 ). Either this value needs to be changed to  RFC5817 's value or this TE metric needs to be removed from this document until agreement with TEAS.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2014-07-10 10:27:43-07:00",
    "end_reason": "position_updated",
    "start": "2014-07-08 13:40:31-07:00",
    "text": "The draft looks good, I just have a question to discuss to see if some additional text is needed for the security considerations section. I don't see any mention of logging and maybe I missed something, if so, please let me know.\u00a0 Since NAT is supported, logging of the NAT translation would be helpful for analysts.\u00a0 Analysts will need to be able to map sessions when investigating possible issues where the NAT happens.\u00a0 Protection of those logs would be helpful as well and should consider log integrity, privacy protection, and purging logs occasionally (retention policies, etc.). Also, logging of connection errors and other messages established by this draft may also be important. Thanks.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 19:55:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-20 00:47:41-07:00",
    "text": "Roman and Russ did the heavy lifting already, but I think I have a bit more fiddling to do regarding the validation procedures (just getting them internally consistent, I think)... (1) Here: \u00a0  As the signer specifies the covered RPKI resources relevant to the \u00a0  signature, the RPKI certificate covering the inetnum: object's \u00a0  address range is included in the [ RFC5652 ] CMS SignedData \u00a0  certificates field. we say that the signing certificate is included in the SignedData certificates field.\u00a0 That makes sense, as SignedData is a SEQUENCE including \"certificates [0] IMPLICIT CertificateSet OPTIONAL\", and CertificateSet, as a SET OF CertificateChoices, allows for the literal \"Certificate\" branch of CertificateChoices. But later on, we say that: \u00a0  1.\u00a0 Obtain the signer's certificate from an RPKI Repository.\u00a0 The \u00a0 \u00a0 \u00a0  certificate SubjectKeyIdentifier extension [ RFC5280 ] MUST match \u00a0 \u00a0 \u00a0  the SubjectKeyIdentifier in the CMS SignerInfo SignerIdentifier \u00a0 \u00a0 \u00a0  [ RFC5286 ].\u00a0 If the key identifiers do not match, then validation \u00a0 \u00a0 \u00a0  MUST fail. which entails fetching the certificate from a directory, based on the SubjectKeyIdentifier. Why do we need to obtain the certificate twice in two different ways? (2) We are careful to note that: \u00a0  The bracketing \"# RPKI Signature:\" and \"# End Signature:\" MUST be \u00a0  present exactly as shown. How do we construct the bits (CIDR block?) that come after the quoted strings?\u00a0 Do they only matter for matching start/end, or are we supposed to check them in the validation procedure?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 21:15:33-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-25 19:55:35-07:00",
    "text": "Roman and Russ did the heavy lifting already, but I think I have a bit more fiddling to do regarding the validation procedures (just getting them internally consistent, I think)... (2) We are careful to note that: \u00a0  The bracketing \"# RPKI Signature:\" and \"# End Signature:\" MUST be \u00a0  present exactly as shown. How do we construct the bits (address range?) that come after the quoted strings?\u00a0 Do they only matter for matching start/end, or are we supposed to check them in the validation procedure?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-20 13:08:48-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 14:17:04-07:00",
    "text": "Thank you for the work on this document, and thank you to the shepherd for a very well-written and in-depth shepherd write up: it was very informative and very appreciated. I have one DISCUSS point (that should be easy to fix) and a question. Francesca 1. ----- \u00a0  then BASE64 encoded and line wrapped to 72 or fewer characters. FP: Please add a (normative) reference to  RFC 4648  and specify if Section 4 (\"base64\") or Section 5 (\"base64url\") is to be used.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-05-21 16:00:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-20 00:36:43-07:00",
    "text": "I may have missed something, but why does Section 5 advocate for use of HTTPS to fetch geofeed files in the second paragraph, and then FTP in the seventh?\u00a0 Which is right?\u00a0 Or perhaps both are right, but there's some context being assumed here that I don't have.\u00a0 In any case, please clarify.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-20 06:52:37-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 14:06:33-07:00",
    "text": "The validation process for the signature computed in Section 4 seems underspecified.\u00a0  For example, let\u2019s consider the example in Appendix A.\u00a0 Through a whois query for 192.0.2.0 one finds a \u201cremarks:\u00a0 \u00a0 \u00a0 \u00a0 Geofeed \u201d field which leads to a geofeed file which had the detached CMS signature blob \u201c# RPKI Signature: 192.0.2.0/24\u201d depicted at the end of Appendix A.\u00a0 What reference or text guides how to validate that signature in the RPKI (akin to the level of detail in Section 3.3 of  RFC7909  or  RFC6125 )? I\u2019m inferring that the steps would roughly be: ** Download the end-entity certificate identified by the subjectKeyIdentifier field via the pointer/URI in the \u201csubjectInfoAccess\u201d\u00a0 field extracted from the CMS signature blob ** Download the intermediate certificate identified by the authorityKeyIdentifier field via the pointer/URI in the \u201ccaIssuer\u201d field extracted from the CMS signature blob ** Based on the RIR identified in the whois query, download the RPKI trust anchor of the RIR ** Validate the certificate chain from the RPKI trust anchor down to the end-entity certificate.\u00a0 Check that all of the basicConstraints, certificatePolicies, etc. are accurate.\u00a0 Check the CRL. ** Verify that the end-entity certificate contains the IP address of interest (192.0.2.0) in the sbgp-ipAddrBlock field ** Validate the signature using the algorithm identified in the CMS signature blog using the end-entity certificate Is that the process?\u00a0 Is that stated somewhere in the document or available via reference?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-01-18 02:14:57-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-14 10:56:11-08:00",
    "text": "I find the document to be a bit short on normative references and some implementation details. Other than that the document looks fine. My specific questions and concern are as follows: 1) Please add a normative reference for HTTP, URI and RelaxNG on first use. 2) Base64 needs a normative reference (including the section number, as there are 2 variants). 3) Section 2 says that all payloads use CMS. None of your examples show CMS. Can you please elaborate on how CMS is used. 4) How can URI of the service be discovered?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-26 06:43:49-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 02:14:57-08:00",
    "text": "I support Alissa's DISCUSS point on versioning. I find the document to be a bit short on normative references and some implementation details. Other than that the document looks fine. My specific questions and concern are as follows: 1) Please add a normative reference for HTTP, URI and RelaxNG on first use. 2) Base64 needs a normative reference (including the section number, as there are 2 variants). 3) Section 2 says that all payloads use CMS. None of your examples show CMS. Can you please elaborate on how CMS is used? 4) How can URI of the service be discovered?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-02-22 11:22:30-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-17 07:39:29-08:00",
    "text": "What is the upgrade path for the future when new versions of this protocol get published? How are clients and servers meant to agree on which version to use?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-02-22 16:11:52-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 16:08:19-08:00",
    "text": "Why is sha-256 hardcoded? You could easily include a hash alg-id even as an option and in that way get algorithm agility, as called for by  BCP201 .\u00a0 (Or you could use something like ni URIs but that's a bit of a self-serving suggestion;-) Anyway, what's the plan for replacing sha-256 here? (This is a bit of a subset of Alissa's discuss with which I agree.) One possible way to handle this here is to identify sha-256 as the default hash algorithm but to re-define the ABNF for hash to allow an alg-id of some sort to be included there. Or have some generic versioning text somewhere that calls for a version bump if sha-256 is not to be used. (If the authors want to include this as a part of the discussion of Alissa's discuss, I'm fine with that and with clearing this discuss and letting the disucsion happen on that thread. But since the solutions could differ, I wanted to at least start a separate discussion on alg. agility.)",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2017-01-17 22:29:47-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-17 22:17:09-08:00",
    "text": "Thanks for finally bringing this protocol forward. I support Alissa's and Alexey's concerns. I only have one discuss for this draft. Looking at section 4, operational considerations I was expecting to see a review of any considerations as to how this protocol works, the interaction between the layers of HTTP, CMS, and XML and any implementation differences/difficulties that exist between the 2 known implementations. Instead there is a discussion on laying out the repository structure under the mandatory to implement _retrieval_ mechanism (RSYNC) and the nuances of RSYNC itself. This appears to be misplaced as the protocol (HTTP/CMS/XML) interactions here are simply about publication from a certificate authority operator to a repository operator, and in that space surely the publication protocol (this doc) is agnostic to the exact repo structure. In both a database world (not a file based one) and where multiple RPKI fetch mechanisms (rsync, http, torrent, etc ...) are used, how is the exact URI meaningful for sidr-publication? There might be a deeper problem here regarding any potential collisions and negotiation of the URI space between the certificate authority operator and the publication repository operator. (sure, in a situation where Alice does both, no problem.) So you may wish to address issues like that in the operational considerations section as opposed to dealing with RSYNC (in)efficiencies.",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2017-03-26 06:42:14-07:00",
    "end_reason": "position_updated",
    "start": "2017-01-17 22:29:47-08:00",
    "text": "Updating after reading sidr-oob-setup-06. I see that the publisher wins as per Section 5.2.4  My original discuss us below, so you may omit the concern about negotiating the URI. The remainder stands. Thanks T. =-=-=-=-=-=-=-=- Thanks for finally bringing this protocol forward. I support Alissa's and Alexey's concerns. I only have one discuss for this draft. Looking at section 4, operational considerations I was expecting to see a review of any considerations as to how this protocol works, the interaction between the layers of HTTP, CMS, and XML and any implementation differences/difficulties that exist between the 2 known implementations. Instead there is a discussion on laying out the repository structure under the mandatory to implement _retrieval_ mechanism (RSYNC) and the nuances of RSYNC itself. This appears to be misplaced as the protocol (HTTP/CMS/XML) interactions here are simply about publication from a certificate authority operator to a repository operator, and in that space surely the publication protocol (this doc) is agnostic to the exact repo structure. In both a database world (not a file based one) and where multiple RPKI fetch mechanisms (rsync, http, torrent, etc ...) are used, how is the exact URI meaningful for sidr-publication? There might be a deeper problem here regarding any potential collisions and negotiation of the URI space between the certificate authority operator and the publication repository operator. (sure, in a situation where Alice does both, no problem.) So you may wish to address issues like that in the operational considerations section as opposed to dealing with RSYNC (in)efficiencies.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-03 10:09:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-01-31 15:19:02-08:00",
    "text": "The CIPO description specifies that a 5-bit Reserved1 field and a 13-bit Public Key Length field are combined to fit into a 16 (not 18)-bit space. (The Figure shows the Public Key Length field as 11 bits.) Why do we need to allow ambiguity/flexibility as to the point representation within a given Crypto-Type value (as opposed to fixing the representation as a parameter of the Crypto-Type)?\u00a0 Alternately, what does \"(un)compressed\" mean, as it's not really clarified directly?\u00a0 Furthermore, Table 2 lists an \"(un)compressed\" representation for type 0 (over P-256), but  RFC 7518  notes that the compressed representation is not supported for P-256 (Section 6.2.1.1).\u00a0 I also am not finding the needed codepoints registered in the JOSE registries to use ECDSA25519 (crypto-type 2) -- do we need to register anything there? Per my comment on Section 4.4, there may be some implicit expectation/requirement of 128+-bit ROVRs for AP-ND, but I didn't find where such a requirement was stated.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-06 16:05:38-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-03 10:09:59-08:00",
    "text": "Why do we need to allow ambiguity/flexibility as to the point representation within a given Crypto-Type value (as opposed to fixing the representation as a parameter of the Crypto-Type)?\u00a0 Alternately, what does \"(un)compressed\" mean, as it's not really clarified directly?\u00a0 Furthermore, Table 2 lists an \"(un)compressed\" representation for type 0 (over P-256), but  RFC 7518  notes that the compressed representation is not supported for P-256 (Section 6.2.1.1).\u00a0 I also am not finding the needed codepoints registered in the JOSE registries to use ECDSA25519 (crypto-type 2) -- do we need to register anything there?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 14:54:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-06 16:05:38-08:00",
    "text": "We need to indicate somehow that the needed codepoints will be registered in the JOSE registries to use ECDSA25519 (crypto-type 2), whether by doing it ourself or by depending on another doc that does so.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-02-01 00:40:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-29 06:18:38-08:00",
    "text": "Thank you for the work put into this document. I found the document easy to read. Please find below a trivial-to-fix DISCUSS (and I am requesting a reply and/or action on this one) plus some non-blocking COMMENTs and NITs. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.4 -- The length of the reserved field is not specified. Or am I missing something obvious ?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-07-03 00:51:19-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-06 20:13:34-07:00",
    "text": "I know this is an optional optimization, as described by the \u201cMAY\u201d in the Introduction.\u00a0 However, some of the other normative language is not as strong as it should be to clearly specify the required behavior (if the mechanisms are being used), cause confusion, or is simply out of place. 1. In 3.1 (Get Sender's IP/MAC Mapping Information for Non-zero IP) the text says that the \u201cRBridge MAY use different strategies to do so\u201d.\u00a0 That \u201cMAY\u201d contradicts the \u201cSHOULD\u201d used before it, which directs the RBridge to verify a duplicate address.\u00a0 s/MAY/may 2. Still in 3.1: \u201c\u2026the RBridge SHOULD verify if a duplicate IP address has already been in use\u2026\u201d\u00a0 What are the reasons where the RBridge would not verify this situation?\u00a0 IOW, why is this \u201cSHOULD\u201d not a \u201cMUST\u201d? 3. I\u2019m confused as to whether the APPsub-TLV is required or not.\u00a0 The source of my confusion comes from Section 3.3 (Determine How to Handle the ARP/ND Response) which says that \u201cR2 SHOULD initiate a link state update to inform all the other RBridges of the target's location\u2026The update message can be carried by an IA APPsub-TLV [IA-draft]\u2026\u201d\u00a0 This text seems to say that the APPsub-TLV SHOULD be used to carry the information \u2014 but text in Section 2 (IP/MAC Address Mappings) sounds to me as if the use of the APPsub-TLV is optional: \u201cIf the RBridge has extracted the sender's IP/MAC address pair from the received data packet (either ARP or ND), it MAY save the information and use the IA APPsub-TLV\u2026\u201d\u00a0 Also, 3.1 and 3.2 both say that an \u201cRBridge MAY use the IA APPsub-TLV\u201d.\u00a0 And finally the Security Considerations section seems to recommend using it\u2026\u00a0 Maybe it\u2019s just me, but please clarify.\u00a0 [BTW, if it is required, then I think that both the IA-draft and DirMech references should be Normative.] 4. In Section 2 (IP/MAC Address Mappings) the \u201cMAY\u201d in the following sentence is out of place since that is already the function of the confidence (as described in  draft-ietf-trill-ia-appsubtlv  and  RFC6325 ): \u201cA different confidence level MAY also be used to indicate the reliability of the mapping information.\u201d 5. In Section 3.2 (Determine How to Reply to ARP/ND), both options (?) a and b say that the \u201cRBridge MAY take one\u2026\u201d.\u00a0 If the RBridge selected that option, then I think the action is no longer optional.\u00a0 s/MAY/MUST",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-11-09 05:40:07-08:00",
    "end_reason": "position_updated",
    "start": "2017-07-05 04:38:50-07:00",
    "text": "It's not clear to me how the security properties of this mechanism compare to existing TRILL. The text says: \u00a0  Unless Secure ND (SEND [ RFC3971 ]) is used, ARP and ND messages can be \u00a0  easily forged. Therefore the learning of MAC/IP addresses by RBridges \u00a0  from ARP/ND should not be considered as reliable. See Section 4.1 for \u00a0  SEND Considerations. \"not considered as reliable\" seems suboptimal. You need to cover how this mechanism compares to the non-use of this mechanism. This document seems very sketchy on what you do when you get duplicate IPs. \u00a0  In the case where the former owner replies, a Duplicate Address has \u00a0  been detected. In this case the querying RBridge SHOULD log the \u00a0  duplicate so that the network administrator can take appropriate \u00a0  action. How does logging solve the problem? What do you reply to ARPs with and/or propagate to other nodes? Do you tell the originator of the advertisement you have a duplicate? \u00a0  When a newly connected end-station exchanges messages with a DHCP \u00a0  [ RFC2131 ] server an edge RBridge should snoop them (mainly the \u00a0  DHCPAck message) and store IP/MAC mapping information in its ARP/ND \u00a0  cache and should also send the information out through the TRILL \u00a0  control plane using ESADI. What happens if the attacker sets up a fake DHCP server and pretends to assign addresses to himself? It seems like maybe that's the same as fake ARPs but maybe not. In general, the security considerations need a complete threat analysis per 3552.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-03-31 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2016-07-07 06:33:09-07:00",
    "text": "Section 3.2 discusses several options for obtaining an answer to a ND query. The section also mentions SEND, which prevents spoofing of results by the bridge itself. I believe it would be useful though to make a clearer recommendation on what to do with regards to the different options on obtaining an answer. Some of them are compatible with SEND, some of them are not. Also, how does one know SEND is being used? Perhaps the document could specify a configurable mode where SEND is assumed to be in use and then you could not use the options that make this problematic. Or, perhaps better, if a node has been observed as using send, then use the correct option for that node.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-07-04 07:59:32-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-05 21:36:08-07:00",
    "text": "* After the ingress RBridge learns the mapping between an IPv6 address and a MAC address how is the liveness being tested/maintained? i.e. If a \"learnt\" target IP goes off link and the Rbridge keeps responding to NS messages wouldn't it make troubleshooting a nightmare? * Section 3.2 case a): There is no guidance as to why or when an Rbridge would pick cases a1..a5. e.g. When a SEND NS is received only option a2 can work and all others will fail.\u00a0  * Section 3.2 case a.1): What should be the source IPv6 address of the NA generated by the ingress RBridge? Will this be an address of the target of the NS or one of the ingress Rbridge that responds? * Section 3.2: How is an ND message where the target IP is not known handled? This case seems to be left out.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-10-22 00:07:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-22 00:06:40-07:00",
    "text": "Thank you for the work put into this document. It is an important topic and the document is both easy to ready and detailed. Please find below one trivial DISCUSS point and a couple of non-blocking COMMENT points but please also check: - Ines Robles IoT directorate review:   https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-iotdir-telechat-robles-2020-10-20/ - Bernie Volz Internet directorate review:    https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-intdir-telechat-volz-2020-10-20/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Please replace all  RFC 4260  reference to  RFC 8200 . Trivial to fix ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-10-30 02:05:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 00:07:30-07:00",
    "text": "Thank you for the work put into this document. It is an important topic and the document is both easy to ready and detailed. Please find below one trivial DISCUSS point and a couple of non-blocking COMMENT points but please also check: - Ines Robles IoT directorate review:   https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-iotdir-telechat-robles-2020-10-20/ - Bernie Volz Internet directorate review:    https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-intdir-telechat-volz-2020-10-20/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Please replace all  RFC 2460  references to  RFC 8200 . Trivial to fix ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-10-30 16:13:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-19 14:51:57-07:00",
    "text": "In Sec 4.1.1: \u00a0  An IPv6 datagram size exceeding 1280 bytes can be avoided by setting \u00a0  the TCP MSS not larger than 1220 bytes.\u00a0 This assumes that the remote \u00a0  sender will use no TCP options, aside from possibly the MSS option, \u00a0  which is only used in the initial TCP SYN packet. \u00a0  In order to accommodate unrequested TCP options that may be used by \u00a0  some TCP implementations, a constrained device may advertise an MSS \u00a0  smaller than 1220 bytes (e.g. not larger than 1200 bytes).\u00a0 Note that \u00a0  it is advised for TCP implementations to consume payload space \u00a0  instead of increasing datagram size when including IP or TCP options \u00a0  in an IP packet to be sent [ RFC6691 ].\u00a0 Therefore, the suggestion of \u00a0  advertising an MSS smaller than 1220 bytes is likely to be \u00a0  overcautious and its suitability should be considered carefully. I would delete everything after the first sentence in this excerpt. While RFC6691  is informational, it clarifies  RFC1122 , which is a standard, and Sec 4.2.2.6 is quite clear that senders MUST consider TCP and IP option length when sizing TCP payloads. Absent any evidence that there are TCP endpoints or middleboxes that are violating  RFC1122 , further reducing the MSS because someone might be violating it is excessive.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-01-18 12:31:28-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-18 12:30:42-08:00",
    "text": "I think this should be an easy DISCUSS to clear; either point to the piece I'm missing, or don't use an overloaded node. Section 2.4 (Overload and Appointed Forwarders) talks about potential Appointed Forwarders which are overloaded.\u00a0 In IS-IS, a node with the overload bit set \"shall not\" (ISO 10589) be considered for transit.\u00a0 However, the use of \"SHOULD NOT appoint an RBridge in overload\" and \"SHOULD re-assign VLANs from the overloaded RBridge\" leaves a potential hole in the proper forwarding of TRILL data packers.\u00a0 Why aren't MUST NOT/MUST used?\u00a0 Is there something in the specific use of IS-IS by TRILL that I am missing?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-03-21 09:17:04-07:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 12:31:28-08:00",
    "text": "Section 2.4 (Overload and Appointed Forwarders) talks about potential Appointed Forwarders which are overloaded.\u00a0 In IS-IS, a node with the overload bit set \"shall not\" (ISO 10589) be considered for transit.\u00a0 However, the use of \"SHOULD NOT appoint an RBridge in overload\" and \"SHOULD re-assign VLANs from the overloaded RBridge\" leaves a potential hole in the proper forwarding of TRILL data packers.\u00a0 Why aren't MUST NOT/MUST used?\u00a0 Is there something in the specific use of IS-IS by TRILL that I am missing? I think this should be an easy DISCUSS to clear; either point to the piece I'm missing, or don't use an overloaded node.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-03-11 00:05:09-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 06:29:36-08:00",
    "text": "I would like to see a resolution to Dan Romascanu's OPS DIR concern. https://datatracker.ietf.org/doc/review-ietf-trill-rfc6439bis-04-opsdir-telechat-romascanu-2017-01-12/ Note that the discussion is under way with Donald Eastlake",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2023-01-15 15:09:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-15 00:41:30-08:00",
    "text": "# Internet AD comments for  draft-ietf-ippm-ioam-deployment-02 CC @ekline ## Discuss ### S7.3 * \"A deployment can choose to configure and support one or both of the \u00a0  IOAM Trace-Option-Types.\" \u00a0 I don't think this paragraph is quite correct as written, since it's \u00a0 theoretically tied to the limitations of the protocols in use in a \u00a0 deployment.\u00a0 Perhaps adding something along the lines: \u00a0 \"Which options can be supported is not only a function of the \u00a0  operator-defined configuration, but may also be limited by protocol \u00a0  constraints unique to a given encapsulation layer.\"",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-01-10 11:27:16-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 14:39:26-08:00",
    "text": "Thanks for working on this specification. I have a easy to fix discuss point. It is a bit confusing to see where these IOAM namespace, IOAM laying at section 7 come from. Is this something this document is suggesting to use to easy implementation and deployment? or is this something described in other documents and merely described here. As Section 7 is the main meat of this specification, I would like to discuss if this could be clarified better.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-06-05 14:35:48-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-22 09:08:36-07:00",
    "text": "I have a small list of issues that I would like to discuss before recommending approval of this document: 1) The first reference to UTF-8 needs a Normative reference to  RFC 3629 . 2) In Section 3.10.1, you say: \u00a0  The names of generic objectives MUST NOT include a colon (\":\") and \u00a0  MUST be registered with IANA (Section 7). In Section 7 you only say: \u00a0  GRASP Objective Names Table.\u00a0 The values in this table are UTF-8 \u00a0  strings.\u00a0 Future values MUST be assigned using the Specification \u00a0  Required policy defined by [ RFC5226 ]. IANA is not going to review section 3.10.1 and there is no back reference in Section 7. IANA needs to know that values with \":\" are not to be registered.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-07-05 17:05:53-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-24 19:32:54-07:00",
    "text": "ISSUE 1 The security situation here is pretty unspecified here, in at least two respects: 1. In terms of communication security, you seem to have two modes: \u00a0  (a) Punt it to ACP \u00a0  (b) Use TLS as specified in S 3.5.2.1 I'm not reviewing ACP here (though I have some comments on that too) but S 3.5.2.1 doesn't (for) instance explain how to do certificate validation, which it clearly needs to do. Finally, I don't understand the security story for the multicast packets. This is especially relevant for Rapid mode, where you are attaching real work to these multicast packets. 2. I didn't find the security model very clear. As I understand things, basically anyone on the network who has ACP credentials is trusted to engage in negotiation with you, so, for instance, if you want to get parameter X, then you basically just trust whoever on the network offers you X. is that correct? That seems like it needs to be very explicitly called out. And if that's not true, then I don't understand the spec. ISSUE 2 This document seems like it provides incomplete guidance on how to actually implement it. For instance: \u00a0  discovery messages to a reasonable value, in order to mitigate \u00a0  possible denial of service attacks.\u00a0 It MUST cache the Session ID \u00a0  value and initiator address of each relayed Discovery message until What's \"reasonable\"? ISSUE 3. I don't think I understand how the transition from UDP multicast to TCP/TLS unicast works. Maybe I'm just misreading the spec, so could you point me to the section that describes this. Finally, I don't see a spec for how you map CBOR onto the wire. Do you just shove them on? Something else? I see that Martin Thomson raised a number of these issues in his review in more detail.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-05-23 08:19:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-23 06:51:11-07:00",
    "text": "1) Use of transport protocols is not sufficiently defined Especially the following text in section 3.5.3 seems not to reflect later assumptions correctly; it seems to be assumed that TCP is used for all messages other than the discovery and therefore reliable transport is provided for these message (see sections 3.5.5 and 3.8.5): \"All other GRASP messages are unicast and could in principle run over \u00a0  any transport protocol.\u00a0 An implementation MUST support use of TCP. \u00a0  It MAY support use of another transport protocol but the details are \u00a0  out of scope for this specification.\u00a0 However, GRASP itself does not \u00a0  provide for error detection or retransmission.\u00a0 Use of an unreliable \u00a0  transport protocol is therefore NOT RECOMMENDED.\" section 3.8.4.: \" It then listens for unicast TCP responses on a given port...\" 2) Time-out handling section 3.5.4.4: \"Since the relay device is unaware of the timeout set by the original \u00a0  initiator it SHOULD set a timeout at least equal to GRASP_DEF_TIMEOUT \u00a0  milliseconds.\" Should a relay really maintain an own time-out? Wouldn't it be suffiecent to just relay again if another discovery message is received. Otherwise this can lead to an amplification, when the own time-out expires and another relay message is sent when another discovery message is received due to the time-out of the orginating peer. Further in relation to the point about, this should be more specific: section 3.5.4.4: \"Also, it MUST limit the total rate at which it relays \u00a0  discovery messages to a reasonable value, in order to mitigate \u00a0  possible denial of service attacks. \" 3) Version and extensibitity: section 3.5.4.5: \"A possible future extension \u00a0  is to allow multiple objectives in rapid mode for greater efficiency.\" How can this extension be defined if there is no version mechanism?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-07-07 04:30:32-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-23 08:19:11-07:00",
    "text": "1) Use of transport protocols is not sufficiently defined Especially the following text in section 3.5.3 seems not to reflect later assumptions correctly; it seems to be assumed that TCP is used for all messages other than the discovery and therefore reliable transport is provided for these message (see sections 3.5.5, 3.8.4 and 3.8.5): \"All other GRASP messages are unicast and could in principle run over \u00a0  any transport protocol.\u00a0 An implementation MUST support use of TCP. \u00a0  It MAY support use of another transport protocol but the details are \u00a0  out of scope for this specification.\u00a0 However, GRASP itself does not \u00a0  provide for error detection or retransmission.\u00a0 Use of an unreliable \u00a0  transport protocol is therefore NOT RECOMMENDED.\" In general the usage of the transport protocols is not well enough specified, see also Spencer's comments and this part of Martin's tsv-art review (Thanks!): \"* Usage of UDP: This document is not discussing any of the aspects in  RFC 8085 . Every usage of UDP is required by IETF consensus to review  RFC 8085  and to address at least the applicable subset of issues listed in  RFC 8085  (or the predecessor  RFC 5405 ). * Starting with UDP and switching to TCP for the data transfer looks like the right do. However, UDP should be really only used to discover other devices, but not piggy back further protocol mechanics. However, this document is not really specific on how to make use of TCP, for instance, how long are TCP connections kept open or closed down after a protocol exchange (persistent vs temporary connections). What happens if a TCP connection is shutdown by one end or is forcefully closed, e.g., by a reset?\" I would recommend, as assumed in the rest of the document, to update section 3.5.3 to only use UDP for the initial recovery message and open a TCP connection for the discovery response and require that all other messages to be sent over TCP (also removing any option to use any other reliable transport because TCP seems to be the right choice here.) Further, additional guidance is needed when to open and close a TCP connection (or keep it alive for later use) and what to do if the connection is interrupted. 2) Time-out handling section 3.5.4.4: \"Since the relay device is unaware of the timeout set by the original \u00a0  initiator it SHOULD set a timeout at least equal to GRASP_DEF_TIMEOUT \u00a0  milliseconds.\" Should a relay really maintain an own time-out? Wouldn't it be sufficient to just relay again if another discovery message is received. Otherwise this can lead to an amplification, when the own time-out expires and another relay message is sent when another discovery message is received due to the time-out of the originating peer. Further in relation to the point about, this should be more specific: section 3.5.4.4: \"Also, it MUST limit the total rate at which it relays \u00a0  discovery messages to a reasonable value, in order to mitigate \u00a0  possible denial of service attacks. \" 3) Version and extensibility: section 3.5.4.5: \"A possible future extension \u00a0  is to allow multiple objectives in rapid mode for greater efficiency.\" How can this extension be defined if there is no version mechanism?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-02-03 19:50:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-20 05:19:46-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D12072 This seems like can be easily fixed, but I do think it needs to be fixed. DETAIL S 2. >\u00a0 \u00a0 \u00a0 header if necessary). >\u00a0   >\u00a0 \u00a0 \u00a0 The token identifies the CDN as a whole.\u00a0 Chosen token values SHOULD >\u00a0 \u00a0 \u00a0 be unique enough that a collision with other CDNs is unlikely. >\u00a0 \u00a0 \u00a0 Optionally, the token can have semicolon-separated key/value >\u00a0 \u00a0 \u00a0 parameters, to accommodate additional information for the CDN's use. I don't know how to understand \"unique enough\" as a conformance requirement. I think you need to specify something specific here, like \"globally unique\" or some other scope. I don't insist that you provide a construction algorithm, though obviously that would be good.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-02-02 16:15:46-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-19 21:32:34-08:00",
    "text": "Thanks, Mike, for the excellent editing work on a very clear and well written document. In Section 4.1.1 I\u2019m confused by the combination of the following two paragraphs, and would like to discuss what I\u2019m missing: \u00a0  Like HTTP/2, HTTP/3 does not use the Connection header field to \u00a0  indicate connection-specific fields; in this protocol, connection- \u00a0  specific metadata is conveyed by other means.\u00a0 An endpoint MUST NOT \u00a0  generate an HTTP/3 field section containing connection-specific \u00a0  fields; any message containing connection-specific fields MUST be \u00a0  treated as malformed (Section 4.1.3). ... \u00a0  This means that an intermediary transforming an HTTP/1.x message to \u00a0  HTTP/3 will need to remove any fields nominated by the Connection \u00a0  field, along with the Connection field itself.\u00a0 Such intermediaries \u00a0  SHOULD also remove other connection-specific fields, such as Keep- \u00a0  Alive, Proxy-Connection, Transfer-Encoding, and Upgrade, even if they \u00a0  are not nominated by the Connection field. Given the MUST in the first, how can the second only be SHOULD?\u00a0 Wouldn\u2019t such an intermediary, acting as the HTTP/3 client, be producing a malformed message if it did not \u201cremove other connection-specific fields\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-02 16:28:49-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-20 10:29:16-08:00",
    "text": "[note to Lucas/chairs: a few (three, I think) of these discusses/comments have preexisting github issues created by the editors over the past couple days due to some out of band discussions; if we can easily reuse them instead of creating new ones that would be preferred] (discuss point 1) Mike already filed  https://github.com/quicwg/base-drafts/issues/4761 and I think we can keep the discussion there. But to reiterate, we reference [SEMANTICS] for certificate validation and use in determining authority for the \"https\" scheme, yet the additional prose discussion we offer (with CN-ID and DNS-ID as the certificate fields to validate against, though not by that name) does not match what's currently present in [SEMANTICS].\u00a0 Discussion so far on the linked issue against [SEMANTICS] suggests that [SEMANTICS] will change, but we should not go forward with this document until we've resolved the disparity.\u00a0 (One might also wonder whether we need to duplicate the content ourselves or should just reference the other document(s).) There is a related topic in that our current formulation in this document treats CN-ID and DNS-ID as equivalently recommended, but current recommendations (including in  RFC 6125 ) are to prefer SAN-based names over the (legacy) CN-ID.\u00a0 I believe there are even some efforts underway in the Web ecosystem to move to fully deprecating the use of CN-ID; at present I believe that some entities require that any name present in the CN-ID be replicated as a DNS-ID as well.\u00a0 If we are to proceed with giving equal preference to CN-ID and DNS-ID, I think that we need to justify or at least call out the divergence from current IETF guidance. [Martin filed  https://github.com/quicwg/base-drafts/issues/4769  for the topic regarding whether CN-ID is mandatory or even recommended.] (discuss point 2) I also think that the procedure, as written, for coalescing HTTP requests against different URI authority components onto a single HTTP/3 connection is under-specified and seems inconsistent both with earlier WG conclusions and with previous IETF-mandated practices for certificate validation. [begin historical tracethrough] There appears to be quite a long history in this space (and I probably missed some of it, even).\u00a0 The idea of coalescing has been around back from the days when we only allowed Alt-Svc as discovery for using QUIC (no direct access), with https://github.com/quicwg/base-drafts/issues/940  being an early issue leading to  https://github.com/quicwg/base-drafts/pull/1024/files , with text that requires both Alt-Svc and valid certificate in order to be authoritative.\u00a0 Then we had https://github.com/quicwg/base-drafts/issues/2223  that notes that this Alt-Svc requirement is more restrictive than  RFC 7540 , which allegedly only requires the certificate to match a given name.\u00a0 (One might argue that 7540's \"additionally depends on having a certificate that is valid\" implies the \"depends on the host having resolved to the same IP address\" still applies, though of course ORIGIN weakens that if it was ever present and this is not terribly relevant to the current question.) Comments on #2223 seem to confirm that the intent is to largely parallel what HTTP/2 does; I'll come back to that in a bit.\u00a0 The corresponding text changes here are https://github.com/quicwg/base-drafts/pull/3558/files  that brings in the concept that \"a server is considered authoritative for all URIs with the 'https' scheme for which the hostname in the URI is present in the authenticated certificate provided by the server, either as [...]\". This text got moved a bit and reworded slightly in response to the secdir review ( https://github.com/quicwg/base-drafts/pull/4419/files ), but the intent is largely still present as \"If a server presents a valid certificate and proof that it controls the corresponding private key, then a client will accept a secured TLS session with that server as being authoritative for all origins with the \"https\" scheme and a host identified in the certificate.\" [end historical tracethrough] So now we have text that says: \u00a0  If a server presents a valid certificate and proof that it controls \u00a0  the corresponding private key, then a client will accept a secured \u00a0  TLS session with that server as being authoritative for all origins \u00a0  with the \"https\" scheme and a host identified in the certificate. This seems problematic to me, and divergent from HTTP/2, in that it focuses on the contents of a certificate *all* being valid/authoritative, as opposed to a certificate being valid for a given host/name.\u00a0 To quote \u00a79.1.1 of  RFC 7540 : \u00a0  For \"https\" resources, connection reuse additionally depends on \u00a0  having a certificate that is valid for the host in the URI.\u00a0 The \u00a0  certificate presented by the server MUST satisfy any checks that the \u00a0  client would perform when forming a new TLS connection for the host \u00a0  in the URI. A representative discussion of these checks is included in  RFC 6125 , and the general procedure for (server) certificate validation takes as input a candidate name of a service or entity that the client is attempting to contact, a certificate (chain) and signature presented by the server, and the application context in which the decision is being made [0].\u00a0 In short, the question is always \"do I (as the client) trust the peer entity to act as this specific name?\", and the answer may differ across names present in a single certificate!\u00a0 So I think we need to refresh this text once more, to bring back the sense that for each name that we might want to allow the server to act as an authority for, we have to do the normal validation checks.\u00a0 Saying that we validate a certificate once along with proof of possession of its private key and then the holder of the key is a valid authority for all names in the certificate invites violation of the client's security policy.\u00a0 For example, the client's trust database might not allow the CA(s) in the presented chain to certify some of the names contained in the certificate, among other reasons. (discuss point 2.1) There is probably some extra excitement surrounding revocation, in that the \"normal certificate validation procedures\" typically involve some form of attempt at a revocation check.\u00a0 What should happen if this check determines that the certificate has been revoked is not entirely clear. Presumably the attempt to use a new name from the certificate would fail, but does it also imply that the entire connection should be torn down, since it was built using the now-revoked certificate? (discuss point 2.2) In practice, the procedure of \"check the name in question against the certificate chain\" seems to mean that a client that is willing to coalesce connections needs to retain the certificate and chain presented by the peer, so that it is available as input to the certificate validation engine (typically accessed via the TLS stack, I suppose) at the time when an authentication decision needs to be made for a given name.\u00a0 This operational practice, as well as the actual mechanics of running a fresh certificate validation procedure, should probably be mentioned down in Section 3.3 where we discuss the actual connection reuse procedures.\u00a0 In particular, I think it would be very benficial to indicate what protocol interactions trigger an attempt by the client to validate a new name from the certificate for use as the authority for HTTP responses, as well as to note clearly that the certificate+chain have to be retained in order to run these checks. (discuss point 2.3) I think we should also look at the procedures for server push as they relate to coalescing; my understanding is that pushed responses are allowed to be for requests to a different authority, and thus that a client will need to discard or reject pushes that are from an authority that the client does not accept the peer as being authoritative for.\u00a0 I guess this is in some sense a check that the client always has to do for all pushed responses, but I'm not entirely sure whether or where that is currently described. [0] This context includes things like the set of trust anchors, as well as potentially information about restrictions on trust anchors, revocation checks, pinning or other restrictive information that reduces the set of CAs that might be allowed to certify a given name, etc.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-23 15:38:53-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-19 15:15:07-07:00",
    "text": "(1) I think that we need some text that covers how the resource server will know to use mtls (and thus, to send a CertificateRequest to the client during the TLS handshake).\u00a0 The authorization server and client can indicate their capabilities/preference via the  RFC 8414  and  RFC 7591 discovery and registration procedures, but I didn't see any discussion of how an AS might know a RS's capabilities, or how an RS might develop expectations of the capabilities of the clients accessing it.\u00a0 A naive conclusion might be that any given RS (hostname+port) would have to either always or never use mtls, given the misordering between TLS handshake completion and delivery of TLS application data (i.e., including the oauth token), though there may be refinements available in the form of the unpopular TLS 1.2 renegotiation or TLS 1.3 post-handshake authentication (or exported authenticators).\u00a0 Doing either of those in an environment with TLS Termination per Section 6.5 may entail additional complications. (We may also want some additional text discussing error handling for the client/AS interaction, e.g., if a request shows up from a client-id that should be using mtls but did not provide a certificate in the TLS handshake, but that is only debatably something that rises to Discuss-level; or if a client that advertised an intent to use MTLS used the regular token endpoint and not the mtls endpoint alias (if they differ).) (2) I can't validate the examples in Appendix A. Specifically, my reading of the text would put the \"x5t#S256\" value as needing 86 characters, but only 43 are provided.\u00a0 The ones there also do not seem to be a prefix of the result that I get from taking the PEM certificate contents and running them through the pipeline: base64 -di | sha256sum |awk '{print $1}'|tr -d '\\n'|base64 (Noting, of course, that 'base64' will be producing the non-URL-safe variant, but expecting it to remain \"pretty close\".) I also had some trouble comparing the \"y\" coordinate from the JWK to the certificate contents, but that may just be user error.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-02-16 07:15:51-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-15 08:06:14-08:00",
    "text": "This is a general discuss on the principle of using extension mechanisms (like versioning) and how and when to use it. This document increases the version number to add one new PDU type as well as to clarify some questions on timing parameters. However, versioning is just one extensibility mechanism out-of a whole set of option. In this case the protocol also has an (8 bit) type field to define new PDU types. Only 8 types are used so far (in version 0 of the protocol) out of 2^8 which leaves another option for extending the protocol. The usually specification here is that the receiver will ignor unknown types which is exactl what you want. There in this case I don't see that a new version necessary.  Further there is an issue on how the versioning is done. This document looks like a bis document and used to obsolete the old spec till the last version (-07) but now neither updates nor obsolete it. If you actually decide to have a new version, that might be right (also updating might be an option which I would actually recommend in this case because I believe the expectation is that new implementation should always implement this version) but I don't really see in this case that doublicating all the text is the best option. I would actually not recommend to increase the version because I really don't see a need for this, given the (much easier) extensibily mechanism you have with the type. If you'd only would like add the new type, then actually a short draft that defines the type and updates  rfc6810  would be sufficient. Regarding the other calrification, I think this could also be done in a short (potentially the same) updating draft. If you still think it better to copy all the text and have one clean draft than obsoleting is the right choice.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-21 07:24:19-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:33:05-07:00",
    "text": "An easy to fix issue. Section 8.\u00a0 I agree with the brevity of this section as the more detailed considerations can be found in [ draft-ietf-netconf-subscribed-notifications ]. [ draft-ietf-netconf-subscribed-notifications ] has a similar statement about buggy subscribers, but also makes a SHOULD statement about operators monitoring for odd behavior.\u00a0 This text doesn\u2019t include this monitoring recommendation but does explicitly discuss terminating sessions.\u00a0 Could the text in these two sections please be reconciled. Perhaps with a reference such as: \u201cThis document does not introduce additional Security Considerations for dynamic subscriptions beyond those discussed in [ draft-ietf-netconf-subscribed-notifications ].\u00a0 In particular for NETCONF subscribers \u2026 \u201d",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-10-07 09:10:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 13:56:38-07:00",
    "text": "I am balloting DISCUSS because I find the document unclear and lacking proper technical details around significant functionality, as reflected in my first 3 points.\u00a0 The fourth point is related to the registration policy (which doesn't match the definition in  rfc8126 ), and my last point is for the IESG to consider. (1) Pseudocode and normative behavior The use of pseudocode was chosen as the mechanism to specify behavior, as explained in \u00a74: \u00a0  An implementation of the pseudocode is compliant as long as the externally \u00a0  observable wire protocol is as described by the pseudocode. Clarity in the pseudocode is essential because it is used to determine compliance.\u00a0 Several places need improvement: (1a) In \u00a74.1/\u00a74.13/\u00a74.15, the pseudocode is missing an ELSE after S04, to include the error conditions if SL != 0.\u00a0 A check for an error condition when SL is decremented is also needed.\u00a0 As written, the pseudocode could process the packet (SL == 0) *and* send an ICMP time exceeded message... :-( I'm using as a reference the pseudocode in \u00a74.3.1.1/rfc8754, which includes the same initial statement. (1b) It would be nice if the behavior in \u00a74.1.1 were also specified using pseudocode.\u00a0 As written, I am not sure if the intent is to process any upper-layer header or only specific ones.\u00a0 Is the objective for this operation to be similar to the one in \u00a74.3.1.2/rfc8754?\u00a0 Please be specific on what is meant by \"allowed by local configuration\". [Note: this point by itself is not DISCUSS-worthy, but \u00a74.1.1 is used, for different reasons, in some of the other items I point to below.\u00a0 That is why I include it here.] (1c) \u00a74.4/\u00a74.6: S01 of the second piece of pseudocode is an instruction for processing a non-IPv6 upper header.\u00a0 However, earlier in that section, it is specified that the SID \"is associated with one or more L3 IPv6 adjacencies/an IPv6 FIB table\".\u00a0 How can the upper header not be IPv6 if the specification explicitly says it has to be? (1d) \u00a74.5/\u00a74.7 have the same issue but related to IPv4. (1e) \u00a74.9 also has the same issue when it specifies that \"End.DX2 SID...is associated with one outgoing interface I\", but allows for the processing of non-ethernet payloads which could then be forwarded through a different outgoing interface. (1f) \u00a74.11/\u00a74.12 allows the processing of non-ethernet payloads, which will not be \"associated with an L2 Table T\" as described. (2) \u00a74.12 describes the only behavior that can carry an ARG.\u00a0 I don't understand how it works: \u00a0 \u00a0 \u00a0 Arg.FE2 is encoded in the SID as an (k*x)-bit value.\u00a0 These bits \u00a0 \u00a0 \u00a0 represent a list of up to k OIFs, each identified with an x-bit \u00a0 \u00a0 \u00a0 value.\u00a0 Values k and x are defined on a per End.DT2M SID basis.\u00a0 The \u00a0 \u00a0 \u00a0 interface identifier 0 indicates an empty entry in the interface \u00a0 \u00a0 \u00a0 list. Let's assume a router has 10 possible OIFs, and the operator uses 4-bit values to identify them; then, the ARG would take 40 bits of the SID.\u00a0 Is that how the math works? Assuming my interpretation is correct, for 20 OIFs and 5-bit values we would need 100 bits.\u00a0 Considering the examples in \u00a73.2, where a /64 is allocated to a router, this behavior wouldn't have enough bits!\u00a0 I realize that maybe a better encoding would be to use a 20-bit field, each representing an interface.\u00a0 However, there would still be a limit of < 64 OIFs.\u00a0 Am I missing something? I'm trying to ultimately get to the fact that there are limits to this behavior, but they are not described in the document.\u00a0 Please clearly explain any limitations and any possible workaround. (3) The description of the flavors in \u00a74.16 is also unclear. The section starts with this introduction: \u00a0  The PSP, USP and USD flavors are variants of the End, End.X and End.T \u00a0  behaviors.\u00a0 For each of these behaviors these flavors MAY be \u00a0  supported for a SID either individually or in combinations. By being \"variants\", I interpret that the behavior is different than what is specified in \u00a74.1.\u00a0  (3a) Some of the behaviors, as listed in Table 4, include an indication of the flavors.\u00a0 How are the values interpreted?\u00a0 For example, the Table lists 8 different behaviors related to End: | 1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0001 |\u00a0  End (no PSP, no USP)\u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0002 |\u00a0 \u00a0 \u00a0  End with PSP\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 3\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0003 |\u00a0 \u00a0 \u00a0  End with USP\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0004 |\u00a0 \u00a0  End with PSP&USP\u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | ... | 28\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001C |\u00a0 \u00a0 \u00a0  End with USD\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 29\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001D |\u00a0 \u00a0  End with PSP&USD\u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 30\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001E |\u00a0 \u00a0  End with USP&USD\u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 31\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001F | End with PSP, USP & USD |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | Is value 1 what is specified in \u00a74.1?\u00a0 Or does it include USD, which is not explicitly excluded)? (3b) If a behavior with more than one flavor is signaled, how should the receiving node determine which one to apply?\u00a0 I guess that the application of behaviors 4 or 29 depends on the number of SLs -- the expected behavior should be clearly specified. (3c) Is it assumed that all nodes support all behaviors?\u00a0 Are there mandatory to implement behaviors?\u00a0 Should the behavior be advertised before it is used? (3d) \u00a74.16.1.2:  \u00a0  When a SID of PSP-flavor is processed at a non-penultimate SR Segment \u00a0  Endpoint Node, the PSP behavior is not performed as described in the \u00a0  pseudocode below since Segments Left would not be zero. For example, for the End behavior, I'm assuming that behavior 1 is performed instead of 2 (or 4, or 29, or 31) if SL != 0.\u00a0 Should this be done even if the node did not advertise the non-PSP flavor?\u00a0 If the node is not known to support the PSP flavor, should it be an error to receive a packet requesting that behavior? If only the PSP flavor is advertised, can the Source assume that the node also supports the non-PSP flavor? \u00a0 [BTW, I'm asking about advertisement because \u00a74.16.1.1 makes the statement \u00a0 that the nodes \"advertise the SIDs instantiated on them via control plane \u00a0 protocols as described in Section 9\".\u00a0 Even though \u00a79 talks about control \u00a0 plane protocols are \"not necessary for an SDN control plane\" because \"one \u00a0 expects the controller to explicitly provision the SIDs\".] (3e) \u00a74.16.2 describes the USP flavor, which is one where the endpoint consumes the packet by processing the next header.\u00a0 I don't understand how the outcome due to the extended process is different from the original one in \u00a74.1.\u00a0 Can you please explain?\u00a0 It seems to me that the externally observable result is the same. I have the same question about the USD flavor and the externally observable behavior related to \u00a74.1. In general, the observable behavior of \u00a74.1, USP, and USD seem the same to me.\u00a0 The next two points are related. (3f) \u00a74.16.3 describes the USD flavor, which assumes that the decapsulation results in a packet that can be forwarded.\u00a0 Can the FIB lookup result in a local destination? (3g) Does the USD flavor mean that, for the End behavior (as described in \u00a74.1), the action of \"process the next header in the packet\" cannot result in a forwarded packet?\u00a0 Same question for the USP behavior? (3h) The last paragraph in \u00a74.16.3: \u00a0  An implementation that supports the USD flavor in conjunction with \u00a0  the USP flavor MAY optimize the packet processing by first looking \u00a0  whether the conditions for the USD flavor are met, in which case it \u00a0  can proceed with USD processing else do USP processing. What are the \"conditions for the USD flavor\"?\u00a0 As far as I can tell from the document, the only condition is for the specific behavior to be signaled.\u00a0 What else? Going back to the questions above...\u00a0 When is the option to optimize possible?\u00a0 Does a specific behavior have to be used?\u00a0 Behavior 30 (End with USP&USD)?\u00a0 Or can it also optimize if behavior 3 (End with USP) is signaled? (4) \u00a710.2 creates a new registry with an \"FCFS\" registration procedure.\u00a0 I am assuming that this is the same as the \"First Come First Served\" (no abbreviation!) policy from  rfc8126 ; please add a reference if that is the case.\u00a0 The description used is not the same as what  rfc8126  specifies: - \"Requests for allocation...must include a...preferably also a brief \u00a0 description of how the value will be used.\"\u00a0  Using \"preferably\" indicates \u00a0 that a description is optional.\u00a0 However, it is not optional in  rfc8126 . - \"...brief description...may be provided with a reference to an Internet \u00a0 Draft or an RFC or in some other documentation that is permanently and \u00a0 readily available.\"\u00a0 There is no such requirement in  rfc8126 .\u00a0 For example, \u00a0 the \"Specification Required\" policy requires \"a permanent and readily \u00a0 available public specification\".\u00a0 Is that what you want\u00a0 instead? (5) This point is for the IESG to discuss. \u00a74.16.1.2: \u00a0 \u00a0 \u00a0 The End, End.X and End.T behaviors with PSP do not contravene \u00a0 \u00a0 \u00a0 Section 4 of [ RFC8200 ] because the destination address of the \u00a0 \u00a0 \u00a0 incoming packet is the address of the node executing the behavior. The spring WG's interpretation of  rfc8200  was a central point in the appeal presented against the WG consensus on this document.\u00a0 The text above, I believe, reflects that consensus.\u00a0  However, given that the document relies on the spring WG's interpretation of  rfc8200 , I think it would be better if the text is explicit.\u00a0  Suggestion: to add at the end of the paragraph>   \u00a0  This conclusion represents the consensus interpretation of the spring WG.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-24 00:52:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-24 00:43:29-07:00",
    "text": "The current requirement that IANA-assigned SRv6 Endpoint Behavior codepoints are used, with no range reserved for local assignment, seems to be inviting codepoint squatting from the nominally reserved range. Why is there an absolute requirement for registration (even FCFS) without ranges for local or experimental use?\u00a0 (What are the various reserved ranges reserved for?) The (normative) pseudocode does not seem to handle the case when the SRH is omitted for the degenerate case where there is only a single segment, or for the PSP flavor. The pseudocode for the PSP and USP procedures seem incorrect -- Hdr Ext Len is measured in units of 8 octets, and does not include the first 8 octets of the extension header, but Payload Length is measured in octets.\u00a0 Literally decreasing the Payload Length by the Hdr Ext Len value will produce a malformed IPv6 packet. If \"PSP operation is deterministically controlled by the SR Source Node\", why do we need to define behavior codepoints that (for example) use both PSP and USP?\u00a0 I don't see how there is full determinism in this case while being different from the \"PSP only\" flavor. There are numerous factual errors and un/under-specified protocol behavior (see COMMENT), including: how to set the outer Hop Limit (multiple instances), the order of segments in the SRH, specification of headend behavior by reference to informal example, L2 frame en/decapsulation procedures, and the \"Opaque\" note for endpoint behavior 65535. A discussion topic, which may or may not entail changes to this document:  RFC 8200  notes that specifications of new extension headers need to indicate their ordering constraints with respect to the other extension headers, but  RFC 8754  makes no such indications.\u00a0 Are there in practice ordering constraints that we should attempt to document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-09 09:04:52-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-24 00:52:05-07:00",
    "text": "[edited to remove nonsensical point that had crept in about the SRH being a new extension header; it's \"just\" a routing header] The current requirement that IANA-assigned SRv6 Endpoint Behavior codepoints are used, with no range reserved for local assignment, seems to be inviting codepoint squatting from the nominally reserved range. Why is there an absolute requirement for registration (even FCFS) without ranges for local or experimental use?\u00a0 (What are the various reserved ranges reserved for?) The (normative) pseudocode does not seem to handle the case when the SRH is omitted for the degenerate case where there is only a single segment, or for the PSP flavor. The pseudocode for the PSP and USP procedures seem incorrect -- Hdr Ext Len is measured in units of 8 octets, and does not include the first 8 octets of the extension header, but Payload Length is measured in octets.\u00a0 Literally decreasing the Payload Length by the Hdr Ext Len value will produce a malformed IPv6 packet. If \"PSP operation is deterministically controlled by the SR Source Node\", why do we need to define behavior codepoints that (for example) use both PSP and USP?\u00a0 I don't see how there is full determinism in this case while being different from the \"PSP only\" flavor. There are numerous factual errors and un/under-specified protocol behavior (see COMMENT), including: how to set the outer Hop Limit (multiple instances), the order of segments in the SRH, specification of headend behavior by reference to informal example, L2 frame en/decapsulation procedures, and the \"Opaque\" note for endpoint behavior 65535.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-28 15:19:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-09 09:04:52-08:00",
    "text": "Thanks for the updates through to the -26; they help a lot. However, I do think there is one final Discuss-level point that needs to be resolved: it's mostly a process point, to make sure that what we say in this document complies to the requirements that were laid out in  RFC 8754  for the procedure we're trying to follow.\u00a0 Specifically, in the process of trying to finalize my review comments, I ended up doing a lot of background reading, in which I noticed that  RFC 8754  says: \u00a0  New SIDs defined in the future MUST specify the mutability properties \u00a0  of the Flags, Tag, and Segment List and indicate how the Hashed \u00a0  Message Authentication Code (HMAC) TLV (Section 2.1.2) verification \u00a0  works.\u00a0 Note that, in effect, these fields are mutable. This is a bit confusing to me, in that the SIDs themselves appear as entries in the Segment List, and it's not quite clear when or how a per-SID behavior relating to fields in the containing SRH might come into play.\u00a0 However, given that we allocate a behavior codepoint for \"the SID defined in  RFC 8754 \", I am forced to conclude that the behaviors specified in this document meet the definition of \"new SIDs\" that are being defined \"in the future\" (from the reference point of  RFC 8754 ), and therefore that they must specify the indicated properties. I'm told out of band that the intent is to do the same thing that  RFC 8754  does for the SID it defines, and so this should be trivial to resolve just by adding a brief note that (e.g.) \"the SIDs specified in this document have the same HMAC TLV handling and mutability properties of the Flags, Tag, and Segment List field as the SID specified in  RFC 8754 \".\u00a0 However, I believe that such an explicit statement is required, and that we would introduce an internal inconsistency between this document and  RFC 8754  if we say nothing on this topic.\u00a0 In particular, I think that we would not inherit that behavior as some kind of default behavior if we make no statement at all. I am sorry that I did not notice this earlier, but I feel that it is important to remain consistent with the requirements of  RFC 8754  and thus that this is appropriate to raise as a Discuss-level point, even if I have previously reviewed the text in question.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-10-29 22:29:51-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 23:40:28-07:00",
    "text": "I support Alvaro's and others' discuss points.\u00a0 I have only a few points that I think are easily cleared. [ section 3.2 ] * I'm a bit concerned about this first example, as it might give the mistaken \u00a0 impression that fc00::/7 is free for anyone to carve up as they wish \u00a0 (I say this regardless of what this operator may or may not have done). \u00a0 Per 4193, operators are supposed to generate random /48s from fd00::/8. \u00a0 I think this is easily corrected though, and I'd suggest: \u00a0 OLD: \u00a0 .....\u00a0 The provider historically deployed IPv6 and assigned \u00a0 infrastructure addresses from a portion of the fc00::/7 prefix.\u00a0 They \u00a0 further subdivided the prefix into three /48 prefixes (Country X, \u00a0 Country Y, Country Z) to support their SRv6 infrastructure.\u00a0 From \u00a0 those /48 prefixes each router is assigned a /64 prefix from which \u00a0 all SIDs of that router are allocated. \u00a0 NEW: \u00a0 .....\u00a0 The provider historically deployed IPv6 and assigned \u00a0 infrastructure addresses from ULA space [ RFC 4193 ].\u00a0 They specifically \u00a0 allocated three /48 prefixes (Country X, Country Y, Country Z) to \u00a0 support their SRv6 infrastructure.\u00a0 From those /48 prefixes each router \u00a0 was assigned a /64 prefix from which all SIDs of that router are allocated. [ section 4.16.2 ] * I'm not sure I understand what the value of specifying USP is.\u00a0 This looks \u00a0 to me like an implementation detail and seems unnecessary.\u00a0 In all cases \u00a0 where the S03 code block is entered it's the processing of the remainder of \u00a0 the inner packet that's important, I would think. \u00a0 I guess, what's the value of specifying the way in which an implementation \u00a0 can begin to process the next header?\u00a0 Is this for chained SRHs and thus \u00a0 resubmitting the inner SRH to the same SID processing (8200 says that the \u00a0 RH 'should appear at most once', but that's as strong as the text gets)? [ section 4.16.3 ] * This too seems like an implementation detail, and it's not clear what it's \u00a0 adding to the document.\u00a0 But I must be misunderstanding something. [ section 7 ] * What flow label is included in hashing where End.DX4 is concerned?\u00a0 If \u00a0 it's the flow label of the outermost IPv6 header, then the same question \u00a0 comes to mind for End.X and End.DX6; I'd assumed it would be the inner \u00a0 packet's flow label (and src/dst addresses) that would factor into the \u00a0 flow hashing. [ section 8 ] * Of what value to the ingress node is knowledge of USP or USD behaviour \u00a0 at the terminus?\u00a0 That still seems like exposing an implementation detail.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-28 09:21:21-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-21 11:23:16-07:00",
    "text": "Section 3.1.\u00a0 (In case I missed it, please provide the obvious reference) Per \u201cIn such a case, the semantics and format of the ARG bits are defined as part of the SRv6 endpoint behavior specification\u201d, is \u201cendpoint behavior specification\u201d Section 4 or another document?\u00a0 If the former, I don\u2019t see any references to argument bits in the pseudo-code of the Section 4.* subsections.\u00a0 If the latter, what document?\u00a0 Can the behaviors be polymorphic (i.e., same network behavior accepting different arguments)?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-10-14 06:56:21-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-12 06:49:25-07:00",
    "text": "= Section 3.17 = \"An application sending ECN-capable datagrams MUST provide an \u00a0 \u00a0 \u00a0 appropriate congestion reaction when it receives feedback \u00a0 \u00a0 \u00a0 indicating that congestion has been experienced.\u00a0 This must result \u00a0 \u00a0 \u00a0 in reduction of the sending rate by the UDP congestion control \u00a0 \u00a0 \u00a0 method (see Section 3.1) that is not less than the reaction of TCP \u00a0 \u00a0 \u00a0 under equivalent conditions.\" \u00a0 \u00a0  Is the second \"must\" meant to be normative? If so, this worries me a bit.  RFC 6679  I believe retains flexibility for endpoints to react to congestion in ways that are different from TCP and dependent on specific codecs, topologies, and other factors.  RFC 3551  provides a lot of qualification in the requirements it places around equivalence to TCP's behavior. So I would be concerned about how this requirement, if normative, would affect RTP and other protocols. If it's not meant to be normative, I would suggest using \"ought to\" or some other word.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-04 13:17:44-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-29 12:40:12-08:00",
    "text": "This is a fairly minor point, but the text of Section 2.3 implies that there is a distinct list of identifier types that the server MAY use (and thus that there would be a protocol element to convey such an identifier type), but the actual schema in Section 4.1 is clear that the\u00a0 element is just a freeform token with some modest length restrictions (i.e., no place for internal structure).\u00a0 I'd like to hear from others on the IESG whether the text about the schema used being up to server policy is enough to make this clear, or we think there is some level of internal inconsistency in the document to be rectified.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-08 08:15:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-06-24 16:09:40-07:00",
    "text": "Thanks for the work on this! I have three points I'd like to discuss, all of which should be easy: \u2014 Section 3.8 \u2014 \u00a0  However, the following exception is permitted in the case where the \u00a0  candidate for an open position is currently a sitting member of the \u00a0  IAB.\u00a0 It is consistent with these rules for the announcements of a \u00a0  resignation of a sitting member of the IAB and of the confirmed \u00a0  candidate for the mid-term vacancy created by that sitting member on \u00a0  the IAB to all occur at the same time as long as the actual sequence \u00a0  of events that occurred did so in the following order: \u00a0  1.\u00a0 The NomCom completes the advice and consent process for the open \u00a0 \u00a0 \u00a0  position being filled by the candidate currently sitting on the \u00a0 \u00a0 \u00a0  IAB. \u00a0  2.\u00a0 The newly confirmed candidate resigns from their current position \u00a0 \u00a0 \u00a0  on the IAB. \u00a0  3.\u00a0 The IAB Chair (or the Managing Director, IETF Secretariat, if no \u00a0 \u00a0 \u00a0  Chair has been named or the vacancy was created via the departure \u00a0 \u00a0 \u00a0  of the IAB Chair) informs the NomCom of the mid-term vacancy. \u00a0  4.\u00a0 The NomCom acts on the request to fill the mid-term vacancy. Either I don\u2019t understand what this is saying or I don\u2019t understand how it\u2019s possible.\u00a0 Paraphrasing, the first paragraph says that it\u2019s OK for the announcement of the sitting IAB member\u2019s resignation to happen at the same time as the announcement of that member\u2019s confirmed replacement.\u00a0 That means that at the time of the resignation, the NomCom already had to have selected the replacement, given that selection to the confirming body, and had it confirmed.\u00a0 Which means that step 4 had to have happened before step 2, or at least before step 3, no? \u2014 Section 4.6 \u2014 \u00a0  Any such appointment must be temporary and does not absolve the Chair \u00a0  of any or all responsibility for ensuring the NomCom completes its \u00a0  assigned duties in a timely fashion. Then where does it say how to permanently replace a NomCom Chair who really does have to leave permanently (say, death or incapacity, unexpected family issues, or even just is no longer willing to do it)? \u2014 Section 4.10 \u2014 \u00a0  The prior year's Chair may select a designee from a pool composed of \u00a0  the voting volunteers of the prior year's committee and all prior \u00a0  Chairs if the Chair is unavailable.\u00a0 If the prior year's Chair is \u00a0  unavailable or is unable or unwilling to make such a designation in a \u00a0  timely fashion, the Chair of the current year's committee may select \u00a0  a designee in consultation with the Internet Society President. Why is it that the prior year\u2019s Chair can pick someone else on her own, but the current Chair has to consult with the ISOC President to do the same thing?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-09 12:22:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-08 08:15:06-07:00",
    "text": "I have one point I'd like to discuss, because think the text is unclear enough to cause problems if the issue comes up: \u2014 Section 3.8 \u2014 \u00a0  However, the following exception is permitted in the case where the \u00a0  candidate for an open position is currently a sitting member of the \u00a0  IAB.\u00a0 It is consistent with these rules for the announcements of a \u00a0  resignation of a sitting member of the IAB and of the confirmed \u00a0  candidate for the mid-term vacancy created by that sitting member on \u00a0  the IAB to all occur at the same time as long as the actual sequence \u00a0  of events that occurred did so in the following order: \u00a0  1.\u00a0 The NomCom completes the advice and consent process for the open \u00a0 \u00a0 \u00a0  position being filled by the candidate currently sitting on the \u00a0 \u00a0 \u00a0  IAB. \u00a0  2.\u00a0 The newly confirmed candidate resigns from their current position \u00a0 \u00a0 \u00a0  on the IAB. \u00a0  3.\u00a0 The IAB Chair (or the Managing Director, IETF Secretariat, if no \u00a0 \u00a0 \u00a0  Chair has been named or the vacancy was created via the departure \u00a0 \u00a0 \u00a0  of the IAB Chair) informs the NomCom of the mid-term vacancy. \u00a0  4.\u00a0 The NomCom acts on the request to fill the mid-term vacancy. Either I don\u2019t understand what this is saying or I don\u2019t understand how it\u2019s possible.\u00a0 Paraphrasing, the first paragraph says that it\u2019s OK for the announcement of the sitting IAB member\u2019s resignation to happen at the same time as the announcement of that member\u2019s confirmed replacement.\u00a0 That means that at the time of the resignation, the NomCom already had to have selected the replacement, given that selection to the confirming body, and had it confirmed.\u00a0 Which means that step 4 had to have happened before step 2, or at least before step 3, no?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-07-07 05:20:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-04 08:38:08-07:00",
    "text": "Don't panic - these should be trivial DISCUSSes to address, either by fixing the text, or swatting me with a clue-by-four. I'm apologize that some of these might be pedantic, but I think that this is an important document to get right and make as clear as possible.  D1: 4.17.\u00a0 Announcement of Selection Results \"If a selected volunteer, upon reading the announcement with the list \u00a0  of selected volunteers, finds that two or more other volunteers have \u00a0  the same affiliation, then the volunteer should notify the Chair who \u00a0  will determine the appropriate action.\" Why is this limited (\"If a selected volunteer...\")? What if someone else notices it? (as an example, the chair notices that they messed up during the previous step?) D2: 6.\u00a0 Dispute Resolution Process \" 4.\u00a0 After consultation with the two principal parties to the issue, the arbiter decides on a resolution.\" Can this be changed to \"After consultation with the principal parties...\"? Disputes get messy and I don't see what specifying \"two\" adds here.  D3: :7.6.\u00a0 3/4 Majority \u00a0  \"A 3/4 majority of the members who vote on the question is required\u00a0 for a recall.\" \"3/4 majority of the members who vote\", or \"eligible voting members\"? If only one person actually casts their vote does that equal 100%?  I'm perfectly fine if that is the intent, just wanted to make sure I'm reading it correctly. I personally feel that everyone should be expected to vote on this - I dislike the idea that people can abstain from voting because they don't want to get their hands dirty, and instead wait for one of their colleagues to stand up and make the hard decision. I also realize that this is already covered in the general confidentiality discussions, but I suspect that there is / will be more drama and intrigue around recalls - might it be worth reiterating that voting is confidential and / or should they be secret ballots? I really don't want anyone to feel uncomfortable voting to recall someone because they fear repercussions....",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-12 10:47:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 13:48:05-08:00",
    "text": "Hello, Thanks for your work on this draft.\u00a0 It appears an older version of the Security Considerations template was used.\u00a0 Could you please update to the current version that adds in transport security and other considerations?\u00a0 I believe this is the latest version, but Benoit can confirm. https://tools.ietf.org/html/draft-ietf-netmod-rfc6087bis-10#page-52",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-03-30 15:52:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 21:15:01-07:00",
    "text": "[ general ] * ND in IPv6 is more than just its analogous ARP function (as immediately \u00a0 evidenced by the need to support passing the NA flags).\u00a0 I'm concerned that \u00a0 this approach isn't actually satisfactory for IPv6, and could end up \u00a0 constraining existing and future ND extensions and uses. \u00a0 [1] New flags \u00a0 As new flags are defined in the NA message, they will not be deployable \u00a0 in these environments until this standard (and possibly others) is updated. \u00a0 A more forward-compatible option might be to just include the whole NA \u00a0 \"flags plus reserved\" word (there is room for it in the format in \u00a0 section 2). \u00a0 [2] Current and new NA ND Options \u00a0 This approach doesn't support sending additional ND Options in the NA, and \u00a0 therefore things like Secure Neighbor Discovery (SeND,  RFC 3971 ) cannot \u00a0 be supported (nor can any future NA option). \u00a0 Arguably, ND proxying might best be disabled when a node is attempting to \u00a0 use SeND and/or whenever a Nonce Option is present an NA.\u00a0 Nevertheless, \u00a0 new ND options might be specified that can be carried in NS/NA messages. \u00a0  RFC 4861  sections 4.2 and 4.3 say that \"[f]uture versions of this protocol \u00a0 may define new option types\", and while it also says that \"[r]eceivers \u00a0 MUST silently ignore any options they do not recognize and continue \u00a0 processing the message\", in this case it would be the infrastructure that \u00a0 would prevent two nodes from attempting to use a newer ND option on either \u00a0 side of this PE/CE proxying boundary and not necessarily a limitation of the \u00a0 nodes themselves. \u00a0 There is no space for these options in the current section 2 format. \u00a0 Can it be extended to optionally carry the ND options that a PE has \u00a0 observed to be sent by the node? \u00a0 Alternatively, I think we'll need some text that ND proxying MUST be \u00a0 disabled if NSes contain any options other things like TLLAO or if NAs are \u00a0 observed to have anything other than SLLAO. \u00a0 Basically, I think we should take care to not impede the deployment of any \u00a0 extensions to ND.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-12-01 03:24:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 13:44:00-07:00",
    "text": "Hi, Hopefully a relatively easy discuss to resolve and this might just be my ignorance here: Section 2 states that I flag is used for an immutable ARP/ND Binding which is for a configured ARP/ND entry. Section 3.2 Reception of the EVPN ARP/ND Extended Community, has the following text: \u00a0 \u00a0 \u00a0 *\u00a0 Receiving multiple EVPN MAC/IP Advertisement routes with I=1 \u00a0 \u00a0 \u00a0 \u00a0  for the same IP but different MAC is considered a \u00a0 \u00a0 \u00a0 \u00a0  misconfiguration. But wouldn't this scenario occur if the configured ARP/ND entry was changed to point to a new MAC address? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-10-12 07:37:38-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 09:16:59-07:00",
    "text": "Be ye not afraid! This DISCUSS should be fairly trivial to address... This allows for more information to be carried with MAC/IP Advertisements. It seems to me that this gives a DoS-style attacker more opportunities to exhaust state on routers - I could sit on a wire and create lots of ARP/ND states (make up new IP and MAC combinations), causing this to be propagated and burning memory / state / etc. This is somewhat discussed in  RFC 7432 , but the technique in this document seems like it makes this issue somewhat worse - a single sentence in the Security Considerations noting it would satisfy me (as would an explanation that I'm mistaken :-)). I also support EK & Rob's DISCUSSes",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-15 07:50:37-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 23:17:01-08:00",
    "text": "We can probably sort this out during the IESG telechat, but I want to be sure it's flagged. A number of the shepherd writeup questions were hastily answered and the information we need is largely missing.\u00a0 For instance: -- > What type of RFC publication is being requested on the IETF stream (Best > Current Practice, Proposed Standard, Internet Standard, > Informational, Experimental or Historic)? Why is this the proper type > of RFC? Do all Datatracker state attributes correctly reflect this intent? yes. -- There are three questions here, and only the last of them can be answered \"yes\".\u00a0 The second one is the most interesting one. -- > Several IETF Areas have assembled lists of common issues that their > reviewers encounter. For which areas have such issues been identified > and addressed? For which does this still need to happen in subsequent > reviews? no. -- I don't understand. -- > Have reasonable efforts been made to remind all authors of the intellectual > property rights (IPR) disclosure obligations described in  BCP 79 ? To > the best of your knowledge, have all required disclosures been filed? If > not, explain why. If yes, summarize any relevant discussion, including links > to publicly-available messages when applicable. yes. -- So something's been filed, or reasonable reminders were sent?\u00a0 If the former, where's the discussion or what was its result?\u00a0 According to the Last Call text, there was one filing.\u00a0 Was it discussed?\u00a0 Is it a source of concern?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-01-03 11:36:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 06:27:36-08:00",
    "text": " ** Section 2. health score.\u00a0 The definition of a health score defined here (0 to 100) is inconsistent with Section 3.2 and the YANG definition in  draft-ietf-opsawg-service-assurance-yang  which uses -1 to 100.\u00a0 Given the shepherd\u2019s write-up for the -yang document says that this (changing from 0..100 to -1..100) was a last-minute addition, it seems that perhaps this document hasn\u2019t caught up. ** Section 4. However, the SAIN agents must be \u00a0  secured: a compromised SAIN agent may be sending wrong root causes or \u00a0  symptoms to the management systems.\u00a0 This can be partially achieved \u00a0  by correctly setting permissions of each node in the YANG model as \u00a0  described in the companion document \u00a0  [ I-D.ietf-opsawg-service-assurance-yang ] -- Can a more specific section reference be provided into the  draft-ietf-opsawg-service-assurance-yang  on this configuration? -- what does it mean to \u201csecure\u201d the SAIN agent and how is this related to a YANG configuration.\u00a0 Isn\u2019t the agent either a running process on the device or a system/process on another system harvesting information (metrics)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-22 21:18:33-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 22:39:44-07:00",
    "text": "I support Roman's Discuss. I think I'm confused about whether REQUESTED-ADDRESS-FAMILY and ADDITIONAL-ADDRESS-FAMILY are mutually exclusive.\u00a0 Does sending just the \"additional\" one secretly mean that you want both v4 and v6? Section 5 I see that the secdir reviewer asked about why it is a \"SHOULD\" to send SOFTWARE, and only got a response that it is defined in stunbis, but not about why it is recommended.\u00a0 There remain some privacy/security considerations with it, and we should either point to the stunbis security considerations or not recommend using it.\u00a0 (FINGERPRINT is, IIRC, less interesting from a security perspective as it's just about confirming that given traffic is in fact STUN and not something else.) Section 12 Do we need to say anything about backwards compatibility with  RFC 5766 peers that use a wider range of channel IDs? Section 12.7 \u00a0  When the server receives an ICMP packet, the server processes it as \u00a0  described in Section 11.5.\u00a0 A Data indication MUST be sent regardless \u00a0  of whether there is a channel bound to the peer that was the \u00a0  destination of the UDP datagram that triggered the reception of the \u00a0  ICMP packet. This MUST seems potentially in conflict with the previous discussion about permissions checks in Section 11.5. Section 20 Looking at the new nonce in the example (\"obMatJos2AAABadl7W7PeDU4hKE72jda\"), and noting that it starts with the nonce cookie, help me decode the security feature bits.\u00a0 The magic prefix is \"obMatJos2\" so the capability bits are encoded as \"AAAB\", which decodes to (hex) 00 00 01.\u00a0 But stunbis says that the bits are ordered from 0 (MSB of first byte) to 23 (LSB of last byte), so this would have bit 23 set, which is in contrast to the registry marking bit 0 as the password-algorithms feature.\u00a0 Where am I messing this up? I'd prefer if the examples showed more usage of MESSAGE-INTEGRITY-SHA256 (especially, any from the server) and fewer MESSAGE-INTEGRITY.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-26 15:05:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 08:55:04-07:00",
    "text": "One quick discussion which probably is only an oversight and therefore should be easy got fix: I'm bit confused about the requirement on using authentication. This draft says in section 5 (as  RFC5766  does): \"The server MUST demand that all requests \u00a0  from the client be authenticated using this mechanism, or that a \u00a0  equally strong or stronger mechanism for client authentication is \u00a0  used.\" However,  RFC 8155  which is even now cited in this draft, updates  RFC5766  and relaxes this requirement. Later in the section 7.2. this draft says: \"The server SHOULD require that the request be authenticated.\" I assume the requirement in section 5 is an oversight?  I also recommend to only specify this requirement normatively in one place.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-10 15:49:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 15:40:00-07:00",
    "text": "(1) Section 12.1.6.\u00a0 (Per the back-and-forth on Chris Wood\u2019s SECDIR review \u2013 thank you Chris!) Per \u201cConfidentiality is only a secondary concern, as TURN control messages do not include information that is particularly sensitive\u201d, wouldn\u2019t the USERNAME and REALM potentially be privacy sensitive?\u00a0 If they aren\u2019t sensitive in all cases (e.g., usernames might be ephemeral), this should be noted and cited. (2) This draft relies on the  draft-ietf-tram-stunbis \u2019s STUN Password Algo Registry which (in Section 16.1.1) already discusses the limitation of SHA-256.\u00a0 Nevertheless, it is still better than MD5 which is still supported too.\u00a0 Is there a reason not to recommend that implementation \u201cSHOULD NOT use MD5\u201d?\u00a0 Also, it seems helpful to reference the caveats about SHA-256 for password hashing from  draft-ietf-tram-stunbis  here too.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-22 05:12:59-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 15:49:17-07:00",
    "text": "(1) Section 12.1.6.\u00a0 (Per the back-and-forth on Chris Wood\u2019s SECDIR review \u2013 thank you Chris!) Per \u201cConfidentiality is only a secondary concern, as TURN control messages do not include information that is particularly sensitive\u201d, wouldn\u2019t the USERNAME and REALM potentially be privacy sensitive?\u00a0 If they aren\u2019t sensitive in all cases (e.g., usernames might be ephemeral), this should be noted and cited.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-05-03 10:32:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-05-02 10:04:11-07:00",
    "text": "I'm wondering a few things that I think are important to discuss.\u00a0 If this is all fine, I may have more comments as I think I'll need to dig into the BGPsec draft first and then this one again. 1.\u00a0 Why is this document preceding the BGP spec?\u00a0 Shouldn't this be part of the BGPSec protocol document?\u00a0 If BGPSec isn't getting deployed because of the AS path migration problem and this gets us a little further, but not quite as secure, maybe that's a trade off we need to accept.\u00a0 But this document coming through first is a little concerning even though the protocol spec is a normative reference.  2.\u00a0 The introduction makes this sound rather innocuous, but the security considerations section is more explicit that this is a work around BGPSec and isn't quite as secure.\u00a0 I'd like to see some text explaining this better in the introduction, more similar to what's in the first paragraph of the security considerations section. Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-01-04 13:51:22-08:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 10:32:06-07:00",
    "text": "I'm wondering a few things that I think are important to discuss.\u00a0 If this is all fine, I may have more comments as I think I'll need to dig into the BGPsec draft first and then this one again. 1.\u00a0 Why is this document preceding the BGP spec?\u00a0 Shouldn't this be part of the BGPSec protocol document?\u00a0 If BGPSec isn't getting deployed because of the AS path migration problem and this gets us a little further, but not quite as secure, maybe that's a trade off we need to accept.\u00a0 But this document coming through first is a little concerning even though the protocol spec is a normative reference.  2.\u00a0 The introduction makes this sound rather innocuous, but the security considerations section is more explicit that this is a work around BGPSec and isn't quite as secure.\u00a0 I'd like to see some text explaining this better in the introduction, more similar to what's in the first paragraph of the security considerations section.\u00a0 See comments below too with some text.\u00a0 Sandy said she was working on this section as well, thanks for that! Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-11-07 20:27:30-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-09 20:10:50-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3506 DETAIL S 4. >\u00a0   >\u00a0 \u00a0 \u00a0 It is worth emphasizing that the nodes specified in >\u00a0 \u00a0 \u00a0 \"parent-reference\" leaf-list are available in the mounted schema only >\u00a0 \u00a0 \u00a0 for XPath evaluations.\u00a0 In particular, they cannot be accessed there >\u00a0 \u00a0 \u00a0 via network management protocols such as NETCONF [ RFC6241 ] or >\u00a0 \u00a0 \u00a0 RESTCONF [ RFC8040 ]. What are the security implications of this XPath reference outside the mount jail? Specifically, how does it interact with the access control for the enclosing module.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2015-10-19 05:41:24-07:00",
    "end_reason": "position_updated",
    "start": "2015-10-13 07:20:25-07:00",
    "text": "Section 3.2. (Elements of procedure) says that the \"interpretation of tag values is specific to the administrative domain of a particular network operator\", which makes them opaque and obviously locally significant.\u00a0 I then have an issue with the following text, which tries to (using  rfc2119  keywords) specify how to interpret the tags, which doesn't make sense to me given the text above: \u00a0  Each tag MUST be treated as an independent identifier that MAY be \u00a0  used in policy to perform a policy action.\u00a0 Tags carried by the \u00a0  administrative tag TLV SHOULD be used to indicate independent \u00a0  characteristics of a node.\u00a0 The administrative tag list within the \u00a0  TLV MUST be considered an unordered list.\u00a0 Whilst policies may be \u00a0  implemented based on the presence of multiple tags (e.g., if tag A \u00a0  AND tag B are present), they MUST NOT be reliant upon the order of \u00a0  the tags (i.e., all policies should be considered commutative \u00a0  operations, such that tag A preceding or following tag B does not \u00a0  change their outcome). \u00a0  To avoid incomplete or inconsistent interpretations of the per-node \u00a0  administrative tags the same tag value MUST NOT be advertised by a \u00a0  router in RI LSAs of different scopes.\u00a0 The same tag MAY be \u00a0  advertised in multiple RI LSAs of the same scope, for example, OSPF \u00a0  Area Border Router (ABR) may advertise the same tag in area-scope RI \u00a0  LSAs in multiple areas connected to the ABR. . . . \u00a0  Being part of the RI LSA, the per-node administrative tag TLV must be \u00a0  reasonably small and stable.\u00a0 In particular, but not limited to, \u00a0  implementations supporting the per-node administrative tags MUST NOT \u00a0  tie advertised tags to changes in the network topology (both within \u00a0  and outside the OSPF domain) or reachability of routes. . . . \u00a0  instances of the RI LSA.\u00a0 The node administrative tags associated \u00a0  with a node that originates tags for the purpose of any computation \u00a0  or processing at a receiving node SHOULD be a superset of node \u00a0  administrative tags from all the TLVs in all the received RI LSA \u00a0  instances originated by that node.When an RI LSA is received that \u00a0  changes the set of tags applicable to any originating node, a \u00a0  receiving node MUST repeat any computation or processing that is \u00a0  based on those administrative tags. If the tags are opaque, I don't think that anything can be mandated as to how they are interpreted or what they're used for.\u00a0 That is the point I want to talk about with this DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-10-07 03:47:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-05 17:51:33-07:00",
    "text": "I am balloting DISCUSS because I believe that the behavior specified in this document is not clear enough.\u00a0 I think these points should be easy to address. (1) The main behavior in this document (using the reverse metric) is covered in the following sentences: \u00a76: \u00a0  A router receiving a Hello packet from its neighbor that contains the \u00a0  Reverse Metric TLV on a link SHOULD use the RM value to derive the \u00a0  metric for the link to the advertising router in its Router-LSA... \u00a0  ... \u00a0  The neighbor SHOULD use the reverse TE metric value... \u00a77: \u00a0  Implementations SHOULD NOT accept the RM from its neighbors by default  \u00a0  and SHOULD provide a configuration option to enable the acceptance of  \u00a0  the RM from neighbors on specific links. For all cases, why is this behavior recommended and not required?\u00a0 When is it ok to not use the RM, or to accept it by default? (2) \u00a76: \u00a0  A router stops including the Reverse Metric TLV in its Hello packets \u00a0  when it needs its neighbors to go back to using their own provisioned \u00a0  metric values.\u00a0 When this happens, a router that had modified its \u00a0  metric in response to receiving a Reverse Metric TLV from its \u00a0  neighbor should revert to using its provisioned metric value. No normative language is used here -- should there be a SHOULD/MUST there? Even if \"should revert\" is used, the behavior is unclear and could be interpreted as not required.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-10-06 16:52:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-10-05 17:26:45-07:00",
    "text": "I hope this is a quick one. A naive reading of Sec 2.2 implies that a router could generate reverse-metric TLVs quite rapidly, triggering a storm of TLVs from a potentially large number of neighbors. Each reverse metric advertisement generates N LSAs, increasing the amplification of any sort of misconfiguration or misbehavior far more than a traditional LSAs that is updated too often. At the very least, this ought to come up in security considerations, but I wonder if applying some sort of rate limit (beyond which neighbors are free to ignore) would be a firmer way of limiting the problem. I'm flexible on the best way forward.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-10-06 16:53:25-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-06 16:52:41-07:00",
    "text": "hanks for handling my DISCUSS.I believe you are still working out the details with Alvaro, but I am satisfied.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-10-10 06:53:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-06 03:50:41-07:00",
    "text": "Thanks for this document. I support Alvaro's discuss.\u00a0 Having read Alvaro's discuss after writing my ballot comments it seems to be some what closely related, but I am also balloting discuss because I find the operational guidelines to be unclear. (1) p 8, sec 7.\u00a0 Operational Guidelines\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  Implementations MUST NOT signal reverse metric to neighbors by\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0  default and MUST provide a configuration option to enable the\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  signaling of reverse metric on specific links.\u00a0 Implementations\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  SHOULD NOT accept the RM from its neighbors by default and SHOULD\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  provide a configuration option to enable the acceptance of the RM\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  from neighbors on specific links.\u00a0 This is to safeguard against\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  inadvertent use of RM.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   I'm not really sure that I properly understand how this feature works from a manageability perspective.\u00a0 Particularly for your first use case, when considering that the proposal is for per link configuration for the acceptance of RM from neighbours.\u00a0 This would seem to suggest that before you can make use of reverse-metric you have to already have determined the links on the affected devices to then configure them to accept the reverse-metrics, at which point, doesn't this partially defeat the use case?\u00a0 Or is the main goal to simplify the coordination of changing the metric at both ends of the link at the same time?\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   Or is the intention that during the maintenance window the operators would enable the \"allow receipt of reverse-metrics\" on all links within, say, an area?\u00a0 If so, would hierarchical device and area specific configuration be more appropriate?\u00a0 E.g., allow it to be enabled/disbaled on individual links, but also allow more coarse grained configuration. Not as an update for this document, but I am assuming that the LSR working group with eventually update or augment the OSPF YANG module with standard configuration to support this feature. (2) p 8, sec 7.\u00a0 Operational Guidelines \u00a0  For the use case in Section 2.1, it is RECOMMENDED that the network \u00a0  operator limits the period of enablement of the reverse metric \u00a0  mechanism to be only the duration of a network maintenance window. Presumably this isn't feasible when the CE is not managed by the provider?\u00a0 In this scenario, is the expectation that the configuration to accept reverse-metrics would just be left always enabled on the CE device?\u00a0 Is this a security concern? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-09-22 20:33:55-07:00",
    "text": "Many thanks for taking on the task of producing a roll-up update for the core TCP specification!\u00a0 I am sure it was a lot of work, but I am happy to see it done. That said, I do have a few points that I would like to have a bit more discussion on before the document is published; I'm happy to see that Warren already linked to https://www.ietf.org/blog/handling-iesg-ballot-positions/  on the topic of what a DISCUSS position can (and cannot) mean. (1) We incorporate some long-standing enhancements that improve the security and robustness of TCP (in particular, random ISN and protection against off-path in-window attacks come to mind), but only at SHOULD or MAY requirements level. For example, we currently say: \u00a0  A TCP implementation MUST use the above type of \"clock\" for clock- \u00a0  driven selection of initial sequence numbers (MUST-8), and SHOULD \u00a0  generate its Initial Sequence Numbers with the expression: \u00a0  ISN = M + F(localip, localport, remoteip, remoteport, secretkey) and: \u00a0 \u00a0 \u00a0 \u00a0  +\u00a0  RFC 5961  [37] section 5 describes a potential blind data \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 injection attack, and mitigation that implementations MAY \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 choose to include (MAY-12).\u00a0 TCP stacks that implement \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  RFC 5961  MUST add an input check that the ACK value is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [...] What prevents us from making a MUST-level requirement for randomized ISNs?\u00a0 Is it just the fact that it was only a SHOULD in  RFC 6528  and a perception that promoting to a MUST would be incompatible with retaining Internet Standard status? Likewise, what prevents using stronger normative language (e.g., MUST) for the  RFC 5961  protections? It seems to me that these mechanisms are of general applicability and provide significant value for use of TCP on the internet, even though they are not fully robust and do not use cryptographic mechanisms.\u00a0 If there are scenarios where their use is harmful or even just not applicable, that seems like an exceptional case that should get documented so as to strengthen the general recommendation for the non-exception cases. (2) I think this is just a process question to ensure that the IESG knows what we are approving at Internet Standard maturity, though it is certainly possible that I misunderstand the situation. In Section 3.7.3 we see the normative statement (SHLD-6) that \"when the when the effective MTU of an interface varies packet-to- packet, TCP implementations SHOULD use the smallest effective MTU of the interface to calculate the value to advertise in the MSS option\".\u00a0 This seems to originate in  RFC 6691  (being obsoleted by this document), but  RFC 6691 is only an Informational document and has not had an opportunity to \"accumulate experience at Proposed Standard before progressing\", to paraphrase  RFC 6410 . Similarly, Section 3.9.2 has (SHLD-23) \"Generally, an application SHOULD NOT change the DiffServ field value during the course of a connection (SHLD-23).\"\u00a0 This is a bit harder to track down, as the DiffServ field was not always known by that name.\u00a0 I actually failed to find a directly analogous previous statement of this guidance (presumably my error), and thus don't know if it had any experience at the PS level or not. RFC 6410  seems pretty clear that some revisions are okay in Internet Standards without such \"bake time\" at PS, but it does seem like something that should be done consciously rather than by accident. (3) This is also a process point for explicit consideration by the IESG. Appendix A.2 appears to discuss a few (rare) scenarios in which the technical mechanisms of this document fail catastrophically (e.g., getting stuck in a SYN|ACK loop and failing to complete the handshake). Does this meet the \"resolved known design choices\" and \"no known technical omission\" bar required by  RFC 2026  even for *proposed* standard? (Note that  RFC 2026  explicitly says that the IESG may waive this requirement, at least for PS.) (AFAICT one such scenario is reported at https://www.rfc-editor.org/errata_search.php?eid=3305  , which the change log for this document calls out as \"not applicable due to other changes\"; I am not sure which \"other changes\" are intended, for this case.) (4) Another point mostly just to get explicit IESG acknowledgment (elevating one of Lars' comments to DISCUSS level, essentially). As the changelog (and gen-art reviewer!) notes: \u00a0  Early in the process of updating  RFC 793 , Scott Brim mentioned that \u00a0  this should include a PERPASS/privacy review.\u00a0 This may be something \u00a0  for the chairs or AD to request during WGLC or IETF LC. I don't see any evidence to suggest that such a review actually occurred.\u00a0 Do we want to seek out such a targeted review before progressing?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-11 02:46:18-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-20 07:18:33-07:00",
    "text": "The IESG needs to approve the following DOWNREFs during the telechat: \u00a0 DOWNREF [10] from this Internet Standard to Proposed Standard  RFC6298 . \u00a0 DOWNREF [2] from this Internet Standard to Draft Standard  RFC1191 . \u00a0 DOWNREF [7] from this Internet Standard to Proposed Standard  RFC3168 . \u00a0 DOWNREF [11] from this Internet Standard to Proposed Standard  RFC6633 . \u00a0 DOWNREF [9] from this Internet Standard to Draft Standard  RFC5681 . \u00a0 DOWNREF [5] from this Internet Standard to Proposed Standard  RFC2675 . \u00a0 DOWNREF [4] from this Internet Standard to Proposed Standard  RFC2474 .",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-09-22 15:52:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-09-22 15:51:13-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-12-16 10:32:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 15:52:37-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS, because I think that it is important enough that it needs addressing: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-02-17 06:37:48-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 13:45:17-07:00",
    "text": "* I found at least one reference that should be normative reference but they are not. Section 3.8.5 : describes -- \u00a0   \u00a0 \u00a0 TCP implementations MUST still include support for the urgent mechanism (MUST-30). Details can be found in  RFC 6093  [38] \u00a0  \u00a0 This to ne makes  RFC6093  a must to read and understand to deploy this specification. Hence it should in the normative references. * (This perhaps more process thing than technical), me and Benjamin Kaduk discussed another issue regarding urgent pointer. This specification specifies - \u00a0 \u00a0 \u00a0  Pointer indicates first non-urgent octet\u00a0 \u00a0 \u00a0  | MUST-62|  \u00a0  \u00a0  RFC1011  rectifies  RFC973  to - \u00a0 \u00a0 \u00a0 The urgent pointer points to the \u00a0 \u00a0 \u00a0 \u00a0  last octet of urgent data (not to the first octet of non-urgent \u00a0 \u00a0 \u00a0 \u00a0  data). \u00a0 So what does happen to  RFC1011  rectification then when 793bis is not bis anymore? Is this a known fact and there is conscious decision not to do anything about it? or was this a unknown fact and that part of  RFC1011  need to be obsoleted (how?)?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-26 09:11:21-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-07 06:58:03-08:00",
    "text": "As per IANA: The IANA Considerations section needs to mention the registration procedure for the new registry. I also agree (at least) with comments raised by Adam, they are similar to what I raised in my own review. Some of them need fixes (e.g. to text or examples).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-29 09:28:23-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-26 09:11:21-07:00",
    "text": "Thank you for addressing earlier comments, including comments from Adam. The media type registration: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"application/x-x509-ca-cert\"\t  \t\u00a0  \"application/x-x509-ca-ra-cert\"\t  \t\u00a0  \"application/x-x509-next-ca-cert\"\t  \t\u00a0  \"application/x-pki-message\" These still need registration templates, even if they are grandfathered.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-08 13:00:37-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-06 21:05:08-08:00",
    "text": "Thanks for this easy-to-read document! I have a fairly silly point, where the behavior seems to still be underspecified: Section 4.4 says that an error-handling path should \"ignore this request\"; does that mean that it should terminate the underlying connection over which HTTP is running?\u00a0 Return an HTTP error?\u00a0 Keep the connection open until the peer times out?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-02-07 06:34:16-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3890 I have not had time to give this as thorough a read as I would like, and would feel necessary were we advancing it at PS, so I am not confident in its security properties. I have nevertheless noted a number of issues that I think merit a DISCUSS. DETAIL S 2.3. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 then a locally generated self-signed certificate MUST be used. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 The keyUsage extension in the certificate MUST indicate that it >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 is valid for digitalSignature and keyEncipherment (if available). >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 The self-signed certificate SHOULD use the same subject name as >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 in the PKCS #10 request.\u00a0 In this case the messageType is PKCSReq >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (see Section 3.2.1.2). Should it use the same *key* as the PKCS#10 request? S 2.3. >\u00a0   >\u00a0 \u00a0 \u00a0 Note that although the above text describes several different types >\u00a0 \u00a0 \u00a0 of operations, in practice most implementations always apply the >\u00a0 \u00a0 \u00a0 first one even if an existing certificate already exists.\u00a0 For this >\u00a0 \u00a0 \u00a0 reason support for the first case is mandatory while support for the >\u00a0 \u00a0 \u00a0 latter ones are optional (see Section 2.9). we probably shouldn't have a SHOULD for something we know people don't do, especially in an Info document. S 2.5. >\u00a0 \u00a0 \u00a0 using CMS (Section 3). >\u00a0   >\u00a0 \u00a0 \u00a0 If the CA supports certificate renewal and if the CA policy permits >\u00a0 \u00a0 \u00a0 then a new certificate with new validity dates can be issued even >\u00a0 \u00a0 \u00a0 though the old one is still valid.\u00a0 The CA MAY automatically revoke >\u00a0 \u00a0 \u00a0 the old client certificate.\u00a0 To renew an existing certificate, the Is this sentence about automatically revoking related to the previous one? I.e., can I revoke the old certificate if the new one is not yet valid? That would seem unwise. S 3. >\u00a0 \u00a0 \u00a0 confidentiality use two layers of CMS, as shown in Figure 2.\u00a0 By >\u00a0 \u00a0 \u00a0 applying both enveloping and signing transformations, the SCEP >\u00a0 \u00a0 \u00a0 message is protected both for the integrity of its end-to-end >\u00a0 \u00a0 \u00a0 transaction information and the confidentiality of its information >\u00a0 \u00a0 \u00a0 portion.\u00a0 Some messages do not require enveloping, in which case the >\u00a0 \u00a0 \u00a0 EnvelopedData in Figure 2 is omitted. I want to make sure I understand which messages *do* require enveloping. I would assume PKSReq, at least if it includes the challenge password, right? Maybe I'm missing it, but i don't see a clear statement anywhere. S 3.1. >\u00a0 \u00a0 \u00a0 the recipient's public key.\u00a0 If the key is encryption-capable (for >\u00a0 \u00a0 \u00a0 example RSA) then the messageData is encrypted using the recipient's >\u00a0 \u00a0 \u00a0 public key with the CMS KeyTransRecipientInfo mechanism.\u00a0 If the key >\u00a0 \u00a0 \u00a0 is not encryption-capable (for example DSA or ECDSA) then the >\u00a0 \u00a0 \u00a0 messageData is encrypted using the challengePassword with the CMS >\u00a0 \u00a0 \u00a0 PasswordRecipientInfo mechanism. This requires a very strong ChallengePassword, which I don't see you saying anywhere. S 3.1. >\u00a0 \u00a0 \u00a0 Note that some earlier implementations of this specification dealt >\u00a0 \u00a0 \u00a0 with non-encryption-capable keys by omitting the encryption stage, >\u00a0 \u00a0 \u00a0 based on the text in Section 3 that indicated that \"the EnvelopedData >\u00a0 \u00a0 \u00a0 is omitted\".\u00a0 This alternative processing mechanism SHOULD NOT be >\u00a0 \u00a0 \u00a0 used since it exposes the challengePassword used to authorise the >\u00a0 \u00a0 \u00a0 certificate issue. Why is this not a MUST? S 8.3. >\u00a0   >\u00a0 \u00a0 \u00a0 The challengePassword sent in the PKCS #10 enrolment request is >\u00a0 \u00a0 \u00a0 signed and encrypted by way of being encapsulated in a pkiMessage. >\u00a0 \u00a0 \u00a0 When saved by the CA, care should be taken to protect this password, >\u00a0 \u00a0 \u00a0 for example by storing a salted iterated hash of the password rather >\u00a0 \u00a0 \u00a0 than the password itself. this won't work if you are using it for encryption. S 8.7. >\u00a0 \u00a0 \u00a0 is public and thus encrypting the requests is of questionable value. >\u00a0 \u00a0 \u00a0 In addition CRLs and certificates sent in responses are already >\u00a0 \u00a0 \u00a0 signed by the CA and can be verified by the recipient without >\u00a0 \u00a0 \u00a0 requiring additional signing and encryption.\u00a0 More lightweight means >\u00a0 \u00a0 \u00a0 of retrieving certificates and CRLs such as HTTP certificate-store >\u00a0 \u00a0 \u00a0 access [13] and LDAP are recommended for this reason. This statement appears to directly cut against  RFC 7258 , which establishes the IETF consensus that we should be considering disclosure of metadata and its impact on pervasive monitoring. A protocol which claims to have IETF consensus should not take the opposite position. In addition to this, the claim that certificates are inherently public is in fact not universally true, as discussions about redaction in CT demonstrate. Moreover, the fact that a given endpoint has given certificate is not public. S 8.8. >\u00a0 \u00a0 \u00a0 default to SHA-1, with many supporting only that hash algorithm with >\u00a0 \u00a0 \u00a0 no ability to upgrade to a newer one.\u00a0 SHA-1 is no longer regarded as >\u00a0 \u00a0 \u00a0 secure in all situations, but as used in SCEP it's still safe.\u00a0 There >\u00a0 \u00a0 \u00a0 are three reasons for this.\u00a0 The first is that attacking SCEP would >\u00a0 \u00a0 \u00a0 require creating a SHA-1 collision in close to real time, which won't >\u00a0 \u00a0 \u00a0 be feasible for a very long time. I don't believe that this statement reflects the consensus of the cryptographic community and it's also not clear to me that the requirement for real-time is correct without quite a bit more analysis.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-08 05:16:32-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-06 05:36:16-08:00",
    "text": "Given the purpose of this document is to describe a deployed protocol that however is not recommended by the IETF community for new deployments anymore, the IESG should discuss if this document should be published as Historic.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-09 03:27:06-08:00",
    "end_reason": "position_updated",
    "start": "2015-09-01 05:49:40-07:00",
    "text": "(1) For a 99 page detailed specification, the security considerations are tremendously brief.\u00a0 There are two non-boilerplate paragraphs - one says developers \"MUST exercise caution\" (meaning what precisely?) and the other extolls the virtues of not encrypting. For a 99 page specification of a highly non-trivial encoding scheme, I would have expected to see the results of a better analysis. Was that analysis done? That should at least include consideration of the CVEs already published relating to H.264 [1] which include 34 CVEs relating to various kinds of remote-code-execution and DoS. If the authors here are asserting that this presumably more complex codec will have few vulnerabilities, then I would welcome seeing the justification for that statement. (Note: In some cases with payload drafts, authors can fairly claim that the I-D does not describe the payload in detail and hence that the security considerations text need not be comprehensive as implementers are expected to find that elsewhere. In this case, the 99 pages strongly argues otherwise IMO - there are plenty of ways to go badly wrong implementing what is stated in this draft.) To summarise: \"MUST exercise caution\" is not useful, can't you translate that into actionable advice to an implementer based on experience with security issues found with this and similar codecs? \u00a0  [1]  https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=h.264 (2) This is just a process nit probably. The shepherd write-up doesn't mention the Nokia IPR declaration.\u00a0 Were the WG also ok with that one? The write-up seems to pre-date that latest IPR declaration, which is from a company that seems to employ one of the authors. That is odd timing really so can someone explain the sequence of events and why all is well?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-04 08:20:07-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-02-15 11:10:41-08:00",
    "text": "Section 7 points to [ICANN-TMCH] for signature validation policy (I think, not quite sure). I did a quick scan (so I might have missed it) of that document and did not find any mention of security or signature validation, so what is an implementer supposed to do, over and above just checking the cryptographic correctness of the XMLDSIG? Note1: I'm not asking that all of the details of how to construct a PKI for this functionality be documented here, somewhere else is fine, but it doesn't seem to be in [ICANN-TMCH] that I can see, so I don't know what I'd have to implement, that'd get interop. Note2: I'm also not asking for a US-DoD-scale super-huge PKI or RPKI to be specified here, something simpler should work.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-10 10:56:09-08:00",
    "end_reason": "position_updated",
    "start": "2016-03-04 08:20:07-08:00",
    "text": "(same holds, for -05, checked on March 4th) Section 7 points to [ICANN-TMCH] for signature validation policy (I think, not quite sure). I did a quick scan (so I might have missed it) of that document and did not find any mention of security or signature validation, so what is an implementer supposed to do, over and above just checking the cryptographic correctness of the XMLDSIG? Note1: I'm not asking that all of the details of how to construct a PKI for this functionality be documented here, somewhere else is fine, but it doesn't seem to be in [ICANN-TMCH] that I can see, so I don't know what I'd have to implement, that'd get interop. Note2: I'm also not asking for a US-DoD-scale super-huge PKI or RPKI to be specified here, something simpler should work.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-01-22 13:49:23-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-20 15:08:51-08:00",
    "text": "This is mainly a process discuss. I share Alvaro's concern about this being marked as \"updating\"  RFC7601 , when it seem like a full replacement. I'm promoting it to a DISCUSS because I think this needs to be resolved before publication. The current structure will make it very difficult for readers to figure out which parts of each doc they need to worry about. I think it needs to either go back to \"obsoleting\" 7601, or it needs to be recast to just talk about the changes. Note that if the former path is chosen, the IANA considerations in 7601 will need to be copied forward.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-21 08:20:28-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-21 05:58:30-08:00",
    "text": "I also appreciate the efforts to reduce the diff between  RFC 7601  and this document; it does help readability greatly.\u00a0 (I also support Ben's  Discuss.)\u00a0 Unfortunately, it also can obscure some aspects where the text of the document did need to change as part of the update, but has not done so. For example, in Section 1: \u00a0  There exist registries for tokens used within this header field that \u00a0  refer to the specifications listed above.\u00a0 Section 6 describes the \u00a0  registries and their contents and specifies the process by which I don't think all of this is still present anymore.\u00a0 (If we were talking about registration policies, for example, we'd need an 8126 reference to replace the 5226 reference that was removed.) \u00a0  entries are added or updated.\u00a0 It also updates the existing contents \u00a0  to match the current states of these specifications. [We should double-check that everything that now allows EAI-formatted stuff is updated to also refer to this document from the IANA registry. On first glance this might include  vbr.mv  and  vbr.md , but probably much more.] Don't we need to mention the updates (or obsoletes) relationship w.r.t. 7601 in the Abstract and Introduction? Section 4.1 has: \u00a0  MUAs and downstream filters MUST ignore any result reported using a \u00a0  \"result\" not specified in the IANA \"Result Code\" registry or a \u00a0  \"ptype\" not listed in the \"Email Authentication Property Types\" \u00a0  registry for such values as defined in Section 6.\u00a0 [...] This would seem to be an internal inconsistency, in that it seems to preclude any sort of experimental usage as described in Sections 2.7.x. In Section 2.3: \u00a0  Combinations of ptypes and properties are registered and described in \u00a0  the \"Email Authentication Methods\" registry, coupled with the \u00a0  authentication methods with which they are used.\u00a0 This is further \u00a0  described in Section 6. The relevant subsection of section 6 is a pretty empty stub now.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-02-23 05:53:10-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-15 16:48:04-08:00",
    "text": "** In following the robust discussion in the TSVART thread ( https://mailarchive.ietf.org/arch/msg/tsv-art/vcJRc6oXRRiCl5-bouLTyRVbTc8/ ), it appears that design assumption of this document is to build on  RFC9301  and  RFC9303 .\u00a0 Section 3 helpfully outlines unique deployment assumptions for PubSub relative to  RFC301 .\u00a0 Missing is an explicit summary of what Alberto stated in  https://mailarchive.ietf.org/arch/msg/tsv-art/80yDl25rP3Ev4H_x_rOstue_J7M/ .\u00a0 There appears to be a stronger requirements to use LISP-SEC or associated pre-shared secret to secure this new mechanism which is not the same as the baseline  RFC9301  (per Section 1.1).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-01-28 19:08:58-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-08 14:02:51-08:00",
    "text": "The security considerations do not seem to follow the YANG security guidelines . They do not list the specific writeable and readable subtrees/nodes and why they are sensitive. The fact that all the writeable nodes could \"negatively affect network operations\" seems trivially true for most writeable YANG module nodes. In the case of these modules, there seem to be multiple different threats relevant to different nodes, including exposure of data about individual users/customers, potential for disruption of the operations of the BR or CE, etc.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-10 11:07:49-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-08 11:38:20-08:00",
    "text": "This document has 7 listed authors/editors.\u00a0 Since, per  RFC 7322 , documents listing more than five authors are unusaul, and seven is greater than five, let's talk about the author count. The binding-table-versioning container's \"version\" leaf is of type uint64 but the in-module description indicates that it is a timestamp.\u00a0 If it is actually supposed to be a timestamp, then the units and zero time need to be specified, but it seems more likely that this should just be described as an abstract version number, if I understand the prose text about this container correctly.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-23 04:24:27-07:00",
    "end_reason": "position_updated",
    "start": "2016-11-01 06:34:58-07:00",
    "text": "I have one small issue that I would like to discuss before recommending approval of this document: Reading Section 8 I was unable to figure out what are \"claim\", \"permitted\" and \"excluded\" and what exact syntaxes they use. I think this is underspecified. You are probably missing some references, examples or both.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-12-13 15:50:32-08:00",
    "end_reason": "position_updated",
    "start": "2017-12-12 15:57:52-08:00",
    "text": "\u00a0  national policies.\u00a0 The count field is only applicable to start\t \u00a0  fields' whose values do not include \"*\" or \"#\" (i.e., a\t \u00a0  TelephoneNumber that does not include \"*\" or \"#\").\u00a0 count never\t \u00a0  overflows a TelephoneNumber digit boundary (i.e., a\t \u00a0  TelephoneNumberRange with TelephoneNumber=10 with a count=91 will\t \u00a0  address numbers 10-99). This text doesn't seem very clear. When you say \"never overflows a digit boundary\" do you mean \"doesn't extend the integer to the left\"? Because you sure seem to be overflowing the 1s place here.  Is the algorithm that you are given the input TN, Count, and TN consists D digits that the range is: \u00a0 MIN(TN + Count, 10^D - 1) That would be consistent with your example here, but I don't think consistent with your text. Or do you mean something else?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-25 07:24:10-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-11-02 18:54:54-07:00",
    "text": "Sorry but I have a load of discuss points on this one. I don't think any of 'em are that hard though, except maybe one. (I'll let us all guess which one:-) (1) TN auth list services - IIUC, these are not free today.\u00a0 Is that correct?\u00a0 It's not clear to me that alternatives such as listing all good numbers inside a cert are practical.\u00a0 Did the WG have an explicit consensus that building in a requirement to have verifiers pay to be an effective RP is ok?\u00a0 If so, can you send a pointer to the list archive or minutes where that was agreed. If not, don't the WG need to explicitly ok that? (2) setion 8: you need to say more clearly exactly what the IA5String values in the extension map to in the JWT. I assume it's the field names but you don't say. You need to say if this extension can or needs to be critical. (3) section 9: you need to say whether this extension needs to be or can be critical and where in the cert path it's allowed to be and how to interpret things if >1 cert in the path has this extension (if that's allowed, and if it is, then complexity awaits us;-). (4) section 10: you need to pick one MTI method I think. Why is that wrong? You nearly, but not quite, do. Why not just do it? (5) section 10: don't you need to somehow define \"short-lived\"? That could be defined as an RP-configurable value, but even if so, I think you need to say that. Even if you do that, I'm not sure that an RP-configured value is right as short-lived certs, vs. not, puts a different burden on the signer and if the signer and RP have different ideas of what short-lived means, then interop failures seem likely. Bottom line for this point: what's a short lived cert? (6) section 10: as with short-lived, don't you need to define HVE? (7) section 10.2.1: Can OCSP be made use HTTPs here?\u00a0 If not, then you have the RP sending out the caller's TN in clear.\u00a0 That seems bad (cf.  BCP188 ). Did the WG consider that? If this spec needs OCSP/HTTPs then I think you need to have a new MUST for that (it's uncommon or maybe never done?) and address the potential bootstrap issues. (But I didn't think those through - did the WG?)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-14 09:17:10-07:00",
    "end_reason": "position_updated",
    "start": "2017-01-25 07:24:10-08:00",
    "text": "Sorry but I have a load of discuss points on this one. I don't think any of 'em are that hard though, except maybe one. (I'll let us all guess which one:-) (1) TN auth list services - IIUC, these are not free today.\u00a0 Is that correct?\u00a0 It's not clear to me that alternatives such as listing all good numbers inside a cert are practical.\u00a0 Did the WG have an explicit consensus that building in a requirement to have verifiers pay to be an effective RP is ok?\u00a0 If so, can you send a pointer to the list archive or minutes where that was agreed. If not, don't the WG need to explicitly ok that? (2) setion 8: you need to say more clearly exactly what the IA5String values in the extension map to in the JWT. I assume it's the field names but you don't say. You need to say if this extension can or needs to be critical. (3) section 9: you need to say whether this extension needs to be or can be critical and where in the cert path it's allowed to be and how to interpret things if >1 cert in the path has this extension (if that's allowed, and if it is, then complexity awaits us;-). (4) section 10: you need to pick one MTI method I think. Why is that wrong? You nearly, but not quite, do. Why not just do it? (5) section 10: don't you need to somehow define \"short-lived\"? That could be defined as an RP-configurable value, but even if so, I think you need to say that. Even if you do that, I'm not sure that an RP-configured value is right as short-lived certs, vs. not, puts a different burden on the signer and if the signer and RP have different ideas of what short-lived means, then interop failures seem likely. Bottom line for this point: what's a short lived cert? (6) section 10: as with short-lived, don't you need to define HVE? (7) section 10.2.1: Can OCSP be made use HTTPs here?\u00a0 If not, then you have the RP sending out the caller's TN in clear.\u00a0 That seems bad (cf.  BCP188 ). Did the WG consider that? If this spec needs OCSP/HTTPs then I think you need to have a new MUST for that (it's uncommon or maybe never done?) and address the potential bootstrap issues. (But I didn't think those through - did the WG?) (new) moving this from 4474bis draft where it used to be - the  authors say they want to fix it here: I think the ABNF conflicts with the E164Number definition in the 4474bis draft.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-09-16 23:02:39-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-16 00:12:06-07:00",
    "text": "Thanks for another clear document.\u00a0 There are some \"SHOULD\" key words in one section that I would like to discuss, and that I think we ought to be able to resolve without much difficulty: \u2014 Section 5.7 \u2014 There are various \u201cSHOULD\u201ds in this section, and I have the same comment about all of them:  BCP 14  says, about \u201cSHOULD\u201d, that \u201cthere may exist valid reasons in particular circumstances to ignore a particular item, but the full implications must be understood and carefully weighed before choosing a different course.\u201d\u00a0 I see no guidance here to help the reader understand what such circumstances and implications are, so I can\u2019t see how an implementer can evaluate the situation.\u00a0 Can you provide any help here?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-26 15:19:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-17 12:34:24-07:00",
    "text": "This document seems generally useful, and thanks for it.\u00a0 I think there's a couple places where it's ambiguous or unclear, and hopefully we can tighten up the language without needing extensive changes. There may be an internal inconsistency in Section 2.3's definitions relating the Overflow-Count and the Overflow-Threshold: the description of Overflow-Count reads as if it is a reported quantity, but the description of Overflow-Threshold implies that Overflow-Count is a configured parameter.\u00a0 (Similarly for the Underflow- variants.) Specifically, the sentence \"[t]his value indicates how many times consecutively, the percentage or absolute difference between the current MaxAvgBw and the current bandwidth reservation of the LSP is greater than or equal to the Overflow-Threshold value\" uses the descriptive verb \"is\" as opposed to a conditional such as \"needs to be [...] in order to [...]\". Section 5.2.3.2 says: \u00a0  If the percentage difference between the current MaxAvgBw and the \u00a0  current bandwidth reservation is greater than or less than or equal \u00a0  to the threshold percentage, the LSP bandwidth is adjusted to the \u00a0  current bandwidth demand (MaxAvgBw) (as long as the difference in the \u00a0  bandwidth is at least or above the Minimum-Threshold). As written (\"greater than or less than or equal to\"), this is always true, which cannot be what was intended.\u00a0 Probably we should reword to just \"greater than\" and talk about the percentage absolute difference, i.e., 100 * abs(MaxAvgBw - CurrentRes) / CurrentRes .",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-03-30 16:44:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-01-02 04:08:23-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-extra-sieve-action-registry-05 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (trivial to address), some non-blocking COMMENT points, and some nits. Special thanks to Bron Gondwana for the shepherd's detailed write-up including the WG consensus and the justification of the intended status (but see my DISCUSS below).  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Intended status The I-D text says \"Informational\" while the meta-data and the shepherd's review say \"proposed standard\".",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-03 06:29:15-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-04 11:17:54-08:00",
    "text": "A registry is surely very useful. Currently, all entries are based on RFCs. Is it the intention of this RFC to change that practice by setting the registry policy to Expert Review? It seems more appropriate to set the policy to RFC Required.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-31 12:06:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-19 15:44:36-07:00",
    "text": "As for other reviewers, many of my comments duplicate those for the OSPF document; I expect that the analogous responses apply and am fine if they only appear for one document's review. Here, the question I have about normative language applies to the text in Section 3: \u00a0  When a router propagates a prefix between ISIS levels ([ RFC5302 ], it \u00a0  MUST preserve the ELC signaling for this prefix. The scenario in question is analogous to the OSPF cross-area case: is the router propagating the prefix between ISIS levels required to implement this document; is preservation of the flag value a new requirement from this document vs. a preexisting property; and is this document trying to make normative requirements of devices that don't implement this document? Likewise, the ASBR case for cross-protocol redistribution seems to rather inherently require understanding the semantics of the flags being translated.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-27 22:27:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-07 15:06:50-07:00",
    "text": "Thanks for this document; it's generally well-written and the changes since 7049 are helpful.\u00a0 I do have a few points that may need discussion before publication, though. Let's discuss whether the framing of tag number 35 for \"regular expressions that are roughly in [PCRE] form or a version of the JavaScript regular expression syntax\" meets the interoperability expectations for Internet Standard status (bearing in mind that we are defining a data format and not a protocol).\u00a0 I note that it is okay to leave the codepoint allocated with the current meaning and the previous document as its reference, but decline to discuss it in the document going for STD (we are in the process of doing that with COSE countersignatures at the moment). The example in Section 5 of \"the item is a map that has byte strings for keys and contains at least one pair whose key is 0xab01\" seems to be in violation of the definition of a valid map, since applications are not allowed to rely on invalid behavior.\u00a0 (That is, the implied \"more than one pair whose key is 0xab01\" would be invalid.) I think that the new deterministic encoding rules for sorting map keys should be clear about whether \"no content\" sorts before or after \"content present\" -- that is, how 0x10 and 0x1020 are ordered when the 0x10 byte is identical and we have to compare\u00a0 with 0x20. The discussion in Appendix C suggests that C (programming language) implementations all use two's-complement representation of signed integers; this requirement is present in POSIX but not C itself (I verified this for C99 and C11). Additionally, the encode_sint() function (also Appendix C) relies on C implementation-defined behavior while right-shifting a signed integer. The C decode_half() function in Appendix D assumes that 'int' is wider than 16 bits (since assigning a value to an int16_t variable when the value is not representable in int16_t incurs implementation-defined behavior).\u00a0 Given that this spec is specifically targetting constrained devices, it's not clear that such an assumption is justified.\u00a0 (It also right shifts a signed integer, incurring the same implementation-defined behavior mentioned above.\u00a0 (The bitwise AND against 0x8000 is also problematic for an int16_t.))",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-09-19 07:53:14-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 12:00:41-07:00",
    "text": "1) In Sec 4.5.1: \"The downstream PLR can assign a bypass tunnel when \u00a0  processing the first Path message of the protected LSP, however, it \u00a0  can not update the forwarding plane until it receives the Resv \u00a0  message containing the downstream MP label.\" Please explain how the downstream PLR can assign a bypass tunnel if the LSP has a loose ERO - so the downstream PLR does not know the next-next-hop that would be the MP for a node-protecting LSP. 2) Sec 4.5.1: \"An upstream PLR (downstream MP) SHOULD check all BYPASS_ASSIGNMENT \u00a0  subobjects in the Path RRO in order to assign a reverse bypass \u00a0  tunnel.\u00a0 The upstream PLR that detects a BYPASS_ASSIGNMENT subobject, \u00a0  selects a reverse bypass tunnel that terminates locally with the \u00a0  destination address and tunnel-ID from the subobject, and has a \u00a0  source address matching the Node-ID address.\" This isn't very clear - particularly given that there will be many BYPASS_ASSIGNMENT subobjects in the path RRO.\u00a0 The case of BYPASS_ASSIGNMENT sub-objects being removed or changed is not addressed at all.\u00a0 In addition, I *assume* that the failure to treat the destination IP address in the BYPASS_ASSIGNMENT as the source IP address for the upstream Bypass tunnel is an oversight? I believe that what is meant\u00a0 is: \"An upstream PLR (downstream MP) SHOULD check all BYPASS_ASSIGNMENT sub-objects in the Path RRO to see if the destination IP address in the BYPASS_ASSIGNMENT matches an address of the upstream PLR.\u00a0 For each BYPASS_ASSIGNMENT sub-object that matches, the upstream PLR looks for a local bypass tunnel that has a destination matching the downstream PLR that inserted the BYPASS_ASSIGNMENT, as indicated by the Node-ID address, and the same tunnel-ID as indicated in the BYPASS_ASSIGNMENT.\" I recall that tunnel-ID is usually scoped by the address of the ingress LSR; this seems to assume that the same tunnel-ID is provided to both the downstream PLR and upstream PLR???\u00a0  Alternately, I am misunderstanding - and the information in the BYPASS_ASSIGNMENT is really intended to be bypass tunnel to be used by the upstream PLR, which the downstream PLR  somehow(??details, hints in the document please) knows . Then there needs to be text to handle the case where the previous PATH message contained a particular BYPASS_ASSIGNMENT sub-object and that sub-object has been removed or changed. 3) Sec 4.5.3: \"In both examples above, the upstream PLR SHOULD send a Notify message \u00a0  [ RFC3473 ] with Error-code - FRR Bypass Assignment Error (value: TBA1) \u00a0  and Sub-code - Bypass Assignment Cannot Be Used (value: TBA2) to the \u00a0  downstream PLR to indicate that it cannot use the bypass tunnel \u00a0  assignment in the reverse direction.\u00a0 Upon receiving this error, the downstream PLR  \u00a0  MAY remove the bypass tunnel assignment and select an alternate bypass tunnel if one available.\" This section is problematic because it creates the use of local policy when the ingress has a clear way to signal what type of protection is desired and because it provides an error message to where it will only cause pointless churn (the MP is the MP based on the type of protection desired - certainly for bypass) rather than to the ingress where it could at least be acted upon.\u00a0 The dynamics at time of failure also do not seem to be well considered; asymmetry is unfortunate, but worse is lack of protection. Consider the case in Example 1.\u00a0 If R5 suffers a node failure, then there is no protection for the upstream LSP from R6 if it prefers the link protection.\u00a0 It simply doesn't matter what bypass tunnel R4 picks! Sending a Notify message to R4 asking for a different tunnel is not productive.\u00a0 If the ingress has requested node-protection, then there is simply nothing that can be done for this topology by R5.\u00a0 It could be helpful to send a Notify to the ingress or have a flag set in the RESV RRO to indicate the issue, but that's about it. For the question about creating local policy, how are the SESSION_ATTRIBUTES used?\u00a0 Obviously, they are available in the PATH message that has the BYPASS_ASSIGNMENTs.\u00a0 Why would the \"Node Protection Desired\" flag not be relevant here? 4) Sec 5: \"\u00a0  o\u00a0 Upstream PLR reroutes traffic upon detecting the link failure or \u00a0 \u00a0 \u00a0 upon receiving RSVP Path message over the bidirectional bypass \u00a0 \u00a0 \u00a0 tunnel.\u00a0  \u00a0  o\u00a0 Upstream PLR also reroutes RSVP Resv signaling after receiving \u00a0 \u00a0 \u00a0 RSVP Path message over the bidirectional bypass tunnel. \" How does the upstream PLR detect that the message was received over the bypass tunnel?\u00a0 Is the assumption that the bypass LSP doesn't do penultimate hop popping? Is the assumption that the PLR can tell because RSVP indicates the downstream PLR as the previous hop in its signaling?\u00a0 Please clarify and describe how this detection is done - to ease interoperability. 5) In Sec 5.1.2:\u00a0 \"When upstream PLR R4 receives the protected LSP Path messages over \u00a0 \u00a0 \u00a0 the restored link, if not already done, it starts sending Resv \u00a0 \u00a0 \u00a0 messages and traffic flow of the protected LSP over the restored \u00a0 \u00a0 \u00a0 link and stops sending them over the bypass tunnel.\" Is there a reason that \"when the downstream PLR receives the protected LSP RESV messages over the restored link, if not already done, it starts sending Path messages and traffic flow of the protected LSP over the restored link and stops sending them over the bypass tunnel.\" doesn't also make sense to put in this section? If this is not a good idea, please explain clearly the issues that it causes. I am assuming that \"after the link is restored\" implies that bidirectional communication has been successfully tested - not merely that the physical layer is up but also that an IGP or BFD is successful across it. (But this is standard for RSVP-TE FRR). 6) Sec 5.2.2: The behavior of R4 is not described.\u00a0 When the link from R3-R4 fails, R4 will redirect traffic to R2. As written at the start of Sec 5, R4 does not start sending its Resv across the bypass tunnel and R2 is thus not triggered to use its bypass tunnel.\u00a0 Please clearly describe this and why.\u00a0 It is this asymmetry in behavior for the downstream PLR and upstream PLR that causes the downstream PLR's bypass tunnel to be prioritized. 7) Sec 5.2.2: The need for the PRR to look up the bypass tunnel and then reprogram the forwarding plane is quite concerning for having this operate at significant scale.\u00a0 What could be done if one assumes that the selected bypass tunnel - from the BYPASS_PROTECTION handling - is used?\u00a0 Is there a reason that decision has to be redone here? What is the issue that the solution is trying to work around?\u00a0  I can certainly imagine scenarios with BFD sessions so that the PRR can be rapidly failed over as the result of the BFD session going down.\u00a0 What scale of LSPs are you expecting this scenario to handle? 8) Sec 5.2.2: Given that the PRR will TEAR DOWN the LSP if it can't find a matching bypass tunnel, it would be quite useful for the ingress to have visibility as to the protection available.\u00a0 In  RFC 4090 , Sec 4.4 defines both \"local protection available\" and \"local protection in use\" flags in the IPv4/IPv6 sub-objects.\u00a0 Clearly, that isn't sufficient for the co-routed case because the ingress needs to know also that \"local upstream protection available\" and perhaps \"local upstream protection in use\".\u00a0  9) Sec 5.2.3: \"\u00a0  o\u00a0 The upstream PLR R4 starts sending the traffic flow of the \u00a0 \u00a0 \u00a0 protected LSP over the restored link towards downstream PLR R3 and \u00a0 \u00a0 \u00a0 forwarding the Path messages towards PRR R5 and stops sending the \u00a0 \u00a0 \u00a0 traffic over the bypass tunnel. \u00a0  o\u00a0 When upstream PLR R4 receives the protected LSP Path messages over \u00a0 \u00a0 \u00a0 the restored link, if not already done, it starts sending Resv \u00a0 \u00a0 \u00a0 messages and traffic flow over the restored link towards \u00a0 \u00a0 \u00a0 downstream PLR R3 and forwarding the Path messages towards PRR R5 \u00a0 \u00a0 \u00a0 and stops sending them over the bypass tunnel.\" In the referenced figures, R4 is NOT an upstream PLR; that is R5.\u00a0 R4 could have forgotten all state associated with the bi-directional LSP.\u00a0  Please fix the text to actually describe the behavior. 10) Sec 5.3: \"\u00a0  Unidirectional link failures can result in the traffic flowing on \u00a0  asymmetric paths in the forward and reverse directions.\u00a0 In addition, \u00a0  unidirectional link failures can cause RSVP soft-state timeout in the \u00a0  control-plane in some cases.\u00a0 As an example, if the unidirectional \u00a0  link failure is in the upstream direction (from R4 to R3 in Figures 1 \u00a0  and 2), the downstream PLR (node R3) can stop receiving the Resv \u00a0  messages of the protected LSP from the upstream PLR (node R4 in \u00a0  Figures 1 and 2) and this can cause RSVP soft-state timeout to occur \u00a0  on the downstream PLR (node R3).\" Is the assumption that there is no IGP or BFD running on the link? If not, then the IGP or BFD session will go down on the link first, making it unavailable to RSVP-TE and should trigger the fast-reroute. Also - given this issue, why does the upstream MP not start using the bypass tunnel when receiving Resv through a bypass tunnel? There is no explanation in the draft and there should be - to prevent incorrect \"optimizations\".\u00a0 Ideally, the draft would specify something like MUST NOT or SHOULD NOT with explanation - if that is the case. 11) Sec 7.1: The description for the BYPASS_ASSIGNMENT completely fails to be clear as to whether the contents are for the bypass tunnel used by the node inserting it into the RRO or whether the contents are a direction for the node that receives it - based on the  Node ID that is included.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-08-03 07:30:22-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 10:34:35-07:00",
    "text": "What stops me from just providing a random IP address that I don't control in BYPASS_ASSIGNMENT and thus causing them to get spammed? I am assuming there are mechanisms to prevent them, but it's not immediately clear to me what those are, so they at minimum need to spelled out in security considerations. This section from  RFC 4090  is not encouraging: \u00a0  This document does not introduce new security issues.\u00a0 The security \u00a0  considerations pertaining to the original RSVP protocol [RSVP] remain \u00a0  relevant. \u00a0  Note that the facility backup method requires that a PLR and its \u00a0  selected merge point trust RSVP messages received from each other.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-03-01 11:50:36-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-21 00:32:44-08:00",
    "text": "Thanks to everyone who worked on this document. I found it well-organized and easy to read. --------------------------------------------------------------------------- See my DISCUSS on  draft-ietf-jmap-mail  regarding the issues that can arise from normatively referencing the WHATWG HTML document. Consider citing https://www.w3.org/TR/html52/  instead.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-08 08:36:18-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-04 18:40:28-08:00",
    "text": "Length of review comments aside, this is actually a quite nice document -- thank you to the authors for making it so clear and well-organized. The only readability complaint I have is that I don't get a great picture of how all the bits of the Email object fit together, but it's complicated enough that maybe a generic schema wouldn't actually be helpful. Section 2 I think we need more precise language than \"corresponds to\" for the relationship between JMAP MailboxRights and IMAP ACLs, specifically because JMAP distinguishes mayRename and mayDelete but IMAP just has the single 'x' ACL.\u00a0 (More in the COMMENT section, but the non-isomporphic mapping of 'x' is the only DISCUSS-worthy part.) Section 4.1.1 We only describe the \"\\\" to \"$\" translation for the four supported system keywords, but it seems that it should be more generic (not that we expect more IMAP system keywords to appear anytime soon)? Section 4.1.2.1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  A server SHOULD replace any octet \u00a0  or octet run with the high bit set that violates UTF-8 syntax with \u00a0  the unicode replacement character (U+FFFD).\u00a0 [...] This seems problematic, given that this is supposed to be the \"Raw\" format.\u00a0 I guess the justification for the replacement is that we use JSON and JSON requires UTF-8, but if that's the case then shouldn't this be a MUST and not a SHOULD?\u00a0 In particular, a client can't rely on the server providing the SHOULD, so it doesn't seem to provide much value. Section 4.7 \u00a0  The server MAY forbid two email objects with the same exact [ RFC5322 ] \u00a0  content, or even just with the same [ RFC5322 ] Message-ID, to coexist \u00a0  within an account; if the target account already has the email the \u00a0  copy will be rejected with a standard \"alreadyExists\" error. This has some security considerations that should probably be mentioned in Section 9.4: when a user only has read privileges to a subset of the folders in an account, this behavior can be abused as an oracle to determine whether a given message exists in the inaccessible portions of that account.\u00a0 (Similarly for /import.) Section 4.9 \u00a0  The following metadata properties on the Email objects will be \"null\" \u00a0  if requested: \u00a0  [...] \u00a0  o\u00a0 mailboxIds This seems in conflict with the Section 4.1.1 text that every Email \"MUST belong to one or more mailboxes at all times (until it is deleted).\" Presumably we want a broader disclaimer in 4.1.1 rather than any changes here... There may also be a related condition wherein an EmailSubmission object refers to an Email after the Email is deleted -- I didn't (yet) see text to indicate whether the emailId in the EmailSubmission is expected to still be resolvable, in which case there would potentially not be an associated Mailbox. Section 9.3 It's 2019.\u00a0 Why are we still recommending SASL PLAIN? We have better options even if we are resigned to passwords, like SCRAM.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-06 20:39:43-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-17 16:06:13-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4198 IMPORTANT: It's a bit hard to tell what the server is required to do. Which of the many properties of emails (headers, the like) is the server required to provide? DETAIL S 2. >\u00a0   >\u00a0 \u00a0 \u00a0 \u00a0  *\u00a0 *mayReadItems*: \"Boolean\" If true, the user may use this >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mailbox as part of a filter in a _Email/query_ call and the >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mailbox may be included in the _mailboxIds_ set of _Email_ >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 objects.\u00a0 If a sub-mailbox is shared but not the parent >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mailbox, this may be \"false\".\u00a0 Corresponds to IMAP ACLs \"lr\". This doesn't have any impact on Email/get? that seems odd.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-01 19:18:09-08:00",
    "text": "I'd like to have a (hopefully brief!) discussion about our description of the \"strict transport security\" functionality the HTTPS RRtype provides, with respect to its accuracty/completeness and how explicit vs implicit we should be about the corresponding divergence from \"pure\" HTTP behavior. It's pretty clear that at a pure HTTP protocol level (which as far as I can tell is the scope of applicability that we claim) that resources accessed with \"http\" scheme and resources accessed with \"https\" scheme have no intrinsic relationship -- \u00a74.2.2 of draft-ietf-httpbis-semantics-19  says: \u00a0  Resources made available via the \"https\" scheme have no shared \u00a0  identity with the \"http\" scheme.\u00a0 They are distinct origins with \u00a0  separate namespaces.\u00a0 [...] But the procedures in this document (e.g., \u00a79.5, \u00a79) seem pretty clear that, when an HTTPS record is published, accesses for \"http\" scheme resources should be converted to \"https\" scheme accesses, with implication that the client should expect to get the same resource back from the modified query compared to the unmodified \"http\"-scheme one. While there is a caution in \u00a79.5 that: \u00a0  If this redirection would result in a loss of functionality (e.g. \u00a0  important resources that are only available on the \"http\" origin), \u00a0  the operator MUST NOT publish an HTTPS RR. but in my reading it leaves some important details as only implicit! We need to care not only about resources only available on one vs the other origin, but also about whether the translation would change the semantics of the client's request/response exchange.\u00a0 That is, whether the resources accessible by the different schemes are actually analogous (which, per the above, is not required by HTTP and is subject to the site administrator's control or in some cases other application protocols on top of HTTP used by that origin). This (mostly implicit) requirement is a potential barrier for adoption of the HTTPS RRtype, and while the precondition is very often going to be satisfied, I wanted to get a sense for whether we should make the requirement more explicit, and possibly more prominent in the document (e.g., mention it in the Introduction).\u00a0 I don't know what the right answer is, but it seems important enough to ensure that the topic receives deliberate consideration.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-05-09 15:27:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-03 00:43:35-08:00",
    "text": "[Appendix D.2] * Sorry to be super nitpicky/petty about this. \u00a0 With respect to Figure 7: IPv4-mapped IPv6 addresses have a complicated \u00a0 history (see  RFC 4942  S2.2 for an amuse-bouche, as well as itojun's \u00a0  draft-itojun-v6ops-v4mapped-harmful ). \u00a0 Unless there is something very useful to be gained by the inclusion of this \u00a0 example (what?) I would strongly suggest removing it.\u00a0 I fear it will only \u00a0 cause confusion.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-05-23 05:01:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-03-02 14:13:10-08:00",
    "text": "Thank you for the work on this document Many thanks to Cullen Jennings for his ART ART review: https://mailarchive.ietf.org/arch/msg/art/CfAGYlDfw5kPjlhbujmikX43J6Q/ .  I am concerned by the use of SHOULD in this document. In several places (see 1. below for what I identified as problematic SHOULDs) the document lacks text about why these are SHOULD and not MUST or MAY. I agree with John Klensin, who formulated it very clearly: If SHOULD is used, then it must be accompanied by at least one of: (1) A general description of the character of the exceptions and/or in what areas exceptions are likely to arise.\u00a0 Examples are fine but, except in plausible and rare cases, not enumerated lists. (2) A statement about what should be done, or what the considerations are, if the \"SHOULD\" requirement is not met. (3) A statement about why it is not a MUST. I also have a number of non blocking comments and questions. I will appreciate answers to my questions, to improve my understanding. If any clarification comes out of it, I hope it will help improve the document. Francesca 1. ----- FP: SHOULD lacking additional context: \u00a0  Within a SVCB RRSet, all RRs SHOULD have the same Mode.\u00a0 If an RRSet \u00a0  is used to impose an ordering on SVCB RRs.\u00a0 SVCB RRs with a smaller \u00a0  SvcPriority value SHOULD be given preference over RRs with a larger \u00a0  SvcPriority value. \u00a0  In AliasMode, the SVCB record aliases a service to a TargetName. \u00a0  SVCB RRSets SHOULD only have a single resource record in AliasMode. \u00a0  If multiple are present, clients or recursive resolvers SHOULD pick \u00a0  one at random. \u00a0  In AliasMode, records SHOULD NOT include any SvcParams, and \u00a0  recipients MUST ignore any SvcParams that are present. \u00a0  Zone-file implementations \u00a0  SHOULD enforce self-consistency.  \u00a0  If the client is SVCB-optional, and connecting using this list of \u00a0  endpoints has failed, the client SHOULD attempt non-SVCB connection \u00a0  modes. \u00a0  If the client enforces DNSSEC validation on A/AAAA responses, it \u00a0  SHOULD apply the same validation policy to SVCB. \u00a0  If the client is unable to complete SVCB resolution due to its chain \u00a0  length limit, the client SHOULD fall back to the authority endpoint, \u00a0  as if the origin's SVCB record did not exist. \u00a0  For compatibility with clients that require default transports, zone \u00a0  operators SHOULD ensure that at least one RR in each RRSet supports \u00a0  the default transports. \u00a0  Global Scoped Entry Registry [Attrleaf].\u00a0 The scheme SHOULD have an \u00a0  entry in the IANA URI Schemes Registry [ RFC7595 ].\u00a0 The scheme SHOULD \u00a0  have a defined specification for use with SVCB.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-05-24 11:44:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-23 05:01:45-07:00",
    "text": "Thank you for the work on this document. Many thanks to Cullen Jennings for his ART ART review: https://mailarchive.ietf.org/arch/msg/art/CfAGYlDfw5kPjlhbujmikX43J6Q/ .  Thank you for addressing my previous DISCUSS and COMMENTs. I have reviewed v-09 and I noticed 4 points were not addressed (or I missed them). Do let me know if you think no further clarifications were necessary - just making sure these were not missed, as I have not seen any answers to them. Re: the use of SHOULD - thank you for adding context to most of them. I did not see any added context to these following two SHOULDs: > Zone-file implementations SHOULD enforce self-consistency.  and > If the client enforces DNSSEC validation on A/AAAA responses, it SHOULD apply the same validation policy to SVCB. If SHOULD is used, then it must be accompanied by at least one of: (1) A general description of the character of the exceptions and/or in what areas exceptions are likely to arise.\u00a0 Examples are fine but, except in plausible and rare cases, not enumerated lists. (2) A statement about what should be done, or what the considerations are, if the \"SHOULD\" requirement is not met. (3) A statement about why it is not a MUST. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-03-22 09:07:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-02 23:39:57-08:00",
    "text": "Section 15.3.1 creates a new IANA registry with a First Come First Served registration policy.\u00a0  RFC 8126  says this of that policy: \u00a0  It is also important to understand that First Come First Served \u00a0  really has no filtering.\u00a0 Essentially, any well-formed request is \u00a0  accepted. Yet this document stipulates: \u00a0  [...]\u00a0 The Format Reference \u00a0  MUST specify how to convert the SvcParamValue's presentation format \u00a0  to wire format and MAY detail its intended meaning and use.\u00a0 An entry \u00a0  MAY specify a Format Reference of the form \"Same as (other key Name)\" \u00a0  if it uses the same presentation and wire formats as an existing key. These seem to me to be in conflict.\u00a0 We're asking IANA to do more than what the BCP says is valid here.\u00a0 Should this instead be Expert Review?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-05-09 15:29:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-22 09:09:16-07:00",
    "text": "Section 15.3.1 creates a new IANA registry with a First Come First Served registration policy.\u00a0  RFC 8126  says this of that policy: \u00a0  It is also important to understand that First Come First Served \u00a0  really has no filtering.\u00a0 Essentially, any well-formed request is \u00a0  accepted. Yet this document stipulates: \u00a0  [...]\u00a0 The Format Reference \u00a0  MUST specify how to convert the SvcParamValue's presentation format \u00a0  to wire format and MAY detail its intended meaning and use.\u00a0 An entry \u00a0  MAY specify a Format Reference of the form \"Same as (other key Name)\" \u00a0  if it uses the same presentation and wire formats as an existing key. These seem to me to be in conflict.\u00a0 We're asking IANA to do more than what the BCP says is valid here.\u00a0 Should this instead be Expert Review?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-23 12:27:10-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 20:59:03-07:00",
    "text": "Section 4.3.4 asserts: \u00a0  [...]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 We'll note that the Join \u00a0  Priority is now specified between 0 and 0x3F leaving 2 bits in the \u00a0  octet unused in the IEEE Std. 802.15.4e specification.\u00a0 After \u00a0  consultation with IEEE authors, it was asserted that 6TiSCH can make \u00a0  a full use of the octet to carry an integer value up to 0xFF. I'm extremely reluctant to publish this text in the IETF stream without a citation. I also think there are more topics that need to be covered in the security considerations (see Comment, and not just the Section-6 portions), especially with respect to the reliance on the link-layer security mechanism and its network-wide shared key.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-25 08:20:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 08:47:54-07:00",
    "text": "I only had a quick read of this document, however, it seems to me that there are strong dependencies on a whole bunch of drafts, that are only listed as informational. I don't have a deep enough understanding to make a final judgement of which draft would need to be listed as normative references, however, I wanted to raise this point on the discuss level in order to ensure that this is considered before publication. To give an example: Section 4.6.3 goes quite seep into details of what's described in [ I-D.ietf-6lo-fragment-recovery ]. However as long as [ I-D.ietf-6lo-fragment-recovery ] is not published yet, the 6tisch arch should probably not rely on the content of this draft that strongly. Putting [ I-D.ietf-6lo-fragment-recovery ] as a normative reference ensures that this draft will not be published before [ I-D.ietf-6lo-fragment-recovery ].",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-01-17 04:59:23-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-30 09:22:18-08:00",
    "text": "This should be a quick issue to handle, but given that there is no language describing what a low threshold event is, I think it needs to be a Discuss. Sec 5.5 & Table 4:\u00a0 I see that only the address pool has a low threshold event.\u00a0 There is no text describing what this means\u00a0 or how to handle it.\u00a0 Also, why does only the address pool need the low threshold event and not the other resources?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-12-13 13:44:45-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-01 06:01:15-08:00",
    "text": "\u00a0  Prior to logging any events, the NAT device MUST send the template of \u00a0  the record to the collector to advertise the format of the data \u00a0  record that it is using to send the events.\u00a0 The templates can be \u00a0  exchanged as frequently as required given the reliability of the \u00a0  connection.\u00a0 There SHOULD be a configurable timer for controlling the \u00a0  template refresh.\u00a0 The IPFIX template management is described in \u00a0  detail in Section 8 of [ RFC7011 ].\u00a0  Not sure what these sentence add (except maybe the last one), as it's part of the IPFIX specs. It's even confusing: what if the IPFIX specs in this document are not inline with the  RFC7011  specs (we could debate: he templates can be exchanged as frequently as required given the reliability of the connection) ? Do you need more that: MUST follow the IPFIX specs? Btw, I have not seen this sentence. The closest one is:  \u00a0  This document assumes that the NAT device will use the existing IPFIX \u00a0  framework to send the log events to the collector.  However, even if not clearly mentioned, I believe your goal is to specify information elements and related encoding, and no specific \"export protocol\" (IPFIX or syslog). Is that right? If yes, then you probably want: \u00a0  if the export protocol is IPFIX, this draft MUST follow the IPFIX specs [ RFC7011 ] Kind of obvious I admit. However, right now, your draft is not clear: a little bit of rewritten IPFIX specs, but not all and no clear link to  RFC7011 What does the following SHOULD want to say: \u00a0  However, the information that is logged \u00a0  SHOULD be the same irrespective of what kind of encoding scheme is \u00a0  used.  - I agree with Jari's DISCUSS. You have some semantic for these \"events\". What if some of the fields are not present. What is the consequence on the implied semantic. For an example, look at  RFC 5476 :  https://tools.ietf.org/html/rfc5476#section-6.5",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-02-22 13:16:26-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-01 01:37:44-08:00",
    "text": "Thanks for this document. I will recommend its publication as an RFC shortly, after we complete the following discussion: Paul's Gen-ART review comments should be looked at and responded to. I'm going to raise one particular issue that in my view needs fixing. The language at the beginning of Section 5.6 gives some room for flexibility in what IEs to include in specific implementations, but it isn't clear how that relates to the mandatory/optional information provided in later tables. Can you clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-20 04:41:48-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-01 04:45:46-08:00",
    "text": "(1) This document has been on the go for 6 years and was a WG document for a while before behave closed. In all that time did anybody consider whether or not we ought define different modes of logging, with different privacy implications, as suggested e.g. in Kathleen's comments - one could have a normal/default mode that's typically used and more privacy friendly, and an \"I might be under attack\" mode that's more intrusive but useful in such situations? If not, why was that not considered given that CGN logging can be very intrusive and is open to some forms of abuse? (Note that I'm not asserting that such modes absolutely need to be visible in the RFC, I'm asking was that considered.) (2) In an overall system that uses this kind of logging, how would one control the duration for which events are stored? Would or should that need to be visible in this e.g. in a template? I figure the answer is probably no, but just wanted to check in case we ought be defining an IE for \"max. retention duration\" here or something similar that might be needed e.g. if different cross-border requirements applied to CGN boxes in different jurisdictions using one log service. (This is only a discuss because if it were missing, it might be hard to introduce later.)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-12-14 20:04:07-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-29 19:32:26-08:00",
    "text": "* Section 5.6.7.5 The rationale for making the sourceIPv6 address mandatory and\u00a0 sourceIPv4 address not mandatory for NAT64s is not clear to me. I am assuming the translator is reassembling packets to meet the REQ-14 \"Received Fragment Out of Order\" behavior of  RFC4787 . In this case the fragmented packets could be received from either direction, right? A fragmented return packet from the IPv4 domain can cause this issue and in this case the source IPv4 address would be useful to have.",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-08-11 07:25:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-11 04:52:37-07:00",
    "text": "Thanks for the solid work on this document, for the most part, I found it clear and easy to parse. In Section 1, I see the following:  Each ROA contains a set of IP prefixes, and an AS number of \u00a0  an AS authorized to originate all the IP prefixes in the set \u00a0  [ RFC6482 ]. While I have some idea of what this means - it's confusing and I believe will cause confusion on the part of other readers.\u00a0 It's confusing to the point where I'm not even sure exactly what the wording should be, but reading that, an AS number of an AS doesn't seem right at all. Let's discuss and see if we can find a way to come to text on this section that is less confusing. Thanks Andrew",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-01-21 12:48:36-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 15:08:19-08:00",
    "text": "(1) This document describes several methods to determine the status of a  tunnel (in \u00a73), none of which \"provide a \"fast failover\" solution when used  alone, but can be used together with the mechanism described in Section 4\"  (\u00a71).\u00a0 \u00a73 also says this: \u00a0  An implementation may support any combination of the methods \u00a0  described in this section and provide a network operator with control \u00a0  to choose which one to use in the particular deployment. While \u00a73.1 is clear in the fact that it is not a requirement for all  downstream PEs to use the same mechanism, there are no guidelines to aid the  operator to chose which mechanism to use.\u00a0 Some cases may be obvious (e.g.  \u00a73.1.3 applies to tunnels of a specific type), but others are not.\u00a0 I would  like to see deployment considerations related to the advantages/disadvantages  that each method may have in specific situations (including their possible  combination). (2) The BFD Discriminator Attribute has a very narrow application in this document when compared to the potential other uses given the extensibility possibilities related to bootstrapping BFD.\u00a0 I have serious concerns about  the attribute being defined in this document, amongst a series of other  mechanisms. (2a) The tunnel can be monitored without the new BGP Attribute (assuming  proper configuration of course).\u00a0 Why is that option is not even mentioned in  the document?\u00a0   In fact, the document recommends deleting the BFD session if the Attribute is not present.\u00a0 Why is that recommendation in place, and what are the cases when it can not be followed? (2b) The fact that BFD monitoring can be achieved without the new attribute makes me think that the bootstrapping of BFD using BGP would be better served  in a document produced by the BFD WG.\u00a0 One of the editors has expressed the  same opinion [1] [2].\u00a0 Has a discussion taken place in the BFD WG (or at least  with the Chairs) about this work?\u00a0 Why was it not taken up there? [1]  https://mailarchive.ietf.org/arch/msg/rtg-bfd/T1jVpgyXuPatTpuD_wA0JC3CT1c/ [2]  https://tools.ietf.org/wg/bess/minutes?item=minutes-96-bess.html",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-23 16:52:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-14 16:51:00-08:00",
    "text": "Let's talk about what the requirements are for consistency across PEs in the algorithm for selecting the Primary Upstream PE.\u00a0 Section 4 notes that \"all the PEs of that MVPN [are required] to follow the same UMH selection procedure\", but leaves the option of non-revertive behavior as something that \"MAY also be supported by an implementation\", without requirement for consistency across all PEs.\u00a0 It seems to me that if some PEs use non-revertive behavior and others do not, then they will disagree as to which PE is the Primary (or active) PE in some cases, which seems to conflict with the initial guidance that all PEs needed to pick the same one.\u00a0 Is it perhaps that the PEs need to agree on which PE is to be advertised as Primary but not necessarily to actually be using that one for traffic?\u00a0 Or am I missing something?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-08-14 10:50:20-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-31 15:48:59-07:00",
    "text": "As compared to  RFC5988 , there are some non-backwards-compatible syntax changes in this new document that can hamper interoperability between new implementations and old ones. These changes should at least be called out explicitly, and guidance given to maximize chances of interop with  RFC5988  implementations. See comments, below, for details.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-08-17 05:43:34-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 15:23:20-07:00",
    "text": "Document:  draft-nottingham-rfc5988bis-07.txt \u00a0  Link applications ought to consider the attack vectors opened by \u00a0  automatically following, trusting, or otherwise using links gathered \u00a0  from HTTP header fields.\u00a0 In particular, Link header fields that use \u00a0  the \"anchor\" parameter to associate a link's context with another \u00a0  resource are to be treated with due caution. I share Alan DeKok's concern here. Say I am a Web browser and I get a link with an anchor tag, what goes in Referer?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-11-15 17:13:08-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-24 21:02:11-07:00",
    "text": "I agree with Ben, Martin, and Mark: the way this document uses /.well-known/ URIs is not consistent with  RFC5785 , section 1.1. It should be understood that /.well-known/ URLs are already a carve-out from overall REST principles regarding the agency of content publishers to assign URLs within their domain as they see fit; and, as such, need non-trivial justification for their use. If there were some fully-defined autodiscovery mechanism that were (non-artificially) constrained in such a way that only a host and port were available, then the use of /.well-known/ URIs would be more understandable. The only constraint hinted at in this document that might have these properties is the use of DNS SRV records. Given that ROLIE is defining a green-field protocol, the use of something as constrained as SRV seems ill-advised, given that the use of NAPTR records would trivially allow retrieval of a complete URL instead of just a host/port combination. The bottom line, however, is that we need to defer specification of a /.well-known/ URL until we completely define a discovery protocol that requires it. The corollary is that we should avoid defining a discovery protocol that requires it.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-10-28 04:33:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-26 04:36:27-07:00",
    "text": "This is a useful document and I will be balloting \"Yes\" once the following small issues are resolved/discussed (some of these come from Martin's ARTART review): 1) 7.4.\u00a0 The \"rolie:property\" Extension Point \u00a0  urn:ietf:params:rolie:property:content-id\u00a0 The \"value\" attribute of \u00a0 \u00a0 \u00a0 this property is a text representation of an identifier pertaining \u00a0 \u00a0 \u00a0 to or extracted from the content referenced by the \"src\" attribute \u00a0 \u00a0 \u00a0 of the entry's atom:content element. Maybe it is just me, but I can't figure out what is the syntax of this field. Can you provide a reference or at least give an example? 2) From Martin's review: Section 5.5 prohibits the use of GET on \"/\".\u00a0 This prohibits use of the resource for other purposes.\u00a0 It seems reasonable to accept POST messages as defined in  RFC 6546 , but this requirement is overly strict (and further entrenches the violation of  RFC 7320 ).\u00a0 If, for instance, the server operator wishes to provide HTML in response to a GET request to \"/\", this would prohibit that.\u00a0 The requirement to return 404 if  RFC 6546  is not supported is worse; not supporting  RFC 6546  might be a choice that a deployment makes to avoid the need to reserve \"/\" for that protocol. Alexey: The text in -12 is an improvement, but I think it is still confusing. Maybe mention something along the lines of Martin's suggestion for the case when  RFC 6546  is not supported (or at least not followed as far as the \"/\" resource is concerned). 5.5.\u00a0 / (forward slash) Resource URL \u00a0  If the \"/\" resource is unsupported, then a request for this resource \u00a0  MAY be handled as deemed appropriate by the server. Nit: You haven't expressed any requirement on implementations here, so use of MAY does not seem appropriate. What are you actually suggesting here? 3) I think some of the text in 6.1.2 is misleading (or I might be wrong): \u00a0  Based on  RFC5005  section 3 [ RFC5005 ], link \u00a0  elements SHOULD be included in all Feeds to support paging using the \u00a0  following link relation types: \u00a0  o\u00a0 \"first\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the furthest preceding page of the \u00a0 \u00a0 \u00a0 Feed. \u00a0  o\u00a0 \"last\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the furthest following page of the \u00a0 \u00a0 \u00a0 Feed. \u00a0  o\u00a0 \"previous\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the immediately preceding page of \u00a0 \u00a0 \u00a0 the Feed. \u00a0  o\u00a0 \"next\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the immediately following page of \u00a0 \u00a0 \u00a0 the Feed. Original definitions of these link relations don't include the word \"page\". I should double check with Mark Nottigham, but I think they reference the next/previous, first/last entry, not page. (And a page may contain several entries.) If I am correct, I don't think it is Ok to redefine meaning of existing link relations the way you do. 4) In Section 8.3: \u00a0  Registration in the ROLIE URN Parameters registry is via the \u00a0  Specification Required policy [ RFC8126 ].\u00a0 Designated Expert reviews \u00a0  should be routed through the MILE WG mailing list.\u00a0 Failing this, the \u00a0  Designated Expert will be assigned by the IESG. As other people already pointed out, the last 2 sentences are confusing. Are you trying to say that registration requests must be sent to the MILE mailing list or that they must be reviewed there? This is actually significant for IANA workflow. One possibility is that all requests are sent to the MILE mailing list and then the designated expert forwards approved requests to IANA. In this case if a Designated Expert misses a request, IANA wouldn't even know that the requester is waiting for the Designated Expert. Another possibility is for all requests to be submitted to IANA directly, then IANA can track them. IANA might either forward requests to the MILE mailing list or require that all request being submitted to the MILE mailing list first before being sent to IANA. So please clarify.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-11-16 04:22:29-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-28 04:33:17-07:00",
    "text": "This is a useful document and I will be balloting \"Yes\" once the following small issues are resolved/discussed (some of these come from Martin's ARTART review): 1) [Addressed in the latest revision] 2) [Addressed in the latest revision] 3) I think some of the text in 6.1.2 is misleading (or I might be wrong): \u00a0  Based on  RFC5005  section 3 [ RFC5005 ], link \u00a0  elements SHOULD be included in all Feeds to support paging using the \u00a0  following link relation types: \u00a0  o\u00a0 \"first\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the furthest preceding page of the \u00a0 \u00a0 \u00a0 Feed. \u00a0  o\u00a0 \"last\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the furthest following page of the \u00a0 \u00a0 \u00a0 Feed. \u00a0  o\u00a0 \"previous\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the immediately preceding page of \u00a0 \u00a0 \u00a0 the Feed. \u00a0  o\u00a0 \"next\" - Indicates that the href attribute value of the link \u00a0 \u00a0 \u00a0 identifies a resource URI for the immediately following page of \u00a0 \u00a0 \u00a0 the Feed. Original definitions of these link relations don't include the word \"page\". I should double check with Mark Nottigham, but I think they reference the next/previous, first/last entry, not page. (And a page may contain several entries.) If I am correct, I don't think it is Ok to redefine meaning of existing link relations the way you do. 4) [Addressed in the latest revision]",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-11-15 17:13:27-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-24 19:10:39-07:00",
    "text": "-5.1.3: I don't think Martin's\u00a0 ART-ART review concern (and Mark's support) about the\u00a0 .well-known URL registration has been fully resolved. While version 11 removed some of the well-known registrations, it still leaves the one.\u00a0 Mark pointed out that  RFC 5785  offers explicit guidance that .well-known URLs are intended to offer site-wide policy or metadata, and are not intended for general information retrieval, or to establish a namespace.\u00a0 This usage seems to me to be exactly the sort of thing that the RFC advises against. I recognize that security information is important, but I don't understand why it's discovery needs to be fundamentally different than for other stuff on using ATOM. I'm willing to be convinced, but if there's been a convincing argument so far I've missed it. I'm not sure what to make of the second paragraph. It says DNS SRV can be used to determine the host and port. Is the expectation that people can just do that without further specification, or that someone could specify it in the future? The former is generally not true. If the intent is the latter, please clarify that in the text.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-12-13 08:27:39-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 23:52:17-07:00",
    "text": "Thanks for the work done on defining this mechanism! I think it's quite useful, and I plan to ballot \"Yes\" as soon as the minor but important issue below is fixed. \u00a76.1: >\u00a0 Status:\u00a0 standard My reading of  RFC 3864  does not allow Experimental RFCs to register HTTP header fields as \"Status: Standard.\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-11-10 13:33:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 09:30:15-07:00",
    "text": "This should be a trivial discuss to resolve, but affects interoperability so is still balloted as such.\u00a0 In Section 3.1: \u00a0  o\u00a0 \"validated-certificate-chain\": the value is the certificate chain \u00a0 \u00a0 \u00a0 as constructed by the UA during certificate chain verification. \u00a0 \u00a0 \u00a0 (This may differ from the value of the \"served-certificate-chain\" \u00a0 \u00a0 \u00a0 key.)\u00a0 The value is provided as an array of strings, which MUST \u00a0 \u00a0 \u00a0 appear in the order matching the chain that the UA validated; each \u00a0 \u00a0 \u00a0 string in the array is the Privacy-Enhanced Mail (PEM) \u00a0 \u00a0 \u00a0 representation of each X.509 certificate as described in \u00a0 \u00a0 \u00a0 [ RFC7468 ]. This needs to say whether the end-entity certificate appears first or last (that is, without assuming what order the UA's chain-validation code uses). I believe we usually say something like \"the first certificate in the chain represents the end-entity certificate being verified\".",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-12-20 12:53:53-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 16:12:07-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4579 This generally seems like a sound mechanism, but I believe there are some points here that are sufficiently unclear they might create interop problems,s o I am balloting DISCUSS. Most importantly, this document just says you support CT, but that creates a potential interop problem if say 6962-tris had a different way of delivering CT information or a different syntax. I'm not saying you need a version here, but you need to indicate that it's not forward-looking. Also, see below. DETAIL S 2.4. >\u00a0 \u00a0 \u00a0 beginning an HTTP conversation over the TLS channel. >\u00a0   >\u00a0 \u00a0 \u00a0 If a connection to a Known Expect-CT Host violates the UA's CT policy >\u00a0 \u00a0 \u00a0 (i.e., the connection is not CT-qualified), and if the Known Expect- >\u00a0 \u00a0 \u00a0 CT Host's Expect-CT metadata indicates an \"enforce\" configuration, >\u00a0 \u00a0 \u00a0 the UA MUST treat the CT compliance failure as an error. Is this supposed to be a hard failure, as with HSTS. If not, how does it interact with HSTS's hard failure reqs. S 3.1. >\u00a0 \u00a0 \u00a0 \u00a0  (This may differ from the value of the \"served-certificate-chain\" >\u00a0 \u00a0 \u00a0 \u00a0  key.)\u00a0 The value is provided as an array of strings, which MUST >\u00a0 \u00a0 \u00a0 \u00a0  appear in the order matching the chain that the UA validated; each >\u00a0 \u00a0 \u00a0 \u00a0  string in the array is the Privacy-Enhanced Mail (PEM) >\u00a0 \u00a0 \u00a0 \u00a0  representation of each X.509 certificate as described in >\u00a0 \u00a0 \u00a0 \u00a0  [ RFC7468 ]. What happens if you try to construct multiple paths? S 3.1. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 does not have or does not trust the public key of the log from >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 which the SCT was issued), \"valid\" (indicating that the UA >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 successfully validated the SCT as described in Section 5.2 of >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC6962 ] or Section 8.2.3 of [ I-D.ietf-trans-rfc6962-bis ]), or >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"invalid\" (indicating that the SCT validation failed because >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 of, e.g., a bad signature). Is \"invalid\" anything other than the specific cases listed above?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-22 01:30:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 06:38:35-07:00",
    "text": "Section 4.1: \u00a0  The API server endpoint MUST be accessed using HTTP over TLS (HTTPS) \u00a0  and SHOULD be served on port 443 [ RFC2818 ]. I have another reason than Roman to discuss this particular sentence. First of all what is the intention of which HTTP version should be supported here?  And which protocol are the port 443 you are recommending, TCP, UDP or SCTP? This also relates to HTTP/3 as it is getting close to being published, we can expect that in the future maybe people would like to upgrade to HTTP/3. Already now I am wondering if the written allow for HTTP/2 over TLS/TCP? Note, that I am mostly commenting from the perspective if you want to be specific that it is HTTP/1.1. over TLS/TCP that is the goal. Then this document should make certain changes in the formulation. If you want to be unspecific and don't think that will hurt interoperability, then another formulation that the current is also needed. Likely also a discussion about how a client will figure out what versions are supported. And maybe one of the ART ADs can help untangle if  RFC 2818  really is the right normative reference here? Or if it should be  RFC 7230  and possibly additional references for HTTP/2?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-06-08 08:08:36-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-06 14:48:48-07:00",
    "text": "Unless I am misinterpreting the language here, there is a disconnect between this document and the architecture document. Sec 2.3 of -architecture says: At minimum, the API MUST provide: (1) the state of captivity and (2) a URI for the Captive Portal Server. But in section 5 user-portal-url is an optional field. Is -architecture actually levying a requirement on the api spec, or the api server? I am also confused by this sentence at the end of section 4.1 about failed authentication: \u201cIt may still be possible for the user to access the network by being redirected to a web portal.\u201d Who is doing the redirecting here? If authentication has failed, how is this redirect authenticated and secure against theft of credentials?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-06-19 05:42:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-09 19:51:18-07:00",
    "text": "\u201cDiscuss discuss\u201d.\u00a0 Section 4 says \u201cThe API server endpoint MUST be accessed using HTTP over TLS (HTTPS) and SHOULD be served on port 443 [ RFC2818 ].\u201d\u00a0 There is also various guidance on verifying the API server identity and access to revocation and time resources.\u00a0 However, the way I read the definition of the \u201cCaptive Portal API Server\u201d per Section 2 and per Figure 1 of  draft-ietf-capport-architecture , the API server is logically different than the service at the user-portal-url URL (i.e., Web Portal Server in the architecture).\u00a0  Section 7.1 helpfully points out \u201cInformation passed between a client and a Captive Portal system may include a user's personal information, such as a full name and credit card details.\u00a0 Therefore, it is important that Captive Portal API Servers do not allow access to the Captive Portal API over unencrypted sessions.\u201d\u00a0 The first sentence is makes sense, but the second, while true, doesn\u2019t follow the first for me.\u00a0 PII and credit card information would be the kind of input you would provide to the _Web Portal Server_ not the Captive Portal API (of course both are part of the overall Captive Portal system).\u00a0 I feel there is missing guidance roughly on the order of the user-portal-url \u201cprovides the URL of a web portal _that MUST be accessed over TLS_ with which a user can interact.\u201d (and the venue-info-url SHOULD use TLS too).\u00a0  Both this draft and  draft-ietf-capport-rfc7710bis-07  are fundamentally providing pointers to other resources.\u00a0 Would it be out of scope for this document to place restrictions on what the API is capable of pointing to?\u00a0 If not here, then where?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-05-23 10:43:57-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 13:24:36-07:00",
    "text": "(1) This first point is a cross-document DISCUSS.\u00a0 In short, the assumptions in this document about what an MCC is responsible for are not in line with the corresponding IGP drafts for OSPF [1][2] and IS-IS [3].\u00a0 This misalignment must be resolved before any of these documents are published. [Note: I'll start a thread with the corresponding WGS, Authors, Shepherds, Chairs and ADs.\u00a0 Let's please discuss this point there.] This document uses the following definition in \u00a72: \"We call \"MPLS Control Plane Client (MCC)\" any control plane entity installing forwarding entries in the MPLS data plane.\u00a0 IGPs with SR extensions...are examples of MCCs.\"\u00a0  The focus of the IGP drafts is on the transport of the SR information, and not on other functions (see below).\u00a0 Which component is responsible for what is the point that needs clarification -- either in this document, the IGP drafts, or both. These are some specific cases: (1.1) \u00a72.4 (Mapping a SID Index to an MPLS label): \"The following rules MUST be applied by the MCC when calculating the MPLS label value corresponding the SID index value \"I\".\"\u00a0 There's nothing in the IGP extension documents that point at this set of rules, and only a passing reference in the OSPF documents about outgoing labels.\u00a0  (1.2) \u00a72.5 (Incoming Label Collision) also assumes more functions from an MCC than what the IGP documents do.\u00a0 For example: \"Within an MCC, apply tie-breaking rules to select one FEC only and assign the label to it.\" (1.3) \u00a72.8 also expects work by the IGPs: \"the MCC is responsible for downloading the correct label value to FIB\"...in this case not just calculating the label, but installing it in the FIB. (1.4) \u00a72.10.1: \"The method by which the MCC on router \"R0\" determines that PUSH or CONTINUE operation must be applied using the SID \"Si\" is beyond the scope of this document. An example of a method to determine the SID \"Si\" for PUSH operation is the case where IS-IS [ I-D.ietf-isis-segment-routing-extensions ]...\" Note that the IS-IS draft (or the OSPF ones, for that matter) don't talk about how to determine the operation -- if that is out of scope of this document, then where is it specified? (1.5) From \u00a72: \u00a0  An implementation SHOULD check that an IGP node-SID is not associated \u00a0  with a prefix that is owned by more than one router within the same \u00a0  routing domain. If so, it SHOULD NOT use this Node-SID, MAY use \u00a0  another one if available, and SHOULD log an error. rfc8402  reads (\u00a73.2): \"An IGP Node-SID MUST NOT be associated with a prefix that is owned by more than one router within the same routing domain.\"\u00a0 The text above is not in line with that (MUST NOT vs SHOULD).\u00a0 Also, how can \"SHOULD check\" be Normatively enforced?\u00a0  Both sentences above seem to be trying to specify a behavior for the IGPs.\u00a0  [1]  https://tools.ietf.org/html/draft-ietf-ospf-segment-routing-extensions [2]  https://tools.ietf.org/html/draft-ietf-ospf-ospfv3-segment-routing-extensions [3]  https://tools.ietf.org/html/draft-ietf-isis-segment-routing-extensions \u00a0  (2) \u00a72.5.1: According to \u00a72.5, a \"tie-breaking rule MUST be deterministic\".\u00a0 However, the specification of the default rules are not: the first step uses the administrative distance, but the specification says that \"the FEC types are ordered using the default administrative distance ordering defined by the implementation\"...and later that the \"user SHOULD ensure that the same administrative distance preference is used on all routers\".\u00a0 The combination of different implementations and the lack of an absolute requirement to ensure consistency can easily be non-deterministic.\u00a0  This point is related to the text in \u00a72.6 which talks about how \"the ingress node MUST resolve\" collisions the same way.\u00a0 Because of the lack of an absolute requirement for consistency, this \"MUST\" doesn't guarantee the same result. Also related is this text in \u00a72.5.1: \"All routers in a routing domain SHOULD use the same tie-breaking rules to maximize forwarding consistency.\"\u00a0 When would all routers not use the same rules?\u00a0 It seems to me that forwarding consistency is very important and would want to be maximized all the time.\u00a0 IOW, why not use MUST? I'm making this point a DISCUSS item because it is directly related to the ability of multiple implementations to interoperate.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-22 21:33:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 15:03:47-07:00",
    "text": "(pro forma) Six authors is more than five, which per  RFC 7322  may require discussion. I have a few questions about whether we need to have more stringent or more specific requirements listed. In Section 2: \u00a0  An implementation SHOULD check that an IGP node-SID is not associated \u00a0  with a prefix that is owned by more than one router within the same \u00a0  routing domain. If so, it SHOULD NOT use this Node-SID, MAY use \u00a0  another one if available, and SHOULD log an error. While it's not entirely clear to me that we need to mandate checking (the \"SHOULD check\"), I have a hard time understanding why we would allow a known-bad SID to be used (\"SHOULD NOT use this Node-SID\"). Shouldn't that be a \"MUST NOT\", since using it could break the SR abstraction? In Section 2.5: \u00a0  5. The remaining FECs with the default algorithm (see the \u00a0 \u00a0 \u00a0 specification of prefix-SID algorithm [ RFC8402 ]) are installed in \u00a0 \u00a0 \u00a0 the FIB natively, such as pure IP entries in case of Prefix FEC, \u00a0 \u00a0 \u00a0 without any incoming labels corresponding to their SIDs. The \u00a0 \u00a0 \u00a0 remaining FECs with a non-zero algorithm are not installed in the \u00a0 \u00a0 \u00a0 FIB. I didn't really find where in  RFC 8402  we assigned numerical values to the prefix-SID algorithms, such that \"non-zero algorithm\" was well-defined.\u00a0 Should I be looking somewhere else for this? In Section 2.5.1: I left several notes in the COMMENT section, but I think I can summarize the point to \"it seems like we are defining a mapping from attributes of a given FEC/description to a byte string and applying an ordering to that byte string.\u00a0 But we don't fully specify how all the bits are encoded in that byte string, and it looks like we can end up with byte strings of a different length, so the comparison rule is not necessarily clear in that case.\"\u00a0 This seems fairly related to Alvaro's point (2). In Appendix A.1 \u00a0 \u00a0 \u00a0  | Local IGP SID allocated dynamically by R2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  for its \"north\" adjacency to R3: 9001 | \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  for its \"north\" adjacency to R3: 9003 | \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  for its \"south\" adjacency to R3: 9002 | \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  for its \"south\" adjacency to R3: 9003 | 9003 is duplicated for different adjacencies?\u00a0 Isn't that a strongly disrecommended scenario?",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2019-04-10 12:35:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-09 14:07:35-07:00",
    "text": "I didn't see a fix/response to one of Sasha's identified items in his RTG Dir review: - 1.\u00a0 \u00a0 The text in Section 1 states \u201cAn implementation MAY check that an IGP node-SID is not associated with a prefix that is owned by more than one router within the same routing domain, If so, it SHOULD NOT use this Node-SID, MAY use another one if available, and SHOULD log an error\u201d. Sasha suggested MAY/s/SHOULD or MUST,\u00a0 saying this aligns with Section 3.2/RFC8402, which uses the wording \"MUST NOT\" be used by another router. I agree with Sasha, to align, it would be a \"MUST\", so why the softer requirement? Also, how does an implementation \"check\"? Wouldn't it be simply \"An implementation MUST ensure that an..\"? Or the operator (NMS) needs to ensure (e.g.  RFC8402  says typically allocated by policy of the operator)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 17:14:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 19:53:14-07:00",
    "text": "I'm not sure I understand how the examples are consistent with the main specification, so let's please discuss it to either un-confuse me or fix the document. Section 3.9 seems to say that the oldest (source or redundant) text at the mixer takes priority when there is text from more than one source waiting to be sent, but the examples in Section 3.21 seem to show (e.g.) text received from A at time 20400 that is to be sent as redundancy, being sent after text from B received at time 20500 (sent as primary). Is the intent that if there is any primary text, the oldest primary text is sent first, and only if there is no outstanding primary text do we consider the redundant text? In a related vein, Section 3.10 says that a packet is sent when (among other things) \"330 ms has passed since already transmitted text was queued for transmission as redundant text\".\u00a0 But that doesn't say anything about the timer being reset by subsequent transmission or queuing of redundant text, so I'm not sure how in the Section 3.21 example, we say that transmitting B1 and B2 as redundancy was planned as 330 ms after packet 105 -- the original B2 was sent in packet 104, so shouldn't the 330ms start from packet 104's transmission?\u00a0 (The stated time for this seems to match 330ms after 104, so maybe the \"105\" is just a typo?) I also left a note in the comment that there's a remark about \"lower security level\" in Section 3.19 that's not really accurate; we should resolve that in some manner before the document proceeds.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-06-17 07:36:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-17 07:36:24-07:00",
    "text": "This memo is defining a RTP payload for JPEG XS that is not publicly available. This hampers the review of the memo, specially when it is defining terminologies which ask me to look a the specifications. This concerns has also been raised by other ADs. was this document made available during the work in the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-06-17 07:37:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-17 07:36:43-07:00",
    "text": "This memo is defining a RTP payload for JPEG XS that is not publicly available. This hampers the review of the memo, specially when it is defining terminologies which ask me to look a the specifications. This concerns has also been raised by other ADs. Was this document made available during the work in the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-07-20 08:26:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-17 07:37:10-07:00",
    "text": "This memo is defining a RTP payload for JPEG XS that is not publicly available. This hampers the review of the memo, specially when it is defining terminologies which ask me to look at the specifications. This concerns has also been raised by other ADs. Was this document made available during the work in the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-09-01 08:57:23-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 16:20:04-07:00",
    "text": "\u00a0 \u00a0 \u00a0  A.\u00a0 Recursive resolvers at sites using ' home.arpa .'\u00a0 MUST \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  transparently support DNSSEC queries: queries for DNSSEC \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  records and queries with the DO bit set ([ RFC4035 ] section \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3.2.1).\u00a0 While validation is not required, it is strongly \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  encouraged: a caching recursive resolver that does not \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  validate answers that can be validated may cache invalid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  data.\u00a0 This in turn will prevent validating stub resolvers \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  from successfully validating answers. I don't understand the rationale for this requirement. As I understand it from this document, stuff ending in  home.arpa  cannot be DNSSEC validated, so what's it the business of this document to levy the requirement on sites which support  home.arpa  that they do anything with DNSSEC at all.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-08-30 08:21:35-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-29 12:46:57-07:00",
    "text": "Thanks for your work on this draft!\u00a0 The SecDir review raised a few important points I'd like to discuss that should be easy to resolve.\u00a0 The first is adding in privacy considerations in his comments for the Security considerations section posted here for convenience (but a response to his full thread might be best): There are also some privacy issues associated to leaking names outside the homenet boundaries. For example daniel_smith.home.arpa reveal the identity of the member of the homenet, my_ipad.home.arpa reveals the devices you own, the application.  home.arpa  may also used in larger environment such as corporate / private. going from one to the other may also leak such information.  The leak can be from the homenet to the outside world in which case one neeed to control the queries sent. But in intruder (or guest) may also access the homenet and proceed to discovery of the names.  As a result even though homenet is believe to be a trusted environment, care should be considered while publishing under the  home.arpa . as well as whose the information is accessible to.\u00a0   They might be collision as well.  myprinter.home.arpa  may be found in various environments, and upon discovery you may also - in this example - print confidential information to that printer.  In some case you may not even be aware, for example, if your printing information failed home, and is re-activated once you are in another environment.\u00a0  As information may be sensitive it may be encrypted using IPsec DTLS as described by dprive for both authentication and confidentiality.  When the trust anchor is configured in the resolver, these must be able to roll-over the key and should follows the requirements for DNSSEC validators. if it is impossible for a resolver to see the difference between an attack and a re-key we are in trouble.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-08-30 14:10:19-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 12:10:37-07:00",
    "text": "1: Section 4.\u00a0 Domain Name Reservation Considerations, Subsection 4 If I'm a recursive server and I am configured \"with a delegation to an authoritative server for that particular homenet\u2019s instance of the domain \u2019 home.arpa .\u2019.\" then I have a local zone containing \" home.arpa \u00a0  IN\u00a0  NS\u00a0  \". Unless I'm really confused, this means that I have to make myself authoritative for .arpa, which will a: break everything else in .arpa, and b: will (correctly!) be DNSSEC bogus to validating stubs. (See also #5). Perhaps you mean that there should be something like (BINDism): zone \" home.arpa \" { \ttype forward; \tforwarders { 192.0.2.1; 192.0.2.2; }; }; This possibility only came to me after much thought, and I do not think that it could be described as \"a delegation\". I also do not think that this is a standard / well defined behavior. 2: Section 4.\u00a0 Domain Name Reservation Considerations, Subsection 4 \"Caching resolvers conforming to this specification MUST support DNSSEC queries.\" This is a MUST, so it's important to understand, but I don't understand what it actually means.\u00a0 What is a \"DNSSEC query\"? It is just one with the DO bit? It is one looking for a DS / RRSIG / similar as the qtype? I don't know what this means, so I don't know if it applies to me / what I should do. 3: \"Unless configured otherwise, recursive resolvers and DNS proxies MUST behave as described in Locally Served Zones ([ RFC6303 ] Section 3).\u00a0 That is, queries for domains that are subdomains of \u2019 home.arpa .\u2019 MUST NOT be forwarded, with one important exception: ...\"  This says that I must not forward for *domains* that are *subdomains* of  home.arpa . The example shows a lookup for NS for ' home.arpa ', so presumably this is actually talking about subdomains of  home.arpa .\u00a0 So, I have no idea what to do for lookups within  home.arpa  itself -- what do I do with query for the A record for  printer.home.arpa?  It is simply a name within  home.arpa ; I have no way of knowing if it is a subdomain of  home.arpa  but it certainly isn't a domain that is a subdomain of  home.arpa  (because there are only three label, not four).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-06-27 07:38:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-24 22:04:11-07:00",
    "text": "Thanks for everyone who worked to get this document out the door. I found it to be well-organized and easy to read. --------------------------------------------------------------------------- This is a process discuss for Roman to handle, and I plan to clear it during the IESG formal telechat. This document is intended for BCP status. It has a normative reference to  RFC 8017 , which is an informational document. Checking the last call text ( https://datatracker.ietf.org/doc/draft-ietf-oauth-jwt-bcp/edit/lastcalltext/ ), there is no mention of  RFC 8017 , nor does  RFC 8017  appear in the downref registry ( https://datatracker.ietf.org/doc/downref/ ). Thanks to  RFC 8067 , we are not required to run this document through IETF LC again (and, given that  RFC 8017 's predecessor,  RFC 3447 , is in the registry, we probably don't want to). However, we'll need to minute that the point was raised and addressed. There is also at least one additional requirement imposed by section 2 of  RFC 8067  that needs to be satisfied (see the last sentence in that section).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-18 18:43:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-24 16:19:58-07:00",
    "text": "Thank you for assembling this document; it will be very valuable to the community.\u00a0 I intend to ballot Yes once the following items are resolved: Section 2.6 notes: \u00a0  Previous versions of the JSON format such as the obsoleted [ RFC7159 ] \u00a0  allowed several different character encodings: UTF-8, UTF-16 and UTF- \u00a0  32.\u00a0 This is not the case anymore, with the latest standard [ RFC8259 ] \u00a0  only allowing UTF-8.\u00a0 [...] The actual situation is a bit more subtle than this text makes it seem; interoperable JSON can only use non-UTF-8 with explicit mutual prearrangement in a closed ecosystem.\u00a0 So, while this statement is true for Internet JWT usage, it may not be true for *all* JWT usage. (I do see that in Section 3.7 of this document we do mandate UTF-8 for JWT, which makes things unambiguous, even if this text here is not correct.) Section 3.2 notes: \u00a0  JWT libraries SHOULD NOT generate JWTs using \"none\" unless explicitly \u00a0  requested to do by the caller. I couldn't find anywhere where we have matching guidance about \"SHOULD NOT consume JWTs using 'none' unless explicitly requested\"; this seems important enough to get called out explicitly.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-01-31 07:34:15-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-30 11:40:58-08:00",
    "text": "I failed to notice that version 13 section 5.2 adds a new IANA registry with no registration policy. This is a post IETF LC change as a result of the opsdir review.  I don't think that registry is needed, and prefer it to be removed. If the authors feel strongly that it is needed, then it needs a registration policy. Given the (potentially fragile) consensus about the IANA action taken by this draft prior to the addition of section 5.2, I think that this would require a repeated IETF last call.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-02-02 07:32:38-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-01 15:29:10-08:00",
    "text": "er RFC 3969, SIP URI parameters and their values can only be defined in standards track RFCs.So why isn't this one?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-09-18 00:32:42-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-01 21:59:49-07:00",
    "text": "Two things are incorrect and need fixing: ---- In Section 4, you have \"tel\" and \"TYPE\", and \"property\" and \"parameter\" reversed in the explanation about the \"main\" parameter value.\u00a0 The sentence is also confusingly worded.\u00a0 Try this (and see also my comments on this bit, below): NEW \u00a0  This document adds a new parameter value called \"main\" to the \u00a0  \"TYPE\" parameter of the \"tel\" property. END ---- In Section 6, there are problems in the MIME structure in the examples (figures 16 and 17). 1. The XML content should be indented at least as much as the SIP headers, so you should either make sure that all XML lines are indented at least 6 characters, or you should make the SIP headers be indented only by 3. 2. There should not be a blank line between the Content-Type and Content-Length headers. 3. There should not be a blank line after each boundary line; the part headers should start immediately, as the first blank line ends the headers. 4. There should be a blank line between the Content-Disposition header and the XML content; that blank line ends the part headers and signals the start of the part body. 5. The intermediate boundary lines should not have the trailing \"--\"; that's reserved for the ending boundary.\u00a0 The intermediates should all be \"--boundary1\". 6. Figure 17 is missing the ending boundary, \"--boundary1--\", at the very end of the figure.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-09-18 09:13:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-01 16:47:46-07:00",
    "text": "I've two things I'd like to chat about. (Note: I'm not trying here to insist on my preferred outcome, but I would like to have the discussion or else be pointed at where the WG  already did that.) (1) section 3: You say these MAY be used.\u00a0 I'm not sure that's a good option.\u00a0 I think the data minimisation recommendations argued for in  RFC6973  and RFC7258  would argue to add a MUST NOT. For example, saying that these additional data MUST NOT be sent in any non-emergency call without explicit user permission on a per-call basis or something similar? I have to admit I'm nervous that defining all of these may mean that some UA somewhere starts sending some of them in other calls without asking. A restriction along those lines would also be more in line with webrtc too perhaps. But maybe this was discussed in the WG, having considered those privacy issues - was it? Either way, would adding such a \"MUST NOT except if...\" be a good plan?\u00a0 4.3.4 is a good example of the kind of thing I'd not want easily emitted in a call. (2) I'd like to (perhaps briefly) argue that the registries here should require more than expert review. Extensibility in dealing with what will inevitably be highly privacy sensitive data structures that are vulnerable to misuse once registered seems to perhaps call for a more stringent registration regime. The document itself also argues (in 4.3.7) that adding new kinds of data here can be counter productive for emergency call handling, so being more conservative in what we add seems unusually correct here. I'd like to suggest we require standards track for extensions. The following very recent -00 draft [1] makes some related arguments (but of course has no standing in the IETF so is just offered as a way to avoid repeating some arguments, not as an appeal to authority.) \u00a0  [1]  https://tools.ietf.org/html/draft-nottingham-transport-metadata-impact-00",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-10-04 14:59:43-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-18 09:13:10-07:00",
    "text": "I've two things I'd like to chat about. (Note: I'm not trying here to insist on my preferred outcome, but I would like to have the discussion or else be pointed at where the WG  already did that.) (1) section 3: You say these MAY be used.\u00a0 I'm not sure that's a good option.\u00a0 I think the data minimisation recommendations argued for in  RFC6973  and RFC7258  would argue to add a MUST NOT. For example, saying that these additional data MUST NOT be sent in any non-emergency call without explicit user permission on a per-call basis or something similar? I have to admit I'm nervous that defining all of these may mean that some UA somewhere starts sending some of them in other calls without asking. A restriction along those lines would also be more in line with webrtc too perhaps. But maybe this was discussed in the WG, having considered those privacy issues - was it? Either way, would adding such a \"MUST NOT except if...\" be a good plan?\u00a0 4.3.4 is a good example of the kind of thing I'd not want easily emitted in a call. (2) cleared",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-05-09 21:56:59-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-04 14:12:09-07:00",
    "text": "Peter Yee's Gen-ART review raised this issue which I agree with. Can this be defined in a more clear fashion? Or is there already a definition somewhere else that I had not seen? Page 5, section 4.2, 2nd paragraph, 1st sentence: The sentence states: \"Being part of the Router CAPABILITY TLV, the node administrative tag sub-TLV MUST be reasonably small and stable.\"\u00a0 If you're going to make this a MUST, you've got to at least give a definition of \"reasonably small\" and perhaps even \"stable\" in the context of this specification.\u00a0 As it stands, there's no test for whether the MUST is enforceable or understandable between parties.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-10-30 07:25:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-25 09:16:28-07:00",
    "text": "Thank you for your work on this document.\u00a0 I have a number of serious concerns - but they all amount to fixing up your references and slight restructuring\u00a0 for clarity and reuse. 1) In Sec 3.1, the reference is system-id to represent the device or\u00a0 node.[ I-D.ietf-spring-sr-yang ] I believe that should be  \"typedef router-id { \u00a0 \u00a0 \u00a0  type yang:dotted-quad; \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0  \"A 32-bit number in the dotted quad format assigned to each \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 router. This number uniquely identifies the router within \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 an Autonomous System.\"; \u00a0 \u00a0  }\" from draft-ietf-rtgwg-routing-types. Certainly \"[ I-D.ietf-spring-sr-yang ]\" is NOT an informative reference with such a dependency. I see that this document actually redefines router-id, instead of using it as part of the included import from  import ietf-routing-types { \u00a0  prefix rt; \u00a0 } On p.27, I see \"leaf system-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type rt:router-id; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"System ID assigned to this node.\"; \u00a0 \u00a0 \u00a0 \u00a0 }\" so it is using the routing-yang-types, but renaming it as system-id, there. Consistency isn't just the hobgoblin of little minds - it's actually useful. In choice to-location, again \"case system-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 leaf system-id-location { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type router-id; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"System id location\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"System ID\";\" using the locally defined router-id and renaming it instead of using rt:router-id. 2) On p. 13 & 14, there are many identities associated with time and time-stamps.\u00a0 I cannot believe that the best way to handle these is by having them as part of an OAM model!\u00a0  At a minimum, they should be defined as a separate module and then included, even if it is in the same draft.\u00a0 Then they will be available for reuse elsewhere. 3) This is extending [ I-D.ietf-i2rs-yang-network-topo ] - I do not believe this should be merely an informative reference. 4) I cannot tell if  I-D.ietf-rtgwg-ni-model  is informative or normative; it is not referenced in the draft - though there are fields that are labeled NI without adequate description. 5) [ I-D.ietf-rtgwg-routing-types ] is not an informative reference.\u00a0 Its module is imported and used.\u00a0 It must be normative. 6) [ I-D.ietf-spring-sr-yang ] is listed as an informative reference, but if it were actually used as described, it would need to be normative. Instead, I believe this can be removed as a reference.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-10-30 08:21:18-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-30 07:25:05-07:00",
    "text": "I took a quick look through version -15 and it looks like it addresses almost all of my serious Discuss points. The only Discuss-worthy point is (c) below.\u00a0 I have a few more points related to the changes that were made; they are just comments & listed here to be with the original points. For version 15: a) In Sec 3.1,\u00a0 it still says  \" o\u00a0 Router-id to represent the device or node. \u00a0 \u00a0 \u00a0 [ I-D.ietf-spring-sr-yang ]\" but [I-D.ietf.spring-sr-yang] has nothing to do with the router-id b) In Section 4, thanks for adding urn:ietf:params:xml:ns:yang:ietf-lime-common-types - but could it be a meaningful and accurate name like \u00a0  ietf-lime-time-types or ietf-time-types\u00a0 (Benoit would know best structure)\u00a0 that clearly  shows its intended scope for reuse and please fix the description for it too. c)\u00a0 [ I-D.ietf-rtgwg-ni-model ] is still listed as informative, but the model defined in there is imported \"import ietf-network-instance { \u00a0 \u00a0 prefix ni; \u00a0 }\"\u00a0  It needs to be normative d)  I-D.ietf-spring-sr-yang  is still listed as informative - but not really correctly used as a reference. ================= Thank you for your work on this document.\u00a0 I have a number of serious concerns - but they all amount to fixing up your references and slight restructuring\u00a0 for clarity and reuse. 1) In Sec 3.1, the reference is system-id to represent the device or\u00a0 node.[ I-D.ietf-spring-sr-yang ] I believe that should be  \"typedef router-id { \u00a0 \u00a0 \u00a0  type yang:dotted-quad; \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0  \"A 32-bit number in the dotted quad format assigned to each \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 router. This number uniquely identifies the router within \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 an Autonomous System.\"; \u00a0 \u00a0  }\" from draft-ietf-rtgwg-routing-types. Certainly \"[ I-D.ietf-spring-sr-yang ]\" is NOT an informative reference with such a dependency. I see that this document actually redefines router-id, instead of using it as part of the included import from  import ietf-routing-types { \u00a0  prefix rt; \u00a0 } On p.27, I see \"leaf system-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type rt:router-id; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"System ID assigned to this node.\"; \u00a0 \u00a0 \u00a0 \u00a0 }\" so it is using the routing-yang-types, but renaming it as system-id, there. Consistency isn't just the hobgoblin of little minds - it's actually useful. In choice to-location, again \"case system-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 leaf system-id-location { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type router-id; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"System id location\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"System ID\";\" using the locally defined router-id and renaming it instead of using rt:router-id. 2) On p. 13 & 14, there are many identities associated with time and time-stamps.\u00a0 I cannot believe that the best way to handle these is by having them as part of an OAM model!\u00a0  At a minimum, they should be defined as a separate module and then included, even if it is in the same draft.\u00a0 Then they will be available for reuse elsewhere. 3) This is extending [ I-D.ietf-i2rs-yang-network-topo ] - I do not believe this should be merely an informative reference. 4) I cannot tell if  I-D.ietf-rtgwg-ni-model  is informative or normative; it is not referenced in the draft - though there are fields that are labeled NI without adequate description. 5) [ I-D.ietf-rtgwg-routing-types ] is not an informative reference.\u00a0 Its module is imported and used.\u00a0 It must be normative. 6) [ I-D.ietf-spring-sr-yang ] is listed as an informative reference, but if it were actually used as described, it would need to be normative. Instead, I believe this can be removed as a reference.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-09-08 08:33:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-08 00:44:27-07:00",
    "text": "Let's chat about IANA Considerations, which I think needs some work.\u00a0 Fortunately, I think these all have straightforward fixes. First, the easy stuff: \"Required parameters\" and \"Optional parameters\" should probably not be \"None\"; see  RFC 6838  Section 5.6. The \"Security Considerations\" field simply states what the payload is.\u00a0 I think, at a minimum, this should specifically refer to the Security Considerations in the referenced document.\u00a0 Moreover, note this from  RFC 6838 : \u00a0  o\u00a0 Any security analysis MUST state whether or not they employ such \u00a0 \u00a0 \u00a0 \"active content\"; if they do, they MUST state what steps have been \u00a0 \u00a0 \u00a0 taken, or MUST be taken by applications of the media type, to \u00a0 \u00a0 \u00a0 protect users of the media type from harm. This required content is absent.\u00a0 In the referenced document I don't see any evidence that there's active content (i.e., the payload is not directly executable as far as I can tell), but it would be a good idea to say so, at least because the BCP requires it. Finally, as this is a standards action with IETF consensus, the change controller is supposed to be the IETF. Separately, the double \"SHOULD\" in bullet #1 of Section 6 leaves the possibility that an implementation does neither of those things.\u00a0 Is that what you intended to allow?\u00a0 If not, some revised guidance here is probably in order.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-12-03 05:55:45-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-02 21:48:24-08:00",
    "text": "I'm lost on something here, so I'd like to discuss it briefly so that I understand what I'm looking at. I'm not expecting this to be hard to resolve. In this text \u00a0  However, the three \u00a0  SSRCs comprising each participant will almost certainly see identical \u00a0  reception quality, since they are co-located. \u00a0   it sounds like you're describing a heuristic (\"will almost certainly see\", so if you use a reporting group, the results will be close enough).  In other places in the document, like \u00a0  Since they are co-located, every \u00a0  SSRC in the RTCP reporting group will have an identical view of the \u00a0  network conditions, and see the same lost packets, jitter, etc.\u00a0  \u00a0   it sounds like you're saying they'll always have an identical view (\"will see\", with no qualification).  Which is it? As a comment, but on exactly the second text so I'll include it here, is \"see the same lost packets\" telling me that more than one SSRC is sending \"the same lost packets\"? If this was \"see (roughly) the same loss rate\", I wouldn't be surprised, but I'm confused here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-08 14:55:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-07 23:56:41-07:00",
    "text": "I support Roman's Discuss points. Sorry to provide so many new substantive points here -- I was only able to follow the email discussions in the WG (and not completely, even) but not to actually read the document earlier.\u00a0 It hopefully goes without saying, but the goal is to make sure we get it right, since it's going to be an important pillar for the future of things; I'm happy to see that this is advancing. (1) I don't think that the claim in Section 4.2 that \"[b]oth RPC and TLS have peer and user authentication\" is correct, at least given my understanding of those terms.\u00a0 Using this document's definition of RPC \"peer authentication\" as analogous to TLS server authentication, the functionality that TLS calls \"mutual authentication\" is more analogous to RPC client authentication, though it is sometimes repurposed for use for user authentication, with concommittant bad user experience.\u00a0 This analogy does not seem critical to the mechanisms of this document, so I believe we should remove or modify it. (2) The mention of using RPCSEC_GSS with GSS channel bindings to TLS is quite underspecified.\u00a0 Unfortunately, this is largely the fault of other specifications, but we have to deal with the fallout.\u00a0 On first glance (but subject to further clarification/change), it seems like we should: - Say what channel binding type (from the registry that  RFC 5929  registered \u00a0 stuff in) is to be used -- just citing 5929 doesn't help, since it \u00a0 mentions three different ones (none of which are really right for TLS 1.3, \u00a0 see below) - provide a mechanism for the peers to determine whether GSS channel binding \u00a0 to TLS is to be used.\u00a0 (As discussed in \u00a0  draft-ietf-kitten-channel-bound-flag , the current state of things GSS is \u00a0 that if one party supplies channel bindings but the other doesn't, the \u00a0 security context negotiation fails, which is usually not the best for \u00a0 usability.)\u00a0 Since this is a greenfield GSS-API application, the simplest \u00a0 thing by far is to just say \"always provide the channel bindings when \u00a0 using RPCSEC_GSS over TLS\".\u00a0 It's even the more secure option, too :) - give more detail about what value to provide as the 'chan_binding' input \u00a0 to the GSS security context negotiation.\u00a0 We currently reference  RFC 5929 , \u00a0 that defines three different channel-binding values, but none of them are \u00a0 really usable for TLS 1.3 (as discussed in \u00a0  draft-ietf-kitten-tls-channel-bindings-for-tls13 ).\u00a0 Most likely this will \u00a0 mean using the tls-exporter value from that document. (3) Please check this reference in Section 5.1.1: \u00a0  Reverse-direction operation occurs only on connected transports such \u00a0  as TCP (see Section 2 of [ RFC8166 ]).\u00a0 [...] It seems likely that  RFC 8167  was intended... (4) I don't think it's particularly safe to suggest that non-protected RPCs should be exchanged on the same 5-tuple that just terminated a DTLS association, since neither DTLS nor UDP provide in-order delivery, so there is ambiguity as to whether a datagram should be interpreted as DTLS protected or not.\u00a0 This is particularly problematic in the face of the three different DTLS record headers (DTLSPlaintext, DTLSCiphertext(full), and DTLSCiphertext(minimal)) with something like 10 or 11 different possible values for the first byte that might be in flight, with limited \"magic number\" verification fields available.\u00a0 I think I need some input from the TSV ADs about what the options are, though -- while a cooling-off period might be fine if an ephemeral port is in use, it seems problematic for cases where fixed port numbers are used for both source and destination. (5) Section 5.2.1 requires that: \u00a0  *\u00a0 Implementations SHOULD indicate their trusted Certification \u00a0 \u00a0 \u00a0 Authorities (CAs). Indicate to whom? (6) The usage of  RFC 6125  procedures in Section 5.2.1 seems counter to its intent.\u00a0 Specifically, we seem to be saying \"the peer gave me a cert, let me look through it to see if it has something I like\", but  RFC 6125 's intended procedure is \"I know a list of names that I expect to see at least one of in the cert; these rules tell me whether the cert is valid for any such name\". It's not entirely clear that it's appropriate for this document to specify how the client has to order its list of names by type (per Section 6.1 of RFC 6125 's \"The client constructs a list of acceptable reference identifiers\"), which the bit about \"The following precedence applies\" seems to be doing.\u00a0 To the extent that we give a recommendation to use DNS-ID instead of CN-ID, and ipAddress SAN instead of CN-ID, that's already covered by  RFC 6125 ; it would be okay for us to say \"use DNS-ID or iPAddress SAN\", though.\u00a0 (Roman's comment about \"why not a normative MUST\" for putting IP addresses in the iPAddress SAN is related, and if we don't have a compelling reason to allow the flexibility, we should limit to the specific DNS-ID/iPAddress options without allowing CN-ID.) (6.1) Note additionally that if wildcard certificates are to be used,  RFC 6125  requires the application protocol specification to give details on how they are to be used. (6.2)  RFC 6125 's procedures are (facially, at least) only valid for TLS server authentication.\u00a0 We also want to authenticate TLS clients, so we should say whether we expect the same procedures to be used, or what procedures should be used (even just as how it differs from the  RFC 6125 ones).\u00a0 Of particular note is that, since the server is not initiating the network connection, it is unlikely to have a preconceived notion of what client identity to expect, and is likely limited to attempting to extract something from the certificate.\u00a0 In this scenario a precedence list (as I complained about being inconsistent with  RFC 6125  above) would be appropriate. (7) Section 5.2.1 uses the phrase \"renegotiate the TLS session\". Renegotiation is not defined or allowed for TLS 1.3; generally one would need to either remember the presented certificate and re-run the validation process on it or shutdown the TLS connection and make a new one, though in theory one could try to define a mechanism using post-handshake authentication.\u00a0 (I don't recommend the latter, though; it's not widely implemented/used.) (8) Can we clarify the status of DNSSEC (or DANE) requirements?\u00a0 Section 1 assumes that support for DNSSEC is already available in an RPC implementation, but Section 7.1.1 says that \"Clients [sic] implementors can choose from\" a list of things including DANE TLSA records.\u00a0 Why would we require DNSSEC support but not using the records if they're present? (9) I agree with Roman('s comment) that Sections 5.2.2 and 5.2.4 should give a minimum amount of information to be exposed to the administrator for implementing the trust mode.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-02 17:30:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-08 14:55:42-07:00",
    "text": "Thank you for the updates in the -09; they address all my previous Discuss points (from the -08).\u00a0 Unfortunately, there is one more issue that was introduced in the update and will need to be resolved: While I appreciate the efforts to find appropriate external specifications to reference, I do not believe that an id-kp-rpcTLSServer certificate is a Resource Certificate per  RFC 6487  -- that specification deals with the RPKI (Resource PKI) used to authenticate IP address assignment, but the RPKI is an entirely separate PKI than the Internet PKI (\"PKIX\").\u00a0 I think we should drop that sentence entirely.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-10-20 07:04:31-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-25 13:55:18-07:00",
    "text": "This presumably a trivial fix but I think it's important enough to be a DISCUSS: I think the document needs some discussion of the security properties of TLS1.3 early data over TCP, if only to refer to Section 8 of  RFC 8446  (replay) and mention that it is not forward-secure, unlike the rest of the payload.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:00:15-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-06 20:24:10-07:00",
    "text": "** Despite Section 5.0 stating that only TLS v1.3+ can be used, there are two references to TLS v1.2 mechanisms: -- Section 5.0. Per \u201cImplementations MUST support certificate-based mutual authentication.\u00a0 Support for TLS-PSK mutual authentication [ RFC4279 ] is OPTIONAL\u201d.\u00a0 Shouldn\u2019t Section 2.2.2 or 4.2.11 of  RFC8446  be used instead?  -- Section 5.2.4.\u00a0 The token binding mechanism suggested here,  RFC8471 , only applies to TLS v1.2.\u00a0 The expired  draft-ietf-tokbind-tls13  provides the TLS v1.3 mechanism. ** Section 7.4.\u00a0 Per \u201cWhen using AUTH_NULL or AUTH_SYS, both peers are required to have DNS TLSA records and certificate material \u2026\u201d, what is \u201ccertificate materials\u201d?\u00a0 Can this guidance please be clarified (and perhaps related to the options specified in Section 5.2).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-18 22:25:55-07:00",
    "text": "My assessment of the IETF consensus is that this document should not have an Updates: relationship with  RFC 8446 , and accordingly it cannot be approved until that (and the corresponding prose) is removed.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-02-23 11:49:01-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-23 11:41:33-08:00",
    "text": " simple thing: the document header should state that it updates RFC 8446.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-07 10:39:25-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-23 11:49:01-08:00",
    "text": "pdate: if the consensus is that the document does not update RFC8446, then the Abstract and Introduction ought not to say otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-02-16 15:58:24-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 12:49:15-08:00",
    "text": "This should be easy: What's the \"Subject\" field in Section 5.1?\u00a0 It doesn't appear to be a column in the current registry ( https://www.iana.org/assignments/channel-binding-types/channel-binding-types.xhtml ).",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-05-04 06:56:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-26 13:53:24-07:00",
    "text": "I am pulling in Ben's DISCUSS here: \u00a0 \u00a0 My assessment of the IETF consensus is that this document should not have an Updates: relationship with  RFC 8446 , and accordingly it cannot be approved until that (and the corresponding prose) is removed. Additionally, I also believe that this change does not really warrant an Updates: clause, as  RFC 8446  simple states that an extension offering channel binding is currently (at the time of writing) not available. In other words, the core TLS 1.3 specification is not updated. One does not require to implement this document to implement a properly up to date TLS 1.3 core specification.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-05 06:18:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-28 13:43:48-08:00",
    "text": "** On the issue of what behavior is MTI, Section 5.2 of Section  RFC5801  and Section of  RFC5802  say: (a)\u00a0  'tls-unique' is the default channel binding type for any application \u00a0  that doesn't specify one. (b)\u00a0  Servers MUST implement the \"tls-unique\" [ RFC5929 ] channel binding \u00a0  type, if they implement any channel binding. Section 3 of this document says: (c) As \"tls-unique\" is not defined for TLS 1.3 (and greater), this \u00a0  document updates [ RFC5801 ], [ RFC5802 ], and [ RFC7677 ] to use \"tls- \u00a0  exporter\" as the default channel binding over TLS 1.3 (and greater). \u00a0  Note that this document does not change the default channel binding \u00a0  for SCRAM mechanisms over TLS 1.2 [ RFC5246 ], which is still \"tls- \u00a0  unique\". No problem with the guidance in (c).\u00a0 Without specific citations being made, I\u2019m inferring that (c) is intended to \u201cupdate\u201d/clarify (a) in a TLS 1.3 context.\u00a0  To the issue of MTI, (c) is silent on the guidance in (b).\u00a0 Since \u201ctls-unique\u201d is not defined for TLS 1.3, how would an implementer comply in the case of a server that is TLS 1.3 only?\u00a0 Should this document make a statement to the effect of \u201ctls-exporter\u201d is MTI for any servers implementing TLS 1.3?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-07-05 17:37:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-07 06:29:00-07:00",
    "text": "Table 3 has \"None\" in all the cells corresponding to SF and SFC OAM functions. But then Sections 6.4.1 through 6.4.4 discuss several tools that can be used to provide some of these functions. I understand that the text about the table says \"Table 3 below is not exhaustive,\" but still it seems misleading to say \"None\" in the table when there are, in fact, tools available that are discussed just a few paragraphs later.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-07 11:07:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-05 22:31:51-07:00",
    "text": "I think this is pretty well done.\u00a0 I had little trouble following it and this is my first foray into the realm of SFC. One item I'd like to discuss though.\u00a0 From Section 3.1.1: \u201cOn one end of the spectrum, one might argue that an SF is sufficiently available if the service node (physical or virtual) hosting the SF is available and is functional.\u00a0 On the other end of the spectrum, one might argue that the SF's availability can only be concluded if the packet, after passing through the SF, was examined and it was verified that the packet did indeed get the expected service.\u201d I found this a bit surprising, especially given the critical nature of many SF functions.\u00a0 Why would it ever be the case that, say, \u201cwell, the hypervisor says the VM is up, so the SF is up\u201d is a safe conclusion?\u00a0 For such a critical component, I would expect only some more complete test is necessary to conclude availability of the SF.\u00a0 Shouldn't we at least be pushing implementers toward the latter end of that spectrum?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-08-23 05:57:14-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-04 16:16:35-07:00",
    "text": "Why omit sha256 (in particular Alg = 8) from this?\u00a0 That seems like a quite bad plan and *not* a BCP given our current knowledge of hash functions.",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-08-11 17:10:38-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-05 21:25:22-07:00",
    "text": "This should be\u00a0 a very easy DISCUSS to resolve. In section 4, the second \"Note\", I urge you to reconsider using the term \"crap-ware\", and words \"stupid\", \"crap\".. these make this document look and sound very poor for an IETF published document. Knowing the intelligence of the authors I can't see how this was thought of as passable and made it through WGLC irrespective of how we collectively view these devices. Perhaps such words like \"protocol naive\" are better placed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-03 10:50:22-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-28 15:25:34-07:00",
    "text": "Let's discuss whether we should have content in this document discussing the relationship between this new certificate extension and the extension defined by  RFC 8226 .\u00a0 In paticular, whether it is permitted/expected for both extensions to appear in the same certificate, and whether any specific processing is required in that case.\u00a0 (If no such processing is specified, we could end up with interesting edge cases where a given PASSporT is handled differently depending on which extension(s) are supported by the recipient.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-05-16 05:31:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-21 03:23:54-07:00",
    "text": "This spec is tackling a hard problem, (machines doing what humans do to classify identifiers), and as a result there are some tricky bits here. That inherently hard problem has thrown up a few things I'd like to discuss (though the 1st one is easy:-)... (1) section 5: this says code points MUST be 4 hex digits. What is s/w supposed to do if it sees only 2 hex digits? Should it ignore the range or char element or fail to process the entire LGR document? I think the same issue applies to other uses of 2119 language as well, (e.g. \"MUST be treated as an error at the end of p19), so I'd recommend you state some kind of general rule if you can. (2) 5.2: when and not-when etc seem to me to allow for infinitely baroque representations of useless things like:      \t\t200D             What is parsing s/w supposed to do with structures like that? For example, how would you handle the likes of this or more convoluted but equivalent structures which could be delivered by accident or deliberately?\u00a0 I think the response to this discuss point needs to either be a) all such constructs are automatically detectable and here's why, or else b) here's how s/w can handle that (without crashing or looping forever). Note that I don't think that the \"MUST be rejected\" at the end of 6.1 provides an answer to this point.\u00a0 (But if you do, please argue that.) (3) 6.3.4: While recursion is said to be disallowed, the \"for which the complete definition has not been seen\" is pretty odd for an XML specification, as it means that you need a full ordering for the elements in the document (or at least within the\u00a0 element).\u00a0 That means if some editor decodes from disk and then encodes to disk, you need to be sure that the order is preserved or else you break the \"has been seen\" constraint. (And if you do that, then you're allowing rules to mutually refer to one another, which brings us back to discuss point 2.) 7.4 maybe has a similar issue. I think for this you could simply state up front that these XML documents MUST NOT be re-ordered during editing. (Or else add some kind of attribute to help with ordering which seems ickky.) (4) section 12: I don't think this is at all sufficient. Missing aspects include: Imprecise LGRs could result in registration of identifiers that are unexpected in many other protocols, leading to new vulnerabilities; LGRs could be deliberately manipulated so as to create such imprecision, and if I could feed one such to a registry (e.g. via some nice friendly looking git repo) then I could exploit the vuln later for fun and profit - that seems to call for some interoperable form of data integrity and origin authentication (is the lager WG doing that?) and lastly (for now), the XML language defined here is very flexible as noted earlier - I would expect there to be many implementation bugs in new code that attempts to parse this language. So I think the security considerations needs to be re-done really.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-05-23 12:46:27-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-16 05:31:24-07:00",
    "text": "Thanks for the changes in -12. I think we're down to one remaining item to discuss. I'll follow up on the earlier email where you answered directly to this point. (4) section 12: I don't think this is at all sufficient. Missing aspects include: Imprecise LGRs could result in registration of identifiers that are unexpected in many other protocols, leading to new vulnerabilities; LGRs could be deliberately manipulated so as to create such imprecision, and if I could feed one such to a registry (e.g. via some nice friendly looking git repo) then I could exploit the vuln later for fun and profit - that seems to call for some interoperable form of data integrity and origin authentication (is the lager WG doing that?) and lastly (for now), the XML language defined here is very flexible as noted earlier - I would expect there to be many implementation bugs in new code that attempts to parse this language. So I think the security considerations needs to be re-done really.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-07-11 06:48:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 09:02:10-07:00",
    "text": "1. In \u00a73.2, \u00a0  The following HHIT Suite IDs are defined: \u00a0 \u00a0 \u00a0 \u00a0 HHIT Suite\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Value \u00a0 \u00a0 \u00a0 \u00a0 RESERVED\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 \u00a0 \u00a0 \u00a0 \u00a0 RSA,DSA/SHA-256\u00a0 \u00a0  1\u00a0 \u00a0 [ RFC7401 ] \u00a0 \u00a0 \u00a0 \u00a0 ECDSA/SHA-384\u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 [ RFC7401 ] \u00a0 \u00a0 \u00a0 \u00a0 ECDSA_LOW/SHA-1\u00a0 \u00a0  3\u00a0 \u00a0 [ RFC7401 ] \u00a0 \u00a0 \u00a0 \u00a0 EdDSA/cSHAKE128\u00a0 \u00a0  TBD3 (suggested value 5)\u00a0  (RECOMMENDED) What, exactly, does the notation \"RECOMMENDED\" on the last quoted line mean? AFAICT there's no unambiguous way to parse this. My guess is that it's meant to mean \"this is the suite we think you should use\". Whatever the intended meaning, please elaborate to make the meaning clear. I suggest removing the notation from the table, and providing prose in some appropriate section instead, with \"RECOMMENDED\" if you think the  RFC 2119  keyword is needed. If desired, you could xref that section from the table, although I don't think that's really necessary. This comment also applies to the similar lines in \u00a73.4.1, \u00a73.4.1.1, and \u00a73.4.2. The use in \u00a73.4.1.1 is especially confounding, since the prose right before the table tells us that (all of) \"the following EdDSA curves are required\" (but evidently not REQUIRED)... but only some of the required curves are RECOMMENDED? I definitely have no clue, then, what \"RECOMMENDED\" means in this section.  RFC 2119  basically defines RECOMMENDED as a weaker form of REQUIRED, but that doesn't seem to be how you're using it. Similarly, I have no clue what \"RECOMMENDED\" is meant to mean in its several uses in \u00a78.2 and \u00a78.4. I suggest simply removing it from those sections entirely. (Taken together, this comment covers every use of RECCOMMENDED in the document.)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-07-13 12:06:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 11:29:55-07:00",
    "text": "John raised this in a comment, and I agree with it: Please provide proper guidance for your new registry's designated experts, or let's discuss why you think what's there is sufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-18 18:21:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 19:07:44-07:00",
    "text": "#1 \u00a0  Note that if the zone  hhit.arpa  is ultimately used, some registrar \u00a0  will need to manage this for all HHIT applications. Regardless of what zone is used, someone needs to keep it operational. It might be an attractive target to attack, eg to try and avoid drones being shut down. I would feel much better if this zone was optional, not mandatory. (but if optional, one could also argue maybe not have it at all?) \u00a0  If the HHITs cannot be \u00a0  looked up with services provided by the registrar identified via the \u00a0  embedded hierarchical information or its registration validated by \u00a0  registration attestations messages [drip-authentication], then the \u00a0  HHIT is either fraudulent or revoked/expired. That's quite catastrophic if there is a Registrar/Registry outage. Would all the drones get shot down or would they all be ignored (so they can fly to their terrorism target) #2 As DISCUSS'ED by others,  https://www.iana.org/assignments/hip-parameters/hip-parameters.xhtml#hi-algorithm  does not seem to have a third field for \"status\" to denotate RECOMMENDED, REQUIRED, etc, even though  RFC 7401  creates the registry, uses the terms too but doesn't populate a status field. Perhaps this or another short RFC could do so. Also, 3.4.1 calls this \"Algorithm profiles\" and \"Values\" but the IANA registry calls it \"Algorithm Profile\" (singular) and \"Value\" (singular) #3 Section 3.4.1.1. has a NULL field of variable length ? Or perhaps the slash and pipe symbols on those first and second lines got swapped by accident? #4 \u00a0  The new EdDSA HI uses [ RFC8080 ] for the IPSECKEY RR encoding: \u00a0 \u00a0 \u00a0 Value\u00a0 Description \u00a0 \u00a0 \u00a0 TBD2 (suggested value 4) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  An EdDSA key is present, in the format defined in [ RFC8080 ] I have asked the Expert of this Registry whether they are okay with this entry to the ipseckey-rr-parameters registry. It might be confusing for IKE.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-13 13:02:05-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 12:02:22-07:00",
    "text": "** With updates tag for  RFC7343 , I read the text in Section 3.5.* as providing a generic description of a new ORCHID computation techniques.\u00a0 Other parts of the text describe how to use it for HIT and HHIT.\u00a0 If that interpretation is correct: -- Section 3.5.1.\u00a0  \u00a0  With a 28-bit IPv6 prefix, the \u00a0  remaining 100 bits can be divided in any manner between the \u00a0  additional information (\"Info\"), OGA ID, and the hash output. Since this section is describing a generic ORCHID technique, does this mean one could potentially choose a 0 or 1 bit hash output size?\u00a0 All the provided security analysis is predicated on a 64-bit HIT.\u00a0 What is associated analysis and security considerations for smaller HITs? -- Section 3.5.1. \u00a0  The header content consists \u00a0  of the Prefix, the Additional Information (\"Info\"), and OGA ID (HIT \u00a0  Suite ID).\u00a0  Secondly, the length of the resulting hash is set by sum \u00a0  of the length of the ORCHID header fields.\u00a0  The second sentence is true only if ORCHID setup is according to the DRIP spec: p=28, info=28, OGA-ID=8 to make 64 bits.\u00a0 However, this is a generic update to define an ORCHID.\u00a0 The previous text said that an OGA-ID could be 4 bits \u2013 28+28+4 = 60, so if the \u201cresulting hash should be set by the length of the ORCHID header field\u201d, it would be off by 4 bits. ** Section 4.2 \u00a0  A mapping service (e.g., DNS) MUST provide a trusted (e.g., via \u00a0  DNSSEC [ RFC4034 ]) conversion of the 4-character Manufacturer Code to \u00a0  high-order 58 bits (Prefix | HID) of the HHIT. Can this \u201ctrust\u201d be described in more detail?\u00a0 Section 4.4 makes it a point to say \u201ccryptographically bind all content in the ORCHID through the hashing function.\u00a0 A recipient of a DET that has the underlying HI can directly trust and act on all content in the HHIT\u201d.\u00a0 Here this information is being split.\u00a0 Is the out-of-scope mechanism expected to provide a similar guarantee? ** Section 4.6 \u00a0  The EdDSA25519 HI (Section 3.4) underlying the DET can be used in an \u00a0  84-byte self-proof attestation (timestamp, HHIT, and signature of \u00a0  these) to provide proof of Remote ID ownership (GEN-1 in [ RFC9153 ]). \u00a0  In practice, the Wrapper and Manifest authentication formats \u00a0  (Sections 6.3.3 and 6.3.4 of [drip-authentication]) implicitly \u00a0  provide this self-attestation.\u00a0 A lookup service like DNS can provide \u00a0  the HI and registration proof (GEN-3 in [ RFC9153 ]). \u00a0  Similarly, for Observers without Internet access, a 200-byte offline \u00a0  self-attestation could provide the same Remote ID ownership proof. \u00a0  This attestation would contain the HDA's signing of the UA's HHIT, \u00a0  itself signed by the UA's HI.\u00a0 Only a small cache that contains the \u00a0  HDA's HI/HHIT and HDA meta-data is needed by the Observer.\u00a0 However, \u00a0  such an object would just fit in the ASTM Authentication Message \u00a0  (Section 2.2 of [ RFC9153 ]) with no room for growth.\u00a0 In practice, \u00a0  [drip-authentication] provides this offline self-attestation in two \u00a0  authentication messages: the HDA's certification of the UA's HHIT \u00a0  registration in a Link authentication message whose hash is sent in a \u00a0  Manifest authentication message. I\u2019m having trouble following along on where the guidance for offline verification is described \u2013 who exactly signs what with what key and in what format is this stored.\u00a0 Is this considered in-scope for this document?\u00a0 Given the asserted security properties,  -- I\u2019ll note that  draft-ietf-drip-auth  is an informative reference. -- What exactly needs to be in the offline Observer\u2019s cache?\u00a0 I couldn\u2019t find that in draft-ietf-drip-auth. -- Why is the first sentence in the first paragraph present?\u00a0 It is describing a hypothetical situation that isn\u2019t used in DRIP.\u00a0 Likewise, the first sentence of the second paragraph also seems like a hypothetical using verbs like \u201ccould provide\u201d -- The text reference a lookup service, how does that service an offline Observer?   ** Section 9.\u00a0  \u00a0  Therefore, the HHIT registration and HHIT/HI registration validation \u00a0  is strongly recommended. If validation isn\u2019t done, who are the promised security guarantees of global non-collision possible?\u00a0 Practically, why isn\u2019t this a MUST? ** Section 9.5. \u00a0  The UAS/USS registration \u00a0  process should include registering the DET and MUST reject a \u00a0  collision, forcing the UAS to generate a new HI and thus HHIT and \u00a0  reapplying to the DET registration process. How does a UAS \u201cgenerate a new HI\u201d in the case of a CTA2063A or manufacturer hard-coding the HHIT per Section 3.2 of  draft-ietf-drip-arch-24 ?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-07-14 11:38:10-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 09:01:06-07:00",
    "text": "Apologies for the terse / rushed tone of this ballot - I'm currently traveling and really short on time.  1: \"A mapping service (e.g., DNS) MUST provide a trusted (e.g., via DNSSEC [ RFC4034 ]) conversion of the 4-character Manufacturer Code to high-order 58 bits (Prefix | HID) of the HHIT.\u00a0 Definition of this mapping service is currently out of scope of this document.\" -- this feels really underspecified, especially because it is a MUST. DNSSEC provides channel security, but by itself doesn't provide \"trusted\" data, nor provide a \"conversion\", etc.  Where is the \"trust\" here? (Sec 9 doesn't really answer this) Who is supposed to run this? Even more so, why is this a \"just stick it in the DNS\" type solution (see comment #2).  2: \"Now it should be noted that the 2^64 attempts is for stealing a specific HHIT.\u00a0 Consider a scenario of a street photography company with 1,024 UAs (each with its own HHIT); you'd be happy stealing any one of them.\" This is only true if I want to steal one for this specific street photography company - surely I'd be perfectly happy \"stealing\" any HHIT that works? Doesn't that make it more on the order of (number of units), not 1024? Also, the \"Therefore, the HHIT registration and HHIT/HI registration validation is strongly recommended.\" bit seems underspecified.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-12-01 07:19:54-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-01 01:28:36-08:00",
    "text": "I am concerned about the issue that Russ Housley raised in his Gen-ART review: bad practices in creating the freshness tokens creates a security issue. If this cannot be handled in the way that Russ initially suggested (setting a minimum number of bits) then a proper discussion of the issue and recommendations to avoid the problems need to be included in the security considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-12-20 13:26:43-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-29 18:21:50-08:00",
    "text": "Holding a discuss until the Gen-art conversation on minimum size of the fressness token resolves.\u00a0 Will switch to a yes once that is resolved. https://www.ietf.org/mail-archive/web/gen-art/current/msg13942.html",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-05 07:18:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 10:55:51-08:00",
    "text": "Thank you for the work put into this document. It is easy to read. Please find below a couple of blocking DISCUSS points and some non-blocking COMMENT points and some nits. In addition to my own points, please consider Zhen Caos' INT directorate review at: https://datatracker.ietf.org/doc/review-ietf-dots-server-discovery-11-intdir-lc-cao-2020-10-12/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4 -- Trivial to fix: there is no \"DHCP lease\" for stateless DHCPv6... You should probably rather refer to the information-request refresh time option (section 21.23 of  RFC 8415 ). -- Section 5.1.2 -- I fully second Zhen Cao's review: how will the IPv4-mapped IPv6 address(es) be used? They MUST not appear on the wire and there is a DHCPv4 option to convey the DOTS information. Is it when DHCPv6 is available, no DHCPv4, and only IPv4 connectivity to the DOTS server ? If so, then please clarify the text.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-22 20:26:58-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-18 15:15:16-08:00",
    "text": "These should be quite straightforward to resolve, but do need to be addressed before publication: (1) Section 2.6.4 lists some KEM identifiers and says that \"these algorithms ... are key encapsulation mechanisms using elliptic curve encryption\".\u00a0 But RSAES-KEM is in the list, which is based on RSA encryption, not elliptic-curve encryption.\u00a0 (I note that the example in \u00a72.6.4 has an\u00a0 element, which seems to make it not a terribly useful example for RSAEA-KEM usage.) (2) Section 2.3 also makes this interesting statement: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  That is to say, the verification \u00a0  key is different from and not feasibly derivable from the signing \u00a0  key. This is demonstrably false; e.g., for the Edwards-Curve methods, where \u00a75.1.5 of  RFC 8032  provides a step-by-step procedure for determining the verification key from the signing key.\u00a0 If the statement was reversed (\"signing key is not feasibly derivable from the verification key\"), it would seem unobjectionable.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 11:56:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-22 20:26:58-08:00",
    "text": "Thanks for the updates in the -23 through -25, they include many good fixes.\u00a0 Unfortunately, the changes introduced a new issue, and in reviewing around that I noticed another thing that seems problematic. The XMSS and XMSSMT identifiers listed don't match up with the prose and are hard to match up to FIPS 202, the stated reference for the SHAKE XOF(s).\u00a0 Specifically, FIPS 202 defines *two* XOFs, SHAKE128 and SHAKE256, not the (one) \"SHAKE extensible output function\" mentioned in the prose. The tabulated identifiers include in the second token of the URI anchor both \"shake\" and \"shake256\", which one might presume to indicate SHAKE128 and SHAKE256, respectively, but we should really be more explicit about what the \"shake\" token means (or just switch to \"shake128\"). We definitely need to correct the prose to indicate that there are two XOFs, though. I'm also a bit confused by the options given for 192-bit output sizes. The prose indicates that there should be a \"SHA2 output size\" of 192 bits, but the listed reference for SHA2 ( RFC 6234 ) does not offer a native 192-bit hash function, and if a truncated version of a SHA2 family hash function is desired, we would need to indicate which member of the SHA2 family is to be used prior to truncation.\u00a0 My apologies for not having noticed this previously. (The SHAKE functions, as XOFs, of course have no difficulty producing a 192-bit output, though the security strength of such an offering is low enough that it's unclear whether we actually want to provide that option.)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-07-05 19:34:00-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-29 16:08:30-07:00",
    "text": "* Section 6 has a few errors that need to get fixed before this document goes forward. e.g. It is not clear what a \"192.0.2.0/32\" subnet means especially since the only host shown to be on the subnet 192.0.2.2 cannot obviously fall inside the subnet range. The /32 needs to be replaced with something shorter depending on what the authors/WG intended (say a /24). * RB2 seems to be advertising ES2s IPv4 address 198.51.100.2/32 instead of the prefix of the subnet while RB1 seems to be advertising the the IPv4 prefix of the ES1 subnet. One of these is wrong. Not sure which one is intended. * What is the rationale for using a /112 IPv6 prefix for numbering an IPv6 link with hosts? Things like SLAAC ( RFC4862 ) will not work in such links. Is there a reason the authors want to use a longer than /64? Please read  RFC7421  for advantages of using a /64 instead and to find out what things break if you do not use a /64.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-15 07:27:03-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-13 07:25:18-08:00",
    "text": "Appendix C: this spec and the whatwg web page may or may not be in conflict. I think this may be the first PS that we've produced where that fact finally hits that fan - is that right? If not, then I'll clear as we'll already have decided there's nothing to be done about odd behaviour with \"competing\" specifications for the same thing (that thing being  RFC3986 ). If this is the first time we've gotten to this point, then I think the IESG ought explicitly decide that we are going to live with what we all know is a pretty crap situation where different implementers (web vs. non-web basically) supporting various kinds of URL/URI are liable to end up doing different and potentially non-interoperable things. (There is no action required from the author. For the IESG - we discussed this a couple of years back, but there have been some personnel changes since and I forget if the current set of ADs are or are not up to speed with and ok with this.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-02-02 07:28:42-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-01 22:43:09-08:00",
    "text": "Okay, there's 5 obstains, and at this rate may be more by the telechat. I can take a hint :-)  This is a discuss-discuss; I want to talk about the recent guidance we've given people for this sort of thing, and how we should address work items that were approved well before that guidance was given. Otherwise, I want to regroup with the authors and working group before progressing this further.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-08-05 09:02:27-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 04:36:13-07:00",
    "text": "Julius, Thank you for the work put into this document. I have one DISCUSS and a couple of COMMENTs. One generic comment: is there a need to describe (even in a short format) Babel again? Regards, -\u00e9ric == DISCUSS == -- Section 2.2 -- The 'bug resistance' property of Babel was perhaps learned during the implementation, but, I wonder whether the document may simply state 'robust with respect to bugs', this is quite a strong statement that needs to be backed by facts or proof.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-31 13:51:22-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-16 09:25:58-07:00",
    "text": "I think (at least with the present formulation) we need greater clarity on when the \"it's up to server policy whether to include, but that policy must be the same for all transactions\" elements ( and ) are returned, as at present there seems to be an internal inconsistency in the text.\u00a0 Section 3.5 and 3.6 just talk about including them \"in responses to all 'transform' or billable commands\", but then we have more qualified text such as (but not limited to) in Section 5.2.5 that only has\u00a0 (and its children) included when the\u00a0 has been processed successfully.\u00a0 So, are  and\u00a0 supposed to be included in error responses or not?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-24 05:55:29-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-18 18:09:59-07:00",
    "text": "** There a few easy clarifications that need to be regarding the cardinality of attributes: -- Section 3.1.\u00a0 Is the use of command@name optional?\u00a0 The schema suggests that it is and the text in this section doesn\u2019t making any claims.\u00a0 If blank, how should such a command be processed? -- Section 3.1.\u00a0 If command@name=\u201dcustom\u201d, MUST\u00a0  command@customName be present?\u00a0 If not, what are the processing instructions to a recipient? -- Section 3.1 and 3.8.\u00a0 Can a client send a command@subphase attribute without a command@phase?\u00a0 The schema suggests this is possible and clarifying text provide no guidance.\u00a0 It seems like this should be an error. -- Section 3.4.\u00a0 Can a fee@lang be present without fee@description?\u00a0 The schema suggests it can but the text provides no direction.\u00a0 If this is possible, what should implementers do with a @lang without a @description? ** Section 6.1.\u00a0 This section needs a normative reference to W3C Schema as the format of the blob between the BEGIN and END tags.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-09 12:28:12-07:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 16:55:47-08:00",
    "text": "I may well just be confused about this, but let's discuss and find out. Section 3.3.2 says \"[a]s per  RFC 8505 , a 6LN MUST NOT register its link-local address.\"\u00a0 Which part of  RFC 8505  says this?\u00a0 Section 5.6 thereof seems to enumerate some cases where link-local addresses MUST (not MUST NOT) be registered, and there's not much other discussion of link-local addresses that I saw.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-04-22 11:37:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 15:55:38-08:00",
    "text": "I found this paragraph in Section 3.1 to be hand-wavy: \"Note that this specification allows using different MTUs in different \u00a0  links.\u00a0 If an implementation requires use of the same MTU on every \u00a0  one of its links, and a new node with a smaller MTU is added to the \u00a0  network, a renegotiation of one or more links can occur.\u00a0 In the \u00a0  worst case, the renegotiations could cascade network-wide.\u00a0 In that \u00a0  case, implementers need to assess the impact of such phenomenon.\" What are the consequences of link \"renegotiation\"? If every MTU downgrade results in a storm of messages, that's a bad property. Is the use case where the MTU must be the same on all links an important one? If not, simply requiring hosts to handle this case seems way cleaner.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-06-16 04:14:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-16 04:09:46-07:00",
    "text": "This document seems to have unresolved IANA issues. Holding a DISCUSS until we can confirm on the telechat that a resolution is in progress.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-29 02:12:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-16 04:14:45-07:00",
    "text": "# GEN AD review of  draft-ietf-avtcore-cryptex-06 CC @larseggert Thanks to Linda Dunbar for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/OSDyO_tiu5StDZyyJjwRP-Nvj-M ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS until we can confirm on the telechat that a resolution is in progress.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-19 09:33:18-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 04:28:16-07:00",
    "text": "Thanks for this document. It is clear, and I appreciate reading the rationale of the proposed solution. Just one discuss item: \u00a0  Peers MAY negotiate both Cryptex and the header extension mechanism \u00a0  defined in [ RFC6904 ] via signaling, and if both mechanisms are \u00a0  supported, either one can be used for any given packet.\u00a0 However, if \u00a0  a packet is encrypted with Cryptex, it MUST NOT also use [ RFC6904 ] \u00a0  header extension encryption, and vice versa. Why this complexity? Based on the Section 1, Cryptex is much more preferred. Why allow \"either one can be used for any given packet\" instead of saying if both are negotiated, Cryptex SHOULD be used? Or why not stronger, if both peers support Cryptex,  RFC6904  SHOULD NOT (MUST NOT?) be used?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-07-25 08:02:18-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-14 14:50:53-07:00",
    "text": "I\u2019m having trouble understanding the relationship between this work and SRTP without making assumptions.\u00a0 Section 1.3 notes that there is a design goal to build on top of SRTP and to have simple SRTP interactions.\u00a0 Section 3 also says the design goal is to \u201creuse the existing SRTP framework.\u201d\u00a0 Finally, Section 6.2 and 6.3 says \u201d[t]he encryption (or decryption) procedure is identical to that of [ RFC3711 ] except for the Encrypted Portion of the SRTP packet.\u201d I believe the correct read is that \u201cdo everything from SRTP unless noted as different here\u201d.\u00a0 However, saying \u201cencryption and description procedures\" per Sections 6.2/6.3 doesn\u2019t capture that for me.\u00a0 This leaves open questions about key management, establish and maintaining state for cryptographic contexts, MTI algorithms, etc. The text would benefit from being explicit on what behavior \u201ca=cryptex\u201d behavior reuses from SRTP.\u00a0 I don\u2019t believe that changes any of the expected core mechanics.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-24 09:12:50-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-08 23:48:31-07:00",
    "text": "Thanks to everyone who contributed to this document. I intend to ballot \"yes,\" once the following issue has been resolved: This document defines three modes: \"enforce\", \"testing\", and \"none\". It is intended to work in conjunction with  draft-ietf-uta-smtp-tlsrpt , which shows the use of \"mode: report\" in all of its examples. On a quick survey of hosts I can quickly find publishing MTA-STS records, I find: version: STSv1 mode: testing mx:  aspmx.l.google.com mx: .aspmx.l.google.com max_age: 86400 version: STSv1 mode: report mx:  mx00.emig.gmx.net mx:  mx01.emig.gmx.net max_age: 604800 version: STSv1 mode: report mx:  mx1.comcast.net mx:  mx2.comcast.net max_age: 2592000 version: STSv1 mode: report mx: *.am0.yahoodns.net max_age: 86400 The implementation confusion here appears to be real. Please ensure that draft-ietf-uta-smtp-tlsrpt  and  draft-ietf-uta-mta-sts  agree about valid values for the \"mode\" parameter.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-05-30 17:29:49-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-03 18:14:42-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4010 DETAIL S 3.3. >\u00a0 \u00a0 \u00a0 \u00a0  character '*' as the complete left-most label within the >\u00a0 \u00a0 \u00a0 \u00a0  identifier. >\u00a0   >\u00a0 \u00a0 \u00a0 The certificate MAY be checked for revocation via the Online >\u00a0 \u00a0 \u00a0 Certificate Status Protocol (OCSP) [ RFC6960 ], certificate revocation >\u00a0 \u00a0 \u00a0 lists (CRLs), or some other mechanism. Why is revocation only MAY? S 4. >\u00a0 \u00a0 \u00a0 1.\u00a0 That the recipient MX supports STARTTLS and offers a valid PKIX- >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 based TLS certificate. >\u00a0   >\u00a0 \u00a0 \u00a0 2.\u00a0 That at least one of the policy's \"mx\" patterns matches at least >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 one of the identities presented in the MX's X.509 certificate, as >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 described in \"MX Certificate Validation\". This doesn't seem like quite what you want. Consider the case where the STS policy has: S 5. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 as though it does not have any active policy; see Section 8.3, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Removing MTA-STS\", for use of this mode value. >\u00a0   >\u00a0 \u00a0 \u00a0 When a message fails to deliver due to an \"enforce\" policy, a >\u00a0 \u00a0 \u00a0 compliant MTA MUST NOT permanently fail to deliver messages before >\u00a0 \u00a0 \u00a0 checking for the presence of an updated policy at the Policy Domain. What exactly does this mean? That you have to do HTTPS or just do a new DNS resolution despite the TTL? S 8.2. >\u00a0 \u00a0 \u00a0 to the hosting organization.\u00a0 This can be done either by setting the >\u00a0 \u00a0 \u00a0 \"mta-sts\" record to an IP address or CNAME specified by the hosting >\u00a0 \u00a0 \u00a0 organization and by giving the hosting organization a TLS certificate >\u00a0 \u00a0 \u00a0 which is valid for that host, or by setting up a \"reverse proxy\" >\u00a0 \u00a0 \u00a0 (also known as a \"gateway\") server that serves as the Policy Domain's >\u00a0 \u00a0 \u00a0 policy the policy currently served by the hosting organization. What certificate do I expect in this case?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-05-09 16:30:48-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-05-09 16:27:33-07:00",
    "text": "I apologize, this DISCUSS written in a rush. I'm uncomfortable with the DNS \"reservations\" happening in this document -- it basically reserves the (leftmost) DNS labels _mta-sts (as a TXT record) and mta-sts as a hard-coded name -- I think that this needs to be better documented / in the IANA considerations. I apologize for the lack of detail/lack of actionable content - I couldn't decide between Deferring and balloting DISCUSS - seeing as there are already 2 DISCUSSes I figured the latter - I think I need to think about this, and clearing a DISCUSS is simpler than having the document stuck.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-05-10 07:39:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-05-09 16:30:48-07:00",
    "text": "I apologize, this DISCUSS written in a rush. I'm uncomfortable with the DNS \"reservations\" happening in this document -- it basically reserves the (leftmost) DNS labels _mta-sts (as a TXT record) and mta-sts as a hard-coded name -- I think that this needs to be better documented / in the IANA considerations. I apologize for the lack of detail/lack of actionable content - I couldn't decide between Deferring and balloting DISCUSS -- I decided on DISCUSS because\u00a0 I think I need to think about this, and clearing a DISCUSS is simpler than having the document stuck for a full cycle.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-05-10 07:40:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-05-10 07:39:49-07:00",
    "text": "[ Edit: Could the format of the _mta-sts to be something like: \"_mta-sts.example.com.\u00a0 TXT \"v=STSv2; id=20180114T070707; label=foo\" This would mean that the policy can be fetched from  foo.example.com  - the record *could* specify \"label=mta-sts\" if it liked... ] I apologize, this DISCUSS written in a rush. I'm uncomfortable with the DNS \"reservations\" happening in this document -- it basically reserves the (leftmost) DNS labels _mta-sts (as a TXT record) and mta-sts as a hard-coded name -- I think that this needs to be better documented / in the IANA considerations. I apologize for the lack of detail/lack of actionable content - I couldn't decide between Deferring and balloting DISCUSS -- I decided on DISCUSS because\u00a0 I think I need to think about this, and clearing a DISCUSS is simpler than having the document stuck for a full cycle.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-05-23 08:00:44-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-10 07:40:59-07:00",
    "text": "[ Edit: Could the format of the _mta-sts to be something like: \"_mta-sts.example.com.\u00a0 TXT \"v=STSv2; id=20180114T070707; label=foo\"\u00a0 ? This would mean that the policy can be fetched from  foo.example.com  - the record *could* specify \"label=mta-sts\" if it wanted - this allows this to work without \"reserving\" a DNS label.\u00a0 ] I apologize, this DISCUSS written in a rush. I'm uncomfortable with the DNS \"reservations\" happening in this document -- it basically reserves the (leftmost) DNS labels _mta-sts (as a TXT record) and mta-sts as a hard-coded name -- I think that this needs to be better documented / in the IANA considerations. I apologize for the lack of detail/lack of actionable content - I couldn't decide between Deferring and balloting DISCUSS -- I decided on DISCUSS because\u00a0 I think I need to think about this, and clearing a DISCUSS is simpler than having the document stuck for a full cycle.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-02-06 09:39:32-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-05 10:48:03-08:00",
    "text": "(1) Picking up on a Gen-ART review comment: Section 5.1.7 seems to be aimed at entities other than the operators of DNS privacy services. That is, the \"impact\" seems like it is on third-party entities, but then the \"optimization\" talks about DNS privacy service operators using \"alternative means for traffic monitoring.\" I guess what I don't understand is why the DNS privacy service operators need alternative means, since they still have access to the cleartext. (2) I think Section 6 needs to clarify that it is providing suggestions only on matters relating to the technical operation of DNS privacy services that may be described in DROP policies, and not on any other matters. There are numerous other matters that are typically addressed in privacy statements (e.g., what form of legal process the operator requires to supply data to law enforcement, how the operator handles data about children, etc.). This document should not give the impression that the listed items in the subsections are an exhaustive list, nor should it attempt to offer an exhaustive list. (3) I do not think item #5 in Section 6.1.2 belongs in this document. I don't see how it is within scope for the IETF to be specifying these sorts of best practices.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-06-28 11:44:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-06 09:39:32-08:00",
    "text": "I have added more detail to point #3 below as requested on today's telechat. (1) Picking up on a Gen-ART review comment: Section 5.1.7 seems to be aimed at entities other than the operators of DNS privacy services. That is, the \"impact\" seems like it is on third-party entities, but then the \"optimization\" talks about DNS privacy service operators using \"alternative means for traffic monitoring.\" I guess what I don't understand is why the DNS privacy service operators need alternative means, since they still have access to the cleartext. (2) I think Section 6 needs to clarify that it is providing suggestions only on matters relating to the technical operation of DNS privacy services that may be described in DROP policies, and not on any other matters. There are numerous other matters that are typically addressed in privacy statements (e.g., what form of legal process the operator requires to supply data to law enforcement, how the operator handles data about children, etc.). This document should not give the impression that the listed items in the subsections are an exhaustive list, nor should it attempt to offer an exhaustive list. (3) I do not think item #5 in Section 6.1.2 belongs in this document. I don't see how it is within scope for the IETF to be specifying these sorts of best practices, which are not technical or operational in nature but focus on legal matters and likely require the involvement of lots of lawyers in order to get the provisions written. This section implies that the DROP documents would become legal/compliance documents by nature, which may or may not be a good choice but is not within the remit of the IETF to specify. Also, I think what this section asks for is not the norm today and therefore it seems odd for the IETF to specify a best practice that operators may not have any chance of being able to comply with (e.g., listing specific law enforcement agencies, privacy laws, or countries where data centers will reside and the data will never move from them).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-07-02 06:16:22-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-28 11:44:02-07:00",
    "text": "Trimmed to the one outstanding point from my original DISCUSS: I do not think item #5 in Section 6.1.2 belongs in this document. I don't see how it is within scope for the IETF to be specifying these sorts of best practices, which are not technical or operational in nature but focus on legal matters and likely require the involvement of lots of lawyers in order to get the provisions written. This section implies that the DROP documents would become legal/compliance documents by nature, which may or may not be a good choice but is not within the remit of the IETF to specify. Also, I think what this section asks for is not the norm today and therefore it seems odd for the IETF to specify a best practice that operators may not have any chance of being able to comply with (e.g., listing specific law enforcement agencies, privacy laws, or countries where data centers will reside and the data will never move from them).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-03 15:20:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-03 15:19:55-08:00",
    "text": "This document is trying to make normative references to sections of draft-ietf-dprive-rfc7626-bis  that have not existed since the -01 of that document, with the content having been removed for being too controversial. Do we need to delay processing this document until 7626bis has settled down and it is clear what content we can refer to in that vs. needing to incorporate into this document?\u00a0 (It's unclear that such content would be less controversial in this document than in that one.) Specifically, Section 5.1.2 of this document refers to Section 2.5.3 of that document (\"Rogue Servers\").",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-05 19:30:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-03 15:20:17-08:00",
    "text": "This document is trying to make normative references to sections of draft-ietf-dprive-rfc7626-bis  that have not existed since the -00 of that document, with the content having been removed for being too controversial. Do we need to delay processing this document until 7626bis has settled down and it is clear what content we can refer to in that vs. needing to incorporate into this document?\u00a0 (It's unclear that such content would be less controversial in this document than in that one.) Specifically, Section 5.1.2 of this document refers to Section 2.5.3 of that document (\"Rogue Servers\").",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-27 16:05:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 19:30:17-08:00",
    "text": "[updated to add one discuss point and a comment section] This document is trying to make normative references to sections of draft-ietf-dprive-rfc7626-bis  that have not existed since the -00 of that document, with the content having been removed for being too controversial. Do we need to delay processing this document until 7626bis has settled down and it is clear what content we can refer to in that vs. needing to incorporate into this document?\u00a0 (It's unclear that such content would be less controversial in this document than in that one.) Specifically, Section 5.1.2 of this document refers to Section 2.5.3 of that document (\"Rogue Servers\"). [new discuss point] This is perhaps more a flaw in  RFC 8310  than in this document, but I'd still like to discuss it: in Section 5.1.2 we read that: \u00a0  When using DNS-over-TLS clients that select a 'Strict Privacy' usage \u00a0  profile [ RFC8310 ] (to mitigate the threat of active attack on the \u00a0  client) require the ability to authenticate the DNS server.\u00a0 To \u00a0  enable this, DNS privacy services that offer DNS-over-TLS should \u00a0  provide credentials in the form of either X.509 certificates \u00a0  [ RFC5280 ] or Subject Public Key Info (SPKI) pin sets [ RFC8310 ]. Authenticating the DoT server via X.509 certificate as described here and in RFC 8310  seesm to involve looking for an ADN in the certificate; however, I could not find any discussion of how to know what CA(s) or trust anchors to trust to certify the ADN in a certificate.\u00a0 It's possible that  RFC 8310 's use of \"PKIX Certificate\" is supposed to imply that Web PKI trust anchors are used, but that's not immediately clear.\u00a0 It may be the case that we need to mention provisioning a trust anchor as well as the X.509 certificate information, here.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-04-27 02:19:43-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-07 04:43:02-07:00",
    "text": "Thanks for this document, and sorry for the late discuss, which should hopefully be trivial to fix. \u00a0  Notification (N): 1 bit \u00a0 \u00a0 \u00a0 When set to 1, this bit indicates that the control plane message \u00a0 \u00a0 \u00a0 exchange is only used for notification during protection \u00a0 \u00a0 \u00a0 switching.\u00a0 When set to 0 (default), it indicates that the control \u00a0 \u00a0 \u00a0 plane message exchanges are used for protection-switching \u00a0 \u00a0 \u00a0 purposes.\u00a0 The N bit is only applicable when the LSP Protection \u00a0 \u00a0 \u00a0 Type Flag is set to 0x04 (1:N Protection with Extra- Traffic), \u00a0 \u00a0 \u00a0 0x08 (1+1 Unidirectional Protection), 0x10 (1+1 Bidirectional \u00a0 \u00a0 \u00a0 Protection), or 0x20 (Shared Mesh Protection).\u00a0 If 0x20 (SMP), the \u00a0 \u00a0 \u00a0 N bit MUST be set to 1.\u00a0 The N bit MUST be set to 0 in any other \u00a0 \u00a0 \u00a0 case. I think that the way that this  RFC4872  text has been updated makes this text unclear/ambiguous. Specifically, I think that somebody could reasonably interpret this as saying that the N bit is set to 1 for SMP, and otherwise it must always be set to 0, but I don't think that is the intention.\u00a0 So please can this be clarified. One fix could be to swap the order of the last 2 sentences.\u00a0 E.g., \u00a0 \u00a0 \u00a0 or 0x20 (Shared Mesh Protection).\u00a0 The N bit MUST \u00a0 \u00a0 \u00a0 be set to 0 in any other case. If 0x20 (SMP), the \u00a0 \u00a0 \u00a0 N bit MUST be set to 1. Alternatively, I think that you could possibly just remove the \"If 0x20 (SMP), the N bit MUST be set to 1.\" and instead rely on the text in 5.2/5.3, (perhaps strengthening with  RFC 2119  language if required). Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-04-21 12:59:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-20 22:49:38-07:00",
    "text": "Thanks for this document.\u00a0 Enabling Open-ID and OAUTH with SIP is quite useful. This document specifically calls out single sign-on as a reason to use this mechanism, and SSO has a host of serious security and privacy issues.\u00a0 As those issues are not discussed in the referenced documents, I think they need to be raised here.\u00a0 Recommended usage/configuration to avoid or mitigate the issues would be ideal, but at the very least I think they need to be documented, as it\u2019s clear that implementors are not aware of them or don\u2019t think they\u2019re important enough to worry about.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-05 11:46:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-23 12:25:03-07:00",
    "text": "I support Roman's Discuss. The \"Bearer\" authentication challenge includes the address (or name?) of an authorization server to contact to obtain tokens, as mentioned in multiple places in the document (noted in the COMMENT section).\u00a0 Our experience in the OAuth world has shown that several classes of vulnerabilities are possible when the client blindly attempt to use any provided AS, and that a whitelist of \"allowed\" or \"trusted\" ASes is needed for secure operation.\u00a0 I believe that the same is true for the SIP usage, and we should mention this requirement explicitly. Section 1.2 tries to apply the OAuth confidential/public client distinction to SIP UACs, but it does so in a non-analogous fashion: the OAuth distinction is for the client's ability to protect credentials that identify the client itself; the usage in this document refers to protecting *user* credentials and obtained tokens.\u00a0 I don't think that it's appropriate to invoke the OAuth terminology when using it for a different meaning. Both Public and Confidential OAuth clients are capable of providing the necessary protections for *user* credentials (though they are of course not guaranteed to do so), which leaves me unclear on what the intended requirements actually are. Section 2.3 states that: \u00a0  When a proxy wishes to authenticate a received request, it MUST \u00a0  search the request for Proxy-Authorization header fields with 'realm' \u00a0  parameters that match its realm.\u00a0 It then MUST successfully validate https://tools.ietf.org/html/rfc7235#section-4.4  suggests that it is not expected to have a sequence or list of Proxy-Authorization header fields present in a single request that are intended to be interpreted by different proxies.\u00a0 Is this text compatible with that part of  RFC 7235 ?\u00a0 Furthermore, I didn't find much guidance in 7235 or 3261 about when to include the \"realm\" parameter in Proxy-Authorization; do we want to give any guidance here?\u00a0 (That is to say, I almost didn't find where it was even defined as possible to do so...) I'm also not sure if we're attempting to profile  RFC 6749  and always require a refresh token to be issued, or just have some editorial tweaks to make to avoid suggesting that we do have such a requirement (noted in the COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-05 15:12:45-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-05 11:46:23-07:00",
    "text": "Thanks for the updates in the -14 (and -15); they cover most of my points. Unfortunately, the new security considerations text seems to introduce a problematic recommendation: \u00a0  Because of that, it is critical to make sure that extra security \u00a0  measures be taken to safeguard credentials used for Single Sign-On. \u00a0  Examples of such measures include long passphrase instead of a \u00a0  password, enabling multi-factor factor authentication, and the use of \u00a0  embedded browser when possible, as defined in [ RFC8252 ]. Looking at  RFC 8252  (Section 8.12), it seems to be rather strongly recommending to *not* use an embedded browser, which is the opposite of the apparent recommendation here.\u00a0 Are we missing a word \"avoiding\" or similar? Also, I am not 100% sure my note about refresh tokens was fully addressed; in Section 2.1.1 we see: \u00a0  The refresh token is only used between the UAC and the AS.\u00a0 If the AS \u00a0  provides a refresh token to the UAC, the UAC uses it to request a new \u00a0  access token and refresh token from the AS before the currently used \u00a0  access token expires ([ RFC6749 ], Section 1.5).\u00a0 If the AS does not Is it accurate to say that the refresh token is used \"to request a new access token and refresh token\" (specifically the \"and refresh token\" part)?\u00a0 I know that it is not always returned, but am less sure about whether the semantics always include an (implicit) request for a new one.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-04-28 02:00:54-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-23 06:31:42-07:00",
    "text": "I think these resolution for this is rather straight forward, however the implications of one is going to break deployed implementations.  1. Section 4: This is rather straight forward to resolve but you do have a SIP syntax violation in these rules.  \u00a0 \u00a0 \u00a0  challenge\u00a0 =/\u00a0 (\"Bearer\" LWS bearer-cln *(COMMA bearer-cln)) \u00a0 \u00a0 \u00a0  bearer-cln = realm / scope / authz-server / error / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 auth-param \u00a0 \u00a0 \u00a0  authz-server = \"authz_server\" EQUAL authz-server-value \u00a0 \u00a0 \u00a0  authz-server-value = https-URI \u00a0 \u00a0 \u00a0  realm =  \u00a0 \u00a0 \u00a0  auth-param =  \u00a0 \u00a0 \u00a0  scope =  \u00a0 \u00a0 \u00a0  error =  \u00a0 \u00a0 \u00a0  https-URI =  So  RFC 3261  defines the Challenge construct as:  challenge\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 (\"Digest\" LWS digest-cln *(COMMA digest-cln)) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / other-challenge Where this extension needs to match the syntax of the other-challenge: other-challenge\u00a0 \u00a0  =\u00a0 auth-scheme LWS auth-param \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *(COMMA auth-param) Where we need to look at: auth-param\u00a0 \u00a0 \u00a0 \u00a0 =\u00a0 auth-param-name EQUAL \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ( token / quoted-string ) Please note what is included in the \"token\" rule.  \u00a0 \u00a0 \u00a0 token\u00a0 \u00a0 \u00a0  =\u00a0 1*(alphanum / \"-\" / \".\" / \"!\" / \"%\" / \"*\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \"_\" / \"+\" / \"`\" / \"'\" / \"~\" ) the allowed syntax for https-URI in  RFC 7230  is: \u00a0 \u00a0 https-URI = \"https:\" \"//\" authority path-abempty [ \"?\" query ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ \"#\" fragment ] Which include both \"/\", \"?\" and \"#\" that are not allowed in token. Thus, the URI included in the authz-server-value\u00a0 MUST be converted into a quoted-string matching syntax rule.  2. In addition should not the \"authz_server\" be registered in the  https://www.iana.org/assignments/sip-parameters/sip-parameters.xhtml#sip-parameters-12  registry?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-05 06:11:48-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 08:01:38-07:00",
    "text": "The use of the OpenID ID token appears to be underspecified.\u00a0 Section 1.3 notes the possibility of using it as one of the three possible tokens.\u00a0 However, the SIP procedures in Section 2 makes no note of it, only covering the use of the \u201caccess token\u201d and the \u201crefresh token\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-11-10 23:58:41-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-10 08:27:51-07:00",
    "text": "Section 4.3.3 recommends that ADs generate and exchange extensive logging information, but the document says nothing about securing these logs or limiting the exchange of private or confidential information between the peers. This seems like it needs to be addressed in the BCP.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-11-03 07:40:54-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-10 22:09:12-07:00",
    "text": "(This is related to Alissa's DISCUSS about logging of privacy-sensitive data. But since it's a little different, I'm entering my own DISCUSS.)  In section 4.4 (operations) the bullet on problem notification states that AD2 will inform AD1 of, among other things, the locations of users. Is that intended to be geolocation, or network location? If the former, that's extremely sensitive information, and needs privacy guidelines.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-11-03 10:34:35-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-10 12:48:53-07:00",
    "text": "Thanks for your work on this draft.\u00a0 I'd like to see some text clarifications on security recommendations that should not be difficult to resolve. Section 4.4 - the exchange of supporting information could be sensitive, are there security requirements on the exchange?\u00a0 I don\u2019t see them in this section. Section 6 - For the following text, it would be helpful to see some recommendations: \u00a0  \u201cDRM and Application Accounting, Authorization and Authentication \u00a0  should be the responsibility of the multicast application source \u00a0  provider and/or AD-1. AD-1 needs to work out the appropriate \u00a0  agreements with the source provider.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-31 01:33:53-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-12 06:49:19-07:00",
    "text": "Sorry for this last minute discuss but I would like to emphasize the points made in the tsv-art review on congestion/rate control (Thanks Yoshi!): Please provide stronger guidance (MUST) on the use of rate/congestion control in these two cases:  In Section 3.1: \u00a0 \u00a0 \" If the peering point between AD-1 and AD-2 is a controlled \u00a0  network environment, then bandwidth can be allocated \u00a0  accordingly by the two domains to permit the transit of non- \u00a0  rate adaptive multicast traffic. If this is not the case, then \u00a0  it is recommended that the multicast traffic should support \u00a0  rate-adaption.\" In Section 4.1, \u00a0 \u00a0  \"When determining the appropriate bandwidth allocation, parties should consider use \u00a0 \u00a0 \u00a0  of a multicast protocol suitable for live video streaming that \u00a0 \u00a0 \u00a0  is consistent with Congestion Control Principles [ BCP41 ].\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-11-27 14:40:39-08:00",
    "text": "(1) Let's talk briefly about how JWT issuers are identified.\u00a0 Section 4 has some text: \u00a0  For this ACME Authority Token usage of JWT, the payload of the JWT \u00a0  OPTIONALLY contain an \"iss\" indicating the Token Authority that \u00a0  generated the token, if the \"x5u\" element in the header does not \u00a0  already convey that information; typically, this will be the same \u00a0  location that appeared in the \"token-authority\" field of the ACME \u00a0  challenge.\u00a0 [...] While \"iss\" is the default way to identify a JWT issuer, the JWT BCP ( RFC 8725 ,  BCP 225 ) does not make a strong recommendation that it is the preferred way to do so, with the implication that other ways to identify the issuer are reasonable.\u00a0 However, the text here only mentions the \"x5u\" element as an alternative to \"iss\" for identifying the issuer, which does not seem to be a comprehensive depiction of the JWT ecosystem.\u00a0 Issuers could be identified by other X.509 related protected headers such as \"x5c\", or in some situations just by the key used for signing (when that key is accompanied by other configured metadata), among other things.\u00a0 So, I don't understand why we call out \"x5u\" specifically here and apparently don't allow other ways of identifying the issuer. (2) We seem to describe the contents of the \"atc\" JWT claim as an array in \u00a74, but the examples show its payload as a JSON map.\u00a0 Which is correct? (3) I'd also like to have a (hopefully brief) discussion about the properties that we do and do not provide as relates to binding an authority token to an ACME client. In particular, in the REST API to the Token Authority, we have the client provide the fingerprint of its ACME key/identity, but the Token Authority does not do any validation on that value and is expected to just include it directly in the issued token.\u00a0 This means that some other entity X who is not the legitimate client but knows their key (fingerprint), and is also authorized to use a given identifier by the Token Authority, could cause a token to be issued that references the legitimate client's key.\u00a0 (Note that X could learn the fingerprint of the client by, e.g., being a semi-trusted CDN in front of the ACME server as considered by  RFC 8555 \u00a710.1.)\u00a0 That token would then only be useful by the legitimate client, and so there would need to be some other vulnerability that lets X trick the client into using that token, but it still seems that we have broken the chain of custody that would let us claim that the authority token was generated \"based on a request from the client\" (\u00a73.3).\u00a0 In particular, it seems that (with these preconditions) we might have a scenario where a client gets issued a certificate for numbers that it is not actually authorized for! This weakness does not immediately lead to an obvious vulnerability, as it requires two additional factors to be exploited -- the attacker must themselves be authorized at the Token Authority, and there needs to be some as-yet-unknown mechanism for the attacker to cause the client to use this new/different token -- but I think we at a minimum need to document the properties that we don't provide. We could choose to make the mechanism more complicated and close off this loophole by requiring proof of possession in the request to the token authority.\u00a0 The obvious way to do this robustly would require another round trip, though, to let the token authority provide a nonce that the proof of possession is provided over.\u00a0 Sometimes we can use a TLS Exporter value to save on that round-trip, but I haven't thought through very carefully what that would look like here.\u00a0 The request to the token authority would probably need to convey the entire public key, not just the fingerprint, so that the signature could be verified. There's another risk relating to thumbprints that is probably worth documenting -- we in effect are hardcoding a dependence on SHA256 for the fingerprints.\u00a0 (I'm happy to see that the wire-format of the thumbprint does identify the hash function used, so a transition mechansims should be pretty straightforward.)\u00a0 In light of the  BCP 201 guidance for building in algorithm agility, I think we should say that we are hardcoding SHA256 and SHA256 is believed to still be quite strong (the SHA-3 contest helped solidify that position), but if a second preimage attack for SHA256 is found, an issued authority token could be used with a different ACME account key.\u00a0 We can also go on to say that in that event, implementations can migrate to using a different hash function for the fingerprints due to the in-band hash function identification in the fingerprint field.\u00a0 Such a transition would require a new RFC to actually specify the details of the new behavior, but would not be very invasive to implementations. (4) We mention almost in passing that the tkauth-01 challenge type has a new \"token-authority\" field that designates a location where a token can be acquired.\u00a0 I think we need to have some more explicit discussion of the semantics of this field and how it's populated, especially in light of how this document implies that typical usage will include \"token-authority\" but the companion document implies that \"token-authority\" will not be in common usage.\u00a0 We definitely need some discussion of the security considerations of having party X tell the client to go authenticate to party Y and do some thing; this type of flow is very prone to enabling phishing attacks where the client gives party Y credentials that party Y is not supposed to have.\u00a0 In many cases it ends up being a de facto requirement that the client is configured with a specific list of allowed values for \"party Y\" and must reject anything not known to be trusted.\u00a0 (So, in this case, that would have the client reject any token authority URLs that are not in this preconfigured allow-list.)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-07-13 12:09:04-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 21:18:43-08:00",
    "text": "The examples in Section 4 make use of a function called \"base64url\" which is defined in  RFC 4648 .\u00a0 Do we not need a normative reference to that document? There was some chatter from the ARTART reviewer (review still pending) that suggested some confusion around validating the examples, and this was part of it.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-03-22 16:04:11-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-16 07:06:38-07:00",
    "text": "Stewart Bryant's Gen-ART review comments deserve more discussion, in my opinion. Perhaps that response is in the way of showing that Stewart is wrong, or that the working group has knowingly chosen a particular path, or that some clarification or changes are needed in the document. But substantial comments need to be addressed in some fashion, and I don't feel we're quite there yet. But I also didn't see much discussion on my e-mail search, it is possible of course that discussion happened without me seeing it (I'm not on the MPLS WG list). All that being said, this Discuss position is a request for discussion, but I do not plan to hold on to it beyond this telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-03-19 20:06:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-04 21:14:44-08:00",
    "text": "Thanks for taking on the task of adding this value. I have a handful of comments, one of which really needs clarification prior to publication. --------------------------------------------------------------------------- This issue is a discuss because the lack of formal language for values and the lack of clarity around case sensitivity has interoperabilty implications. \u00a74: >\u00a0 The Augmented >\u00a0 BNF (ABNF) [ RFC5234 ] for this parameter is shown in Figure 1. Figure 1 is not valid ABNF. It contains ABNF, and then has a whole bunch of other stuff. I suspect you wanted to have something more like this, using  RFC 7405  extensions: \u00a0  reason-extension =/ isup-cause-location \u00a0  isup-cause-location =\u00a0 \"location\" EQUAL isup-location-value \u00a0  isup-location-value = \u00a0 \u00a0 \u00a0 %s\"U\" /\u00a0 \u00a0 \u00a0 ; for 0 0 0 0 user \u00a0 \u00a0 \u00a0 %s\"LPN\" /\u00a0 \u00a0 ; for 0 0 0 1 private network serving the local user \u00a0 \u00a0 \u00a0 %s\"LN\" /\u00a0 \u00a0  ; for 0 0 1 0 public network serving the local user \u00a0 \u00a0 \u00a0 %s\"TN\" /\u00a0 \u00a0  ; for 0 0 1 1 transit network \u00a0 \u00a0 \u00a0 %s\"RLN\" /\u00a0 \u00a0 ; for 0 1 0 0 public network serving the remote user \u00a0 \u00a0 \u00a0 %s\"RPN\" /\u00a0 \u00a0 ; for 0 1 0 1 private network serving the remote user \u00a0 \u00a0 \u00a0 %s\"LOC-6\" /\u00a0 ; for 0 1 1 0 spare \u00a0 \u00a0 \u00a0 %s\"INTL\" /\u00a0  ; for 0 1 1 1 international network \u00a0 \u00a0 \u00a0 %s\"LOC-8\" /\u00a0 ; for 1 0 0 0 spare \u00a0 \u00a0 \u00a0 %s\"LOC-9\" /\u00a0 ; for 1 0 0 1 spare \u00a0 \u00a0 \u00a0 %s\"BI\" /\u00a0 \u00a0  ; for 1 0 1 0 network beyond interworking point \u00a0 \u00a0 \u00a0 %s\"LOC-11\" / ; for 1 0 1 1 spare \u00a0 \u00a0 \u00a0 %s\"LOC-12\" / ; for 1 1 0 0 reserved for national use \u00a0 \u00a0 \u00a0 %s\"LOC-13\" / ; for 1 1 0 1 reserved for national use \u00a0 \u00a0 \u00a0 %s\"LOC-14\" / ; for 1 1 1 0 reserved for national use \u00a0 \u00a0 \u00a0 %s\"LOC-15\"\u00a0  ; for 1 1 1 1 reserved for national use If you choose to instead keep the current formulation, please:  - Move the list of valid values out of the figure, and  - Add text clarifying whether the values are case-sensitive.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-20 19:01:46-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-06 21:21:18-08:00",
    "text": "I support Adam's Discuss. I also think that the Section 4 text: \u00a0  The use of the location parameter is restricted to Q850 cause values. \u00a0  Other values MUST be ignored if present. needs to be clear about whether it is intended to limit to the exact 16 strings listed above, or whether the intent is to update with Q850 if new values are allocated.\u00a0 Are string aliases allowed for the \"national-use\" codepoints if allocated within a given nation?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-24 14:50:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-30 14:37:34-07:00",
    "text": "I'd like to DISCUSS some questions I have about the content of Section 4's IS-IS rules. I don't expect it will be difficult to resolve these, I just want to be sure we have the conversation. 1. In \u00a74 (2.C), \u00a0 \u00a0 \u00a0  C.\u00a0 The SRLGs advertised in IS-IS SRLG ASLA TLVs and the other \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  link attributes advertised in IS-IS ASLA sub-TLVs are \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  REQUIRED to be collated, on a per-application basis, for all \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  applications that have their bit set in the SABM/UDABM in at \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  least one of the aforementioned TLV types. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   Is there some reason that there's no need to consider the case where both of the TLV types in question have zero-length application bit masks? 2. Later in the same paragraph, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  When performing \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  this collation, only the TLVs with the application's bit set \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  in SABM/UDABM MUST be used when such TLVs are available from \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  either TLV types. I suspect you aren't saying what you mean, and the \"only... MUST\" construct is hard to puzzle out. Do you perhaps mean TLVs that don\u2019t have the application's bit set MUST NOT be used? Because as you've written it,  - All TLVs with the bit set MUST be collated, - Any TLVs without the bit set MAY be collated (by implication). Which doesn't seem very sensible AFAICT. A possible rewrite, if I've understood your intention correctly, might be \"When performing this collation, every TLV with the application's bit set in SABM/UDABM MUST be included, when such TLVs are available from either TLV type.\" (Note also a minor fix for agreement in number, s/types/type/ in the last word.) 3. And still later in the same paragraph, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If the bit for an application is set in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the SABM/UDABM of only one of the TLV types, then the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  attributes from the other TLV type with zero-length \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application bit mask MUST be also collated for that \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application, if such TLV is available. I'm confused by the reference to a zero-length application bit mask. Can't the other TLV type have a nonzero-length application bit mask, but still have the application bit in question not set within the bit mask? I guess probably what you mean is, if the other TLV type is present and has a zero-length application bit mask, since a zero-length SABM/UDABM basically is a wildcard, the equivalent of all bits being set (as I read  RFC 8920 ).  If that's right, then a change seems in order, along the lines of \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If the bit for an application is set in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the SABM/UDABM of only one of the TLV types, and if the  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  other TLV type has a zero-length application bit mask, then the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  attributes from the other TLV type with zero-length \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application bit mask MUST be also collated for that \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application, if such TLV is available. I just interpolated the \"and\" clause. It's a bit wordy and could probably be further condensed, but I think it clarifies sufficiently. On the other hand, if I'm not right about this (very possible) then I'd appreciate further discussion on what I got wrong, so we can figure out if the text needs clarification or if I just need a clue bat.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-08-07 07:06:35-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-02 07:09:54-07:00",
    "text": "Is it really appropriate for this document to put normative requirements on OpenID Connect? The reverse would typically not be true, which is why I wanted to check.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-08-03 13:56:38-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-01 16:25:24-07:00",
    "text": "I am concerned that the IANA considerations may be inappropriate for the purpose of the document, and possibly harmful. I'd like to see some discussion of this; if afterwards people still think it's a good idea, I will clear. If I understand correctly, the interpretation of a component name is entirely contextual to the trust framework. While trust frameworks are encouraged to reuse existing components for similar purposes, there's no real way to enforce that. And given that even if trust frameworks share a component, they may assign entirely different value types, I don't see the value of registering components. Furthermore, since the instructions to the experts asks them to look at things like general applicability vs limited application, I can see registration requests creating a fair amount of discussion (meaning work for people). So, why register components at all? Why not leave them up to trust frameworks to define as they please? Is harm done if different frameworks use the same component name for completely different things? (I could see registering the frameworks themselves, but I leave that to the WG to decide.)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-16 03:50:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-03-15 08:23:53-07:00",
    "text": " document that obsoletes an existing RFC needs to contain section describing changes since. I haven't found this from a very quick scan.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-16 08:36:43-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-16 03:50:30-07:00",
    "text": "A document that obsoletes an existing RFC needs to contain section describing changes since. I haven't found this. (Ben and Benoit are effectively explained this in more details.)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-04-07 08:18:04-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-16 08:24:35-07:00",
    "text": "After looking at the comments from the IESG and IANA, it seems better to rewrite this document as an update to  RFC6890  for improved clarity. The authors will work on a new version written as an update to  RFC6890 . I will put it up on future telechat when it is ready.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-06-26 12:49:35-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-23 08:41:03-07:00",
    "text": "Several sections mandate actions to be taken where the specific mechanisms are not clearly defined.\u00a0 This lack of specifics leaves me at a loss about what is being mandated. Specifically: (1) \u00a74.3.2 (Quality of Service): \"Quality of Service...MUST be provided  \u00a0 \u00a0 locally by the DetNet-aware hosts and routers supporting DetNet flows.\u00a0  \u00a0 \u00a0 The traffic control mechanisms used to deliver QoS...are expected to be  \u00a0 \u00a0 defined in a future document.\" (2) \u00a75.2 (Forwarding Procedures): \"Specifically...SHALL use management and  \u00a0 \u00a0 control information to select the one or more outgoing interfaces and  \u00a0 \u00a0 next hops...\"\u00a0 This sentence sounds very generic to me: using management  \u00a0 \u00a0 and control information is what every forwarder does -- regardless of  \u00a0 \u00a0 DetNet.\u00a0 Not only is it a generic statement, but the management and  \u00a0 \u00a0 control functions are not defined... (3) \u00a75.3 (DetNet IP Traffic Treatment Procedures): \"MUST ensure that a  \u00a0 \u00a0 DetNet flow receives the traffic treatment that is provisioned for  \u00a0 \u00a0 it...Typical mechanisms used to provide different treatment to different  \u00a0 \u00a0 flows includes the allocation of system resources...and provisioning or related parameters...Other mechanisms than the ones used in the TSN case are outside the scope of this document.\"  It is ok to define the mechanisms in a different document -- but there are no specific references.\u00a0 What exactly is this document requiring (MUST)?\u00a0 If there are no specifics on the mechanisms (or where they are defined), how can an implementation comply with this document?\u00a0 What are the interoperability consequences if not all nodes comply with the same set of (undefined) mechanisms? I am balloting DISCUSS because I believe that this omission makes the specification incomplete.\u00a0  Adding details will satisfy my concern.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-10 04:22:47-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-22 11:51:02-07:00",
    "text": "A few easy clarifications: ** Section 7.\u00a0 Per \u201cFrom a data plane perspective this document does not add or modify any header information\u201d, this statement, which is also found in Section 9.1 of  draft-ietf-detnet-security-10  does not seem consistent with Section 3 which states \u201c\u2026 however modification of these fields is allowed, for example changing the DSCP value, when required by the DetNet service\u201d. ** Section 7.\u00a0  RFC8655  reminds us that \u201cSecurity considerations for DetNet are constrained (compared to, for example, the open Internet) because DetNet is defined to operate only within a single administrative domain\u201d.\u00a0 However, the only IP-specific guidance on preventing escape from the DetNet domain is in Section 4.2 (\u201cNote that not mixing DetNet and non-DetNet traffic within a single 5-tuple,\u00a0 as described above, enables simpler 5-tuple filters to be used (or re-used) at the edges of a DetNet network to prevent non-congestion-responsive DetNet traffic from escaping the DetNet domain.\u201d).\u00a0 Please provide more prescriptive guidance in this section. ** Section 7.\u00a0 The guidance from  RFC8655  and  draft-ietf-detnet-security  needs to be deconflicted relative to confidentiality.\u00a0 The following assertions are stated in a single paragraph: (a) The primary considerations for the data plane is to maintain \u00a0  integrity of data and delivery of the associated DetNet service \u00a0  traversing the DetNet network.\u00a0   (b) Application flows can be protected \u00a0  through whatever means is provided by the underlying technology.\u00a0 For \u00a0  example, encryption may be used, such as that provided by IPSec \u00a0  [ RFC4301 ] for IP flows and/or by an underlying sub-net using MACSec \u00a0  [IEEE802.1AE-2018] for IP over Ethernet (Layer-2) flows. (a) appears to be a cut-and-paste (or maybe vice versa) from Section 9 of  draft-ietf-detnet-security-10 (b) appears to be a cut-and-paste from Section 5 of  RFC8655 . The concatenation of (a) + (b) appears to be unique to this document. When  RFC8655  states (b), it prefaced with \u201c[t]o maintain confidentiality of data traversing the DetNet, application flows can be protected through whatever means is provided by the underlying technology.\u201d\u00a0 (a) makes no references to confidentiality.\u00a0 It seems like it should.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-17 01:39:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-21 09:29:05-07:00",
    "text": "Thank you for the work on this document. This is a discuss DISCUSS - while reading this document and considering the normative downref to  RFC 8907  TACACS+, which is informational, I agree with Elliot [1] that to me this document would make more sense as informational. I have followed the mail thread and saw the authors' responses, which quoted  RFC 3967  : \u00a0  o\u00a0 A standards document may need to refer to a proprietary protocol, \u00a0 \u00a0 \u00a0 and the IETF normally documents proprietary protocols using \u00a0 \u00a0 \u00a0 informational RFCs. I am not convinced that this is one of the cases that this bullet was supposed to cover. Additionally, I could not find in meeting minutes that this was ever discussed in the wg, as was suggested in the mail thread [2]. I'd like to know if the resp AD is aware of any related discussion after this point was raised. Another point the authors made in favor of keeping this std track was that they haven't seen any YANG data model published as informational. Again, I am not convinced that this is reason enough to progress this as std track. I note that this was reported in the shepherd write up [3] and in the last call [4], so won't block progress after a discussion, but I do think it is worth talking about. Please let me know if I missed anything. Thanks, Francesca [1]  https://mailarchive.ietf.org/arch/msg/opsawg/2mRkaXy5M9XCPp4_wXNpQd9GLdk/   [2]  https://mailarchive.ietf.org/arch/msg/opsawg/MOnCfYBS3j4wBnZWDjl_YQHfvzg/ [3]  https://datatracker.ietf.org/doc/draft-ietf-opsawg-tacacs-yang/shepherdwriteup/ [4]  https://mailarchive.ietf.org/arch/msg/opsawg/FJmtUtB0x8tV0MUdO9Uhvc2e1p0/",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-13 12:17:25-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-19 15:08:09-07:00",
    "text": "**  RFC8907  was published with informational status and it contained substantial caution in its security considerations that the protocol was fundamentally insecure and would not \u201cmeet modern-day requirements.\u201d\u00a0 This measured approach was taken to provide a stable description of a widely deployed protocol and to serve as the basis for future improvements. The context for this follow-on, seemingly related work does not track the situation around  RFC8907  (as I remember it).\u00a0 Specifically: -- this functionality is new, and is not documenting the \u201cas is\u201d deployed state -- this functionality is advocating for supporting an insecure approach with proposed standard (rather than informational) status ** Is this document intentionally breaking backward compatibility on the \u201cshared-secret\u201d size specified in  RFC8907 ? (a) Section 4. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case shared-secret { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 leaf shared-secret { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type string { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 length \"16..max\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } (b) Section 10.5.1 of  RFC8907  says \u201cTACACS+ server administrators SHOULD configure secret keys of a minimum of 16 characters in length.\u201d As (b) is not a MUST (a \u201csecret key\u201d shorter than 16 is possible), it would appear that (a) breaks compatibility.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-11 08:06:40-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 13:53:02-08:00",
    "text": "Hello, I'm a little confused on the Security Consideration section as it doesn't use the latest template, but does specify SSH for NETCONF, so I'm good with that part.\u00a0 Will RESTCONF also be used as a transport or is there some reason it won't be used for this YANG module?\u00a0  Here's what I think is the latest template and please let me know if sections of it do not apply to this draft and I'll drop the discuss for correcting the security considerations section. https://tools.ietf.org/html/draft-ietf-netmod-rfc6087bis-10#page-52 Thanks in advance!",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-04-10 12:39:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-10 12:38:34-07:00",
    "text": "I support the DISCUSS positions of Warren and Magnus. Also, this work item does not appear to be inside the scope of the MANET charter, at least based on my reading of the charter. Am I missing something?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-05-10 07:04:04-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 12:39:41-07:00",
    "text": "This work item does not appear to be inside the scope of the MANET charter, at least based on my reading of the charter. Am I missing something?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-06 15:01:58-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-10 17:58:11-07:00",
    "text": "Section 3.1 defines 'Scale' as a four-bit unsigned integer field but only the values 0-3 are assigned, leaving 4-16k usable.\u00a0 How will future values be assigned? In Section 3.1.1: \u00a0  DS Field Qn: \u00a0 \u00a0 \u00a0 The data item contains a sequence of 8 bit DS Fields.\u00a0 The number \u00a0 \u00a0 \u00a0 of DS Fields present MUST equal the sum of all Num DSCPs field \u00a0 \u00a0 \u00a0 values. Perhaps I'm misreading, but I thought the Num DSCPs Qn field was global for this queue index, so there would just be one of them and no need to take a sum. In Section 3.3: \u00a0  A router which receives the Restart Data Item SHOULD resume \u00a0  transmission of the identified traffic to the modem. Why is this only a \"SHOULD\"? Section 4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The extension does not inherently \u00a0  introduce any additional vulnerabilities above those documented in \u00a0  [ RFC8175 ].\u00a0 [...] As noted by others, this sentence is just not true. I will not duplicate the suggestions for additional considerations that need to be documented.\u00a0 In particular, I agree with Roman that the use of TLS needs to be mandatory, especially since this protocol is nominally only defined for use with radio links.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-14 16:21:24-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-06 15:01:58-07:00",
    "text": "[Future 'Scale' allocations will be done via Updates:] In Section 3.1.1: \u00a0  DS Field Qn: \u00a0 \u00a0 \u00a0 The data item contains a sequence of 8 bit DS Fields.\u00a0 The number \u00a0 \u00a0 \u00a0 of DS Fields present MUST equal the sum of all Num DSCPs field \u00a0 \u00a0 \u00a0 values. Perhaps I'm misreading, but I thought the Num DSCPs Qn field was global for this queue index, so there would just be one of them and no need to take a sum. [Restart Data may not lead to data restart due to other conditions on the router] Section 4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The extension does not inherently \u00a0  introduce any additional vulnerabilities above those documented in \u00a0  [ RFC8175 ].\u00a0 [...] As noted by others, this sentence is just not true. I will not duplicate the suggestions for additional considerations that need to be documented.\u00a0 In particular, I agree with Roman that the use of TLS needs to be mandatory, especially since this protocol is nominally only defined for use with radio links.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-06 00:56:41-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-04 04:42:28-07:00",
    "text": "It is unclear to me what the purpose of the pause and resume is here?  Is it to enable the router to build the queue rather than the modem if there is a queue buildup in the modem?  If that is the case, then pause and resume will be done frequently and on short time scales due to variability of the link. And then the router resumes transmission to the modem when the buffer has been reduced? As this is enabled to be done on a queue level what how does one ensure the per hop behavior that is intended based on the DSCP with this split. Because you will get an interaction between the two queue that are in series for the same link which makes ensuring the PHB difficult.  I hope for a timely clarification to determine if this is a discuss or not and make it more actionable.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-04-04 08:29:31-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-04 08:28:44-07:00",
    "text": "I have similar questions as Magnus does about the specific use case for this mechanism. Moreover I wonder about the assumed usage of the different DSCPs. If he router would want to assign assign code points to the traffic, then it would need to know what the requirement of the traffic is which is usually unknown. If there is an assumption that the traffic is marked with the right DSCP by the origin than the router does not need to know about the available DS queue configuration. Can you please clarify!",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-06-06 09:56:53-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-04 08:29:31-07:00",
    "text": "I have similar questions as Magnus does about the specific use case for this mechanism. Moreover I wonder about the assumed usage of the different DSCPs. If the router would want to assign code points to the traffic, then it would need to know what the requirements of the traffic is which is usually unknown to a router. If there is an assumption that the traffic is marked with the right DSCP by the origin than the router does not need to know about the available DS queue configuration. Can you please clarify!",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-17 11:44:04-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 14:40:31-07:00",
    "text": "Unauthenticated shutdown of the network seems exceedingly dangerous.\u00a0 An expansion of the implementation scenarios described in Section 4 of  RFC8175  and the architecture laid out in Figure 1 of  RFC8175  appears to be: (a) single direct connect (1x modem + 1x router) (b) single dedicated switch (1x modem + 1x switch + 1x router) (c) multiple connect (>1x modem + >=0 switches + 1x router) (d) mobile environment (>=1x modem + switch + router + other devices in the switch) (e) networked deployment (as stated in  RFC8175 /anything more complicated) I believe that the safest thing is that using TLS with this extension should be a MUST.\u00a0 If that is problematic, then I\u2019d only soften it to (text that amounts to) \u201cin environments and deployment scenarios (a) and (b), TLS SHOULD be used.\u00a0 In all other environments, TLS MUST be used.\u201d Warren: I believe that your neighbor scenario is likely scenario (c). As the current security considerations say, using TLS in scenario (a) won\u2019t help if the modem gets compromised.\u00a0 In the above recommendation, there is an assumption that the switch(s) isn\u2019t compromised (and that should be documented).",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-04-11 06:29:48-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-08 11:57:03-07:00",
    "text": "Please note that I'm really not a DLEP person, and so this may be completely incorrect -- in which case I'm (of course!) happy to clear my discuss. Hypothetical Scenario: My next-door neighbor keeps using up all the bandwidth, making my Internets slow! Stupid neighbor! Until now I didn't have much motivation to mess with DLEP (it didn't really gain me anything), but now I can spoof Pause Data Items to get the router to stop sending traffic to her, freeing up all the bandwidth for me. The security considerations section doesn't *really* cover this -- it says:  \" Note that this extension does allow a compromised or impersonating modem to suppress transmission by the router, but this is not a substantively different attack by such a compromised modem simply dropping all traffic destined to, or sent by a router.\" -- that only covers compromised modems, not impersonating modems. It also says: \"[ RFC8175 ] defines the use of TLS to protect against the impersonating attacker.\" -- yes,  RFC8175  does indeed define the use of TLS, but doesn't require it. RFC8175  Security Considerations also say: \" This specification does not address security of the data plane, as it (the data plane) is not affected, and standard security procedures can be employed.\" and \"Similar issues can arise if DLEP data is used as an input to policing algorithms -- injection of malicious data via DLEP can cause those policing algorithms to make incorrect decisions, degrading network throughput.\" It seems that this specification is specifically allowing the dataplane to be affected by (spoofed) DLEP messages, and in a much more direct way than discussed in the  RFC8175  security considerations section. I think that this is dangerous without much more direct advice (like \"MUST use TLS\" or similar).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-05-19 18:06:02-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-08 13:54:10-07:00",
    "text": "I'm putting in this point as a DISCUSS because I think that the current text may be confusing and vague. As others have pointed out, this document includes  rfc2119 -like language, both capitalized and not.\u00a0 I realize that  rfc1981  was published before  rfc2119  and that no expectation on the language existed then.\u00a0 However, we're at a point in time where not only  rfc2119  is in place, but  draft-leiba-rfc2119-update  (which clarifies that only uppercase language has special meaning) is in AUTH48.\u00a0 I think that this leads to the possibility that the average reader may interpret the requirements in this document in a way that it wasn't intended. While I would prefer that this document be consistent (and either use capitalized  rfc2119  language as intended, OR, not used it at all), I understand the intent of not changing some of the original text.\u00a0 I would be happy with a note like this one: \"Note:\u00a0 This document is an update to  RFC1981  that was published prior to  RFC2119  being published.\u00a0 Consequently while it does use \"should/must\" style language in upper and lower case, the document does not cite the  RFC2119  definitions.\u00a0 This update does not change that.\"\u00a0  [I borrowed this text from the the INTDIR review thread. [1]] I find that including a note in the Shepherd's write-up is not enough because the average reader/implementer will not consult it. [1]  https://mailarchive.ietf.org/arch/msg/int-dir/bVH_0ydVdGssOiszJKhQXLYPuXY/?qid=4000f8a954b226266f429842911101f5",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-05-20 04:29:31-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-11 03:45:27-07:00",
    "text": "\u00a0 Nodes not implementing Path MTU Discovery MUST use the IPv6 minimum \u00a0  link MTU defined in [ I-D.ietf-6man-rfc2460bis ] as the maximum packet \u00a0  size.  I searched for \"IPv6 minimum link MTU\" in  draft-ietf-6man-rfc2460bis-09 , and could not find that term. Even unlikely at this point in the IPv6 implementation cycle, we don't want readers to believe that they should look at the minimum of the device IPv6 MTU link(s). Proposal: define \"IPv6 minimum link MTU\" as 1280 octets in 2460bis, or in both documents.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-05-29 05:38:09-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-08 12:08:00-07:00",
    "text": "I know this is a bis document and my discuss does not address any text that changed in the bis version but given all previous discussion, I would like to discuss the following text parts on statements regarding retransmissions which don't seem to be appropriate for this document and are partly even wrong. In general it does not make a lot of sense to talk about retransmission semantics in this document because this really depends on the upper layer protocol, and I'm really not sure if any implementaiton of a reliable transport does send retransmission based on the receptions of PTB messages (if exposed) rather than only relying on it's own loss detection mechanism. This discuss concerns a few sentence all over the document and most parts of section 5.4. Details proposals below: I propose to either remove this sentence, or at least reword to the following (or something similar): OLD: \"Retransmission should be done for only for those packets that are \u00a0  known to be dropped, as indicated by a Packet Too Big message.\" NEW: \"The IP layer may indicate loss to the upper layer protocol of those packets that are \u00a0  known to be dropped, as indicated by a Packet Too Big message.\" Or MAY or SHOULD or MUST...? Subsequently the following sentence should be removed as well: \"An upper layer must not retransmit data in response to an increase in \u00a0  the PMTU estimate, since this increase never comes in response to an \u00a0  indication of a dropped packet.\" And here is the bigger change in section 5.4: OLD \"When a Packet Too Big message is received, it implies that a packet \u00a0  was dropped by the node that sent the ICMPv6 message.\u00a0 It is \u00a0  sufficient to treat this in the same way as any other dropped \u00a0  segment, and will be recovered by normal retransmission methods.\u00a0 If \u00a0  the Path MTU Discovery process requires several steps to find the \u00a0  PMTU of the full path, this could delay the connection by many round- \u00a0  trip times. \u00a0  Alternatively, the retransmission could be done in immediate response \u00a0  to a notification that the Path MTU has changed, but only for the \u00a0  specific connection specified by the Packet Too Big message.\u00a0 The \u00a0  packet size used in the retransmission should be no larger than the \u00a0  new PMTU.\" NEW \"When a Packet Too Big message is received, it implies that a packet \u00a0  was dropped by the node that sent the ICMPv6 message.\u00a0 A reliable  \u00a0  upper layer protocol will detect the loss of this segment, and recover \u00a0  it by its normal retransmission methods.\u00a0 Depending on the loss  \u00a0  detection method that is used by the upper layer protocol, this  \u00a0  could delay the connection by many round-trip times. \u00a0  Alternatively, the retransmission could be done in immediate response \u00a0  to a notification that the Path MTU was decreased, but only for the \u00a0  specific connection specified by the Packet Too Big message.\u00a0 The \u00a0  packet size used in the retransmission should be no larger than the \u00a0  new PMTU.\" I don't understand the following paragraph. Can this be removed? \"Note: A packetization layer must not retransmit in response to \u00a0 \u00a0 \u00a0 every Packet Too Big message, since a burst of several oversized \u00a0 \u00a0 \u00a0 segments will give rise to several such messages and hence several \u00a0 \u00a0 \u00a0 retransmissions of the same data.\u00a0 If the new estimated PMTU is \u00a0 \u00a0 \u00a0 still wrong, the process repeats, and there is an exponential \u00a0 \u00a0 \u00a0 growth in the number of superfluous segments sent.\" The following text is fine but probably is not needed if the whole document is reworded accordingly to ensure that retransmissions are solely the responsibility of the upper layer protocol:  \u00a0 \u00a0  \"Retransmissions can increase network load in response to \u00a0 \u00a0 \u00a0 congestion, worsening that congestion.\u00a0 Any packetization layer \u00a0 \u00a0 \u00a0 that uses retransmission is responsible for congestion control of \u00a0 \u00a0 \u00a0 its retransmissions.\u00a0 See [ RFC8085 ] for more information.\" This can also be removed, because a reliable protocol that detected loss and decided to send a retransmission, should and will do the same processing as for all other retransmissions, e.g. reset the retransmission time in TCP. Mentioning this separately is rather confusing. \u00a0 \u00a0 \u00a0 \"This means that the TCP layer must be able to recognize when a \u00a0 \u00a0 \u00a0 Packet Too Big notification actually decreases the PMTU that it \u00a0 \u00a0 \u00a0 has already used to send a packet on the given connection, and \u00a0 \u00a0 \u00a0 should ignore any other notifications.\" And this is even incorrect. Slow start means that you will increase the connection window exponentially. Only sending one segment means setting the congestion/sending window to one. I propose the following change: OLD \u00a0  \"Many TCP implementations incorporate \"congestion avoidance\" and \u00a0  \"slow-start\" algorithms to improve performance [CONG].\u00a0 Unlike a \u00a0  retransmission caused by a TCP retransmission timeout, a \u00a0  retransmission caused by a Packet Too Big message should not change \u00a0  the congestion window.\u00a0 It should, however, trigger the slow-start \u00a0  mechanism (i.e., only one segment should be retransmitted until \u00a0  acknowledgements begin to arrive again).\" NEW \"A loss caused by a PMTU probe indicated by the reception of a Packet Too Big message MUST NOT be considered as a congestion notification and hence the congestion window may not change.\" And I also don't understand this sentence: \"TCP performance can be reduced if the sender's maximum window size is \u00a0  not an exact multiple of the segment size in use (this is not the \u00a0  congestion window size).\"",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-05-19 09:06:30-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-10 08:52:30-07:00",
    "text": "The OpsDir review ( https://datatracker.ietf.org/doc/review-ietf-6man-rfc1981bis-04-opsdir-lc-hares-2017-03-04/  ) raises an interesting point, which I had not occurred to me. If the MTU for a path is 1440 bytes, and ND/RA suddenly says that the interface MTU is only 1400 bytes, what should implementations do?  I'd expect something like decrease the path MTU (for all paths) to min (new link MTU, current path MTU), but it isn't (AFAICT) specified. It's entirely possible that this is a: already covered and / or b: covered at a different layer / different protocol, happy to be hit with a clue bat...",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-03-25 07:54:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-25 02:23:44-07:00",
    "text": "\"Appendix C\", paragraph 1, discuss: > Appendix C: Automating the Initial Window in TCP over Long Timescales The content of this appendix seems to be unrelated to TCB sharing and reads like a separate document - why is it included in this document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-17 00:31:35-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-19 19:45:44-07:00",
    "text": "(1) I am not entirely sure what we mean by saying that temporary addresses must have a lifetime that is \"statistically different\" across different addresses, and accordingly I am not sure that the procedures in Section 3.4+3.5 for rereshing a temporary address achieve that property.\u00a0 (The text about \"statistically different\" does not appear in  RFC 4941 , and the relevant parts of Section 3.4/3.5 are unchanged from  RFC 4941 , so this may be the result of an incomplete update.) Specifically, when Section 3.5 says to \"[repeat] the actions described in Section 3.4, starting at step 4\" that seems to (for long-lived PIOs) result in, e.g., the new temporary address having lifetime TEMP_VALID_LIFETIME starting at exactly the time when the previous one expired; wouldn't an observer be able to trivially correlate \"new address showed up with TEMP_VALID_LIFETIME\" with \"address that expired at that time\"?\u00a0 Note that the attacker does not need to know the value of TEMP_VALID_LIFETIME in order to perform a DFT on the distribution of \"new address\" events.\u00a0 (Furthermore, we apparently qualify the \"repeating the actions\" with some caveats, which doesn't exactly qualify as \"repeating the actions\" anymore.\u00a0 That said, the caveats currently listed in Section 3.5 don't seem to be enough to provide the \"statistically different property\" in what I believe to be the intended interpretation.) (2) Please fix the reference for DupAddrDetectTransmits in Section 3.8 -- it is defined in 4862, while RetransTimer is in 4861. (3)  RFC 4941  cannot be a *normative* reference of this document if we are going to Obsolete it.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-12-01 10:55:29-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 01:47:45-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-v6ops-ipv6-deployment-08 CC @evyncke Thank you for the work put into this document even if I had hoped for a cleaner document. I also regret that security is not mentioned as an incentive to deploy IPv6 security policies as most end-points have IPv6 enabled by default. I am also concerned that this document did not get enough reviews (thanks Robert for your  https://mailarchive.ietf.org/arch/msg/v6ops/Trz62uglkVKOuXY3gXV_lNpyBEc/  and 3 reviews -- if not mistaken -- during V6OPS WGLC). Please find below several blocking DISCUSS points (should the document be sent back to the V6OPS WG ?) and some non-blocking COMMENT points. Special thanks to Fred Baker for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this review helps to improve the document because it is important Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 1.1 ``` \u00a0 \u00a0 \u00a0 IPv4 as a Service (IPv4aaS): It means that IPv4 service support is \u00a0 \u00a0 \u00a0 provided by means of transition mechanism, therefore there is a \u00a0 \u00a0 \u00a0 combination of encapsulation/translation + IPv6-only overlay + \u00a0 \u00a0 \u00a0 decapsulation/translation.\u00a0 For an IPv6-only network, connectivity \u00a0 \u00a0 \u00a0 to legacy IPv4 is either non-existent or provided by IPv4aaS \u00a0 \u00a0 \u00a0 mechanisms. ``` It must be \"IPv6-only underlay\", see other use of \"underlay/overlay\" in other IETF published RFC: 7364, 7365, 9272, ... ### Section 4.2 overlay Again the title and the introduction are incorrect. It should be \"IPv4 as a Service and IPv6-only ***Underlay***\". ``` \u00a0  Both are IPv4aaS solutions by leveraging IPv6-only overlay.\u00a0 IPv4aaS \u00a0  offers Dual-Stack service to users and allows an ISP to run IPv6-only \u00a0  in the network (typically, the access network). ``` The above text repeats the same mistake. ### Section 4.2 464XLT and MAP-T While I really like 464XLT, it should not appear in a section with \"underlay\" as it is *not* an encapsulation mechanism. The same reasoning applies for MAP-T. The section should be about IPv4aaS then 464XLAT and MAP-T could be included. ### Section 5.2 ``` \u00a0  IPv6 addresses can be assigned to an interface \u00a0  through different means, such as Stateless Auto-Configuration (SLAAC) \u00a0  [ RFC4862 ], stateful and stateless Dynamic Host Control Protocol \u00a0  (DHCP) [ RFC8415 ].\u00a0  ``` Stateless DHCPv6 *does not* assign IPv6 addresses/prefixes. ### Section 5.4.2 As it is linked to security, I am raising this to a DISCUSS level. Fragmentation can be used to bypass all layer-4 filters not only in NDP as mentioned in the draft, but in any protocol. Please add text about  RFC 8200  section 5: ``` \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Extension headers, if any, and the Upper-Layer header.\u00a0 These \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  headers must be in the first fragment. ```",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-08 05:32:32-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-02 23:55:18-07:00",
    "text": "This is a fine document, but I have one quick question: Values TBD1..TBD4 are not listed in the IANA Considerations section. Should they be?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-24 19:40:54-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-05 09:43:44-08:00",
    "text": "I see that the list of \"changes since  RFC 7540 \" in Appendix B lists: \u00a0  *\u00a0 The ranges of codepoints for settings and frame types that were \u00a0 \u00a0 \u00a0 reserved for \"Experimental Use\" are now available for general use. But this doesn't seem to be reflected in either \u00a711 (IANA Considerations) or the live registry. Should it be?\u00a0 (Some backchannel discussion suggests that it's rather this entry in the appendix is erroneous.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-17 09:27:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-09 23:21:21-07:00",
    "text": "(Very much a \"discuss discuss\" -- I just want to make sure the conversation happens, regardless of the outcome.) I do see the response to Alvaro's ballot position but I'm still not sure that I understand what specifically requires this document to be on the standards-track. Yes, there are differences between IP-over-MPLS and IP-over-DetNet-MPLS, but (e.g.) how much of the DetNet-specific handling is just \"when you send the traffic onwards you need to ensure the quality of service\" which in this scenario means translating the DetNet IP needs into the DetNet MPLS configuration?\u00a0 In other words, a lot of this seems to be just giving information about how to fulfill the existing requirements from (e.g.)  draft-ietf-detnet-ip , so I am not sure that I understand what the truly new protocol pieces and/or requirements are.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-24 08:48:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-18 20:53:13-08:00",
    "text": "I think the following text from Section 4.1 of  RFC8314  needs to be updated as well. Is there any reason this is left out? \u00a0  Transition of users from SSL or TLS 1.0 to later versions of TLS MAY \u00a0  be accomplished by a means similar to that described above.\u00a0 There \u00a0  are multiple ways to accomplish this.\u00a0 One way is for the server to \u00a0  refuse a ClientHello message from any client sending a \u00a0  ClientHello.version field corresponding to any version of SSL or \u00a0  TLS 1.0.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-24 08:48:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-24 08:48:16-07:00",
    "text": "hanks for addressing my DISCUSS point about legacy ClientHello handling in -05.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-16 05:34:41-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-13 05:03:02-08:00",
    "text": "I have two discuss points to chat about before I ballot yes for this: (1) I think it'd be good to make the nature of this RFC clear in the document, so that folks don't get confused and implement this now, when we think they ought be using TLS for stub to recursive privacy. I'd suggest maybe adding a note here (possibly an IESG note, or just more text before 1.1, whatever), that says something like: \"This DTLS solution was considered by the DPRIVE working group as an option to use in case the TLS based approach specified in RFC7858  turns out to have some issues when deployed.\u00a0 At the time of writing, it is expected that  RFC7858  is what will be deployed, and so this specification is mainly intended as a backup.\" Note that while text like that may also end up in the profiles document, I still think it may be useful here as well. (2) Section 4: No mention of OCSP stapling? And come to think of it, how would non-stapled OCSP even work? And since I've now thought of it, how will OCSP work with RFC7858 ? Does this (and 7858) need to mandate stapling or no revocation checking via OCSP at all?\u00a0 (Apologies for not asking about that when we were processing 7858;-)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-02 17:36:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-20 16:40:01-07:00",
    "text": "In Section 2.3 we make a claim about item 'e)' of section 5.5.3 of  RFC 4862 , in particular that it says that 'an RA may never reduce the  RemainingLifetime\" to less than two hours', but the relevant text from  RFC 4862  seems to be: \u00a0 \u00a0 \u00a0 2.\u00a0 If RemainingLifetime is less than or equal to 2 hours, ignore \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the Prefix Information option with regards to the valid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 lifetime, unless the Router Advertisement from which this \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 option was obtained has been authenticated (e.g., via Secure \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Neighbor Discovery [ RFC3971 ]).\u00a0 If the Router Advertisement \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 was authenticated, the valid lifetime of the corresponding \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 address should be set to the Valid Lifetime in the received \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 option. which clearly allows an *authenticated* RA to reduce the \"RemainingLifetime\" to smaller values.\u00a0 (Text with a similar not-quite-accurate statement appears in Section 2.4 of this document as well.)",
    "type": "Discuss"
  },
  {
    "ad": "Adrian Farrel",
    "end": "2014-11-22 06:43:37-08:00",
    "end_reason": "position_updated",
    "start": "2014-10-28 06:01:24-07:00",
    "text": "There is an on-going discussion between Martin Thomson and Christopher Dearlove about the key authorities and mechanisms described in this document. This Discuss is to track that conversation and wait for a resolution.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-24 05:58:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2014-11-24 03:47:30-08:00",
    "text": "(1) I am concerned that  RFC6507  may not be ready for use in standards-track RFCs. So far it has not been and I have found no peer reviewed security or cryptographic analysis that indicates that it is has been studied to see if it is good enough for that. I've also not seen any MANET list discussion of that aspect (and indeed the MANET list discussion I did see seems to involve very few people).\u00a0 I asked on the CFRG list about  RFC6507  and it seems [1] to be the case that no-one has so far really evaluated its security, other than folks associated with the author's institution. (Which applies to both 6507 and this I think.) I also didn't find any references to 6507 in Google scholar.\u00a0 Lastly, I think we should be, and be seen to be, more careful than usual with this draft - given the situation with DUAL-EC-DRBG, and that this is a new signature scheme that allows the KMS to fake anyone's signature and the author involved.\u00a0 Note that that last is not any imputation of misbehaviour, but the IETF would not be\u00a0 doing due-dilligence if we didn't explicitly consider that aspect. \u00a0 [1]  https://www.ietf.org/mail-archive/web/cfrg/current/msg05540.html (2) How does a router get its private key? Why is it ok to not specify that? Seems like an interop fail if that is not done. (3) I think this is the first asymmetric scheme the WG have adopted. If that's wrong then this discuss point is fairly moot:-) When did the WG discuss whether to adopt IBS as its first asymmetric appraoch and not traditional signature schemes that don't have spoofing by the KG/KMS as an inherent property? That might be a reasonable decision, but I don't see where that decision was made, nor why. (That could be just that I've not looked far enough back in the WG list archives, in which case this is easy.) (4) 4.1: The usual revocation trick of including a time value in the name is referred to at the end of this section but without sufficient detail to allow interop. Why is that ok? (5)  RFC6507  isn't compatible with e.g. Curve25519 or perhaps other \"rigid\" curves. Given that CFRG are in the process of picking new curves, with better properties, wouldn't it be better for the WG to wait and have the choice of using those as well or instead?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-18 07:59:42-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-24 05:58:06-08:00",
    "text": "(Updated after 1 year when author resumed discussion.) (1) I am concerned that  RFC6507  may not be ready for use in standards-track RFCs. So far it has not been and I have found no peer reviewed security or cryptographic analysis that indicates that it is has been studied to see if it is good enough for that. I've also not seen any MANET list discussion of that aspect (and indeed the MANET list discussion I did see seems to involve very few people).\u00a0 I asked on the CFRG list about  RFC6507  and it seems [1] to be the case that no-one has so far really evaluated its security, other than folks associated with the author's institution. (Which applies to both 6507 and this I think.) I also didn't find any references to 6507 in Google scholar.\u00a0 Lastly, I think we should be, and be seen to be, more careful than usual with this draft - given the situation with DUAL-EC-DRBG, and that this is a new signature scheme that allows the KMS to fake anyone's signature and the author involved.\u00a0 Note that that last is not any imputation of misbehaviour, but the IETF would not be\u00a0 doing due-dilligence if we didn't explicitly consider that aspect. \u00a0 [1]  https://www.ietf.org/mail-archive/web/cfrg/current/msg05540.html (2) How does a router get its private key? Why is it ok to not specify that? Seems like an interop fail if that is not done. (3) cleared (4) 4.1: The usual revocation trick of including a time value in the name is referred to at the end of this section but without sufficient detail to allow interop. Why is that ok? (5) cleared",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-21 07:13:57-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-18 07:59:42-08:00",
    "text": "My main discuss point on -02 of this was: (1) I am concerned that  RFC6507  may not be ready for use in standards-track RFCs. So far it has not been and I have found no peer reviewed security or cryptographic analysis that indicates that it is has been studied to see if it is good enough for that. I've also not seen any MANET list discussion of that aspect (and indeed the MANET list discussion I did see seems to involve very few people).\u00a0 I asked on the CFRG list about  RFC6507  and it seems [1] to be the case that no-one has so far really evaluated its security, other than folks associated with the author's institution. (Which applies to both 6507 and this I think.) I also didn't find any references to 6507 in Google scholar.\u00a0 Lastly, I think we should be, and be seen to be, more careful than usual with this draft - given the situation with DUAL-EC-DRBG, and that this is a new signature scheme that allows the KMS to fake anyone's signature and the author involved.\u00a0 Note that that last is not any imputation of misbehaviour, but the IETF would not be\u00a0 doing due-dilligence if we didn't explicitly consider that aspect. \u00a0 [1]  https://www.ietf.org/mail-archive/web/cfrg/current/msg05540.html The authors have added section 6.1 and changed the intended status to experimental which does almost entirely resolve the above. I have one issue with the text of 6.1 though that I think needs fixing before we can proceed. I'll state that in the form of an OLD/NEW suggestion in case that just works: OLD: \t\u00a0  This specification is thus published as experimental, in order to\t  \t\u00a0  encourage its use and reports of its use.\u00a0 Once experiments have been\t  \t\u00a0  carried out and reported, it is intended to advance this\t  \t\u00a0  specification, with any changes identified by such experimentation,\t  \t\u00a0  to standards track. NEW: \t\u00a0  This specification is thus published as experimental, in order to\t  \t\u00a0  encourage its use and reports on its use.\u00a0 Once experiments have been\t  \t\u00a0  carried out and reported, and when some public analysis of the underlying  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  cryptographic algorithms is available, it may be appropriate\u00a0 to advance this\t  \t\u00a0  specification, with any changes identified by such experimentation and \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  analysis, to standards track. My reasoning is as follows: the main problem (I see) with this being on the standards track is the total lack of public analysis of the signature  algorithm. That is not fixed via usage or reports of usage.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-23 03:59:23-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-16 06:22:04-07:00",
    "text": "I would totally be a yes on this document, but I would like to first discuss a processing issue: I do not agree with the assessment that this draft should obsolete  RFC6555 . The draft itself says: \"This document expands on \"Happy Eyeballs\" [ RFC6555 ]...\" which sounds to me like an update. Further I believe  RFC6555  is still a valid algorithm that can be used as specified, also  RFC6555  provides probably more useful background info that is not captured by this new draft. I would recommend to update instead. Also, in any case the obsolete or update should to be mentioned in the abstract.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-11-20 06:09:04-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 21:21:54-08:00",
    "text": "Thanks for all the work that went into creating this document. I have one point that I think needs discussion, although it's entirely possible that I'm thinking about this the wrong way. \u00a73.8: Given that the list of control operators can be expanded in the future, it's not clear what automated tools are supposed to do if they encounter controls that they do not understand. I initially thought that it might be possible to just ignore control operators (and their parameters) if they aren't understood, as this would simply result in a more permissive validation of data against a schema; but the \".and\" control gives an example of a control operator where this kind of elision would fail. With the lack of any version indicators in CDDL, this seems like a straight-up interoperability issue.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-23 21:02:48-07:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 17:46:25-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4234 I am marking this document discussed because I have concerns about whether this document can be interoperably implemented. I have noted a number of points below. DETAIL S 3.5.2. >\u00a0 \u00a0 \u00a0 point.) >\u00a0   >\u00a0  3.5.2.\u00a0 Tables >\u00a0   >\u00a0 \u00a0 \u00a0 A table can be specified by defining a map with entries where the >\u00a0 \u00a0 \u00a0 keytype is not single-valued, e.g.: this is the first use of the term single-valued, so I don't know how to interpret this. More generally: it seems like: ``` \u00a0 square-roots = {x => y} \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  x = int \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  y = float ``` Defines a map and yet ``` \u00a0 square-roots = {x => y} \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  y = float ``` Defines a struct. Is that correct? If so, does that mean that I don't know whether something is a map or a struct until I ahve parsed the whole definition? S 3.5.3. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  mynumber = int / float >\u00a0   >\u00a0  3.5.3.\u00a0 Non-deterministic order >\u00a0   >\u00a0 \u00a0 \u00a0 While the way arrays are matched is fully determined by the Parsing >\u00a0 \u00a0 \u00a0 Expression Grammar (PEG) algorithm, matching is more complicated for PEG is an informative reference, and this text seems to create a normative dependency. S 3.6. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  * tstr => any >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } >\u00a0   >\u00a0  3.6.\u00a0 Tags >\u00a0   >\u00a0 \u00a0 \u00a0 A type can make use of a CBOR tag (major type 6) by using the What happens if I define a type twice? Is that permitted? S 3.7. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  buuid = #6.37(bstr) >\u00a0   >\u00a0 \u00a0 \u00a0 In the following example, usage of the tag 32 for URIs is optional: >\u00a0   >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  my_uri = #6.32(tstr) / tstr >\u00a0   I am basically unable to make sense of this section. Your previous example of tags used #7.25 but here you are specifying everything as using 6. It seems like the semantics here are something to the effect of:  X = #6.Y(Z) means: act as if this were a thing of type Z but it's tagged by Y. Is that correct? But then is this about the wire encoding or the interpretation or both? And in either case, what if what appears on the wire has a different tag. S 3.8.2. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  cwr: 15, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ns: 0, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ) / (4..7) ; data offset bits >\u00a0   >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  rwxbits = uint .bits rwx >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  rwx = &(r: 2, w: 1, x: 0) What is the scope of the definition for r, w, and x? is it global. S 3.9. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  $$tcp-option //= ( >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  sack-permitted: true >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ) >\u00a0   >\u00a0 \u00a0 \u00a0 Names that start with a single \"$\" are \"type sockets\", names with a >\u00a0 \u00a0 \u00a0 double \"$$\" are \"group sockets\".\u00a0 It is not an error if there is no what is the difference between these two? S 7.3. >\u00a0 \u00a0 \u00a0 order of the rules given.\u00a0 (It is not an error to extend a rule name >\u00a0 \u00a0 \u00a0 that has not yet been defined; this makes the right hand side the >\u00a0 \u00a0 \u00a0 first entry in the choice being created.) >\u00a0   >\u00a0 \u00a0 \u00a0 genericparm = \"<\" S id S *(\",\" S id S ) \">\" >\u00a0 \u00a0 \u00a0 genericarg = \"<\" S type1 S *(\",\" S type1 S ) \">\" What is the meaning of\u00a0 ",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-14 22:01:53-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 20:53:14-08:00",
    "text": "(1) Rather a \"discuss-discuss\", but we seem to be requiring some changes to TLS 1.3 that are arguably out of charter.\u00a0 In particular, in Section 8.3 we see that clients are forbidden from sending EndOfEarlyData and it (accordingly) does not appear in the handshake transcript.\u00a0 The reasoning for this is fairly sound; we explicitly index our application data streams and any truncation will be filled in as a normal part of the recovery process, so the attack that EndOfEarlyData exists to prevent instrinsically cannot happen.\u00a0 However, the only reason we'd be required to send it in the first place is if the server sends the \"early_data\" extension in EncryptedExtensions ... and we already have a bit of unpleasantness relating to the \"early_data\" extension, in that we have to use a sentinel value for max_early_data_size in NewSessionTicket to indicate that the ticket is good for 0-RTT, with the actual maximum amount of data allowed indicated elsewhere.\u00a0 TLS extensions are cheap, so a new \"quic_early_data\" flag extension valid in CH, EE, and NST would keep us from conflating TLS and QUIC 0-RTT semantics, thus solving both problems at the same time.\u00a0 On the other hand, that would be requiring implementations to churn just for process cleanliness, so we might also consider other alternatives, such as finessing the language and/or document metadata for how this specification uses TLS 1.3. (There are a couple other places in the COMMENT where we might suffer from scope creep regarding TLS behavior as well, but I did not mark them as DISCUSS since they are not changing existing specified behavior.) (2) Let's check whether the quic_transport_parameters TLS extension should be marked as Recommended or not.\u00a0 The document currently says \"Yes\", and the live registry say 'N'.\u00a0 That said, the earliest mention I can see of using 'N' in the archives is in https://mailarchive.ietf.org/arch/msg/tls-reg-review/z8MOW0bYNP2KIj4XcCXBe2IOKfI/ which seems to just be stating what IANA did when they changed what codepoint (since there were issues with the initially selected value '46') and not a reasoned decision. The perhaps haphazard nature of that change notwithstanding, in my opinion the 'N' actually is correct, since the extension is not appropriate for general use *of TLS* (indeed, we require that TLS implementations that support this document abort the connection if it is used for non-QUIC connections).",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-03-02 08:41:45-08:00",
    "end_reason": "position_updated",
    "start": "2017-03-01 15:05:45-08:00",
    "text": "Thank you for a clear document.\u00a0 I think that this should be a straightforward Discuss to better clarify. In Section 4.8.1, it says \"The RTM Set sub-object contains an ordered list, from egress node to \u00a0  ingress node, of the RTM capable nodes along the LSP's path.\" but the sub-TLVs (as most clearly indicated by \"4.8.1.3.\u00a0 Unnumbered Interface Sub-TLV\" are actually meant to be a list of interfaces. It isn't clear whether these are supposed to be the egress interface, the ingress interface, or just any interface - or why sending just a Router ID wouldn't be sufficient.\u00a0  There is no indication as to whether it is ok to include both the IPv4 and IPv6 address Sub-TLVs for the same node or how to select which one to use.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-11-21 13:49:05-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-10 19:12:55-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5110 I believe there are security issues as detailed in this review. DETAIL S 9. >\u00a0 \u00a0 \u00a0 For such an attack to be effective, the attacker would need to know >\u00a0 \u00a0 \u00a0 both the client identifier and active IPv4 address lease currently in >\u00a0 \u00a0 \u00a0 use by another client.\u00a0 The risk of this can be reduced by using a >\u00a0 \u00a0 \u00a0 client identifier format which is not easily guessable, e.g., by >\u00a0 \u00a0 \u00a0 including a time component for when the client identifier was >\u00a0 \u00a0 \u00a0 generated (see [ I-D.ietf-dhc-rfc3315bis ] Section 11.2). This doesn't seem like a very strong defense. At minimum you need an analysis of the level of entropy. I note that an on-path attacker (as  RFC 3552  requires us to consider) will have no real problem with this attack. This seems fairly serious.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-13 21:21:17-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 22:47:08-08:00",
    "text": "s the genart reviewer noted, the sentence being deleted isin Section 2.1 of RFC 2026, not Section 2.6 (as currently claimed).",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-03-10 08:57:11-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 06:48:23-08:00",
    "text": "Thanks for the effort here. I am putting a discuss as I agree with TSVART review by Bernard Aboba\u00a0 about normative ref to iab-rfcefdp-rfced-model. That will be downref as well.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-06-15 12:17:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 09:53:46-07:00",
    "text": "# ART AD Review of  draft-ietf-avtcore-rtp-vvc-16 cc @fpalombini Thank you for the work on this document. I have two DISCUSS points - hopefully easy to resolve - and a few non blocking comments, but answers will be appreciated. Francesca ## Discuss ### DONL and NALU size in figures 5 and 6 Section 4.3.2: ``` \u00a0  The first aggregation unit in an AP consists of a conditional 16-bit \u00a0  DONL field (in network byte order) followed by a 16-bit unsigned size \u00a0  information (in network byte order) that indicates the size of the ``` Which indicates DONL to be a 16-bit field, but in the figure 5 DONL appears to be 24 bits. ``` \u00a0  An aggregation unit that is not the first aggregation unit in an AP \u00a0  will be followed immediately by a 16-bit unsigned size information \u00a0  (in network byte order) that indicates the size of the NAL unit in ``` Same for the NALU size: 16 bits in the paragraph above, but 24 bits in figure 6. ### IANA Media type review request missing As specified by  RFC6838 , it is strongly encouraged to post the media type registration to the media-types mailing list for review (see  https://mailarchive.ietf.org/arch/msg/media-types/3_DukpPWrpkTXO-zynjJlShtC1w/  for an example of a\u00a0 registration review). Is there any reason this was not done here? If not, please post to the media-types mailing list, and I will remove the discuss with no objections raised in a week or so.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-06-20 03:01:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 12:17:25-07:00",
    "text": "# ART AD Review of  draft-ietf-avtcore-rtp-vvc-16 cc @fpalombini Thank you for the work on this document. I have two (EDIT: one) DISCUSS points - hopefully easy to resolve - and a few non blocking comments, but answers will be appreciated. Francesca ## Discuss ### IANA Media type review request missing As specified by  RFC6838 , it is strongly encouraged to post the media type registration to the media-types mailing list for review (see  https://mailarchive.ietf.org/arch/msg/media-types/3_DukpPWrpkTXO-zynjJlShtC1w/  for an example of a\u00a0 registration review). Is there any reason this was not done here? If not, please post to the media-types mailing list, and I will remove the discuss with no objections raised in a week or so.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-15 06:47:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 06:47:28-07:00",
    "text": "lease be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. Is something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can optiin or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-15 06:48:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 06:47:59-07:00",
    "text": "Please be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. Is something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can optiin or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-15 06:51:55-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 06:48:29-07:00",
    "text": "Please be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. If something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can optiin or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-07-08 06:54:46-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 06:51:55-07:00",
    "text": "Please be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. If something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can opt-in or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-08-18 01:43:12-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-16 05:59:37-07:00",
    "text": "I would like discuss if this specification should be making stronger statement to enforce the reinterpretation the SDP Offer/Answer model for parameters sprop-max-don-diff and sprop-depack-buf-bytes. In section 7.3.2.3, it says sprop-max-don-diff and sprop-depack-buf-bytes parameter should be interpreted differently than usual interpretation of the parameters according to  RFC 3264 . This is a significant change and kind of easy to miss. This section does not use any normative text to enforce the change either.\u00a0  I am also supporting Francesca's discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-20 10:44:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 21:22:10-08:00",
    "text": "I have a very boring Discuss point and a somewhat boring point, and expect to change my ballot to Yes once they're resolved. In Section 3.2 we say that pacing mechanisms \"MAY\" be used to avoid bursts when the CMD is fanning out PBUs, but in Section 6 we say that pacing \"SHOULD\" be used; please resolve the inconsistency (preferrably with \"MUST\" as Mirja requests). Please also include some discussion of privacy considerations (I give some suggestions in the COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-03-08 14:31:21-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 12:54:31-08:00",
    "text": "Thank you for the work put into this document. And congratulations for the many advanced ASCII art ! Except for section 3.6, the text is really easy to read. I have a block DISCUSS below but it should be trivial to fix. Please also address the points raised by Carlos during the INT directorate review. Thank you again Carlos ! https://datatracker.ietf.org/doc/review-ietf-dmm-pmipv6-dlif-05-intdir-telechat-pignataro-2020-02-28/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.3 & 4.4 & 4.5 -- Probably trivial to fix but is \"Prefix Length\" expressed in bits (/64) or in bytes (8 bytes). If the latter, then how can we have a prefix of /57 ? The definition of the \"Prefix length\" field should be specific about the unit (bits/bytes) and be aligned with the definition of \"Anchored prefix\" (as this one seems to assert that the prefix length must be a multiple of 8).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-28 09:06:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-28 09:05:48-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message send by the P/S-MAAR in other modes.  Finally on in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-28 09:06:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-28 09:06:06-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message send by the P/S-MAAR in other modes.  Finally in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-02 02:11:12-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-28 09:06:20-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message sent by the P/S-MAAR in other modes.  Finally in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-19 02:47:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 02:11:12-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message sent by the P/S-MAAR in other modes.  Finally in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST? Update: This discuss is inline with the comments provided by the TSV-ART review (thanks J\u00f6rg!) which lead to an update that don't seem fully addressed. So please review that feedback as well and continue discussion with the TSV-ART reviewer if needed.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-02-03 04:28:08-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-02 13:39:33-08:00",
    "text": "Thank you for writing this much clarifying document! I want to recommend its approval with a 'Yes' position shortly, but before that I had one question which I believe would benefit from some discussion: Section 7.5.1.2 says: \u00a0  If an NTP packet is received with two or more extension fields that \u00a0  require a MAC with different algorithms, the packet MUST be \u00a0  discarded. However, Section 7.5 already said earlier: \u00a0  If a host receives an \u00a0  extension field with an unknown Field Type, the host SHOULD ignore \u00a0  the extension field and MAY drop the packet altogether if policy \u00a0  requires it. This leaves me wondering how the MUST-drop-packet-with-fields-with-different-algs can be implemented. Did you perhaps mean: \u00a0  If an NTP packet is received with two or more extension fields that \u00a0  this receiver recognises and those fields require a MAC with \u00a0  different algorithms, the packet MUST be discarded. Or maybe something else? Can you clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-02-04 07:12:50-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-04 07:09:41-08:00",
    "text": "Suresh Krishnan's Gen-ART review raised a number of comments, and I thought fixing this was important: > I could not find the text in  RFC5905  Section 7.5 that this draft says it is > replacing. Specifically the following \"OLD:\" text does not exist in  RFC5905 Can the authors comment on this and make any changes that might be needed?",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-08-18 07:40:07-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-17 13:04:49-07:00",
    "text": "I would like to Discuss with the other ADs tomorrow on how they perceived the content in the draft, and how well they've been able to review it and convince themselves of its correctness. I had trouble and my Gen-ART reviewer had trouble....",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-06-07 11:12:17-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-13 13:22:33-07:00",
    "text": "I have a question about the interaction between the protocol versioning and the way the flags B-H are defined. This doc specifies that B MUST be set to 0 and that future specs might require it to be set to 1, which could alter the meanings of the C-H flags. This is the same way that B is defined in  RFC 6824 . This spec goes on to define C and H differently from how they are defined in  RFC 6824 . Thus, both v0 and v1 implementations will have B set to 0, but they will have C and H defined differently. I guess it depends on how you interpret \"extensibility flag,\" but my interpretation of this is that the version number negotiated using MP_CAPABLE is the actual extensibility mechanism that this specification is making use of, because although it changed C and H it did not change B. Is this right? If so, I'm wondering what the threshold is for defining new versions of this protocol versus using this extensibility mechanism based on the B flag. Given the way the version negotiation mechanism is defined -- requiring extra round-trips in the event of a fallback attempt, and it being subject to a downgrade attack -- I'm wondering if some guidance needs to be provided about which sorts of protocol changes are expected to be made using the B-flag mechanism versus using the version negotiation mechanism. I guess the drawback of using the B-flag mechanism is that once a future spec sets it to 1, from then on logic within implementations will be required to interpret potentially multiple different semantics of C-H. I guess this potentially raises another question, which is why the B flag isn't just deprecated given the addition of the version negotiation mechanism.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-09-10 11:32:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-03 20:55:54-07:00",
    "text": "This should be a very easy discussion to have and to resolve: \u2014 Section 2.1 \u2014 \u00a0  The OCSP \u00a0  clients SHOULD use a length of 32 octets for the Nonce extension. \u00a0  The minimum nonce length of 1 octet is defined to provide the \u00a0  backward compatibility with older clients following [ RFC6960 ] \u00a0  however, the newer OCSP clients MUST use a length of at least 16 \u00a0  octets for Nonce extension. I\u2019m puzzled by this, so please explain: as long as we\u2019re talking about new clients, developed with this document in place, why shouldn\u2019t it be a MUST to use 32 octets?\u00a0 Why would a new client use 16 bits, rather than 32, and what are the considerations that the coder would need to understand in making that decision?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-03-13 07:14:08-07:00",
    "end_reason": "position_updated",
    "start": "2018-03-06 20:43:57-08:00",
    "text": "* Section 4.25 I think this might be a simple misunderstanding but I have no idea what compliance with this statement implies.  \"A YANG module MUST NOT be designed such that the set of modules found on a server implementation can be predetermined in advance.\" Can you please clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-04-03 03:48:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 03:12:11-07:00",
    "text": " have significant concerns about the practical usability of this proposed model.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-04-03 04:09:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 03:48:30-07:00",
    "text": "I have significant concerns about the practical usability of this proposed model. The intended decoupling of fabric implementation properties (what is termed as \"underlay network infrastructure\" in the document) and its topology seems to be contradicting to general operational practices of fabric based networks. It is generally true for the context of the overlay but that is not what the document seems to be focusing on. Fabric defines and implements the underlay, not the other way around.  The document does not contain a sufficient description of the logic of the model itself, the reasons for choices made for representation of types and attributes, and at the same time descriptions in modules are single lines that do not add clarification beyond being copies of leaf names. Either there needs to be a section that describes the logic of the model and how it relates to other models, also including examples, or module description fields need to have enough content to be able to have equivalent understanding of model intent and operation. Both are strongly encouraged, as descriptions have value of itself for being a reference for use, and model description is needed for understanding how this particular model fits into the larger hierarchy. network management does not end at the boundary of the single domain-specific model.  Why TE topology model is not sufficient for modelling the representation of DC fabric?  How this model could be used for representing more than two stage fabrics that are in wide deployment?  Limiting port bandwidth to a fixed rate is too restrictive. The model as specified already does not cover a set of port speeds that are in wide deployment.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-04-03 04:14:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 04:09:30-07:00",
    "text": "I have significant concerns about the practical usability of this proposed model as it is specified now.  The intended decoupling of fabric implementation properties (what is termed as \"underlay network infrastructure\" in the document) and its topology seems to be contradicting to general operational practices of fabric based networks. It is generally true for the context of the overlay but that is not what the document seems to be focusing on. Fabric defines and implements the underlay, not the other way around.  The document does not contain a sufficient description of the logic of the model itself, the reasons for choices made for representation of types and attributes, and at the same time descriptions in modules are single lines that do not add clarification beyond being copies of leaf names. Either there needs to be a section that describes the logic of the model and how it relates to other models, also including examples, or module description fields need to have enough content to be able to have equivalent understanding of model intent and operation. Both are strongly encouraged, as descriptions have value of itself for being a reference for use, and model description is needed for understanding how this particular model fits into the larger hierarchy. network management does not end at the boundary of the single domain-specific model.  Why TE topology model is not sufficient for modelling the representation of DC fabric?  How this model could be used for representing more than two stage fabrics that are in wide deployment?  Limiting port bandwidth to a fixed rate is too restrictive. The model as specified already does not cover a set of port speeds that are in wide deployment. How would a device that has more than a single role in the fabric be represented?  Service capabilities as they are described belong to the overlay context while they are called device capabilities. Are those the only possible service capabilities? What is the effect of configuring those capabilities?  What is compose-fabric RPC? The document does not define any RPCs.  What is policy driven traffic behavior?  Looking at the history of the document from the individual submission time and the comments received, it seems that the point fixes to the text went in to cover the specific comments but not to address the broader scope of comments. The document would definitely benefit from a major rewrite clarifying the logic behind the decisions made, aligning more with the operational practice of fabric based network design and deployment, and bringing the content in YANG modules to be self-describing.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-04-03 04:30:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 04:14:15-07:00",
    "text": "I have significant concerns about the practical usability of this proposed model as it is specified now.  The intended decoupling of fabric implementation properties (what is termed as \"underlay network infrastructure\" in the document) and its topology seems to be contradicting to general operational practices of fabric based networks. It is generally true for the context of the overlay but that is not what the document seems to be focusing on. Fabric defines and implements the underlay, not the other way around.  The document does not contain a sufficient description of the logic of the model itself, the reasons for choices made for representation of types and attributes, and at the same time descriptions in modules are single lines that do not add clarification beyond being copies of leaf names. Either there needs to be a section that describes the logic of the model and how it relates to other models, also including examples, or module description fields need to have enough content to be able to have equivalent understanding of model intent and operation. Both are strongly encouraged, as descriptions have value of itself for being a reference for use, and model description is needed for understanding how this particular model fits into the larger hierarchy. network management does not end at the boundary of the single domain-specific model.  Why TE topology model is not sufficient for modelling the representation of DC fabric? Why is DC fabric network topology special compared to any generic fabric based topology? How this model could be used for representing more than two stage fabrics that are in wide deployment?  Limiting port bandwidth to a fixed rate is too restrictive. The model as specified already does not cover a set of port speeds that are in wide deployment. How would a device that has more than a single role in the fabric be represented?  Service capabilities as they are described belong to the overlay context while they are called device capabilities. Are those the only possible service capabilities? What is the effect of configuring those capabilities?  What is compose-fabric RPC? The document does not define any RPCs.  What is policy driven traffic behavior?  Looking at the history of the document from the individual submission time and the comments received, it seems that the point fixes to the text went in to cover the specific comments but not to address the broader scope of comments. The document would definitely benefit from a major rewrite clarifying the logic behind the decisions made, aligning more with the operational practice of fabric based network design and deployment, and bringing the content in YANG modules to be self-describing.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-04-03 04:33:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 04:30:12-07:00",
    "text": "I have significant concerns about the practical usability of this proposed model as it is specified now.  The intended decoupling of fabric implementation properties (what is termed as \"underlay network infrastructure\" in the document) and its topology seems to be contradicting to general operational practices of fabric based networks. It is generally true for the context of the overlay but that is not what the document seems to be focusing on. Fabric defines and implements the underlay, not the other way around.  The document does not contain a sufficient description of the logic of the model itself, the reasons for choices made for representation of types and attributes, and at the same time descriptions in modules are single lines that do not add clarification beyond being copies of leaf names. Either there needs to be a section that describes the logic of the model and how it relates to other models, also including examples, or module description fields need to have enough content to be able to have equivalent understanding of model intent and operation. Both are strongly encouraged, as descriptions have value of itself for being a reference for use, and model description is needed for understanding how this particular model fits into the larger hierarchy. Network management does not end at the boundary of the single domain-specific model, it is important to build it into a whole system.  Why TE topology model is not sufficient for modelling the representation of DC fabric? Why is DC fabric network topology special compared to any generic fabric based topology? How this model could be used for representing more than two stage fabrics that are in wide deployment?  Limiting port bandwidth to a fixed rate is too restrictive. The model as specified already does not cover a set of port speeds that are in deployment. How would a device that has more than a single role in the fabric be represented?  Service capabilities as they are described belong to the overlay context while they are called device capabilities. Are those the only possible service capabilities? What is the effect of configuring those capabilities?  What is compose-fabric RPC? The document does not define any RPCs.  What is policy driven traffic behavior? Is there the only one policy that fits all possible deployment scenarios?  Looking at the history of the document from the individual submission time and the comments received, it seems that the point fixes to the text went in to cover the specific comments but not to address the broader scope of comments. The document would definitely benefit from a major rewrite clarifying the logic behind the decisions made, aligning more with the operational practice of fabric based network design and deployment, and bringing the content in YANG modules to be self-describing.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-11-25 11:59:08-08:00",
    "end_reason": "position_updated",
    "start": "2018-04-03 04:33:34-07:00",
    "text": "I have concerns about the practical usability of this proposed model as it is specified now.  The intended decoupling of fabric implementation properties (what is termed as \"underlay network infrastructure\" in the document) and its topology seems to be contradicting to general operational practices of fabric based networks. It is generally true for the context of the overlay but that is not what the document seems to be focusing on. Fabric defines and implements the underlay, not the other way around.  The document does not contain a sufficient description of the logic of the model itself, the reasons for choices made for representation of types and attributes, and at the same time descriptions in modules are single lines that do not add clarification beyond being copies of leaf names. Either there needs to be a section that describes the logic of the model and how it relates to other models, also including examples, or module description fields need to have enough content to be able to have equivalent understanding of model intent and operation. Both are strongly encouraged, as descriptions have value of itself for being a reference for use, and model description is needed for understanding how this particular model fits into the larger hierarchy. Network management does not end at the boundary of the single domain-specific model, it is important to build it into a whole system.  Why TE topology model is not sufficient for modelling the representation of DC fabric? Why is DC fabric network topology special compared to any generic fabric based topology? How this model could be used for representing more than two stage fabrics that are in wide deployment?  Limiting port bandwidth to a fixed rate is too restrictive. The model as specified already does not cover a set of port speeds that are in deployment. How would a device that has more than a single role in the fabric be represented?  Service capabilities as they are described belong to the overlay context while they are called device capabilities. Are those the only possible service capabilities? What is the effect of configuring those capabilities?  What is compose-fabric RPC? The document does not define any RPCs.  What is policy driven traffic behavior? Is there the only one policy that fits all possible deployment scenarios?  Looking at the history of the document from the individual submission time and the comments received, it seems that the point fixes to the text went in to cover the specific comments but not to address the broader scope of comments. The document would definitely benefit from a major rewrite clarifying the logic behind the decisions made, aligning more with the operational practice of fabric based network design and deployment, and bringing the content in YANG modules to be self-describing.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-11 00:52:39-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-30 05:27:11-07:00",
    "text": "# GEN AD review of  draft-ietf-lsr-pce-discovery-security-support-11 CC @larseggert ## Discuss ### Section 4, paragraph 3 ``` \u00a0 \u00a0  Section 4 of [ RFC5088 ] states that no new sub-TLVs will be added to \u00a0 \u00a0  the PCED TLV, and no new PCE information will be carried in the \u00a0 \u00a0  Router Information LSA.\u00a0 This document updates [ RFC5088 ] by allowing \u00a0 \u00a0  the two sub-TLVs defined in this document to be carried in the PCED \u00a0 \u00a0  TLV advertised in the Router Information LSA. \u00a0 \u00a0  Section 4 of [ RFC5089 ] states that no new sub-TLVs will be added to \u00a0 \u00a0  the PCED TLV, and no new PCE information will be carried in the \u00a0 \u00a0  Router CAPABLITY TLV.\u00a0 This document updates [ RFC5089 ] by allowing \u00a0 \u00a0  the two sub-TLVs defined in this document to be carried in the PCED \u00a0 \u00a0  TLV advertised in the Router CAPABILITY TLV. \u00a0 \u00a0  This introduction of additional sub-TLVs should be viewed as an \u00a0 \u00a0  exception to the [ RFC5088 ][ RFC5089 ] policy, justified by the \u00a0 \u00a0  requirement to discover the PCEP security support prior to \u00a0 \u00a0  establishing a PCEP session.\u00a0 The restrictions defined in \u00a0 \u00a0  [ RFC5089 ][ RFC5089 ] should still be considered to be in place. ``` (This is mostly for discussion on the telechat, and I expect to clear during the call.) Why were 5088/89 so strict on not allowing new sub-TLVs? This seems quite unusual for IETF specs. I'm not arguing that this document can't update those earlier RFCs to allow these new sub-TLVs, but it seems odd to do so and in the same sentence say \"the restrictions should still be considered in place.\" ### Section 8.2, paragraph 1 ``` \u00a0 \u00a0  The PCED sub-TLVs were defined in [ RFC5088 ] and [ RFC5089 ], but they \u00a0 \u00a0  did not create a registry for it.\u00a0 This document requests IANA to \u00a0 \u00a0  create a new registry called \"PCED sub-TLV type indicators\" under the \u00a0 \u00a0  \"Interior Gateway Protocol (IGP) Parameters\" grouping.\u00a0 The \u00a0 \u00a0  registration policy for this registry is \"IETF Review\" [ RFC8126 ]. \u00a0 \u00a0  Values in this registry come from the range 0-65535. ``` Should the registration policy not be stricter (e.g., Standards Action?) given that 5088/89 didn't even allow any new values?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-10-10 12:19:03-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-10 09:26:00-07:00",
    "text": "This should be simple to resolve, but it has to be clarified: The shepherd writeup says there were IPR claims made about the document.\u00a0 The question also asks for a summary of the resulting discussion, but the shepherd writeup doesn't provide one.\u00a0 Can we confirm that the discussion was had, or some other answer to the question can be provided?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-10-13 03:47:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-04 09:47:50-07:00",
    "text": "Hi, Sorry for the discuss, but I find a couple of specification aspects of this draft to be unclear enough that I think that they probably warrant a discuss, hopefully easy to explain or resolve: In section 3.2, it wasn't clear to me exactly where I find what the Key-Id is.\u00a0 I suspect that this is probably referring to \"KeyId\" in  rfc5925 .\u00a0 If so, I think that would be emphasizing. In section 3.3, it wasn't clear to me what the Key chain name is, or what exactly it refers to.\u00a0 Is this referring to a local key-chain name installed in a YANG Keystore (given that there is a reference to  RFC8177 ) or something else.\u00a0 Either way, I think that expanding on the description here would probably be very beneficial.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-12-18 11:07:48-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-16 08:45:29-07:00",
    "text": "I have two points below: 1) The first one should be easy to address: \"Transport redundancy mechanisms such as Multipath TCP (MPTCP) and the \u00a0  Stream Control Transmission Protocol (SCTP) will need to be evaluated \u00a0  for applicability. \" This sentence is not correct; MPTP and SCTP do not provide any redundancy mechanisms; they simply just provide a reliable transport as TCP does. Therefore I would just remove this sentence here. Further, on this paragraph, it is not clear to me why you say that reliable transport is needed. Especially for some monitoring purposes, unreliable transport might be acceptable as well. Or do you think that all communication for security systems have always to be reliable? I don't think this document discusses things in detail enough to make such an assessment. 2) This second is a very high level concern and I'm not sure if balloting discuss on this is the right thing to do but I definitely would like to get some feedback from the group to better understand this document before publication: This document seem not very security specific to me. To say this in a somehow sloppy way: I have the feeling that if you would just remove the word \"security\" everywhere in the text, it would still be the same document. I checked the charter and the charter is also not very concrete about what to expect, besides motivating the needed interfaces with the need for in-network security function. However, if there is nothing security specific about this, what's the difference to the usually control plane architecture as usually deployed with the use of NETCONF? And I am actually wondering if this is the right wg to write such a document. Further, I would at least have expected that this framework mandates for high control plan security given we are talking about the configuration and deployment of security function. However, it does not. It does rarely provide any concrete recommendation here, and basically leaves the door open to used these interfaces without authentication which I think is not acceptable.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-11-12 15:56:24-08:00",
    "end_reason": "position_updated",
    "start": "2019-04-11 04:45:50-07:00",
    "text": "This document makes some well-needed extensions to existing PCEP concepts such as bandwidth, but I'm not convinced that the way they interact with existing PCEP functionality is sufficiently well specified to admit interoperable implementation.\u00a0 Specifically, we introduce the generalized bandwidth structures and reuse that encoding for the generalized load balancing structures, which includes a notion of \"minimum bandwidth specification\".\u00a0 But now that the bandwidth specification is a compound data structure instead of a scalar type, it's not guaranteed that we have a strict linear ordering with well-defined minimum.\u00a0 If we consider the specific case of Intserv, do I insist upon all three of the minimum bucket rate, minimum bucket size, and minimum peak data rate?\u00a0 Or perhaps I only care about the peak data rate and not the bucket size/rate.\u00a0 We need more text in order to specify what \"minimum\" actually means/measures. Similarly, I'm not sure all the referenced generalized bandwidth types/traffic parameters in Section 2.3 clearly indicate which structures/fields we are to incorporate by reference (see COMMENT). Section 2.1.2 says: \u00a0  GMPLS-CAPABILITY TLV it is RECOMMENDED that the PCC does not make use \u00a0  of the objects and TLVs defined in this document. Why is this not \"the PCC MUST NOT make use of the objects and TLVs defined in this document\"?\u00a0 Ignoring the peer's (non-)advertisement and plowing ahead seems like a recipe for non-interoperability. Section 2.5.1 notes that: \u00a0 \u00a0 \u00a0 ::= \u00a0 \u00a0 \u00a0 \u00a0 [] \u00a0 \u00a0 \u00a0  [ []]... \u00a0  For endpoint type Point-to-Multipoint, several endpoint objects MAY \u00a0  be present in the message and each represents a leave, exact meaning \u00a0  depend on the endpoint type defined of the object. If all s represent leaves, then how is the head node specified? I couldn't find a full spcification for some of the fields in the XRO Label subobject (Section 2.7) by chasing the indicated references (see COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2019-04-11 14:00:00-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-11 04:19:57-07:00",
    "text": "Hi, thanks for this document. I have a discuss point that shouldn't be difficult to resolve: Why do you define a flag field in the GMPLS-CAPABILITY TLV if you don't have any flag? I guess the easy answer is that there might be some in the future. If so, I tend to think that creating a registry for that field would be a good thing to do now. -m",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-17 07:33:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 15:12:47-07:00",
    "text": "(1) Section 6, Per \u201cThe answer can make that the LSP traverses some geographical place known to the attacker where some sniffing devices could be installed\u201d, this is a concern.\u00a0 Good that it is here.\u00a0 However, it seems like the consequences could be even more expansive \u2013 confidentiality (sniffing), integrity (modifying the traffic) or availability (choose to drop it). (2) Section 6, [ RFC8253 ] is mentioned a few times as having a variety of capabilities to mitigate the described threats.\u00a0 This is the right reference.\u00a0 However, the current text doesn\u2019t explicitly state whether and how this guidance should be followed (should, must, is recommended?)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-10-07 14:32:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 13:11:18-07:00",
    "text": "\u00a78.7: \"it is possible that Flow Specifications will be distributed by BGP as well as by PCEP as described in this document...implementations MAY provide a configuration control to allow one protocol to take precedence over the other as this may be particularly useful if the Flow Specification make identical matches on traffic but have different actions.\" I understand the need to allow one protocol to take precedence over the other. The concern I have is that in BGP's distribution model FlowSpecs are forwarded to other BGP speakers...which may not also be PCCs.\u00a0 If PCEP takes precedence, and the actions are different, then there might be nodes that take the BGP-defined action when not intended to...potentially resulting in unexpected forwarding or rate-limiting of the traffic. Clearly, this issue is related to the different distribution models for the information.\u00a0 If the operator took care of using BGP to distribute FlowSpecs to only the PCCs, then this issue wouldn't exist.\u00a0 I would like to see some text that provides guidance when using both distribution mechanisms.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-29 17:57:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-25 13:31:02-07:00",
    "text": "As with the others, I also found this document to be quite easy to read and well-structured; thank you!\u00a0 I just have a couple points I'd like to discuss, but I am not pressing for a specific resolution and expect to change to No Objection once the discussion has occurred (whatever the conclusion is). This is a Discuss because I want to have a discussion, not because I'm confident in the correctness of my position.\u00a0 But it seems like the ambiguity about when multiple flow specifications in single FLOWSPEC object are treated as logical AND to narrow a single flow specification versus treated as separate flow specifications per Section 8.4 could lead to confusion, and it would be simpler and have less risk to stick to the \"one flow specification per FLOWSPEC object\" model as discussed in the rest of the document.\u00a0 If the ability to define multiple flows within a single FLOWSPEC object is retained, I think we need more specific procedures for identifying when that is the case, quite possibly with a specific enumeration of cases. I also mention in the per-section comments several places where (IIUC) there seems to be a need to match the Speaker Entity Identifier TLV as well as the FS-ID value.\u00a0 It might even be an exhaustive list, but please do a pass to check.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-05 14:41:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 14:34:23-08:00",
    "text": "Thank you for the work on this document. Many thanks to Thomas Fossati for his in-depth review:  https://mailarchive.ietf.org/arch/msg/art/MKG2Cdin96WLcksnA6nAu6pvThM/  , and thanks to the authors for addressing it. I have two comments that need to be addressed before publication. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0 \u00a0  data:\u00a0  }, \u00a0 \u00a0  data:\u00a0  { \"op\": \"add\", \u00a0 \u00a0  data:\u00a0 \u00a0  \"/cdni-advertisement/capabilities-with-footprints \u00a0 \u00a0  /0/footprints/0/footprint-value/-\", \u00a0 \u00a0  data:\u00a0 \u00a0  \"value\": \"192.0.2.0/24\" \u00a0 \u00a0  data:\u00a0  } \u00a0 \u00a0  data: ] FP: JSON doesn't validate. The key \"path\": is missing. 2. ----- Media type registration FP: I haven't seen the media type registrations being reviewed by the media-type mailing list, as requested by  RFC 6838 . Before progressing the document, I would really appreciate the authors to post the registrations to the media-type mailing list for review. Note that people there might also weigh in to the point Thomas made about the media type name, and if it's worth specifying a more detailed media type name, or not in this case.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-17 07:09:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-05 14:41:40-08:00",
    "text": "Thank you for the work on this document, and for partly addressing my previous DISCUSS. Many thanks to Thomas Fossati for his in-depth review:  https://mailarchive.ietf.org/arch/msg/art/MKG2Cdin96WLcksnA6nAu6pvThM/  , and thanks Alexey Melnikov for his media-types review. I will keep this DISCUSS while waiting for the update making the changes discussed with Alexey:  https://mailarchive.ietf.org/arch/msg/media-types/GhN8V1BqwcC4fEThhSRpCcn48gI/ Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-25 05:19:59-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-17 07:09:40-08:00",
    "text": "Thank you for the work on this document, and for partly addressing my previous DISCUSS. Many thanks to Thomas Fossati for his in-depth review:  https://mailarchive.ietf.org/arch/msg/art/MKG2Cdin96WLcksnA6nAu6pvThM/  , and to Alexey Melnikov for his media-types review:  https://mailarchive.ietf.org/arch/msg/media-types/uGakYYYPVjBEwei9isTaluPwhDE/ . Only 2 small changes noted by Alexey are still missing - quoting the relevant text in his mail  https://mailarchive.ietf.org/arch/msg/media-types/LU4gHAY4fQZ6vK7rh8pdSfDwTO0/: 1. >>\u00a0 \u00a0  Also when you split the registration template into 2 it would be \u00a0  >>\u00a0 \u00a0  good to have a sentence here explaining how the two formats differ. > > > Thanks for the suggestion. Could you kindly give us some further  > examples about what should be explained? Do we need to explain the  > different cases where the two subtypes should be used, or just explain  > the difference between the two registration forms? The former. If I as an implementor read the registration, I need to  decide whether or not I should implement processing of this particular  media type. 2. I've just realized that you are also missing \"Fragment identifier  considerations:\" field after this one. (See  RFC 6838 ) Having it as \"N/A\"  is fine. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-05 13:30:45-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:42:11-08:00",
    "text": "The security consideration is silent on how to handle client (uCDN) authentication for this specific CDN use case.\u00a0 Hence, the default guidance from Section 15.13.2 of  RFC7285  seems to apply -- that HTTP Digest Authentication or TLS client authentication could be used. If I understand the use case right, it seems like the uCDNs and dCDNs should know about each other, and there wouldn\u2019t be an unreasonably large number of them to prevent credentials existing for peers.\u00a0 Is there a reason why there isn\u2019t a normative guidance requiring some kind of peer authentication given this narrow use case?\u00a0 If not, why is ok given the significance of this ALTO data in FCI model.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-06-05 03:42:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-01 00:46:50-07:00",
    "text": "This is generally a well written document, but I have a couple of very small points that need to be fixed: Abstract: I have no CLUE what you are talking about. Abstracts should be self contained, i.e. being understandable on its own. The Introduction section has more relevant text which you might want to copy here. In 11.13: you need to have a Normative Reference to the language tag document here ( RFC 5646 ) when you describe the \"lang\" attribute.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-06-05 03:52:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-05 03:42:37-07:00",
    "text": "Thank you for updating the document. However one of the changes looks incorrect to me: You incorrectly using  RFC 2119  as a reference for language tags instead of  RFC 5646 . In 11.13: you need to have a Normative Reference to the language tag document here ( RFC 5646 ) when you describe the \"lang\" attribute.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-15 08:25:53-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-05 03:52:32-07:00",
    "text": "Thank you for updating the document. However one of the changes looks incorrect to me: You incorrectly using  RFC 2119  as a reference for language tags instead of  RFC 5646 . The following changes will address my concern: In 11.3 replace: OLD: \u00a0 Such an attribute is compliant with [ RFC2119 ]. NEW: \u00a0 Such an attribute is compliant with the Language-Tag ABNF production from [ RFC5646 ]. In 11.5 replace: OLD: \u00a0 Each such element has to be compliant with [ RFC2119 ]. NEW: \u00a0 Each such element has to be compliant with the Language-Tag ABNF production from [ RFC5646 ].",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-06-01 10:40:04-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-01 07:22:24-07:00",
    "text": "- 11.2: I would like to discuss whether it's a good idea to allow arbitrary values for mediaType, beyond those types registered in IANA. The text seem to encourage proprietary values. Did the working group consider requiring IANA registration of some sort for new values?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-06-08 08:31:24-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-31 14:37:56-07:00",
    "text": "The document looks good, I just have a couple of items on the security considerations to discuss as they are not mentioned and I'm not sure if they have a good reason to be excluded. 1. Session encryption to prevent active (tampering) or passive (information gathering for example) attacks.\u00a0 Integrity protection and authentication are mentioned, but without looking through a few documents, I don't know if that means encryption or some hash value comparisons or something else.  2. Schema drafts tend to cover the need for well-formed schemas as part of the security considerations.\u00a0 Can you add something in about that (not much is required, but it's good for implementers to know this is important)?\u00a0 You can see two recent examples for guidance: YANG -  https://datatracker.ietf.org/doc/draft-ietf-netmod-rfc6020bis/ IODEF -  https://datatracker.ietf.org/doc/draft-ietf-mile-rfc5070-bis/",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-01 14:34:16-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-01 12:32:19-07:00",
    "text": "There may be no change needed here, but I want to check. This draft defines no security mechanisms and doens't say how to interoperably use any security mechanisms. For example, I don't understand how one might (interoperably) do RBAC or other \"advanced\" security mechanisms that are promised in other CLUE documents. [1] Even worse, I don't get how one could e.g. use XMLENC to encrypt parts of the schema here, as that'd (I think) almost certainty have to have been considered in the design of this schema, but there's no evidence of that. That seems to end up meaning that the only security mechanisms that one can use with CLUE and for which one can currently achieve interop are transport security mechanisms. That all seems to conflict with text in the security consideration of the CLUE protocol draft. So my question to discuss is: other than transport security, what interoperable security mechanisms are expected to be defined in CLUE, and where might I find descriptions of those?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-11-16 08:42:00-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-25 10:08:17-07:00",
    "text": "This document is generally fine, but I would like to clarify a few things before recommending its approval as an RFC: In Section 2: \u00a0 Identifier persistence considerations: \u00a0 \u00a0 \u00a0 ETSI will update the ETSI URN Namespace (EUN) registry to document \u00a0 \u00a0 \u00a0 the registered resources that will use the \"etsi\" NID. URN namespace registrations should not contain forward looking statements and should describe the process that is expected to be used. You already included . Is it where these registered resources will be mentioned? If yes, point to this web page. \u00a0  Process of identifier assignment: \u00a0 \u00a0 \u00a0 Assignment of a URN from the ETSI namespace will be documented as \u00a0 \u00a0 \u00a0 part of the ETSI URN Namespace (EUN) registry. I think\u00a0 already covers this, so please reword this not to use future tense. \u00a0 Security and Privacy: \u00a0  If an namespace is URN-equivalent to another namespace used by the \u00a0  device, as per the rules specified in Section 3.1 of URNs [ RFC8141 ], \u00a0  Section 6.1 of URI Generic Syntax [ RFC3986 ], and the lexical rules \u00a0  specified in this document, the request is rejected. I am not sure how URN equivalence is related to security. Can you elaborate?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-16 14:48:34-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-02 19:38:23-08:00",
    "text": "I'm concerned that this is not sufficiently specified to be implementable in an interoperable fashion.\u00a0 In particular, I'm concerned that there need to be some values allocated from IANA registries that are not currently mentioned in this document, and there are some potential subtleties surrounding data structure reuse that I'm not entirely sure about as well. I include section-by-section comments in this DISCUSS section (populated by duplicating my COMMENT section and trimming; my apologies is a comment is duplicated in both ballot sections by mistake). Section 4.1 \u00a0  Additionally, given a range of potential labels to allocate, the \u00a0  request SHOULD convey the heuristic / mechanism to the allocation. I can't tell which protocol interaction is being described here. \u00a0 \u00a0 ::=  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 Where: \u00a0 \u00a0 \u00a0 \u00a0  ::=[] \u00a0 \u00a0 \u00a0 \u00a0  ::=  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [other optional objects...] Is this intended to conform to any particular formal language, or is it an ad hoc description?\u00a0 Where is\u00a0 defined?\u00a0 ( RFC 5440  spells it as \"\" and not \"\", BTW.) \u00a0  If the WA object is present in the request, it MUST be encoded after \u00a0  the ENDPOINTS object as defined in [PCEP-GMPLS]. Orderings with \u00a0  respect to the other following objects are irrelevant. The prose and the figure do not exactly match up in this regard (is WA optional or mandatory; does\u00a0 need to be the first of the optional objects?). \u00a0 \u00a0  . Wavelength Selection TLV (32 bits): See Section 4.2 for \u00a0 \u00a0 \u00a0 \u00a0 details. Either this is a proper TLV, in which case it has 32 bits of tag and length plus an additional 32 bits of value, for 64 bits total, or it is not a TLV and comprises solely of the \"value\" field of the Wavelength Selection Sub-TLV.\u00a0 Section 8.2 allocates a TLV type indicator for it, which suggests that the full TLV encoding is intended; where are the 32 bits for type and length reflected in this text and in the figure? Section 4.3 \u00a0  The Wavelength Restriction Constraint TLV type is TBD3 (See Section \u00a0  8.3). This TLV MAY appear more than once to be able to specify \u00a0  multiple restrictions. This is in conflict with the diagram in Section 4.1 (which does not appear to depict multiple occurrences).\u00a0 It's also unclear that the stated reasoning applies, since the RBNF indicates that ( ) can repeat, so the need for multiple TLVs is for different *action* (and count) rather than specifically for the wavelength restrictions. How are future \"Action\" values to be defined? \u00a0  Various encoding errors are possible with this TLV (e.g., not \u00a0  exactly two link identifiers with the range case, unknown identifier \u00a0  types, no matching link for a given identifier, etc.). To indicate \u00a0  errors associated with this type, a new Error-Type (TBD8) and an \u00a0  Error-value (Error-value=3) MUST be defined so that the PCE MUST \u00a0  send a PCErr message with a PCEP-ERROR Object. See Section 5.1 for \u00a0  the details. This normative language is not appropriate -- it in effect is only constraining the current document, so descriptive language of \"a new error type is assigned\" is more appropriate. What is the mechanism for extensibility of future Link Identifier sub-TLV types?\u00a0 Should there be a registry? Section 4.3.2 RFC 6205  says that the \"Identifier\" is a per-node assigned and scoped value that may change on a per-hop basis.\u00a0 I don't see where our base label gets scoped to a node (just that it's part of a PCReq message which does not seem scoped to a node), so this seems problematic. Section 4.4 \u00a0  The END-POINTS type generalized endpoint is extended as follows: \u00a0 \u00a0 ::=  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [...] Where is the original\u00a0 definition that is being updated?\u00a0 (Why does this definition not include the  component from [PCEP-GMPLS]?)\u00a0 Why is there no Updates: relationship to reflect this extension?\u00a0 Is\u00a0 supposed to be the same TLV as defined in Section 4.3.2 without a separate containing PCEP object? Per [PCEP-GMPLS],\u00a0 is a TLV.\u00a0 Does that not also mean that  and  need to be (comprised of) sibling TLVs?\u00a0 This document allocates a TLV type for Wavelength Restriction Constraint in Section 8.3, but the references to RFC 7581  for\u00a0 and  seem to only be for the encoding of sub-TLVs, with sub-TLV values that live in the separate \"Types for Subfields of WSON Resource Block Information\" registry and are in a colliding namespace.\u00a0 Don't we need to allocate TLV values from the same place as\u00a0 (i.e., first-level PCEP TLVs) in order for this to be en/decodable? Section 4.4.1 \u00a0  The permitted sub-sub objects are the Optical Interface Class List \u00a0  and the Client Signal information whose encodings are described in \u00a0  Section 4.1 and Section 4.2 of [ RFC7581 ], respectively. Similarly to for the , don't we need to allocate XRO Subobject values in order for these structures to be semantically en/decodable? Section 4.4.2 \u00a0  This is supported by adding the sub-object \"WSON Processing Hop \u00a0  Attribute TLV\" defined for ERO in Section 4.2 [ RFC7689 ] to the PCEP \u00a0  IRO object [ RFC5440 ]. The referenced structure is defined as an RSVP-TE LSP attribute. I cannot find any evidence that its usage in PCEP is defined, nor any TLV or subobject type allocated for its usage with PCEP.\u00a0 (Is there some generic equivalence or mapping between (G)MPLS EROs and IROs and the PCEP analogues that I haven't encountered yet?)\u00a0 Don't we need to allocate an IRO Subobject value for this usage in a PCEP IRO object?\u00a0 Also, the WSON Processing Hop Attribute field is encoded as a sequence of sub-TLVs; if we want to reuse the same sub-TLVs from the existing usage, don't we need to document the linkage from the existing registry to the new usage somewhere? How does the error handling translate to PCEP usage? This seems rather underspecified. Section 5 I'm very confused by the structure definition.\u00a0 It claims to be the \"TLV data\", but also includes a type and length field so as to indicate that it is not just the data contents but the header as well.\u00a0 But the length field is truncated by a bit for use as the 'M' flag -- how can we modify the outer TLV header in this way?!\u00a0 Section 8.4 indicates that this type value is to be allocated from the \"PCEP TLV Type Indicators\" subregistry created by  RFC 5440 , that uses the full 2 bytes for the \"length\" field. Section 5.1 This section describes an Error-value=3 that is not reflected in Section 8.8 in the requests to IANA. Section 8.5 Isn't this mentioned in Section 4.4 (not 4.3)? Section 8.6 As above, isn't this mentioned in Section 4.4 (not 4.3)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-16 14:49:01-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-16 14:48:34-08:00",
    "text": "I'm concerned that this is not sufficiently specified to be implementable in an interoperable fashion.\u00a0 In particular, I'm concerned that there need to be some values allocated from IANA registries that are not currently mentioned in this document, and there are some potential subtleties surrounding data structure reuse that I'm not entirely sure about as well. I include section-by-section comments in this DISCUSS section (populated by duplicating my COMMENT section and trimming; my apologies if a comment is duplicated in both ballot sections by mistake). Section 4.1 \u00a0  Additionally, given a range of potential labels to allocate, the \u00a0  request SHOULD convey the heuristic / mechanism to the allocation. I can't tell which protocol interaction is being described here. \u00a0 \u00a0  . Wavelength Selection TLV (32 bits): See Section 4.2 for \u00a0 \u00a0 \u00a0 \u00a0 details. Either this is a proper TLV, in which case it has 32 bits of tag and length plus an additional 32 bits of value, for 64 bits total, or it is not a TLV and comprises solely of the \"value\" field of the Wavelength Selection Sub-TLV.\u00a0 Section 8.2 allocates a TLV type indicator for it, which suggests that the full TLV encoding is intended; where are the 32 bits for type and length reflected in this text and in the figure? Section 4.3.2 RFC 6205  says that the \"Identifier\" is a per-node assigned and scoped value that may change on a per-hop basis.\u00a0 I don't see where our base label gets scoped to a node (just that it's part of a PCReq message which does not seem scoped to a node), so this seems problematic. Section 4.4.2 \u00a0  This is supported by adding the sub-object \"WSON Processing Hop \u00a0  Attribute TLV\" defined for ERO in Section 4.2 [ RFC7689 ] to the PCEP \u00a0  IRO object [ RFC5440 ]. The WSON Processing Hop Attribute field is encoded as a sequence of sub-TLVs; if we want to reuse the same sub-TLVs from the existing usage, don't we need to document the linkage from the existing registry to the new usage somewhere? How does the error handling translate to PCEP usage? This seems rather underspecified. Section 8.5 Isn't this mentioned in Section 4.4 (not 4.3)? Section 8.6 As above, isn't this mentioned in Section 4.4 (not 4.3)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-01 11:37:32-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-16 14:49:01-08:00",
    "text": "I'm concerned that this is not sufficiently specified to be implementable in an interoperable fashion.\u00a0 In particular, I'm concerned that there need to be some values allocated from IANA registries that are not currently mentioned in this document, and there are some potential subtleties surrounding data structure reuse that I'm not entirely sure about as well. I include section-by-section comments in this DISCUSS section (populated by duplicating my COMMENT section and trimming; my apologies if a comment is duplicated in both ballot sections by mistake). Section 4.1 \u00a0  Additionally, given a range of potential labels to allocate, the \u00a0  request SHOULD convey the heuristic / mechanism to the allocation. I can't tell which protocol interaction is being described here. \u00a0 \u00a0  . Wavelength Selection TLV (32 bits): See Section 4.2 for \u00a0 \u00a0 \u00a0 \u00a0 details. Either this is a proper TLV, in which case it has 32 bits of tag and length plus an additional 32 bits of value, for 64 bits total, or it is not a TLV and comprises solely of the \"value\" field of the Wavelength Selection Sub-TLV.\u00a0 Section 8.2 allocates a TLV type indicator for it, which suggests that the full TLV encoding is intended; where are the 32 bits for type and length reflected in this text and in the figure? Section 4.3.2 RFC 6205  says that the \"Identifier\" is a per-node assigned and scoped value that may change on a per-hop basis.\u00a0 I don't see where our base label gets scoped to a node (just that it's part of a PCReq message which does not seem scoped to a node), so this seems problematic. Section 4.4.2 \u00a0  This is supported by adding the sub-object \"WSON Processing Hop \u00a0  Attribute TLV\" defined for ERO in Section 4.2 [ RFC7689 ] to the PCEP \u00a0  IRO object [ RFC5440 ]. The WSON Processing Hop Attribute field is encoded as a sequence of sub-TLVs; if we want to reuse the same sub-TLVs from the existing usage, don't we need to document the linkage from the existing registry to the new usage somewhere? How does the error handling translate to PCEP usage? This seems rather underspecified.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2019-03-20 12:46:38-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-07 06:57:38-08:00",
    "text": "ANA requested a hold so they can check the revised IANA section.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-05-19 07:22:25-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-18 10:25:14-07:00",
    "text": "First off, let me say that this is a very well written and informative document.\u00a0  I went back and forth when considering my ballot for this document.\u00a0 I decided to put in a DISCUSS for the IESG to talk about the Intended Status and whether anything needs to be done in the current document.\u00a0 My intent is to attract the attention of the IESG towards the Gen-art review (where the topic of the Intended Status first came up [2]) and the longer than expected thread [3] in the teas WG, where a couple of the authors have said that they don't know why BCP is the right answer [4] and [5]. By the time we get to the Telechat (tomorrow!) my comments may have already been taken over by events; if so, I will clear. If asked to decide I would have leaned towards Informational \u2014 there is lot of content describing the problem and an architecture (not a solution).\u00a0 I think Adrian made more persuasive points towards Informational (probably not his intent) in one of his messages to the teas WG [1]. The document does present the best thinking of the WG at this point, but I think it falls short of explicitly documenting the \"the best way to perform some operations\" [ rfc2026 ].\u00a0 In fact, the current way to implement the architecture is left to an Appendix. If the resulting Status remains as BCP (or even Standards Track), then I would like to support Brian Carpenter (Gen-art reviewer) in his request for the document to call out which sections are not normative (5 \u2013 Building on Existing Protocols and 9 \u2013 Scoping Future Work, are high on my list).\u00a0 This action shouldn't require more than a couple of sentences. Just to recap.\u00a0 This DISCUSS is for the IESG to talk\u2026\u00a0 I don't expect any action from the authors at this point \u2014 maybe just help the IESG in the discussion\u2026 [1]  https://mailarchive.ietf.org/arch/msg/teas/ql2RDMcvMZZU9KPKTdKijIqMtBA [2]  https://mailarchive.ietf.org/arch/msg/gen-art/yDlSiKhKzkEhrXbuXSJtdYivhbc [3]  https://mailarchive.ietf.org/arch/msg/teas/qMbaZkMi4iJMAzZPq8SYrxMmtPg [4]  https://mailarchive.ietf.org/arch/msg/teas/aq8YSEDr6BP6V1MdN4ZNTJUQd4k [5]  https://mailarchive.ietf.org/arch/msg/gen-art/kMwMDZ8nU8t4dKKI1ImN3l6YdbY",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-04-14 06:56:57-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-11 04:28:48-07:00",
    "text": "Thank you for the work put into this document. I *really* find the idea and the protocol interesting and useful. The text is also easy to read and to understand (albeit underspecified in some cases -- hence my DISCUSS). Please find below some blocking DISCUSS points (easy to address by adding some text), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Chris Wood for the shepherd's detailed write-up including the WG consensus *but* it lacks the justification of the intended status.  Other thanks to Tim Winters, the Internet directorate reviewer (at my request): https://datatracker.ietf.org/doc/review-ietf-masque-connect-ip-09-intdir-telechat-winters-2023-04-07/  (and I have read the email exchange, thanks to all) I hope that this review helps to improve the document, Regards, -\u00e9ric # DISCUSS (blocking) As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 8 Several parts of this section are unspecified, see below. `Note that ICMP messages can originate from a source address different from that of the IP proxying peer.` is of course obvious, but I think that this case (ICMP originating from the global Internet to the proxy client) deserves a section on its own. Notably whether this source must be within the target ? The source address to be used by the proxy when originating an ICMP should also be specified, even if just a reference to  RFC 6724  for IPv6. ## Section 9.2 In the example where the IP proxy has an IP address in the same prefix as the legacy client (there is no on-link / off-link state for IPv4 as opposed to IPv6), the encapsulation behavior of section 7 requires the TTL to be decremented before entering the tunnel, which is really wrong as it this case it is not formally a routing to a different prefix and some protocols may expect TTL=255, which won't be the case. Request to add some text about this \"issue\".",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-08-08 16:47:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-08 16:45:17-07:00",
    "text": "The way JSON is defined in this document is ambiguous and/or incomplete to such a degree that I doubt interoperability can be achieved. There are two major issues. The first issue is that the \"info\" field is described as containing one of four variations (dn, ski, iasn, and url), but there's no instruction about how to indicate which variation is being used; and, for DistinguishedName, it's not clear how one encodes the issuer and serial elements. There are a handful of ways you could address this. I think the one that makes the most sense is to specify your JSON such that the objects relate to each other in the same way as they do in XML. This means that the \"info\" value would be an object containing one key (selected from \"dn\", \"ski\", \"iasn\", and \"uri\"), and the value of this key would be a string (for dn, ski, and uri) or an object containing an issuer and a serial key (for iasn). An example JSON PAL under this scheme would look like: [ \u00a0 { \u00a0 \u00a0 \"Type\": 3, \u00a0 \u00a0 \"Date\": \"2016-12-29T09:28:00Z\", \u00a0 \u00a0 \"Size\": 1234, \u00a0 \u00a0 \"Info\": { \u00a0 \u00a0 \u00a0 \"url\": \" https://www.example.com/.well-known/est/eecerts/1234 \" \u00a0 \u00a0 } \u00a0 }, \u00a0 { \u00a0 \u00a0 \"Type\": 3, \u00a0 \u00a0 \"Date\": \"2016-12-29T09:28:00Z\", \u00a0 \u00a0 \"Size\": 1234, \u00a0 \u00a0 \"Info\": { \u00a0 \u00a0 \u00a0 \"iasn\": { \u00a0 \u00a0 \u00a0 \u00a0 \"issuer\": \"CN = TrustID Server CA A52, OU = TrustID Server, O = IdenTrust, C = US\", \u00a0 \u00a0 \u00a0 \u00a0 \"serial\": 1 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 } \u00a0 } ] The second issue with JSON handling is that the implied syntax is in violation of  RFC 7159 , section 6 (\"Leading zeros are not allowed.\"). For example, if you take the example given in the document and run it through a JSON parser, you get: { \"Type\": 0003, \"Date\": \"2016-12-29T09:28:00Z\", \"Size\": 1234, \"Info\": \" https://www.example.com/.well-known/est/eecerts/1234 \" } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^ SyntaxError: Unexpected number in JSON at position 11 So, if you keep the fixed-width, zero-padded format for PAL identifiers (and I don't see why you should -- see my comments below), you'll need to encode them as strings rather than integers in JSON.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-12 15:18:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-08 16:47:05-07:00",
    "text": "[NOTE -- While I did not have time to review this document prior to last week's telechat, the author reached out to me to specifically request that I review it and enter a ballot] The way JSON is defined in this document is ambiguous and/or incomplete to such a degree that I doubt interoperability can be achieved. There are two major issues. The first issue is that the \"info\" field is described as containing one of four variations (dn, ski, iasn, and url), but there's no instruction about how to indicate which variation is being used; and, for DistinguishedName, it's not clear how one encodes the issuer and serial elements. There are a handful of ways you could address this. I think the one that makes the most sense is to specify your JSON such that the objects relate to each other in the same way as they do in XML. This means that the \"info\" value would be an object containing one key (selected from \"dn\", \"ski\", \"iasn\", and \"uri\"), and the value of this key would be a string (for dn, ski, and uri) or an object containing an issuer and a serial key (for iasn). An example JSON PAL under this scheme would look like: [ \u00a0 { \u00a0 \u00a0 \"Type\": 3, \u00a0 \u00a0 \"Date\": \"2016-12-29T09:28:00Z\", \u00a0 \u00a0 \"Size\": 1234, \u00a0 \u00a0 \"Info\": { \u00a0 \u00a0 \u00a0 \"url\": \" https://www.example.com/.well-known/est/eecerts/1234 \" \u00a0 \u00a0 } \u00a0 }, \u00a0 { \u00a0 \u00a0 \"Type\": 3, \u00a0 \u00a0 \"Date\": \"2016-12-29T09:28:00Z\", \u00a0 \u00a0 \"Size\": 1234, \u00a0 \u00a0 \"Info\": { \u00a0 \u00a0 \u00a0 \"iasn\": { \u00a0 \u00a0 \u00a0 \u00a0 \"issuer\": \"CN = TrustID Server CA A52, OU = TrustID Server, O = IdenTrust, C = US\", \u00a0 \u00a0 \u00a0 \u00a0 \"serial\": 1 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 } \u00a0 } ] The second issue with JSON handling is that the implied syntax is in violation of  RFC 7159 , section 6 (\"Leading zeros are not allowed.\"). For example, if you take the example given in the document and run it through a JSON parser, you get: { \"Type\": 0003, \"Date\": \"2016-12-29T09:28:00Z\", \"Size\": 1234, \"Info\": \" https://www.example.com/.well-known/est/eecerts/1234 \" } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^ SyntaxError: Unexpected number in JSON at position 11 So, if you keep the fixed-width, zero-padded format for PAL identifiers (and I don't see why you should -- see my comments below), you'll need to encode them as strings rather than integers in JSON.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-13 09:10:27-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-12 15:18:16-07:00",
    "text": "Thanks for addressing my previous DISCUSS and comments. Unfortunately, the new text contains a mismatch between specification and example, which is a common source of incompatibilities -- this leads to a different blocking issue. The specification says: \u00a0 \u00a0 \u00a0  [ | 'iasn'] includes both [ | 'issuer'] \u00a0 \u00a0 \u00a0  and [ | 'serial'] as a complexType in XML and an object \u00a0 \u00a0 \u00a0  in JSON.\u00a0 [ | 'issuer'] is a DN encoded as a string with \u00a0 \u00a0 \u00a0  the format defined in [ RFC4514 ];\u00a0 is a positiveInteger \u00a0 \u00a0 \u00a0  and 'serial' is a number. An excerpt from the relevant example: \u00a0 \u00a0 \u00a0  \"info\": \u00a0 \u00a0 \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0 \u00a0  \"iasn\": \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"issuer\": \"CN=Sean Turner,O=sn3rd,C=US\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"sn\": 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 \u00a0 } Note the difference between \"serial\" (spec) and \"sn\" (example).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-01 11:15:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-01 11:14:59-07:00",
    "text": "I am planning to refine my DISCUSS/comments, but for now the two major points: 1)\u00a0 Every time you say in the document \"HTTP 200 response code with no content\" you should reference HTTP 204 response code  2) Content-Transfer-Encoding header field is not used in HTTP. base64 encoding is not defined, so you can't use it. 3) In the IANA considerations: \u00a0  Package types MUST be paired with a media type. How? Does the list in Section 2.1.1 provide MIME types (it doesn't seem to)?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-01 11:36:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-01 11:15:45-07:00",
    "text": "I am planning to refine my DISCUSS/comments, but for now the following major points (they should be easy to address though): 1)\u00a0 Every time you say in the document \"HTTP 200 response code with no content\" you should reference HTTP 204 response code  2) Content-Transfer-Encoding header field is not used in HTTP. base64 encoding is not defined, so you can't use it. 3) In the IANA considerations: \u00a0  Package types MUST be paired with a media type. How? Does the list in Section 2.1.1 provide MIME types (it doesn't seem to)?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-03 02:07:40-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-01 11:36:27-07:00",
    "text": "I am planning to refine my DISCUSS/comments, but for now the following major points (they should be easy to address though): 1)\u00a0 Every time you say in the document \"HTTP 200 response code with no content\" you should reference HTTP 204 response code , as it means no content. 2) As far as I know Content-Transfer-Encoding header field is not used in HTTP. You can use transfer coding or content coding instead (See ). But either way \"base64\" encoding is not defined in HTTP, so you can't use it. 3) In the IANA considerations: \u00a0  Package types MUST be paired with a media type. How? Does the list in Section 2.1.1 provide MIME types (it doesn't seem to)?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-10-01 10:24:01-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-03 02:07:40-07:00",
    "text": "I am generally fine with publishing this document, but there are several issues (mostly related to HTTP use) which need to be addressed before the document goes forward: 1)\u00a0 Every time you say in the document \"HTTP 200 response code with no content\" you should reference HTTP 204 response code , as it means no content. (We discussed this and proposed text work for me.) 2) As far as I know Content-Transfer-Encoding header field is not used in HTTP. You can use transfer coding or content coding instead (See ). But either way \"base64\" encoding is not defined in HTTP, so you can't use it. Mark Nottingham wrote about this: ------- CTE escapes into HTTP sometimes because of gateways to other protocols, or because of wrong-headed developers, but it has *NO* HTTP semantics. They can send the header all they want (after all, new headers can be introduced by anyone), but it's not interoperable. This was widely known enough that we took advice about it out of HTTPbis; see: \u00a0  https://tools.ietf.org/html/rfc2616#section-19.4.5 Looks like 7030 needs an errata, at a minimum. They don't want content-encoding (it's not terribly useful to introduce a base64 encoding on a binary-clean transport; they probably want to be using a content-type that dictates base64 encoding. Or just send the binary. ------- 3) In the IANA considerations: \u00a0  Package types MUST be paired with a media type. How? Does the list in Section 2.1.1 provide MIME types (it doesn't seem to)? (We discussed this and proposed text work for me.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-10-12 17:09:10-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 17:16:38-07:00",
    "text": "1. The following requirement doesn't seem to do much on its own \u00a0  If a symmetric key package (which might be signed) or an encrypted \u00a0  key package (which might be signed before and after encryption) is \u00a0  digitally signed, the client MUST reject it if the digital signature \u00a0  does not validate back to an authorized TA. [S 5.1] The reason is that an attacker might just strip the signature and then it would be acceptable. So, I think it needs to somehow be paired with a way of knowing when things ought to be signed. There is another instance of this under asymmetric keys. 2. S 1.1. \u00a0  Package: An object that contains one or more content types.\u00a0 There \u00a0  are numerous types of packages: Asymmetric Keys, Symmetric Keys, \u00a0  Encrypted Keys, CRLs, Public Key Certificate Management, Firmware, \u00a0  Public Key Certificates, and TAMP packages.\u00a0 All of these packages \u00a0  are digitally signed and encapsulated in a CMS signed data \u00a0  [ RFC5652 ][ RFC6268 ] (except the public key certificates and CRLs that \u00a0  are already digitally signed); Signed using what key? 3. The reasoning for why some things need client auth and others do not is opaque to me. Like, why does firmware need client auth?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-08-02 12:25:19-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-26 13:41:10-07:00",
    "text": "olding a discuss pending a final answer on an XML schema resolution underway.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-08-02 07:26:53-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 15:27:24-07:00",
    "text": "The XML doesn't seem to validate, and seems to have multiple errors (but it's possible I missed something): The\u00a0 tag on line 17 doesn't seem to be terminated (there is a closing tag on line 66, but it is out of place), there is an extra , etc etc. I finally made it lint clean by doing the following: diff -Naur orig-schema.xml schema.xml --- orig-schema.xml\t2017-08-01 18:17:34.000000000 -0400 +++ schema.xml\t2017-08-01 18:21:09.000000000 -0400 @@ -20,10 +20,10 @@ \u00a0 \u00a0  Subject Key Identifier, Issuer and Serial Number tuple, \u00a0 \u00a0  or URI. \u00a0   -   \u00a0   \u00a0   + \u00a0   \u00a0 \u00a0   \u00a0 \u00a0 \u00a0  This type defines the Package Availability List (PAL). @@ -60,10 +60,10 @@ \u00a0       -\u00a0  +\u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  -\u00a0 \u00a0 \u00a0   + \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0  NOTE: I have NO idea if this still means the same thing, all I know is it satisfied the linter :-P",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 14:22:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-10 17:22:08-07:00",
    "text": "Thank you for this document; it has been a long time coming and is much awaited.\u00a0 That said, I have a few points I'd like to discuss before I can comfortably ballot Yes: I'm happy to see prominent references to RFCs 7525 and 6125. Unfortunately, merely citing  RFC 6125  does not provide a usable specification for an application to implement; we need to additionally state what type of name (e.g., SRV-ID or DNS-ID) is used as input to the validation process and how the application obtains that name.\u00a0 Given that we are defining a service name (and port number) for ntske, SRV-ID might be appropriate (DNS-ID is the most common form I see consumers of  RFC 6125  using). In a related vein, if ALPN is necessary for confirming ntske operation, it's not entirely clear to me that a dedicated port (in addition to service name) is required, and  RFC 6335  discourages fixed port numbera llocations.\u00a0 Perhaps it's not intended that DNS-SD is used to discover NTS-KE servers, though -- there's no reference to  RFC 6763  in this document, or other discussion of server discovery that I can see. We seem to be internally inconsistent about whether the Cookie extension can be encrypted -- Section 5.7 says \"MUST NOT be encrypted\", but Section 5.2 implies that it could be encrypted: \u00a0  Always included among the authenticated or authenticated-and- \u00a0  encrypted extension fields are a cookie extension field and a unique \u00a0  identifier extension field.\u00a0 [...] Section 7.6 says that applications for new record types need to specify the contents of the \"Set Critical Bit\" field, but this field is not included in the table of initial entries.\u00a0 Additionally, there doesn't seem to be a clear description of what the semantics of the \"Set Critical Bit\" field should be.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-22 16:01:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-19 14:22:59-07:00",
    "text": "[updated for -25] Thank you for this document; it has been a long time coming and is much awaited.\u00a0 That said, I have a few points I'd like to discuss before I can comfortably ballot Yes: I'm happy to see prominent references to RFCs 7525 and 6125. Unfortunately, merely citing  RFC 6125  does not provide a usable specification for an application to implement; we need to additionally state what type of name (e.g., SRV-ID or DNS-ID) is used as input to the validation process and how the application obtains that name.\u00a0 Given that we are defining a service name (and port number) for ntske, SRV-ID might be appropriate (DNS-ID is the most common form I see consumers of  RFC 6125  using).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-20 03:28:34-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-18 07:24:58-07:00",
    "text": "Two issues I would like to discucss: 4.1.7.\u00a0 NTPv4 Server Negotiation The \u00a0  contents of the string SHALL be either an IPv4 address, an IPv6 \u00a0  address, or a fully qualified domain name (FQDN). The client MUST NOT send more than one \u00a0  record of this type. I get there are assumptions about which address family to use for this record. Is it assumed that one the KE server will chose what address family the clien'ts request is coming in over? Do there need to be more discussion of this assumption in the document? For example an client indication of an IPv4 address can the server respond with an IPv6? And maybe even more relevant, what if the client has included an IPv6 address in the field in the request, even if the connection to the KE is over IPv4. I would appreciate some clarification or recommendation on how to select what family to use so that the protocol achieve the least amount of surprise here.  Secondly, I struggle to full understand the implementation requirements of the replay protection.  5.7:  \u00a0 \u00a0 \u00a0 Exactly one Unique Identifier extension field which MUST be \u00a0 \u00a0 \u00a0 authenticated, MUST NOT be encrypted, and whose contents MUST NOT \u00a0 \u00a0 \u00a0 duplicate those of any previous request. Is the last \"MUST NOT\" really a MUST NOT in the most strict sense? It could require a client to keep a history of all used Unique Identifiers since it started. I think that would be a significant state management task for the client. I would expect that a client could work well with a window of N packets, where N is in the range hundreds to thousands and using a RNG for the Unique Id field. By tracking requests sent, their timestamp and Unique Id the client wouldn't the client be able to protect against replays? Discard any unknown unique IDs, discard any second reception of Unique IDs. This also depends on that replay packets outside of the window can be detected even if the RNG generated a duplicate ID. I assume so is possible based on that the NTP timestamps that are authenticated will be outside of the window of what is acceptable and not match the request.  To summarize can we get some more clarity on how the client process of replay protection.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-24 11:17:18-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-19 06:10:07-07:00",
    "text": "Two rather small and hopefully quick-to-address points that I think must be clarified before publication of this spec: 1) Sec 5.7: \"In that \u00a0  case, it MUST be able to detect and stop looping between the NTS-KE \u00a0  and NTP servers by rate limiting the retries using e.g. exponential \u00a0  retry intervals.\" Yes, rate limiting and exponential back-off is good here. However, you anyway need to define a maximum number of retries (to actually make it stop at some point) and further given some recommendation for an appropriate rate limit (e.g. initial retry after 3 seconds...?). 2) Sec 4.1.3: \"\u00a0 \u00a0 \u00a0 Error code 2 means \"Internal Server Error\".\u00a0 The server MUST \u00a0 \u00a0 \u00a0 respond with this error if it is unable to respond properly due to \u00a0 \u00a0 \u00a0 an internal condition.\" At least for this error, I think you need to specify what the client should do on reception. Retry? Immediately? How often? Or wait for a while?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-01 08:22:54-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-01 05:55:33-07:00",
    "text": "Apologies if these discuss points are off-base, I was pressed for time when reviewing this:-( (1) section 6 correctly says that encryption and integrity protection are needed to prevent attacks, but the wording seems ambiguous. Does the MUST here mean that a) TURN servers MUST use strong crypto whenever they send tickets or b) if a TURN server does not use strong crypto then tickets can be abused? I hope it's the former, but in any case I think you need to clearly say. (2) I guess the use of (D)TLS is fairly clear here. But I'm less clear that things are ok for the other cases when the ticket is (I guess?) visible to a network attacker. Don't you need to say that in those other cases the server MUST NOT honour the ticket unless the authentication mechanisms have worked out ok?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-03-07 07:30:36-08:00",
    "end_reason": "position_updated",
    "start": "2018-03-07 05:29:49-08:00",
    "text": "Thank you for a well written document. I will be switching to Yes once the following is addressed/discussed: Relationship to TLS 1.2 needs to be clarified. The document is adding requirements on TLS 1.2 clients. Implementors of TLS 1.2 are not going to (or very unlikely to) read this document. This looks fishy to me. Two examples on page 37: \u00a0 TLS 1.2 clients SHOULD also check that the last eight bytes\u00a0 are not equal to the second value if the ServerHello indicates TLS\u00a0 1.1 or below and  A legacy TLS client performing renegotiation with TLS 1.2 or prior\u00a0 and which receives a TLS 1.3 ServerHello during renegotiation MUST\u00a0 abort the handshake with a \"protocol_version\" alert.\u00a0 Note that\u00a0 renegotiation is not possible when TLS 1.3 has been negotiated. There are similar statements on page 45: \u00a0 TLS 1.2 implementations SHOULD also process this extension. and on page 48: \u00a0 However, the old semantics did not constrain the signing \u00a0 curve.\u00a0 If TLS 1.2 is negotiated, implementations MUST be prepared \u00a0 to accept a signature that uses any curve that they advertised in \u00a0 the \"supported_groups\" extension. I think you need to clarify whether these normative requirements apply to pure TLS 1.2 clients or TLS clients that implement both 1.2 and 1.3 and choose to use 1.2 for some reason. Or maybe you need to say in the Abstract/Introduction that although this document obsoletes TLS 1.2 it also specifies new requirements on TLS 1.2 implementations. (So it is sort of both \"Obsoletes\" and \"Updates\" TLS 1.2 RFC.)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2018-01-18 07:55:48-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-04 21:27:50-08:00",
    "text": "I like this document, and look forward to it being published.\u00a0 However, it caught my attention that there are no Normative References. It seems clear to me that (at least) an understanding of the ACP is necessary to properly achieve the objective of the document: \"how to integrate OAM processes with the autonomic control plane (ACP) in Autonomic Networks (AN) in order to provide stable and secure connectivity for those OAM processes.\"\u00a0 I then think that the reference to  I-D.ietf-anima-autonomic-control-plane  should be Normative.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-02-09 04:44:25-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-05 10:23:31-08:00",
    "text": "Section 2.1.5 talks about use of MPTCP: \"DNS naming is set up to provide the ACP IPv6 address of network \u00a0  devices.\u00a0 Unbeknownst to the application, MPTCP is used.\u00a0 MPTCP \u00a0  mutually discovers between the NOC and network device the data-plane \u00a0  address and caries all traffic across it when that MPTCP subflow \u00a0  across the data-plane can be built.\" However, I'm actually uncertain how this is supposed to work and what \"Unbeknownst to the application\" should mean. If another address should be signaled to the other host, this needs to be indicated by the application or at least some kind of policy framework above MPTCP. Also MPTCP will by default use both paths simultaneously while still looking like one connection to the application, meaning the application has no control which path is used for which traffic. I guess you can open a second subflow and then configure the first subflow as backup path but I'm not sure if that's what you want (given the application/policy framework will still not know which path is used)..? Please provide more information about what the expected usage scenario is here.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-10-01 05:14:53-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-29 08:37:53-07:00",
    "text": "Thank you for this document. I have a trivial thing I would like to discuss before recommending approval of this document: Section 3 of  RFC 6066  says: \u00a0  \"HostName\" contains the fully qualified DNS hostname of the server, \u00a0  as understood by the client.\u00a0 The hostname is represented as a byte \u00a0  string using ASCII encoding without a trailing dot. However your example shows in Section 6: \u00a0  For the \"tls-alpn-01\" challenge the subjectAltName extension in the \u00a0  validation certificate MUST contain a single iPAddress that matches \u00a0  the address being validated.\u00a0 As [ RFC6066 ] does not permit IP \u00a0  addresses to be used in the SNI extension HostName field the server \u00a0  MUST instead use the  IN-ADDR.ARPA  [ RFC1034 ] or  IP6.ARPA  [ RFC3596 ] \u00a0  reverse mapping of the IP address as the HostName field value instead \u00a0  of the IP address string representation itself.\u00a0 For example if the \u00a0  IP address being validated is 2001:db8::1 the SNI HostName field \u00a0  should contain \"1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d \u00a0  .0.1.0.0.2.ip6.arpa.\". I.e. there is a trailing dot after \u201carpa\u201d. Is the example wrong or am I missing something?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-10-01 15:03:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-01 08:24:24-07:00",
    "text": "This is either a huge issue, or a complete non-event -- I'm not sure which - please help me understand / convince me I'm missing something. Contrived, but simple example scenario: My local coffeeshop runs their Point of Sale (POS) system on 192.0.2.10. They have a certificate for this (e.g from LE), and all of their credit card machines contact the POS system using https://192.0.2.10.  I now visit the coffee shop, and using e.g ARP spoofing grab 192.0.2.10. I then use ACME to request and get a cert for 192.0.2.10. I now fire up a webserver, the credit card machines happily connect to me, I present a valid cert, and they send me those sweet, sweet credit card numbers. I get that this isn't really an issue with ACME itself, but rather A: the existence of IP based certificates, and B: the fact that the ability to \"control\" an IP is\u00a0 more easily under an attackers control than the ability to \"control\" a useful domain name. As another exmaple, I could construct scenarios where I use BGP route hijacking to control an address remotely, without having to visit the victim network. The Security Considerations section *does* say: \"The CA may wish to perform additional checks not \u00a0  specified in this document.\u00a0 For example if the CA believes an IP \u00a0  identifier belongs to a ISP or cloud service provider with short \u00a0  delegation periods they may wish to impose additional restrictions on \u00a0  certificates requested for that identifier.\" Again, I understand that ACME is \"just\" the protocol / means to automate this, but it seems that this is a sufficiently dangerous thing to be doing that having it more automated is a bad idea.  Please don't misunderstand, I really like ACME - it's made my life much better, but its power / convenience might be dangerous here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-25 16:00:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-21 22:45:38-07:00",
    "text": "(1) Can we check whether it's okay to use the yang \"string\" type for raw cryptographic keys (e.g., ospfv2-key, ospfv3-key)?\u00a0 My understanding was that yang strings were limited to human-readable, but that the crypto keys could be raw binary values. (2) Do we need to say anything about how to indicate when there are discontinuities for the various \"counter\" types?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-26 08:07:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-25 16:00:09-07:00",
    "text": "[\"string\" type for raw keys is intentional, and incentive to move to the more modern key-chain model] (2) Do we need to say anything about how to indicate when there are discontinuities for the various \"counter\" types?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-26 13:03:38-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-20 10:58:39-07:00",
    "text": "A \u201cdiscuss to discuss\u201d.\u00a0 Per the convention outlined in  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines , thank you for clearly noting the implication of not securing these nodes properly.\u00a0  Furthermore, following the convention, I would have expected Section 4 to have enumerated the sensitive writeable/creatable/deletable data nodes; and the sensitive readable nodes individually.\u00a0 For a model this large, I can imagine that individual enumeration would be a long list.\u00a0  In the case of read operations, the text opens with saying that \u201csome of the readable data nodes ...\u201d and later says \u201cThe exposure of the ... LSDB will expose the detailed topology ...\u201d.\u00a0 Can you help me understand which part of ietf-ospf.yang is the LSDB and which parts refer to \u201csome of the readable nodes\u201d?\u00a0 Is there are a difference, or is this text asserting that all parts of the modules are sensitive and need access control?\u00a0  A related line of questioning for the write operation.\u00a0 The text opens with saying that \u201cThere are a number of data nodes defined in ietf-ospf.yang ... [and that] [w]rite operations ... to these nodes without proper protection can have a negative effect on the network operations ... [and] ... the ability to modify OSPF configuration ...\u201d is problematic.\u00a0 Can you help me understand which parts of the text is the \u201cOSPF configuration\u201d vs. \u201cthere are number of data nodes ...\u201d?\u00a0 If there isn\u2019t a different, is the text asserting that all parts of the modules are sensitive and need access control?",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-10-28 04:36:45-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-15 00:38:39-07:00",
    "text": "This is a great document, thank you for writing it. I have one small change request though (based on Dan Romascanu's Gen-ART review): > Multipath TCP was standardized in [ RFC6824 ] Please change this to \"specified\" ( RFC 6824  is experimental).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-10 11:49:20-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 07:48:59-07:00",
    "text": "Thank you for this document. I think this is an important document which should move forward, but I would like to discuss some points before it does so. These might result in simple clarifications, or might require more discussion, but I do hope they help improve the document. General comments: I found confusing to understand how optional or mandatory is the use of CBOR for profiles of this specification compared to the transport used. I understand the need for flexibility, but maybe it should be clarified the implication of using CoAP (is CBOR mandatory then?) vs HTTP (is CBOR always permitted? How is the encoding in that case? Is the same media type application/ace+cbor used in that case?). Note also that while requests include the content type to use, both in case HTTP or CoAP+CBOR are used, the response don't seem to include this information.  I would like it to be clarified what requirements (or even just recommendations) are there to use CoAP vs HTTP for different legs of the exchange - not necessarily remove the flexibility but to clarify for implementers what can be done and what would be the reasoning to do that: for example if both endpoints support HTTP with the AS, most likely you can have HTTP between C and RS, so does it really make sense to run this instead of OAuth 2.0? Right now all is permitted, but does it all make sense? I feel like this type of considerations are missing. As a note - I am not sure what allowing a different encoding than CBOR for any leg of the exchange adds to the specification - it makes things more confusing, and if needed it could be specified in another document. While going through and thinking about encodings (assuming we keep the doc as is with regards to allowing more than just CBOR), I wondered if it would be better to define a new media type to use when the ACE framework is used with HTTP, to differentiate from OAuth 2.0, since some of the endpoints used are the same (/token and /introspect at the AS). I am interested to hear more from my co-AD as well if this would be an OK use of a new media type - I am thinking of the case where AS is supporting both OAuth 2.0 and the Ace framework - or if it is unnecessary, since the encodings are the same, and the parameters are registered in OAuth 2.0 registry.  More detailed comments below. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-11 00:20:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-05-11 00:17:29-07:00",
    "text": "This one should be easy: Section 6.1: * Why is an Experimental status RFC registering a new header field with \"standard\" status?\u00a0 (See  RFC3864 , Section 4.2.1.)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-18 08:26:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-11 00:20:32-07:00",
    "text": "This one should be easy, then I plan to ballot \"Yes\": Section 6.1: * Why is an Experimental status RFC registering a new header field with \"standard\" status?\u00a0 (See  RFC3864 , Section 4.2.1.)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-30 09:39:35-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-23 02:58:49-08:00",
    "text": "Thank you for this document. I have several small comments similar to what was raised by Roman and Ben: 1) In 4.1: \u00a0  :\u00a0 OPTIONAL client user agent that identifies the \u00a0 \u00a0 \u00a0  client application software, technology, and operating system \u00a0 \u00a0 \u00a0  used by the server to identify functional or security \u00a0 \u00a0 \u00a0  constraints, current security issues, and potential future \u00a0 \u00a0 \u00a0  functional or security issues for the client.\u00a0 The \u00a0 \u00a0 \u00a0 \u00a0 element MUST contain at least one of the \u00a0 \u00a0 \u00a0  following child elements: \u00a0 \u00a0 \u00a0  :\u00a0 OPTIONAL name of the client application software \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  with version if available, such as the name of the client SDK \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"EPP SDK 1.0.0\". \u00a0 \u00a0 \u00a0  :\u00a0 OPTIONAL technology used for the client \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  software with version if available, such as \"Java 11.0.2\". \u00a0 \u00a0 \u00a0  :\u00a0 OPTIONAL client operating system used with \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  version if available, such as \"x86_64 Mac OS X 10.11.6\". Is there a registry of allowed values or at least some instructions how to construct these values? There are probably several existing IETF registries that can be reused. If these values are not supposed to be used by servers for anything other than logging (i.e. if they can't be used to work around bugs), then the document needs to say that. 2) In the same section: \u00a0  :\u00a0 OPTIONAL plain text password that is case sensitive, \u00a0 \u00a0 \u00a0  has a minimum length of 6 characters, and has a maximum length \u00a0 \u00a0 \u00a0  that is up to server policy.\u00a0 All leading and trailing whitespace \u00a0 \u00a0 \u00a0  is removed, and all internal contiguous whitespace that includes \u00a0 \u00a0 \u00a0  #x9 (tab), #xA (linefeed), #xD (carriage return), and #x20 \u00a0 \u00a0 \u00a0  (space) is replaced with a single #x20 (space).\u00a0 This element \u00a0 \u00a0 \u00a0  MUST only be used if the [ RFC5730 ]\u00a0 element is set to the \u00a0 \u00a0 \u00a0  \"[LOGIN-SECURITY]\" value. What is the definition of \"whitespace\"? Does this only include characters listed above or does it also include other Unicode characters (e.g. Unicode whitespace property)? If the former, then instead of using \"whitespace that includes ...\" use something like \"whitespace is defined as one of ...\" \u00a0  :\u00a0 OPTIONAL plain text new password that is case \u00a0 \u00a0 \u00a0  sensitive, has a minimum length of 6 characters, and has a \u00a0 \u00a0 \u00a0  maximum length that is up to server policy.\u00a0 All leading and \u00a0 \u00a0 \u00a0  trailing whitespace is removed, and all internal contiguous \u00a0 \u00a0 \u00a0  whitespace that includes #x9 (tab), #xA (linefeed), #xD (carriage \u00a0 \u00a0 \u00a0  return), and #x20 (space) is replaced with a single #x20 (space). \u00a0 \u00a0 \u00a0  This element MUST only be used if the [ RFC5730 ]\u00a0 element \u00a0 \u00a0 \u00a0  is set to the \"[LOGIN-SECURITY]\" value. As above.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-22 18:50:36-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-21 10:34:52-08:00",
    "text": "Perhaps some simple questions (apologies if I'm missing something obvious): since there is no registry of custom events, how do developers of independent implementations know which custom events they should be aiming to support? And how do they understand the semantics associated with custom events beyond what the event names can convey?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-26 14:15:48-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-22 18:30:17-08:00",
    "text": "This document+extension claims to provide \"Login Security\" but has no substantive discussion of why the previous mechanism was insecure and how this extension improves the security.\u00a0 I find it hard to believe that any such discussion could fail to acknowledge that sending the plaintext password (after only processing for whitespace) to the server (akin to SASL PLAIN) is severely lacking on several security-related fronts.\u00a0 While it may be possible that there is adequate justification for only pursuing the smallest incremental improvement in the current document, it would require some additional discussion to convince me that the \"small incremental improvement\" of removing a protocol-level maximum password length is the best choice at this time, as opposed to a broader approach that attempts to tackle more axes upon which \"security\" can be measured.\u00a0 Does this discussion already exist somewhere? (This document also includes functionality for relatively rich event notifications, that are likely worth doing in their own right, but do not seem to be \"security improvements\" per se, to me.) I also think that there many places in the description of the XML elements/attributes that are underspecified, given that XML is traditionally thought of as a machine-readable format.\u00a0 Several instances have already been noted by my fellow IESG members (e.g., custom events, statistical warnings, \"value\" attribute), but they seem prevalent enough that I would like to see the authors make a pass through all the protocol elements and assess which ones need to be machine-readable vs. only for human consumption, and accurately document that.\u00a0 I list some examples in the Comment section, and specifically call out the\u00a0 and\u00a0 encodings, which leaves many ambiguities with respect to what non-ASCII behavior is allowed other than OpaqueString, what constitutes \"whitespace\" in the two listed situations, and whether the password encoding is related to the XML document encoding of the request.\u00a0 As I note in the comment, my understanding was that the PRECIS profiles were intended to be used at a protocol-level (vs. a deployment level) and thus the nature of the profile usage would be fairly tightly specified by this document; perhaps the responsible AD (or someone else) will correct my understanding. I'd also like to have a bit of discussion regarding the prohibition of using the literal string \"[LOGIN-SECURITY]\" as an actual password. Section 3.2 notes '''[t]he server MUST NOT allow the client to set the password to the value \"[LOGIN-SECURITY]\"''', and though I did not do a full case-by-case analysis, this feels like something that a server implementing this extension wants to do always, regardless of whether a given client indicates support for this extension.\u00a0 That seems like it could meet the criteria to mark this document as Updating  RFC 5730 , to reserve this sentinel value.\u00a0 Is there more reasoning for or against having this document Update the password-handling behavior  RFC 5730  to reserve this sentinel value?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-03 07:18:45-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-22 09:51:49-08:00",
    "text": "** Section 3.1.\u00a0 When @type=\u201dstat\u201d and the name of the stat is set in @name, how does a client know the semantics of this stat?\u00a0 Is that negotiated out of band? ** Section 4.1.\u00a0 Per\u00a0 , how are the clients supposed to generate the app, tech or os strings in a way that the server will understand? If this is out of scope, please just say so.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-01-05 09:09:49-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-13 20:36:26-08:00",
    "text": "Sections 6.4.1 and 6.4.2 The Ingress and Egress PE Addresses are encoded as 4 byte fields. How is this expected to work with IPv6 addresses for the PEs?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-08-30 02:46:43-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-20 05:04:07-07:00",
    "text": "As stressed by Dan Romascanu part of his MIB doctor review, clearly not ready to go This is the MIB Doctor Review for draft-ietf-tictoc-ptp-mib-08.txt.  Note that this document has a long history. A MIB Doctor review was performed already by Bert Wijnen back in 2011.  I do not believe that this document is ready for approval in its current form.  Here are my findings.    1.\u00a0 \u00a0 \u00a0  PARSING Using smilint: smistrip -d mibs docs/draft-ietf-tictoc-ptp-mib-08.txt timeout 10 smilint -s -e -l 5 mibs/PTPBASE-MIB 2>report.txt You can access any intermediately created files, the processing report (which might be empty if no errors or warnings have been found), and output files (in case of a conversion request) for reading and download from a temporary server directory for approx. 24 hours. While processing your request the following errors and/or warnings have been found: mibs/PTPBASE-MIB:426: [2] {bad-identifier-case} `XXX' should start with a lower case letter mibs/PTPBASE-MIB:426: [2] {object-identifier-not-prefix} Object identifier element `XXX' name only allowed as first element mibs/PTPBASE-MIB:26: [2] {module-identity-registration} illegal module identity registration Using smicng (thanks to Bert Wijnen): C:\\bw\\smicng\\work>smicng  ptpbase.inc Successful parsing   C:\\bw\\smicng\\work>   **** now setup for STRICT checking:   C:\\bw\\smicng\\work>smicstrict   C:\\bw\\smicng\\work>smicng  ptpbase.inc W: f( rfc2863 .mi2), (274,17) Item \"ifPhysAddress\" should have SIZE specified E: f( rfc2863 .mi2), (1092,23) Index item \"ifRcvAddressAddress\" must be defined with syntax that includes a SIZE W: f( rfc2863 .mi2), (1084,1) Row \"ifRcvAddressEntry\" has indexing that may create variables with more than 128 sub-ids W: f( rfc2863 .mi2), (1103,17) Item \"ifRcvAddressAddress\" should have SIZE specified W: f( rfc2863 .mi2), (1146,15) Variable \"ifIndex\" in notification \"linkDown\" is an index for a table W: f( rfc2863 .mi2), (1158,15) Variable \"ifIndex\" in notification \"linkUp\" is an index for a table W: f( rfc2863 .mi2), (1691,1) OBJECT-GROUP \"ifOldObjectsGroup\" is not used in a MODULE-COMPLIANCE in current module E: f(ptpbase.mi2), (413,19) Sub-Id for item \"ptpbaseMIB\" must be \"number\" or \"name(number)\" format   *** 2 errors and 6 warnings in parsing   C:\\bw\\smicng\\work>   As the two errors refer to the  RFC 2863  module rather than to the PTBASE-MIB: the compilation seems clean.  2.\u00a0 \u00a0 \u00a0  TEXTUAL CONVENTIONS are prefixed differently than the MIB objects. This is not forbidden, but it creates inconsistency. Also the prefix \u2018Clock\u2019 for the TCs hints to a more generic functionality, although the TCs seem to be PTP-related. I would suggest prefixing the TCs also with PTP or Ptp 3.\u00a0 \u00a0 \u00a0  The following TC ClockIdentity ::= TEXTUAL-CONVENTION \u00a0 \u00a0 STATUS\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \"The clock Identity is an 8-octet array... \u00a0 \u00a0 REFERENCE\u00a0 \u00a0 \u00a0  \"Section 7.5.2.2.1 from [IEEE \u00a0 \u00a0 SYNTAX\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 OCTET STRING (SIZE (1..255)) If this is 8-Octet why is the OCTET STRING size 255? 4.\u00a0 \u00a0 \u00a0  I see in the Abstract:  \u00a0  This memo specifies a MIB module in a manner that is both compliant \u00a0  to the SNMPv2 SMI, and semantically identical to the peer SNMPv1 \u00a0  definitions.   Do you actually mean SMIv2 rather than SNMPv2 SMI? I am not sure why this is important, but if this is important, please provide a reference to the document that includes the \u2018peer SNMPv1\u2019 definitions (probably SMIv1)   5.\u00a0 \u00a0 \u00a0  Most of the document speaks about PTP, but in the DESCRIPTION clause at page 7 it mentions:   \u00a0 \u00a0 \u00a0 \u00a0 [IEEE 1588-2008] defines a protocol enabling precise \u00a0 \u00a0 \u00a0 \u00a0 synchronization of clocks in measurement and control systems \u00a0 \u00a0 \u00a0 \u00a0 implemented with packet-based networks, the Precision Time \u00a0 \u00a0 \u00a0 \u00a0 Protocol Version 2 (PTPv2).\u00a0 This MIB does not address the \u00a0 \u00a0 \u00a0 \u00a0 earlier version IEEE Std. 1588(TM)-2002 (PTPv1).    So, when it says \u2018PTP\u2019 does it mean PTPv2 or any version of PTP? It would be good to clarify.   6.\u00a0 \u00a0 \u00a0 \u00a0 The document uses the improper terminology \u2018MIB\u2019 when it means MIB module. For example \u2018Relationship to other Profiles and MIBs\u2019 or \u2018This MIB is intended to be used \u2026\u2019 etc., etc., 7.\u00a0 \u00a0 \u00a0  Idnits complains about an obsolete reference to  RFC 1906 :  -- Obsolete informational reference (is this intentional?):  RFC 1906 \u00a0 \u00a0  (Obsoleted by  RFC 3417 ) 8.\u00a0 \u00a0 \u00a0  I do not believe that Section 3 includes any useful information.  9.\u00a0 \u00a0 \u00a0  The DESCRIPTION clause is unusually long and includes a lot of abbreviations, terminology, architectural details and other pieces of information which is not clear why they need to be hardcoded in the MIB module. Maybe the place for all these is in the currently empty-content section 3?  10.\u00a0  I do not understand how the ClockPortTransportTypeAddress TC works. If this TC defines an address type why is it not an enumeration? What is the string that for example indicates IPv6? Is it \u2018IPv6\u2019? who guarantees that a manager and an agent spell the same? Or is the intention to use the list of identifiers for \u2018Well Known transport types for PTP communication\u2019at page 64? If yes, how is this extended? Probably an IANA maintained enumerated TC would be a better solution.\u00a0  11.\u00a0  Why is not the SYNTAX of ClockQualityClassType an enumeration, when the DESCRIPTION indicates clearly that this is an enumeration.  12.\u00a0  I do not understand how ClockTimeInterval works. The example does not help either. It says \u2018For example, 2.5 ns is expressed as 0000 0000 0002 8000 in Base16.\u2019 and than the SYNTAX is SYNTAX\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 OCTET STRING (SIZE (1..255)) What is the STRING for the object in this example?  13.\u00a0  For objects like ptpDomainIndex there is no need to copy again the possible values in the DESCRIPTION clause, because these are already listed in the TC. 14.\u00a0  Why is ptpDomainClockPortsTotal of SYNTAX Gauge32? Does this value change all the time? Does it latch at a max value?  15.\u00a0  There is no indication of behavior for counter discontinuity, or object for counter discontinuity \u2013 see section 4.6.1.2 in  RFC 4181 16.\u00a0  Why is the SYNATX of ptpbaseClockTransDefaultDSNumOfPorts Counter32? This does not seem to be a counter, but an unsigned integer. 17.\u00a0  The DESCRIPTION clause of the ptpbaseClockPortDSPTPVersion objects reads: \"This object specifies the PTP version being used.\u201d However, the DESCRIPTION clause of the MIB module says that this module refers only to PTPv2. So what does this object stand for? And in any case, how is this coded? (1) for v1 and (2) for v2? Then why is it not an enumerated value? 18.\u00a0  How does ptpbaseClockPortAssociateAddressType work? What would be included under the AutonomousType SYNTAX to make possible interoperability? 19.\u00a0  The Security Considerations section does not follow the template defined at  http://trac.tools.ietf.org/area/ops/trac/wiki/mib-security .",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-03-19 23:36:28-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-20 22:05:50-07:00",
    "text": "Thanks for the work, and happy to approve this document. But before doing so, I wanted to briefly discuss whether all points from Peter Yee's Gen-ART review have been answered, particularly the one about copying text.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-10-09 10:29:49-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-17 23:03:03-07:00",
    "text": "Thanks to everyone who worked on this revision of the STUN protocol. Thanks in particular to the ARTART reviewer and to the authors for actively engaging on the points he raised. I have one concern about interoperability and another about the IANA changes that I believe require changes to the document prior to publication. \u00a714.2: >\u00a0 X-Port is computed by taking the mapped port in host byte order, >\u00a0 XOR'ing it with the most significant 16 bits of the magic cookie, and >\u00a0 then the converting the result to network byte order.\u00a0 If the IP >\u00a0 address family is IPv4, X-Address is computed by taking the mapped IP >\u00a0 address in host byte order, XOR'ing it with the magic cookie, and >\u00a0 converting the result to network byte order.\u00a0 If the IP address >\u00a0 family is IPv6, X-Address is computed by taking the mapped IP address >\u00a0 in host byte order, XOR'ing it with the concatenation of the magic >\u00a0 cookie and the 96-bit transaction ID, and converting the result to >\u00a0 network byte order. The discussion of performing operations \"in host byte order\" is very confusing, and seems likely to cause issues communicating between machines of different endianness. As an implementor, based on this description, I cannot tell whether, given a port of 0x1234 (and operating on a little-endian machine), I'm supposed to do: Port (host order):\u00a0  34 12 Magic Cookie Prefix: 21 12 Result (host order): 15 00 X-Port (net order):\u00a0 00 15 or: Port (host order):\u00a0  34 12 Magic Cookie Prefix: 12 21 Result (host order): 26 33 X-Port (net order):\u00a0 33 26 One of these is clearly wrong. I think it's the first one, but I *also* think that the first one is the most straightforward interpretation of the quoted paragraph. The following would seem to be a complete description of the operation without introducing possible confusion about the difference between host and network order: \u00a0  X-Port is computed by XOR'ing the mapped port with the most significant 16 \u00a0  bits of the magic cookie.\u00a0 If the IP address family is IPv4, X-Address is \u00a0  computed XOR'ing the mapped IP with the magic cookie.\u00a0 If the IP address \u00a0  family is IPv6, X-Address is computed by XOR'ing the mapped IP address with \u00a0  the concatenation of the magic cookie and the 96-bit transaction ID. In all \u00a0  cases, the XOR operation works on its inputs in network byte order (that is, \u00a0  the order they will be encoded in the message). This makes it clear that the proper operation is: Port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 12 34 Magic Cookie Prefix: 21 12 Result / X-Port:\u00a0 \u00a0  33 26 --------------------------------------------------------------------------- \u00a717.3.1: >\u00a0 IANA is requested to update the names for attributes 0x0002, 0x0003, >\u00a0 0x0004, 0x0005, 0x0007, and 0x000B, and the reference from  RFC 5389 >\u00a0 to RFC-to-be for the following STUN methods: ... >\u00a0 0x0003: (Reserved; prior to [ RFC5389 ] this was CHANGE-REQUEST) The attribute 0x0003 is registered by  RFC 5780 , and should not be removed by this document.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-05-04 09:18:16-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-18 09:29:09-07:00",
    "text": "I would like to discuss several issues with the document (which look easy to fix to me) before recommending its approval for publication as an RFC: 1) 14.3.\u00a0 USERNAME \u00a0  The USERNAME attribute is used for message integrity.\u00a0 It identifies \u00a0  the username and password combination used in the message-integrity \u00a0  check. \u00a0  The value of USERNAME is a variable-length value containing the \u00a0  authentication username.\u00a0 It MUST contain a UTF-8 [ RFC3629 ] encoded \u00a0  sequence of less than 509 bytes, and MUST have been processed using \u00a0  the OpaqueString profile [ RFC8265 ]. I am trying to understand if there was a particular reason why you didn't use UsernameCasePreserved (or its case insensitive alternative) profile here which was specifically designed for usernames? \u00a0  A compliant implementation MUST \u00a0  be able to parse UTF-8 encoded sequence of less than 763. I am confused by this statement: you already have 509 bytes above. Is \"no\" missing above? 14.4.\u00a0 USERHASH \u00a0  The USERHASH attribute is used as a replacement for the USERNAME \u00a0  attribute when username anonymity is supported. \u00a0  The value of USERHASH has a fixed length of 32 bytes.\u00a0 The username \u00a0  and the realm MUST have been processed using the OpaqueString profile \u00a0  [ RFC8265 ] before hashing. As above: why didn't you use UsernameCasePreserved profile which was specifically designed for usernames? 2) 14.9.\u00a0 REALM \u00a0  The REALM attribute may be present in requests and responses.\u00a0 It \u00a0  contains text that meets the grammar for \"realm-value\" as described \u00a0  in [ RFC3261 ] but without the double quotes and their surrounding \u00a0  whitespace.\u00a0 That is, it is an unquoted realm-value (and is therefore \u00a0  a sequence of qdtext or quoted-pair).\u00a0 It MUST be a UTF-8 [ RFC3629 ] \u00a0  encoded sequence of less than 128 characters (which can be as long as \u00a0  509 bytes when encoding them and a long as 763 bytes when decoding \u00a0  them), (Here and similar text in several other sections) Can you please elaborate on how you came up with values 509 and 763? And why you need more space for decoding than for encoding of UTF-8. \u00a0  and MUST have been processed using the OpaqueString profile \u00a0  [ RFC8265 ]. 3) 14.16.\u00a0 ALTERNATE-DOMAIN \u00a0  The value of ALTERNATE-DOMAIN is variable length.\u00a0 It MUST be a UTF-8 \u00a0  [ RFC3629 ] encoded sequence of less than 128 characters (which can be Ekr already pointed this out, but I want to expand on this: you need to say whether this allows U-label (which are UTF-8) or A-labels (which are ASCII only). If you only allow Punycode encoded A-labels, this field doesn't need to be UTF-8, it only need to be ASCII. As far as I remember ASCII domain names are limited to 255 bytes. \u00a0  as long as 509 bytes when encoding them and as long as 763 bytes when \u00a0  decoding them). 4)  10.\u00a0 ALTERNATE-SERVER Mechanism \u00a0  If the transport protocol uses TLS or DTLS, then the \u00a0  client looks for an ALTERNATE-DOMAIN attribute.\u00a0 If the attribute is \u00a0  found, the domain MUST be used to validate the certificate using the \u00a0  recommendations in [ RFC6125 ]. When you reference  RFC 6125  you need to provide more details: a) Are you expecting support for DNS-ID, CN-ID or both? I assume you don't support SRV-ID/URI-ID (saying so explicitly would be great too). b) Are you expected to allow wildcards in DNS-IDs/CN-IDs? If yes, you need to say so. There is one more reference to  RFC 6125  in the document, you should make a similar change there as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-04-16 12:57:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-16 12:51:00-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5132 Can you please indicate how you addressed the points Matt Miller raised in his secdir review about the use of MD5. DETAIL >\u00a0 \u00a0 \u00a0 by the agent sending the indication.\u00a0 It primarily serves to >\u00a0 \u00a0 \u00a0 correlate requests with responses, though it also plays a small role >\u00a0 \u00a0 \u00a0 in helping to prevent certain types of attacks.\u00a0 The server also uses >\u00a0 \u00a0 \u00a0 the transaction ID as a key to identify each transaction uniquely >\u00a0 \u00a0 \u00a0 across all clients.\u00a0 As such, the transaction ID MUST be uniformly >\u00a0 \u00a0 \u00a0 and randomly chosen from the interval 0 .. 2**96-1, and SHOULD be I didn't realize this was a SHOULD. ICE depends on it as a security condition, so it probably needs to be a MUST. >\u00a0 \u00a0 \u00a0 For a request or indication message, the agent MUST include the >\u00a0 \u00a0 \u00a0 USERNAME, MESSAGE-INTEGRITY-SHA256, and MESSAGE-INTEGRITY attributes >\u00a0 \u00a0 \u00a0 in the message unless the agent knows from an external indication >\u00a0 \u00a0 \u00a0 which message integrity algorithm is supported by both agents.\u00a0 In >\u00a0 \u00a0 \u00a0 this case either MESSAGE-INTEGRITY or MESSAGE-INTEGRITY-SHA256 MUST >\u00a0 \u00a0 \u00a0 be included in addition to USERNAME.\u00a0 The HMAC for the MESSAGE- This text appears to conflict with S 7.3 of 5245-bis, which says: >\u00a0 \u00a0 \u00a0 STUN Security Feature it is understood that the corresponding STUN >\u00a0 \u00a0 \u00a0 Security Feature bit in the \"nonce cookie\" is set to 1. >\u00a0   >\u00a0 \u00a0 \u00a0 For example, in Section 9.2.4 discussing the PASSWORD-ALGORITHMS >\u00a0 \u00a0 \u00a0 security feature, it is implied that the \"Password algorithms\" bit, >\u00a0 \u00a0 \u00a0 as defined in Section 17.1, is set to 1 in the \"nonce cookie\". I'm not sure I understand the bid down attack here or the proposed defense.\u00a0 Can you please walk through what the assumed attacker capabilities are, what the client and server capabilities are, how the bid down attack works, and how this protects against it?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-04-18 15:48:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-16 12:57:07-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5132 Can you please indicate how you addressed the points Matt Miller raised in his secdir review about the use of MD5. DETAIL >\u00a0 \u00a0 \u00a0 by the agent sending the indication.\u00a0 It primarily serves to >\u00a0 \u00a0 \u00a0 correlate requests with responses, though it also plays a small role >\u00a0 \u00a0 \u00a0 in helping to prevent certain types of attacks.\u00a0 The server also uses >\u00a0 \u00a0 \u00a0 the transaction ID as a key to identify each transaction uniquely >\u00a0 \u00a0 \u00a0 across all clients.\u00a0 As such, the transaction ID MUST be uniformly >\u00a0 \u00a0 \u00a0 and randomly chosen from the interval 0 .. 2**96-1, and SHOULD be I didn't realize this was a SHOULD. ICE depends on it as a security condition, so it probably needs to be a MUST. >\u00a0 \u00a0 \u00a0 For a request or indication message, the agent MUST include the >\u00a0 \u00a0 \u00a0 USERNAME, MESSAGE-INTEGRITY-SHA256, and MESSAGE-INTEGRITY attributes >\u00a0 \u00a0 \u00a0 in the message unless the agent knows from an external indication >\u00a0 \u00a0 \u00a0 which message integrity algorithm is supported by both agents.\u00a0 In >\u00a0 \u00a0 \u00a0 this case either MESSAGE-INTEGRITY or MESSAGE-INTEGRITY-SHA256 MUST >\u00a0 \u00a0 \u00a0 be included in addition to USERNAME.\u00a0 The HMAC for the MESSAGE- This text appears to conflict with S 7.3 of 5245-bis, which says: >\u00a0 \u00a0 \u00a0 STUN Security Feature it is understood that the corresponding STUN >\u00a0 \u00a0 \u00a0 Security Feature bit in the \"nonce cookie\" is set to 1. >\u00a0   >\u00a0 \u00a0 \u00a0 For example, in Section 9.2.4 discussing the PASSWORD-ALGORITHMS >\u00a0 \u00a0 \u00a0 security feature, it is implied that the \"Password algorithms\" bit, >\u00a0 \u00a0 \u00a0 as defined in Section 17.1, is set to 1 in the \"nonce cookie\". I'm not sure I understand the bid down attack here or the proposed defense.\u00a0 Can you please walk through what the assumed attacker capabilities are, what the client and server capabilities are, how the bid down attack works, and how this protects against it?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-22 10:03:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-18 15:48:37-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5132 Can you please indicate how you addressed the points Matt Miller raised in his secdir review about the use of MD5. DETAIL >\u00a0 \u00a0 \u00a0 by the agent sending the indication.\u00a0 It primarily serves to >\u00a0 \u00a0 \u00a0 correlate requests with responses, though it also plays a small role >\u00a0 \u00a0 \u00a0 in helping to prevent certain types of attacks.\u00a0 The server also uses >\u00a0 \u00a0 \u00a0 the transaction ID as a key to identify each transaction uniquely >\u00a0 \u00a0 \u00a0 across all clients.\u00a0 As such, the transaction ID MUST be uniformly >\u00a0 \u00a0 \u00a0 and randomly chosen from the interval 0 .. 2**96-1, and SHOULD be I didn't realize this was a SHOULD. ICE depends on it as a security condition, so it probably needs to be a MUST. >\u00a0 \u00a0 \u00a0 For a request or indication message, the agent MUST include the >\u00a0 \u00a0 \u00a0 USERNAME, MESSAGE-INTEGRITY-SHA256, and MESSAGE-INTEGRITY attributes >\u00a0 \u00a0 \u00a0 in the message unless the agent knows from an external indication >\u00a0 \u00a0 \u00a0 which message integrity algorithm is supported by both agents.\u00a0 In >\u00a0 \u00a0 \u00a0 this case either MESSAGE-INTEGRITY or MESSAGE-INTEGRITY-SHA256 MUST >\u00a0 \u00a0 \u00a0 be included in addition to USERNAME.\u00a0 The HMAC for the MESSAGE- This text appears to conflict with S 7.3 of 5245-bis, which says that you must have MESSAGE-INTEGRITY. >\u00a0 \u00a0 \u00a0 STUN Security Feature it is understood that the corresponding STUN >\u00a0 \u00a0 \u00a0 Security Feature bit in the \"nonce cookie\" is set to 1. >\u00a0   >\u00a0 \u00a0 \u00a0 For example, in Section 9.2.4 discussing the PASSWORD-ALGORITHMS >\u00a0 \u00a0 \u00a0 security feature, it is implied that the \"Password algorithms\" bit, >\u00a0 \u00a0 \u00a0 as defined in Section 17.1, is set to 1 in the \"nonce cookie\". I'm not sure I understand the bid down attack here or the proposed defense.\u00a0 Can you please walk through what the assumed attacker capabilities are, what the client and server capabilities are, how the bid down attack works, and how this protects against it?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-15 03:36:37-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 05:25:30-08:00",
    "text": "The document is generally quite readable, which is great. But I have a few small issues I would like to get clarification on before recommending approval of this document: In 4.1: \u00a0  Message Type: The last byte is used to indicate the type of the \u00a0  EKTField.\u00a0 This MUST be 2 for the FullEKTField format and 0 in \u00a0  ShortEKTField format.\u00a0 Values less than 64 are mandatory to \u00a0  understand while other values are optional to understand. I thought I knew what this meant when I read it, and then I saw this: \u00a0  A receiver \u00a0  SHOULD discard the whole EKTField if it contains any message type \u00a0  value that is less than 64 and that is not understood. \"SHOULD discard ... EKTField\" makes this field NOT mandatory. (If you said \"SHOULD discard the whole packet\", that would have been different.) Also, how \"discard\" different from the following sentence suggesting \"ignore\"? I think you have some inconsistencies/terminology problem here! \u00a0  Message type \u00a0  values that are 64 or greater but not implemented or understood can \u00a0  simply be ignored.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-16 02:20:38-08:00",
    "end_reason": "position_updated",
    "start": "2019-07-15 03:44:36-07:00",
    "text": "ecent ABNF changes (from \"*\" to \"\\*\") made the ABNF invalid.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-02-21 09:17:21-08:00",
    "text": "I'm adding a process discuss to hold things until we get clarity around the IANA expert reviews.  I know Benjamin mentioned this in his DISCUSS; I am duplicating it here in case we clear up the rest of Benjamin's discuss points prior to the IANA questions.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-20 08:33:44-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-19 09:39:57-08:00",
    "text": "[this is a placeholder Discuss\u00a0 to indicate a couple of broad issues early; a full review and ballot position is forthcoming] I think\u00a0 we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection. (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper? I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field.\u00a0 Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-17 13:12:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-20 08:33:44-08:00",
    "text": "I think we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection.\u00a0 (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper? I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field. Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType? I'll also hold a discuss for the IANA NOT OK (I noticed the need for more columns for TLS extension type, at least, and there seems to be more in their review). Please state clearly what the scope of an SPI value (and its binding to EKTKey and\u00a0 other parameters) is; e.g., that it is only defined within a given communications session. Section 4.2.1 \u00a0  Outbound packets SHOULD continue to use the old SRTP Master Key for \u00a0  250 ms after sending any new key.\u00a0 This gives all the receivers in \u00a0  the system time to get the new key before they start receiving media \u00a0  encrypted with the new key. What channel is the \"sending any new key\" to occur on?\u00a0 The most straightforward reading would be in the FullEKTField, but that does not seem to make much sense.\u00a0 (Also, is the \"any new key\" an SRTP master key or an EKTKey?) Section 5's one-paragraph intro doesn't really paint a clear picture for me of why/which DTLS connections are \"secure\" in a way that the central media distribution is not.\u00a0 From reading the whole doc, my perception is that basically this scheme is useful in cases when you have a central hub for DTLS negotiation that's trusted to have access to media plaintext, plus a mesh of SRTP streams (whether centrally mediated or directly connected), and that it's not appropriate when the\u00a0 central hub is not trusted with media access or when there is not a single DTLS party that can distribute the EKT to all (other) participants).\u00a0 Could we get some clear explanation of where this technique is and is not expected to be utilized? Section 5.5.2 has: \u00a0  Note: To be clear, EKT can be used with versions of DTLS prior to \u00a0  1.3.\u00a0 The only difference is that in a pre-1.3 TLS stacks will not \u00a0  have built-in support for generating and processing Ack messages. You need to be more clear about the Ack being needed even when pre-1.3 is in use (which would seem to make DLTS 1.3 a normative reference). (See also the COMMENT about citing both DTLS 1.2 and 1.3.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-05 16:57:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-17 13:12:07-07:00",
    "text": "Thanks for the updates in the -10; we're\u00a0 making progress.\u00a0 I think there are still some issues left to resolve, though. My previous position had: \"\"\"I think we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection.\u00a0 (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper?\"\"\" I think I remember having such a discussion, but cannot find any record of it.\u00a0 Does anyone have a pointer handy (or a corrective to my memory)? Similarly, I don't remember any discussion on: \"\"\"I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field. Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType?\"\"\" We are also still waiting on IANA, if I understand correctly.\u00a0 I do not see  any indication that the needed expert review for TLS ExtensionType allocation has been requested (the authors should initiate this, per  RFC 8447 ), and there may have been other matters that needed clarification.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-11-19 17:25:22-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-05 16:57:26-07:00",
    "text": "Thanks for the updates in the -10; we're\u00a0 making progress.\u00a0 I think there are still some issues left to resolve, though. My previous position had: \"\"\"I think we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection.\u00a0 (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper?\"\"\" I think I remember having such a discussion, but cannot find any record of it.\u00a0 Does anyone have a pointer handy (or a corrective to my memory)? Similarly, I don't remember any discussion on: \"\"\"I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field. Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType?\"\"\" [IANA says they're okay now]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-15 11:32:27-08:00",
    "end_reason": "position_updated",
    "start": "2019-11-19 17:25:22-08:00",
    "text": "The -10 introduced text implying that the DTLS 1.3 retransmission rules are normative, that is in conflict with the existing text indicating that DTLS 1.2 retransmission rules are normative (see COMMENT). The DTLS 1.3 Ack message is a dedicated content-type, not a handshake-type. I support Alexey's Discuss about the ABNF breakage. Note that there is a similar issue in the names of the TLS extensions in the IANA considerations -- the names now include \"\\_\" instead of just \"_\".",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-22 01:42:20-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 07:18:15-08:00",
    "text": "I think there are an important discrpency between the figure and the ABNF for the full EKT message in section 4.1: Figure 1:  \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  : \u00a0 \u00a0  :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 EKT Ciphertext\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  : \u00a0 \u00a0  :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  : \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |\u00a0  Security Parameter Index\u00a0 \u00a0 | Length\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |0 0 0 0 0 0 1 0| \u00a0 \u00a0  +-+-+-+-+-+-+-+-+ The ABNF parts that appears relevant:  \u00a0 \u00a0 EKTCiphertext = 1*256BYTE ; EKTEncrypt(EKTKey, EKTPlaintext) \u00a0 \u00a0 Epoch = 2BYTE \u00a0 \u00a0 SPI = 2BYTE \u00a0 \u00a0 FullEKTField = EKTCiphertext SPI Epoch EKTMsgLength EKTMsgTypeFull Note that the above ABNF states that the SPI is followed by a 16-bit Epoch field prior to the length field.  Can you please ensure that this discrepancy is clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-06-16 03:11:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 09:47:14-07:00",
    "text": "This is I think simply a oversight but I am putting a discuss so that this certainly gets addressed before the document proceeds to the next stage. Section 3.2 does not say what happens when the requirements are not met. There must be guidance on what to do in that case like there are in section 3.3, 3.4 an 3.5.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-04-19 05:36:14-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 04:30:50-07:00",
    "text": "Thank you for the work put into this document. This document describes a nice addition to CBOR. Please find below one blocking DISCUSS points (mainly to generate discussion -- I will clear my DISCUSS most probably after discussion), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Christian Ams\u00fcss for the shepherd's write-up even if the justification for the intended status is somehow weak (but at least present).  I hope that this helps to improve the document, Regards, -\u00e9ric As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: Just a normal DISCUSS based on the absence of  BCP14  and any normative language in a standard track document. Explanations from the authors/WG/AD will be more than welcome as I am not convinced by the shepherd's explanation (basically \"let's avoid down ref\").",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-05-06 04:30:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 19:03:00-07:00",
    "text": "Section 2.1. (a) \"In both enveloping methods, CBOR Protocol designers need to obtain a CBOR tag for each kind of object that they might store on disk.\u00a0 ... The IANA policy for 4-byte CBOR Tags is First Come First Served, ...\" (b) \"This tag needs to be allocated by the author of the CBOR Protocol.\" Both of these statements are made in this section and they appear to conflict.\u00a0 (a) appears to be saying that CBOR tags will be allocated from the FCFS IANA registry to the protocol designer.\u00a0 However, later in the section (b) says that the author is allocating the tags.\u00a0 If the author performing the allocation/assignment, it would seem to be coming from the registry per (a).",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-27 04:53:30-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 12:19:40-07:00",
    "text": "I have two things I'd like to chat about, given that these applicability documents are where the roll WG has iirc said it'd address security and privacy issues with RPL: (1) 7.1.7: Don't you need to turn that \"may not need\" around and say that AMI deployments of RPL REQUIRE implementation (and maybe use) of link layer and higher layer security features? (You almost say that in 9.3 I think, so it'd maybe be good to be crystal clear. (2) Why are there no privacy considerations? I think this document needs that. For example, an AMI mesh based purely on link layer security could be a total privacy nightmare. And part of that is down to RPL - if I can cause lots of folks' traffic to be sent to me, that is RPL's issue. That I can then see the application layer content is not RPL's fault, but is still relevant.\u00a0 I think this section is important to include because the authors here are presumably the ones who know the application layer information. And the sensitive information might not only be readings, it could include packet size, if larger packets are caused by activity such as turning on heating, then larger packets indicate presence and smaller ones absence, depending on weather. I am also concerned that there may be privacy issues arising from the various identifiers in use here.\u00a0 Did the WG consider these issues and their potential impact on how it is or is not safe to use RPL? (While the analysis might sound complex, I'd bet that not much new text would be needed, but who knows until the analysis has been done.)",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-04-13 06:20:26-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-04 10:41:07-07:00",
    "text": "Sec 5.2 says: \"Cloud Access (cloud-access):\u00a0 All sites in the L2VPN MUST be \u00a0 \u00a0 \u00a0 authorized to access to the cloud.\u00a0 The cloud-access container \u00a0 \u00a0 \u00a0 provides parameters for authorization rules.\u00a0 A cloud identifier \u00a0 \u00a0 \u00a0 is used to reference the target service.\u00a0 Th\" But Sec 5.2.3 says: \"By default, all sites in the L2VPN SHOULD be authorized to access the \u00a0  cloud.\u00a0 If restrictions are required, a user MAY configure the \u00a0  \"permit-site\" or \"deny-site\" leaf-list.\u00a0 The permit-site leaf-list \u00a0  defines the list of sites authorized for cloud access.\u00a0 The deny-site \u00a0  leaf-list defines the list of sites denied for cloud access.\u00a0 The \u00a0  model supports both \"deny-any-except\" and \"permit-any-except\" \u00a0  authorization.\" These seem to be conflicting normative requirements. At a minimum, they need to be aligned (presumably to the formulation in 5.2.3, given the existence of permit-site and deny-site). But more generally, why does the model need to normatively require nodes to have a certain kind of access? As the Gen-ART reviewer pointed out, this doesn't seem necessary. And given that the cloud-access configuration requires the specification of a specific cloud-access identifier, what does it even mean that nodes should be authorized to access \"the\" cloud?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-02-09 08:59:21-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-17 11:07:23-08:00",
    "text": "I have a couple of questions and observations I'd like to discuss. (1) From Section 3: \"The scenarios serve as examples.\u00a0 This document does not restrict the \u00a0  applicability of the THIRD_PARTY_ID to certain scenarios.\u00a0 The \u00a0  THIRD_PARTY_ID can include any Layer-2 identifier like a MAC address \u00a0  or other subscriber identifiers as, for example, mentioned in section \u00a0  6 of [ I-D.boucadair-pcp-sfc-classifier-control ].\u00a0 The THIRD_PARTY_ID \u00a0  can also be used for the firewall control, including the case of a \u00a0  virtual CPE, see section 3 of [ I-D.lee-vhs-usecases ].\" I think the document makes a reasonable case for why carrying a tunnel ID in a THIRD_PARTY_ID option is useful. I don't think it makes a reasonable case for any other use of the option, though, given the potential security and privacy issues associated with sending a potentially unique and permanent subscriber identifier. The drafts mentioned above envision much broader uses for both the option and PCP than the use case in this document, and suggest some uses of the option that seem like a mismatch for what the identifiers embedded within it were originally intended for (e.g., using an IMSI for traffic classification/policing).  Conflating these cases also makes it difficult to understand how the THIRD_PARTY_ID relates back to NAT. Presumably, a PCP-controlled NAT needs traffic on the incoming side to always include the THIRD_PARTY_ID -- otherwise, the fact that the mapping table contains the additional ID is only useful in one direction. This seems workable when the THIRD_PARTY_ID is a tunnel ID, but not for any identifier that anyone might stick in there. Again coming back to the traffic policing scenario, it seems unlikely that every time I as the subscriber send traffic through the NAT, my IMSI will be included to differentiate my traffic from another subscriber who has the same internal address as I do. So by allowing this field to contain any identifier, it becomes less obvious why PCP should be used to communicate it in the first place. In short, I think this draft needs to either more narrowly specify a means to communicate a tunnel ID, or provide both a more thorough security and privacy analysis of the implications of sending any identifier and an explanation of the implications on the availability of those identifiers in traffic sent to a PCP-controlled NAT. (2) Section 5.2 seems underspecified.  RFC 6887  has a lot logic riding on the question of whether two requests are meant to identify the same host or not (in sec 11.3 and sec 12.3) based on the combination of internal address, protocol, and port, but this draft leaves unspecified what the comparison logic is supposed to be or the error conditions that result from adding another field to the determination of whether two hosts are the same or not. For example, is every instance of \"internal address, protocol, and port\" in those sections meant to be replaced with \"internal address, protocol, port, and THIRD_PARTY_ID\"? If a device that already has a mapping for a particular internal address, port, protocol and THIRD_PARTY_ID receives a new request for the same internal address, port, and protocol but has no THIRD_PARTY_ID, what steps is it supposed to follow? Saying that the THIRD_PARTY_ID should be \"used in addition when accessing a mapping table\" doesn't seem like enough detail to go implement this.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-02-23 08:52:26-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-19 02:45:40-08:00",
    "text": "Suresh Krishnan raised an issue in his Gen-ART review about the lack of specification for the format of identifiers. And I agree that is an issue that should be fixed. Based on recent e-mail, the authors seem to agree as well, so hopefully we can fix this.  I would also like to add that the issue is not one of mere comparison. It is a basic issue of building equipment that can interoperate, involving clients and servers and so on from multiple vendors. I have no specific suggestion for a fix, but further standardisation of the formats for typical values while leaving some room for opaque identifiers would perhaps be one avenue.",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2015-11-22 13:12:56-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-17 07:19:39-08:00",
    "text": "I see the secdir reviewer has raised this issue as well, but from my vantage point the issue of is slightly different. the use of the mac address or alternatively a different third party identifier is underspecified. What's the purpose of using a stable identifier except to facilitate tracking? if that's the case then it should be a spelled out,\u00a0 a pcp interworking function could use basically anything to distinguish between two hosts when requesting a mapping, e.g. the mapping is bound to ip addresses. Extending the the option to applications outside of the L2 domain (as described in section 3) proposes to extended the use of this mac based identifier still further, which seems like an opportunity for information leakage outside the scope of the L2 domain, when ephemeral or session based identifiers might be more appropriate.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-22 09:33:15-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-18 16:58:11-08:00",
    "text": "(1) The THIRD_PARTY stuff in PCP was always a bit concerning from a security point of view.  RFC 6887  says that you MUST NOT implement or use that except in some specific environments. At the time we would have liked to say that you MUST use PCP authentication when using that but  RFC 7652  wasn't done until some time later. My DISCUSS question though is: why can't you distinguish based on a Key ID used with PCP authentication? Wouldn't that help with the privacy concerns (one can manage Key IDs well if one wants) and also with the secrity concerns, and I would guess it should solve the tunnel issues that this is intended to address as well? (There may be good reasons why that doesn't work of course, but I'd like to understand them.) (2) Section 7: The \"must be fully trusted\" phrase is not a good one to use - iirc that was a compromise figured out to allow PCP to proceed ahead of the PCP auth spec.\u00a0 And of course, it's really a nonsense. I think you should properly characterise the issues or else delete the unfortunate phrase. I also think you should not encourage the use of this for carrying location or profile information.\u00a0 What \"Means\" exist that could be used to really protect this? And why do you want to \"protect unauthorized access\"? that's oddly phrased at best. All in all I think you need better text for section 7, and I'm happy to try help find that.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-27 02:47:33-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-22 09:33:15-08:00",
    "text": "(Emailed authors on Jan 22nd, 2nd issue may be solved, not clear about 1st) (1) The THIRD_PARTY stuff in PCP was always a bit concerning from a security point of view.  RFC 6887  says that you MUST NOT implement or use that except in some specific environments. At the time we would have liked to say that you MUST use PCP authentication when using that but  RFC 7652  wasn't done until some time later. My DISCUSS question though is: why can't you distinguish based on a Key ID used with PCP authentication? Wouldn't that help with the privacy concerns (one can manage Key IDs well if one wants) and also with the secrity concerns, and I would guess it should solve the tunnel issues that this is intended to address as well? (There may be good reasons why that doesn't work of course, but I'd like to understand them.) (2) Section 7: The \"must be fully trusted\" phrase is not a good one to use - iirc that was a compromise figured out to allow PCP to proceed ahead of the PCP auth spec.\u00a0 And of course, it's really a nonsense. I think you should properly characterise the issues or else delete the unfortunate phrase. I also think you should not encourage the use of this for carrying location or profile information.\u00a0 What \"Means\" exist that could be used to really protect this? And why do you want to \"protect unauthorized access\"? that's oddly phrased at best. All in all I think you need better text for section 7, and I'm happy to try help find that.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-06-25 00:25:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-05 23:29:57-07:00",
    "text": "Thank you for the work put into this document. I found the use cases part of section 3.1 very interesting to read even if some of them seem very far fetched ;-) Please find below some blocking DISCUSS points (easy to address though), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to - Carlos Bernardos for the shepherd's write-up even if a justification for the informational status would have been welcome but the WG consensus description is appreciated.  - Pascal Thubert for his IETF last call INT directorate review at:  https://datatracker.ietf.org/doc/review-ietf-ipwave-vehicular-networking-20-intdir-lc-thubert-2021-06-18/  and for his IESG telechat INT directorate review  https://datatracker.ietf.org/doc/review-ietf-ipwave-vehicular-networking-27-intdir-telechat-thubert-2022-02-28/  Pascal's Last Call & telechat reviews were (at least partially) acted upon by Paul ;-) I hope that this helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Abstract & Section 1 \"then enumerates requirements for the extensions of those IPv6 protocols\" does not match any IPWAVE WG work item, i.e., it is outside the scope of the charter of IPWAVE WG. As the document does not explicitly specify requirements, I strongly suggest to use the word \"gaps\" rather than \"requirements\" in the abstract and section 1. ## Section 4.1 Using an IPv6 address out of a ULA prefix still requires DAD. So the text below should be updated to be corrected: \u00a0 \"their own IPv6 Unique Local Addresses \u00a0  (ULAs) [ RFC4193 ] over the wireless network, which does not require \u00a0  the messaging (e.g., Duplicate Address Detection (DAD)) of IPv6 \u00a0  Stateless Address Autoconfiguration (SLAAC) [ RFC4862 ].\" ## Section 4.2 Very similar comment as above (i.e., DAD & MLD must be done for all IPv6 addresses of an interface and not only for the global one): \u00a0 \"... When global IPv6 \u00a0  addresses are used, wireless interface configuration and control \u00a0  overhead for DAD\" ## Section 5.2 \u00a0 \"... If DHCPv6 is used to assign \u00a0  a unique IPv6 address to each vehicle in this shared link, DAD is not \u00a0  required. \" This is incorrect and must be changed (see section 18.2.10.1. of  RFC 8415 )",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-23 09:04:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-04-05 20:17:31-07:00",
    "text": "I had difficulty in understanding the bounds for the scope of the use cases and proposed architecture.\u00a0 At times I had trouble understanding what was an example of related work, and what was narrative formally describing the gaps in IPv6 for vehicular networking.\u00a0 In that spirit: ** The Privacy Considerations are under-specified: -- Section 6.3 suggests the needs for logging, \u201cTo deal with this kind of security issue, for monitoring suspicious behaviors, vehicles' communication activities can be recorded in either a central way through a logging server (e.g., TCC) in the vehicular cloud or a distributed way (e.g., blockchain [Bitcoin]) along with other vehicles or infrastructure.\u00a0 To solve the issue ultimately, we need a solution where, without\u00a0 \u00a0 privacy breakage, \u2026\u201d.\u00a0 Some discussion on the \u201cprivacy breakage\u201d is needed.\u00a0 What exactly would be the trade offs between a centralized vs. distributed log?\u00a0 Who would get to see this information?\u00a0 What is sensitive about this information? -- Section 5.1.2 and 6.3 highlights the use of MAC address pseudonyms.\u00a0 This is helpful.\u00a0 More discussion is needed about the associate privacy threat being mitigated.\u00a0 Section 6.3 mentions an \u201cadversary from tracking a vehicle\u201d which I think means a passive observer of the path.\u00a0 However, there are other entities in which ecosystem \u2013 what is the privacy exposure to the TCC, V2I, etc?\u00a0 The opening in Section 6 notes that \u201cvehicles and infrastructure must be authenticated\u201d and those credentials (perhaps bound to even MAC pseudonyms) would also facilitate tracking even given MAC pseudonyms.\u00a0 Section 6.1 explicit comments on using VINs in certificates.\u00a0 Who are the assumed trusted actors? -- Section 3.3 notes a V2P use case where the pedestrian\u2019s smart-phone is sharing unspecified information.\u00a0 Does that include location information?\u00a0 Who gets it?\u00a0 What kind of identifiers are shared? ** Section 4.2 \u00a0  Note that it is dangerous if the \u00a0  internal network of a vehicle is controlled by a malicious party.\u00a0 To \u00a0  minimize this kind of risk, an reinforced identification and \u00a0  verification protocol shall be implemented.  -- What are these dangers? -- What is a \u2018reinforced identification\u2019? -- Who are the parties in this verification protocol?\u00a0 What security properties is this verification providing? ** Section 6. \u00a0  Vehicles and infrastructure must be authenticated in order to \u00a0  participate in vehicular networking.\u00a0  Authenticated with respect to whom? Vehicles to infrastructure and vice-versa?\u00a0 Or to someone else? ** Section 6 makes references to \u201csecure communication\u201d \u2013 what is the expected key management approach and is that in scope? ** The need for safety properties (very helpful) is asserted multiple times but not further discussed in the Security Considerations: -- Section 3:\u00a0  \u00a0 \u00a0 \u00a0  In addition, IPv6 \u00a0 \u00a0 \u00a0 security needs to be extended to support those V2V use cases in a \u00a0 \u00a0 \u00a0 safe, secure, privacy-preserving way. -- Section 3.1:  \u00a0 \u00a0 \u00a0 To support applications of these V2V use cases, the required \u00a0 \u00a0  functions of IPv6 include IPv6-based packet exchange and secure,\u00a0 \u00a0  \u00a0 \u00a0  safe communication between two vehicles.\u00a0  -- Section 3.3: \u00a0  To support applications of these V2X use cases, the required \u00a0  functions of IPv6 include IPv6-based packet exchange, transport-layer \u00a0  session continuity, and secure, safe communication between a vehicle \u00a0  and a pedestrian either directly or indirectly via an IP-RSU.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-11-02 15:42:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-23 09:04:49-07:00",
    "text": "Thanks for all of the changes in -29 to address the DISCUSS points noted for -28.\u00a0 To help us talk these through the remaining issues, I have updated my ballot to remove issues that have already been resolved.\u00a0 I have also provided feedback on the new text in -29 intended to resolve the original DISCUSS points. (1) The Privacy Considerations are under-specified: (1.a) [per -28] Section 6.3 suggests the needs for logging, \u201cTo deal with this kind of security issue, for monitoring suspicious behaviors, vehicles' communication activities can be recorded in either a central way through a logging server (e.g., TCC) in the vehicular cloud or a distributed way (e.g., blockchain [Bitcoin]) along with other vehicles or infrastructure.\u00a0 To solve the issue ultimately, we need a solution where, without\u00a0 \u00a0 privacy breakage, \u2026\u201d.\u00a0 Some discussion on the \u201cprivacy breakage\u201d is needed.\u00a0 What exactly would be the trade offs between a centralized vs. distributed log?\u00a0 Who would get to see this information?\u00a0 What is sensitive about this information? From -29: \u00a0  Alternatively, for \u00a0  completely secure vehicular networks, we shall embrace the concept of \u00a0  \"zero-trust\" for vehicles in which no vehicle is trustable and \u00a0  verifying every message (such as IPv6 control messages including ND, \u00a0  DAD, NUD, and application layer messages) is necessary.\u00a0 In this way, \u00a0  a failure to prevent a cyberattack shall never happen on a vehicular \u00a0  network.\u00a0 Thus, we need to have an efficient zero-trust framework or \u00a0  mechanism for vehicular networks. I\u2019m speculating that the second from last sentence, \u201c[i]n this way, a failure to prevent a cyberattack shall never happen on a vehicular network\u201d was added to partially respond to the above feedback.\u00a0 Saying that an attack will \u201cnever\u201d success due to a zero-trust framework is not plausible.\u00a0 Could this please rephrased. (1.b) [per -28] Section 3.3 notes a V2P use case where the pedestrian\u2019s smart-phone is sharing unspecified information.\u00a0 Does that include location information?\u00a0 Who gets it?\u00a0 What kind of identifiers are shared? Thanks for adding the following text -29: \u00a0  The location information of a VRU from a smart device is multicasted \u00a0  only to the nearby vehicles.\u00a0 The true identifiers of a VRU's \u00a0  smartphone shall be protected, and only the type of the VRU, such as \u00a0  pedestrian, cyclist, and scooter, is disclosed to the nearby \u00a0  vehicles. To clarify, this \u201cmulticasted\u201d in the IPv6 sense?\u00a0 The VRU\u2019s smartphone is using some kind of \u201cfake identifier\u201d (source address?) to announce its presence so as not to reveal its \u201ctrue identifier\u201d?\u00a0 Is there a security consideration (attack) that these \u201cfake identifiers\u201d multicasting to nearby vehicles could convince that vehicle that they are surrounded by pedestrians (e.g., roughly  https://www.abc.net.au/news/2020-02-04/man-creates-fake-traffic-jam-on-google-maps-by-carting-99-phones/11929136)? \u00a0  Can we state the security properties or provide a reference to handle this issue.\u00a0 I see the following text later in the section: \u00a0  To support applications of these V2X use cases, the required \u00a0  functions of IPv6 include IPv6-based packet exchange, transport-layer \u00a0  session continuity, and secure, safe communication between a vehicle \u00a0  and a pedestrian either directly or indirectly via an IP-RSU. I don\u2019t recognize the desired properties of protecting identifiers as being congruent with the above text. (2) Section 4.2 \u00a0  Note that it is dangerous if the \u00a0  internal network of a vehicle is controlled by a malicious party.\u00a0 To \u00a0  minimize this kind of risk, an reinforced identification and \u00a0  verification protocol shall be implemented.  -- [per -28] Who are the parties in this verification protocol?\u00a0 What security properties is this verification providing? [new per -29] Thanks for adding this new text in -29 in response: \u00a0  To minimize this kind of risk, \u00a0  an augmented identification and verification protocol with extra \u00a0  means shall be implemented.\u00a0 These extra means can be certificate- \u00a0  based, biometric, credit-based, and one-time passcode (OTP) \u00a0  approaches in addition to a used approach [ RFC8002 ].\u00a0 The \u00a0  verification shall provide security properties such as \u00a0  confidentiality, integrity, authentication, authorization, and \u00a0  accounting [ RFC7427 ]. I\u2019m having trouble understanding this guidance.\u00a0 The architecture is suggesting \u201caugmented identification and verification with extra means.\u201d\u00a0 I don\u2019t follow what \u201caugmented means\u201d or \u201cextra\u201d -- augmented or extra from what baseline?\u00a0 The security properties this provides is \u201cconfidentiality, integrity, authentication, authorization and accounting\u201d don\u2019t seem to match authentication and identity topics.\u00a0  To the specific examples, how does \u201ccredit-based\u201d provide the stated security properties?\u00a0  I have the same question for the others.  ** [per -28 and same for -29] The need for safety properties (very helpful) is asserted multiple times but not further discussed in the Security Considerations: -- Section 3:\u00a0  \u00a0 \u00a0 \u00a0  In addition, IPv6 \u00a0 \u00a0 \u00a0 security needs to be extended to support those V2V use cases in a \u00a0 \u00a0 \u00a0 safe, secure, privacy-preserving way. -- Section 3.1:  \u00a0 \u00a0 \u00a0 To support applications of these V2V use cases, the required \u00a0 \u00a0  functions of IPv6 include IPv6-based packet exchange and secure,\u00a0 \u00a0  \u00a0 \u00a0  safe communication between two vehicles.\u00a0  -- Section 3.3: \u00a0  To support applications of these V2X use cases, the required \u00a0  functions of IPv6 include IPv6-based packet exchange, transport-layer \u00a0  session continuity, and secure, safe communication between a vehicle \u00a0  and a pedestrian either directly or indirectly via an IP-RSU. The explanation from the authors noted that the following text was added to Section 4.2 -29: \u201cA malicious party can be a group of hackers, a criminal group, and a competitor for industrial espionage or sabotage.\u201d \u201cThe verification shall provide security properties such as confidentiality, integrity, authentication, authorization, and accounting [ RFC7427 ].\u201d I\u2019m having trouble understanding how this text addresses the safety properties.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-12 07:18:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-05 01:52:43-08:00",
    "text": "Thank you for a well written document! My apologies for filing a procedural DISCUSS on this, but I am looking at: 7.5.\u00a0 Determining the IdP URI \u00a0  3.\u00a0 The path, starting with \"/.well-known/idp-proxy/\" and appended \u00a0 \u00a0 \u00a0  with the IdP protocol.\u00a0 Note that the separator characters '/' \u00a0 \u00a0 \u00a0  (%2F) and '\\' (%5C) MUST NOT be permitted in the protocol field, \u00a0 \u00a0 \u00a0  lest an attacker be able to direct requests outside of the \u00a0 \u00a0 \u00a0  controlled \"/.well-known/\" prefix.\u00a0 Query and fragment values MAY \u00a0 \u00a0 \u00a0  be used by including '?' or '#' characters. \"idp-proxy\" is not registered in the IANA's\u00a0 registry and this document doesn't register it either. If I missed where this is registered, please point me to the right document. If I haven't, please register it in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-12 20:01:08-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-06 18:30:17-08:00",
    "text": "The question of when an IdP is trustworthy, whether at all (even for \"authoritative\" IdPs) or for a specific user, is a pretty core topic for the identity assertion scheme presented here.\u00a0 These topics do get explained in localized sections of the document, but there seem to be other portions of the text that do not really acknowledge the risks. I've tried to note these in the COMMENT section (though having finished reading the document, perhaps I am overzealous about determination that an authoritative IdP is indeed authoritative). I also think that we need to be more careful about having the IdP know the semantics of what it's signing (or otherwise attesting to), so that it does not turn into a signing oracle, etc.. The \"Modifying the Session\" treatment for the SDP \"identity\" attribute seems incompletely specified. I'm a bit unclear about how the port in the IdP URI's Authority (Section 7.5) would get discovered.\u00a0 If it can be remotely supplied, there may be risks in just trusting blindly whatever value is received. It seems like there are some unstated privacy considerations in allowing the IdP proxy to automatically generate an assertion (that reveals the user's identity) at the request of javascript from the calling application, as described in Section 7.7. Section 9.4 talks about how the IdP is attesting to the binding of the user identified in the assertion with the key fingerprints, but in Sections 7.4 and 7.6 we claim that this assertion is \"opaque to the IdP\"; these statements appear to be in conflict with each other.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-06 04:43:22-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-13 14:19:17-08:00",
    "text": "This is generally a well written document, but I have a small list of issues that I would like to discuss before recommending its approval: 1) Are a=ws-uri and a=wss-uri mutually exclusive? (Section 4.3 is a good place to mention what to do if both are specified). Why not a single attribute, considering that both ws: and wss: URIs are possible? 2) In Section 6: how is Websocket TLS server identity verified?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-05-11 08:58:38-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-03 21:38:54-07:00",
    "text": "This model tries to squeeze the 20 bit IPv6 flow label into a 16 bit field. This will result in a loss of data and needs to be fixed before the document is published.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2015-12-14 05:48:58-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-02 19:06:25-08:00",
    "text": "Thank you for a clear and well-written document.\u00a0 I have one point that is peripheral to most of the draft. In Section 4.3, it says:  \" In addition, for any other \u00a0  applications that generate intra-subnet traffic with TTL set to 1, \u00a0  these applications may not work properly in the Virtual Subnet \u00a0  context, unless special TTL processing for such context has been \u00a0  implemented (e.g., if the source and destination addresses of a \u00a0  packet whose TTL is set to 1 belong to the same extended subnet, \u00a0  neither ingress nor egress PE routers should decrement the TTL of \u00a0  such packet.\u00a0 Furthermore, the TTL of such packet should not be \u00a0  copied into the TTL of the transport tunnel and vice versa).\" The idea of not decrementing TTL is quite concerning.\u00a0 I can conjecture cases where there is a routing loop between the relevant PEs - during reconvergence when a host moves from one datacenter to another is a trivial case.\u00a0  One approach may be to ask why a packet would have a TTL of 1 and determine if this case must be resolved.\u00a0 Another might detecting a loop back to an out-of-datacenter PE and dropping the packet.\u00a0 I'm sure you can develop other good ideas and solutions.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-10 14:21:46-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-03 06:25:56-08:00",
    "text": "(1) Surely extending a subnet from one to many data centres should only be done if inter-data-centre traffic is all encrypted and authenticated? I don't get why there isn't a MUST-like statement here for such protection, and going a bit further, why some interoperable form of protection for such traffic (e.g. IPsec, MACsec) isn't recommended as being MTI in such cases. The huge variety of potentially and actually sensitive traffic being handled by VMs these days and which ought not be, and probably is not, understood by folks doing routing seems to very strongly imply that such protection should in fact be turned on all of the time. (But stating that would be going beyond current IETF consenus on MTI security as expressed in  BCP61 .\u00a0 It'd still be a good idea I think though.) (2) I'm guessing one reaction to the above discuss point could be \"sure, but this is the wrong document.\" In that case, please show me the right document and then tell me why a reference to that is not needed here. Note: none of the above is about  RFC2119  MUST/SHOULD etc terms  even though I use them above. Just normal english that makes the point would be fine.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-11-30 12:50:58-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-10 12:44:38-07:00",
    "text": "I agree with the comment made by the ops-dir reviewer, and I don't think the parenthetical in 2.2.1 addresses the problem. It seems that FETCH is not a useful operation unless the server is capable of understanding what it is supposed to fetch. So it's not true that \"any\" media type can be used, but rather only those media types for which a definition exists for what the fetch parameters indicate and which part of the resource they are intended to delineate. Shouldn't the use of FETCH be constrained to such media types?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-11-13 18:15:35-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-12 10:33:37-07:00",
    "text": "I'd like to see more of the actual requirements for this draft in the security considerations as the pointers include all of the configuration options for DTLS, including the \"nosec\" option.\u00a0 I would think this operation would require authentication to prevent unauthorized access by devices that are clones.\u00a0 This is a real problem in the non-IoT space for firmware updates and will be a problem in this space if it isn't already - knock off hardware that installs the firmware of a popular product.\u00a0 In In section 5 of  RFC5789 , I see this: \u00a0  These \u00a0  include authorizing requests (possibly through access control and/or \u00a0  authentication) and ensuring that data is not corrupted through \u00a0  transport errors or through accidental overwrites.  And would like to see something similar in this section to at least list some of the requirements and reasoning.\u00a0 For patch and fetch, I think the reason outlined above needs to be included as well so it is top of mind for implementers and they are aware of this very real threat.\u00a0 It is important they understand why they need authentication and encryption to prevent attacks against their brand.\u00a0 If someone buys knock-off hardware that is faulty and uses their firmware, they have multiple problems to deal with, not just the loss of sales.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2016-11-14 19:54:51-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-12 09:00:11-07:00",
    "text": "I'm following most of your reasoning behind having the twin methods PATCH and iPATCH, but I'm struggling a bit that there's nothing that I saw that prevents a problem when the client implements only PATCH and the server implements only iPATCH.  The only text I saw that provides guidance about which method to implement is \u00a0  A client can mark a request as idempotent by using the iPATCH method \u00a0  instead of the PATCH method.\u00a0 This is the only difference between the \u00a0  two.\u00a0 The indication of idempotence may enable the server to keep \u00a0  less state about the interaction; some constrained servers may only \u00a0  implement the iPATCH variant for this reason. \u00a0   Maybe I missed something?  If not, I saw \u00a0  There is no guarantee that a resource can be modified with PATCH or \u00a0  iPATCH. \u00a0   so, maybe that mismatch isn't going to be a problem in practice, but it seems sad that you might have a patchable resource, that can't be patched because of that mismatch. I'm not asking for \"clients MUST implement iPATCH if you implement PATCH\" (which would accommodate servers that only implement iPATCH), but I wonder if the working group talked about a way to avoid this mismatch?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-12-21 19:59:04-08:00",
    "end_reason": "position_updated",
    "start": "2018-07-02 08:38:17-07:00",
    "text": "Section 5.13('s subsections) of this document replace sections 6.8.6 and 6.8.7 of  RFC 5880 .\u00a0 I extracted the relevant text and performed a diff, and think some discussion is needed of some portions present in  RFC 5880  that are not present in these new texts.\u00a0 (The separation of the demultiplexing procedure to a separate subsection is fine, though it does make the diff a little nosier to read.) In particular, from  RFC 5880  Section 6.8.6, the paragraph: %\u00a0 \u00a0 \u00a0 If the Poll (P) bit is set, send a BFD Control packet to the %\u00a0 \u00a0 \u00a0 remote system with the Poll (P) bit clear, and the Final (F) bit %\u00a0 \u00a0 \u00a0 set (see section 6.8.7). Does not appear to have any corresponding text in this document. From  RFC 5880  Section 6.8.7, the first four paragraphs (too long for me to include here) do not appear to have their substance covered in this document, either (largely discussion about the pacing of BFD Control packets and jitter in their scheduling). Section 5.13.3's text now only covers how to set Min Echo Rx Interval for MultipointHead and MultiplintTail sessions, which seems to remove guidance on how to set it for other session types. While it is permissible for a document that Updates another document to perform this sort of deprecation of behavior, it is potentially confusing for implementors to do so without mentioning the change in behavior. Separately, I wonder if it is appropriate to Update  RFC 7880  as well as 5880, given (e.g.) Section 5.4.1. I also think that Section 6 should describe more clearly how asymmetric message authentication relates to this work (i.e., whether it is entirely incompatible with BFD or does it merely require additional specification).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-10-18 01:46:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-03 11:31:33-07:00",
    "text": "This mechanism has the potentially to easily overload the network as there is no handshake and therefore also no feedback mechanism (as already noted by the TSV-ART review of Bob - Thanks!). Regarding the base spec in  RFC5880 , this mechanism can only be used under certain constrains which should be clearly stated in this doc, which are: 1) See sec 6.8.1 of  RFC5880 : \"bfd.DesiredMinTxInterval \u00a0 \u00a0 \u00a0 [...] The actual \u00a0 \u00a0 \u00a0 interval is negotiated between the two systems.\u00a0 This MUST be \u00a0 \u00a0 \u00a0 initialized to a value of at least one second (1,000,000 \u00a0 \u00a0 \u00a0 microseconds) according to the rules described in section 6.8.3.\" As there no negotiation in this spec, bfd.DesiredMinTxInterval MUST always be at least one second. Actually  RFC8085  even recommend 3 sec (see sec 3.1.3). 2) See sec 7 of  RFC 8085 \"When BFD is used across multiple hops, a congestion control mechanism \u00a0  MUST be implemented, and when congestion is detected, the BFD \u00a0  implementation MUST reduce the amount of traffic it generates. \" As there is no feedback and therefore no congestion control, this spec can only be used for one-hop scenarios and the TTL or Hop Count MUST be set to one. 3) Also given the traffic load multipoint BFD generates depends on the number of active session, and there is no feedback mechanism, I recommend to also limit the number of active session of MultipointHead type to a small number (per link).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-12-13 08:15:39-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-18 01:46:50-07:00",
    "text": "This mechanism has the potentially to easily overload the network as there is no handshake and therefore also no feedback mechanism (as already noted by the TSV-ART review of Bob - Thanks!). Regarding the base spec in  RFC5880 , this mechanism can only be used under certain constrains which should be clearly stated in this doc, which are: 1) See sec 6.8.1 of  RFC5880 : \"bfd.DesiredMinTxInterval \u00a0 \u00a0 \u00a0 [...] The actual \u00a0 \u00a0 \u00a0 interval is negotiated between the two systems.\u00a0 This MUST be \u00a0 \u00a0 \u00a0 initialized to a value of at least one second (1,000,000 \u00a0 \u00a0 \u00a0 microseconds) according to the rules described in section 6.8.3.\" As there no negotiation in this spec, bfd.DesiredMinTxInterval MUST always be at least one second. Actually  RFC8085  even recommend 3 sec (see sec 3.1.3). 2) See sec 7 of  RFC5880 \"When BFD is used across multiple hops, a congestion control mechanism \u00a0  MUST be implemented, and when congestion is detected, the BFD \u00a0  implementation MUST reduce the amount of traffic it generates. \" As there is no feedback and therefore no congestion control, this spec can only be used for one-hop scenarios and the TTL or Hop Count MUST be set to one. 3) Also given the traffic load multipoint BFD generates depends on the number of active session, and there is no feedback mechanism, I recommend to also limit the number of active session of MultipointHead type to a small number (per link).",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-01-05 00:13:37-08:00",
    "end_reason": "position_updated",
    "start": "2014-10-29 04:25:51-07:00",
    "text": "\u00a0  Req. 1:\u00a0  Multiple simultaneous data channels MUST be supported. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Note that there may be 0 or more SRTP media streams in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  parallel with the data channels in the same PeerConnection, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  and the number and state (active/inactive) of these SRTP \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  media streams may change at any time. Multiple simultaneous data channels from different \"modes\" (unreliable, partially or fully reliable), or even from the same mode? \"modes\" in double quotes, because, if I recall correctly SCTP delivery mode is per message, not per stream. However, I don't have a better word. Then I started to wonder...\u00a0 I've see those requirements before.  http://tools.ietf.org/html/draft-ietf-rtcweb-use-cases-and-requirements-14 \u00a0  ---------------------------------------------------------------- \u00a0  F22\u00a0 \u00a0  The browser must be able to receive streams and \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  data from multiple peers concurrently. \u00a0  ---------------------------------------------------------------- So I should not be commenting on the requirements again! Why do you repeat, with different wording, the use cases and requirements in this document? Note that this document contains  RFC 2119  keywords for the requirements, while  draft-ietf-rtcweb-use-cases-and-requirements  doesn't.  Does it imply the requirements in this document are more important? This is confusing.  Disclaimer: I have not done a 1:1 comparison of the requirements in both documents. A discrepancy would be another DISCUSS reason. Referring to  draft-ietf-rtcweb-use-cases-and-requirements  is the way to go. Even if [ I-D.ietf-rtcweb-use-cases-and-requirements ] is an informative reference, progressing this draft while [ I-D.ietf-rtcweb-use-cases-and-requirements ] still has issues is not appropriate. I'll trust the responsible AD on that. Ah, I just realized that Pete has got a similar feedback.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-16 04:01:58-08:00",
    "end_reason": "position_updated",
    "start": "2020-04-20 14:06:32-07:00",
    "text": "Let's discuss whether the various and sundry conditional SHOULDs in Section 3.1 are better written as conditional MUSTs (i.e., with the listed exclusions being the only allowed exclusion). Also, Appendix A.2 seems to show \"Len (extended)\" as just 0-2 bytes when IIUC it is 0-4 bytes.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-11-05 07:30:09-08:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 22:13:49-07:00",
    "text": "[[ discuss ]] [ section 2.2.2 ] * I agree with Ben's point about MTU.\u00a0 Some text about the implications seems \u00a0 warranted.\u00a0 Even just a link to 7252#4.6 might be fine (and maybe a \u00a0 skull-and-crossbones emoji [\u2620\ufe0f] if they can be included now ;-) * 60 minutes for address changes?\u00a0 Out of curiosity, upon what was this based? \u00a0 I lack a good deal of context, but this kind of feels like the kind of \u00a0 constant that will get baked into code and come to govern some behaviour \u00a0 that later might need updating.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-09-28 05:29:08-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-27 01:04:06-07:00",
    "text": "I have a simple issue with the IANA Considerations section which should be easy to address: The IANA section seem to be suggesting that IANA should do full search of its registries to update all references to  RFC 4447  to point to rfc4447bis. I don't think it is easy for IANA to do that. This document is obsoleting  RFC 4447 , which means that there is no need to ever read  RFC 4447  in order to implement this document. For that reason, you should copy and paste content of the original  RFC 4447 's IANA Considerations into this document. After that, add a sentence saying that the only change is updating references to point to this document.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-08-24 06:37:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-22 14:12:24-07:00",
    "text": "(1) [I'm raising this point to be a discussion -- it may not end with changes to the document.] This document recommends that route refresh not be used when inbound policies change at a relatively high rate.\u00a0 ROV validation is \"only\" an example. As Jeff Haas wrote on the idr list [1]: \u00a0  This isn't any different than any other over-aggressive  \u00a0  provisioning tool's impact.\u00a0  Was there any consideration given to making a general recommendation and not just limiting it to ROV?\u00a0 I can see the direct impact on  rfc6811 /rfc8481, and how general BGP advice is out of scope for sidrops.\u00a0 However, I am primarily curious whether there is anything particular to ROV to focus the recommendation this way.\u00a0 I couldn't find a related discussion (beyond Jeff's message) in the archive, but I may have missed it. [1]  https://mailarchive.ietf.org/arch/msg/idr/F3w0RDyv9dK4w15fzuDZx3P4Jw0 (2) I have a couple of issues with this paragraph from \u00a74.\u00a0 Addressing them should be relatively easy: \u00a0  When RPKI data cause one or more paths to be dropped due to ROV, \u00a0  those paths MUST NOT be evaluated for best path, but MUST be saved \u00a0  (either separately or marked) so they may be reevaluated with respect \u00a0  to new RPKI data. (2a) \"paths to be dropped due to ROV, those paths MUST NOT be evaluated for best path\" Neither  rfc6811  nor  rfc8481  require that routes be \"dropped due to ROV\".\u00a0  rfc8481  requires that \"Absent specific operator configuration, policy MUST NOT be applied.\" Please clarify that the trigger above (\"dropped due to ROV\") is defined by the operator and is not just a result of ROV. (b) \"MUST be saved (either separately or marked)\" For a required action, the description is not clear.\u00a0 For starters, \"marked\" how?\u00a0 Separately where? From \u00a71.1/rfc4271: \u00a0  The Adj-RIBs-In contains unprocessed routing information that has \u00a0  been advertised to the local BGP speaker by its peers. The RIB structures in  rfc4271  are conceptual -- but since this document requires keeping information (presumably in the Adj-RIB-In), please be more specific about where and marked how. (3) The following requirement from \u00a75 is outside the scope of this document: \u00a0  If the BGP speaker has insufficient resources to support either of \u00a0  the two proposed options, it MUST NOT be used for Route Origin \u00a0  Validation.\u00a0 I.e. the knob in Section 4 should only be used in very \u00a0  well known and controlled circumstances. Requiring a node not to be used for ROV is a powerful statement.\u00a0 It basically invalidates the base operation specified on  rfc6811 /rfc8481 by always requiring the mechanism in this document.\u00a0 While I understand the potential resource demands, selecting a node to perform a specific operation in a particular operator's network is outside the scope of this document. Instead, I would like to see guidance to the operator to consider not using the specific piece of equipment to perform a particular function.\u00a0 This can be as easy as: \u00a0 \u00a0 If the BGP speaker has insufficient resources to support either  \u00a0 \u00a0 of the two proposed options, the operator is strongly encouraged  \u00a0 \u00a0 to consider an alternate piece of equipment to perform Route Origin  \u00a0 \u00a0 Validation. The second part of the sentence (\"I.e. ...\") sounds like a better recommendation -- and, clearly, not the same as \"MUST NOT be used\".",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-09-08 03:35:58-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 06:22:15-07:00",
    "text": "Hi Authors, Thanks for the document, for the most part I find it clear and easy to understand. I however would like to discuss the following:  If the BGP speaker's equipment has insufficient resources to support \u00a0  either of the two proposed options, it MUST NOT be used for Route \u00a0  Origin Validation.\u00a0 The equipment should either be replaced with \u00a0  capable equipment or ROV not used.\u00a0 I.e. the knob in Section 4 should \u00a0  only be used in very well known and controlled circumstances. My concerns with this are two fold - firstly - it's entirely unclear what is meant by \"well known and controlled circumstances\". More importantly, I'm concerned that this paragraph as written could lead to a situation that where people read this as \"if you can't support this behavior - forget BGP security\" - and that I would think would be a more dangerous situation than the route refresh behavior. I'd be happier if we could  a.) Either say that operators should plan for upgrades - but turn off RPKI in the meantime or b.) Change the wording such that it says something along the lines of \"it MUST not be used for ROV without the informed consent of the peers\" - meaning that peer that takes the brunt of the refreshes has to consent explicitly. Either option prevents the position where operators running smaller older hardware are handed an excuse to forgo RPKI entirely - or to turn it off - because in my experience once someone turns something off, getting them to turn it back on again, can be a tricky proposition. Let's discuss! Thanks Andrew",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-24 13:46:54-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-24 13:45:40-07:00",
    "text": "I'm strongly in favor of this work and glad to see it here.\u00a0 I do want to DISCUSS Section 4, though.\u00a0 I apologize for not having reviewed and commented on this section before now. My concern can be summed up as, some of the language of Section 4 while well-intentioned, can mislead the reader into thinking it's fine to continue sending Route Refreshes after all.\u00a0 If you could see your way clear to taking a swing at reorganizing it to  mitigate that, it would be great.\u00a0 The most notable example of a place where the reader could be misled is the third paragraph, which has the clause \"... MUST issue a route refresh\".\u00a0 I think  you are probably meaning to say that such a route refresh would be a natural consequence of not following this spec (and not saving the ineligible routes) -- but by using the 2119 keyword you  create a different expectation. Please let me know if you want to talk this through in more detail.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-24 14:07:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 13:46:54-07:00",
    "text": "I'm strongly in favor of this work and glad to see it here.\u00a0 I do want to DISCUSS Section 4, though.\u00a0 I apologize for not having reviewed and commented on this section before now. My concern can be summed up as, some of the language of Section 4 while well-intentioned, can mislead the reader into thinking it's fine to continue sending Route Refreshes after all.\u00a0 If you could take a swing at reorganizing it to mitigate that, it would be great. The most notable example of a place where the reader could be misled is the third paragraph, which has the clause \"... MUST issue a route refresh\".\u00a0 I think you are probably meaning to say that such a route refresh would be a natural consequence of not following this spec (and not saving the ineligible routes) -- but by using the 2119 keyword you create a different expectation. Please let me know if you want to talk this through in more detail.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-24 07:02:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 03:31:26-07:00",
    "text": "# GEN AD review of  draft-ietf-sidrops-rov-no-rr-03 CC @larseggert Thanks to Paul Kyzivat for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/Qhb_8-Kc5e5QEE47En6NhULHnjI ). ## Discuss ### Unclear RFC status ``` \u00a0 Intended status: Standards Track\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Arrcus, Inc. ``` The datatracker metadata for this document indicated a intended status of \"Internet Standard\". I assume this is incorrect and needs to be changed (probably to \"Proposed Standard\".)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-08-25 07:48:43-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 23:30:21-07:00",
    "text": "This should be easy to resolve, but it's a necessary process check:\u00a0 The shepherd writeup says this is going for Internet Standard status, but the other metadata and the document itself seems to be set for Proposed Standard.\u00a0 Which is right?\u00a0 I believe there are other incantations that have to be done if the former is true.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-20 08:05:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 12:35:27-07:00",
    "text": "Section 8.2.8: \"In the RFC specifications that register new values for SDP \"media\", \u00a0  \"proto\", \"fmt\", \"bwtype\", \"nettype\", and \"addrtype\" parameters, the \u00a0  authors MUST include the following information for IANA to place in \u00a0  the appropriate registry:\" It doesn't look like all the fields that are listed after this text actually appear in the registries. For some of these I don't see why the information would be put into the registries (e.g., contact name, contact email address, since those appear in the RFCs themselves). I think this needs to be clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-24 05:43:10-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 03:47:37-07:00",
    "text": "I'll raise Martin's comment to DISCUSS level: OLD \u00a0  decimal-uchar =\u00a0 \u00a0 \u00a0  DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / POS-DIGIT DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"1\" 2*(DIGIT)) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") DIGIT) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" \"5\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\")) NEW \u00a0  decimal-uchar =\u00a0 \u00a0 \u00a0  DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / POS-DIGIT DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"1\" 2(DIGIT)) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") DIGIT) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" \"5\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\")) END Is there a reason NOT to make this change, or was it just overlooked?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-19 07:53:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 11:31:43-07:00",
    "text": "I\u2019d like to escalate Alissa\u2019s point about the k= language in Section 7 (Security Considerations).\u00a0 It looks like the new Section 5.12 removes all of the historical language beyond saying it MUST NOT be used.\u00a0 This approach makes sense to me.\u00a0 However, the language in Section 7 could be read as conflicting with that.\u00a0 Specifically: \u00a0  Use of the \"k=\" line poses a significant security risk, since it \u00a0  conveys session encryption keys in the clear.\u00a0 SDP MUST NOT be used \u00a0  to convey keying material, unless it can be guaranteed that the \u00a0  channel over which the SDP is delivered is both private and \u00a0  authenticated. \u00a0  ... \u00a0  The \"k=\" line MUST \u00a0  NOT be used, as discussed in Section 5.12. The first sentence makes a strong statement.\u00a0 The first clause of the second sentence makes a more generic MUST NOT statement but the second clause seems to say that is acceptable under certain circumstances.\u00a0 The third sentence reiterates that k= MUST NOT be used.\u00a0 How should this be reconciled?\u00a0 Is the text suggesting that conveying keying materials outside of k= is acceptable over the right kind of channel?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-12-09 18:19:40-08:00",
    "end_reason": "position_updated",
    "start": "2015-08-19 14:33:01-07:00",
    "text": " I share Barry's and Alvaro's concern about the lack of evidence of community consensus for this to be published as a BCP. But I further question whether it should be a BCP in the first place. The shepherd write up doesn't say why it should be a BCP (which, by the way, is an explicit question in the template.) There are normative requirements that appear to be externally observable (especially bullets 3 and 4), which makes me wonder why this is not a PS. (And I note that versions 00 and 01 were listed as standards track.) It's also not clear to me whether the recommendations are the consensus of the community, or just the recommendations of the authors, which might even argue for \"informational\". I think given the questions about the RFC type combined with the consensus questions make this rise to the level of a DISCUSS. Hopefully this can be cleared easily with an explanation of why this is a BCP, and a clarification of the consensus issues.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 09:17:22-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-11 19:02:22-07:00",
    "text": "Let's discuss whether [ I-D.mizrahi-ippm-compact-alternate-marking ] needs to be a normative reference, to describe how the Hash selection method works for multipoint.\u00a0 This document alone does not even mention what is used as input to the hash (though I think I have a good guess based on the context).\u00a0 Even if the intent is that  RFC 5474  suffices (avoiding the \"dependency on individual document\" issue), that is also listed only as an informative reference. Also, if the grouping procedure (section 6.1) does in fact require a distinguished (but arbitrary?) choice of initial endpoint as I suspect it does, that should be clarified.\u00a0 (See COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-09-19 09:55:40-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 12:22:32-07:00",
    "text": "I was wondering about why this document is going for informational rather than proposed standard. I see that  draft-ietf-taps-interface-01  has a normative reference to it, so this is effectively setting up a downref situation. That isn't necessarily a problem, but if the point is for this document to recommend an actual minimal set of transport services to be supported and exposed via the API specified in  draft-ietf-taps-interface  and other APIs, shouldn't that set be normative?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-09-18 17:19:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 17:38:45-07:00",
    "text": "[My general summary view of this document is not really relevant to these Discuss points and appears in the COMMENT section.] This document includes a general discussion of the features/services that IETF transport protocols (TCP, MPTCP, SCTP, UDP, etc.) provide ... and also throws in LEDBAT congestion control, with no real coverage of all the other congestion control schemes the IETF provides.\u00a0 It seems that there should be some text/justification of why LEDBAT (but none of the others) fall into the same categorization as the general transport features.\u00a0 As far as I can tell, the idea is that there can be a \"low-impact background data transfer\" feature/service, which LEDBAT attempts to provide, but I'm basing that on  inference and not something explictily stated in the document. Section 3.3.2 and Appendix A.3.1 are limiting this \"minimal set\" of transport services to exclude discrete messages and allow only the provisioning for TCP-like byte streams.\u00a0 While I can understand the desire to make TCP the \"gold standard\", the surrounding discussion, particularly in A.3.1, seems to be a layering violation.\u00a0 That is, we are hearing that AFra-Bytestream requires receivers (i.e., applications) to be able to consume contiguous bytestreams.\u00a0 But this seems to really be a requirement on the application protocol to be self-framing (and to provide its own sequence numbers if needed)!\u00a0 Normally we think of an application protocol placing requirements on the transport, or a particular transport as being inappropriate for use with a given application protocol.\u00a0 So I think this document needs to more explicitly acknowledge that this is not a \"generic minimal set\" of transport features, but rather a minimal set that is applicable for many, but not all, applications: some application protocols have requirements that are not met by this \"minimal set\". In Section A.3.6, \"Data encryption\" and \"source authenticity\" are absent from the list of \"security related transport features\" (that are relegated to the other document); this seems like a fatal omission.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-11-07 13:54:56-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-15 22:53:06-07:00",
    "text": "Thanks for the work everyone put into this document. I think it's not quite ready to publish, due to one ambiguity, one critical missing feature, and the lack of guidance around fragmentation. I also have two comments that I consider very important, although they don't quite rise to the level of blocking publication. As always, it's possible that my DISCUSS points are off-base, and I'd be happy to be corrected if I've misunderstood anything here. --------------------------------------------------------------------------- \u00a74.1: >\u00a0 \u00a0  When the document spans more >\u00a0 \u00a0  than one RTP packet, the entire document is obtained by >\u00a0 \u00a0  concatenating User Data Words from each contributing packet in >\u00a0 \u00a0  ascending order of Sequence Number. This is underspecified, in that it doesn't make it clear whether it would be valid to split a single UTF-8 or UTF-16 character between RTP packets, and it is nearly certain that different implementations will make different assumptions on this point, leading to interop failures. For example, the UTF-8 encoding of '\u00a2' is 0xC2 0xA2. Would it be valid to place the \"0xC2\" in one packet and the \"0xA2\" in a subsequent packet? Without specifying this, it is quite likely that some implementations will use, e.g., UTF-8 strings to accumulate the contents of RTP packets; and most such libraries will emit errors or exhibit unexpected behavior if units of less than a character are added at any time.\u00a0 (The same point holds for splitting a UTF-16 byte across packets). I don't think it much matters which choice you make (explicitly allowing or explicitly forbidding splitting characters between packets), but it does need to be explicit. I have a slight personal preference for requiring that characters cannot be split (both for ease of implementation on the receiving end and to more smoothly handle missing data due to extended packet loss), but leave it to the authors and working group to decide. --------------------------------------------------------------------------- Unlike other definitions to convey non-loss-resilient data on RTP streams, this document had no defined mechanism to deal with packet loss. This makes it unusable on the public Internet, where packet loss is an inevitable feature of the network. The existing text-in-RTP specifications define procedures to deal with such loss (see, e.g.,  RFC 4103  section 4 and  RFC 4396  section 5). --------------------------------------------------------------------------- This format is rather unique in that it, alone among all other RTP text formats, is designed to send monolithic documents that may stretch into the multiple kilobyte range.\u00a0 While fragmentation is mentioned as a possibility, the document provides no implementation guidance about when to fragment documents, and what sizes each fragment should assume.  RFC 4396  section 4.4 is an example of the kind of information I would expect to see in a document like this, with emphasis on the fact that TTML documents are going to frequently exceed the PTMU for a typical network connection.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-10-21 07:02:13-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-15 07:41:11-07:00",
    "text": "James and WG,  I do have a couple of issues I want to have your feedback on if they should be corrected or not before proceeding to publication. Note they are for discussion and in cases where things have been discussed and there is consensus please reference that so that I can take that into consideration when we resolve these.  1. Section 4.1:  \tTimestamp:  \tThe RTP Timestamp encodes the time of the text in the packet.   \tAs timed text is a media that has duration, from a start time to an end time, and the RTP timestmap is a single time tick in the chose clock resolution the above text is not clear. I would think the start time of the document would be the most useful to include?\u00a0    \tI think the text in 4.2.1.2 combined with the above attempts to imply that the RTP timestamp will be the 0 reference for the time-expression?    \tI think this needs a bit more clarification. Not having detailed studied TTML2/1 I might be missing important details. But some more information how the document timebase:media time line connects to the RTP timestamp appears necessary.    2. A Discuss Discuss: As Timed Text is directly associated with one or more video and audio streams and requires synchronization with these other media streams to function correct. This leads to two questions.    \tFirst of all is application/ttml+xml actually the right top-level media type? If using SDP that forces one unless one have BUNDLE to use a different RTP session. Many media types having this type of properties of being associated with some other media types have registered media types in all relevant top-level media types.    \tSecondly, this payload format may need some references to mechanisms in RTP and signalling that has the purpose of associating media streams? I also assume that we have the interesting cases with localization that different languages have different time lines for the text and how long it shows as there are different tranditions in different countries and languages for how one makes subtitles.    \tThis may also point to the need for discussing the pick one out of n mechanism that a manifest may need.    3. Section 7.1:   \tIt may be appropriate to use the same Synchronization \u00a0  Source and Clock Rate as the related media.   \tUsing the same SSRC as another media stream in the same RTP Session is no-no. If you meant to use multiple RTP sessions and associate them using the same SSRC in diffiernt, yes it works but is not recommended. This points to the need for a clearer discussion of how to achieve linkage and the reasons for why same RTP timestamp may be useful or not.    4. Fragmentation: \tI think the fragmentation of an TTML document across multiple RTP payloads are a bit insufficiently described. I have the impression that it is hard to do something more clever than to fill each RTP payload to MTU limtiation, and send them out insequence. However, I think a firm requirement to apply RTP sequence number for a single document in consecutive numbers. Also the re-assebly process appear to have to parts for detecting what belongs together, same timestamp and last packet of document should have marker bit set.  \tAs a receiver can loose the last packet in the previous document, still know that it has received everything for the following document. However, if the losses are multiple, inspection of the re-assemblied document will be necessary to determine if the correct beginning is present. I have the impression that a proper section discussing these matter of fragmentation and re-assembly are necessary for good interoperability and function.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-10-29 04:49:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-21 07:02:13-07:00",
    "text": "James and WG,  I do have a couple of issues I want to have your feedback on if they should be corrected or not before proceeding to publication. Note they are for discussion and in cases where things have been discussed and there is consensus please reference that so that I can take that into consideration when we resolve these.  1. Section 4.1:  \tTimestamp:  \tThe RTP Timestamp encodes the time of the text in the packet.   \tAs timed text is a media that has duration, from a start time to an end time, and the RTP timestmap is a single time tick in the chose clock resolution the above text is not clear. I would think the start time of the document would be the most useful to include?\u00a0    \tI think the text in 4.2.1.2 combined with the above attempts to imply that the RTP timestamp will be the 0 reference for the time-expression?    \tI think this needs a bit more clarification. Not having detailed studied TTML2/1 I might be missing important details. But some more information how the document timebase:media time line connects to the RTP timestamp appears necessary.    2. A Discuss Discuss: As Timed Text is directly associated with one or more video and audio streams and requires synchronization with these other media streams to function correct. This leads to two questions.    \tFirst of all is application/ttml+xml actually the right top-level media type? If using SDP that forces one unless one have BUNDLE to use a different RTP session. Many media types having this type of properties of being associated with some other media types have registered media types in all relevant top-level media types.    \tSecondly, this payload format may need some references to mechanisms in RTP and signalling that has the purpose of associating media streams? I also assume that we have the interesting cases with localization that different languages have different time lines for the text and how long it shows as there are different tranditions in different countries and languages for how one makes subtitles.    \tThis may also point to the need for discussing the pick one out of n mechanism that a manifest may need.    3. Section 7.1:   \tIt may be appropriate to use the same Synchronization \u00a0  Source and Clock Rate as the related media.   \tUsing the same SSRC as another media stream in the same RTP Session is no-no. If you meant to use multiple RTP sessions and associate them using the same SSRC in diffiernt, yes it works but is not recommended. This points to the need for a clearer discussion of how to achieve linkage and the reasons for why same RTP timestamp may be useful or not.    4. Fragmentation: \tI think the fragmentation of an TTML document across multiple RTP payloads are a bit insufficiently described. I have the impression that it is hard to do something more clever than to fill each RTP payload to MTU limtiation, and send them out insequence. However, I think a firm requirement to apply RTP sequence number for a single document in consecutive numbers. Also the re-assebly process appear to have to parts for detecting what belongs together, same timestamp and last packet of document should have marker bit set.  \tAs a receiver can loose the last packet in the previous document, still know that it has received everything for the following document. However, if the losses are multiple, inspection of the re-assemblied document will be necessary to determine if the correct beginning is present. I have the impression that a proper section discussing these matter of fragmentation and re-assembly are necessary for good interoperability and function. 5. Lack of definition of parameter types in the media type when using SDP Offer/answer.  As the application/ttml media type do contain parameters (charset and profile) there is a need to define what SDP O/A interpretations they need to have. See section 3.4.2.1 of  RFC 8088  for discussion of these different types.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-10-29 07:35:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-29 04:49:00-07:00",
    "text": "Thanks for the discussion and addressing most of the issues completely. I leave these in so that I know that the remaining text issues to be addressed are associated with these.    3. Section 7.1:   \tIt may be appropriate to use the same Synchronization \u00a0  Source and Clock Rate as the related media.   \tUsing the same SSRC as another media stream in the same RTP Session is no-no. If you meant to use multiple RTP sessions and associate them using the same SSRC in diffiernt, yes it works but is not recommended. This points to the need for a clearer discussion of how to achieve linkage and the reasons for why same RTP timestamp may be useful or not.    4. Fragmentation: \tI think the fragmentation of an TTML document across multiple RTP payloads are a bit insufficiently described. I have the impression that it is hard to do something more clever than to fill each RTP payload to MTU limtiation, and send them out insequence. However, I think a firm requirement to apply RTP sequence number for a single document in consecutive numbers. Also the re-assebly process appear to have to parts for detecting what belongs together, same timestamp and last packet of document should have marker bit set.  \tAs a receiver can loose the last packet in the previous document, still know that it has received everything for the following document. However, if the losses are multiple, inspection of the re-assemblied document will be necessary to determine if the correct beginning is present. I have the impression that a proper section discussing these matter of fragmentation and re-assembly are necessary for good interoperability and function.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-06 12:32:30-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-17 18:28:24-08:00",
    "text": "Thanks for the work that the authors and working group put into this document. I have one DISCUSS-level comment that should be very easy to resolve, and a small number of editorial nits. --------------------------------------------------------------------------- \u00a79: Since this specification is adding new endpoints under /.well-known/est, it needs to update the \"Well-Known URIs\" registry so that the entry for \"est\" indicates this document (in addition to  RFC 7030 ).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-06 09:20:49-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 05:26:59-08:00",
    "text": "Thank you for this well written document. I have a couple of small DISCUSS points and a few minor comments/questions that I would like to discuss. DISCUSS: 5.4.\u00a0 Message Bindings \u00a0  o\u00a0 The CoAP Options used are Uri-Host, Uri-Path, Uri-Port, Content- \u00a0 \u00a0 \u00a0 Format, Block1, Block2, and Accept.\u00a0 These CoAP Options are used \u00a0 \u00a0 \u00a0 to communicate the HTTP fields specified in the EST REST messages. \u00a0 \u00a0 \u00a0 The Uri-host and Uri-Port Options can be omitted from the COAP \u00a0 \u00a0 \u00a0 message sent on the wire. The statement above \u00a0 \u00a0 \u00a0 When omitted, they are logically \u00a0 \u00a0 \u00a0 assumed to be the transport protocol destination address and port \u00a0 \u00a0 \u00a0 respectively.\u00a0 Explicit Uri-Host and Uri-Port Options are \u00a0 \u00a0 \u00a0 typically used when an endpoint hosts multiple virtual servers and \u00a0 \u00a0 \u00a0 uses the Options to route the requests accordingly. and the last quoted statement: How can the sender know whether or not it is Ok to omit Uri-Host/Uri-Port? 7.\u00a0 Parameters \u00a0  It is recommended, based on experiments, \u00a0  to follow the default CoAP configuration parameters ([ RFC7252 ]). \u00a0  However, depending on the implementation scenario, retransmissions \u00a0  and timeouts can also occur on other networking layers, governed by \u00a0  other configuration parameters.\u00a0 When a change in a server parameter \u00a0  has taken place, the parameter values in the communicating endpoints \u00a0  MUST be adjusted as necessary. The last sentence: use of MUST with passive voice is really unhelpful here. Adjusted by whom? How can this MUST be satisfied?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-12-29 05:51:26-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-19 04:53:33-08:00",
    "text": "Section 5.6: The EST-coaps client MUST support \u00a0  Block1 only if it sends EST-coaps requests with an IP packet size \u00a0  that exceeds the Path MTU. I think the requirement for when Block1 is required to be supported in the above sentence is unclear. Is the intention to say: An EST-coaps MUST support block1 to be capable to send requests that would otherwise result in the reliance on IP level fragmentation?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-01-18 14:53:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-01-18 14:49:40-08:00",
    "text": "I would like to discuss this point with the responsible area director during the telechat. No action from the authors is required on this point at this point. The manageability considerations section is a direct cut/paste from a charter (i.e. minimal effort) + two informative references to drafts, not even WG docs. What are we suppose to conclude from this?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-03-01 07:16:12-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-18 14:53:59-08:00",
    "text": "I would like to discuss this point with the responsible area director during the telechat. No action from the authors is required on this point at this point. The manageability considerations section is a direct cut/paste from a charter (i.e. minimal effort) + two informative references to drafts, not even WG docs. What are we suppose to conclude from this, in terms of manageability requirements?",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2016-02-03 06:14:32-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-02-03 06:13:36-08:00",
    "text": "* Section 3.4 If the intent is to create a new RH type how will the interoperability or backward compatibility be possible? Specifically because intermediate nodes (that are segment routing hops) that encounter unknown RH types are required to drop the packet and send an ICMPv6 Parameter Problem back. * Security considerations In general this document does not talk anything about the security issues with IPv6 routing headers and how they would be avoided. e.g. The following paper describes an attack. \u00a0  [CanSecWest07]\u00a0 Biondi, P. and A. Ebalard, \"IPv6 Routing Header \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Security\", CanSecWest Security Conference 2007, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  April 2007. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   http://www.secdev.org/conf/IPv6_RH_security-csw07.pdf I think the security considerations are very light and need to be greatly improved.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2016-03-01 07:55:50-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-03 06:14:32-08:00",
    "text": "The following is a training review from the Suresh Krishnan (incoming INT AD) * Section 3.4 If the intent is to create a new RH type how will the interoperability or backward compatibility be possible? Specifically because intermediate nodes (that are segment routing hops) that encounter unknown RH types are required to drop the packet and send an ICMPv6 Parameter Problem back. * Security considerations In general this document does not talk anything about the security issues with IPv6 routing headers and how they would be avoided. e.g. The following paper describes an attack. \u00a0  [CanSecWest07]\u00a0 Biondi, P. and A. Ebalard, \"IPv6 Routing Header \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Security\", CanSecWest Security Conference 2007, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  April 2007. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   http://www.secdev.org/conf/IPv6_RH_security-csw07.pdf I think the security considerations are very light and need to be greatly improved.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2016-04-12 15:26:16-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-31 15:03:18-08:00",
    "text": "The main focus of my discuss are the disparaging comments on MPLS and RSVP-TE for the apparent purpose of justifying the need for SPRING. The statements in Section 3.3, paragraph 2, are not accurate. As an IETF document, even though Informational, it harms another IETF technology. This paragraph needs to be removed. Very disappointing to see this unfair comparison of centralized control vs. distributed control in an IETF document.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-02 04:21:16-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-04 06:09:45-08:00",
    "text": "I concur with the other folks who've bemoaned the fact that the security considerations text is less comprehensive than the charter text. Which document in the WG will document the security issues with SPRING generally and which WG documents currently contain the kind of security analysis called for in the charter? (I had a quick look and didn't see anything obvious.) I'm making this a DISCUSS ballot on the assumption that we're better off having the \"who's doing the work and where is it?\" discussion now and not each time a document gets to the IESG without that work having been done.",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-04-06 06:36:45-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-18 19:11:31-08:00",
    "text": "Thanks for putting in the effort in writing this. Firstly, I concur with Benoit's observation about text taken from the charter and laid in to the document verbatim. That tends not to help the reader and a large assumption is made that the reader understands the concerns of source based routing for partitioning VPNs, fast re-route, TE, signalling, and so on. Please consider rewriting the intro and other parts to help with understanding (for example in 3.2 Fast Reroute; microploop avoidance is listed as a requirement, however a sensible coverage of microloop avoidance is not found in the draft, nor in the nearby referenced spring-resiliency-use-cases). This also leaves me scratching my head as to why we don't see this document and the resiliency-use-cases (and others) at the same time when they are aligned? Or restructure the document to be more informative on these facets in the first case. Can the document also be explicit that while the SPRING problem/solution space needs to be cognisant of autonomous systems that share policy/interoperate across boundaries the primary port of call is in regard to the IGP. This will certainly aide in restraining everyone (esp. the reader) from trying to boil the 'internet ocean'. (this at least should be easy to address :)",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2021-03-09 05:17:43-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-07 18:43:15-07:00",
    "text": "== Section 1 == \"At the time of writing, almost all this DNS traffic is currently sent \u00a0  in clear (i.e., unencrypted).\u00a0 However there is increasing deployment \u00a0  of DNS-over-TLS (DoT) [ RFC7858 ] and DNS-over-HTTPS (DoH) [ RFC8484 ], \u00a0  particularly in mobile devices, browsers, and by providers of anycast \u00a0  recursive DNS resolution services.\u00a0 There are a few cases where there \u00a0  is some alternative channel encryption, for instance, in an IPsec VPN \u00a0  tunnel, at least between the stub resolver and the resolver. \u00a0  Today, almost all DNS queries are sent over UDP [thomas-ditl-tcp]. \u00a0  This has practical consequences when considering encryption of the \u00a0  traffic as a possible privacy technique.\u00a0 Some encryption solutions \u00a0  are only designed for TCP, not UDP and new solutions are still \u00a0  emerging [ I-D.ietf-quic-transport ] [ I-D.huitema-quic-dnsoquic ].\" This text made me wonder about the value of publishing this bis document at this point in time. Things are evolving so rapidly that, with respect to several of the new parts of this document (e.g., the last few paragraphs of Sec. 6.1.1, Sec. 6.1.1.1, Sec. 6.1.1.2), an immutable summary designed to represent reality over the long term doesn't really seem feasible right now. Why not wait to see how QUIC, DOH, ADD, ODNS, etc. shake out in the next few years and take this up then? == Section 6.1.1.2 == \"Users will only be aware of and have the ability to control such \u00a0  settings if applications provide the following functions: \u00a0  o communicate clearly the change in default to users \u00a0  o provide configuration options to change the default \u00a0  o provide configuration options to always use the system resolver\" This doesn't seem true. If the third bullet isn't provided, users still have awareness and control. Also, the bullets seem redundant with the text above, as if this is saying \"users only have awareness and control if they have awareness and control.\" As a result I'm not sure what this text is really meant to convey.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-10-05 14:42:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-05 14:40:30-07:00",
    "text": "Apologies for changing my YES to a DISCUSS -- I found a later version of my notes on this draft. My DISCUS is specifically around the\"The Alleged Public Nature of DNS Data\" / \"It has long been claimed that \"the data in the DNS is public\" section -- it seems to be unnecessarily creating and then shooting down a strawman. The \"the data in the DNS is public\" aphorism talks is more about the confidentiality one can expect **publishing** data in the DNS, not the privacy of the lookups.\u00a0 This whole section (to my mind) undersells the threat that publishing something in the DNS and expecting it to remain private creates -- for example, I'd be extremely foolish to insert: my-password-fd345432233e.example.com  600 IN TXT \"Hunter2\" Services like Farsight Securities (excellent!) DNSDB will likely capture this almost as soon as I use it somewhere. In addition, the \"Due to the lack of search capabilities, only a given QNAME will reveal the resource records associated with that name\" sentence is either false, or at the very least, misleading. $ dig +dnssec  foo.ietf.org  | grep NSEC  clearly tells me that the names  etherpad.ietf.org  and  ftp.ietf.org  both exist, and  $ dig +dnssec  ftpa.ietf.org  | grep NSEC  tells me that the next name is  guides.ietf.org .... I think that the last 4 or 5 sentences of the section are useful, but that the rest of the section is actively dangerous as it is likely to be misunderstood... Please don't misunderstand - I still believe that the document itself is really important and useful, but the section seems dangerous.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-10-08 05:55:52-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-05 14:42:06-07:00",
    "text": "Apologies for changing my YES to a DISCUSS -- I found a later version of my notes on this draft. My DISCUS is specifically around the\"The Alleged Public Nature of DNS Data\" / \"It has long been claimed that \"the data in the DNS is public\" section -- it seems to be unnecessarily creating and then shooting down a strawman. The \"the data in the DNS is public\" aphorism talks is more about the confidentiality one can expect **publishing** data in the DNS, not the privacy of the lookups.\u00a0 This whole section (to my mind) undersells the threat that publishing something in the DNS and expecting it to remain private creates -- for example, I'd be extremely foolish to insert: my-password-fd345432233e.example.com  600 IN TXT \"Hunter2\" Services like Farsight Securities (excellent!) DNSDB will likely capture this almost as soon as I use it somewhere. In addition, the \"Due to the lack of search capabilities, only a given QNAME will reveal the resource records associated with that name\" sentence is either false, or at the very least, misleading. $ dig +dnssec  foo.ietf.org  | grep NSEC  clearly tells me that the names  etherpad.ietf.org  and  ftp.ietf.org  both exist, and  $ dig +dnssec  ftpa.ietf.org  | grep NSEC  tells me that the next name is  guides.ietf.org .... I think that the last 4 or 5 sentences of the section are useful, but that the rest of the section is actively dangerous as it is likely to be misunderstood. Please don't misunderstand - I still believe that the document itself is really important and useful, but the section seems dangerous (and yes, I realize that it is in  RFC7626 )",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-06-29 12:13:41-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-11 14:21:28-07:00",
    "text": "0) The intended scope of this protocol is not clearly specified in the Abstract or Introduction.\u00a0 By \u00a0 \u00a0 looking at  RFC 6478 , I can see that the original method (and hence the optimization) is for  \u00a0 \u00a0 static pseudo-wires.\u00a0  However, in the introduction, it says \" When PWs use a Multi Protocol  \u00a0  Label Switched (MPLS) network as the Packet Switched Network (PSN), they are setup according \u00a0  to [ RFC8077 ] static configuration mode and the PW status information is propagated \u00a0  using the method described in [ RFC6478 ].\"\u00a0 \u00a0 Looking at  RFC8077  - I see a single line about static \u00a0  assignment. \u00a0  From reading the abstract & introduction, I cannot tell whether this technology applies to: \u00a0 \u00a0 \u00a0  a) statically configured PWs across a dynamically controlled PSN \u00a0 \u00a0 \u00a0  b) statically configured PWs across an MPLS-TP network \u00a0 \u00a0 \u00a0  c) any PWs across a dynamically controlled PSN \u00a0 \u00a0 \u00a0  d)\u00a0 any PWs across an MPLS-TP network \u00a0 I'm sure that the authors and WG have a clearly understood scoping - but\u00a0 it isn't obvious, even \u00a0 after scanning references to me.\u00a0 I think that it is intended for \"statically configured PWs\" because \u00a0 if LDP were used to create the PWs, there would be information about the PW status in LDP so this \u00a0 mechanism (optimizing the mechanism that is in  RFC 6478 ) is only needed for statically configured PWs. 1) In Sec 2, it states \"A PE using the PW status refresh reduction protocol MUST send the PW \u00a0  status refresh reduction Message as soon as a PW is configured on a \u00a0  particular LSP. \"\u00a0   \u00a0 \u00a0 \u00a0  I have several questions as I think about implementing this and dig into the nuances.\u00a0 As it \u00a0 \u00a0 \u00a0  is stated, I think it has issues. \u00a0 \u00a0 \u00a0  a) Is the assumption that a PE will use the PW status reduction protocol for every LSP it has? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Wouldn't that depend on the egress of the LSP & specifics of configuration?\u00a0 This MUST \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  removes such flexibility without any discussion. \u00a0 \u00a0 \u00a0  b) Do you mean the PW status refresh reduction message MUST be sent as soon as the first PW \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  is configured on an LSP?\u00a0  If this is for every new PW without consideration for dampening, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  I could see a new configuration being loaded, processed, and resulting in a flood of PW status \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  refresh reduction messages.\u00a0  Surely there should be a maximum rate at least. 2) In Sec 3: \"If the refresh reduction protocol session is terminated by entering \u00a0  the INACTIVE or STARTUP states, the PE MUST immediately re-send all \u00a0  the previously sent PW status messages for that particular LSP for \u00a0  which the session terminated. In this case the refresh timer value \u00a0  MUST NOT be set to zero, and MUST be set according to the local \u00a0  policy of the PE router.\" \u00a0  This MUST forces a flood of messages.\u00a0 Is there a reason that the PW status messages \u00a0  shouldn't be staggered out in time based upon 2x the refresh timer for PW status messages? \u00a0  At a minimum, something like \"the PE SHOULD re-send .... as soon as possible and MUST \u00a0  resent them within .... interval\" would be safer for the spiked load.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-05 13:51:52-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:17:49-07:00",
    "text": "I need a bit of help understanding how to read the Security Considerations text \u2013 threats are identified but how they are mitigated seems implicit.\u00a0 The text, \u201cIn general the same types of attacks \u2026 However, the latter will be more difficult to detect \u2026\u201d, alludes to a similar threat without a reference and seems to suggest it will be worse in the deployed environment of this extension. The next paragraph, \u201cExisting security extensions \u2026 [ RFC5304 ] and [ RFC5310 ] apply \u2026\u201d states that [ RFC5304 ] and [ RFC5310 ] also apply.\u00a0 What does apply mean here \u2013 should they be used?\u00a0 Do they mitigate what\u2019s described in the previous paragraph?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-31 14:38:43-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-17 14:58:19-07:00",
    "text": "* Section 3.1 It is not clear to me what exactly the normative addendum is requiring the client to do as regards to the DNS query while implementing \"The dual-stack client SHOULD look up all address records\". Does this mean that the client should do a AAAA (28) query followed by (or in parallel or preceded ) for a A (1) query? I think it would be good to clarify the types and ordering/concurrency of the queries. * Section 4 I am a bit puzzled by the merging of the address lists from two separate DNS queries in relation to  RFC6724 . This is how I see the destination address selection in  RFC6724 . The application ends up calling some kind of name resolution API (something like getaddrinfo()) with a hostname/FQDN (say  sip-1.example.com ) and this results in a set of addresses being returned. The destination address selection algorithm specified in Section 6 of  RFC6724  then orders these addresses and picks one. I am not seeing how the second FQDN and its associated set of addresses become involved in the  RFC6724  process. Is this something that you are adding on top of  RFC6724 ? Please clarify.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-04-14 21:19:50-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-06 21:17:47-07:00",
    "text": "[ section 2.1 ] * \"may also force the use of NPTv6\" seems like it draws some conclusions. \u00a0 Perhaps something like: \u00a0 \"may also increase the perceived need for the use of NPTv6\"? [ section 2.2 ] * \"It must also be noted that there is no indication in the IPv6 packet \u00a0  as to whether the Next Protocol field points to an extension header \u00a0  or to a transport header.\" \u00a0 What is this trying to say?\u00a0 Is this about what 8200 calls the \"Next \u00a0 Header\" field?\u00a0 If so, the Next Header field indicates...the next \u00a0 header, and whether that's a transport header or not depends on its \u00a0 value. \u00a0 I guess I read this text as implying that the 8200 standard is somehow \u00a0 ambiguous about what NH means, but it's really not.\u00a0 It's just that \u00a0 NH does not always indicate a transport. [ section 2.3.2.4 ] * \"Only trivial cases [...] should have RA-guard...\" \u00a0 Only?\u00a0 This doesn't strike me as being obviously the best recommendation. \u00a0 Definitely in trivial cases it should be enabled, but surely it should \u00a0 also be enabled even in more complex cases, albeit ones where \u00a0 knowledgeable administrators can configure things appropriately \u00a0 (vis. the applicability statement in section 1.1)...maybe?",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-02-02 06:31:33-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-01 19:53:32-08:00",
    "text": "Thank you for a clearly written document.\u00a0 I have a couple technical concerns that I think should be quick to handle. \u00a0 Section 4.1: \"A mid-point LSR MAY send an unsolicited PathErr with the Notify error \u00a0  code and sub-code \"Preferable P2MP-TE Tree Exists\" to the ingress \u00a0  node to notify of a preferred P2MP-TE LSP tree when it determines it \u00a0  exists. \"\u00a0  I think it would be better to have some text about dampening so that PathErrs are \u00a0  emitted at a reasonable rate.  \u00a0  Related, I see \" The sending of an RSVP PathErr with the Notify error code and \u00a0  \"Preferable P2MP-TE Tree Exists\" sub-code to the ingress node \u00a0  notifies the ingress node of the existence of a preferable P2MP-TE \u00a0  LSP tree and upon receiving this PathErr, the ingress node MUST \u00a0  trigger re-optimization of the LSP using the MBB method with a different LSP-ID.\" \u00a0  At a minimum can you please explain why this would be a MUST instead of a MAY or a SHOULD? \u00a0  I believe this would need to be in the document to be clear\u00a0 what the \u00a0 assumptions are.\u00a0 The rest of the document is providing mechanisms for fragmenting \u00a0 and requesting reoptimization checks.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-09-28 06:07:03-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 14:20:44-07:00",
    "text": "We previously had a work item we were tracking with the IEEE leadership around the IEEE writing a YANG module for ethertypes. I just wanted to check that the IEEE is aware that this document is defining a placeholder module for ethertypes until such time that they define one.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-09-28 09:40:35-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 10:31:30-07:00",
    "text": "I think this is good work to have, overall, and the document pretty easy to read. That said, I think the Security Considerations need to be expanded a bit more before this document get published: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Write operations (e.g., ) \u00a0  to these data nodes without proper protection can have a negative \u00a0  effect on network operations. I think the effects can be on more than just *network* operations, there can be negative effects for end systems that (e.g.) experience DoS attacks that would otherwise have been blocked, receive maliciously crafted packets that trigger application bugs, are used as part of (e.g.) UDP amplification attacks, etc. \u00a0 \u00a0 \u00a0 /acls/acl/aces: This list specifies all the configured access \u00a0 \u00a0 \u00a0 control entries on the device.\u00a0 Unauthorized write access to this \u00a0 \u00a0 \u00a0 list can allow intruders to access and control the system. \u00a0 \u00a0 \u00a0 Unauthorized read access to this list can allow intruders to spoof \u00a0 \u00a0 \u00a0 packets with authorized addresses thereby compromising the system. I agree with the secdir reviewer that \"the system\" needs to be clarified, and that the consequences of unauthorized write and read access need to be more clearly described. His proposed text is much better than the present text, though there are other ways to convey the needed information.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-11-06 02:22:25-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-21 06:47:07-07:00",
    "text": "1) The tcp options element is type uint32, however, the option field in the TCP header can be up to 40 bytes. 2) Why are only TCP and UDP supported? What's about SCTP and DCCP? 3) The icmp rest-of-header can also be larger than 4 bytes but the type is uint32 again.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-10-01 19:42:09-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 21:36:43-07:00",
    "text": "This document is missing ACL handling for ICMPv6 ( RFC4443 ) completely. As the ICMP types and codes are different for ICMP and ICMPv6 I think this model should be included to cover ICMPv6.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-09-26 18:56:11-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 13:49:08-07:00",
    "text": "Be ye not afraid -- this DISCUSS is easily cleared, but sufficiently important that I thought it worth making, and making sure it didn't slip through the cracks. The description for match-on-ipv4 says: \"The device can support matching on IPv4 headers.\", but the description for 'match-on-tcp', 'match-on-udp', 'match-on-icmp' say: \"The device can support\u00a0 headers.\" I really think that these need to be \"The device can support matching on\u00a0 headers.\"",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-04-12 13:50:42-07:00",
    "end_reason": "position_updated",
    "start": "2015-11-30 20:58:14-08:00",
    "text": "(1) I have a fairly fundamental concern about this document that I'd like to discuss. My impression is that most B2BUAs in the market today that handle DTLS-SRTP do so with the explicit purpose of accessing the media. That is, if I need a box that doesn't access the media I use a SIP proxy, and if I need one that does access it I use a B2BUA. I realize that there are more flavors of B2BUA defined in  RFC 7092 , but in terms of how real SBCs work, it seems to me that they break DTLS-SRTP intentionally if they do so at all.  If that's the case, the question then arises about the value of writing down normative recommendations that are more than likely to be ignored. Perhaps this document would have made more sense as informational, offering a non-normative explanation of what a B2BUA should do if it does not want to break e2e security. Even as an informational document it's still not obvious to me that there is much at all to say here for media-aware B2BUAs that isn't entirely reductive -- \"don't terminate DTLS-SRTP if you don't want to break DTLS-SRTP\" -- but at least as an informational document it wouldn't be suggesting normative requirements that are out of sync with real deployments. Could you articulate the reasons why someone would build a B2BUA that follows the recommendations in this draft? I note that the draft says nothing about using a TURN server as a media relay, which seems like it would be more common than using a B2BUA for the same purpose. Aren't B2BUAs typically deployed *because* they are media-aware? (2) Taking into account the above comment, I think 3.1.2.1 and 3.1.2.2 are problematic. 3.1.2.1 creates a normative SHOULD NOT-level requirement for inspection B2BUAs without explaining what the exception cases are, and 3.1.2.2 creates no normative requirements for modification B2BUAs. It's not even clear to me why the distinction is being drawn between the two kinds of B2BUAs if the bottom line is that in both cases the recommendation is to not terminate DTLS-SRTP. But this brings us back to the above comment. The problem here seems to be that what the WG and the IETF would want to say here is that B2BUAs MUST NOT terminate DTLS-SRTP to man-in-the-middle the media, but that is what B2BUAs generally do, so instead the text waffles and the recommendations are watered down and unclear. (3) The characterization of the  RFC 4474  mechanism seems to contradict the way the mechanism is actually specified. The 4474 mechanism was designed such that intermediaries would be able to provide signatures on behalf of users (e.g., see  RFC 4474  Section 3, \"This specification allows either a user agent or a proxy server to provide identity services and to verify identities ... in the initial use of this mechanism, it is likely that intermediaries will instantiate the authentication service role\"). So the claim that terminating DTLS-SRTP would cause 4474 identity and integrity checks to fail isn't true, because an SBC can decrypt and re-sign the request itself. A B2BUA that bridges two administrative domains can check the validity of the signature in the domain on on side as authorization to form a new signature that is valid in the domain in the other side. The fact that user-provided identity assertions are not guaranteed to persist end-to-end is one key reason for the ongoing work in the STIR WG. The work there and elsewhere shows that it's fairly widely acknowledged that 4474 has not seen the deployment that was hoped for when it was specified. Making its use a normative requirement here again seems out of sync with deployment reality. I would encourage you to review  draft-ietf-stir-rfc4474bis  and reconsider what security mechanism should form the basis of the recommendations in this draft.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-01 03:37:16-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-01 15:29:55-08:00",
    "text": "I wonder if you've gotten wrapped around the axle here knowing that we won't standardise a (D)TLS MitM, but yet trying to describe things that basically are often deployed as MitMs.\u00a0 Anyway, while I do agree with Alissa's discuss, I also have some additional points to raise, some of which I think came up when we had some mail exchanges about an earlier version of this draft back in January of this year. (1) Alissa is correct that the unqualified SHOULD NOT \"terminate\" DTLS is insufficient, but in addition to her call for qualification of that, (or I guess moving to a MUST NOT,) I would like to chat about the consequences should one (for whatever reason) ignore that SHOULD NOT. Whether or not this discuss point is worth talking about depends on how Alissa's discuss on this is resolved.\u00a0 It seems to me (as I said back in January) that keeping the SHOULD NOT would mean that any UA that is able to inter-operate with a B2BUA that does \"terminate\" DTLS (because it fits with whatever qualifiers you end up adding to the SHOULD NOT) can never ever be confident of the identity of any DTLS peer (since it has code that lets the call happen regardless of the DTLS-layer peer identity). I can't see how that wouldn't make the Internet worse, hence the discuss. (2) In the introduction you say \"B2BUAs terminating DTLS-SRTP session are outside the scope of this document.\" yet if you keep the SHOULD NOT and don't move that to a MUST NOT (which was an option we discussed back in Jan, I assume the WG didn't like that?), then you are in fact including those are within the scope of this document and therefore you would need to specify how to \"terminate\" a DTLS or DTLS-SRTP session when one is a B2BUA but yet respect  RFC2804 .\u00a0 I just can't see how one might do that to be honest. (3) 3.1.2 says: \"There are two types of media-aware relays, those that merely inspect the RTP headers and unencrypted portions of RTCP packets, and those that inspect and modify the RTP headers and unencrypted portions of RTCP packets.\" Logically, those are not the only options, as one can modify the encrypted portions too. (Hopefully resulting in the integrity checking causing the packets to be dropped.) I think this particular lack of clarity does raise to the level of a DISCUSS as it's crucial for this document to be clear about not standardising a MitM. (\"Sins of omission\" are  probably not a good idea here:-) (4) 3.1.2.2 says: \"This security and privacy problem can be mitigated by having different keys for protecting RTP header integrity and encrypting the RTP payload.\u00a0 For example, the approach discussed in [ I-D.jones-perc-private-media-reqts ] can be used.\" I have two issues with that. First, where is having different keys documented? If only in the draft referenced, then what is the status of that? And secondly, doesn't perc require a KMS to exist? In which case I can't see how this specification works for calls between UAs (via a B2BUA) where there is no KMS. I think there are both security and interop (and hence also process) issues with what you're saying here. (5) 3.2 says: \"the ClientHello message from a B2BUA (acting as DTLS client)\" I don't see how a B2BUA can send it's own ClientHello (as opposed to forwarding a UA's) unless it is a MitM.\u00a0 Since we do not standardise MitM (cf.  RFC2804 ) this text must be wrong or out of place?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-10-06 22:57:38-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-05 06:33:59-07:00",
    "text": "Thank you for the work put into this document.  Please find below two blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Barry Leiba for his concise shepherd's write-up but very clear about the WG consensus. Thank you also to Donald Eastlake for this INT directorate review that I am vastly supporting: https://mailarchive.ietf.org/arch/msg/int-dir/6Ox8iEBMqXkUoC2aUEF3wi4-c5g/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Generic comment how are link-local address (LLA) with scope encoded ? I would expect CBOR to work also on LLA only networks... At the bare minimum, please state that link-local addresses cannot be encoded with their scope, hence, they cannot represent an interface. -- Section 3.1.3 -- How can 2 valid link-local addresses (fe80::1%eth0, fe80::1%eth1) can be represented in order to identity two interfaces ?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-10-06 18:49:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-06 18:47:42-07:00",
    "text": "Thanks for this document. In general I found it easy to read, blessedly concise, and useful. I do have one concern with how you treat the covert channel concern you raise, which I'm making a DISCUSS (which I think will be easily cleared). Section 4 says: \u00a0  even though variations like: \u00a0  54([44, h'20010db81233']) \u00a0  54([45, h'20010db8123f']) \u00a0  would be parsed in the exact same way; they MUST be considered \u00a0  invalid. You choose to use a  RFC 2119  keyword here, and this is in the encoder section, so presumably you are insisting that the encoder MUST... what? You already said, in an earlier paragraph, that the encoder MUST set the trailing bits to zero, so I can't figure out what the quoted text is telling me to do. (Presumably any compliant encoder won't produce the depicted values, and an encoder that's noncompliant for the purpose of deliberately exfiltrating data using this covert channel won't be put off by this MUST.) Then in Section 5 we have: \u00a0  A particularly paranoid decoder could examine the lower non-relevant \u00a0  bits to determine if they are non-zero, and reject the prefix.\u00a0 This \u00a0  would detect non-compliant encoders, or a possible covert channel. The fairly dismissive tone (\"paranoid decoder could\"), not to mention the preceding pseudocode, suggests that you have no real expectation the decoder will do anything to \"consider invalid\" values with nonzero low bits. So probably the MUST from Section 4 isn't meant to apply to the decoder. In short I don't understand what that clause in Section 4 is telling me to do. One fix would simply to weaken the text, as in \u00a0  would be parsed in the exact same way, they should not be  \u00a0  considered legitimate encodings. \u00a0   P.S.: The semicolon in the quoted text is also either wrong, or I'm even more confused about what's being specified than I thought I was.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-10-09 07:47:40-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 18:49:01-07:00",
    "text": "Thanks for this document. In general I found it easy to read, blessedly concise, and useful. I do have one concern with how you treat the covert channel concern you raise, which I'm making a DISCUSS (which I think will be easily cleared). Section 4 says: \u00a0  even though variations like: \u00a0  54([44, h'20010db81233']) \u00a0  54([45, h'20010db8123f']) \u00a0  would be parsed in the exact same way; they MUST be considered \u00a0  invalid. You choose to use a  RFC 2119  keyword here, and this is in the encoder section, so presumably you are insisting that the encoder MUST... what? You already said, in an earlier paragraph, that the encoder MUST set the trailing bits to zero, so I can't figure out what the quoted text is telling me to do. (Presumably any compliant encoder won't produce the depicted values, and an encoder that's noncompliant for the purpose of deliberately exfiltrating data using this covert channel won't be put off by this MUST.) Then in Section 5 we have: \u00a0  A particularly paranoid decoder could examine the lower non-relevant \u00a0  bits to determine if they are non-zero, and reject the prefix.\u00a0 This \u00a0  would detect non-compliant encoders, or a possible covert channel. The fairly dismissive tone (\"paranoid decoder could\"), not to mention the preceding pseudocode, suggests that you have no real expectation the decoder will do anything to \"consider invalid\" values with nonzero low bits. So probably the MUST from Section 4 isn't meant to apply to the decoder. In short I don't understand what that clause in Section 4 is telling me to do. One fix would simply be to weaken the text, as in \u00a0  would be parsed in the exact same way, they should not be  \u00a0  considered legitimate encodings. \u00a0   P.S.: The semicolon in the quoted text is also either wrong, or I'm even more confused about what's being specified than I thought I was.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-03 10:07:35-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 13:51:00-08:00",
    "text": "I think we need greater clarity on whether the list of GDR candidate addresses is sorted or not (i.e., whether it is required for protocol operation), as indicated by the rtgdir reviewer. Specifically, Section 5.3 is clear in the descriptive text that the list is sorted (as if a recipient might rely on that behavior), but Section 5.3.2 and Section 5.4 only have it as RECOMMENDED.\u00a0 Given my understanding of the protocol, it seems that all routers need to receive the DRLB-List in order to perform the GDR selection algorithm, in which case the extra information about the addresses being sorted would not be useful for the calculation.\u00a0 That would actually suggest that we do not need  RFC 2119  keywords here, and could just say (as we do in Section 5.4) that it's recommended for the DR to use a deterministic procedure, such as sorting. I also think the text should be more clear in Section 5.3.2 about the use of the Router Identifier as the \"GDR Candidate Address\".\u00a0 I believe (but am not certain) that the intended behavior is that the elected DR use all the PIM Hellos it has received (from candidate GDRs) to assemble the list of candidate \"addresses\", but instead of using the actual IP addresses it uses the Router Identifier construction described here when assembling the \"GDR Candidate Address(es)\" field.\u00a0 The current text leaves unsaid what entity is performing this operation and how the PIM Hello+Router Identifier corresponds to an entry in the list of addresses.\u00a0 Furtheremore, for the IPv6 case, it seems like this substitution procedure interacts very poorly with the masking procedure when the network includes a mix of routers that do/don't send a Router ID (as it may not be possible to set a 32-bit contiguous mask that captures the varying parts of IPv6 router addresses and the space reserved here for \"Router ID\"). I'm concerned about hash algorithm agility (in the vein of  BCP 201 , though since this is not a cryptographic hash that BCP does not strictly speaking apply), as the rtg-dir review noted.\u00a0 Specifically, each router has to commit in its Hello to a single hash algorithm, so transitioning to a new algorithm will require accepting reduced functionality during the transition period (a reduced list of potential GDR candidates), which is contrary to the goals of algorithm negotiation espoused in  BCP 201 .\u00a0 Is this not a significant concern for this use case?\u00a0 I see that Section 6 attempts to disclaim discussion of algorithm migration, but I am not yet convinced that it is appropriate to do so. Please also remove from Section 5.7 the stale statement referring to the previous section (see COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-11 13:01:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 00:42:00-07:00",
    "text": "My apologies if this is super-obvious and I'm just missing it ... but Section 4.3 dictates that part of the value for the application-specific SRLG TLV is a \"Neighbor System-ID + pseudo-node ID (7 octets)\".\u00a0 Where are these defined?\u00a0 (We don't exactly say that we're reusing the structure from, e.g., TLV 138, which I note refers to the seventh octet as \"pseudonode number\", not \"pseudo-node ID\".\u00a0 Similarly for the interpretation of the SRLG value(s).\u00a0 Do we just need to reference that we're reusing the encoding from  RFC 5307  (or similar) or are some changes needed?",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-06-18 12:45:41-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 15:16:11-07:00",
    "text": "This should be simple to resolve - the use of the SR-TE term is out-of-alignment with other drafts, spring and idr. Suggest: Segment Routing Traffic Engineering/s/Segment Routing Policy and SRTE/s/SR Policy.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-06-11 15:29:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 12:29:20-07:00",
    "text": "An easy one: Sections 7.3 and 7.5 create new IANA registries with \"Expert Review\" rules, but Section 7.5 provides no particular guidance to the Designated Expert about how to review applications, as required by Section 4.5 of  BCP 26 .",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2016-05-02 15:14:40-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-05-02 14:24:09-07:00",
    "text": "a) In Sec 7.2.3:\u00a0 \"If the SBFDReflector is generating a response S-BFD control packet for a local entity that is in \u00a0 \u00a0 \u00a0 service, then \"state\" in response BFD control packets MUST be set to UP.\" \u00a0 \u00a0 So far, it looked like the SBFDReflector only sends BFD control packets in response to receiving such packets \u00a0 \u00a0 from SBFDInitiators.\u00a0  This paragraph (not just copied) does not clearly describe the desired behavior.\u00a0 If the \u00a0  monitored local entity is \"temporarily out of service\", does the SBFDReflector respond back to the SBFDInitiator \u00a0  with 2 BFD control packets - one indicating UP (as a MUST) and then the next indicating ADMINDOWN?\u00a0 Is the \u00a0  SBFDReflector expected to store a list of active SBFDInitiators and proactively send BFD control packets indicating \u00a0  ADMINDOWN?\u00a0  Please clarify in non-trivial detail. b) Appendix A:\u00a0 The looping problem is nicely defined but the text still discusses three potential solutions; clearly the use of the D bit has been chosen.\u00a0  It would be much nicer to have the justification in line, but for this discuss - the unselected alternatives don't belong. c) Sec 7.2.1: \"\u00a0  S-BFD packet MUST be demultiplexed with lower layer information \u00a0  (e.g., dedicated destination UDP port, associated channel type).\" \u00a0 Where precisely is this defined or described?\u00a0 Is there an allocation for a dedicated UDP port for S-BFD?\u00a0 I don't see any normative reference to such.\u00a0 In particular, since the format for an S-BFD control packet is exactly the same as for BFD and since only this demultiplexing with lower layer information is used to tell the difference between S-BFD and BFD packets, this document requires more specifics.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2016-05-03 09:22:43-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-02 15:14:40-07:00",
    "text": "a) In Sec 7.2.3:\u00a0 \"If the SBFDReflector is generating a response S-BFD control packet for a local entity that is in \u00a0 \u00a0 \u00a0 service, then \"state\" in response BFD control packets MUST be set to UP.\" \u00a0 \u00a0 So far, it looked like the SBFDReflector only sends BFD control packets in response to receiving such packets \u00a0 \u00a0 from SBFDInitiators.\u00a0  This paragraph (not just copied) does not clearly describe the desired behavior.\u00a0 If the \u00a0  monitored local entity is \"temporarily out of service\", does the SBFDReflector respond back to the SBFDInitiator \u00a0  with 2 BFD control packets - one indicating UP (as a MUST) and then the next indicating ADMINDOWN?\u00a0 Is the \u00a0  SBFDReflector expected to store a list of active SBFDInitiators and proactively send BFD control packets indicating \u00a0  ADMINDOWN?\u00a0  Please clarify in non-trivial detail. b) Appendix A:\u00a0 The looping problem is nicely defined but the text still discusses three potential solutions; clearly the use of the D bit has been chosen.\u00a0  It would be much nicer to have the justification in line, but for this discuss - the unselected alternatives don't belong. c) Sec 7.2.1: \"\u00a0  S-BFD packet MUST be demultiplexed with lower layer information \u00a0  (e.g., dedicated destination UDP port, associated channel type).\" \u00a0 Please add a clear reference to [ draft-ietf-bfd-seamless-ip ] here to show where to find the dedicated UDP port for S-BFD; I think this or some other mechanism needs to be a normative reference, because I don't see how one could implement S-BFD without this knowledge.\u00a0 \u00a0 In particular, since the format for an S-BFD control packet is exactly the same as for BFD and since only this demultiplexing with lower layer information is used to tell the difference between S-BFD and BFD packets, this document requires more specifics.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-05-03 18:23:38-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 13:27:24-07:00",
    "text": "This should be easy to resolve, but given the usage in a \"MUST\" in the security considerations, I think it's important to fix: In section 11, it's not clear to me what is meant by \"look at\" in the 2nd and 3rd bullets. I assume you mean that the SBFDReflector MUST NOT/MAY use those respective values to make some decision? Otherwise, it's pretty hard to test whether something \"looks at\" a field.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-05-03 14:04:01-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-02 12:36:20-07:00",
    "text": "This should be pretty easy to address.\u00a0 In the security consideration section, the following recommendation appears:  o\u00a0 SBFDReflector MUST NOT look at the crypto sequence number before \u00a0 \u00a0 \u00a0 accepting the packet. Could you please add text to say what happens (what attacks are possible) if this is looked at?\u00a0 There is nothing to stop the crypt sequence number from being looked at, right?\u00a0 Is there a way to actually prevent that?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-05-04 08:55:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 02:35:07-07:00",
    "text": "As S-BFD has no initiation process anymore it is not guarenteed that the receiver/responder actually exists. That means that packets could float (uncontrolled) in the network or even outside of the adminstrative domain (e.g. due to configuration mistakes). From my point of view this document should recommend/require two things: 1) A maximum number of S-BFD packet that is allow to be send without getting a response (maybe leading to a local error report). 2) Egress filtering at the adminstrative border of the domain that uses S-BFD to make sure that no S-BFD packets leave the domain.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-08-10 07:50:15-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-23 19:30:47-07:00",
    "text": "\u00a0 \u00a0 \u00a0 Since xattrs are application data, security issues are exactly the \u00a0 \u00a0 \u00a0 same as those relating to the storing of file data and named \u00a0 \u00a0 \u00a0 attributes.\u00a0 These are all various sorts of application data and \u00a0 \u00a0 \u00a0 the fact that the means of reference is slightly different in each \u00a0 \u00a0 \u00a0 case should not be considered security-relevant.\u00a0 As such, the \u00a0 \u00a0 \u00a0 additions to the NFS protocol for supporting extended attributes \u00a0 \u00a0 \u00a0 do not alter the security considerations of the NFSv4.2 protocol \u00a0 \u00a0 \u00a0 [ RFC7862 ]. This seems inadequate. The issue is that if machine A writes some extended attribute which is security relevant (i.e., this file is only readable under certain conditions) and then machine B doesn't know about the attribute, then you have a security problem on B because it will not enforce it. It seems like FreeBSD uses extended attributes for this purpose, so this isn't just theoretical.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-12-08 07:51:53-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-10 13:50:22-07:00",
    "text": "Section 5.1. (Definitions) refers to a couple of \u201cexisting IGP timers\u201d.\u00a0 I understand the concepts, but can you please reference the IGP documents where these timers are defined?\u00a0 I quickly checked  rfc2328  and couldn\u2019t find a specific place that talked about LSP_GEN_TIMER (or LSA, of course!), or a similar concept.\u00a0 SPF_DELAY seems to be introduced by I-D.ietf-rtgwg-backoff-algo.\u00a0 Given that the rest of Section 5. (Specification) is built on these \u201cexisting IGP timers\u201d, I think that the references should be Normative. Note also that the description in Section 5.2. (Current IGP reactions) is described (in 5.3) as the \u201cstandard IP convergence\u201d and carries a \u201cMUST\u201d associated with it.\u00a0 It was mentioned (in 5.1) that the timers in question are \u201coften associated with a damping mechanism\u201d, which is not part of the base IGP specifications.  I\u2019m putting this comment in as a DISCUSS given that understanding the definitions (and having then Normative references) is necessary for the implementation of the mechanism described.\u00a0 I think it should be easy to resolve by just adding the appropriate references.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-10-25 10:23:54-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-25 10:23:16-07:00",
    "text": "The Introduction says: \u00a0  The YANG module described in [ RFC8049 ] cannot be implemented because \u00a0  of issues around the use of XPATH.\u00a0 This document obsoletes [ RFC8049 ] \u00a0  by creating a new module with the same name that is not backward \u00a0  compatible (in the sense described in YANG 1.1 [ RFC7950 ]).\u00a0 The \u00a0  changes (listed in full in Section 1.4) are small in scope, but \u00a0  include fixes to the module to make it possible to implement. As the text above says, the model in this document is not compliant with what  rfc7950  (The YANG 1.1 Data Modeling Language) specifies in Section 11 (Updating a Module), which starts by saying: \u00a0  As experience is gained with a module, it may be desirable to revise \u00a0  that module.\u00a0 However, changes to published modules are not allowed \u00a0  if they have any potential to cause interoperability problems between \u00a0  a client using an original specification and a server using an \u00a0  updated specification. It seems clear to me that experience after the original module ( rfc8049 ) was published has lead to the conclusion that an implementation is impossible \u2014 as this fact was not discovered before publication.\u00a0 I believe that the possibility of implementation (or not) of the module in  rfc8049  is irrelevant as the specification in  rfc7950  talks about updates without any qualification.  The solution seems straight forward to me: follow  rfc7950 , either by changing the module name, or by keeping the name and following the specification on how to update a module. I am concerned that the discussions related to the RtgDir review [1] in the netmod [2][3] and ietf@ietf [4] lists have not resulted in an updated draft which complies with  rfc7950 .\u00a0 Even if any relevant WGs (this document is AD-sponsored) or the ietf@ietf list reached consensus on moving forward with the document as is, it would still not be following what a Standards Track document specifies ( rfc7950 , in this case).\u00a0 IOW, documents that don\u2019t conform to what is clearly specified in a Standards Track, community consensus RFC, should not be approved for publication (without the proper Updates to that RFC, of course). I am then Balloting DISCUSS for the authors to update the document according to the module update specification in  rfc7950 , or for the discussions on the lists to reach (a different) consensus [*] and then consider the next steps. [1]  https://datatracker.ietf.org/doc/review-wu-l3sm-rfc8049bis-07-rtgdir-lc-berger-2017-10-16/ [2]  https://mailarchive.ietf.org/arch/msg/netmod/-VC7QhHzTyY0P8sL1m4QRg20cv8/?qid=373bf84b373edd7be9e51621c294189a [3]  https://mailarchive.ietf.org/arch/msg/netmod/xDIT_6R0cw_UT97scDYPArTbCYU/?qid=373bf84b373edd7be9e51621c294189a [4]  https://mailarchive.ietf.org/arch/msg/ietf/f4xmJk651EYzIlGi2bgDxAWQkWU/?qid=9c0f779d3f35b9787d796586750fcf36 [*] I know that the conversation on versioning is still ongoing.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-10-25 10:25:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-25 10:23:54-07:00",
    "text": "The Introduction says: \u00a0  The YANG module described in [ RFC8049 ] cannot be implemented because \u00a0  of issues around the use of XPATH.\u00a0 This document obsoletes [ RFC8049 ] \u00a0  by creating a new module with the same name that is not backward \u00a0  compatible (in the sense described in YANG 1.1 [ RFC7950 ]).\u00a0 The \u00a0  changes (listed in full in Section 1.4) are small in scope, but \u00a0  include fixes to the module to make it possible to implement. As the text above says, the model in this document is not compliant with what  rfc7950  (The YANG 1.1 Data Modeling Language) specifies in Section 11 (Updating a Module), which starts by saying: \u00a0  As experience is gained with a module, it may be desirable to revise \u00a0  that module.\u00a0 However, changes to published modules are not allowed \u00a0  if they have any potential to cause interoperability problems between \u00a0  a client using an original specification and a server using an \u00a0  updated specification. It seems clear that experience after the original module ( rfc8049 ) was published has lead to the conclusion that an implementation is impossible \u2014 as this fact was not discovered before publication.\u00a0 I believe that the possibility of implementation (or not) of the module in  rfc8049  is irrelevant as the specification in  rfc7950  talks about updates without any qualification.  The solution seems straight forward to me: follow  rfc7950 , either by changing the module name, or by keeping the name and following the specification on how to update a module. I am concerned that the discussions related to the RtgDir review [1] in the netmod [2][3] and ietf@ietf [4] lists have not resulted in an updated draft which complies with  rfc7950 .\u00a0 Even if any relevant WGs (this document is AD-sponsored) or the ietf@ietf list reached consensus on moving forward with the document as is, it would still not be following what a Standards Track document specifies ( rfc7950 , in this case).\u00a0 IOW, documents that don\u2019t conform to what is clearly specified in a Standards Track, community consensus RFC, should not be approved for publication (without the proper Updates to that RFC, of course). I am then Balloting DISCUSS for the authors to update the document according to the module update specification in  rfc7950 , or for the discussions on the lists to reach (a different) consensus [*] and then consider the next steps. [1]  https://datatracker.ietf.org/doc/review-wu-l3sm-rfc8049bis-07-rtgdir-lc-berger-2017-10-16/ [2]  https://mailarchive.ietf.org/arch/msg/netmod/-VC7QhHzTyY0P8sL1m4QRg20cv8/?qid=373bf84b373edd7be9e51621c294189a [3]  https://mailarchive.ietf.org/arch/msg/netmod/xDIT_6R0cw_UT97scDYPArTbCYU/?qid=373bf84b373edd7be9e51621c294189a [4]  https://mailarchive.ietf.org/arch/msg/ietf/f4xmJk651EYzIlGi2bgDxAWQkWU/?qid=9c0f779d3f35b9787d796586750fcf36 [*] I know that the conversation on versioning is still ongoing.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-10-25 10:26:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-25 10:25:03-07:00",
    "text": "The Introduction says: \u00a0  The YANG module described in [ RFC8049 ] cannot be implemented because \u00a0  of issues around the use of XPATH.\u00a0 This document obsoletes [ RFC8049 ] \u00a0  by creating a new module with the same name that is not backward \u00a0  compatible (in the sense described in YANG 1.1 [ RFC7950 ]).\u00a0 The \u00a0  changes (listed in full in Section 1.4) are small in scope, but \u00a0  include fixes to the module to make it possible to implement. As the text above says, the model in this document is not compliant with what  rfc7950  (The YANG 1.1 Data Modeling Language) specifies in Section 11 (Updating a Module), which starts by saying: \u00a0  As experience is gained with a module, it may be desirable to revise \u00a0  that module.\u00a0 However, changes to published modules are not allowed \u00a0  if they have any potential to cause interoperability problems between \u00a0  a client using an original specification and a server using an \u00a0  updated specification. It seems clear that experience after the original module ( rfc8049 ) was published has lead to the conclusion that an implementation is impossible \u2014 as this fact was not discovered before publication.\u00a0 I believe that the possibility of implementation (or not) of the module in  rfc8049  is irrelevant as the specification in  rfc7950  talks about updates without any qualification.  The solution seems straight forward to me: follow  rfc7950 , either by changing the module name, or by keeping the name and following the specification on how to update a module. I am concerned that the discussions related to the RtgDir review [1] in the netmod [2][3] and ietf@ietf [4] lists have not yet resulted in an updated draft which complies with  rfc7950 .\u00a0 Even if any relevant WGs (this document is AD-sponsored) or the ietf@ietf list reached consensus on moving forward with the document as is, it would still not be following what a Standards Track document specifies ( rfc7950 , in this case).\u00a0 IOW, documents that don\u2019t conform to what is clearly specified in a Standards Track, community consensus RFC, should not be approved for publication (without the proper Updates to that RFC, of course). I am then Balloting DISCUSS for the authors to update the document according to the module update specification in  rfc7950 , or for the discussions on the lists to reach (a different) consensus [*] and then consider the next steps. [1]  https://datatracker.ietf.org/doc/review-wu-l3sm-rfc8049bis-07-rtgdir-lc-berger-2017-10-16/ [2]  https://mailarchive.ietf.org/arch/msg/netmod/-VC7QhHzTyY0P8sL1m4QRg20cv8/?qid=373bf84b373edd7be9e51621c294189a [3]  https://mailarchive.ietf.org/arch/msg/netmod/xDIT_6R0cw_UT97scDYPArTbCYU/?qid=373bf84b373edd7be9e51621c294189a [4]  https://mailarchive.ietf.org/arch/msg/ietf/f4xmJk651EYzIlGi2bgDxAWQkWU/?qid=9c0f779d3f35b9787d796586750fcf36 [*] I know that the conversation on versioning is still ongoing.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-11-29 11:25:39-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-25 10:26:24-07:00",
    "text": "The Introduction says: \u00a0  The YANG module described in [ RFC8049 ] cannot be implemented because \u00a0  of issues around the use of XPATH.\u00a0 This document obsoletes [ RFC8049 ] \u00a0  by creating a new module with the same name that is not backward \u00a0  compatible (in the sense described in YANG 1.1 [ RFC7950 ]).\u00a0 The \u00a0  changes (listed in full in Section 1.4) are small in scope, but \u00a0  include fixes to the module to make it possible to implement. As the text above says, the model in this document is not compliant with what  rfc7950  (The YANG 1.1 Data Modeling Language) specifies in Section 11 (Updating a Module), which starts by saying: \u00a0  As experience is gained with a module, it may be desirable to revise \u00a0  that module.\u00a0 However, changes to published modules are not allowed \u00a0  if they have any potential to cause interoperability problems between \u00a0  a client using an original specification and a server using an \u00a0  updated specification. It seems clear that experience after the original module ( rfc8049 ) was published has lead to the conclusion that an implementation is impossible \u2014 as this fact was not discovered before publication.\u00a0 I believe that the possibility of implementation (or not) of the module in  rfc8049  is irrelevant as the specification in  rfc7950  talks about updates without any qualification.  The solution seems straight forward to me: follow  rfc7950 , either by changing the module name, or by keeping the name and following the specification on how to update a module. I am concerned that the discussions related to the RtgDir review [1] in the netmod [2][3] and ietf@ietf [4] lists have not yet resulted in an updated draft which complies with  rfc7950 .\u00a0 Even if any relevant WGs (this document is AD-sponsored) or the ietf@ietf list reached consensus on moving forward with the document as is, it would still not be following what a Standards Track document specifies ( rfc7950 , in this case).\u00a0 IOW, documents that don\u2019t conform to what is clearly specified in a Standards Track, community consensus RFC, should not be approved for publication (without the proper Updates to that RFC, of course). I am then Balloting DISCUSS for the authors to update the document according to the module update specification in  rfc7950 , or for the discussions on the lists to reach (a different) consensus [*] and then consider the next steps. [1]  https://datatracker.ietf.org/doc/review-wu-l3sm-rfc8049bis-07-rtgdir-lc-berger-2017-10-16/ [2]  https://mailarchive.ietf.org/arch/msg/netmod/-VC7QhHzTyY0P8sL1m4QRg20cv8/?qid=373bf84b373edd7be9e51621c294189a [3]  https://mailarchive.ietf.org/arch/msg/netmod/xDIT_6R0cw_UT97scDYPArTbCYU/?qid=373bf84b373edd7be9e51621c294189a [4]  https://mailarchive.ietf.org/arch/msg/ietf/f4xmJk651EYzIlGi2bgDxAWQkWU/?qid=9c0f779d3f35b9787d796586750fcf36 [*] I know that the conversation on versioning is still ongoing.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-11-29 11:26:24-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-11-29 11:25:39-08:00",
    "text": "[Given that this document is returning to the IESG, I\u2019m updating my DISCUSS (after IETF 100 and to (hopefully) clarify.] The basis of this DISCUSS is that this document defines a non-backwards-compatible update to the module in  rfc8049 , which is not in compliance with the YANG module update process specified in  rfc7950  (YANG 1.1). My interpretation of the discussions in the netmod WG (on the list and during the in-person meeting at IETF 100) is that the WG recognizes that this document presents a case to change the process \u2014 but so far it has only agreed on there being a problem, and not on any path forward [A].\u00a0 There is at least one proposal [B] on the table, but no clear and formal intention from the WG on whether that is in fact the solution, part of it, or anything else. It would be enough for me to clear this DISCUSS if the netmod WG reached (at least initial) consensus on a path forward.\u00a0 Other solutions require following  rfc7950 : either by changing the module name, or by keeping the name and following the specification on how to update a module. [I realize that the latter may not be possible.] It seems to me that tooling and implementation/deployment considerations around having the same module name are the leading reasons towards looking for alternate solutions and not complying with  rfc7950  in this case.\u00a0 Given the very few dependents on this module (just one!) [C], I think it could be palatable to everyone to change the module name and move on with the updated process separately. I am also holding this DISCUSS because I don\u2019t think it is a good precedent for the IESG to approve a document that doesn\u2019t follow a standard procedure \u2014 regardless of the reasons.\u00a0 I believe that if the IESG approves this document (without a proper Update to the procedures in  rfc7950 , or at least a WG-agreed plan to do so) then it will have to consider breaking (or at least bending) the rules for any other module \u2014 and even for any other document that doesn\u2019t want to comply with what is standardized already\u2026. Note that I\u2019m not suggesting that the IESG will have to break/bend the rules for everyone, but that it will have to at least consider other requests. In summary\u2026 To be clear, I believe YANG is an important technology for the IETF and the Internet and the last thing I want to do is stand in the way of getting more modules our faster.\u00a0 However, the process is in place for a reason and breaking it (without a viable alternative) is not the right way forward.\u00a0 This DISCUSS is clearly for the IESG to consider, as the authors seem to just be caught in the middle.\u00a0 Instead of making an example of this document, I strongly suggest that the name be changed so the document can be published without compromising the standards process \u2014 the update to the  rfc7950  process can then be considered separately. [A]  https://mailarchive.ietf.org/arch/msg/netmod/IOMNpqPqhGKxR1MEUB7tQmv3KiA/?qid=185ce790ada5150129831ec488ebad81 [B]  https://tools.ietf.org/html/draft-clacla-netmod-yang-model-update   [C]  https://www.yangcatalog.org/yang-search/impact_analysis.php?modules[]=ietf-l3vpn-svc@2017-10-11.yang&recurse=0&rfcs=1&show_subm=1&show_dir=both",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-12-07 08:39:29-08:00",
    "end_reason": "evaluation_closed",
    "start": "2017-11-29 11:26:24-08:00",
    "text": "[Given that this document is returning to the IESG, I\u2019m updating my DISCUSS (after IETF 100 and to (hopefully) clarify.] The basis of this DISCUSS is that this document defines a non-backwards-compatible update to the module in  rfc8049 , which is not in compliance with the YANG module update process specified in  rfc7950  (YANG 1.1). My interpretation of the discussions in the netmod WG (on the list and during the in-person meeting at IETF 100) is that the WG recognizes that this document presents a case to change the process \u2014 but so far it has only agreed on there being a problem, and not on any path forward [A].\u00a0 There is at least one proposal [B] on the table, but no clear and formal intention from the WG on whether that is in fact the solution, part of it, or anything else. It would be enough for me to clear this DISCUSS if the netmod WG reached (at least initial) consensus on a path forward.\u00a0 Other solutions require following  rfc7950 : either by changing the module name, or by keeping the name and following the specification on how to update a module. [I realize that the latter may not be possible.] It seems to me that tooling and implementation/deployment considerations around having the same module name are the leading reasons towards looking for alternate solutions and not complying with  rfc7950  in this case.\u00a0 Given the very few dependents on this module (just one!) [C], I think it could be palatable to everyone to change the module name and move on with the updated process separately. I am also holding this DISCUSS because I don\u2019t think it is a good precedent for the IESG to approve a document that doesn\u2019t follow a standard procedure \u2014 regardless of the reasons.\u00a0 I believe that if the IESG approves this document (without a proper Update to the procedures in  rfc7950 , or at least a WG-agreed plan to do so) then it will have to consider breaking (or at least bending) the rules for any other module \u2014 and even for any other document that doesn\u2019t want to comply with what is standardized already\u2026. Note that I\u2019m not suggesting that the IESG will have to break/bend the rules for everyone, but that it will have to at least consider other requests. In summary\u2026 To be clear, I believe YANG is an important technology for the IETF and the Internet and the last thing I want to do is stand in the way of getting more modules our faster.\u00a0 However, the process is in place for a reason and breaking it (without a viable alternative) is not the right way forward.\u00a0 This DISCUSS is clearly for the IESG to consider, as the authors seem to just be caught in the middle.\u00a0 Instead of making an example of this document, I strongly suggest that the name be changed so the document can be published without compromising the standards process \u2014 the update to the  rfc7950  process can then be considered separately. [A]  https://mailarchive.ietf.org/arch/msg/netmod/IOMNpqPqhGKxR1MEUB7tQmv3KiA/?qid=185ce790ada5150129831ec488ebad81 [B]  https://tools.ietf.org/html/draft-clacla-netmod-yang-model-update   [C]  https://www.yangcatalog.org/yang-search/impact_analysis.php?modules[]=ietf-l3vpn-svc@2017-10-11.yang&recurse=0&rfcs=1&show_subm=1&show_dir=both",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2017-12-05 06:51:09-08:00",
    "end_reason": "position_updated",
    "start": "2017-11-29 16:59:07-08:00",
    "text": "I agree with Alvaro's Discuss, I think it is a bad operational precedent for IETF to obsolete a published Yang RFC with a non-backward compatible update; reusing a module name and creating a new module (with the same name) that is not backward compatible. I don't think it is an acceptable guideline to rationalize that non-backward compatibility is ok as only a small interest group.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-10-23 18:46:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-23 18:45:45-07:00",
    "text": "* The usage of the term mask with reference to the \"mask\" leaf node in all the places in this document seems to be incorrect. There are two issues with this wrong usage. IPv4 subnet masks are 32 bits in length and cannot be represented with an uint8. IPv6 does not have the same concept of subnet masks as IPv4 at all. So, I think the easiest way to fix this would be to replace the instances of mask with \"prefix-length\" instead which can be represented with an uint8 and works for both IPv6 and IPv4 (CIDR). * There is an off-by-one error in the definition of the prefix lengths for IPv6 addresses. Currently this is defined as \u00a0 \u00a0  leaf mask { \u00a0 \u00a0 \u00a0 type uint8 { \u00a0 \u00a0 \u00a0 range \"0..127\"; \u00a0 \u00a0  } \u00a0  but prefix lengths of 128 bits are perfectly legal are common especially in DHCPv6 assigned addresses. So the range must be \"0..128\"",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-10-23 18:46:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-23 18:46:05-07:00",
    "text": "* The usage of the term mask with reference to the \"mask\" leaf node in all the places in this document seems to be incorrect. There are two issues with this wrong usage. IPv4 subnet masks are 32 bits in length and cannot be represented with an uint8. IPv6 does not have the same concept of subnet masks as IPv4 at all. So, I think the easiest way to fix this would be to replace the instances of mask with \"prefix-length\" instead which can be represented with an uint8 and works for both IPv6 and IPv4 (CIDR). * There is an off-by-one error in the definition of the prefix lengths for IPv6 addresses. Currently this is defined as \u00a0 \u00a0  leaf mask { \u00a0 \u00a0 \u00a0 type uint8 { \u00a0 \u00a0 \u00a0 range \"0..127\"; \u00a0 \u00a0 \u00a0 } \u00a0  but prefix lengths of 128 bits are perfectly legal are common especially in DHCPv6 assigned addresses. So the range must be \"0..128\"",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-10-30 08:01:52-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-23 18:46:47-07:00",
    "text": "* The usage of the term mask with reference to the \"mask\" leaf node in all the places in this document seems to be incorrect. There are two issues with this wrong usage. IPv4 subnet masks are 32 bits in length and cannot be represented with an uint8. IPv6 does not have the same concept of subnet masks as IPv4 at all. So, I think the easiest way to fix this would be to replace the instances of mask with \"prefix-length\" instead which can be represented with an uint8 and works for both IPv6 and IPv4 (CIDR). * There is an off-by-one error in the definition of the prefix lengths for IPv6 addresses. Currently this is defined as \u00a0 \u00a0  leaf mask { \u00a0 \u00a0 \u00a0 type uint8 { \u00a0 \u00a0 \u00a0 range \"0..127\"; \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 ... \u00a0  but prefix lengths of 128 bits are perfectly legal are common especially in DHCPv6 assigned addresses. So the range must be \"0..128\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-23 13:13:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 19:15:28-08:00",
    "text": "I think we need to discuss how this document refers to the level of security provided by the network, \"insecure network\"s or portions thereof, etc..\u00a0 In the normal  RFC 3552  threat model, we assume the entire network is under the control of an attacker.\u00a0 Any exception to that is going to be treated as a special case (usually only grudgingly so), e.g., if a portion of a network is under administrative control of a single entity and physically controlled as well, or if a network uses MAC-layer security technologies.\u00a0 I don't think this mindset is well-reflected in the current text. I agree with Mirja that we need more clarity on usable security contexts for interoperable implementation.\u00a0 My suggestion would be to define a security context that is usable for normal Internet hosts over the normal Internet (i.e., not a stressed network) to have as a baseline secure configuration, and customizations for other environments would be treated as deviations from that well-established baseline in terms of algorithms and security strength.\u00a0 I furthermore note that even after reading draft-ietf-dtn-bpsec-interop-sc  I do not have a clear picture of exactly which bytes are used as input to the various cryptographic algorithms and how the output is encoded.\u00a0 For example, is the block data contents of a target block always going to be a fixed-length bstr?\u00a0 Can the process of applying protection change whether the #6.24 tag is present? I understand the need to provide a defined processing order for message deprotection (and thus to avoid having the same operation applied to the same target), but I still don't have a clear picture of why we can't define things in such a way that allows (e.g.) nested signatures over the same content block.\u00a0 I understand the current mechanics where in the abstract model we only can protect a single block at a time (not a combination of blocks), so that blindly applying the current mechanics to an attempt at a nested signature would produce the problematic ambiguity of processing order, but I don't understand why it has to be that way.\u00a0 Relatedly, I think that the current formulation where the target list can be freely modified/split into separate BIB/BCBs by any waypoint will probably leave us open to some semantic attacks that drop some blocks but not others, when there is supposed to be semantic interdependence between those blocks. The diagram in Figure 2 seems to incorrectly indicate a degree of freedom in the number of results per target: if we are applying the same operation to all blocks in the target array, the operation should produce the same number of results for all target blocks, thus constraining 'K' to be equal to 'M'. Exclusion of most of the block parameters from confidentiality processing seems to be a critical flaw in the cryptographic hygeine; I think we should include the Block Type Code, Block Number, possibly Block Processing Control Flags, CRC Type and CRC Field (if present), and Block Data Length fields as \"additional data\" input to the AEAD to provide integrity protection, as well as use them as input to BIB calculation.\u00a0 Failing to include these parameters seems to leave us prone to \"slice and dice\" style attacks.\u00a0 Also, the description in Section 4 is unclear about whether the surrounding CBOR array encoding is excluded from AEAD iput (though it doesn't really seem like it would make sense to re-encode as a one-item CBOR array prior to applying message protection, the current text is worded such that one might think the array framing is not explicitly excluded). Section 9.1 gives an example of using a (presumed unprotected in the absence of any disclaimer) cryptographic key as a security context parameter; given that (per Section 3.6) the parameters are included in the wire-format abstract security block, and not subject to BCB protection, this is wholly insecure and cannot reasonably be used as an example.\u00a0 (At least draft-ietf-dtn-bpsec-interop-sc  had a bit of note about \"encoded or protected by the key management system\" to give this a veneer of respectability.) There's a couple places (noted in the COMMENT) where we claim some combination of things to be \"insecure\" without justification; in the noted instances this doesn't seem to be immediately obvious, so I think the justification is needed (or the claim should be removed). Section 7 includes a note that \"It is recommended that security operations only be applied to the blocks that absolutely need them.\u00a0 If a BPA were to apply security operations such as integrity or confidentiality to every block in the bundle, regardless of need, there could be downstream errors processing blocks whose contents must be inspected or changed at every hop along the path.\"\u00a0 While this statement, taken literally, is true, it also seems inconsistent with, e.g.,  BCP 188 , as well as the  RFC 3552  threat model, let alone the BPSec threat model of Section 8.\u00a0 I suggest phrasing that makes applying security operations the default behavior and requiring justification to diverge from that.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-10 11:38:48-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-11-30 15:08:20-08:00",
    "text": "- Is this meant to obsolete  RFC 6257 ? - Section 3.8 says \"BCB blocks MUST NOT have the 'block must be removed from bundle if \u00a0 \u00a0 \u00a0 it can't be processed' flag set.\" However, the notes for this section ask that \"designers carefully consider the effect\" of setting this flag. I presume the latter should have been deleted? - Sec 11.3 specifies an unsigned integer with certain meanings attached to negative values.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-10 11:38:55-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-10 11:38:48-08:00",
    "text": "hanks for addressing (and correcting) my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-02-03 03:17:07-08:00",
    "text": "Sec 1.2 says: \"A sample security \u00a0  context has been defined ([ I-D.ietf-dtn-bpsec-interop-sc ]) to support \u00a0  interoperability testing and serve as an exemplar for how security \u00a0  contexts should be defined for this specification.\" However I don't really understand how interoperability can be reached if there is not at least one security context that is mandatory to implement in this draft (especially as ietf-dtn-bpsec-interop-sc is expired for more than half a year already)...?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-06-23 12:31:00-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-21 07:38:52-07:00",
    "text": "** Section 5.\u00a0 There is seemingly conflicting guidance on the interpreting the E and L flag. Statement #1 \u00a0 \u00a0 \u00a0 When E flag is set to 0, the value of the L flag SHOULD be \u00a0 \u00a0 \u00a0 respected as selection criteria; Statement #2 \u00a0  When the L flag is set to 1 and the E flag is set to 0, then the PCE \u00a0  MUST consider the protection eligibility as a PROTECTION PREFERRED \u00a0  constraint. Statement #3 \u00a0  When L flag is set to 0 and E flag is set to 1, then the PCE MUST \u00a0  consider the protection eligibility as an UNPROTECTED MANDATORY \u00a0  constraint. -- The Statement #1 appears to be weaker (SHOULD) than Statement #2 and 3. -- What is the difference between \u201crespecting [something] in the selection criteria\u201d and \u201cconsider[ing] the protection eligibility\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-10-17 11:22:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-16 23:32:47-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ipsecme-mib-iptfs-06 CC @evyncke Thank you for the work put into this document (even if I am balloting a DISCUSS); Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Tero Kivinen for the shepherd's detailed write-up including the WG consensus *but* it lacks the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Inconsistent intended status & use of experimental code point This document is standard track, but the OID used in section 4.1 is 'experimental' and in section 4.2 `experimental 500` per  https://www.iana.org/assignments/smi-numbers/smi-numbers.xhtml . Please request IANA to assign an OID from the 1.3.6.1.2.1 tree.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-20 08:25:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-20 02:42:46-07:00",
    "text": "# GEN AD review of draft-ietf-ipsecme-mib-iptfs- CC @larseggert Thanks to Joel Halpern for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/5gau5fsdf6JutMgWnPRn9R_HVto ). ## Discuss ### Section 4.2, paragraph 28 ``` \u00a0 \u00a0 \u00a0 \u00a0  l2FixedRate OBJECT-TYPE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  SYNTAX\u00a0 \u00a0 \u00a0 CounterBasedGauge64 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  MAX-ACCESS\u00a0 read-only \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  STATUS\u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"TFS bit rate may be specified as a layer 2 wire rate.\u00a0 On \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  transmission, target bandwidth/bit rate in bps for iptfs \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  tunnel.\u00a0 This rate is the nominal timing for the fixed \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  size packet. If congestion control is enabled the rate \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  may be adjusted down (or up if unset).\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ::= { iptfsConfigTableEntry 5 } \u00a0 \u00a0 \u00a0 \u00a0  l3FixedRate OBJECT-TYPE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  SYNTAX\u00a0 \u00a0 \u00a0 CounterBasedGauge64 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  MAX-ACCESS\u00a0 read-only \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  STATUS\u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"TFS bit rate may be specified as a layer 3 packet rate. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  On Transmission, target bandwidth/bit rate in bps for \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  iptfs tunnel.\u00a0 This rate is the nominal timing for the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  fixed size packet. If congestion control is enabled the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  rate may be adjusted down (or up if unset).\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ::= { iptfsConfigTableEntry 6 } ``` I'm not sure what the intended meaning of the two \"or up if unset\" statements is. Even when congestion control is disabled (=unset), the given fixed rates will not be exceeded?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-10-20 08:47:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-19 06:06:21-07:00",
    "text": "Thanks for working on this specification. I am balloting a Discuss, so that we pick the correct default value of congestionControl object. - Section 4.2 says \u00a0 \u00a0 congestionControl OBJECT-TYPE \u00a0 \u00a0 \u00a0 \u00a0 SYNTAX\u00a0 \u00a0 \u00a0 TruthValue \u00a0 \u00a0 \u00a0 \u00a0 MAX-ACCESS\u00a0 read-only \u00a0 \u00a0 \u00a0 \u00a0 STATUS\u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 \u00a0 \u00a0 DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"When set to true, the default, this enables the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 congestion control on-the-wire exchange of data that is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 required by congestion control algorithms as defined by \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  RFC 5348 .\u00a0 When set to false, IP-TFS sends fixed-sized \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 packets over an IP-TFS tunnel at a constant rate.\" \u00a0 \u00a0 \u00a0 \u00a0 DEFVAL { false } \u00a0 \u00a0 \u00a0 \u00a0 ::= { iptfsConfigTableEntry 2 } \u00a0   \u00a0  While the description says the default value should be true, the DEFVAL mentions \"false\".",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-17 12:26:33-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-09 23:21:10-07:00",
    "text": "Two small points that will be trivial to address: \u2014 Section 4 \u2014 \u00a0  The existing flags are defined in section 4.2 [ RFC7854 ] and the \u00a0  remaining bits are reserved for future use.\u00a0 They SHOULD be \u00a0  transmitted as 0 and their values MUST be ignored on receipt. Why \u201cSHOULD\u201d?\u00a0 That\u2019s inconsistent with Section 4.2 of 7854, which says \u201cMUST\u201d.\u00a0 Failing to set the reserved bits to 0 will cause interoperability problems with future extensions. \u00a0  The following fields in the Per-Peer Header are redefined: You aren\u2019t redefining them completely, right?\u00a0 Don\u2019t you mean, \u201cWhen the O flag is set to 1, the following fields in the Per-Peer Header are redefined:\u201d ?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-15 10:04:53-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-08 15:40:36-07:00",
    "text": "The \"Peer Up message Information\" TLV type seems under-specified and under-motivated.\u00a0 (It is not mentioned in Abstract or Introduction.)\u00a0 Why does it need to be defined in this document, and what role is it expected to play?\u00a0 Who is the expected audience for it?\u00a0 Is it limited to the \"group name\"-like functionality described in Section 7.1?\u00a0 Why is cleartext appropriate, and are there any potential privacy considerations for any potential use cases?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-04-01 18:06:58-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-03 08:11:23-07:00",
    "text": "Despite the length of the list of numbered points, this document is actually in pretty good shape -- most of them just relate to clarifying/correcting how this document interacts with other documents rather than issues with the way this mechanism works. (1) Section 4 calmly asserts that \"[i]n the STIR ecosystem, CA certificates may be used to sign PASSporTs\", but I could not find this documented in RFCs 8224, 8225, or 8226.\u00a0 If it is already documented somewhere, please provide a reference; if it is a new property of the architecture being asserted by this specification, we should be more clear about it, as well as how it is not entirely consistent with cryptographic best practice (see COMMENT). (It is perhaps unfortunate that  RFC 8225  did not talk about (extended) key usage values suitable for signing PASSporTs, though it is probably not appropriate to start doing so in this document.) (2) We are introducing new entities that act as X.509 CAs with this mechanism.\u00a0 Do we need to mandate that they provide CRLs/OCSP/etc. for making revocation information available?\u00a0 (\"This is already covered by RFC XXXX\" is a fine answer, though it is probably worth a reminder in the text.) (3) I think we are missing some exposition about how an SPC TNAuthList value is treated as \"encompassing\" specific telephone numbers/ranges controlled by the provider to which that SPC is assigned (more than just a mention in passing that the CA has to have access to the industry database), such that the CA cert might have the SPC form of TNAuthList but the child certificate a different form.\u00a0 I was also looking for some discussion of the related risk of skew if the database changes, but perhaps  https://tools.ietf.org/html/rfc8226#section-10  is enough to cover that.\u00a0 (It would be nice to have some data on the relative lifetime of database mappings and certificate lifetimes, though.) (4) We seem to have an internal inconsistency about whether alternative certification paths are allowed -- Section 6 implies that it is a very rigid procedure (and Section 7 requires AuthorityKeyIdentifier/SubjectKeyIdentifier matching), but Section 8.2 suggests the use of cross-signing and AIA for an alternate chain construction. (5) Section 9 contains a false statement that TLS subcerts has ways for the issuer of a (TLS) delegated credential to revoke that credential. https://tools.ietf.org/html/draft-ietf-tls-subcerts-09#section-7.3  is quite clear that expiration is the only mechanism to invalidate the delegated credential, with the risk of stolen/leaked delegated credentials limited by their short-lived nature. (6) Section 4.1 seems to waver on where the \"encompassing\" check is performed, leaving open the possibility that it is not performed at all. I think we need to be very explicit about what is required, not just what might be done or what is desirable.\u00a0 This might end up needing to be passing the buck (\"the authority for the deployment in question will specify which entity performs this validation\"), but at present it seems like there's a gap that needs to be filled in some manner. (7) Section 8.1 has what I think is a stale statement about ACME, relating to suitability of the certificate URL for use as \"x5u\" --  RFC 8555  only requres POST-AS-GET access, not the GET access that we imply. (See COMMENT for additional related points.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-21 10:22:06-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-24 20:42:38-07:00",
    "text": "Thanks for having the discussion with John and updating the document already; I benefitted a lot from being able to read the -11 that has started rolling in fixes from the prior discussion.\u00a0 My one new discuss point is relatively minor, all things considered, and is really just trying to nail down an aspect of internal consistency.\u00a0 (I also support Roman's disuss, but we don't need to rehash that here.) When we introduce the concept of gateways, we say that they can be attached to the Internet or a backbone network.\u00a0 We then go on to provide a mechanism for gateways to advertise to some tunnel ingress node the complete set of gateways for a given site.\u00a0 It seems that we do fairly consistently refer to this advertisement as being over \"the backbone network\", but I'm not seeing anything that clearly disclaims the applicability of this technique over the Internet itself.\u00a0 However, I think we need to have such a disclaimer, since we do have a clearly stated assumption that \"the connected set of DCs *and the backbone network connecting them* are part of the same SR BGP Link State (LS) instance ([ RFC7752 ] and [ I-D.ietf-idr-bgpls-segment-routing-epe ])\" (emphasis mine).\u00a0 If the intent is to only use this mechanism over \"in-BGP-LS-instance\" backbones and not over the Internet, we should explicitly set the scope of applicability and contrast a gateway as a generic concept and the gateway scenarios that this mechanism applies to.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-05-13 14:40:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-13 14:38:18-07:00",
    "text": "I have several points I\u2019d like to discuss, listed below from most general to most specific. 1. There\u2019s surprisingly little in this document that seems to be SR-specific (and what there is, has some problems, see below). Is there some reason you rule out interconnecting domains using other tunneling technologies? I ask this question first because if the answer were to be \u201coh huh, we don\u2019t need to make this SR-specific after all\u201d some of the other things I\u2019m asking about might go away. 2. There\u2019s no discussion about what trust model you\u2019re assuming. SR brings with it its own assumed trust model, laid out in  RFC 8402  as \u201cSR operates within a trusted domain\u201d (whatever *that* means). On the one hand, given you\u2019re tying yourself to SR you presumably are tied to its trust model. On the other hand, there are some tantalizing tidbits that suggest otherwise. I would be happier if there were some explicit description of the trust model you\u2019re presuming. It\u2019s hard to evaluate some aspects of the document without knowing if you\u2019re assuming the  RFC 8402  closed domain model, or something else. 3. The use of the term \u201cSR domain\u201d in this document appears inconsistent with its definition in  RFC 8402 . Here\u2019s that definition, from \u00a72: \u00a0  Segment Routing domain (SR domain): the set of nodes participating in \u00a0  the source-based routing model.\u00a0 These nodes may be connected to the \u00a0  same physical infrastructure (e.g., a Service Provider's network). \u00a0  They may as well be remotely connected to each other (e.g., an \u00a0  enterprise VPN or an overlay).\u00a0 If multiple protocol instances are \u00a0  deployed, the SR domain most commonly includes all of the protocol \u00a0  instances in a network.\u00a0 However, some deployments may wish to \u00a0  subdivide the network into multiple SR domains, each of which \u00a0  includes one or more protocol instances.\u00a0 It is expected that all \u00a0  nodes in an SR domain are managed by the same administrative entity. And notably, later in 8402 \u00a78 we are told that \u00a0  By default, SR operates within a trusted domain.\u00a0 Traffic MUST be \u00a0  filtered at the domain boundaries. Which specifically means, to take the MPLS instantiation of SR (\u00a78.1): \u00a0  SR domain boundary routers MUST filter any external traffic destined \u00a0  to a label associated with a segment within the trusted domain.\u00a0 This \u00a0  includes labels within the SRGB of the trusted domain, labels within \u00a0  the SRLB of the specific boundary router, and labels outside either \u00a0  of these blocks.\u00a0 External traffic is any traffic received from an \u00a0  interface connected to a node outside the domain of trust. More simply put, 8402 says you can\u2019t send an SR packet from outside an SR domain, into that domain. But your document is written in terms of a multiplicity of SR domains, for example this in Section 1: \u00a0  Tunnel Encapsulation attribute.\u00a0 The gateway in the ingress SR domain \u00a0  can now see all possible paths to X in the egress SR domain Maybe a quick fix, assuming you really do subscribe to the  RFC 8402  trust model, is to invent, define, and use the term \u201cSR subdomain\u201d and deem all the subdomains to be one SR domain, in the sense of  RFC 8402  \u00a72 \u2014 \u201cThey may as well be remotely connected to each other (e.g., an enterprise VPN or an overlay)\u201d seems to describe your situation pretty well.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-06-01 12:05:05-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-13 14:40:20-07:00",
    "text": "I have several points I\u2019d like to discuss, listed below from most general to most specific. 1. There\u2019s surprisingly little in this document that seems to be SR-specific (and what there is, has some problems, see below). Is there some reason you rule out interconnecting domains using other tunneling technologies? I ask this question first because if the answer were to be \u201coh huh, we don\u2019t need to make this SR-specific after all\u201d some of the other things I\u2019m asking about might go away. 2. There\u2019s no discussion about what trust model you\u2019re assuming. SR brings with it its own assumed trust model, laid out in  RFC 8402  as \u201cSR operates within a trusted domain\u201d (whatever *that* means). On the one hand, given you\u2019re tying yourself to SR you presumably are tied to its trust model. On the other hand, there are some tantalizing tidbits that suggest otherwise. I would be happier if there were some explicit description of the trust model you\u2019re presuming. It\u2019s hard to evaluate some aspects of the document without knowing if you\u2019re assuming the  RFC 8402  closed domain model, or something else. 3. The use of the term \u201cSR domain\u201d in this document appears inconsistent with its definition in  RFC 8402 . Here\u2019s that definition, from \u00a72: \u00a0  Segment Routing domain (SR domain): the set of nodes participating in \u00a0  the source-based routing model.\u00a0 These nodes may be connected to the \u00a0  same physical infrastructure (e.g., a Service Provider's network). \u00a0  They may as well be remotely connected to each other (e.g., an \u00a0  enterprise VPN or an overlay).\u00a0 If multiple protocol instances are \u00a0  deployed, the SR domain most commonly includes all of the protocol \u00a0  instances in a network.\u00a0 However, some deployments may wish to \u00a0  subdivide the network into multiple SR domains, each of which \u00a0  includes one or more protocol instances.\u00a0 It is expected that all \u00a0  nodes in an SR domain are managed by the same administrative entity. And notably, later in 8402 \u00a78 we are told that \u00a0  By default, SR operates within a trusted domain.\u00a0 Traffic MUST be \u00a0  filtered at the domain boundaries. Which specifically means, to take the MPLS instantiation of SR (\u00a78.1): \u00a0  SR domain boundary routers MUST filter any external traffic destined \u00a0  to a label associated with a segment within the trusted domain.\u00a0 This \u00a0  includes labels within the SRGB of the trusted domain, labels within \u00a0  the SRLB of the specific boundary router, and labels outside either \u00a0  of these blocks.\u00a0 External traffic is any traffic received from an \u00a0  interface connected to a node outside the domain of trust. More simply put, 8402 says you can\u2019t send an SR packet from outside an SR domain, into that domain. But your document is written in terms of a multiplicity of SR domains, for example this in Section 1: \u00a0  Tunnel Encapsulation attribute.\u00a0 The gateway in the ingress SR domain \u00a0  can now see all possible paths to X in the egress SR domain Maybe a quick fix, assuming you really do subscribe to the  RFC 8402  trust model, is to invent, define, and use the term \u201cSR subdomain\u201d and deem all the subdomains to comprise one SR domain, in the sense of  RFC 8402  \u00a72 \u2014 \u201cThey may as well be remotely connected to each other (e.g., an enterprise VPN or an overlay)\u201d seems to describe your situation pretty well.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-06-11 08:03:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 13:02:41-07:00",
    "text": "RFC8402  tells us: (a)\u201cSegment Routing domain (SR domain): the set of nodes participating in the source-based routing model \u2026\u00a0  (a.1) \u201cThese nodes may be connected to the same physical infrastructure (e.g., a Service Provider's network).\u201d (a.2) \u201cThey may as well be remotely connected to each other (e.g., an\u00a0 enterprise VPN or an overlay).\u201d (b) \u201cBy default, SR operates within a trusted domain.\u00a0 Traffic MUST be filtered at the domain boundaries.\u201d My understanding of this document is that it is an enabling capability to help establish SR domains of the like described in (a.2).\u00a0 What I see missing is text that provides the confidence suggested by the language of \u201ctrusted domain\u201d in (b). -- Section 1 hints at various VPN technologies perhaps being used\u00a0 \u201cThe various ASes that provide connectivity between the Ingress and Egress\u00a0  Domains could each be constructed differently and use different technologies such as IP, MPLS with global table routing native BGP to the edge, MPLS IP VPN, SR-MPLS IP VPN, or SRv6 IP VPN.\u201d\u00a0 However, the security properties of all of those aren\u2019t clear to a degree that would seem consistent with being a \u201ctrusted domain\u201d.\u00a0 For example, saying \u201cIP\u201d might suggest that naked IP packets with SR headers (with no additional security primitives) could be dropped onto the open Internet, or at least through networks not under the control the \u201cdata centers\u201d use case suggested by the name of the document.\u00a0  -- The discussion at  https://mailarchive.ietf.org/arch/msg/bess/zY783PgnXSCp6GNSRF4kY0diLYs/  around the forwarding plane trust model is also informative.\u00a0  It is noted that that the \u201ctransit nodes of the AS are not part of the domain.\u201d\u00a0 I could agree, but only to the degree that the SR packets are tunneled in such as way that suggested a trusted domain at least of equal security as (a.1). I think language is needed to describe the normative security requirements of the tunnels that will be created on top of the routes enables by this work to substantiate the claim that at a \u201ctrusted domain\u201d is being maintained.\u00a0 This has some overlap with John\u2019s text about clarify the proposed trust model.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-05-18 17:03:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-18 17:02:59-07:00",
    "text": "I hope that I'm just misunderstanding something obvious, but I strongly support John's DISCUSS -- when SR was \"approved\" it was with the understanding that it would only be used within \"real\" limited domains, and would never be sent outside of closed/limited network. The document says: \"The solution defined in this document can be seen in the broader context of SR domain interconnection in [ I-D.farrel-spring-sr-domain-interconnect ]. \", which says: \" Traffic originating in one SR domain often terminates in another SR domain, but must transit a backbone network that provides interconnection between those domains.\" -- is it unclear to me if this is really what is being proposed...",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-05-27 07:57:51-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 17:03:26-07:00",
    "text": "I hope that I'm just misunderstanding something obvious, but I strongly support John's DISCUSS -- when SR was \"approved\" it was with the understanding that it would only be used within \"real\" limited domains, and would never be sent outside of closed/limited network. The document says: \"The solution defined in this document can be seen in the broader context of SR domain interconnection in [ I-D.farrel-spring-sr-domain-interconnect ]. \", which says: \" Traffic originating in one SR domain often terminates in another SR domain, but must transit a backbone network that provides interconnection between those domains.\" -- is it unclear to me if this is really what is being proposed... I'm hoping that I'm really misunderstanding something here -- please educate me.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-01-24 07:12:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-01-24 07:11:42-08:00",
    "text": "Thanks for a clearly written document. I agree with the tsv-review (Thanks David!) that the minimum time between two messages incl. triggered PFM messages should be specified as well. Also thanks for the quick reply, Stig! I will hold this discuss until this point has been fully resolved, however, I'm certain we can resolve it quickly!",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-02-01 05:54:19-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-24 07:12:04-08:00",
    "text": "Thanks for a clearly written document. I agree with the tsv-art review (Thanks David!) that the minimum time between two messages incl. triggered PFM messages should be specified as well. Also thanks for the quick reply, Stig! I will hold this discuss until this point has been fully resolved, however, I'm certain we can resolve it quickly!",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-01-11 06:41:16-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-01-11 06:40:24-08:00",
    "text": "Sorry for the late input, but based on the additional TSV review provided by Martin Stiemerling (Thanks!), I got convenience I would like to discuss the TCP related part of this document further before publication (even though this is \"only\" information doc). I agree with the TSV review that the solution approaches discussed in 7.1 and 7.2 are slightly speculative and should therefore probably not be published in an RFC without further discussions in respective other groups of the IETF. Per-packet/flowlet path switching (7.1) will have an impact on the TCP machinery and should be further discussed in a tsv group before it would be presented as a solution approach in an RFC. Performance-aware routing (7.2) is actually a hard problem as congestion state is changing very dynamically and an attempt to utilize this information on a different time-scale than TCP does can lead to unwanted interfere and interdependencies. We currently have a proposed research group (PANRG) for this sort of problems, and this group would probably a better place for discussing these problems and proposed solutions (instead of an RFC-to-be). The easiest way to address my concerns is probably to removed TCP-related paragraph from section 3 as well as remove section 7.1 and 7.2 entirely and follow on those discussions in tsv area/tcpm and panrg instead.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-11-30 00:05:11-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-11 06:41:16-08:00",
    "text": "Sorry for the late input, but based on the additional TSV review provided by Martin Stiemerling (Thanks!), I got convenienced that I would like to discuss the TCP related parts of this document further before publication (even though this is \"only\" an informational doc). I agree with the TSV review that the solution approaches discussed in 7.1 and 7.2 are slightly speculative and should therefore probably not be published in an RFC without further discussions in respective other groups of the IETF. Per-packet/flowlet path switching (7.1) will have an impact on the TCP machinery and should be further discussed in a tsv group before it would be presented as a solution approach in an RFC. Performance-aware routing (7.2) is actually a hard problem as congestion state is changing very dynamically and an attempt to utilize this information on a different time-scale than TCP does can lead to unwanted interfere and interdependencies. We currently have a proposed research group (PANRG) for this sort of problems, and this group would probably a better place for discussing these problems and proposed solutions (instead of an RFC-to-be). The easiest way to address my concerns is probably to removed TCP-related paragraph from section 3 as well as remove section 7.1 and 7.2 entirely and follow on those discussions in tsv area/tcpm and panrg instead.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-27 19:15:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 20:53:50-08:00",
    "text": "Let's discuss whether it's appropriate to include vendor-specific functionality (e.g., linux NETKEY/XFRM marking) in a standards-track protocol/model. The ASN.1 GeneralName type is an abstract type; in order to represent it in a string we must have some discussion of how it is encoded.\u00a0 (A similar concern might apply to the other ASN.1 types used, such as DistinguishedName, though the latter does have a fairly well-established string presentation form, so the concern is of lesser magnitude there. That said,  RFC 5280  is not a suitable reference for the DistinguishedName string presentation form.) In a similar vein, the 'id-key' identity representation is listed as type 'string' but the description lists it as an \"opaque octet string\". YANG strings are not directly suitable for holding binary content (which is what an opaque octet string is), so either a scheme for encoding arbitrary binary content as a string is needed, the YANG 'binary' type should be used, or this node needs to be documented as only allowing valid Unicode (IIUC, in UTF-8 encoding, though https://tools.ietf.org/html/rfc6020#section-9.4  is not as clear about this as I would like). The two 'anti-replay-window' leafs are (1) using different-width types, and (2) do not have enough of a description to indicate what content they hold, especially whe combined with a default value of 32. (I mention both locations in the COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-24 13:52:04-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-01 23:35:22-08:00",
    "text": " general ] * Similar to df-bit and ecn, should there be a tunnel-grouping leaf that \u00a0 controls how inner DSCP marking should be reflected on the outer IPsec \u00a0 header? ( RFC 2983  suggests using multiple tunnels instead and warns about \u00a0 the danger of packet reordering as a result of variable DSCP marking (as \u00a0 well as the potential information leak as a security issue), so maybe this \u00a0 isn't important. \u00a0 Separately, what about a setting to explicitly configure the DSCP mark on \u00a0 the outer header for all encap'd packets? [ appendix A ] * I'm unclear on what bypass-dscp=true means.\u00a0 Does it mean that the DSCP \u00a0 value is *not* part of the traffic selector? \u00a0 Should this instead be called \"ignore-dscp\" or \"skip-dscp\"? * Related: does the dscp-mapping leaf only have significance if bypass-dscp \u00a0 is false?\u00a0 If so, is there some \"must ../bypass-dscp ...\" syntax that would \u00a0 be applicable?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-02-19 08:11:06-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 06:55:21-08:00",
    "text": "\u00a0 \u00a0 \u00a0 \u00a0 leaf ecn { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type boolean; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 default false; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Explicit Congestion Notification (ECN). If true \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 copy CE bits to inner header.\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Section 5.1.2 and Appendix C in  RFC 4301 .\"; \u00a0 \u00a0 \u00a0 \u00a0 } There is something wrong here, likely in the description of the option. This as the outer IP header on sender side needs to set ECN field to ECT to enable so that any CE marks can be received. I think it is reasonable to have an option to just enable ECN, but that requires several things. Secondly with the changes in  RFC 8311 , there might be need to be more explicit in the configuration of ECN to actually indicate which ECT value that should be set on send side for the established IPsec tunnel. Due to under discussion experiments with ECT values per  RFC 8311  we should verify that just copying the inner header value to the external is fine and don't break anything as path and/or marking behavior may not be the same.  I think there is also the question if  RFC 6040  needs to be referenced in this context to ensure that people pick up on that  RFC 6040  updates  RFC 4301 .",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-22 07:45:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-10 02:02:59-08:00",
    "text": "Updating my ballot after reviewing draft-ietf-ace-aif-06. Just want to make sure we don't miss anything, please feel free to correct me if I missed the mark here. FP:  https://datatracker.ietf.org/doc/html/draft-ietf-ace-aif-06#section-4  states: default values are the values \"URI-local- \u00a0  part\" for Toid and \"REST-method-set\" for Tperm, as per Section 3 of \u00a0  the present specification. \u00a0  A specification that wants to use Generic AIF with different Toid \u00a0  and/or Tperm is expected to request these as media type parameters \u00a0  (Section 5.2) and register a corresponding Content-Format \u00a0  (Section 5.3). FP: I wonder if this document should define a new media type parameter for Tperm (as REST-method-set is not appropriate for \"pub\"/\"sub\" value) and register a corresponding Content-Format as indicated in the paragraph above. CC'ing Carsten for his opinion.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-03-22 05:18:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 22:34:50-08:00",
    "text": "This should be quick to resolve.\u00a0 In Section 3.2: \u00a0  The Broker MUST NOT forward messages to unauthorized subscribers. \u00a0  There is no way to inform the Clients with invalid tokens that an \u00a0  authorization error has occurred other than sending a DISCONNECT \u00a0  packet.\u00a0 Therefore, the Broker SHOULD send a DISCONNECT packet with \u00a0  the reason code '0x87 (Not authorized)'. This seems like a contradiction.\u00a0 How is that SHOULD not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-02-02 15:31:36-08:00",
    "end_reason": "position_updated",
    "start": "2015-09-14 14:10:12-07:00",
    "text": "I have some questions about this draft. They derive from the position that some of the values in the options specified can reveal sensitive information about the mobile user. I would put access network name (especially when it's SSID, since people put identifying information in SSIDs), access point name, and BSSID in that category at a minimum. The draft specifies DHCP options for downstream use in PMIPv6 scenarios, but makes no mention about actually limiting the use of these options to those scenarios. It's not clear to me whether those limits could be achieved in any case, since an AP won't know a priori whether it is being deployed in a service-provider-WiFi or cellular context or not. So what is the authors' expectation about the breadth of deployment of these options? Every DHCP stack? Something less than that? Furthermore, are any of the individual fields required or optional?  RFC 6757  indicates that within PMIPv6 only the ATT is required. Given the drawbacks discussed in Section 9, why was DHCP the protocol chosen for this? Is there no other protocol that APs speak to MAGs that has confidentiality, integrity protection, and authentication support? If DHCP is the only choice, why are none of the security fixes normatively required (\"confidentiality and integrity protection should be employed,\" \"DHCP server administrators are strongly advised to configure DHCP servers ... using IPsec,\" \"administrators have to consider disabling the capability specified\")? Why would an LMA need the MAC address of the AP? Are there examples of policies that mobile networks have in place that apply differently to two devices connected to the same SSID but different APs, for example? I looked for this in  RFC 6757  too but did not see it. Given the potential sensitivity of this field it seems like a justification for sharing it in an eavesdroppable way needs to be provided.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-02-02 12:59:38-08:00",
    "end_reason": "position_updated",
    "start": "2015-09-15 15:11:15-07:00",
    "text": "-- 4.3.2 The name of an 802.11 access point can imply the users location with a fair bit of precision, making it effectively count as location data. The draft needs\u00a0 more discussion of the privacy implications of that.  -- 6:  This section seems underspecified. There seems to be a missing discussion about interdependencies among options. For example, For example, network name is meaningless without the technology type. What is the minimum needed to be coherent?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-01-15 17:33:10-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-17 03:44:36-07:00",
    "text": "I would like to discuss the following point. You define the \"Vendor ID\" and then the Operator Enterprise ID. Why don't you reuse the  RFC 6757  Operator-Identifier? Operator-Identifier \u00a0 \u00a0 \u00a0 The Operator-Identifier is the Structure of Management Information \u00a0 \u00a0 \u00a0 (SMI) Network Management Private Enterprise Code of the IANA- \u00a0 \u00a0 \u00a0 maintained \"Private Enterprise Numbers\" registry [SMI].\u00a0 It \u00a0 \u00a0 \u00a0 identifies the operator running the network attached to a specific \u00a0 \u00a0 \u00a0 interface of the mobile access gateway.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-02-02 01:24:02-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-15 17:33:10-08:00",
    "text": "MY PREVIOUS DISCUSS: I would like to discuss the following point. You define the \"Vendor ID\" and then the Operator Enterprise ID. Why don't you reuse the  RFC 6757  Operator-Identifier? Operator-Identifier \u00a0 \u00a0 \u00a0 The Operator-Identifier is the Structure of Management Information \u00a0 \u00a0 \u00a0 (SMI) Network Management Private Enterprise Code of the IANA- \u00a0 \u00a0 \u00a0 maintained \"Private Enterprise Numbers\" registry [SMI].\u00a0 It \u00a0 \u00a0 \u00a0 identifies the operator running the network attached to a specific \u00a0 \u00a0 \u00a0 interface of the mobile access gateway. MY NEW DISCUSS: I see that you have now used the Operator-Identier. Good. However, it's not fully inline with the  RFC 6757  definition. Why? Why not refer to the  RFC 6757  definition, and include it here for the convenience of the readers. Also, what is the Enterprise ID\u00a0 (two instances of this)? \u00a0 Operator Enterprise ID \u00a0 \u00a0 \u00a0 The operator's Enterprise ID (as described in Section 3) is \u00a0 \u00a0 \u00a0 Private Enterprise Number (PEN)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-10 13:57:39-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-15 09:14:16-07:00",
    "text": "(1) Did the DHC working group consider how this information, when sent without adequate protection between relay and dhcp server, could help in pervasive monitoring? If so, what was the conclusion reached? We have seen http header field information sent between infrastructure nodes being intercepted for that purpose, so this has to be similarly at risk.\u00a0 If the answer is that this is only to be used within a single network operator's setup (or a roaming arrangement) then that needs to be justified (as practical) and, if it can be justified (I'm not sure tbh), also made explicit.  (2) I had a DISCUSS on the draft that became  rfc 6757  about protection of this kind of data. In that context I think I was assured that everything (in PMIPv6) was IPsec protected so it was fine.\u00a0 Why, in what we now know is a more threated environment, is it ok to now have weaker protection when I was assured then that IPsec was in fact quite usable in PMIPv6? I think you maybe need to put in a MUST use IPsec requirement for this to be as safe.  (3) section 7: MAY store - this is possibly sensitive information so you ought say that it SHOULD NOT be stored unless needed, and if stored, SHOULD be deleted as soon as possible. Storing sensitive information when not needed just shouldn't be considered acceptable anymore I think - is that reasonable?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-02-08 04:11:33-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-01-10 13:57:39-08:00",
    "text": "(Sent mail 2016-01-10, checking on change vs. discuss) (1) Did the DHC working group consider how this information, when sent without adequate protection between relay and dhcp server, could help in pervasive monitoring? If so, what was the conclusion reached? We have seen http header field information sent between infrastructure nodes being intercepted for that purpose, so this has to be similarly at risk.\u00a0 If the answer is that this is only to be used within a single network operator's setup (or a roaming arrangement) then that needs to be justified (as practical) and, if it can be justified (I'm not sure tbh), also made explicit.  (2) I had a DISCUSS on the draft that became  rfc 6757  about protection of this kind of data. In that context I think I was assured that everything (in PMIPv6) was IPsec protected so it was fine.\u00a0 Why, in what we now know is a more threated environment, is it ok to now have weaker protection when I was assured then that IPsec was in fact quite usable in PMIPv6? I think you maybe need to put in a MUST use IPsec requirement for this to be as safe.  (3) section 7: MAY store - this is possibly sensitive information so you ought say that it SHOULD NOT be stored unless needed, and if stored, SHOULD be deleted as soon as possible. Storing sensitive information when not needed just shouldn't be considered acceptable anymore I think - is that reasonable?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-02-08 14:41:53-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-08 04:11:33-08:00",
    "text": "Thanks for the changes made in response to my and, in particular, Alissa's discuss ballots. Having looked back at the email thread I don't believe I got any  answer to the question \"Did the DHC working group consider how  this information, when sent without adequate protection between  relay and dhcp server, could help in pervasive monitoring?\" I think the focus of the discussion has been on the applicability of  this being limited to \"typically\" one operator's network, which  does of course mean that the traffic is less at risk than had it  transited many networks. However, we have seen (Belgacom) that  the PM threat also applies within a single operator's network. So I am still interested in the answer to the above question. The DHC WG might consider this threat and still conclude that a SHOULD statement about IPsec is the best we can do in practice,  but that isn't clear to me at present, so I'd still like to chat about  the PM threat. (Note: it's the WG's consideration of the threat  I'd like to chat about, not only about the potential of IPsec to  mitigate that threat.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-25 15:09:27-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-02 22:14:52-07:00",
    "text": "I have two points for discussion: (1) If this document was subject to the approval requirements for standards action, it would basically be suffering from \"death by abstain\"; this seems like a good signal for the IESG to discuss whether it makes sense to approve this document even though the more-lenient document-action requirements would otherwise let it go forward. (2) The document seems incomplete to me.\u00a0 It has some aspects of being all/any of a use-cases document, an architecture document, and an applicability analysis, but does not seem to have a complete treatment for any of them.\u00a0 To be clear, there is enough in the document to indicate that the topic merits further work, and there are some interesting results, but I'm not sure that publication as an RFC is appropriate for this document in this form.\u00a0 Specifically: (2a) use-cases: we see the examples of star topology with BRAS/SR and the simulated network in Figure 6, but there is not much discussion of where these (or similar) scenarios arise in practice, how common they are, and how closely the simulation reflects actual usage. (2b) architecture: a very high-level picture is given (\"use a PCE to engineer some of the IP traffic on a network and improve overall efficiency\"), but we don't see much about how PCCs will be involved and apply the computed paths or what requirements will need to be met by the protocols and components used to instantiate the architecture (2c) applicability: we see some scenarios where the proposed technology shows drastic improvement over the alternative selected for comparison, but there is little to give confidence that this reflects a broad maxima that is robust to environmental variations.\u00a0 Is the alternative selected for comparison an appropriate one for the cases in question?\u00a0 How would the propsal react in the face of changes in the environment it runs in, such as link or node failure, changes in the baseline usage, or traffic spikes?\u00a0 What timescale can it react in and what level of visibility does the PCE need into current conditions in order to be reliable?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-10-03 07:30:02-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-03 02:42:46-07:00",
    "text": "I also think IESG and the WG really should have a discussion if this document should be published at all. In addition to the points raised by Benjamin I want to add my view to this.  The document in its current form appear to be outside of TEAS Charter. This document is none of the several things TEAS is approved to work with. As Benjamin enumerates so well the document is also a very poor support or architecture document. Which is why I would argue that it fully outside of the TEAS charter as neither a main objective of the WG or a support document.  Even if fixed to be a better support document, I still think the WG should consider its charter and the IESG statement on support documents:  https://www.ietf.org/about/groups/iesg/statements/support-documents/  and ask themselves if that is really something that is worth publishing.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-08-14 06:45:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-13 19:06:30-07:00",
    "text": "I'd like to thank the author and all other involved parties for the work that has gone into making CoA transactions work across multiple domains. I have a couple of DISCUSS points that I think need to be cleared up. --------------------------------------------------------------------------- This is a concern with the general mechanism, and might be due to a misunderstanding on my part (which I hope you can clear up); but if I'm not wrong, then I'm concerned that the mechanism as described can introduce RADIUS message routing loops in some very common deployment scenarios. Consider a setup involving three networks: a Visited network (with its NAS and a Radius server), a Clearinghouse network (with one or more proxies), and a Home network (with a border proxy and a Home Server). Both the Home and Visited network also have federated networks that they communicate directly with without traversing the Clearinghouse network. The Clearinghouse determines the destination of any request message by looking at the realm portion of the NAI present in the \"User-Name\" attribute, which I believe is pretty common routing logic in these kinds of cases. Now, consider what happens when the Home network updates to use this mechanism (in order to better work with their federated partners), and the Visited network also updates to use this mechanism (for the same reason), but the Clearinghouse is not yet updated. I'll try to step through section 5 with this scenario: 1) The NAS in the Visited network sends an Access-Request packet to the \u00a0  Visited Radius server. The visited RADIUS server will see that the \u00a0  user is roaming, and will add an Operator-Name attribute, with value \u00a0  \"1\" followed by it's own realm name.\u00a0 e.g. \" 1example.com \". 2) The visited RADIUS server will then proxy the authentication request \u00a0  to the Clearinghouse network, which uses the NAI in the User-Name to forward \u00a0  it to the Home network. 3) The Home Server records the Operator-Name along with other information \u00a0  about the users session 4) When the Home Server determines that a user should be disconnected, \u00a0  it looks up the Operator-Name, along with other user session identifiers as \u00a0  described in [ RFC5176 ]. 5) The Home Server sends the Disconnect-Request to the Home domain's border \u00a0  proxy. 6) The Home domain's border proxy looks up the Operator-Name in the \u00a0  Disconnect-Request message, determines that it is an operator that it is \u00a0  not federated with, and consequently sends the Disconnect-Request to the \u00a0  Clearinghouse. 7) The Clearinghouse receives the Disconnect-Request message. Since it has not \u00a0  yet been updated to handle the Operator-Name attribute as described in this \u00a0  document, it follows its normal logic of routing according to the NAI in the \u00a0  User-Name attribute. 8) Go to 6 --------------------------------------------------------------------------- \u00a74.2: >\u00a0 The value SHOULD be cryptographically strong, and SHOULD be >\u00a0 verifiable by the Visited Network, without requiring it to track in a >\u00a0 database every individual value of Operator-NAS-identifier which was >\u00a0 issued. I don't think this is really phrased in a way that means what you want to say. If I had to guess, you mean to say that the value must be encrypted, and that it must be integrity-protected. If integrity protection is important, then you also need to consider techniques to avoid replay of previously-seen tokens (e.g., the integrity protection needs to be over not just the Operator-NAS-Identifier, but also over some portion of the session that prevents its replay). Most notably, this desire for encryption and integrity protection is almost certainly at odds with the assertion (in \u00a73.3) that \"A twenty octet string is more than sufficient to individually address all of the NASes on the planet.\" For example, the na\u00efve approach of appending a SHA-256 hash to the end of an encrypted, salted index into a table of NAS devices would require over 32 bytes at its absolute minimum. So, if integrity protection is something that any operator might ever want, you need to revisit the 20-byte limit. >\u00a0 Exactly how this requirement is implemented is outside of the scope >\u00a0 of this document. That's fair, but I think you need a proof-of-concept example of how it could be done, so that you find any additional corner cases beyond the one I've identified above. I think these aspects of this attribute need a lot more treatment in Section 6.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-11-15 14:35:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-14 06:45:49-07:00",
    "text": "Thanks for the quick response on the looping concern I thought might exist. The original text for my other concern appears below. \u00a74.2: >\u00a0 The value SHOULD be cryptographically strong, and SHOULD be >\u00a0 verifiable by the Visited Network, without requiring it to track in a >\u00a0 database every individual value of Operator-NAS-identifier which was >\u00a0 issued. I don't think this is really phrased in a way that means what you want to say. If I had to guess, you mean to say that the value must be encrypted, and that it must be integrity-protected. If integrity protection is important, then you also need to consider techniques to avoid replay of previously-seen tokens (e.g., the integrity protection needs to be over not just the Operator-NAS-Identifier, but also over some portion of the session that prevents its replay). Most notably, this desire for encryption and integrity protection is almost certainly at odds with the assertion (in \u00a73.3) that \"A twenty octet string is more than sufficient to individually address all of the NASes on the planet.\" For example, the na\u00efve approach of appending a SHA-256 hash to the end of an encrypted, salted index into a table of NAS devices would require over 32 bytes at its absolute minimum. So, if integrity protection is something that any operator might ever want, you need to revisit the 20-byte limit. >\u00a0 Exactly how this requirement is implemented is outside of the scope >\u00a0 of this document. That's fair, but I think you need a proof-of-concept example of how it could be done, so that you find any additional corner cases beyond the one I've identified above. I think these aspects of this attribute need a lot more treatment in Section 6.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-11-15 14:35:14-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-15 14:35:02-08:00",
    "text": "hanks for addressing my DISCUSS points.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-08-16 07:24:17-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-14 20:18:12-07:00",
    "text": "(This is a procedural DISCUSS. Hopefully it can be resolved easily, but I do think it needs to be resolved prior to publication..) This draft is standards track, yet it primarily serves to extend  RFC 5176 . That RFC is informational. The shepherd writeup argues that this is okay because it seems like 5176 should have been standards track. But the applicability statement  RFC 5176  explains why it was informational, and the reasons seem convincing. Therefore I do not think it is appropriate to publish this draft as Standards Track. I think it would be fine to progress it as Informational (or even Experimental) if it included an applicability statement explaining why in order to avoid the appearance of a standard masquerading as an Informational RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-31 06:06:15-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-22 06:58:47-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ipsecme-yang-iptfs-08 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (very easy to address ;-) ), some non-blocking COMMENT points (also very easy to fix), and some nits. Special thanks to Tero Kivinen for the shepherd's detailed write-up including the WG consensus even if there is no justification for the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section A.2 wrong prefix size ? ``` \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2001:DB8::0/16 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2001:DB8::1:0/16 ``` Beside the lack of  RFC 5952  (see my comment below), is it on purpose that both prefix with a /16 are identical ? The authors probably mean a different prefix size rather than /16.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-08-31 06:37:25-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 07:18:11-07:00",
    "text": "Hi Chris, Don, This YANG module and document looks good to me. The one discuss issue that I wanted to check on the commented out when statements, e.g.,  \u00a0 \u00a0 \u00a0 \u00a0  uses ipsec-tx-stat-grouping { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  //when \"direction = 'outbound'\"; \u00a0 \u00a0 \u00a0 \u00a0  } Are these when statement meant to just be descriptive?\u00a0 If so, then writing them in plain English is probably better.\u00a0 Or otherwise, can they just be removed from the module, or is there another plan?",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2016-05-04 09:14:33-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-02 15:26:22-07:00",
    "text": "I think that these are both simple fast issues to resolve. 1) Sec 3: \"This document defines only the UDP port value \u00a0  for the S-BFD Echo function.\u00a0 The source port and the procedures for \u00a0  the S-BFD Echo function are outside the scope of this document.\" Please add a reference to the S-BFD base document for defining where the procedures are found.  Where, precisely, is the source port defined?\u00a0 It wasn't in the S-BFD base document.\u00a0 This seems like a hole.\u00a0 Can you please clarify? 2) Sec 4:\u00a0 \" If the port is not 7784, then the packet MUST be looked up to locate \u00a0  a corresponding SBFDInitiator session or classical BFD session based \u00a0  on the value from the \"your discriminator\" field in the table \u00a0  describing BFD discriminators. \" I assume that you mean that UDP source port is used to look up the appropriate receiver. If that receiver handles BFD and S-BFD packets, then the \"your discriminator\" field is used to identify the BFD session.\u00a0  PLEASE clarify that because this reads as if BFD is the only application that uses UDP.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-05-03 20:00:26-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 14:00:28-07:00",
    "text": "Section 4, 2nd paragraph: \"\u00a0 If the port is not 7784, then the packet MUST be looked up to locate \u00a0  a corresponding SBFDInitiator session or classical BFD session based \u00a0  on the value from the \"your discriminator\" field in the table \u00a0  describing BFD discriminators.\u00a0 \" Do I understand correctly that whether or not the destination port is 7784 tells you if this is an \"initial\" packet vs a \"reflected\" packet? If the destination port is not 7784, how do you know it\u2019s not some competely different protocol? Do you assume the receiver has no other UDP based services?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-20 14:18:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-15 06:48:43-07:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-assert-packing-10 CC @jgscudder Thanks for this document, it seems likely to be useful and my DISCUSS notwithstanding, for the most part I found it easy to read and understand.  ## DISCUSS I am ballotting DISCUSS because although I found the casual, expository style of Section 3.1.1 to be enjoyable to read as a tutorial, I'm concerned that it may not be as well-suited when being used as a reference specification for producing an implementation. And of course, that is the primary purpose of a Standards Track document. Most concerning is the mixture of actual requirements language, with language that's only exemplary -- I found it impossible to determine exactly what parts I have to strictly follow in order to produce a compliant implementation. Rather than call out any particular issue here, I refer to the comments section for my various specific points about Section 3.3.1. Let's discuss those, make any changes you agree to, or you can make the case that it's fine as it stands. That is to say, I don't expect this DISCUSS to be blocking in the long term, rather it's here to make sure we do have the discussion. Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-17 06:56:20-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 08:21:56-07:00",
    "text": "I would like to discuss one issue before recommending approval of this document: In Section 2.1: \u00a0  The value field of the Multiple Labels Capability (shown in Figure 1) \u00a0  consists of one or more triples, where each triple consists of four \u00a0  octets.\u00a0 The first two octets of a triple specify an AFI value, the \u00a0  third octet specifies a SAFI value, and the fourth specifies a Count. \u00a0  If one of the triples is , the Count is the maximum \u00a0  number of labels that the BGP speaker sending the Capability can \u00a0  process in a received UPDATE of the specified AFI/SAFI. I think lack of recommendations on the minimal supported Count value will result in lack of interoperability. What are the common Count values used by implementations?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-08 14:41:28-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-18 13:53:24-08:00",
    "text": "I'm confused about some parts of how I'd implement this. It's quite possible this is just my error, but I'm including this point in the Discuss section in case it's not.\u00a0 This basically relates to how multiple recovery packets from a given FEC block get encoded and identified on the wire, but also how to populate the source block when multiple SSRCs are included. In short: suppose that I have D=3 and L=2.\u00a0 I should expect 5 repair packets for the six source packets in a block; the scheme for determining what order to generate them in and what their contents are is fairly clear to me.\u00a0 But how do I identify them on the wire?\u00a0 I'm assuming that the D and L on the wire are fixed values, since there's the possibility to only send zero on the wire and negotiate their values out of band.\u00a0 It's a little less clear whether the \"SN base\" fields are expected to be the same for all 5 recovery packets based on a given block, but if they do change then I'm not sure how I tell whether a given recovery packet is for a row or a column.\u00a0 Is this supposed to be using the sequence number from the outer RTP header for packet ordering, and the implicit order for row/column FEC packets?\u00a0 (It seems that in case of very bad packet loss and dynamic L+D, the receiver could then get out of sync as to what the sequence number is that corresponds to the start of a new batch of recovery blocks.) I also don't see how, for the case when there are multiple SSRCs, I know how many source packets to include from each SSRC in order to make up the D x L source block -- since Section 6.2's discussion lumps all the \"source packets\" together into a single set that get mutually xor'd, that seems to imply that the encoding is not \"do recovery for SSRC1, do recovery for SSRC2, ..., concatenate them all\". There are perhaps some other scenarios to worry about, such as interleaved recovery within a single block, but I'm happy to focus on the single 2-D case for purposes of illustration. Any insight into what I'm missing would be appreciated. A couple other points to check on: I'm not sure I'm following the procedures in Section 6.3.2 properly (see COMMENT) -- is the text correct as written? I also think there are a couple more factors worth mentioning in the security considerations (see COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-09-25 13:18:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 09:53:05-07:00",
    "text": "I'm sure this will be easy to either explain to me or re-phrase: Sections 4 and 6 both say something like \"MUST be agreed by all users of the network\".\u00a0 What does that really mean?\u00a0 How is it remotely possible to get agreement from all users of your network?\u00a0 How is it remotely possible that they could understand what you're asking them to agree to?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-23 10:38:30-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 17:49:59-07:00",
    "text": "We don't ever clearly state that the protocol allows for packet sizes other than the listed 44- and 112-octet variants, that content larger than that is to be treated as padding unless directed otherwise by configuration, that the reflected packet must be the same size as the incoming packet, and how a Session-Reflector should set any such padding that it needs to add in order to produce a same-sized packet. This document hardcodes the truncated HMAC-SHA-256 algorithm.\u00a0 Per  BCP 201 , what is the procedure for cryptographic algorithm agility? Please also consider the discussion in  BCP 107  about key lifecycles and key management, including whether it is appropriate to use a key-derivation function to produce short-term (e.g., per flow) keys from a long-lived key (e.g., one fixed in static configuration). What is the input plaintext to the HMAC computation?\u00a0 In the case of future extensions, does the HMAC field remain at its current fixed offset in the packet or move to always be the last 16 octets?\u00a0 Is any additional padding/TLV content protected by the HMAC? What error does the error estimate ... estimate? Clock skew between sender and receiver? I think we need to require some level of cryptographic protection whenever control information is included in a Session-Sender's test packet.\u00a0 That is, that a Session-Reflector MUST NOT act on control information received in unauthenticated packets.\u00a0 (That said, this document itself does not describe a way to include control information, so perhaps the note about \"optional control information communicated in the Session-Sender's test packet\" in Section 4 is misplaced. In Section 4.2.1: \u00a0  o\u00a0 Timestamp and Receiver Timestamp fields are each eight octets \u00a0 \u00a0 \u00a0 long.\u00a0 The format of these fields, NTP or PTPv2, indicated by the \u00a0 \u00a0 \u00a0 Z flag of the Error Estimate field as described in Section 4.1. I think you need to explicitly say that \"Timestamp\" is echoed from the received packet and \"Receiver Timestamp\" is determined locally as close to (reciept? transmission?) as possible. I think we need greater clarity on whether the normative statements in Section 4.4 apply only to STAMP peers that are aware they are interacting with TWAMP Light, or apply to all STAMP peers (see Comment for further discussion on why the current text seems internally inconsistent). In Section 4.1.1: \u00a0  o\u00a0 Timestamp is eight octets long field.\u00a0 STAMP node MUST support \u00a0 \u00a0 \u00a0 Network Time Protocol (NTP) version 4 64-bit timestamp format \u00a0 \u00a0 \u00a0 [ RFC5905 ], the format used in [ RFC5357 ].\u00a0 STAMP node MAY support \u00a0 \u00a0 \u00a0 IEEE 1588v2 Precision Time Protocol truncated 64-bit timestamp \u00a0 \u00a0 \u00a0 format [IEEE.1588.2008], the format used in [ RFC8186 ]. I think a note that which one is in use will be configured by the configuration/management function is in order.\u00a0 Except that the Z bit below confuses things terribly... \u00a0 \u00a0 \u00a0 The STAMP Session-Sender and Session-Reflector MAY use, not use, \u00a0 \u00a0 \u00a0 or set value of the Z field in accordance with the timestamp \u00a0 \u00a0 \u00a0 format in use.\u00a0 This optional field is to enhance operations, but \u00a0 \u00a0 \u00a0 local configuration or defaults could be used in its place. ... since, as noted by the secdir reviewer, this line just confuses everything.\u00a0 Either keep the \"must be zero\" semantics of 4656 or the \"MUST match reality\" semantics of 8186, but this middle case is actively harmful. (I also support Barry and Magnus' Discusses.)",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-09-26 01:41:18-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 06:53:55-07:00",
    "text": "Two very much discussing discusses. However, I would really like to hear the answer to these concerns before clearing.  1. Section 4.3: Is the HMAC field size of 16 bytes hard coded? If there ever would exist a need to deploy another integrity solution, even if the actual algorithm used to construct the tag can be agreed by the management, there appear to exist a hard look in to use 16-byte tags. Have this issue been considered?  \t2. Section 6:  \tThe possible impact of the \u00a0  STAMP test packets on the network MUST be thoroughly analyzed, and \u00a0  the use of STAMP for each case MUST be agreed by all users on the \u00a0  network before starting the STAMP test session.   \tI assume some potential issues are know, shouldn't they really be listed here in the security consideration to further motivate why the analysis needs to happen.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-09-04 18:45:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-04 18:44:36-07:00",
    "text": "(1) Section 4.3.\u00a0 The text does not explicitly state the data on which the HMAC is computed (i.e., bytes 1 to the end of the last MBZ field of the message?) (2) Section 6.\u00a0 Per \u201cIn general, all the security considerations related to TWAMP-Test, discussed in [ RFC5357 ] apply to STAMP.\u201d, what exact guidance is relevant here: -- Section 6 (Security Considerations) of  RFC5357  says follow the guidance of  RFC4656  and guidance on the OWAMP Server-Greeting messages, only the former seems relevant -- Section 6 (Security Considerations) of  RFC4656  has: Section 6.1 which discusses authenticated and encrypted mode of OWAMP; but STAMP has no encrypted mode.\u00a0 The claims about authenticate mode seem to be similar to OWAMP, but that\u2019s not explicitly said Section 6.2 discusses DoS, seems to have some related guidance but also discusses TCP handshakes  Section 6.3 discusses covert channels, this seems relevant Section 6.4 seems to discuss key management that section 4.3 of this draft seems to suggest is out of scope Section 6.5 seems to provide guidance on resource provisioning but uses the KeyID primitive that doesn\u2019t appear present in this draft [\u2026]",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-20 10:32:14-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 18:45:07-07:00",
    "text": "(1) Section 4.3.\u00a0 The text does not explicitly state the data on which the HMAC is computed (i.e., bytes 1 to the end of the last MBZ field of the message?) (2) Section 6.\u00a0 Per \u201cIn general, all the security considerations related to TWAMP-Test, discussed in [ RFC5357 ] apply to STAMP.\u201d, what exact guidance is relevant here: -- Section 6 (Security Considerations) of  RFC5357  says follow the guidance of  RFC4656  and guidance on the OWAMP Server-Greeting messages, only the former seems relevant -- Section 6 (Security Considerations) of  RFC4656  has: Section 6.1 which discusses authenticated and encrypted mode of OWAMP; but STAMP has no encrypted mode.\u00a0 The claims about authenticate mode seem to be similar to OWAMP, but that\u2019s not explicitly said Section 6.2 discusses DoS, seems to have some related guidance but also discusses TCP handshakes  Section 6.3 discusses covert channels, this seems relevant Section 6.4 seems to discuss key management that section 4.3 of this draft seems to suggest is out of scope Section 6.5 seems to provide guidance on resource provisioning but uses the KeyID primitive that doesn\u2019t appear present in this draft [please review the other sections too ...]",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-30 07:41:03-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-25 22:50:30-07:00",
    "text": "I'm confused about whether the text in this document is intended to form a normative description of SCReAM. The document contains the following statement: \u00a0  Note that the pseudo code does not show all \u00a0  details for reasons of readability, the reader is encouraged to look \u00a0  into the C++ code in [SCReAM-CPP-implementation] for the details. This effectively states that the cited C++ code forms the normative specification of the SCReAM algorithm, and that this document is a non-normative companion to help understand the normative code. If this is the case, then: - The [SCReAM-CPP-implementation] reference needs to be moved from \"Informative References\" to \"Normative References\",  - The abstract and introduction need to make it much clearer that the normative definition of the SCReAM algorithm is a body of C++ code rather than the prose and psuedocode in this document, and - We need to coordinate with the RFC editor to ensure proper archival of the code at [SCReAM-CPP-implementation]. At this time,  github.com  does not meet the standards of archival quality that the RFC series is expected to meet. If the C++ implementation is *not* the normative definition of SCReAM, then the psuedocode and definitions in this document need to be complete and sufficient to implement the algorithm; and, in particular, it cannot omit algorithm details \"for reasons of readability.\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-16 10:45:25-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-29 19:48:04-07:00",
    "text": "Thank you for writing this document; I'm really glad that it will be available to illuminate the particulars of BPsec usage and provide a default option when running BPsec in relatively bland environments. However, I think there are a few gaps between the current specification and a strong/reliable default security option. (D1) the construction for the HMAC input plaintext and GCM AAD seems to be \"malleable\" at the security context layer.\u00a0 That is, in order for the cryptographic integrity protection mechanism to provide strong guarantees for the application protocol's semantics, the mapping from protocol parameters (e.g., \"security target contents\", \"primary block\") to the actual byte string used as the IPPT/AAD inputs to HMAC/GMAC needs to be an injective mapping (in the mathematical sense).\u00a0 If injectivity does not hold, then there is more than one possible application semantics that could be perceived as valid upon successful validation of the authentication tag at the recipient; this \"malleability\" across different interpretations of the bytes covered by a given integrity tag gives an opening by which an attacker can target the application semantics. The current construction seems \"malleable\" because the scope flags are not protected in any way and could be modified by an attacker, and the scope flags affect which application protocol fields (and thus, semantics) are used to construct the IPPT/AAD.\u00a0 If the attacker modifies the messages to move those encoded bytes from one location to another, the modified message could still pass cryptographic verification but be interpreted with different semantics than intended.\u00a0 We do correctly note that the security context identifier and the security context parameters of the security block are not included in the input data, but the conclusion that \"successful verification implies that these parameters were unchanged from what the security source has specified\" does not seem entirely warranted without further analysis that relies on the internal structure of the different potential parts of the IPPT/AAD. [side note: the IETF security community tends towards \"always include as much information in the MAC as you can without breaking operations\", which would naively be everything included with scope flags 0x7.\u00a0 Always including everything removes the malleability, since there are no gaps to move around.\u00a0 But I think I can come up with scenarios where this flexibility would indeed be needed in BP operations, so my tentative conclusion is that the simple \"always MAC everything\" approach will not work here.] Specifically, to the extent that we may have injectivity, we seem to be relying on the specific encoding details of the different types of information that could be used in constructing the IPPT and AAD.\u00a0 Since the IPPT/AAD is currently just the concatenation (in a particular order) of any/all of a few pieces of data, we can only get injectivity if each of those pieces of data is self-framing and *self-identifying* by its encoded form.\u00a0 (If we, for example, prefixed each self-framing part with a type identifier for what followed, that would make the overall encoding self-identifying for what is contained therein.)\u00a0 E.g., the primary block is going to be a CBOR array with (at least?) 8 elements, starting with 0x0808, and is self-framing by virtue of being a CBOR object.\u00a0 But the \"security target other fields\" are not so clearly self framing, as it's more of a CBOR sequence with type code, block number, and control flags as three unsigned integers; we have to know a priori to read three CBOR unsigned integers and treat that as a single object. Furthermore, the \"BIB other fields\" (or \"BCB other fields\") are also three CBOR unsigned integers, and since it's possible for (e.g.) a BIB to be the security target of a BIB, the block type code cannot distinguish between a security target and the BIB information.\u00a0 Only the block number could, but IIRC the block number itself is malleable to an on-path attacker.\u00a0 And this analysis only covers the currently specified scope flags; any future additions might add new ways for injectivity to fail.\u00a0 It's much better to have a strong injective construction at the higher layer and not rely on the internal encoding details of the component pieces. So, I think we need to include at least the scope flags as part of the IPPT/AAD in order to provide injectivity.\u00a0 It might be worth considering adding additional framing and typing to make clear boundaries between the different parts of the IPPT/AAD, but my current understanding is that it would not be strictly necessary to do so. (D2) There seems to be some risk associated with the current HMAC construction, since the HMAC with a given key over a given plaintext will be the same each time it is calculated.\u00a0 In other protocol contexts, this has led to practical attacks and HMAC forgery, by using a side-channel to gain insight into the verifier's behavior and guessing the correct HMAC tag for a given (attacker-selected) plaintext a byte at a time.\u00a0 With only a modest number of trials (4k on average for HMAC-SHA-256, assuming a fully reliable side channel) this would let the attacker extract the valid HMAC tag that the verifier produced for comparison against the attacker's guess at the HMAC tag.\u00a0 Since this is the HMAC tag over the attacker's chosen plaintext, this lets the attacker obtain a valid HMAC tag without knowing the HMAC key. Now, it seems clear that in the preponderance of BP deployments there will not be an effective side channel available!\u00a0 But IMO this still reflects a fundamental cryptographic weakness in the protocol and we should make some effort to address it.\u00a0 There are a couple potential mitigation approaches off the top of my head, which can be combined if desired: include a nonce as part of the HMAC input (and encourage rejection of reused nonces), and require constant-time comparison of the supplied and expected authentication tag (to prevent using a side channel from reading it off byte by byte).\u00a0 I suspect that there may be some operational issues with the \"unique nonce per HMAC\" approach that would make it not terribly reliable in practice, but \"use a constant-time comparison\" should be fairly straightforward. (D3) While we do provide the standard guidance against using any given key with more than one algorithm (e.g., with HMAC-SHA-256 and AES256-GCM), there seem to be additional considerations relevant to this protocol that merit further discussion in the security considerations. Specifically, we make provision for an AES-KW wrapped key to be included along with the security payload and mandate that if present, such a key be used.\u00a0 Given that the parameter holding the wrapped key does not seem to be bound to a given message, it seems fairly straightforward for an in-network attacker to \"slice and dice\" the ciphertext and wrapped key away from each other, and cause any wrapped key it has seen to be attempted to be used with a given algorithm+ciphertext.\u00a0 This, in turn, would provide attacker-induced key reuse across algorithms, which is something that we want to avoid.\u00a0 While providing full protection against key reuse with different algorithms would prove fairly challenging and probably require significant state on the verifier/security destination, we should at least have some discussion of the situation, and could provide some modest mitigation techniques such as using distinct KEKs for receiving wrapped keys that have different intended usage.\u00a0 That is, one KEK for receiving AES keys, another for HMAC keys, etc..\u00a0 Attaching context (intended algorithm, etc.) to the KEK allows such context to be indirectly attached to the received wrapped keys, which otherwise would come without much context for intended usage.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-07-13 04:35:36-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-29 07:39:45-07:00",
    "text": "Thank you for the work on this document. I'd like to discuss the following point. I also have some non blocking comments, which I hope will help improve the document. Francesca 1. ----- FP: I agree with my colleagues that extensibility should be considered for algorithms. This document defines BIB-HMAC-SHA2 and BCB-AES-GCM, with the algorithms these security contexts provide. Adding support for one algorithm would need to define a new security context. Wouldn't it make sense to, instead, provide a way to add algorithms to the existing algorithms? For example, defining an IANA registry for each security context with the IDs of algorithms supported (taken from COSE). 2. ----- \u00a0 \u00a0 \u00a0 - Bit 2 (0x0003): Security Header Flag. FP: This should be (0x0004) and not (0x0003) (and same in a later section). Also, this is not wrong, but the bitmaps (here and everywhere else) could also be represented as 0b0100 in CBOR diagnostic notation, which to me is clearer. 3. ----- \u00a0 \u00a0 \u00a0 - Bits 8-15 are unassigned. FP: I am wondering why the limit on Bit 15, marked as unassigned: I think it would make sense to say Bits 8 and higher are unassigned. (This change would need to be reflected in the IANA sections) 4. ----- FP: this might be me missing some fundamental reading from bpsec, but I see that the blocks are defined as CBOR sequences. However, that is only mentioned in the appendix (meant to be informative): \u00a0  represented using CBOR structures.\u00a0 In cases where BP blocks (to \u00a0  include BPSec security blocks) are comprised of a sequence of CBOR \u00a0  objects, these objects are represented as a CBOR sequence as defined \u00a0  in [ RFC8742 ]. Is this defined somewhere else? If yes, could you add a pointer to the doc where it is defined? If not, this should be clarified, and specified earlier in the text, say in sections 3 and 4. 5. ----- \u00a0 \u00a0  [1, b'Twelve121212'] / Initialization Vector /, FP: I think the IV value is wrong here and should be h'5477656c7665313231323132'.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-07-09 13:25:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-25 13:20:36-07:00",
    "text": "There are several references to the possibility that the AES-GCM API doesn't allow for separation of the tag from the cipher text. I have not heard of products with this API but will accept that they exist. But I'm confused as to the handling of this case: (4.4.1) says the tag MUST be CBOR encoded and (4.8.1) says the tag MUST be reported in the security result; but how is this possible if the tag is not extractable from the ciphertext? Moreover, shouldn't there be a parameter or a scope flag somewhere that tells the receiver if the tag is in the cipher text? It would be hard to discern the sender's API a priori!",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-07-15 07:40:35-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-01 00:53:13-07:00",
    "text": "Sections 5.2 and 5.3 declare new IANA registries with Specification Required policies.\u00a0  BCP 26  ( RFC 8126 ) says of such registries that \"clear guidance to the designated expert should be provided when defining the registry\", but none is provided here.\u00a0 While that's obviously not a MUST, I would like to have a short discussion about why no such guidance is appropriate (or get some crafted and added).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-13 10:06:19-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-20 06:38:26-08:00",
    "text": "I think we may need to have a discussion about when it's appropriate to provide resources intended for machine consumption without a machine-readable way of knowing how to consume those resources.\u00a0 (See comments on Sections 3.2, 3.3, 4.3, and 5.) I also have some reservations about the \"status\" relation, or perhaps just with the way it is described.\u00a0 Section 1 implies that it is supposed to be about the status of the service as a whole, as opposed to potentially being limited to just the resource returning the link relation.\u00a0 Since web services, while widespread, are not universal, I would be reluctant to use such a generic term in the namespace for a more specific use case.\u00a0 The actual registration in Section 6.4 is more vague, though, talking just about the status of \"the context\", which I suppose could apply even to resources that are not part of a web service. It's quite possible I'm in the rough on one or both of those, in which case I'll happily clear.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-01-19 14:41:14-08:00",
    "end_reason": "position_updated",
    "start": "2015-01-19 12:48:06-08:00",
    "text": "I'll clear once we've checked on this. Section 5 says DTLS1.0 (from 2006) is MTI and DTLS1.2 (2012) is a SHOULD. I could imagine that being reasonable when DTLS1.2 was newish, say when this work was getting started 2 years ago, but now a couple of years have passed, it might well be just fine to require DTLS1.2 - a lot has happened since and TLS1.2 deployment is now far ahead of where it was in 2012, and most specs have tended to include text like this because some implementers only had the older TLS version. So the DISCUSS is - is the 9 year old RFC still needed as MTI - can we not just say to use 1.2 now?\u00a0 (Note: since this is sort-of a WebRTC spec, I think it's worth quickly re-visiting this question now to be sure we're taking the right approach, as the answer we pick here is quite likely to be followed by other WebRTC docs over the next year or so. I think this is the first relevant WebRTC protocol spec with this bit of text isn't it?\u00a0 Apologies to the authors of this one for landing the discuss on them:-)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-26 15:23:11-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-20 19:12:54-08:00",
    "text": "Section 9.\u00a0 The primary impact of the manipulating writable nodes appears to be characterized as DoS.\u00a0 Don\u2019t the possible consequences also include the ability to leak traffic outside the trusted domain or to route traffic through arbitrary paths of the attackers choosing potentially enable on-path inspection or manipulation of traffic; or avoidance of security controls?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-04-04 14:01:52-07:00",
    "end_reason": "position_updated",
    "start": "2015-08-07 14:40:38-07:00",
    "text": "There are ballot comments from Spencer, Stephen, Barry, and Kathleen that still need to be addressed. (Even though Stephen cleared his DISCUSS, I think the remaining comments need to be considered.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-03-23 13:29:05-07:00",
    "end_reason": "position_updated",
    "start": "2015-02-05 06:33:38-08:00",
    "text": "I just want to check one thing... Section 5: why is there a MUST for Digest auth?\u00a0 What'd be wrong with TLS client auth here?\u00a0 I do wish the WG had considered some alternative to passwords, which don't make so much sense in this use-case.\u00a0 (BTW: You could chose HOBA here I guess, but that's still in the RFC editor queue and not supported by libraries so perhaps doesn't suit. But it'd work. I'm an author of the HOBA spec though, so I'm biased:-) Anyway - can you tell me if the WG considered dropping passwords entirely and mandating TLS client auth be implemented?\u00a0 If the WG seriously considered TLS client auth already, I'll just clear.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-02-07 06:24:08-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-19 06:00:35-08:00",
    "text": "olding a DISCUSS pending expert review for the Emergency Call Data Types subregistry of the Emergency Call Additional Data registry.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-10 17:49:08-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-04 19:43:55-08:00",
    "text": "What is the extensibility model for the \"AF\" (address family) field in the OSPFv3 Extended Prefix Range TLV?\u00a0 That is, what do we need to say about  current implementations' behavior to allow future changes?\u00a0 (I also a  little bit wonder if we really need a full eight bits, but that's basically  aesthetic.) Some of the text in Section 8.1 (see the COMMENT section) reads like it might have an \"Updates\" relationship with other documents, but I don't know enough to be sure.\u00a0 Hopefully we can have a conversation to clarify the situation.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-14 10:52:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-20 20:55:05-08:00",
    "text": "I'm pretty sad to see that the \"RequireTLS: no\" header field has the name \"require TLS\" and the opposite semantics.\u00a0 It seems like the positvie signal that we are trying to indicate is \"Ignore TLS\" or \"TLS optional\" or similar; why does the header field need to be named \"Require TLS\" -- isn't that confusing to users? While I understand that there can be cases where it is desired to ignore recipient-domain indications to use TLS, such as to report problems with the TLS capabilities of those domains, I have strong qualms about describing this protocol as an \"override\" for DANE and MTA-STS, or that such recipient-domain signals should be \"ignored\".\u00a0 In effect, by attempting to do so, this document is fundamentally modifying the protocol semantics for (SMTP) DANE and MTA-STS, something that can only properly be done by clearly calling out the behavior change and an Updates: relationship with the documents whose semantics are being modified.\u00a0 Alternately, it could also be reasonable to remove claims of \"override\" or \"ignore\" and to leave the semantics of the header field as being that the sender requests one behavior, and the MTA can balance the requests of the sender and recipient at their own discretion. This is still not a great option, though, as it would seem to put multiple IETF proposed standards at odds with each other. I'm also concerned about the apparent new burden placed on senders to actively decide whether every outgoing message requires end-to-end TLS protection or is safe to forward without TLS, especially in light of the apparent goal (see next paragraph) of quickly achieving (near-)universal deployment.\u00a0 There doesn't seem to be much in this document to justify the stance that the default \"don't care\" option should be removed. The \"must chain forward to final delivery\" property for the REQUIRETLS option seems to present some incremental deployment difficulties, in that it will be nigh-impossible to successfully deliver such a message until there is fairly significant deployment coverage.\u00a0 E.g., if any major email hosting provider does not implement, then it will forever remain a niche technology.\u00a0 What indication to we have that this technology can succeed as specified?\u00a0 If we anticipate it becoming a part of the de facto core, mandatory, SMTP feature set, should we not indicate that by an Updates: relationship? I'm also unsure exactly how tightly nailed down the (non-DANE) TLS certificate validation process is supposed to be as a result of this document; more in the COMMENT section.\u00a0 It seems that without some form of strict certificate (host)name validation, this mechanism does not actually mitigate the lack of server authentication by the client that's described as a goal. I'd also like to discuss whether it's safe to require that the tag and header be mutually exclusive.\u00a0 (As per the COMMENT section,) I don't have a great picture on what scenarios could cause that to arise, how common they are, and what the impact would be for strict enforcement.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-17 12:15:36-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-14 10:52:00-07:00",
    "text": "I'm pretty sad to see that the \"RequireTLS: no\" header field has the name \"require TLS\" and the opposite semantics.\u00a0 It seems like the positvie signal that we are trying to indicate is \"Ignore TLS\" or \"TLS optional\" or similar; why does the header field need to be named \"Require TLS\" -- isn't that confusing to users, as opposed to, say, \"TLS-Required\"? While I understand that there can be cases where it is desired to ignore recipient-domain indications to use TLS, such as to report problems with the TLS capabilities of those domains, I have strong qualms about describing this protocol as an \"override\" for DANE and MTA-STS, or that such recipient-domain signals should be \"ignored\".\u00a0 In effect, by attempting to do so, this document is fundamentally modifying the protocol semantics for (SMTP) DANE and MTA-STS, something that can only properly be done by clearly calling out the behavior change and an Updates: relationship with the documents whose semantics are being modified (i.e., the DANE and MTA-STS specifications). Alternately, it could also be reasonable to remove claims of \"override\" or \"ignore\" and to leave the semantics of the header field as being that the sender requests one behavior, and the MTA can balance the requests of the sender and recipient at their own discretion. This is still not a great option, though, as it would seem to put multiple IETF proposed standards at odds with each other. I'm also concerned about the apparent new burden placed on senders in Section 4.3 to actively decide whether every outgoing message requires end-to-end TLS protection or is safe to forward without TLS (\"when TLS is to be required, [...].\u00a0 When TLS is not to be required, [...]\"), where both \"[...]\" require new behavior not present in a client that does not implement this specification.\u00a0 To some extent this is an editorial matter of how the new mechanisms are portrayed, but I don't see much in this document to justify the stance that the default \"don't care\" option should be removed (for clients that implement this specification at all). [discussion of \"de facto part of the core SMTP spec\" removed, on\u00a0 indications that this is not the intent] I'm also unsure exactly how tightly nailed down the (non-DANE) TLS certificate validation process is supposed to be as a result of this document; more in the COMMENT section.\u00a0 It seems that without some form of strict certificate (host)name validation, this mechanism does not actually mitigate the lack of server authentication by the client that's described as a goal.\u00a0 That is, while the referenced DANE procedures for validating a TLS connection for SMTP are pretty clear and exhaustive, the non-DANE case does not seem to have thorough instructions for how to validate the TLS connection, whether in this document or an external reference. I'd also like to discuss whether it's safe to require that the tag and header be mutually exclusive.\u00a0 (As per the COMMENT section,) I don't have a great picture on what scenarios could cause that to arise, how common they are, and what the impact would be for strict enforcement, but there doesn't seem to be much reason to actively allow conflicting indications, even when we say which one takes precedence.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-02 15:06:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-17 12:15:36-07:00",
    "text": "I'm glad that we were able to come to consensus to rename the header field to \"TLS-Required\"; that addresses a key concern of mine. I\u00a0 also appreciate the addition of the \"Policy Conflicts\" section that portrays a fairly clear picture of the interaction between this mechanism, DANE, and MTA-STS.\u00a0 I still wish that we were able to bring the technologies into greater alignment and not need to convey the sense that standards-track mechanisms are in conflict with each other, but cannot justify blocking publication based solely on that desire. In this space, though, I do request an additional wording tweak in Appendix A.2, which currently states \"The TLS-Required header field is used when the sender of the message wants to override the default policy of the recipient domain to require TLS.\" which uses the \"override\" terminology without couching it as a request.\u00a0 Can we reword to include \"request\" here as well? The following paragraph (unchanged from my ballot on -07) received only minimal discussion so far: I'm also concerned about the apparent new burden placed on senders in Section 4.3 to actively decide whether every outgoing message requires end-to-end TLS protection or is safe to forward without TLS (\"when TLS is to be required, [...].\u00a0 When TLS is not to be required, [...]\"), where both \"[...]\" require new behavior not present in a client that does not implement this specification.\u00a0 To some extent this is an editorial matter of how the new mechanisms are portrayed, but I don't see much in this document to justify the stance that the default \"don't care\" option should be removed (for clients that implement this specification at all). It seems that we are in agreement that it's okay to have a \"don't care\" option, which is indicated by not using the extension at all.\u00a0 That said, I still think that the specific text of Section 4.3 conveys an impression that there is a requirement to actively decide, with the language about \"has the authority to decide whether to require TLS\", \"when TLS is\u00a0 to be required\", \"when TLS is not to be required\", and \"in either case, the decision [...] MAY be done based on [...]\".\u00a0  Perhaps I'm just misreading the text, but I haven't seen any signals to that effect yet.\u00a0 I'd suggest (but am open to further refinement\" changing to \"has the option to decide whether to require TLS\" and \"if one of these cases is selected, the decision [...]\" as a way to clarify the language used. [discussion of \"de facto part of the core SMTP spec\" removed, on\u00a0 indications that this is not the intent] We had some good discussion about the three potential cases for authenticating the TLS connection: (1) Dane per  RFC 7672 (2) MTA-STS per  RFC 8461 (3) DNSSEC-validated MX records + WebPKI authentication of the MX hosts I think a little more specificity is needed for the (3) case; we do say to use the  RFC 6125  procedures but still need to specify (e.g.) that the DNS-ID name type is used and (IIRC) that the hostname resulting from the MX lookup is used as the DNS-ID to be validated.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-02-21 07:07:06-08:00",
    "text": "I support Benjamin's DISCUSS. To elaborate on one point a bit: it seems to me that it's harmful to security to allow the sender to unilaterally override the recipient's preferences that something be encrypted. To forestall one argument, yes, the sender knows the contents of the message, but the recipient knows their own circumstances, and they may be at particular risk \u00a0 \u00a0 \u00a0  The choices of key lengths and algorithms change over time, so a \u00a0 \u00a0 \u00a0  specific requirement is not presented here. \u00a0 \u00a0 \u00a0   This is not a verifiable conformance requirement. You either need to not have a 8174 SHOULD here, or actually specify what \"meaningfully secure\" means.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-08-29 08:20:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-16 03:00:14-07:00",
    "text": "1. Section 5.1: To me it appears that one fundamental security flaw exists in the definition of the inner encryption. That is the fact that RTP padding is not included into the inner encrypted part. This prevents the application of RTP padding to prevent the potential privacy leakage that \"Guidelines for the Use of Variable Bit Rate Audio with Secure RTP\" ( RFC 6562 ) documents. To prevent this type of information leakage and other privacy preserving operations based on applying RTP padding it would be necessary to include the RTP padding into the inner encrypted envelope. Appendix A figure indicates that is the case, but the process description in 5.1 is not matching that.  2. Section 5.1:  \u00a0  1.\u00a0 Form an RTP packet.\u00a0 If there are any header extensions, they \u00a0 \u00a0 \u00a0  MUST use [ RFC8285 ]. I got the impression from the framework that it was possible to have some header extension being encrypted using the inner key as (Section 4:3) says:  \u00a0  If there is a need to encrypt one or more RTP header extensions end- \u00a0  to-end, the endpoint derives an encryption key from the E2E SRTP \u00a0  master key to encrypt header extensions as per [ RFC6904 ].  That is missing from this step as it can't be applied in step 4. And shouldn't the headers protected in this fashion with the inner keys be part of the authenticated synthetic packet?  3. Section 5.2:  This is minor but still a significant inconsistency:  \u00a0  3.\u00a0 A Media Distributor can add information to the OHB, but MUST NOT \u00a0 \u00a0 \u00a0  change existing information in the OHB.\u00a0 If RTP value is changed \u00a0 \u00a0 \u00a0  and not already in the OHB, then add it with its original value \u00a0 \u00a0 \u00a0  to the OHB. 4.\u00a0 If the Media Distributor resets a parameter to its original \u00a0 \u00a0 \u00a0  value, it MAY drop it from the OHB.\u00a0 Note that this might result \u00a0 \u00a0 \u00a0  in a decrease in the size of the OHB. So reseting back to original value, is according to 3 not allowed. I think the MUST NOT is wrongly formulated. I assume that the point is that any field value carrying an original value MUST NOT be changed, however, if the field is changed back to its original value, the value SHALL/SHOULD be removed from the OHB? 4. Section 5.2:  ... SHOULD use an independent salt for each recipient, Is that possible on any other legs than MD to MD? What has been statated is that all end-point are required to use the same sal for a session as that is not included in the EKT. Putting a SHOULD requirement on something that is not possbile appears counter productive.  5. Section 7.1: This section fails to make it clear why RTX packets are retransmitting the double encrypted packets. In normal application of SRTP the buffered packet and what is used for constructing the RTX packet is the unencrypted one. Thus the equivalent for an MD would be to handle the Inner protected only in its cache. Is the reason that an endpoint that recovers a packet anyway have to pass it through the double decryption process and thus it is to avoid a exception case for the endpoint? If that is the case, please note it in the text.  6. Section 7.2: I fail to see how one can follow this procedure and generate anything that is workable. The reasons is that that the primary encoding and each of multiple redundancy encoding all share the same SSRC and have no independent sequence number space or timestamp space. Thus, I don't see how it is possible to create inner encrypted payloads for each of the primary and redundnacy encoding without two time pads. Why wasn't the simple choice applied here. That is to treat RED as a single endpoint to endpoint format. Thus making it robust if packets are lost on the path, but the MD's can't recreate a packet based on a redundancy paylaod and inject that instead.  I don't see how that this is a correct statement. As RED does not have different SSRCs for the different media encodings what it does can't be represented in FlexFEC.     \"Note that Flex FEC [ I-D.ietf-payload-flexible-fec-scheme ] is a \u00a0  superset of the capabilities of RED.\u00a0 For most applications, FlexFEC \u00a0  is a better choice than RED.\" 7. Section 9:  \tWhen this is done, the cryptographic \u00a0  contexts used for decryption and re-encryption MUST use different, \u00a0  independent master keys and master salts.    \tRelated to discuss item 4 and here at different  RFC 2119  levels.    8. Section 9. The use of AES-GCM as symmetric algorithms results in that the source authication level for the inner part has a limited scope, in that any endpoint can create a double protected packet, not only the one that which SSRC it is as there are no cryptographic protection on that level. I think that point is significant for something that is primarily targeting group communication scenarios.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-09-12 15:23:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-09-12 15:23:20-07:00",
    "text": "I am concerned that the specification of \"delay-compression\" is not specified with enough detail to ensure compatible interoperation. I may have missed something in the protocols this document relies upon; but if I haven't, I think this needs additional specification. The current definition for \"delay-compression\" is: \u00a0 \u00a0 string\u00a0 \u00a0 \u00a0 \u00a0  \"delay-compression\" \u00a0 \u00a0 string: \u00a0 \u00a0 \u00a0 name-list\u00a0 \u00a0 compression_algorithms_client_to_server \u00a0 \u00a0 \u00a0 name-list\u00a0 \u00a0 compression_algorithms_server_to_client In reading through this document (and skimming  RFC4251 ), I don't see anything that indicates the on-the-wire encoding for \"string containing multiple name-lists.\" I suspect that the intention is something like [string-length][list-length]value[list-length]value; however, that requires making a number of unstated assumptions, and I doubt that all implementors will make the same assumptions. To be clear, what I mean by my formulation above would result in the value field of client_to_server=\"foo,bar\" and server_to_client=\"bar,baz\" being encoded as: 00 00 00 16 00 00 00 07 66 6f 6f 2c 62 61 72 00 00 00 07 62 61 72 2c 62 61 7a If this is the intention, please be explicit (and, ideally, provide an example).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-09-14 10:24:03-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-12 15:23:50-07:00",
    "text": "I am concerned that the syntax of \"delay-compression\" is not specified with enough detail to ensure compatible interoperation. I may have missed something in the protocols this document relies upon; but if I haven't, I think this needs additional specification. The current definition for \"delay-compression\" is: \u00a0 \u00a0 string\u00a0 \u00a0 \u00a0 \u00a0  \"delay-compression\" \u00a0 \u00a0 string: \u00a0 \u00a0 \u00a0 name-list\u00a0 \u00a0 compression_algorithms_client_to_server \u00a0 \u00a0 \u00a0 name-list\u00a0 \u00a0 compression_algorithms_server_to_client In reading through this document (and skimming  RFC4251 ), I don't see anything that indicates the on-the-wire encoding for \"string containing multiple name-lists.\" I suspect that the intention is something like [string-length][list-length]value[list-length]value; however, that requires making a number of unstated assumptions, and I doubt that all implementors will make the same assumptions. To be clear, what I mean by my formulation above would result in the value field of client_to_server=\"foo,bar\" and server_to_client=\"bar,baz\" being encoded as: 00 00 00 16 00 00 00 07 66 6f 6f 2c 62 61 72 00 00 00 07 62 61 72 2c 62 61 7a If this is the intention, please be explicit (and, ideally, provide an example).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-09-14 06:26:37-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-13 05:00:17-07:00",
    "text": "This is generally a good and useful document. I have some minor comments I would like to discuss: 3.2.\u00a0 \"delay-compression\" \u00a0 This extension MAY be sent by both parties as follows: \u00a0  \u00a0 \u00a0 string\u00a0 \u00a0 \u00a0 \u00a0  \"delay-compression\" \u00a0 \u00a0 string: \u00a0 \u00a0 \u00a0 name-list\u00a0 \u00a0 compression_algorithms_client_to_server \u00a0 \u00a0 \u00a0 name-list\u00a0 \u00a0 compression_algorithms_server_to_client It is not clear for me from the formatting whether the first name-list is sent by the client and the second by the server, or both lists are always included in the value. I suspect it is the former, but can you please clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-09-13 21:24:37-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-13 12:30:14-07:00",
    "text": "I plan to ballot \"yes\", but I want to discuss one point first. Alexey mentioned this in his comments, but I think it's discuss worthy. Hopefully it's an easy fix, and it may well be because I've missed something obvious. If people think it really, really needs to be this way, I will clear--but I want to discuss it first: - 2.5: The relative order in which extensions appear in an \u00a0 EXT_INFO message MUST be ignored by default; but an extension MAY \u00a0 specify that the order matters for that extension, in a specific way. I don't think allowing specific extensions to add ordering requirement works. It opens up the possibility of incompatible ordering requirements across extensions. As far as I can tell, the only control over this is the \"IETF Consensus\" requirement for adding new extensions. I'm open to arguments that this is good enough, but my knee-jerk response is that it puts an undue burden on the consensus process for little return.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-09-15 12:10:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-15 12:08:07-07:00",
    "text": "This should be trivial to address, either by telling my why I'm wrong, or fixing it -- in either case, I'll change to a YES. The IANA considerations section says: ----- \u00a0  The IANA is requested to update the Encryption Algorithm Name \u00a0  Registry of the Secure Shell (SSH) Protocol Parameters [IANA].\u00a0 The \u00a0  Registration procedure is IETF Review which is achieved by this \u00a0  document.\u00a0 The registry should be updated as follows: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +------------------------------+------------+------+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | Encryption\u00a0 Algorithm\u00a0 Name\u00a0 | Reference\u00a0 | Note | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +------------------------------+------------+------+ | arcfour | arcfour128 | arcfour256 +------------------------------+------------+------+ \u00a0  Where TBD is the RFC number assigned to the document. --- I think it would be vastly preferable to include a Note saying something along the lines of: \"DEPRECATED\" (or \"HISTORIC\" like for des-cbc). Someone implementing SSH / updating their implementation may look at the IANA page and not read all of the links.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-09-19 07:19:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-15 12:10:03-07:00",
    "text": "Be ye not alarmed -- this should be super-trivial to address, either by telling my why I'm wrong, or fixing it -- in either case, I'll change to a YES. I'm also fine with this being addressed in AUTH48, etc (if I'm not on the telechat, no need to for Revised ID Needed on my behalf) The IANA considerations section says: ----- \u00a0  The IANA is requested to update the Encryption Algorithm Name \u00a0  Registry of the Secure Shell (SSH) Protocol Parameters [IANA].\u00a0 The \u00a0  Registration procedure is IETF Review which is achieved by this \u00a0  document.\u00a0 The registry should be updated as follows: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +------------------------------+------------+------+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | Encryption\u00a0 Algorithm\u00a0 Name\u00a0 | Reference\u00a0 | Note | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +------------------------------+------------+------+ | arcfour | arcfour128 | arcfour256 +------------------------------+------------+------+ \u00a0  Where TBD is the RFC number assigned to the document. --- I think it would be vastly preferable to include a Note saying something along the lines of: \"DEPRECATED\" (or \"HISTORIC\" like for des-cbc). Someone implementing SSH / updating their implementation may look at the IANA page and not read all of the links.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-12-02 03:57:01-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-15 03:02:03-07:00",
    "text": "This DISCUSS is in line with Mahesh's OPS DIR review. If BMP (which I consider like a span port feature btw) troubleshooting shows that the BGP configuration is required, then the standard way to configure BGP will be  https://tools.ietf.org/html/draft-ietf-idr-bgp-model-00 . I'm wondering about the link between BMP and the following  draft-ietf-idr-bgp-model-00.txt  YANG models: \tbgp-types.yang \tbgp-policy.yang \tbgp-multiprotocol.yang \tbgp.yang \tbgp-operational.yang Specifically: are we able to map the Per-Peer Header (section 4.2) and Information TLV (section 4.4) to draft-ietf-idr-bgp-model-00.txt.\u00a0 Either because the field information come from the same reference (ex: both this draft and the idr one have the same reference for the Peer Distinguisher), or because specific references to the YANG key information is provided. I believe that the  draft-ietf-grow-bmp  and  draft-ietf-idr-bgp-model  authors should sit down and go through the exercise of mapping the BMP data model into the YANG data model, for a couple of troubleshooting scenarios. The OPS world suffers from too many different data models (MIB, IPFIX, YANG, etc.). With this DISCUSS, I want to make sure that we won't fall into the trap of defining a new one without at least providing the necessary mappings. Note: I see that sysName and sysDescr make the link with the MIB world, that's a step in the right direction. Below is Mahesh's OPS DIR review: Summary: This document defines a protocol, BMP, that can be used to monitor BGP sessions.\u00a0 BMP is intended to provide a convenient interface for obtaining route views.\u00a0 Prior to introduction of BMP, screen-scraping was the most commonly-used approach to obtaining such views.\u00a0 The design goals are to keep BMP simple, useful, easily implemented, and minimally service-affecting.\u00a0 BMP is not suitable for use as a routing protocol. The document is on standards track and defines another monitoring method specifically for BGP. The original draft is dated 2005, long before NETCONF or YANG were defined, and when there was probably no way to view routes. With the advent of NETCONF and specifically the BGP YANG model, which is currently a WG document, it would be helpful to know how BMP stands apart. The NETCONF notification structure allows for notifications described in this draft and the ability to collect stats reports and route monitoring. It would be helpful to know how BMP compliments that capability.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-02-10 08:12:18-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-13 19:06:10-07:00",
    "text": "The statements on authenticated access and confidentiality are helpful, but this is a new protocol and should not start out with the security property levels of the current BGP deployments.\u00a0 Efforts have been made to publish RFCs to fix BGP security and the vulnerabilities have been published - even in the Washington Post.\u00a0 I'd like to see more security required for the properties mentioned to prevent active and passive attacks getting dumps of the BGP data, which was not previously available.\u00a0 If this is not possible per the suggestions below, please explain why.\u00a0 If there is a good reason, it would be helpful to remove the text that says its okay to leave security out because BGP isn't secure and just include the security considerations. Now for specifics: 1. In the Security considerations, it is not only a passive attacker, but also an active one that could gain access to the session if it is not encrypted (protected for confidentiality).\u00a0 An active attacker might change routes causing network disruption.\u00a0 A passive attacker might better understand the possible paths to an AS, assisting with a more effective DDoS attack.\u00a0 The latter point is important to consider in the first paragraph of this section that currently says, \u00a0 \"although it's hard to consider the content of BGP routes in the \u00a0  public Internet to be confidential,\"  I think this is a bit of an overstatement as the exact routes and paths are not published for each router and could be used for DoS attacks - for example taking out one or more paths to a network AS. What I am suggesting for #1 is a simple text change to address the fuller set of security considerations. Change from: \u00a0  Unless a transport that provides confidentiality is used, \u00a0  a passive attacker could gain access to BMP data in flight.  To: \u00a0  Unless a transport that provides confidentiality is used, \u00a0  a passive or active attacker could gain access to or tamper the BMP data in flight.  2. The last paragraph would be the right place to require session encryption and authentication for sessions (unless there is a good explanation as to why this is not needed).\u00a0 If the transport may vary, then it's okay to leave IPsec as a suggestion.\u00a0 It would be nice if there was an MTI for transport, so the security protections could be consistent and interoperability would be easier between implementations.\u00a0 This also came up in the SecDir review. https://www.ietf.org/mail-archive/web/secdir/current/msg06011.html In any case, it would be good to discuss this and see if there are good reasons to leave it as-is or to change the text to improve security, preventing a few attack types.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-12-04 09:00:07-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-10-14 09:42:08-07:00",
    "text": "Apologies in advance for the rant, but this is a new protocol and not something deployed for decades that can't be fixed. (At least so says the write-up.) The state of security here is just sad. It reminds me of the 1980's. And introducing new protocols without improving that goes against very long held IETF consensus that protocols need to have some actually usable strong security mechanism defined.\u00a0 It seems the wg here get that but are choosing to do nothing about it - I mean in their day-jobs, not that writing RFC text is \"doing something.\" The responses to the secdir review seem to make it clear that the claim that IPsec can be used is mythical, so this discuss to ask that the security considerations properly document the utter absence of any modern way to secure this protocol and not pretend that there are ways that can be used to secure this in the real world. I would suggest text that simply says that:  \"This is an inherently insecure protocol for no particularly good reason and mostly due to the lack of implementation of basic security mechanisms (SSH, TLS) but also due to a lack of customer/operator pressure to ensure those are present, usable and interoperate, despite evidence that attacks on the links over which this data will be sent are ongoing.\" I'd not be surprised if you preferred some other text:-)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-22 09:37:30-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-04 09:00:07-08:00",
    "text": "Hi, this is an update of my discuss. After some discussion the authors changed from: OLD: \u00a0  Where the security considerations outlined above are a concern, users \u00a0  of this protocol should consider using some type of transport that \u00a0  provides mutual authentication, data integrity and transport \u00a0  protection, such as IPsec [ RFC4303 ] or TCP-AO [ RFC5925 ].\u00a0 If \u00a0  confidentiality is considered a concern, a transport providing that \u00a0  as well could be selected. NEW: \u00a0  This document does not specify any security mechanism for BMP. I do not believe that it is ok to merely state that one is not paying attention to IETF BCPs ( BCP61  specifically) but one needs to explain why. Hence my original suggestion which was: \"This is an inherently insecure protocol for no particularly good reason and mostly due to the lack of implementation of basic security mechanisms (SSH, TLS) but also due to a lack of customer/operator pressure to ensure those are present, usable and interoperate, despite evidence that attacks on the links over which this data will be sent are ongoing.\" I would like to talk about the right text to add here. My  belief (having chatted with a few folks but not everyone)  was that some people would be ok with saying you ought implement IPsec, others would be ok with you ought do TLS so backing right back down to \"it's ok and not sad to do nothing\" seems wrong to me.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-05-03 07:29:46-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-02 00:10:41-07:00",
    "text": "This is a well written document. I have one small issue to discuss before voting \"no objection\". At the end of section 2: why path identifier \"SHOULD be treated as opaque\" instead of \"MUST be treated as opaque\"? What are possible reasons to violate the SHOULD?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-07-19 09:30:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-14 02:37:14-07:00",
    "text": "Hi, Thanks for this document, I think that it is a helpful update.\u00a0 Disclaimer, I'm not a security expert, but I would like to discuss some of the  RFC 2119  constraints that have been specified please: (1)  I find some of the 2119 language to be somewhat contradictory: \u00a0 *\u00a0 Implementations MUST NOT negotiate TLS version 1.1 [ RFC4346 ]. \u00a0 *\u00a0 Implementations MUST support TLS 1.2 [ RFC5246 ] and MUST prefer to \u00a0 \u00a0  negotiate TLS version 1.2 over earlier versions of TLS. The second sentence implies that a TLS 1.2 is allowed to negotiate earlier versions of TLS, but a previous statement indicates that this is not allowed.\u00a0 A similar contradiction appears for DTLS: \u00a0  *\u00a0 Implementations MUST NOT negotiate DTLS version 1.0 [ RFC4347 ]. \u00a0  *\u00a0 Implementations MUST support DTLS 1.2 [ RFC6347 ] and MUST prefer to \u00a0 \u00a0 \u00a0 negotiate DTLS version 1.2 over earlier versions of DTLS. (2)   \t\u00a0  *\u00a0 New protocol designs that embed TLS mechanisms SHOULD use only TLS\t  \t\u00a0 \u00a0 \u00a0 1.3 and SHOULD NOT use TLS 1.2; for instance, QUIC [ RFC9001 ]) took\t  \t\u00a0 \u00a0 \u00a0 this approach.\u00a0 As a result, implementations of such newly-\t  \t\u00a0 \u00a0 \u00a0 developed protocols SHOULD support TLS 1.3 only with no\t  \t\u00a0 \u00a0 \u00a0 negotiation of earlier versions. Why is this only a SHOULD and not a MUST?\u00a0 If a new protocol (rather than an updated version of an existing protocol) was being designed why would it be reasonable to design it to support TLS 1.2?\u00a0 If you want to keep these as SHOULD rather than MUSTs then please can the document specify under what circumstances it would be reasonable for a new protocol design to use TLS 1.2. (3)  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  When TLS-only \u00a0 \u00a0 \u00a0 communication is available for a certain protocol, it MUST be used \u00a0 \u00a0 \u00a0 by implementations and MUST be configured by administrators.\u00a0 When \u00a0 \u00a0 \u00a0 a protocol only supports dynamic upgrade, implementations MUST \u00a0 \u00a0 \u00a0 provide a strict local policy (a policy that forbids use of \u00a0 \u00a0 \u00a0 plaintext in the absence of a negotiated TLS channel) and \u00a0 \u00a0 \u00a0 administrators MUST use this policy. The MUSTs feel too strong here, since there are surely deployments and streams of data where encryption, whilst beneficial, isn't an absolute requirement? In addition \"MUST be used by implementations and MUST be configured by administrators\" also seem to conflict, i.e., if the implementation must use it then why would an administrator have to enable it? (4)\u00a0   \u00a0  When using RSA, servers MUST authenticate using certificates with at \u00a0  least a 2048-bit modulus for the public key.\u00a0 In addition, the use of \u00a0  the SHA-256 hash algorithm is RECOMMENDED and SHA-1 or MD5 MUST NOT \u00a0  be used ([ RFC9155 ], and see [CAB-Baseline] for more details). So, for clarity, this would presumably mean that SHA-256 is also preferred over say SHA-512?\u00a0 Is that the intention?\u00a0 Or would it be better if the SHOULD allowed stronger ciphers?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-11-29 14:05:18-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-10-22 18:40:47-07:00",
    "text": "This document places normative requirements on new tunnel types but does not indicate this in a way that someone specifying a new tunnel type would be forced to see.\u00a0 This occurs both in Section 5.2: \u00a0  o\u00a0 When additional tunnel types are defined, the specification for \u00a0 \u00a0 \u00a0 how MVPN is to use those tunnel types must also specify how to \u00a0 \u00a0 \u00a0 construct the PTA of a Leaf A-D route that is originated in \u00a0 \u00a0 \u00a0 response to the LIR-pF flag.\u00a0 As an example, see [BIER-MVPN]. and in Section 6: \u00a0  If L's PTA specifies a tunnel type not mentioned above, the \u00a0  specification for how MVPN uses that tunnel type must specify the \u00a0  actions that N is to take upon receiving L.\u00a0 As an example, see \u00a0  [BIER-MVPN]. I think the best way to do this would be to have IANA Considerations updating the registration procedure for P-Multicast Service Interface (PMSI) Tunnel Type codepoints to note that new registrations must include this information.\u00a0 It might also suffice to call out the existence of these requirements in the portion of the Introduction that discusses how this document Updates  RFC 6514  (though, per the COMMENT section, this portion of the Introduction doesn't exist in a good form yet). Thank you for providing the BIER example, though -- it is helpful to see how the requirement plays out in practice!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-12-02 16:21:21-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-29 14:05:18-08:00",
    "text": "Thank you for addressing my original DISCUSS point! The updates in the -13 include new Updates headers for RFCs 7582 and 7900, which may or may not call for additional IESG eyes on the changes.\u00a0 Just from looking at the diff, it's not entirely clear to me what about those documents is being updated.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-11-29 05:30:47-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 05:28:12-07:00",
    "text": "In section 9 (security considerations): Thanks for discussing network load here! However, I find this sentence a bit unsatisfactory: \u00a0  \u201eThe specification of counter-measures for this problem is outside the scope of this document.\u201c Isn\u2019t there any easy way to make some more recommendations for counter measures that could be discussed here? E.g. implement some rate limiting or filtering. Or only accept LIR-PF request from preconfigured hosts (given that LIR-PF support must anyway be pre-configured)? I\u2019m not an expert on this topic and therefore don\u2019t know if any of such recommendations make sense, however, I would quickly like to discuss if it is potentially possible to say more than what\u2019s current said. Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-11-28 09:05:48-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 20:05:31-07:00",
    "text": "* Section 5.2. In the NLRI format it is not clear what the length of the \"Ingress PE's IP address\" field is supposed to be. i.e. what address families does it support and how do we determine what sort of address follows since there is no length field in front.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-06 20:47:03-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-16 06:48:13-08:00",
    "text": "My apologies for placing a Discuss so close to the telechat.\u00a0 I believe that both of these topics are comparatively minor and should be easy to resolve, but that it's important for the document to have a clear answer for them. I ask this with nospecific answer in mind that I need to hear -- per my comments on \u00a75.1.3, what are the actual requirements on the (cryptographic) protection of the State Cookie?\u00a0 I feel like I got different signals from different parts of the document, and it would be good to have consistent messaging throughout. Section 15.5 establishes a registry for payload protocol identifiers, but I am not sure how this registry is supposed to be able to effectively avoid collisions when we do not specify the endianness in which the value is represented on the wire (per \u00a73.3.1).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-11-03 02:12:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 06:34:07-07:00",
    "text": "In Section 7. there is discussion that CCFB will replace the ECN FB format. I find that appropriate however there is one function in ECN FB format that is not discussed here. Section 7.2.1 in  RFC 6679  states An immediate or \u00a0 \u00a0 \u00a0 early (depending on the RTP/AVPF mode) ECN feedback packet SHOULD \u00a0 \u00a0 \u00a0 be generated on receipt of the first ECT- or ECN-CE-marked packet \u00a0 \u00a0 \u00a0 from a sender that has not previously sent any ECT traffic.\u00a0 Each \u00a0 \u00a0 \u00a0 regular RTCP report MUST also contain an ECN Summary Report \u00a0 \u00a0 \u00a0 (Section 5.2).\u00a0 Reception of subsequent ECN-CE-marked packets MUST \u00a0 \u00a0 \u00a0 result in additional early or immediate ECN feedback packets being \u00a0 \u00a0 \u00a0 sent unless no timely feedback is required. There are no specification in this document that says that on reception of ECN-CE marks the feedback packet should be sent using early or immediate. That might not be required given a correctly configured session, where reporting occur on the time scale. However, I think some discussion of the usage of early reporting for ECN-CE mark is needed if longer reporting intervals are used.  Where there any discussion in the WG of this subject?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-09 07:38:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-09 03:01:09-07:00",
    "text": "Thank you for the work put into this document. It is really easy to read. Nevertheless, I am balloting a DISCUSS (see below), I sincerely hope that I am wrongly asserting the lack of IPv6 support for CurveCP else the easy way to clear my DISCUSS would be to mention this limitation in section 3 even if the focus of this I-D is on the API. Please find below some non-blocking COMMENTs. An answer will be appreciated. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == I question the inclusion of CurveCP in the mix as per  https://curvecp.org/addressing.html  it does not seem to support IPv6. At the bare minimum, the I-D should mention this restriction in section 3. (and I hope to be corrected about CurveCP IPv6 support).",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-12-05 09:13:11-08:00",
    "end_reason": "position_updated",
    "start": "2018-07-02 18:21:36-07:00",
    "text": "This is a process discuss: If I read things correctly, this draft purports to update an _unpublished_ RFC (i.e., another draft.). If so, can't we just correct that draft before publishing it?",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-01-09 06:40:30-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-05 04:35:56-08:00",
    "text": "Thank you for working on this important spec. I would like to recommend its approval, but before that I had a request for a clarification, inspired by Orit Levin's Gen-ART review. In Section 5.1, what specifically is the requirement regarding OSPF TTZ/TTZID uniqueness. It just says \"unique within a network\". For instance, if I have TTZID 17 under Area 0 and Area 223 among the same set of routers implementing multiple Areas simultaneously, is that allowed? Or are different Areas automatically different networks? Can you specify an algorithm or rule, or make the current wording more precise?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-24 08:10:37-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-16 04:39:34-07:00",
    "text": "I'm not sure that the answer to this question will require any change to the document but wanted to check...  I wondered about the privacy properties of these (and related) WebRTC identifiers, esp. if they are being handled at various different layers. Is there work somewhere in the WebRTC space that's analysing that? For example, one concern might be that msid-appdata could end up with some kind of privacy sensitive value, but there's no guidance here about that and as the examples use UUIDs it's not clear to me those represent nor what typical values will be used. (Note: I'm not saying that I believe this is a problem, I'm just checking if it's been considered.) I hope that there's no reason why these can't be very ephemeral values that don't identify (or help re-identification of) people or their preferences, locations etc., and I'd imagine there's little reason to e.g. log them. If that's the case wouldn't it be useful to add such guidance (somewhere, maybe not here) to help developers to do the right thing?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-04-18 08:33:08-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-04-18 08:32:30-07:00",
    "text": "[Authors:\u00a0 Thank you for the work!\u00a0 There's no action required from you.\u00a0 My opinion below is to be discussed with the IESG.] I found this document very informative, and there is value in publishing it as an RFC.\u00a0 However, I don't believe it can pass the rough consensus bar set by rfc8789  to become an IETF Stream RFC. As mentioned by the Shepherd, this document is a \"description by matter specialists of an externally-defined link-layer\".\u00a0 The technology described is an overview of work done elsewhere.\u00a0 There was no discussion of the content on the mailing list, which shows only two messages from non-authors: one asking  for more information; the reply was a pointer to the LDACS external  specification [1] -- the other was the single WGLC reply from the document shepherd [2]. I want to discuss this question with the IESG:\u00a0 Can the IETF reach rough consensus on a document that describes someone else's technology?\u00a0 This  document is akin to many others that have been published through the ISE as,  for example, a vendor's implementation of a specific protocol.\u00a0  My opinion is that documents that describe someone else's technology cannot be published as IETF RFCs given the requirement in  rfc8789 . [1]  https://mailarchive.ietf.org/arch/msg/raw/iyext4Ub8MgUjNYYPE7XOPpq1Y0 [2]  https://mailarchive.ietf.org/arch/msg/raw/L-ByflWTn_3vcGC8NNfMO-blkJU",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-05-12 06:30:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-04-18 08:33:08-07:00",
    "text": "[Authors:\u00a0 Thank you for the work!\u00a0 There's no action required from you.\u00a0 My opinion below is to be discussed with the IESG.] I found this document very informative, and there is value in publishing it as an RFC.\u00a0 However, I don't believe it can pass the rough consensus bar set by rfc8789  to become an IETF Stream RFC. As mentioned by the Shepherd, this document is a \"description by matter specialists of an externally-defined link-layer\".\u00a0 The technology described is an overview of work done elsewhere.\u00a0 There was no discussion of the content on the mailing list, which shows only two messages from non-authors: one asking  for more information; the reply was a pointer to the LDACS external  specification [1] -- the other was the single WGLC reply from the document  shepherd [2]. I want to discuss this question with the IESG:\u00a0 Can the IETF reach rough consensus on a document that describes someone else's technology?\u00a0 This  document is akin to many others that have been published through the ISE as,  for example, a vendor's implementation of a specific protocol.\u00a0  My opinion is that documents that describe someone else's technology cannot be published as IETF RFCs given the requirement in  rfc8789 . [1]  https://mailarchive.ietf.org/arch/msg/raw/iyext4Ub8MgUjNYYPE7XOPpq1Y0 [2]  https://mailarchive.ietf.org/arch/msg/raw/L-ByflWTn_3vcGC8NNfMO-blkJU",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-10-25 09:09:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-12 06:30:47-07:00",
    "text": "[I'm updating the text of my DISCUSS ballot from Apr/18.\u00a0 This is a clarification  to avoid misinterpretations when considering the ballot in a general context.] [Authors:\u00a0 Thank you for the work!\u00a0 There's no action required from you.\u00a0 My opinion below is to be discussed with the IESG.] I found this document very informative, and there is value in publishing it as an RFC.\u00a0 However, I don't believe it can pass the rough consensus bar set by rfc8789  to become an IETF Stream RFC. As mentioned by the Shepherd, this document is a \"description by matter specialists of an externally-defined link-layer\".\u00a0 The technology described is an overview of work done in another standards development organization (SDO)  [1].\u00a0 There was no discussion of the content on the mailing list, which shows  only two messages from non-authors: one asking for more information; the reply  was a pointer to the LDACS external specification [2] -- the other was the  single WGLC reply from the document shepherd [3]. I want to discuss this question with the IESG:\u00a0 Can the IETF reach rough consensus on a document that describes technology developed by a different  SDO?\u00a0  My opinion is that documents that describe technology developed by a different  SDO cannot be published as IETF RFCs given the requirement in  rfc8789 . [1]  https://www.ldacs.com/wp-content/uploads/2013/12/SESAR2020_PJ14_D3_3_030_LDACS_AG_Specification_00_02_02-1_0.pdf [2]  https://mailarchive.ietf.org/arch/msg/raw/iyext4Ub8MgUjNYYPE7XOPpq1Y0 [3]  https://mailarchive.ietf.org/arch/msg/raw/L-ByflWTn_3vcGC8NNfMO-blkJU",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-11-06 11:31:16-08:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 08:39:25-07:00",
    "text": "Firstly thank you to the authors of the document for the good work. I however must agree with Alvaro's ballot and further expand on it.\u00a0 I have a concern that publishing a document that merely describes an outside standard, that is not developed within the IETF, could open a significantly problematic door to people developing standards outside of the IETF, and then using a mechanism like this, to effectively get a rubber stamp on something that the IETF has no control over.\u00a0 To me, this document would seem better suited to the ISE rather than the IETF track.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-10-21 06:50:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 01:41:13-07:00",
    "text": "Thank you for the work put into this document. It is also important for the IETF to welcome new work. The content is really interesting to read (especially for a private pilot!); albeit, it appears more like a roadmap / plan to use IETF protocols for aviation rather than being focused only on LDACS. Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. I also support Alvaro Retana's DISCUSS on using the right publication stream, which should have been ISE in this case as often done for documents describing specifications done outside the IETF. I notice that this document as an \"unknown\" status for the consensus boilerplate and setting it to \"No\" (if possible) would probably address Alvaro's concern. Special thanks to: - Pascal Thubert for the shepherd's write-up including the WG consensus and the intended status.  - Carlos Bernardos for his INT directorate review at  https://mailarchive.ietf.org/arch/msg/int-dir/oRK9fXWx48Xj6VhdJMMarEPFB3c/  which also raises the same issue as Alvaro but also has other points deserving a reply I hope that this helps to improve the document, Regards, -\u00e9ric As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 4 Raising a DISCUSS just to get a discussion with authors, RAW WG, ICAO representatives, and the community: \u00a0 \"There is currently no \"IPv6 over LDACS\" specification \u00a0  publicly available; however, SESAR2020 has started the testing of \u00a0  IPv6-based LDACS testbeds.\" Is the plan to have this \"IPv6 over LDACS\" be specified in an IETF WG (e.g., intarea) ? Or will ICAO work alone on this specification (and perhaps not using the experience of the IETF community)? ## Section 5.2.1 Let me share Carlos' point, which I second (it would be enough to state the intention about MIPv6 to address it): - \"Technically the FCI multilink concept will be realized by multi-homed mobile IPv6 networks in the aircraft.\" --> how is Mobile IPv6 going to be used and which specific protocol of the Mobile IPv6 family? just MIPv6 and/or PMIPv6? implications on mobility and RAW are unclear at this point (probably this is for the RAW WG to evaluate, but just wanted to point it out).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-31 19:29:57-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 20:23:57-07:00",
    "text": "** With the upfront acknowledgement that I have little familiarity with LDACS, I had significant difficulty in assessing the alignment of most this document to the defined charter of RAW.\u00a0 It appears to me that only a narrow portion of the document is in-charter scope. References were provided for LDACS (e.g., [ICAO2015]), but as they were behind a paywall I was not able to review them.\u00a0 Relying primarily on Section 7.3 and Figure 3 of the [MAE20192], it appears that LDACS is a series of technologies that operate below layer-3.\u00a0 Operating on top of LDACS at layer3+ is the FCI.\u00a0 Section 4 reminds us that \u201cThe IPv6 architecture for the aeronautical telecommunication network is called the FCI.\u201d\u00a0  Per the RAW charter, \u201cRAW will stay abstract to the radio layers underneath, addressing the Layer 3 aspects in support of applications requiring high reliability and availability.\u201d\u00a0 With that in mind, I was looking for the in scope RAW work items to produce \u201cUse Cases, Requirements, Architecture/Framework Aspects for a Wireless Network, and an Evaluation of Existing IETF Technologies and Gap Analysis\u201d for technologies at or above layer 3.\u00a0 In Section 5.2.3, I first found specifics on FCI that appear to a use cases within that scope.\u00a0 In Section 7.3.3,\u00a0 there is text on the SNP which describes activity germane to handling layer-3 services.\u00a0 However, this section also excludes this work as out of scope -- \u201c[t]his work is ongoing and not part of this document.\u201d In my assessment the overwhelming majority of the text in this document is describing technologies and architecture not in RAW\u2019s in-scope remit of layer 3+.  If the WG finds documenting this otherwise paywalled information in an information document valuable, I see no issue keeping this material in an Appendix.\u00a0 However, the framing of this document needs to be clearer to highlight the in-scope materials around FCI. ** Section 9.\u00a0 Please explicitly document the Security Considerations of FCI (i.e., the IPv6/layer behaviors).\u00a0 Is that Section 9.2? -- Section 9, Per \u201cThese requirements imply that LDACS must provide layer 2 security in addition to any higher layer mechanisms\u201d, it isn\u2019t clear how this is in-scope given the remit of RAW (see above). -- Section 9.1 is helpful background but what of that applies to layer 3?\u00a0 The specifics in the threat analysis of [STR2016] and the advent of SDRs appears to be largely data link considerations. -- Section 9.2\u00a0 How does [MAE20181] inform layer 3 threats as it\u2019s explicitly focused on data link issues? -- Section 9.3.\u00a0 Which of these security objectives apply to the FCI? -- Section 9.5.3.\u00a0 Architecturally, it isn\u2019t clear how IPSec, TLS are being used by the FCI.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-03-10 02:50:56-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-07 08:46:13-08:00",
    "text": "Hopefully an easy one to fix or clarify: \u00a0  *\u00a0 The set of numbers is converted into a single number REST-method- \u00a0 \u00a0 \u00a0 set by taking each number to the power of two and computing the \u00a0 \u00a0 \u00a0 inclusive OR of the binary representations of all the power \u00a0 \u00a0 \u00a0 values. I just wanted to check that this is expressed the right way round?\u00a0 I read \"taking each number to power of two\" as meaning taking the square of each method number.\u00a0 Whereas, I would have assumed that what you mean is \"two to the power of each method number\", i.e., each REST method is indicated by a binary bit position in a potentially 64 bit number? E.g., a/led should be 2^0 | 2^2 = 5",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-06-03 07:50:59-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 05:43:41-07:00",
    "text": "Thank you for the work on this document. (This is a \"let's talk\" DISCUSS, which I don't expect to hold after the telechat) I wonder if it wouldn't make sense to add a step where IANA gets the help of the designated experts from each respective registry when elements are added to the DNS class or RR type registries, either by the experts creating the substatements to be added, or at least checking and confirming those created by IANA. A couple of minor comments below. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-06-17 01:37:06-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-03 04:16:19-07:00",
    "text": "Hi, One issue that I think we should should discuss and resolve (sorry for the late discuss ballot): In section 4, it states: \u00a0  \"status\":\u00a0 Include only if a class or type registration has been \u00a0 \u00a0 \u00a0 deprecated or obsoleted.\u00a0 In both cases, use the value \"obsolete\" \u00a0 \u00a0 \u00a0 as the argument of the \"status\" statement. I know that we have had some previous discussion on this on Netmod, but, if  draft-ietf-netmod-yang-module-versioning-02  gets standardized then it will effectively evolve YANG's \"status deprecated\" into \"must implement or explicitly deviate\" and YANG's \"status obsolete\" into \"must not implement\".\u00a0 It wasn't clear to me that marking one of these fields as being deprecated in an IANA registry would mean that existing implementations must stop using it if they migrate to a new version of the generated YANG module.\u00a0 Hence, I think that at this stage, it may be safer to map IANA \"deprecated\" into YANG's \"status deprecated\"?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-12-02 14:36:28-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-12-02 14:35:55-08:00",
    "text": "Apologies for changing to DISCUSS after my initial NO OBJECTION position, but I just realized an implication to my comment about copying the IKEv2 text: The shepherd's write up says \"It is the proper type of RFC because the document describes implementation recommendations for a proposed standard and is not a proposed standard in itself.\". But this document does not merely make recommendations; it claims to stand alone as a full specification of everything needed to for a minimal implementation that works with IKEv2.\u00a0 I'd like to discuss why this should not be standards track, as it's currently written.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-12-02 14:37:33-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-12-02 14:36:28-08:00",
    "text": "Apologies for changing to DISCUSS after my initial NO OBJECTION position, but I just realized an implication to my comment about copying the IKEv2 text: The shepherd's write up says \"It is the proper type of RFC because the document describes implementation recommendations for a proposed standard and is not a proposed standard in itself.\". But this document does not merely make recommendations; it claims to stand alone as a full specification of everything needed\u00a0 for a minimal implementation that works with IKEv2.\u00a0 I'd like to discuss why this should not be standards track, as it's currently written.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-12-04 15:26:41-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-02 14:37:33-08:00",
    "text": "Apologies for changing to DISCUSS after my initial NO OBJECTION position, but I just realized an implication to my comment about copying the IKEv2 text: The shepherd's write up says \"[Informational] is the proper type of RFC because the document describes implementation recommendations for a proposed standard and is not a proposed standard in itself.\". But this document does not merely make recommendations; it claims to stand alone as a full specification of everything needed\u00a0 for a minimal implementation that works with IKEv2.\u00a0 I'd like to discuss why this should not be standards track, as it's currently written.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-10 14:17:53-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-03 06:57:11-08:00",
    "text": "I'll be a yes ballot but I'd like to chat briefly if that's ok, just to check the level of consensus behind the algorithm choices documented here.\u00a0 For example, is A.3.2 recommending that only AES_CBC and AES-CCM_8 ought be implemented?\u00a0 And would we still recommend 1536 D-H and wouldn't 2048 by itself be sufficient? Shouldn't you be clear about that kind of stuff? (I mean what algs you're telling folks to implement in appendix A.)\u00a0 Did the WG discuss all those kinds of decision? (Or are they just what you implemented?)  The reason this is a discuss is just so that we're clear about the algorithm stuff - I suspect a bunch of folks will just do what this document says (or have already) so ensuring these choices are good ones that the WG actually thought about now is I think worthwhile.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-25 01:13:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-20 05:02:51-07:00",
    "text": "# GEN AD review of  draft-ietf-dnsop-dnssec-bcp-05 CC @larseggert Thanks to Linda Dunbar for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/TNMpPSf36E8i5Nt96FoRSlbjPFA ). ## Discuss ### \"Abstract\", paragraph 1 ``` \u00a0 \u00a0  This document describes the DNS security extensions (commonly called \u00a0 \u00a0  \"DNSSEC\") that are specified RFCs 4033, 4034, 4035, and a handful of \u00a0 \u00a0  others.\u00a0 One purpose is to introduce all of the RFCs in one place so \u00a0 \u00a0  that the reader can understand the many aspects of DNSSEC.\u00a0 This \u00a0 \u00a0  document does not update any of those RFCs.\u00a0 Another purpose is to \u00a0 \u00a0  move DNSSEC to Best Current Practice status. ``` I don't understand what \"move DNSSEC to Best Current Practice status\" means in terms of the standards track. I'm all for advancing the RFC set that makes up DNSSEC along the standards track, but BCP it not part of that track. Publishing a BCP that normatively references some DNSSEC RFCs isn't doing anything in terms of moving them forward. ### Section 1.1, paragraph 2 ``` \u00a0 \u00a0  The DNSSEC set of protocols is the best current practice for adding \u00a0 \u00a0  origin authentication of data in the DNS.\u00a0 To date, no standards- \u00a0 \u00a0  track RFCs offer any other method for such origin authentication of \u00a0 \u00a0  data in the DNS. ``` Just because no other standards track RFCs compete with DNSSEC does not mean it is a BCP. A BCP is something else, i.e. \"The BCP subseries of the RFC series is designed to be a way to standardize practices and the results of community deliberations.\" [ RFC2026 ] ### Section 1.1, paragraph 1 ``` \u00a0 \u00a0  However, this low level of implementation does not affect whether \u00a0 \u00a0  DNSSEC is a best current practice; it just indicates that the value \u00a0 \u00a0  of deploying DNSSEC is often considered lower than the cost. ``` Protocols aren't BCPs. HTTP isn't the \"best current practice\" for transporting HTML either.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-10-19 23:01:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-17 18:07:41-07:00",
    "text": "Since  draft-ietf-dnsop-rfc5933-bis  is in IETF Last Call now, I think it is worth waiting on and updating this text: \u00a0  The GOST signing algorithm [ RFC5933 ] was also adopted, but \u00a0  has seen very limited use, likely because it is a national algorithm \u00a0  specific to a very small number of countries. To add a reference that RFCXXX updates the GOST algorithms for DNSSEC (but that it is uncertain at this point whether it will be widely adopted) I could be convinced for this document to not wait, but then I do think this paragraph should state that it is NOT RECOMMENDED to implement  RFC5933  since the underlying GOST algorithms have been deprecated by its issuer.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-06 11:45:03-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-06 11:08:42-08:00",
    "text": "I'd like to have a brief discussion about a few points, though it's not clear that any change to the document will be required (details in the COMMENT section for all of these): Mutually-verifiable \"secure mode\" seems to require that the peer's browser be included in the TCB, which is a bit hard to swallow.\u00a0 Are we comfortable wrapping that in alongside \"we trust the peer to not be malicious\"? It's not clear how much benefit we can get from *optional* third-party identity providers; won't the calling service have the ability to silently downgrade to their non-usage even if both calling peers support it?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-03-07 05:12:58-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-28 08:46:52-08:00",
    "text": " think this document is clearly informational. Other RTCweb documents should refer this document informatively and only reference the sec arch doc normatively.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-10-11 07:30:18-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-10 13:43:42-07:00",
    "text": "This is a process discuss, or maybe a discuss discuss. I expect to clear it once a discussion has occurred regardless of the outcome, but I want to make sure the discussion happens. \u00a72 contains the following paragraph: \"\u00a0 The readers are assumed to be familiar with IEEE 1588-2008. As all \u00a0  PTP terminologies and PTP data set attributes are described in \u00a0  details in IEEE 1588-2008 [IEEE1588], this document only outlines \u00a0  each of them in the YANG module.\" If I understand correctly, IEEE 1588-2008 is not available without payment. If so, then I don't see how we can assume that reviewers of this draft are actually familiar with IEEE 1588-2008. It seems like that makes it hard for the draft to get sufficient review to be considered a standards-track IETF consensus document. I recognize that we do not have a policy against normative references to paywalled sources, but I read the disclaimer to make the IEEE document more foundational than just any normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-11 10:35:55-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-11 06:50:57-07:00",
    "text": "I appreciate that there has been some previous work in this area, but it seems that there are still many instances of bare integral types with no  indication of what units are used to report a numerical value, whether larger or smaller priority values indicate a more preferred status, how the sign of an \"offset\" measurement should be interpreted, etc.\u00a0 This leaves the specification unimplementable in an interoperable way.\u00a0 A (possibly incomplete) list of such values includes: clock-class (is this really more like an enum than an int?) clock-accuracy (ditto?) offset-scaled-log-variance priority1 (are small or large values more-preferred?) priority2 (ditto) offset-from-master (interpretation of sign bit) observed-parent-offset-scaled-log-variance observed-parent-clock-phase-change-rate grandmaster-priority1 grandmaster-priority2 current-utc-offset (sign bit) time-source (is this more like an enum?) log-min-delay-req-interval (units have to be scaled out before log operation) log-announce-intervale (ditto) log-sync-interval (ditto) log-min-pdelay-req-interval (ditto, two different nodes)",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2019-01-29 04:32:10-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-11 07:04:35-07:00",
    "text": "The model was not reviewed by YANG doctors, at least there is no record of such review. It should be, especially given the subject area of the model is not a native IETF technology.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-11-16 19:15:31-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-13 02:22:20-07:00",
    "text": "To IESG: Is this just me or do other people find it to be quite confusing why information such as URIs and JSON blobs can be included in LISP mapping database? I admit that this might be just my ignorance of LISP, but the document Introduction (or Abstract) doesn't explain the need.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-10-14 12:07:25-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-13 01:48:17-07:00",
    "text": "Thanks for writing this doc. I plan to recommend its approval, but there were a couple of things that I think should be fixed for clarity before issuing the RFC. First, I agree with Peter Yee who did a Gen-ART review on this document: > Page 6, Rsvd2 definition: the definition both says \"reserved for future use\" > and then says some types actually use it.\u00a0 That sounds like present use. > And to generically say that it should be sent as zero and ignored, but then > to give uses (such as Type 2)\u00a0 for it\u00a0 is confusing.\u00a0 I suggest rethinking > the wording here. The type that seems to differ from the \"ignore\" advice in Section 3 is Type 14. Perhaps you can reword somehow, or name the Rsvd2 field to Flags, and let the Subsections define that as \"set to 0 and ignore on receipt\". Or something along those lines? I also agree with this comment and believe the text should be corrected: > Page 6, Length definition: there's mention of a \"Reserved\" field that's > included in the minimum length of 8 bytes that are not part of the length > value.\u00a0 Since there are actually Rsvd1 and Rsvd2 fields in the generic > version of the LCAF and sometimes even Rsvd3 and Rsvd4 fields when using > specific Types, it might be better to spell out which reserved fields (Rsvd1 > and Rsvd2) are meant here rather than giving the field a summary name that > doesn't actually appear in the format.\u00a0 This is also important because any > Rsvd3 and Rsvd4 fields are included in the Length field, so using a generic > \"Reserved\" description is ambiguous at best. And this seems like a bug as well: > Page 13, RTR RLOC Address definition, 4th sentence: The ability to determine > the number of RTRs encoded by looking at the value of the LCAF length > doesn't seem feasible.\u00a0 3 IPv4 RTR RLOCs will produce the same LCAF Length > as 1 IPv6 RTR RLOC.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-11-07 16:35:52-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-13 06:05:07-07:00",
    "text": "I basically support Alexey's discuss position and Ben's comment but with a bit more detail below. - section 3: I don't see how you can produce a canonical order of the LCAF encodings if two can contain e.g. the same values other than different URLs, since there is no canonical way to order URLs (or JSON structures etc.) without a lot more specification. - 4.3: I agree with Ben's comment. You ought include some text here to the effect that this information can be privacy senseitive and to recommend not sending or storing it in such cases. - 4.4: there are also potential privacy issues here if this could be used to identify traffic that is from one specific host behind a NAT. A similar privacy warning should be included. - 4.7: Sorry, when is key material sent in a message? How is that protected? (Key ids are fine, but not key values) - 4.10.2: The same privacy issues apply here as for 4.3 and 4.4, if the MAC address maps to e.g.\u00a0 a portable device carried by a person. - 4.10.3 and all of section 5: What are these for?\u00a0 I don't see the sense in defining these if there is no well defined way to use them. Any of these might have undesirable security and/or privacy characteristics. - Section 6: There are security considerations.\u00a0 See above.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-01 13:54:38-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-07 16:35:52-08:00",
    "text": "(More mail sent for -20, basically discussion continues) I basically support Alexey's discuss position and Ben's comment but with a bit more detail below. - section 3: I don't see how you can produce a canonical order of the LCAF encodings if two can contain e.g. the same values other than different URLs, since there is no canonical way to order URLs (or JSON structures etc.) without a lot more specification. - 4.3: I agree with Ben's comment. You ought include some text here to the effect that this information can be privacy senseitive and to recommend not sending or storing it in such cases. - 4.4: there are also potential privacy issues here if this could be used to identify traffic that is from one specific host behind a NAT. A similar privacy warning should be included. - 4.7: Sorry, when is key material sent in a message? How is that protected? (Key ids are fine, but not key values) - 4.10.2: The same privacy issues apply here as for 4.3 and 4.4, if the MAC address maps to e.g.\u00a0 a portable device carried by a person. - 4.10.3 and all of section 5: What are these for?\u00a0 I don't see the sense in defining these if there is no well defined way to use them. Any of these might have undesirable security and/or privacy characteristics. - Section 6: There are security considerations.\u00a0 See above.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-10-13 07:04:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-11 18:19:13-07:00",
    "text": "The way that the length field is specified in this document is inconsistent, extremely confusing and sometimes wrong.  e.g. In Section ASCII Names in the Mapping Database  Length value n:\u00a0 length in bytes AFI=17 field and the null-terminated ASCII string (the last byte of 0 is included). but the field mentions 2+n. Only one of these can be correct Similarly in Section 4.9.\u00a0 Replication List Entries for Multicast Forwarding \u00a0  Length value n:\u00a0 length in bytes of fields that follow. but the field mentions 4+n. Again one of these can be correct. Similar error in Section 5.2 (Generic Database Mapping Lookups) * Section 4.10.4.\u00a0 Using Recursive LISP Canonical Address Encodings The \"IP TOS, IPv6 QQS or Flow Label\" field is underspecified and cannot be implemented in an interoperable manner. There are multiple ways to encode the 8 bit values (the IP TOS and the IPv6 Traffic Class) into the 24 bit field. Similarly, there are at least two obvious ways to encode the 20 bit flow label into this field. Also the \"IPv6 QoS\" needs to be renamed to \"IPv6 Traffic Class\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-28 15:09:56-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-28 14:23:30-08:00",
    "text": "Section 5 refers to a \"max_packet_size\" transport parameter but I do not see that parameter defined in the registry or  RFC 9000 . It seems that a transport parameter of that name was present in earlier versions of  draft-ietf-quic-transport , but got renamed to max_udp_payload_size in the -28, so hopefully this is just a trivial rename.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-22 06:35:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-14 14:15:17-07:00",
    "text": "Its is good to see that this document has continued to improve since I read the early versions. However, there are some one issues we do need to discuss if they should be better handled before this document is ready for publication.  A significant security vunerability in PERC that should be made more explicit and is totally missing is the risks with compromised endpoints. Beyond the very evident thing that this endpoint can decrypt all media it receives there are far more sinister risk here. Namely the potential for injection of media that attempts to impersonate another endpoints media stream. Most of SRTP's cipher suits only use symmetric crypto functions, thus enabling anyone with the key to send a packet with any SSRC, and have that being accepted as that source. Where it is has no practical usage in point to point communication, in conferencing it becomes an issue. It allows the usage of media level replay or deep fakes to be used to create media streams that are injected into the media distributors using an SSRC of another endpoint.  The mitiagations that are missing from this document. The fact that a media distributor that is not compromised or collaborating with the compromised endpoint could actually prevent such media injection by applying source filtering of SSRCs and drop all that aren't associated with the endpoint. The other potential mitigation is to introduce another cipher suit that uses a non symmetric integrity protection mechanism, such as TESLA to prevent this type of injection.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-05 13:42:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 18:52:28-07:00",
    "text": "I support Magnus\u2019s DISCUSS about the need to further discuss the impact of a compromised/rogue end-point.\u00a0 In addition to the impersonation of others in the conference, I am wondering about the impact (perhaps a DoS?) of rogue client flooding the conference with EKT Key updates.",
    "type": "Discuss"
  },
  {
    "ad": "Adrian Farrel",
    "end": "2015-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2015-03-03 14:09:09-08:00",
    "text": "Thank you for this document. It is really helpful to have a clear introduction to LISP, and I appreciate the hard work that has gone into producing this text. I have a small Discuss that is easily fixed. The essence is that you  should limit this document to a description of LISP and not try to use it to bash other solutions. In Section 4.2 \u00a0  On the contrary BGP is a \u00a0  push architecture, where the required network state is pushed by \u00a0  means of BGP UPDATE messages to BGP speakers. You will be aware of  RFC 5291  and the use of ORF to make BGP a pull-mode protocol. (I won't say to you that LISP is push mode because a Map-Reply pushes  the mapping information from the map server to the client :-) So, my advice is to describe LISP in this document and to not make comments about other systems. It isn't a beauty contest and it isn't wise to try to say \"my system is better/different from yours\". The solution is to just remove this sentence. Similarly in 7.1 \u00a0  BGP is the standard protocol to implement inter-domain routing.\u00a0 With \u00a0  BGP, routing information are propagated along the network and each \u00a0  autonomous system can implement its own routing policy that will \u00a0  influence the way routing information are propagated.\u00a0 The direct \u00a0  consequence is that an autonomous system cannot precisely control the \u00a0  way the traffic will enter the network. \u00a0  As opposed to BGP, a LISP site can strictly impose via which ETRs the \u00a0  traffic must enter the the LISP site network even though the path \u00a0  followed to reach the ETR is not under the control of the LISP site. Let's not get into the \"BGP this, BGP that\" debate. Just remove the  first paragraph and the first four words of the second paragraph. That way you avoid all contention and write a document about LISP.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2015-04-14 12:05:24-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 07:14:04-08:00",
    "text": "I support Adrian's discuss.\u00a0 In a similar vein: In Sec 3.2: Please either remove the claim of \"Such LISP capable routers, in most cases, only require a software upgrade.\" or explain how you can justify the need to add and remove new encapsulations and handle the various flag triggers and caching at line rate.\u00a0 There is no need for such marketing in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-04-14 13:56:06-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-04 18:08:42-08:00",
    "text": "It appears the SecDir review didn't make it to LISP list for some reason.\u00a0 There is one important security request from Radia's review and many other good suggestions. https://www.ietf.org/mail-archive/web/secdir/current/msg05415.html Expanding the Security Considerations section would be helpful, here is the background on the request: There is a security considerations section, which focuses on a class of denial of service attacks. There are presumably security considerations sections in the other documents, including one that focuses entirely on security, so it is not necessary that all security issues be brought up here. That said, I think that if you were to write an \"introduction to security considerations\", there are more important ones than the DoS threat. in particular, as a routing protocol care must be taken to make sure a bad actor cannot attract someone else's traffic with mechanisms like those we are trying to address with BGP security. Much of the routing information is maintained in a database \"like DNS\". If it *were* DNS, DNSSEC could be used to address the integrity issues. If it is home grown, some equivalent mechanism will be necessary.\u00a0 Why not use DNS?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-19 09:25:57-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-05 15:07:49-07:00",
    "text": "I must apologize first to the authors. Many months ago I promised to send a diff with language improvements, and I did not do so. Unfortunately, I do think the document needs this and the amount is too much to leave on the RFC Editor. I will send a separate diff for language improvements to the authors and not further comment on language in my ballot here. [1] Section 2: It suggests a partial SPI match can be used, based on the assumption that the SPI number is known to have mostly zeros because the device only uses a hardcoded limited set (eg 257 to 260). While this is true for the outbound SPI, this may not be true for the inbound SPI, especially if the peer is not a \"minimal ESP\" device but a regular multipurpose OS. I think some clarification is needed for this minimum implementation optimization. [2] Section 2.1: \u00a0 \u00a0 \u00a0  SPI that are not randomly generated over 32 bits may lead to privacy \u00a0 \u00a0 \u00a0  and security concerns. The \"may lead to security concerns\" would be something that at the very least needs to be understood and specified in the Security Considerations section. If it is too difficult to determine the concerns, perhaps this optimization should be removed from the draft. \u00a0 \u00a0 \u00a0  As a result, the use of alternative designs requires careful security \u00a0 \u00a0 \u00a0  and privacy reviews. If it is known this proposal requires careful security reviews, were these done? If so, why not replace this warning of danger with the actual output of those reviews? If reviews were not done, it would imply this document hasn't fully worked out its Security Considerations. [3] \u00a0 \u00a0 \u00a0  SPI can typically be used to implement a key update What is a \"key update\" in this context? It seems this section is suggesting to use part of the SPI octet space to signal things to another part of the code on the device? If so, would that code part then clear out those overloaded SPI octets or would they go (unencrypted!) over the network for everyone to see? [4] \u00a0 \u00a0 \u00a0  While the use of randomly generated SPIs may reduce the leakage or \u00a0 \u00a0 \u00a0  privacy of security related information by ESP itself, these \u00a0 \u00a0 \u00a0  information may also be leaked otherwise. This is not a strong argument. This sentence and the entire paragraph really seem to want to say something like \"if you can see the network packets, the information leak would already be present by seeing the encrypted traffic, irrespective of whether the SPI is truly random or selected in a way that identifies the manufacturer\" [5] \u00a0 \u00a0 \u00a0  The security of all data \u00a0 \u00a0 \u00a0  protected under a given key decreases slightly with each message I do not know of a generic claim like this for ESP. Can a reference be provided? In general, rekeying is done to avoid decrypting previous traffic in case of a key compromise. Or perhaps you mean the limits of algorithms like AES_CBC (or 3DES) with respect to birthday and collision attacks? eg the commonly used maximum of 2^32-1 crypto operations (which is not the same as maximum packets) In these cases, the SN is only relevant for very high speed links, eg gbps and would never apply to an IoT device that requires minimal ESP. [6] As noted in the TSVART review: \u00a0 \u00a0 \u00a0  Also, for devices that spend significant time sleeping, the SN \u00a0 \u00a0 \u00a0  would jump hugely on first waking. That shouldn't require any \u00a0 \u00a0 \u00a0  larger window (unless a stale packet from prior to the sleep was \u00a0 \u00a0 \u00a0  only released after a new packet on waking). But the receiver \u00a0 \u00a0 \u00a0  would need to be able to somehow detect massive jumps in the high \u00a0 \u00a0 \u00a0  order bits that are not communicated in the SN field. Perhaps the document can add more specific detail on how to use the commonly implemented time values into valid SNs that avoid ESN issues ? [7] \u00a0 \u00a0 \u00a0  so the constrained device may not proceed to such checks The language issue here inverts the meaning. What is meant is \"so the constrained device may omit such checks\" [8] \u00a0 \u00a0 \u00a0  TFC has not yet being widely adopted for standard ESP traffic. It is widely implemented (eg in Linux). I agree that using it seems rare. I am not convinced the reason for this is as is written. The issue I think more relates to deciding to what size to pad. The easiest is to use the MTU, but due to various encapsulation techniques (ESPinUDP, PPP-OE) it is not always clear what the MTU of the IPsec link is. And path MTU discovery with IPsec does not really work in practice. But if the application/device tends to send packets between 1 and say 125 bytes, it could always pad to 125 to not leak any information by packet size. The question on when to do this or not really depends on the traffic being protected. And if this the case, then it might be best to let the IKEv2 negotiation determine whether or not to use this - just like regular use of TFC. Regardless, TFC is optional and a minimum implementation can just omit it. Since this document would also be combined with efforts reducing sending bytes to preserve energy, it would make sense to avoid using TFC padding. Especially for sensors that for example just always send a one byte temperature value to begin with. \u00a0 \u00a0 \u00a0  Such information could be used by the attacker in case a vulnerability is \u00a0 \u00a0 \u00a0  disclosed on the specific device. I don't think \"vulnerability\" here is the issue. It could lead to exposing the size of the original packet being protected by IPsec, which could (or could not) leak information to an observer on the network. [9] \u00a0 \u00a0 \u00a0  a minimal ESP implementation may not generate such dummy packet. I think what is meant is \"MUST NOT generate\". [10] The Next Header Section is better named Dummy Packet. While it discusses the mandatory Next Header field, it really only states not to send Dummy Packets. But it almost reads as if the Next Header can be ignored or omitted. [11] \u00a0 \u00a0 \u00a0  4.\u00a0 Avoid Padding by sending payload data which are aligned to \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the cipher block length - 2 for the ESP trailer. Isn't this advise just moving the padding from the IPsec layer to the application layer? Eg the packet size or energy use would not be different if one implements this advise? [12] Would it be useful to be able to signal a \"mininum ESP\" via IKEv2? I can imagine a simple Notify could be used to signal this. A peer receiving this could then ensure it is behaving in a \"minimum ESP\" compatible way even if it is a multi-purpose OS.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-12 10:39:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 19:42:05-07:00",
    "text": "** Section 5.\u00a0 The paragraph starting with \u201cAs the generation of dummy packets \u2026\u201d would benefit from refinement.\u00a0 It starts with saying dummy packets \u201cmay be avoided\u201d, but the second half of the paragraph argues the opposite.\u00a0 The use cases of constrained devices concerned about device lifetimes (first half of the paragraph) doesn\u2019t seem mutually exclusive from those with dedicated applications (second half).\u00a0 I recommend being cleared on the assumptions guiding the use of dummy packets.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-13 20:48:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-07 15:26:33-07:00",
    "text": "This being a discuss ballot notwithstanding, the protocol mechanisms here seem pretty well thought-out; I'm just wanting changes to how they are described. There seems to be an internal inconsistency in Section 4.3, between \"[t]he PCE SHOULD add the scheduled LSP into its scheduled LSP-DB and update its scheduled TED\" and \"[t]he stateful PCE is required to update its local scheduled LSP-DB and scheduled TED\".\u00a0 (I think the \"SHOULD\" one is wrong, personally.) Let's also take a closer look at the precise interdependency between the B bit and PD bit -- Section 5.1 implies that the PD bit itself cannot be set in the absence of the B bit, referring forward to Section 5.2.2, but Section 5.2.2 seems to only say that you need both the B and PD bits set in order to send SCHED-PD-LSP-ATTRIBUTE.\u00a0 Bits being set as a prerequisite for sending the TLV is a subtly different condition than having the one bit itself depend on the other, with correspondingly different error handling. Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-13 20:48:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-13 20:48:26-07:00",
    "text": "This being a discuss ballot notwithstanding, the protocol mechanisms here seem pretty well thought-out; I'm just wanting changes to how they are described. There seems to be an internal inconsistency in Section 4.3, between \"[t]he PCE SHOULD add the scheduled LSP into its scheduled LSP-DB and update its scheduled TED\" and \"[t]he stateful PCE is required to update its local scheduled LSP-DB and scheduled TED\".\u00a0 (I think the \"SHOULD\" one is wrong, personally.) Let's also take a closer look at the precise interdependency between the B bit and PD bit -- Section 5.1 implies that the PD bit itself cannot be set in the absence of the B bit, referring forward to Section 5.2.2, but Section 5.2.2 seems to only say that you need both the B and PD bits set in order to send SCHED-PD-LSP-ATTRIBUTE.\u00a0 Bits being set as a prerequisite for sending the TLV is a subtly different condition than having the one bit itself depend on the other, with correspondingly different error handling. Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 7.3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-04 18:16:39-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-13 20:48:57-07:00",
    "text": "[edited to fix a typo in the section number, but otherwise unchanged from the original position on the -19] This being a discuss ballot notwithstanding, the protocol mechanisms here seem pretty well thought-out; I'm just wanting changes to how they are described. There seems to be an internal inconsistency in Section 4.3, between \"[t]he PCE SHOULD add the scheduled LSP into its scheduled LSP-DB and update its scheduled TED\" and \"[t]he stateful PCE is required to update its local scheduled LSP-DB and scheduled TED\".\u00a0 (I think the \"SHOULD\" one is wrong, personally.) Let's also take a closer look at the precise interdependency between the B bit and PD bit -- Section 5.1 implies that the PD bit itself cannot be set in the absence of the B bit, referring forward to Section 5.2.2, but Section 5.2.2 seems to only say that you need both the B and PD bits set in order to send SCHED-PD-LSP-ATTRIBUTE.\u00a0 Bits being set as a prerequisite for sending the TLV is a subtly different condition than having the one bit itself depend on the other, with correspondingly different error handling. Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 7.3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-07 17:44:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-04 18:16:39-07:00",
    "text": "Thanks for addressing my first two discuss points from the -19; it looks like the last one is still remaining (please note that I had a typo in my original ballot on the -19, referring to a section 3.3 when 7.3.3 was intended): Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 7.3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-05-12 07:22:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-12 02:52:25-07:00",
    "text": "I've been sitting trying to work out in my mind if a BCP document should be requesting code points - and if I should change the position from a no objection to a discuss - and the more I think about this - I feel that a discuss here is probably the right option.  I'd like to discuss if both the sections of the document that utilize normative language and require additional code points aren't better suited to a standards track document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-05-29 12:09:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-10 11:23:14-07:00",
    "text": "#1:\u00a0 This document updates  RFC 5155  but has no Updates: clause and no reference of this in the Abstract. In case this would not be seen as an Update:able offense, then the text \"Note that this specification updates [ RFC5155 ]\" should be changed :)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-07-19 06:53:38-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-18 15:00:21-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3169 I am marking this DISCUSS because it appears to endorse Random padding, which is known to be an unsafe practice. DETAIL S 4.2.2. >\u00a0 \u00a0 \u00a0 Disadvantage: This policy requires a good source of (pseudo) random >\u00a0 \u00a0 \u00a0 numbers which can keep up with the required message rates. >\u00a0 \u00a0 \u00a0 Especially on busy servers, this may be a hindrance. >\u00a0   >\u00a0 \u00a0 \u00a0 According to the limited empirical data available, Random Length >\u00a0 \u00a0 \u00a0 Padding performs slightly worse than Block Length Padding. Random padding allows an attacker who can observe a large number of requests to infer the length of the original value by observing the distribution of total lengths.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-10-28 02:09:22-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-12 11:25:54-07:00",
    "text": "Thank you for a well written document. I have a few minor points which I would like to discuss before recommending approval of this document: 1) In 2.4: TLS server identity verification using  RFC 6125  is underspecified. Please provide all details as described in Section 3 of  RFC 6125 , in particular, please specify which of CN-ID, DNS-ID, SRV-ID, URI-ID are allowed/required and whether wildcards are allowed in them. 2) In 3.5.3.1: api-path is using \"|\" instead of \"/\" for alternatives. The \"*\" must be before a rule, not after it. It looks like the ABNF was not validated with a tool, so there might be other errors in it. 3) In 4.6:  ... server MUST support the PATCH method. ... . It is optional to implement by the server.  - These statements seem to be in conflict. 4) In 5.2: The server is only required to implement one of XML / JSON. Does this mean that a compliant client need to support both in order to achieve interoperability? The document doesn't say that.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-08-30 07:14:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-29 21:48:26-07:00",
    "text": "Thanks for all the work that everyone has put into this protocol. I'm excited by what it's been able to do for the certificate issuance sector as a whole, and truly appreciate all of the early implementors who have put both clients and servers into active production. I'm definitely balloting YES once we get clarity on my DISCUSS, below. --------------------------------------------------------------------------- I've looked at this several different ways, and I must be missing something obvious -- which should make this easy to clear. \u00a76.2: >\u00a0 Note that authentication via signed JWS request bodies implies that >\u00a0 GET requests are not authenticated.\u00a0 Servers MUST NOT respond to GET >\u00a0 requests for resources that might be considered sensitive.\u00a0 Account >\u00a0 resources are the only sensitive resources defined in this >\u00a0 specification. This doesn't seem correct. For example, let's imagine that I, as a user, get the directory for an ACME server, the body of which is the example in \u00a77.1.1. Then, I go through the new-account process, and receive the Account object in \u00a77.1.2: \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  \"contact\": [ \u00a0 \u00a0 \u00a0  \"mailto: cert-admin@example.com \", \u00a0 \u00a0 \u00a0  \"mailto: admin@example.com \" \u00a0 \u00a0  ], \u00a0 \u00a0  \"termsOfServiceAgreed\": true, \u00a0 \u00a0  \"orders\": \" https://example.com/acme/acct/1/orders \" \u00a0  } Huh. Suddenly, I'm not so interested in *my* orders, because I've noticed that different users' orders are apparently at a predictable URL that varies only by a small integer. Curious, I change the \"1\" to a \"2\" and send: \u00a0 GET /acme/acct/2/orders HTTP/1.1 \u00a0 Host:  example.com And get back not *my* orders, but someone *else's* orders. \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"orders\": [ \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/1 \", \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/2 \", \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/3 \", \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/4 \" \u00a0 \u00a0  ] \u00a0  } Interesting. So now I can do four more unauthenticated GETs and grab those order objects. \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"dns\", \"value\": \"smithforcongress.example\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/1234 \" \u00a0  } ---------- \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"dns\", \"value\": \"something-embarassing-with-goats.example\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/5678 \" \u00a0  } ---------- \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"email\", \"value\": \"smith-personal@obscure-domain.example\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/9abc \" \u00a0  } ---------- \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"tn\", \"value\": \"+12025550172\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/defg \" \u00a0  } So now I've learned that the same account has pulled certs for both \"smithforcongress.example\" and \"something-embarassing-with-goats.example\"; that they have control over the email address \"smith-personal@obscure-domain.example,\" and that their phone number is +1 202 555 0172. There's a pretty good chance that... someone didn't want all of that to be generally known. And... huh... that's interesting. \u00a0 \u00a0  GET /acme/cert/9abc HTTP/1.1 \u00a0 \u00a0  Host:  example.com \u00a0 \u00a0  HTTP/1.1 200 OK \u00a0 \u00a0  Content-Type: application/pem-certificate-chain \u00a0 \u00a0  Link: ;rel=\"index\" \u00a0 \u00a0  -----BEGIN CERTIFICATE----- \u00a0 \u00a0  [X.509 Cert for smith-personal@obscure-domain.example] \u00a0 \u00a0  -----END CERTIFICATE----- \u00a0 \u00a0  -----BEGIN CERTIFICATE----- \u00a0 \u00a0  [Issuer certificate contents] \u00a0 \u00a0  -----END CERTIFICATE----- \u00a0 \u00a0  -----BEGIN CERTIFICATE----- \u00a0 \u00a0  [Other certificate contents] \u00a0 \u00a0  -----END CERTIFICATE----- Whoa. That's cool. The next thing I'm doing is configuring Thunderbird to forge mail from smith-personal@obscure-domain.example and going on an email spree admitting to owning a rather embarrassing domain name, in which I ask concerned constituents to call me on my unlisted phone number to discuss the issue. Clearly I've missed something, because this just seems way too obvious. What prevents this attack (or a similar one from observing that the order URLs are predictable?) If I *haven't* missed something, then there appears to have been an assumption here, never written into the document, that the URLs generated for the orders list and for the order objects are unguessable. If that's the case, I would: (1) Expect this to be stated in section 7.1.2.1 and 7.1.3 (2) Expect a specification of a reasonable number of bits of entropy to use in \u00a0 \u00a0 orders list and order object URLs. (3) Expect the examples to show appropriately random URLs (e.g. \u00a0 \u00a0  https://example.com/acme/acct/9258fac3-7866-4922-90e6-bbd0c89e751a/orders ) (4) Expect a treatment in section 10 of the risks that might arise from third \u00a0 \u00a0 parties gaining access to orders, as doing so provides free-and-clear access \u00a0 \u00a0 to private certificates (which, for dns, can be trivially used to \u00a0 \u00a0 revoke certs; and for other types, can be used for impersonation as well) Again, I'm still expecting that I've simply missed something obvious -- I just can't for the life of me figure out what it is.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-10-16 12:11:05-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-30 07:14:20-07:00",
    "text": "Thanks for all the work that everyone has put into this protocol. I'm excited by what it's been able to do for the certificate issuance sector as a whole, and truly appreciate all of the early implementors who have put both clients and servers into active production. I'm definitely balloting YES once we get clarity on my DISCUSS, below. --------------------------------------------------------------------------- I've looked at this several different ways, and I must be missing something obvious -- which should make this easy to clear. \u00a76.2: >\u00a0 Note that authentication via signed JWS request bodies implies that >\u00a0 GET requests are not authenticated.\u00a0 Servers MUST NOT respond to GET >\u00a0 requests for resources that might be considered sensitive.\u00a0 Account >\u00a0 resources are the only sensitive resources defined in this >\u00a0 specification. This doesn't seem correct. For example, let's imagine that I, as a user, get the directory for an ACME server, the body of which is the example in \u00a77.1.1. Then, I go through the new-account process, and receive the Account object in \u00a77.1.2: \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  \"contact\": [ \u00a0 \u00a0 \u00a0  \"mailto: cert-admin@example.com \", \u00a0 \u00a0 \u00a0  \"mailto: admin@example.com \" \u00a0 \u00a0  ], \u00a0 \u00a0  \"termsOfServiceAgreed\": true, \u00a0 \u00a0  \"orders\": \" https://example.com/acme/acct/1/orders \" \u00a0  } Huh. Suddenly, I'm not so interested in *my* orders, because I've noticed that different users' orders are apparently at a predictable URL that varies only by a small integer. Curious, I change the \"1\" to a \"2\" and send: \u00a0 GET /acme/acct/2/orders HTTP/1.1 \u00a0 Host:  example.com And get back not *my* orders, but someone *else's* orders. \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"orders\": [ \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/1 \", \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/2 \", \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/3 \", \u00a0 \u00a0 \u00a0  \" https://example.com/acme/acct/2/order/4 \" \u00a0 \u00a0  ] \u00a0  } Interesting. So now I can do four more unauthenticated GETs and grab those order objects. \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"dns\", \"value\": \"smithforcongress.example\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/1234 \" \u00a0  } ---------- \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"dns\", \"value\": \"something-embarassing-with-goats.example\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/5678 \" \u00a0  } ---------- \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"email\", \"value\": \"smith-personal@obscure-domain.example\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/9abc \" \u00a0  } ---------- \u00a0  HTTP/1.1 200 OK \u00a0  Content-Type: application/json \u00a0  { \u00a0 \u00a0  \"status\": \"valid\", \u00a0 \u00a0  ... \u00a0 \u00a0  \"identifiers\": [ \u00a0 \u00a0 \u00a0  { \"type\": \"tn\", \"value\": \"+12025550172\" } \u00a0 \u00a0  ], \u00a0 \u00a0  ... \u00a0 \u00a0  \"certificate\": \" https://example.com/acme/cert/defg \" \u00a0  } So now I've learned that the same account has pulled certs for both \"smithforcongress.example\" and \"something-embarassing-with-goats.example\"; that they have control over the email address \"smith-personal@obscure-domain.example,\" and that their phone number is +1 202 555 0172. There's a pretty good chance that... someone didn't want all of that to be generally known. Clearly I've missed something, because this just seems way too obvious. What prevents this attack (or a similar one from observing that the order URLs are predictable?) If I *haven't* missed something, then there appears to have been an assumption here, never written into the document, that the URLs generated for the orders list and for the order objects are unguessable. If that's the case, I would: (1) Expect this to be stated in section 7.1.2.1 and 7.1.3 (2) Expect a specification of a reasonable number of bits of entropy to use in \u00a0 \u00a0 orders list and order object URLs. (3) Expect the examples to show appropriately random URLs (e.g. \u00a0 \u00a0  https://example.com/acme/acct/9258fac3-7866-4922-90e6-bbd0c89e751a/orders ) (4) Expect a treatment in section 10 of the risks that might arise from third \u00a0 \u00a0 parties gaining access to orders, as doing so provides free-and-clear access \u00a0 \u00a0 to private certificates (which, for dns, can be trivially used to \u00a0 \u00a0 revoke certs; and for other types, can be used for impersonation as well) Again, I'm still expecting that I've simply missed something obvious -- I just can't for the life of me figure out what it is.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-03 08:56:46-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-29 11:53:24-07:00",
    "text": "This is a great thing to have, and I intend to eventually ballot Yes, but I do have some questions that may require further discussion before this document is approved. It looks like the server returns an unauthenticated \"badSignatureAlgorithm\" error when the client sends a JWS using an unsupported signature algorithm (Section 6.2).\u00a0 What prevents an active attacker from performing a downgrade attack on the signature algorithm used? Similarly, since we include in the threat model a potentially hostile CDN/MitM between the ACME client and ACME server, can that attacker strip a success response and replace it with a badNonce error, causing the client to retry (and thus duplicate the request processing on the server)? I am not an ART AD, but there is not yet an internationalization directorate, and seeing statements like \"inputs for digest computations MUST be encoded using the UTF-8 character set\" (Section 5) without additional discussion of normalization and/or what the canonical form for the digest input is makes me nervous.\u00a0 Has sufficient internationalization review been performed to ensure that there are no latent issues in this space? Section 6.1 has text discussing TLS 1.3's 0-RTT mode.\u00a0 If this text is intended to be a profile that defines/allows the use of TLS 1.3 0-RTT data for the ACME protocol, I think you need to be more specific and say something like \"MAY allow clients to send early data (0-RTT); there are no ACME-specific restrictions on which types of requests are permitted in 0-RTT\", since the runtime configuration is just 0-RTT yes/no, and the protocol spec is in charge of saying which PDUs are allowed or not. Section 6.2 notes that servers MUST NOT respond to GET requests for sensitvie resources.\u00a0 Why are account resources the only sensitive ones? Are authorizations not sensitive?\u00a0 Or are those considered to fall under the umbrella of \"account resources\" (Section 7.1 seems pretty clear that they do not)? Section 7.1.1 discusses how the server can include a caaIdentities element in its directory metadata; does this (or anything else) need to be integrity protected by anything stronger than the Web PKI cert authenticating the HTTPS connection?\u00a0 It seems that a bogus caaIdentities value could lead to an unfortunate DoS in some cases. I am also a bit uncertain if the document is internally consistent about whether one challenge verification suffices or there can be cases when multiple challenge verifications are required for a successful authorization.\u00a0 I attmpted to note relevant snippets of the text in my comments on Section 7.1.4. I also have some important substantive comments in the section-by-section COMMENTS, since they would not in and of themselves block publication.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-01-27 10:35:04-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-15 01:19:21-08:00",
    "text": "obert Sparks' Gen-ART review comments would deserve some discussion, to make sure that we've addressed all comments received during the last call period.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-06-21 05:54:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-01 00:33:33-07:00",
    "text": "I will move to yes when the following issue is discussed. Robert Sparks' SecDir review reminded me: I am concerned by the requirement to automatically download updates from IANA. If many devices or software programs implement IODEF and start doing schema validation, this can cause DDoS attack on IANA infrastructure.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-06-24 15:43:20-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-21 05:54:29-07:00",
    "text": "I will move to yes when the following issue is discussed. Robert Sparks' SecDir review reminded me: I am concerned by the requirement to automatically download updates from IANA. If many devices or software programs implement IODEF and start doing schema validation, this can cause DDoS attack on IANA infrastructure. I am still thinking whether the new text about automatic schema updates are reasonable. I will either clear or suggest some extra text in a few days.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-07-07 14:58:04-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-31 16:23:40-07:00",
    "text": "The Confidence class as defined in 3.12.5 seems underspecified. It does not specify a max value, so some implementations might use 1 as the max while others might use 100.  It's also hard to understand how a single confidence value is supposed to be applied to elements with multiple fields, as in 3.12 and 3.29. What do I do if I have high confidence in my estimate of SystemImpact but low confidence in my estimate of MonetaryImpact?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-23 11:43:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-01 16:41:44-07:00",
    "text": "(1) 3.6: Does one confidence value apply to all of these? That seems wrong. And over-confidence is attributing threat actor identity is a real issue with real consequences, hence the discuss to make sure we bottom out on this. I think it's just too error-prone to be ablve to associate one confidence value with two things about which one can have very different concreteness. Mixing up high confidence in a campaign with a lack of confidence in threat actor identification is precisely the kind of thing that goes wrong, or that could be deliberately manipulated (for eventual media/marketing reasons). (This overlaps with but isn't quite the same as Alissa's 2nd discuss point. In this case, I'm explicitly worried about the threat actor identity confidence, as that has possibly severe impacts, so the resolution here could differ from what results from Alissa's discuss.) (2) 3.18.1 - you provide a way to specify e.g. an address and netmask, or v6 prefix. But you don't specify any way to say that some of the address (or prefix) bits are not real or are additionally masked for privacy reasons. E.g. If everyone in 2001:1:1:beef::/64 is misbehaving, but I don't (yet) want to specify the exact prefix, I might want to say \" some 2001:1:1:xxxx::/64\" is misbehaving, meaning one /64 in 2001:1:1::/48 is being bad and not the entire /48. Why is support for that not required?\u00a0 (IPFIX does have that as an option, and it's been added to CDNI too.) Same idea can apply to other address forms too.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-07 02:41:28-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-23 11:43:33-07:00",
    "text": "(1) 3.6: Does one confidence value apply to all of these? That seems wrong. And over-confidence is attributing threat actor identity is a real issue with real consequences, hence the discuss to make sure we bottom out on this. I think it's just too error-prone to be ablve to associate one confidence value with two things about which one can have very different concreteness. Mixing up high confidence in a campaign with a lack of confidence in threat actor identification is precisely the kind of thing that goes wrong, or that could be deliberately manipulated (for eventual media/marketing reasons). (This overlaps with but isn't quite the same as Alissa's 2nd discuss point. In this case, I'm explicitly worried about the threat actor identity confidence, as that has possibly severe impacts, so the resolution here could differ from what results from Alissa's discuss.) (2) Cleared",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-01-25 06:36:13-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-24 15:58:18-08:00",
    "text": "Sorry for the late DISCUSS. I'm likely to clear after discussions on the call tomorrow. I'm somewhat surprised at how much this document glosses over the (sometimes extensive) broadcast/multicast twiddling that Access Points and similar do (a fair bit of discussion of which can be found in  draft-perkins-intarea-multicast-ieee802  (which I think will be expiring) or  draft-mcbride-mboned-wifi-mcast-problem-statement ).  Simply saying: \"A feature not uncommonly found on access points e.g. is to filter broadcast and multicast traffic.\u00a0 This will potentially break certain applications or some of their functionality but will also protect the users from potentially leaking sensitive information.\" seems to be shrugging off all of the privacy benefits (or possibly harms) that this might create.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-07-05 13:09:17-07:00",
    "end_reason": "position_updated",
    "start": "2018-11-20 15:39:29-08:00",
    "text": "Thanks to everyone who worked on this document. I have a blocking issue that should be easy to resolve, and a handful of more minor issues. \u00a72.1: >\u00a0 The client makes a token exchange request to the token endpoint with >\u00a0 an extension grant type by including the following parameters using >\u00a0 the \"application/x-www-form-urlencoded\" format This document needs a normative citation for this media type. My suggestion would be to cite REC-html5-20141028 section 4.10.22.6, as this appears to be the most recent stable description of how to encode this media type. I'd love to hear rationale behind other citations being more appropriate, since I'm not entirely happy with the one I suggest above (given that it's been superseded by HTML 5.2); but every other plausible citation I can find is even less palatable (with HTML 5.2 itself having the drawback of not actually defining how to encode the media type, instead pointing to an unstable, unversioned document).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-07-08 05:54:03-07:00",
    "end_reason": "position_updated",
    "start": "2018-11-20 11:50:35-08:00",
    "text": "ection 6: The requirements around confidentiality here are weaker than in both RFC 7519 Sec. 12 and RFC 6749 Sec. 10.8. Why?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-24 11:55:55-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-11-21 05:43:38-08:00",
    "text": "It looks like allocations in the OAuth URIs registry are merely \"Specification Required\", so we should not have the expectation of WG exclusivity and thus are squatting on unallocated values here. Process-wise, that's not great and the IESG shouldn't approve a document that is squatting on codepoints. why do we allow both client authentication (i.e., using an actor token) and a distinct actor_token request parameter?\u00a0 Is it supposed to be the case that the actor_token parameter is only supplied for delegation flows?\u00a0 If so, that needs to be made explicit in the document. Are the privacy considerations (e.g., risk of a tailed per-request error_uri) relating to the use of error_uri discussed in some other document that we can refer to from this document's security considerations?\u00a0 (I say a bit more about this in my COMMENT.) Section 2.1 has: \u00a0  audience \u00a0 \u00a0 \u00a0 OPTIONAL.\u00a0 The logical name of the target service where the client \u00a0 \u00a0 \u00a0 intends to use the requested security token.\u00a0 This serves a \u00a0 \u00a0 \u00a0 purpose similar to the \"resource\" parameter, but with the client \u00a0 \u00a0 \u00a0 providing a logical name rather than a location.\u00a0 Interpretation \u00a0 \u00a0 \u00a0 of the name requires that the value be something that both the \u00a0 \u00a0 \u00a0 client and the authorization server understand.\u00a0 An OAuth client \u00a0 \u00a0 \u00a0 identifier, a SAML entity identifier [OASIS.saml-core-2.0-os], an \u00a0 \u00a0 \u00a0 OpenID Connect Issuer Identifier [OpenID.Core], or a URI are \u00a0 \u00a0 \u00a0 examples of things that might be used as \"audience\" parameter \u00a0 \u00a0 \u00a0 values.\u00a0 [...] How does the STS know what type of identifier it is supposed to interpret the provided audience value as?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-05 20:56:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-24 11:55:55-07:00",
    "text": "[early allocations have been approved] why do we allow both client authentication (i.e., using an actor token) and a distinct actor_token request parameter?\u00a0 Is it supposed to be the case that the actor_token parameter is only supplied for delegation flows?\u00a0 If so, that needs to be made explicit in the document. [suggested text forthcoming] Are the privacy considerations (e.g., risk of a tailed per-request error_uri) relating to the use of error_uri discussed in some other document that we can refer to from this document's security considerations?\u00a0 (I say a bit more about this in my COMMENT.) [better in oauth-security-topics; an external reference from this document may or may not be appropriate] [STS will be able to look up based on audience name what type/policy to use]",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-10-01 18:22:45-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-01 18:17:08-07:00",
    "text": "Thanks for the work that everyone put into this document! I have one item that needs discussion, and then a small number of very minor editorial nits. I plan to ballot YES once the issue I identify below has been addressed. 7.3: >\u00a0 In order to avoid correlation of certificates by account, if >\u00a0 unauthenticated GET is negotiated (Section 3.4) the recommendation in >\u00a0 Section 10.5 of [ RFC8555 ] regarding the choice of URL structure >\u00a0 applies, i.e. servers SHOULD choose URLs of certificate resources in >\u00a0 a non-guessable way, for example using capability URLs >\u00a0 [W3C.WD-capability-urls-20140218]. Thanks for reinforcing the privacy point from 8555 here; however, I think the situation here is substantially more sensitive. With base 8555 behavior, the existence of a URL (as can be deduced by distinguishing between 401 and 404 responses) poses a privacy risk, if parties can deduce a pattern to the URL paths, allowing correlation of users' domains. With unauthenticated GET, the ability to guess the associated URL would be incredibly dire, allowing arbitrary unauthorized parties to download the cert in question. While this may be somewhat obvious to the authors and working groups, it's the kind of thing that really needs to be spelled out in the security section, to avoid any oversight on the part of implementors. For a similar reason, I'm pretty sure that \"SHOULD\" is not the right level of requirement for unguessability. An ACME STAR service with guessable URLs may as well not perform validation at all, since it's effectively handing out everyone's cert to everyone on the Internet. Unguessability for unauthenticated GET needs to be a MUST, and the document should explain why this is a hard requirement.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-29 09:29:19-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-29 09:12:14-07:00",
    "text": "ection 6.4 and 6.6 don\u2019t seem to specify IANA registration procedure for new subregistries.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-10-21 10:16:44-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-29 09:29:19-07:00",
    "text": "Thank you for this well written document. I have one small issue that I would like to discuss before recommending approval of this document: Section 6.4 and 6.6 don\u2019t seem to specify IANA registration procedure for new subregistries.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-18 18:33:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-02 11:06:13-07:00",
    "text": "RFC 8555  (and the IANA registry) list the 'status' field of the order object as not configurable, yet we propose to configure it (in Sections 3.1.1 and 3.1.2).\u00a0 It would perhaps be possible to make this work procedurally, by updating the registry entry and maybe an Updates: header, but it may be worth a broader rethink.\u00a0 Specifically, if we add a new field to the order instead, for the cancellation URL, then we do not modify the order directly (but instead request the server to take an action that does so as a side effect), and we also can avoid state-machine concerns about attempting to enter \"canceled\" state from a state other than \"valid\" by simply not making the cancellation URL visible until the order is \"valid\". A more minor concern, but when we consider the examples in this document in conjunction with the examples in  RFC 8555  itself, we find several protocol invariants violated: we reuse a nonce for different requests, but nonces are single-use; we use the same Order URL for two different order contents, the same certificate URL for two different (star-)certificates, and (not quite a protocol invariant, but \"with very high probability\" so) the signature on a request is duplicated.\u00a0 I also note that we reuse an account URL from  RFC 8555 , which is not inherently problematic, but my suggestion would be to generate a new one to make a clean break.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-01-10 08:05:19-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-09 20:33:00-08:00",
    "text": "[This is a DISCUSS-DISCUSS, since I don't know the answer to my question. I expect to clear it after a little discussion. Likely at the first indication that one or another ADs hold the clue that I am missing :-)\u00a0 ] Is it reasonable to have a Yang module for an experimental protocol in a standards track RFC? What would that mean from a protocol maturity perspective? (I refer to the module for dense-mode PIM ( RFC 3973 ).",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2018-03-23 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-01-11 04:57:54-08:00",
    "text": "hanks to J\u00fcrgen, who reminded me that the YANG doctor feedback has not been addressed or replied to.https://datatracker.ietf.org/doc/review-ietf-pim-yang-12-yangdoctors-lc-schoenwaelder-2017-12-20/",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-08 13:21:12-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-01-08 08:55:29-08:00",
    "text": "Hello,\u00a0 Thanks for your work on this draft.\u00a0 If you could please update the draft to follow the YANG security template and be sure to list out the nodes in each of the sections if they are sensitive or security related (graceful restart could do some damage, etc.), that would resolve my discuss.\u00a0 Here's a link to the template and I'm not sure if there is a later version posted somewhere. There seems to be a number of rw in this draft (with some overlap between modules), is that why this step was left out? https://tools.ietf.org/html/rfc6087#section-6.1 Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-10 14:27:31-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 13:21:12-08:00",
    "text": "Hello,\u00a0 Thanks for your work on this draft.\u00a0 If you could please update the draft to follow the YANG security template and be sure to list out the nodes in each of the sections if they are sensitive or security related (graceful restart could do some damage, etc.), that would resolve my discuss.\u00a0 Here's a link to the template and I'm not sure if there is a later version posted somewhere. There seems to be a number of rw in this draft (with some overlap between modules), is that why this step was left out? https://tools.ietf.org/html/rfc6087#section-6.1 The update in this draft appears to be the current, but please correct me if I am wrong and there is a later template: https://tools.ietf.org/html/draft-ietf-netmod-rfc6087bis-10#page-52 Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-23 19:33:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-22 10:14:55-07:00",
    "text": "Sections 4.16 and 4.17 have some discussion that suggests that the respective extended errors apply only to the current \"local hop\" of a DNS query, and thus should not be propagated by a resolver/forwarder as part of a response.\u00a0 If so, this would be at odds with the discussion in Section 3 that leaves such bhavior as merely \"implementation dependent\" (giving some MAY-level options).\u00a0 I'm not sure what the intent is, here, so let's talk about whether there's anything that should change.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-24 12:51:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-23 19:33:09-07:00",
    "text": "Sections 4.16 and 4.17 have some discussion that suggests that the respective extended errors apply only to the current \"local hop\" of a DNS query, and thus should not be propagated by a resolver/forwarder as part of a response.\u00a0 If so, this would be at odds with the discussion in Section 3 that leaves such bhavior as merely \"implementation dependent\" (giving some MAY-level options).\u00a0 I'm not sure what the intent is, here, so let's talk about whether there's anything that should change. [Also reminding myself to check that the allocation policy/ranges are updated per Donald Eastlake's LC review]",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-24 14:32:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 00:10:11-07:00",
    "text": "Thank you for the work put into this document. The document is clear, easy to read and quite useful. I have a trivial to fix DISCUSS about  BCP14  (see below). I hope that this helps to improve the document, Finally, I loved reading the acknowledgements section ;-) Regards, -\u00e9ric -- Section 1.1 -- Trivial to fix: please use  BCP 14  boilerplate (see  RFC 8174 ).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-03-11 10:20:28-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 13:58:12-08:00",
    "text": "(1) This specification should formally Update  rfc8402 . What is the relationship between this document and  rfc8402 ?\u00a0 If this document details the concept introduced in  rfc8402 , why isn't there a formal Update relationship? Even the initial definition of SR Policy in this document (\u00a72) doesn't match what  rfc8402  says.\u00a0 This document defines it as \"a framework that enables the instantiation of an ordered list of segments\", while  rfc8402  states it is \"an ordered list of segments.\"\u00a0 In \u00a72.2, this document uses the term  \"segment-list\" for that. Besides the general topic of clarifying and updating what an SR Policy is, this document also includes other items that were not present in  rfc8402 ; the list includes: \u00a0  \u00a72.1: \"SR Policy MUST be identified through the tuple .\"\u00a0  There's not even a mention of \"color\" in  rfc8402 . \u00a0  \u00a72.1: \"The headend is specified as an IPv4 or IPv6 address and is expected  \u00a0  to be unique in the domain.\"\u00a0 Neither the mechanism to identify a node nor  \u00a0  the expectation is present in  rfc8402 . \u00a0  \u00a72.1: \"The endpoint is specified as an IPv4 or IPv6 address and is expected \u00a0  to be unique in the domain.\"\u00a0  Same as above. The SR Database is a new element not in the base architecture.\u00a0 The text in \u00a73 says that \"use of the SR-DB for computation and validation of SR Policies is outside the scope of this document\", but it is then mentioned and used in \u00a75.1/\u00a75.2. Accordingly, the added details require additional Security and Manageability considerations. I couldn't find a related discussion in the archive.\u00a0 If I missed it, please point me in the right direction. (2) \u00a75.1: \u00a0  Types A or B MUST be used for the SIDs for which the reachability \u00a0  cannot be verified.\u00a0 Note that the first SID MUST always be reachable \u00a0  regardless of its type. These two requirements and the text in the description of these types (\"...does not require the headend to perform SID resolution.\") results in a  contradiction: Types A and B are not to be resolved, but if they are the first  SID then they MUST.\u00a0 If it's not a contradiction, then Types A and B would not  be allowed to be the first SID, which is not correct because the most  straightforward mechanism to define a path is to list SR-MPLS Labels or SRv6  SIDs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-24 18:04:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 22:16:18-08:00",
    "text": "(1) I may just be misunderstanding things, but I'd like to pull on a thread in \u00a78.4 a bit more.\u00a0 We say that the headend H learns a BGP route that has a VPN label V, but then the following procedures seem to say that we install a route on the appropriate SR Policy P and that when we receive a packet that matches the route in question, push a label stack including the VPN label, and send the resulting packet out.\u00a0 Nowhere do we say to check the VPN status of the incoming packet, so this seems like it would open a hole in the VPN by allowing \"arbitrary\" incoming traffic (not marked as specific to V) to enter that VPN.\u00a0 Is the label V filling some other role than identifying a specific VPN of many VPNs that could run along the route R/r? (This is the only instance of the phrase \"VPN label\" in the document, and no reference is given, so I'm relying heavily on instinct to ascertain the intent here.) (2) The security considerations says that this document does not define any new protocol extensions and (accordingly) does not introduce any further security considerations.\u00a0 The first part of this seems false, not least since we define the meaning of the \"CO\" bits in the Color Extended Community.\u00a0 I'm pretty sure that makes the second part also false, and we need to discuss the security considerations relating to imposing SR Policies based only on color and not next-hop.\u00a0 Alvaro has also noted additional aspects where security considerations are missing. (3) The Discriminator as defined in \u00a72.5 does not seem wide enough to be able to provide the needed properties.\u00a0 Some later clarification in \u00a72.6 implies that the definition in \u00a72.5 is incomplete and the width is actually appropriate, but in either case \u00a72.5 seems inadequate in its current form. (Details in the COMMENT.) (4) Section 2.11 contains the statement, \"A valid SR Policy is instantiated in the forwarding plane.\" Is this a statement of fact (i.e., a consequence of the definition of \"valid\") or a mandate for something (e.g., the headend) to take action to make it so?\u00a0 Given that the point of SR is to be stateless on nodes other than the headend, I suspect the former, but if we are relying on the headend (or some other entity) to take action to ensure this is the case, that needs to be a clearly stated normative requirement. (5) Section 8.4 uses the phrase \"any AFI/SAFI of LISP [ RFC6830 ].\" There's nothing in the IANA registry for SAFI ( https://www.iana.org/assignments/safi-namespace/safi-namespace.xhtml ) about LISP, and  RFC 6830  doesn't talk about SAFI.\u00a0 What is this referring to?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 20:33:03-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-24 18:04:55-08:00",
    "text": "[removing topics that are addressed; the below are (verbatim) copies from my ballot on the -17, for topics that remain open] (3) The Discriminator as defined in \u00a72.5 does not seem wide enough to be able to provide the needed properties.\u00a0 Some later clarification in \u00a72.6 implies that the definition in \u00a72.5 is incomplete and the width is actually appropriate, but in either case \u00a72.5 seems inadequate in its current form. (Details in the COMMENT.) (4) Section 2.11 contains the statement, \"A valid SR Policy is instantiated in the forwarding plane.\" Is this a statement of fact (i.e., a consequence of the definition of \"valid\") or a mandate for something (e.g., the headend) to take action to make it so?\u00a0 Given that the point of SR is to be stateless on nodes other than the headend, I suspect the former, but if we are relying on the headend (or some other entity) to take action to ensure this is the case, that needs to be a clearly stated normative requirement.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:52:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:51:37-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:52:45-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:52:06-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:53:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:52:45-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong.And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:53:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:53:04-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:54:00-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:53:30-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:54:31-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:54:00-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:55:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:54:31-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? If that's so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:55:57-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:55:40-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? If that's so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. - Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don't see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.  \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-03-22 11:18:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 08:55:57-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? If that's so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. - Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don't see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-20 06:38:39-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 14:05:57-08:00",
    "text": "There appear to be a few places where additional pointers or specification is needed to ensure interoperability. ** Section 2.5 \u00a0  When signaling is via PCEP, the method to uniquely signal an \u00a0  individual candidate path along with its discriminator is described \u00a0  in [ I-D.ietf-pce-segment-routing-policy-cp ].\u00a0  Where is the explanation of discriminator in this reference?\u00a0 \u201cDiscriminator\u201d appears in Sections 3.1, 3.2, 4.1.2, and 5.2.2.\u00a0 In the first three section it is simply named but not explained.\u00a0 In the last section, it isn\u2019t explained beyond being defined as 32-bits. ** Section 2.6.\u00a0  \u00a0 Candidate paths MAY also be assigned or signaled with a symbolic name \u00a0  comprising printable ASCII [ RFC0020 ] [ RFC5234 ] characters How these candidate paths names are signaled isn\u2019t defined.\u00a0 I believe it is per Section 5.2.3 of  draft-ietf-pce-segment-routing-policy-cp  and Section 2.4.7 of draft-ietf-idr-segment-routing-te-policy. ** Section 2.7.\u00a0 How is the candidate path preference signaled?\u00a0 Is that  draft-ietf-idr-segment-routing-te-policy-14 #section-2.4.1 and  https://datatracker.ietf.org/doc/html/draft-ietf-idr-segment-routing-te-policy-14#section-2.4.1?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-16 13:56:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-09-28 05:38:56-07:00",
    "text": "I think this is a fine design and well documented, (though long) and I'm sure we'll clear up the points below quickly enough. Some of them may need some discussion but others are mostly checking. (1) general: I think the inclusion of CDDL is an error here and we'd be better off having someone (if interested) generate the CDDL schema stuff later on when/if CDDL is standardised/stabilised. Including it now creates the potential for breakage unnecessarily IMO. However, the WG did explicitly discuss iirc, so this is just a personal comment that I'm also in the rough on inclusion of CDDL in this spec. (As an example, for someone not familiar with CDDL, the inclusion of fragments interspersed in the text is distracting and potentially puzzling when one gets to the end of section 3.) However, I do think there are places where the CDDL is effectively normative despite what is said in the introduction, the ones I've spotted are below. (Happy to chat about 'em as I may be mistaken.) I also wondered if one could really implement this if all the CDDL was removed from the text, which is what I think would be required if CDDL were really to be informative. Anyway the places I think some more text may be needed are: (1.1) table 2: As-is the value type column seems to me to make CDDL normative. I don't see the natural language version that you said would be normative.  (1.2) 4.4, 2nd list point 1: the use of Sig_structure makes the CDDL normative. (Same with the use in 4.5 and Enc_structure in 5.3.) (1.3) 7.1, the key_ops value is only specified in CDDL, in Table 3. (It is well-defined below the table in text though, so this one's borderline.) (1.4) 11.2: it's not clear to me that a reader knows how to handle decoding of the two optional fields at the end (other and SuppPrivInfo) without looking at the CDDL. Can you explain? (That might be just my ignorance of CBOR, but wanted to check.) (2) 3.1, alg: so you're disallowing a setup where the kid alone identifies the key and algorithm to the recipient? That is used in some IETF protocols (OSPF iirc) so rhat's a pity, and will in those (maybe less common) cases consume a few bytes that could otherwise be saved.\u00a0 I think, but am not sure, that the WG already discussed this, but if not, maybe worth a thought? (Or even a 2nd thought:-) And appendix A.1 is really puzzling - as it provides instructions for how to not follow a MUST in the body of the document. (3) 7.1: key_op 8, \"derive bits\" - I don't think this usage is clear enough, can you say what's meant here? (4) Why not make deterministic ECDSA a MUST?\u00a0 8.1.1 says: \"Applications that specify ECDSA should evaluate the ability to get good random number generation and require deterministic signatures where poor random number generation exists.\"\u00a0 I don't think that is sufficiently clear, nor realistic, and I don't recall this being discussed on the list (sorry if I'm forgetting) and bad random values are a killer flaw here that has happened in the wild. (5) Table 6, is this 25519 or 448? Where does it say?\u00a0 Sorry if I'm being dumb here, but I don't see where you say which curve is specified, the definition of 'crv' says defined for this alg which I assume means listed in Table 6. (6) section 10: why MUST the kty values be present always? That seems unnecessary in some contexts and I don't get a security reason why it's needed e.g. if there's an alg id somewhere - can you explain? I can see folks omitting this leading to interop problems for not useful reasons. (Same comment applies in other cases where kty is a MUST, e.g. 12.1.2, 12.2.1.) (7) section 11: given that we know people will use human memorable secrets, why have you not defined codepoints for PBES2 (or the more commonly supported?) PBDKF2?\u00a0 I'm fine if there's a reason, or even if it was discussed by the WG, but just wanted to check as I'd worry that folks will use the ones defined here with human memorable secrets no matter what the spec says so giving 'em something more tailored might be better. (OTOH, one could argue that making this apparent might be worse too I guess.)  (8) 12.4: Why is no ephemeral-ephemeral (E-E) variant supported? Some protocols will allow for that and it seems wrong to disallow it when it could relatively easily be supported. For some applications where content is dealt with in store-and-forward mode, there may be situations (e.g. provisioning, \"introduction\") where E-E could be used. As-is, applications wanting that will have to hack the recipient DH-public into a home-grown structure (or use one of the COSE_Key labels from Table 19) and then treat that as ES-DH. That seems likely to lead to non-interop or security errors being made. I'd be fine if you even said how to re-use the structures currently defined for E-E btw and didn't introduce new structures. (9) 16.4: I'm not sure expert review is right here.\u00a0 What if the expert is asked to add SM2/SM4 while there is still no widely available non-Chinese text to describe those?\u00a0 I think the expert ought enforce a \"specification required\" rule at least and maybe more.\u00a0 (And ought never allow an algorithm with no specification publicly available.) (10) 16.4 (and elsewhere maybe) I think this registry is missing a column - as is being done in the TLS WG, I think there should be a column saying if the IETF is happy enough with an algorithm and that getting a \"Y\" in that ought require standards action. (Or some similar scheme.) I don't think the standards-track range of codepoints is enough here, e.g. at some time we will want to deprecate things, and at other times we may want to define things for the future on the standards-track but not (yet) recommend their use.\u00a0 The last bullet in 16.11 does help here, but I'd argue that we need to do more to protect the expert (and implementers) from the trickle of vanity/national algorithms/curves that are always being proposed.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-16 15:42:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-16 13:56:09-07:00",
    "text": "Thanks for the updates in -20. I think we've only the following points left. Note that 2 of those are questions to the WG chairs and not to Jim. \u00a0  (1.1) table 2: As-is the value type column seems to me to \u00a0  make CDDL normative. I don't see the natural language version \u00a0  that you said would be normative.\u00a0  Can you help me see that the changes there are such that CDDL is ok as informative? I'm not sure but as I read it there is still no natural language statement that a  \"counter signature\" is one (or more) COSE_Signature values. \u00a0  (2) 3.1, alg: so you're disallowing a setup where the kid \u00a0  alone identifies the key and algorithm to the recipient? \u00a0  That is used in some IETF protocols (OSPF iirc) so rhat's a \u00a0  pity, and will in those (maybe less common) cases consume a \u00a0  few bytes that could otherwise be saved.\u00a0 I think, but am not \u00a0  sure, that the WG already discussed this, but if not, maybe \u00a0  worth a thought? (Or even a 2nd thought:-) And appendix A.1 \u00a0  is really puzzling - as it provides instructions for how to \u00a0  not follow a MUST in the body of the document. I think we left the mail thread on this with you saying \"Best to ask the chairs if they agree that this is WG consensus,\" as you're an admitteddly strong partisan on this topic.  So, COSE chairs - what's your take? (If you say this is ok with the WG, I'll clear.) \u00a0  (6) section 10: why MUST the kty values be present always? \u00a0  That seems unnecessary in some contexts and I don't get a \u00a0  security reason why it's needed e.g. if there's an alg id \u00a0  somewhere - can you explain? I can see folks omitting this \u00a0  leading to interop problems for not useful reasons. (Same \u00a0  comment applies in other cases where kty is a MUST, e.g. \u00a0  12.1.2, 12.2.1.) I think this is the similar to discuss point (2) above. So again, COSE chairs, can you confirm that this design does reflect WG consensus and isn't just a thorough and good editor getting his way? (If you say this is ok with the WG, I'll clear.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-16 16:03:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-16 15:42:37-07:00",
    "text": "Thanks for the updates in -20. I think we've only the following points left. Note that all of those are questions to the WG chairs and not to Jim. \u00a0  (2) 3.1, alg: so you're disallowing a setup where the kid \u00a0  alone identifies the key and algorithm to the recipient? \u00a0  That is used in some IETF protocols (OSPF iirc) so rhat's a \u00a0  pity, and will in those (maybe less common) cases consume a \u00a0  few bytes that could otherwise be saved.\u00a0 I think, but am not \u00a0  sure, that the WG already discussed this, but if not, maybe \u00a0  worth a thought? (Or even a 2nd thought:-) And appendix A.1 \u00a0  is really puzzling - as it provides instructions for how to \u00a0  not follow a MUST in the body of the document. I think we left the mail thread on this with you saying \"Best to ask the chairs if they agree that this is WG consensus,\" as you're an admitteddly strong partisan on this topic.  So, COSE chairs - what's your take? (If you say this is ok with the WG, I'll clear.) \u00a0  (6) section 10: why MUST the kty values be present always? \u00a0  That seems unnecessary in some contexts and I don't get a \u00a0  security reason why it's needed e.g. if there's an alg id \u00a0  somewhere - can you explain? I can see folks omitting this \u00a0  leading to interop problems for not useful reasons. (Same \u00a0  comment applies in other cases where kty is a MUST, e.g. \u00a0  12.1.2, 12.2.1.) I think this is the similar to discuss point (2) above. So again, COSE chairs, can you confirm that this design does reflect WG consensus and isn't just a thorough and good editor getting his way? (If you say this is ok with the WG, I'll clear.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-16 23:36:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-16 16:03:12-07:00",
    "text": "-21 means I need to put back the DISCUSS point about deterministic ECDSA. Could be an error though, checking... Thanks for the updates in -20. I think we've only the following points left. Note that all of those are questions to the WG chairs and not to Jim. \u00a0  (2) 3.1, alg: so you're disallowing a setup where the kid \u00a0  alone identifies the key and algorithm to the recipient? \u00a0  That is used in some IETF protocols (OSPF iirc) so rhat's a \u00a0  pity, and will in those (maybe less common) cases consume a \u00a0  few bytes that could otherwise be saved.\u00a0 I think, but am not \u00a0  sure, that the WG already discussed this, but if not, maybe \u00a0  worth a thought? (Or even a 2nd thought:-) And appendix A.1 \u00a0  is really puzzling - as it provides instructions for how to \u00a0  not follow a MUST in the body of the document. I think we left the mail thread on this with you saying \"Best to ask the chairs if they agree that this is WG consensus,\" as you're an admitteddly strong partisan on this topic.  So, COSE chairs - what's your take? (If you say this is ok with the WG, I'll clear.) \u00a0  (6) section 10: why MUST the kty values be present always? \u00a0  That seems unnecessary in some contexts and I don't get a \u00a0  security reason why it's needed e.g. if there's an alg id \u00a0  somewhere - can you explain? I can see folks omitting this \u00a0  leading to interop problems for not useful reasons. (Same \u00a0  comment applies in other cases where kty is a MUST, e.g. \u00a0  12.1.2, 12.2.1.) I think this is the similar to discuss point (2) above. So again, COSE chairs, can you confirm that this design does reflect WG consensus and isn't just a thorough and good editor getting his way? (If you say this is ok with the WG, I'll clear.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-11-22 14:14:06-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-16 23:36:33-07:00",
    "text": "Thanks for the updates in -20. I think we've only the following points left. Note that all of those are questions to the WG chairs and not to Jim. \u00a0  (2) 3.1, alg: so you're disallowing a setup where the kid \u00a0  alone identifies the key and algorithm to the recipient? \u00a0  That is used in some IETF protocols (OSPF iirc) so rhat's a \u00a0  pity, and will in those (maybe less common) cases consume a \u00a0  few bytes that could otherwise be saved.\u00a0 I think, but am not \u00a0  sure, that the WG already discussed this, but if not, maybe \u00a0  worth a thought? (Or even a 2nd thought:-) And appendix A.1 \u00a0  is really puzzling - as it provides instructions for how to \u00a0  not follow a MUST in the body of the document. I think we left the mail thread on this with you saying \"Best to ask the chairs if they agree that this is WG consensus,\" as you're an admitteddly strong partisan on this topic.  So, COSE chairs - what's your take? (If you say this is ok with the WG, I'll clear.) \u00a0  (6) section 10: why MUST the kty values be present always? \u00a0  That seems unnecessary in some contexts and I don't get a \u00a0  security reason why it's needed e.g. if there's an alg id \u00a0  somewhere - can you explain? I can see folks omitting this \u00a0  leading to interop problems for not useful reasons. (Same \u00a0  comment applies in other cases where kty is a MUST, e.g. \u00a0  12.1.2, 12.2.1.) I think this is the similar to discuss point (2) above. So again, COSE chairs, can you confirm that this design does reflect WG consensus and isn't just a thorough and good editor getting his way? (If you say this is ok with the WG, I'll clear.)",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2018-04-16 17:11:33-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-16 08:54:25-07:00",
    "text": "Please consider this to be an opportunity to explain something to an AD who doesn't understand codecs super well ... so I doubt it will be hard to clear my Discuss. I'm not entirely comfortable that Section 8 isn't normative. Is the theory that if (for example) I decide that my H.264 format parameter maps onto a codec-independent parameter that you don't think it maps to, then you and I probably would probably end up ignoring the rid and doing what we would do, if one of us didn't support rids? If not, what's supposed to happen (normatively)?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-06-25 22:58:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-21 06:19:43-07:00",
    "text": "Thank you for the work put into this document. The comparison between the IPv4aaS technologies is well done. Please find below some blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Ron Bonica for the shepherd's write-up and the justification for the intended status, I would have appreciated a little more text about the WG consensus though.  Authors may also expect an internet directorate review by Dave Lawrence, the delay in the review should not hinder the publication process though. Finally, I would like to apologise for not sending those comments earlier (just before telechat! there is NO need to reply immediately) but also during the WG process as I try to follow closely the V6OPS work. I hope that this helps to improve the document, Regards, -\u00e9ric As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 2.2 A important and trivial to fix \"translates the IPv4 payload to public IPv4 source address using a stateful NAPT44\" => \"translates the IPv4 source address in the payload to public IPv4 source address using a stateful NAPT44\" ## Section 3.3 \"Here, the centralized network function (lwAFTR or BR) only needs to perform stateless encapsulation/decapsulation or NAT64\", actually in MAP-T, BR does translation. ## Section 3.4 I am afraid that the number of IPv4 public addresses that are required goes beyond this \"simple\" computation. There are also other constraints such as laws, MoU, rules and operators BCP, see: -  https://bipt.be/operators/publication/consultation-of-11-october-2016-regarding-the-conditions-of-use-of-ipv4cgn  (alas in French/Dutch) but meaning that in my country, Belgium, an IP address can be shared by 16 subscribers max -  https://www.europol.europa.eu/media-press/newsroom/news/are-you-sharing-same-ip-address-criminal-law-enforcement-call-for-end-of-carrier-grade-nat-cgn-to-increase-accountability-online",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-06-16 13:50:49-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-18 19:23:00-07:00",
    "text": "** Section 4.7 notes detailed connection level logging of user behaviors.\u00a0 Please discuss the privacy and security implications \u2013 securing these logs at rest from unauthorized access, retention, etc.  ** Section 8. \u00a0  According to the simplest model, the number of bugs is proportional \u00a0  to the number of code lines.\u00a0 Please refer to Section 4.4.3 for code \u00a0  sizes of CE implementations. What is the intent of this text and how should the reader use it to choose a IPv4aaS? Taking the simple model above and the text from Section 4.4.3 (\u201c\u2026 17kB, 35kB, 15kB, 35kB, and 48kB for 464XLAT, lw4o6, DS-Lite, MAP-E, MAP-T, and lw4o6 \u2026\u201d), is it suggesting that 464XLAT the most \u201csecure\u201d protocol because it\u2019s code size the smallest?\u00a0 How does that metric work across different implementation?\u00a0 I recommend removing this text.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-06 19:33:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-12-16 14:36:01-08:00",
    "text": "I'm going to defer this document's evaluation because I think there are several interrelated subtle issues that merit closer consideration than has been given so far.\u00a0 I will also invite the TLS WG to provide input on these issues, since they relate to rather fundamental issues of the operation of the TLS sub-protocols. Most of them concern the Commitment Message, in terms of what goals it aims to achieve, how it is specified, and what mechanism is used to effectuate it. To start with the easy one: currently the way in which the structure of the Commitment Message is described makes reference to many fields of TLS Record Layer structures in order to specify what is fundamentally a message on the TLS Application Data stream.\u00a0 This is a layering violation; I don't see any reason to say more than what was suggested in https://mailarchive.ietf.org/arch/msg/emu/ECgvnq-C_VVXT5bpvOowte8LBjw/  : \"the commit[ment] message is a single byte of [value] 0 in the application data stream\".\u00a0 All the bits about cryptographic protection and expansion of the plaintext in prepararation for record protection are just adding noise, and the interface between the TLS stack and the application is supposed to be a data-stream abstraction, not a record abstraction. Next, the whole reason for the existence of a Commitment Message seems under-justified -- the only mention I could find in the document is that it serves \"to decrease the uncertainty for the EAP-TLS peer\".\u00a0 What harm would be caused by a lack of certainty in this area?\u00a0 Why does waiting for an EAP-Success or EAP-Failure not provide a similar level of certainty? The document also suggests in several places that the Commitment Message can or should be sent at 0.5-RTT data in the same flight as the server Finished.\u00a0 The intent, as determined from the mailing list archive, seems to be to save a round-trip compared to a typical full message flow where the server does not send application data until after the client's Finished (and any application data alongside it) is received.\u00a0 In particular, this came out during discussion of how a TLS \"close_notify\" alert would be unsuitable for the role of the Commitment Message, since sending the \"close_notify\" in 0.5-RTT would prevent sending an alert if the client authentication failed, and the diagnostic value of such alerts is significant.\u00a0 This is where the issues start to become interrelated -- the Commitment Message as a new application-data construct is for the objective of reducing the number of round trips. However, TLS session resumption is also designed to reduce the number of round-trips (including by no longer needing to send potentially large TLS Certificate messages that get fragmented at the EAP layer, with the cost of a round trip per fragment), and there is a nasty interaction between the two mechanisms.\u00a0 Specifically, TLS 1.3 session resumption requires the use of a NewSessionTicket message, which is associated with a resumption secret; the resumption secret, in turn, is not available in the key schedule until the client Finished (and client authentication messages, if any) is available.\u00a0 While it is possible in many Web scenarios for NewSessionTicket to be issued in the 0.5-RTT flight, this is because the server can precompute what the valid client Finished would be and use that in the key schedule to precompute the resumption secret.\u00a0 If the client is to be authenticated, as is the case for the vast majority of EAP exchanges, then such precomputation is impossible, and the session ticket cannot be issued until the extra round trip is completed.\u00a0 The document contains no discussion of the inherent tradeoff between sending the commitment message in 0.5-RTT and using resumption, and this tradeoff seems to call into question the merits of choosing this mechanism to implement the commitment message, since... The commitment message as specified seems to itself be a layering violation.\u00a0 The TLS protocol itself consists of a few sub-protocols, e.g., the handshake protocol, record protocol, and alert protocol.\u00a0 The operation of the handshake protocol is supposed to be completely independent of the application-data record protocol (except to the extent that the handshake protocol supplies the keys used for cryptographic protection of application data records).\u00a0 In particular, there should not be any interaction between the handshake state machine and the application data.\u00a0 If there is to be a commitment made about the operation of the TLS handshake protocol, that more properly belongs in the handshake layer itself, or perhaps the alert layer if it relates to the overall operation of the TLS connection.\u00a0 It seems inappropriate and unsustainable to expect that an application-data message would affect the operation of the handshake layer. The use of application data for the commitment message also may have unfortunate interactions with other TLS-using EAP methods, which is very briefly mentioned as a possibility but not explored at all: \u00a0  While EAP-TLS does not protect any application data except for the \u00a0  Commitment Message, the negotiated cipher suites and algorithms MAY \u00a0  be used to secure data as done in other TLS-based EAP methods. If we are to expect this construction of commitment message to become the de facto standard for using TLS 1.3 with EAP, I think we need to consider whether other EAP methods that do need to actually protect application data with the TLS connection will be affected by this proposal to insert the EAP commitment message into the application data stream.\u00a0 This is worth particular consideration given that we require that \"EAP-TLS peer implementations MUST accept any application data as a Commitment Message from the EAP-TLS server to not send any more handshake messages\" -- these seem like new semantics that might be quite unexpected if applied to other EAP methods. There's also a few internal inconsistencies that raise to a discuss-level and will need to be resolved before publication: The body text around Figure 3 indicates that mutual authentication should be depicted, but the figure shows only normal server-only authentication. The example in Figure 8 needs a TLS CertificateRequest in there in order for the rest of the flow to make sense. Section 2.1.4 says that \"TLS warning alerts generally mean that the connection can continue normally and does not change the message flow.\" but this is no longer true with TLS 1.3 -- the only alerts sent at warning level are \"close_notify\" and \"user_cancelled\", both of which indicate that the connection is not going to continue normally. Section 2.1.9 claims that the largest size of a TLS record is 16387 octets, but by my count a TLSCiphertext can get up to 16643, since the length field \"MUST NOT exceed 2^14 + 256 bytes\" (and there's the other 3 bytes of header). Please also check the statements made about  RFC 8446  that I note in my comments on Section 5.1.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-07 16:17:02-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 19:33:35-07:00",
    "text": "Many thanks for the updates since the -13, the last version I reviewed. I'm happy to report that the structural issues I noted in that version have been addressed, and my new Discuss point is a fairly mundane one. In several sections, we say that the text \"updates Section X of [ RFC5216 ] by amending it with the following text\", but I'm quite unclear on exactly what that is intended to mean.\u00a0 Are we adding to the end, prepending to the beginning, replacing wholesale, replacing in part, or doing something else to the indicated text of  RFC 5216 ?\u00a0 I expect that just tweaking a few words can resolve the ambiguity, but am not sure which ones yet. It is also interesting to contrast the \"amending\" language with what we say in Sections 2.1.4 and 2.3 about \"replacing\" text from  RFC 5216  and the various places where we report a \"new section when compared to [ RFC5216 ]\".",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-01-11 07:16:09-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-05 04:27:21-08:00",
    "text": "Thank you for updating EAP to support TLS 1.3. This document is outside my area of expertise, and others will be able to give a better technical review. However, I do think that it would be useful to have a brief discussion with the authors/ADs about the structure of the document.\u00a0 I.e., this document leaves  RFC 5216  as an active updated RFC, although that RFC depends on TLS version 1.2 ( RFC 5246 ) that is obsoleted by TLS 1.3. I also note that this document contains 30 pages of updates to an RFC that is only 32 pages long. Taking both of these into consideration, I think that it would be better (and longer term probably an easier reference) if this document could stand on its own, by obsoleting  RFC 5216  and including any text from  RFC 5216  that is still relevant when using EAP with TLS 1.3. I appreciate that this would be a significant change and hence would welcome input from the authors and other ADs as to whether this change would be worth the effort. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-01-14 20:48:06-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-04 20:10:02-08:00",
    "text": "I have a couple of items I would like to see discussed prior to approval. Hopefully they can be resolved easily: - 12.1 says: \"Id:\u00a0 The number assigned to the attribute.\u00a0 In the event of conflicts \u00a0  between the assigned number and [NFSv42xdr], the latter is likely \u00a0  authoritative, but should be resolved with Errata to this document \u00a0  and/or [NFSv42xdr].\u00a0 See [IESG08] for the Errata process.\" This leaves a window open for considerable confusion down the road. Is there a reason not to just fix it now? This draft normatively depends on [NFSv42xdr] anyway, so why not completely delegate the assigned Id numbers to it? - 4.4.2, \"The client SHOULD write back the data...\" SHOULD seems weak for something where failure\u00a0 could result in data corruption. Are there ever situations where it might make sense not to do this?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-05-22 00:06:15-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-18 04:21:29-07:00",
    "text": "For the AD: Please note that the intended status in the datatracker is \"Proposed Standard\" while the doc itself says \"Informational\". After reading the doc, I would find informational correct. However, please clarify what the intended status is supposed to be!",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-06-15 13:10:07-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-14 23:05:03-07:00",
    "text": "In Section 5.1 when the SRLG collection request was contained in an LSP_REQUIRED_ATTRIBUTES and the RRO would become too big, a node drops the RRO from the Path message entirely. It is not clear what the next node that receives this SRLG collection request without an RRO would need to do as the spec only says that the RRO is inserted at the ingress. What is the expected behavior here on the subsequent node?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-27 20:24:51-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 15:00:23-08:00",
    "text": "(1) Section 8.6 seems to have some conflicting requirements.\u00a0 The filtered property map response \"MUST include all the inherited property values for the requested entities and all the entities which are able to inherit property values from the requested entities.\"\u00a0 We then go on to say that to do this, the server MAY follow three rules, that themselves include SHOULD-level guidance, but don't say how the MUST is achieved if the SHOULDs or MAY are ignored.\u00a0 I was expecting to see a construction of the form \"SHOULD do X, but if not, MUST do Y\". (2) Many of the examples in Sections 10.X do not seem to match up with the prose that describes them and the previous data tables that they are intended to illustrate (see COMMENT).\u00a0 We should make sure that the examples are internally consistent. (3) Section 4.6.2 says: \u00a0  *\u00a0 Last, the entity domain types \"asn\" and \"countrycode\" defined in \u00a0 \u00a0 \u00a0 [ I-D.ietf-alto-cdni-request-routing-alto ] do not have a defining \u00a0 \u00a0 \u00a0 information resource.\u00a0 Indeed, the entity identifiers in these two \u00a0 \u00a0 \u00a0 entity domain types are already standardized in documents that the \u00a0 \u00a0 \u00a0 Client can use. But earlier we said that \"the defining information resource of a resource-specific entity domain D is unique\", but this seems to be saying that the defining information resource of domains of the \"asn\" and \"contrycode\" type are *not* unique, by virtue of not existing at all.\u00a0 How can we rectify these two statements?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:37:53-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 10:35:38-08:00",
    "text": "Thank you for the work on this document. Many thanks to Spencer Dawkins for his thoughtful review:  https://mailarchive.ietf.org/arch/msg/art/BcZimefF1WXXgcmg0qjc3P__EGg/  , and thanks to the authors for addressing it. I have two blocking comments, and some non blocking comments (to which I would still appreciate answers) below. Francesca 1. ----- Media type registration FP: I haven't seen the media type being reviewed by the media-type mailing list, as requested by  RFC 6838 . Before progressing the document, I would really appreciate the authors to post the registrations to the media-type mailing list for review. 2. ----- Sections 4.6.1, 12.2.2 and 12.3 FP: The use of the term \"unique\" when referred to media types and entity domains (or properties) is confusing - it makes it sound as if the authors mean that each different entity domain (or property) is to be associated with a different unique media type, which doesn't seem to be the intent. As this is related to the media type registration, I believe this should be clarified and possibly checked with the media type experts (so it would be good to copy paste the relevant text in the email to the media-type mailing list).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-25 05:58:04-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:37:53-08:00",
    "text": "Thank you for the work on this document. Many thanks to Spencer Dawkins for his thoughtful review:  https://mailarchive.ietf.org/arch/msg/art/BcZimefF1WXXgcmg0qjc3P__EGg/  , and thanks to the authors for addressing it. I have two blocking comments, and some non blocking comments (to which I would still appreciate answers) below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- Media type registration FP: I haven't seen the media type being reviewed by the media-type mailing list, as requested by  RFC 6838 . Before progressing the document, I would really appreciate the authors to post the registrations to the media-type mailing list for review. 2. ----- Sections 4.6.1, 12.2.2 and 12.3 FP: The use of the term \"unique\" when referred to media types and entity domains (or properties) is confusing - it makes it sound as if the authors mean that each different entity domain (or property) is to be associated with a different unique media type, which doesn't seem to be the intent. As this is related to the media type registration, I believe this should be clarified and possibly checked with the media type experts (so it would be good to copy paste the relevant text in the email to the media-type mailing list).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:36:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-27 06:27:50-07:00",
    "text": "In the thread with the Gen-ART reviewer, the rationale that was given for advancing this document now even though rfc6834bis is nascent was: \"We do not expect big changes in any bis document, since they are just the PS version of deployed technology.\" This seems somewhat less likely given the feedback received on the LISP documents on the telechat this week, so I'd like to discuss whether it really makes sense to advance this one now given its normative dependencies on 6834bis and 6830bis.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-24 17:45:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-27 04:38:45-07:00",
    "text": "[Unlike for the 683xbis documents, this is a more mundane Discuss, with one process issue and one issue of clarity with respect to randomness requirements, that should be fairly easy to resolve.] I think that 8060 needs to be a normative reference; it seems to be needed to implement the Multiple Data-Planes LCAF type.\u00a0 Arguably 6040 also should be, though that seems less clear-cut to me. (8060 would be a new normative downref and require another IETF LC, IIUC.) Section 3 notes: \u00a0 \u00a0 \u00a0 The encoding of the Nonce field in LISP-GPE, compared with the one \u00a0 \u00a0 \u00a0 used in [ I-D.ietf-lisp-rfc6830bis ] for the LISP data plane \u00a0 \u00a0 \u00a0 encapsulation, reduces the length of the nonce from 24 to 16 bits. \u00a0 \u00a0 \u00a0 As per [ I-D.ietf-lisp-rfc6830bis ], Ingress Tunnel Routers (ITRs) \u00a0 \u00a0 \u00a0 are required to generate different nonces when sending to \u00a0 \u00a0 \u00a0 different Routing Locators (RLOCs), but the same nonce can be used \u00a0 \u00a0 \u00a0 for a period of time when encapsulating to the same Egress Tunnel \u00a0 \u00a0 \u00a0 Router (ETR).\u00a0 The use of 16 bits nonces still allows an ITR to \u00a0 \u00a0 \u00a0 determine to and from reachability for up to 64k RLOCs at the same \u00a0 \u00a0 \u00a0 time. That seems to be missing the point of the nonce -- it's not just for unique  identification but also to prevent off-path attackers from guessing a valid value and spoofing a bogus map-reply!\u00a0 Using the entire 64k of nonce space means that such a spoofing attack can succeed pretty reliably (e.g., by over-claiming so that the response EID-prefix contains whatever the request was for).\u00a0 I think it's important to accurately describe what properties are required of indivdiual nonces and the combined set of active nonces, which this text seems to mischaracterize.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-25 17:19:48-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-24 17:45:20-07:00",
    "text": "Thank you for the updates in the -08! Can you please say \"partially mitigates\" instead of \"mitigates\" in \"However, the use of common anti-spoofing mechanisms such as uRPF mitigates this form of attack.\"? Now that  RFC 8060  is a normative reference, it's a downref that I believe will need to be IETF LC'd again.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-09 05:43:27-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 02:14:55-07:00",
    "text": "Section 4.2: To me it looks like this is normative reference to the : Such new encapsulated payloads, when registered with LISP- \u00a0  GPE, MUST be accompanied by a set of guidelines derived from \u00a0  [ I-D.ietf-tsvwg-ecn-encap-guidelines ] and [ RFC6040 ].",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-19 10:38:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-19 09:38:02-07:00",
    "text": "Sorry not an expert on 802.1Q, however, I think section 4.2 would need to say more about HOW the PCP should be mapped to DSCPs.  RFC8325  has shown that there is usually no straight forward approach and therefore more guidance might be needed. Further, I would guess one would also need to define a more concrete mapping for section 4.3 but here I'm really not an expert at all.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-19 10:38:37-07:00",
    "text": "Thanks for addressing the TSV-ART review (and Magnus for doing the review)! I assume that the proposed text will be incorporated in the next version. (Would have been even better if those (larger) changes would have been added before the doc was put on the telechat; please update as soon as possible so other AD can review that text as well).  However, I think the text still needs to say more about HOW the PCP should be mapped to DSCPs.  RFC8325  doesn't provide guidelines but a mapping for 802.11. Is the same mapping applicable here? Also, I'm not an expert for that part, but I guess there also is further guidance needed on HOW to map the VID...?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-11-19 19:39:11-08:00",
    "text": "Thanks for all the work on this over the years. I have a few concerns that I think require discussion prior to publication: \u00a75.7: Is the \"description\" field expected to be human readable? If so, are there internationalization issues to consider? \u00a76.2, 5th paragraph: This says that if you get an error back for a configure message, you send a new configure message. This seems likely to cause an infinite loop unless some guidance is given about escaping the loop when the endpoints cannot agree on a configuration. \u00a77:\u00a0 I\u2019m confused by the versioning mechanisms. This section requires an endpoint to ignore unknown elements, but it also requires the peer to downgrade to the highest shared version. These requirements seem to be at cross purposes. If the peer downgrades, one should only see unknown elements in the case of implementation errors. The requirement to ignore unknown elements does not come for free; nor does the requirement to downgrade. \u00a75.1 and \u00a78: The use of the options message to negotiate extensions seems underspecified. How does an endpoint compare extensionType elements?\u00a0 Is a spec required or expected? Is the extension spec expected to register the URI for schemaRef somewhere? Does this need to be in IANA?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-09 18:03:15-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 10:25:40-08:00",
    "text": "Thanks for the generally clear and well-written document! I would like to discuss whether there needs to be more prominent coverage of timers/timeouts, especially as relating to the state machines.\u00a0 (I'd be happy to learn that this is well-covered elsewhere in the document set; I just haven't run into it yet.) In a similar vein, do we want to have any treatment of avoiding infinite loops (e.g., when a 'configure' or 'advertisement' is rejected in expectation of modification but the sending implementation continues to generate an identical message)? It is not clear to me that any change to the document text is needed in either case, but I don't know to what extent the topics have already been discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-10-31 12:38:01-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-31 12:31:39-07:00",
    "text": "This document does not discuss any interactions with the transport protocol (e.g. who establishes the connection? what happens if the connections breaks; who should re-establish?). Also, I assume that SCTP is used (instead of TCP) because the idea is to use different SCTP streams for the different directions of the communication...? However, this is a complete guess, as the document does unfortunately not say nothing about the mapping of CLUE messages to SCTP sessions. In case all message are assumed to be send over the same stream instead, why is SCTP used and not TCP? Please provide more information and guidance on the use of SCTP!",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2021-12-10 07:47:37-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-26 06:12:46-08:00",
    "text": "Hi, thank you for your work. I have two points I'd like to discuss with you: 1/ You write: \u00a0  If the value of the OptionLength field is not equal to 4, the BFD \u00a0  Discriminator PIM Hello option is considered malformed, and the \u00a0  receiver MUST stop processing PIM Hello options. Do you mean ignore all other options that would be in the PIM Hello message? I rapidly skimmed through 7761 and could not find such requirement nor an indication that documents defining new Hello options would have to define how to treat options when at least one is malformed. It may be that I simply failed to find the relevant text in PIM specs but I'd nevertheless appreciate if you could elaborate a bit on this. 2/ Twice you write that a PIM-SM router MAY/can become a head. First time in 2nd paragraph of 2.1, and the second time in 2.2. \"become\" gives a sense of automation, meaning without human intervention, and this is apparently confirmed by section 2.2 where becoming a head is driven by the node becoming a GDR. The issue I have is that 8562 is pretty explicit about the fact that the transition to Up state for a head is administratively controlled. You take great care in reusing that word (The head router administratively sets the bfd.SessionState to Up in the MultipointHead session) but I'm not sure this is sufficient to make this an administratively driven action. Maybe it's simply a discussion about the meaning of \"administratively\", but according to the understanding I have of this word (which is influenced by the typical use of it in router implementations), it seems to me that this document departs from 8562. Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-05-10 06:19:39-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-19 14:38:30-08:00",
    "text": "Per my comment below, it seems like there are some fairly significant privacy considerations related to the choice of how the client id is constructed. I think these need to be described in the document so implementors are aware of them. (And my bad for not noticing this before the publication of  RFC 7530 , since they would have applied there as well.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-01-26 19:35:28-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-20 12:58:51-08:00",
    "text": "This draft recommends the use of the uniform client-ID string approach. I admit to not being an NFS expert, but that seems to add a lot of complexity. It seems counter to advice in 7530. Section 4.7 of this draft points out that this may create interop problems with some servers. It seems to increase the privacy impact of persistent and potentially user and hardware identifying client-ID strings. There seems to be an issue of balancing harms here. I'd like to see some text describing how the harm avoided by the uniform approach balances out with the other issues.  The security considerations seem incomplete. This draft makes a number of normative changes and clarifications that are likely to introduce new security and/or privacy considerations that are not mentioned. This is especially true for the guidance about using uniform client-IDs.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-02-23 12:14:57-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-12 21:45:27-08:00",
    "text": "Thanks for this document.\u00a0 This is a simple DISCUSS point that should be very easy to resolve: \u2014 Section 5.2 \u2014 \u00a0  A sender computes the encoded \u00a0  value by dividing the buffer size, in octets, by 1024 and subtracting \u00a0  one from the result. Is the buffer size necessarily a multiple of 1024?\u00a0 If so, where is that specified?\u00a0 If not, what is the encoded value when the buffer size is, say, 2000?\u00a0 Is it zero?\u00a0 Or one?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-04 23:32:36-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 09:40:48-08:00",
    "text": "I do see the previous discussion in https://mailarchive.ietf.org/arch/msg/cose/E6ApKPKlESQQSZwySJAVF1l27OE but I am still unclear on where exactly we can represent the octet string that is the HMS-LMS public key.\u00a0 Do we not need to define a COSE Key Type Parameter (i.e., label) that maps to the public key value?\u00a0 For reference, the examples in Appendix C.7.1 of  RFC 8152  include key/value pairs with the negative map labels from https://www.iana.org/assignments/cose/cose.xhtml#key-type-parameters corresponding to the key type in question. Hopefully I'm just confused and missing where this is already done, but marking as a Discuss point in case I'm not.\u00a0 (The linked cose-wg/Examples seem to be using a JSON structure to describe the input to the example generation, with the \"public\" and \"private\" members of the \"key\" that do not seem to correspond to anything that I can find at https://www.iana.org/assignments/jose/jose.xhtml#web-key-parameters , and which would in any case not directly apply to the *COSE* usage.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-03-15 08:04:14-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-14 18:05:43-07:00",
    "text": "If I am reading things correctly, the security considerations just say the extensions in this draft may raise new security considerations, but doesn't say anything about what they might be. That's an incomplete analysis. What new considerations actually (not \"may\") exist? What potential attacks may be enabled by these extensions, if any? Are there things people can do to mitigate them?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-11-01 13:21:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-26 07:29:12-07:00",
    "text": "olding a discuss on my own document as a marker to ensure that the IANA Review completes.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-04-24 05:52:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 06:45:56-07:00",
    "text": "Apologies as this may be a really silly question, but isn't it possible for traffic-rate-bytes and traffic-rate-packets to interfere with each other? That is, if by mistake a flow specification shows up containing both actions and they contradict each other (e.g., 0 bytes but 1M packets), how is that situation supposed to be handled?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-23 18:45:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 17:42:18-07:00",
    "text": "There might be a minor internal inconsistency to tidy up (or I might be misunderstanding things).\u00a0 Section 8 states that: \u00a0  Contrary to the behavior specified for the non-VPN NLRI, Flow \u00a0  Specifications are accepted by default, when received from remote PE \u00a0  routers. As far as I can tell, this is referring to the text in Section 6 where (for the non-VPN case) \"By default a Flow Specification NLRI MUST be validated such that it is considered feasible if and only if all of the below is true [...]\".\u00a0 But immediately following what I quote above is a statement that \"the validation proceure (section 6) [...] [is] the same as for IPv4\", which seems to be in conflict with this statement (\"contrary to\" vs. \"the same as\").",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-24 06:50:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-24 06:46:49-07:00",
    "text": "Thank you for the work put into this document. The document is clear, easy to read (I appreciated the given examples). Alas, due to overload of work, I had only a quick browse through the document with specific focus points and found nothing EXCEPT why having two different documents ? One for IPv4 and one for IPv6... I am more than surprized... hence my DISCUSS... This blocking DISCUSS can easily be fixed: e.g., with a RFC Editor note to make a cluster of this document and  draft-ietf-idr-flow-spec-v6  so that they are published together with adjacent RFC numbers. Please find below a couple on non-blocking COMMENTs. I hope that this helps to improve the document, Regards, -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-27 08:57:12-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-24 06:50:16-07:00",
    "text": "Thank you for the work put into this document. The document is clear, easy to read (I appreciated the given examples).  Alas, due to overload of work, I had only a quick browse through the document with specific focus points and found nothing EXCEPT why having two different documents ? One for IPv4 (with the core elements of the protocol) and one for IPv6 (with only the IPv6 specifics)... I am more than surprized to say the least... hence my DISCUSS... This blocking DISCUSS can easily be fixed: e.g., with a RFC Editor note to make a cluster of this document and  draft-ietf-idr-flow-spec-v6  so that they are published together with adjacent RFC numbers. Merging the two documents would be preferred but I understand that this is more work (albeit a missed opportunity). Please find below a couple on non-blocking COMMENTs. I hope that this helps to improve the document, Regards, -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-04-27 09:50:59-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-24 02:47:23-07:00",
    "text": "I don't know if this is a valid discuss point, so happy to be educated that it is always written this way and I'll remove my discuss ... I note that in 5 places this document has text that states the equivalent to \"SHOULD be set to 0 on encoding, and MUST be ignored during decoding.\" (example given below). Doesn't this make extending this in future more risky because if new meaning are given to these bits then there could be senders already transmitting non 0 values which a receiver might then misinterpret? Hence, I was surprised that the constraints did not also include a MUST on the encoding side (i.e. be strict in what you send ...), i.e. \"MUST be set to 0 on encoding, and MUST be ignored during decoding.\" Example: \u00a0  The extended is encoded as follows: \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |\u00a0  reserved\u00a0 \u00a0 |\u00a0  reserved\u00a0 \u00a0 |\u00a0  reserved\u00a0 \u00a0 |\u00a0  reserved\u00a0 \u00a0 | \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |\u00a0  reserved\u00a0 \u00a0 | r.|\u00a0 \u00a0 DSCP\u00a0  | \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Figure 6: Traffic Marking Extended Community Encoding \u00a0  o\u00a0 DSCP: new DSCP value for the transiting IP packet. \u00a0  o\u00a0 reserved, r.: SHOULD be set to 0 on encoding, and MUST be ignored \u00a0 \u00a0 \u00a0 during decoding.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-01-30 13:45:10-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-30 13:44:04-08:00",
    "text": "I have a couple of points I think we should DISCUSS before moving this document forward: the intended status and the definition of the registry.\u00a0 Both points are intertwined. (1) Intended Status: The Datatracker indicates that the Intended RFC status for this document is Proposed Standard (as does the Shepherd WriteUp and the IETF LC), but the header on the document says Experimental.\u00a0 I note that the document header was changed after a discussion on the WG list resulting from the RTG Directorate review [1], but that happened after the WGLC.\u00a0 Which is the right status?   (2) LISP Packet Types Registry Definition: It seems very odd to me that the LISP Packet Types Registry uses Standard Action as the registration policy given that the LISP work is currently Experimental -- and that the other references in it would in fact be from an Experimental RFC ( rfc6380 ).\u00a0 I know there's work on rfc6830bis (in the Standards Track), but I think it would be better to have this registry defined in the base specification (rfc6833bis, in this case)...or to wait for the publication of that document to progress this one. I think there's nothing procedurally wrong with having an Experimental RFC define a Standard Action Registry and populate part of it with references to Experimental RFC.\u00a0 However, the solution just doesn't seem clean to me -- so I would like to hear the justification for the rush (and not waiting for rfc6380bis/rfc6388bis). I have no issue with a document making use of the Code Point to describe the new LISP Shared Extension Message Type (without creating the Registry).\u00a0 But given that the base LISP specification is still Experimental, then this document should be too.\u00a0 There shouldn't be an issue with changing the Status of this document (in-place) once rfc6380bis/rfc6388bis progress. There's also the issue that  RFC6830  (and rfc6833bis) contain the following text: \"This section will be the authoritative source for allocating LISP Type values...\"\u00a0  Which means that (if the registry is to be defined here), this document should at least Update  RFC6830 ... In summary, I think that the correct Status for this document is Experimental.\u00a0 I also think that it would be better to wait for rfc6833bis to define the Registry. \u00a0  [1]  https://mailarchive.ietf.org/arch/msg/lisp/m1EicCexdX1GI183pba-mcHJM7g/?qid=ada479dce3c434bfaf948b0ee8240996",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-02-01 01:48:20-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-30 13:45:10-08:00",
    "text": "I have a couple of points I think we should DISCUSS before moving this document forward: the intended status and the definition of the registry. (1) Intended Status: The Datatracker indicates that the Intended RFC status for this document is Proposed Standard (as does the Shepherd WriteUp and the IETF LC), but the header on the document says Experimental.\u00a0 I note that the document header was changed after a discussion on the WG list resulting from the RTG Directorate review [1], but that happened after the WGLC.\u00a0 Which is the right status?   (2) LISP Packet Types Registry Definition: It seems very odd to me that the LISP Packet Types Registry uses Standard Action as the registration policy given that the LISP work is currently Experimental -- and that the other references in it would in fact be from an Experimental RFC ( rfc6380 ).\u00a0 I know there's work on rfc6830bis (in the Standards Track), but I think it would be better to have this registry defined in the base specification (rfc6833bis, in this case)...or to wait for the publication of that document to progress this one. I think there's nothing procedurally wrong with having an Experimental RFC define a Standard Action Registry and populate part of it with references to Experimental RFC.\u00a0 However, the solution just doesn't seem clean to me -- so I would like to hear the justification for the rush (and not waiting for rfc6380bis/rfc6388bis). I have no issue with a document making use of the Code Point to describe the new LISP Shared Extension Message Type (without creating the Registry).\u00a0 But given that the base LISP specification is still Experimental, then this document should be too.\u00a0 There shouldn't be an issue with changing the Status of this document (in-place) once rfc6380bis/rfc6388bis progress. There's also the issue that  RFC6830  (and rfc6833bis) contain the following text: \"This section will be the authoritative source for allocating LISP Type values...\"\u00a0  Which means that (if the registry is to be defined here), this document should at least Update  RFC6830 ... In summary, I think that the correct Status for this document is Experimental.\u00a0 I also think that it would be better to wait for rfc6833bis to define the Registry. \u00a0  [1]  https://mailarchive.ietf.org/arch/msg/lisp/m1EicCexdX1GI183pba-mcHJM7g/?qid=ada479dce3c434bfaf948b0ee8240996",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-02-02 00:24:45-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-01 13:30:15-08:00",
    "text": "* Section 4.1 \"The value 15 is reserved for Experimental Use [ RFC5226 ]\" I don't think this document should be reserving value 15 for Experimental use based on its stated intentions \"a LISP shared message type for defining future extensions and conducting experiments\". RFC3692  defines the experimental values as  \"\u00a0 Mutually consenting devices could use \u00a0  these numbers for whatever purposes they desire, but under the \u00a0  understanding that they are reserved for generic testing purposes, \u00a0  and other implementations may use the same numbers for different \u00a0  experimental uses.\" which means that devices may use any of the sub-types under 15 for experimentation and potentially collide with the \"extension\" uses. I would propose that a sub range of the sub-types (e.g. 2048-4095) under type 15 be reserved for experimentation and the rest of the range (0-2047) for extensions be specified using some other IANA policy (e.g. FCFS as specified in the document).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-11-07 23:31:06-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 11:05:09-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3624 This DISCUSS should be easy to clear. I have noted a few points where I do not believe that the spec is sufficiently clear to implement. DETAIL S 3.4. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 clientUpdateProhibited, serverUpdateProhibited: Requests to update >\u00a0 \u00a0 \u00a0 \u00a0  the object (other than to remove this status) MUST be rejected. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 clientDeleteProhibited, serverDeleteProhibited: Requests to delete >\u00a0 \u00a0 \u00a0 \u00a0  the object MUST be rejected. How does access control work here? If either of these values are set, then it must be rejected? S 4.1.2. >\u00a0 \u00a0 \u00a0 C:\u00a0 \u00a0 \u00a0 \u00a0 res1523 >\u00a0 \u00a0 \u00a0 C:\u00a0 \u00a0 \u00a0  >\u00a0 \u00a0 \u00a0 C:\u00a0 \u00a0  >\u00a0 \u00a0 \u00a0 C:\u00a0 \u00a0 ABC-12345 >\u00a0 \u00a0 \u00a0 C:\u00a0  >\u00a0 \u00a0 \u00a0 C: So I can only\u00a0 one org? S 4.1.2. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 One or more\u00a0 elements that contain the operational >\u00a0 \u00a0 \u00a0 \u00a0  status of the organization, as defined in Section 3.4. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 An OPTIONAL\u00a0 element that contains the identifier of >\u00a0 \u00a0 \u00a0 \u00a0  the parent object, as defined in Section 3.6. It's not clear to me what's really optional here, because you say above that it's up to the server but then you label some stuff here as OPTIONAL",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-13 20:08:00-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-04 15:32:07-07:00",
    "text": "(Quite possibly a \"discuss discuss\"...) What would the behavior be if someone was shipping an implementation that used a point in the 128-255 range intending for the \"private use\" semantics, a conflicting codepoint was assigned via FCFS, and then needed to use the feature with conflicting codepoint in that implementation? It seems likely that we should discuss the plausibility of such scenarios and what options are available to handle it.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-05-06 04:58:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-05-06 04:27:20-07:00",
    "text": "This is a discuss point, but I don't want the document to go forward before this discussion has concluded.  In section 3 the following statement is done:  \u00a0  Note: a separate \"owner\" column is not provided because the owner of \u00a0  all registrations, once made, is \"IESG\". First of all, just because something is under IETF Review policy does not imply that change control of a registration entry is owned by IETF. It might be true that all current entries are established through IETF stream specifications, where it make sense that change control is owned by IETF. So I would recommend that you reformulate the note.  Secondly, the IESG has discussed this and are currently of the opinion that registrations done by IETF documents should be \"owned\" by IETF. We are in the process of establishing an IETF consensus on this. There is currently a draft on this:  https://datatracker.ietf.org/doc/draft-leiba-ietf-iana-registrations/   Reasons for this are several, consistency to intended state, making it clear that it is the IETF that owns IETF specification based registry entries, not created management bodies, thirdly one can replace the IESG with soemthing else without having to update all these registries.  Section 3.  Looking at the table. I see no explanation in this document to these entries. Still you want to add them with this document as reference. Can you please add an explanation behind the values being registered in the below table?  \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  | Value | Description\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Reference /\u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Change\u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Controller\u00a0  | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 128\u00a0 | Prestandard Route Refresh (deprecated)\u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 129\u00a0 | Prestandard Outbound Route Filtering\u00a0 \u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | (deprecated),\u00a0 \u00a0 \u00a0 \u00a0 prestandard Routing\u00a0  | document)\u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | Policy Distribution (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 130\u00a0 | Prestandard Outbound Route Filtering\u00a0 \u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 131\u00a0 | Prestandard Multisession (deprecated)\u00a0 \u00a0 \u00a0 | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 184\u00a0 | Prestandard FQDN (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 185\u00a0 | Prestandard OPERATIONAL message\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 255\u00a0 | Reserved\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-05-12 01:23:16-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-06 04:58:10-07:00",
    "text": "[corrected] I mistook the IETF review policy for the content of the IESG Approval.  This is a discuss point, but I don't want the document to go forward before this discussion has concluded.  In section 3 the following statement is done:  \u00a0  Note: a separate \"owner\" column is not provided because the owner of \u00a0  all registrations, once made, is \"IESG\". The IESG has discussed this and are currently of the opinion that registrations done by IETF documents should be \"owned\" by IETF. We are in the process of establishing an IETF consensus on this. There is currently a draft on this:  https://datatracker.ietf.org/doc/draft-leiba-ietf-iana-registrations/   Reasons for this are several, consistency to intended state, making it clear that it is the IETF that owns IETF specification based registry entries, not created management bodies, thirdly one can replace the IESG with soemthing else without having to update all these registries.  Section 3.  Looking at the table. I see no explanation in this document to these entries. Still you want to add them with this document as reference. Can you please add an explanation behind the values being registered in the below table?  \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  | Value | Description\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Reference /\u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Change\u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Controller\u00a0  | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 128\u00a0 | Prestandard Route Refresh (deprecated)\u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 129\u00a0 | Prestandard Outbound Route Filtering\u00a0 \u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | (deprecated),\u00a0 \u00a0 \u00a0 \u00a0 prestandard Routing\u00a0  | document)\u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | Policy Distribution (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 130\u00a0 | Prestandard Outbound Route Filtering\u00a0 \u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 131\u00a0 | Prestandard Multisession (deprecated)\u00a0 \u00a0 \u00a0 | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 184\u00a0 | Prestandard FQDN (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 185\u00a0 | Prestandard OPERATIONAL message\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  | (deprecated)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+ \u00a0  |\u00a0 255\u00a0 | Reserved\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | (this\u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | document)\u00a0 \u00a0 | \u00a0  +-------+--------------------------------------------+--------------+",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-21 15:28:20-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 13:29:48-07:00",
    "text": "The prose and tabular IANA considerations in \u00a711.3 are inconsistent about whether the End.X/LAN End.X SID sub-TLVs are allowed to appear in TLV 25.\u00a0 (I may have noted all instances in the prose, in my COMMENT, but it's worth checking for others.)",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-06-21 15:48:51-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 18:58:26-07:00",
    "text": "[ section 9 ] * I share the concerns of several of the others here about SRv6 SIDs being \u00a0 claimed to be IPv6 addresses but kinda not really being IPv6 addresses \u00a0 if their internal structure is exposed outside of the given SR router. \u00a0 If \"[i]t's usage is outside of the scope of this document\", can this be \u00a0 removed for now, and maybe take up the issue at some point in the future \u00a0 by which time a motivating use case might have presented itself?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-10-20 01:39:46-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-18 14:57:43-07:00",
    "text": "Thanks for the work on this document. I was not around for  RFC 8986 , and I am not sure I understand the use case fully (I agree with Ben there), but I'll trust the responsible AD and the wg. I'll also note that I was hoping to see \"Implementation status report\" in the draft, as mentioned in the shepherd writeup, and was disappointed not to find any. However, I'd like to discuss a number of points, mostly on the IANA considerations and on detailed fields descriptions. I also want to bring 7. below regarding the IANA registries names to your attention, although it's not a hill I am willing to die on (that one is a \"let's talk\" DISCUSS, the rest I hope can be acted upon). As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- Section 7.1 FP: The locator entries ASCII figure is not consistent with the descriptive text following it: specifically, Loc Size should follow Algorithm directly; instead, the picture seems to show there are 2 octets unused between Algorithm and Loc Size. 2. ----- \u00a0 \u00a0 \u00a0 Type: 5. FP: For consistency (and to make sure implementers don't rely on the ASCII figure), it would be good to indicate Type's length (1 octet I assume). 3. ----- \u00a0 \u00a0 Length: variable. FP: This does not help much understanding what this field is supposed to contain. 4. ----- Section 7.2 FP: Same issue as in 1. for the ASCII figure. 5. ----- Sections 8.1 and 8.2 FP: Same comments as 1. 2. and 3. 6. ----- \u00a0 If a behavior is advertised it MUST \u00a0  only be advertised in the TLV[s] as indicated by \"Y\" in the table \u00a0  below, and MUST NOT be advertised in the TLV[s] as indicated by \"N\" \u00a0  in the table below. FP: I find the sentence after the comma confusing, and don't understand the presence of the MUST NOT here. 7. ----- Section 11.1.1 FP: It sounds like a bad idea in general to have to rename the registry every time a TLV needs to be added to the registry... Maybe the wg and the AD should consider renaming the registries so not to have this sort of dependency. (I understand that this is a low priority comment, but still, it feels wrong to put in titles what would fit really well in a registry itself). This very much applies to Section 11.6 as well: the registry's name with the hierarchy of TLVs as part of the name feels like a really bad idea. That is typically data that goes into registries. 8. ----- Section 11.3 FP: The registry needs to be defined in the document. In particular, I see that IANA is interpreting the columns as \"Value\" \"Description\" \"Reference\"; is that right or should this be \"Type\" \"Description\" \"Reference\" (I see a mix of the two for different IANA registries)? 9. ----- Section 11.8 FP: Are bits 0, 2-15 reserved or unassigned? The terminology in section 2 is ambiguous, as it talks about \"reserved for future use\" (but the IANA section leaves them unassigned). Please clarify for IANA. 10. ----- Section 11.10 FP: Please define the registry (I assume it is going to be \"Bit #\", \"Name\", \"Reference\").",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-06-02 06:53:45-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-02 05:36:25-07:00",
    "text": "here was a Gen-ART review with some minor but good questions about clarifications. I believe there should be a revision or a response.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-08-18 12:25:51-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-16 07:46:13-07:00",
    "text": "== Section 12 == \"This document allows for additional parameters (generic-param) to be \u00a0  included in the Session-ID header.\u00a0 This is done to allow for future \u00a0  extensions while preserving backward compatibility with this \u00a0  document.\u00a0 To protect privacy, the data for any generic-param \u00a0  included in the Session-ID header value MUST NOT include any user or \u00a0  device information.\" To preserve the privacy properties of the session identifier, I think this prohibition needs to extend further -- not just to any user or device information, but to any identifier that persists beyond the current session. Otherwise some parameter defined in the future could easily be used to correlate sessions, while the identifier is currently specified so as to avoid that.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-08-18 07:25:48-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-15 14:03:43-07:00",
    "text": "(I'm entering a DISCUSS to make sure we get discussion of this topic among the ISEG before we progress the document. Whatever the outcome, I expect to clear the DISCUSS and go back to a YES position after the telechat.) Please see the thread resulting from Elwyn's gen-art review from the 2nd IETF last call, called specifically because of the downref to  RFC 7206  that was added after the first LC. This downref was due to the definitions of \"communication session\" and \"session ID\" from that RFC. https://mailarchive.ietf.org/arch/msg/gen-art/3cLlqju62bY1w5MTA72YpOjL_GQ",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-18 19:53:50-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-16 16:30:46-07:00",
    "text": "* Section 5 I do have a concern about backward compatibility regarding the sess-uuid. Looks like this document allows the sess-uuid to contain either uppercase or lowercase hex digits (\"sess-uuid\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  = 32(DIGIT / %x41-46 / %x61-66)\") while the legacy version in  RFC7329  does not allow uppercase hex digits. Looks like a compliant implementation of the spec using upper case hex digits will fail to interoperate with a legacy implementation. I do not have a particular preference, but either this rule needs to be tightened or there needs to be some text added to Section 11 to say this will cause an interoperability issue.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-05-14 06:22:17-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-13 10:16:36-07:00",
    "text": "The Gen-ART reviewer noted that there seems to be one case of how OPEN is handled that is under-specified. In Section 3.2.1 and Section 4.1, if the originator sends an OPEN with P set to 0 and the response has P set to 1, what is the originator expected to do?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-05-23 12:43:35-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-22 11:52:59-07:00",
    "text": "I'm sure that this has already been discussed somewhere, and that I'll be able to quickly clear my DISCUSS once pointed at it, but:  \"To put an upper bound on the amount of time a router retains the stale routes, an implementation MUST support a (configurable) timer, called the \"stale timer\", that imposes this upper bound. A suggested default value for the stale timer is 180 seconds. An implementation MAY provide the option to disable the timer (i.e., to provide an infinite retention time) but MUST NOT do so by default.\" The \"infinite retention time\" part of this makes me deeply uncomfortable -- I can see a good reason for the stale timer, and the default \"feels\" fine to me, but having an infinite retention time (or, really anything over 10 to 15 minutes) feels like a really dangerous idea, and that it will come back and bite.  I'm hoping that I'm missing something obvious, but can you please explain under what conditions an infinite retention policy makes sense? It seems like there would be multiple opportunities for blackholing traffic with this.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-13 21:14:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 22:24:52-08:00",
    "text": "The original IAB charter in  RFC 2850  claims that the IAB is chartered both as a committee of the IETF and as an advisory body of the Internet Society. Can we change the charter and retain this dual status, without approval of the Internet Society? It seems this was already considered, in https://mailarchive.ietf.org/arch/msg/rfced-future/RMeW4u_-ZbeJ23oYUcZ9ZAg2kkY/  , but the mailarchive does not seem to find any evidence that any action was taken to consult the ISOC Board.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-03-10 07:53:42-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-08 23:10:46-08:00",
    "text": "his doc has a DOWNREF to Informational draft-iab-rfcedp-rfced-model,which I failed to include in the Last Call message.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-10 15:35:02-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-10 12:38:34-07:00",
    "text": "Do not panic! This should be trivial to address, probably by pointing me at something that I missed (very likely), or by dropping in a sentence to two into the document. The document starts off with: \"This document describes a method to transport Internet Key Exchange Protocol (IKE) and IPsec packets over a TCP connection for traversing network middleboxes that may block IKE negotiation over UDP.\" As far as I can tell (and again, it is likely that I missed something!) it doesn't really discuss the fact that the operator may be intentionally blocking IKE. For example, many enterprises really don't want their users to be building IPSec tunnels into/out of their network because they want to do DLP, firewalling, and so they block IKE to block IPSec. This may be a flawed concept, and you and I may think that it's a losing battle, but I really think that the document needs to at least discuss that this potentially bypasses intentional security controls. See:  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-11-28 11:27:51-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-18 21:42:00-08:00",
    "text": "I have two points that I'd like to discuss, both of which should be very easy to resolve: -- Section 10.1 -- For all the capability values you say something like this: \u00a0 \u00a0 \u00a0 It MUST be set to some value between 1 and 7 \u00a0 \u00a0 \u00a0 included (4 is the default) if the router is capable of proxying \u00a0 \u00a0 \u00a0 MDNS and 0 otherwise. First, the word you want is \"inclusive\", not \"included\". Second, \"4 is the default\" really means that you can set it to 0, and that's the same as setting it to 4.\u00a0 But it seems that 0 means that the router does not have the specified capability.\u00a0 Those seem to be in conflict.\u00a0 I strongly suggest you do NOT have a default, and allow the use of 0 *only* to designate lack of that capability. Please discuss this with me to make sure I'm not misunderstanding you here. -- Section 13 -- I have two concerns with how the HNCP TLV Types registry is specified: 1. Because the DNCP TLV Types registry specifically allocates 32-511 for profiles, it'd be better to simply limit the range of values in this registry to those values, rather than making it broader and duplicating the other values from the other registry. 2. I think it's a bad idea for HNCP to re-define DNCP's Private Use range in its registry.\u00a0 I would rather see this be text in the document (here in the IANA Considerations is a fine place for it) that says that HNCP uses the Private Use range for per-implementation experimentation, and not have that be in the HNCP registry. In other words, I'd make it more like this (and add a reference to  RFC 5226 ): NEW \u00a0  IANA should set up a registry for the (decimal values within range \u00a0  32-511, as allocated to profiles by DNCP) \"HNCP TLV Types\" under \u00a0  \"Distributed Node Consensus Protocol (DNCP)\", with the following \u00a0  initial contents: \u00a0 \u00a0 \u00a0 32: HNCP-Version \u00a0 \u00a0 \u00a0 33: External-Connection \u00a0 \u00a0 \u00a0 34: Delegated-Prefix \u00a0 \u00a0 \u00a0 35: Assigned-Prefix \u00a0 \u00a0 \u00a0 36: Node-Address \u00a0 \u00a0 \u00a0 37: DHCPv4-Data \u00a0 \u00a0 \u00a0 38: DHCPv6-Data \u00a0 \u00a0 \u00a0 39: DNS-Delegated-Zone \u00a0 \u00a0 \u00a0 40: Domain-Name \u00a0 \u00a0 \u00a0 41: Node-Name \u00a0 \u00a0 \u00a0 42: Managed-PSK \u00a0 \u00a0 \u00a0 43: Prefix-Policy \u00a0 \u00a0 \u00a0 44-511: Unassigned \u00a0 \u00a0 \u00a0  \u00a0  The policy \"RFC Required\" [ RFC5226 ] should be used for future \u00a0  assignments. \u00a0  The range reserved by DNCP for Private Use (768-1023) is used by \u00a0  HNCP for per-implementation experimentation.\u00a0 How collisions are \u00a0  avoided is out of scope of this document. END Does that make sense?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-11-26 10:33:55-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-18 06:19:47-08:00",
    "text": "One issue to be discussed: the link with the future BCP  draft-ietf-v6ops-reducing-ra-energy-consumption-03 , on the same telechat.  draft-ietf-v6ops-reducing-ra-energy-consumption-03  mentions: \u00a0  \"On links with a large number of battery-powered devices, sending \u00a0  solicited Router Advertisements multicast can severely impact host \u00a0  power consumption.\" From this document: I see \"HNCP operates on multicast-capable interfaces only\" Do we expect battery-powered devices in homenet? I guess so: my phone for example. I discussed this topic with Mark Townsley, who is on it already.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2015-11-30 07:04:58-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-19 05:59:25-08:00",
    "text": "* I see where HNCP describes how interfaces are classified as internal or external, but how does an interface get classified as leaf, guest, or ad-hoc?\u00a0 Is this some manual configuration step that needs to be described somewhere? * The definition of Leaf in 5.1 is unclear.\u00a0 It says \"Such an interface uses the Internal category with the exception that HNCP traffic MUST NOT be sent on the interface, and all such traffic received on the interface MUST be ignored.\" The \"all such traffic\" is ambiguous. Based on the definition of the Guest category, I think \"all such traffic\" is really \"all HNCP traffic\". * The text in section 5.3 seems incomplete. It gives a 4-step algorithm for border discovery, but says \"if the node does not implement auto-detection, only the first step is required.\" If auto detection is not supported and a fixed category is not configured, what happens? Does this mean that if auto detection is not supported manual configuration of the border is required? * Section 7 describes how to handle non-HNCP capable routers. However, I don't see any operational issues described that could arise from having a non-HNCP capable router connecting two clouds of HNCP within the same home network. It seems like that could cause problems with a bunch of the services provided by HNCP.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-12-03 06:01:26-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-17 15:50:28-08:00",
    "text": "I have a couple of pints to discuss that should be pretty easy to resolve as I wasn't clear on the first because of wording (should be very simple) and would like to chat about the second.\u00a0 Thanks. 1. I'm not clear on one of the bullets in section 3,  \u00a0 o\u00a0 HNCP nodes MUST use the leading 64 bits of MD5 [ RFC1321 ] as DNCP \u00a0 \u00a0 \u00a0 non-cryptographic hash function H(x). Is this meant to use a message digest ( RFC1321 ) or a cryptographic hash for authentication ( RFC2104 )?\u00a0 If it's the former, can you make this more clear in the bullet?\u00a0 If it's the latter, can you update the reference and the number of bits to use for truncation is 80 for the minimum.\u00a0 You do explicitly mention HMACs later on for PSKs using SHA256, so maybe the reference is correct and the wording should just be a bit more clear? 2. Can you explain why DTLS is a SHOULD and not a MUST?\u00a0 The bullet in section 3 reads as if this is for use, not implementation.\u00a0 Is there a MUST for implementation (I didn't see one, but maybe I missed that)?  Could you add a reference to  RFC7525  to help with configuration and cipher suite recommendations?\u00a0 This could be in section 12, security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-12-04 08:51:41-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-19 06:20:43-08:00",
    "text": "(Sorry for the N-th discuss, I quite like this protocol and I'm sure we'll get 'em all cleared soon, but... ;-)   I'd like to chat about whether or not the DTLS recommendations are correct here. To me, the consensus stuff (from section 8.3 of dncp) is not clearly baked (as I noted in iesg review of dncp). The PKI stuff is well known, even if it it is a PITA from many points of view. I don't think a SHOULD for the former and a MAY for the latter is appropriate now. If the consensus based stuff gets deployed and works, then it might be time to say what you're now saying, but I don't think we're there yet. (I'd be happy to look @ evidence that we are, and to change my opinion accordingly.) Please note that I think I like the consensus based scheme, I'm just concerned it may not be ready for prime time. I'm also not really convinced that all you need to do to get interop for that is mention it and refer to dncp. But again, I could be wrong and would appreciate being corrected if so. In summary, I think you should say \"when using DTLS with asymmetric keying, then you SHOULD support the PKI-based method and MAY support the consensus based method, which is still somewhat experimental.\"",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-10 10:51:57-08:00",
    "end_reason": "position_updated",
    "start": "2016-03-09 06:19:09-08:00",
    "text": "Many thanks for doing this work. Before I ballot yes on this one, there are two things I'd like to check (and a bunch of  non-blocking comments about which I'm also happy to chat): (1) 4.2: Why didn't you just mandate one way of calculating a fingerprint as being mandatory to implement? (E.g. a sha256 hash of the DER encoded SPKI?) and why is the \"don't pin to a CA\" rule in appendix A not a MUST in the body of the document? Wouldn't it be better to do both of those? (Or to say why you're not doing them, e.g. if current implementations do different things.) Given that recursives publishing PINs will pick something, having that something supported by all clients would seem like a fine thing. (2) Section 5: Is it ok to (almost:-) recommend TLS false start like that?\u00a0 Don't you need to at least point out that that has additional requirements over and above  RFC7525 ? I've not checked those in detail though, as I'm waiting for the TLS WG to do their publication request for false start. If you've done that checking, then you might be just able to say \"yeah, that's not a problem\" but I'd like to know since implementers here are likely to read this as saying \"Do  RFC7525  and you're good.\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-09-14 14:45:07-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-14 14:25:46-07:00",
    "text": "(0) (I came to this realization rather late in my review process, so there may be places where the COMMENT and this discuss point are in disagreement; this DISCUS takes precedence.) I fear that the construction that separately distributes ENC_KEY and MAC_KEY in an attempt to achieve privilege separation is fatally flawed. In particular, the CBC encryption mode is a malleable encryption mode, in that flipping a bit of ciphertext will filp the corresponding bit of the next block of recovered plaintext (at the cost of completely garbling the recovered block containing the bit that was modified). Subsequent blocks are unaffected.\u00a0 Typically we combine CBC mode with a MAC such as HMAC in order to prevent such modifications from being exposed as attack vectors, and while we do use HMAC here for that purpose, we also introduce a separate class of actors that have access to the HMAC key but not the encryption key.\u00a0 Accordingly, those actors can produce a new, valid, integrity tag after making a modification to the ciphertext, allowing them to engage in attacks that make use of ciphertext malleability.\u00a0 Ciphertext malleability is particularly useful as an attack vector when the structure of the plaintext being encrypted is known, and there are portions of the plaintext that the application will either ignore if they are garbled or are expected to be near random in the normal case (and thus for which garbled output does not cause rejection by the application).\u00a0 In a SFC environment it seems highly likely that the structure of the plaintext will be known or guessable, and we don't have any real mechanisms to control what types of metadata go into encrypted context headers, so it seems that we must act as if we are exposed to this risk. While \u00a74.3 does have a note that use of GCM with HMAC is undesirable due to the additional authentication tag, it may be unavoidable in order to provide the properties that we need. (1) Section 5.1 describes the MAC as: \u00a0  Message Authentication Code:\u00a0  Covers the entire NSH data, excluding \u00a0 \u00a0 \u00a0 the Base header.\u00a0 The Additional Authenticated Data (defined in \u00a0 \u00a0 \u00a0 [ RFC7518 ]) MUST be the Service Path header, the unencrypted \u00a0 \u00a0 \u00a0 Context headers, and the inner packet on which the NSH is imposed. This description seems to exclude from the MAC most of the MAC context header itself (if we go by the corresponding figure), which is very bad for security.\u00a0 We definitely need to include under the MAC the MAC context header bits from metadata class through and including at least timestamp, and I think IV length as well.\u00a0 (The IV itself would be incorporated via the ciphertext, since the IV is an input to encryption, but since the IV length field indicates whether or not encryption was performed, we'd need to protect that information.) Similarly, Section 5.2 has the description: \u00a0  Message Authentication Code:\u00a0 Coves the entire NSH data.\u00a0 The \u00a0 \u00a0 \u00a0 Additional Authenticated Data (defined in [ RFC7518 ]) MUST be the \u00a0 \u00a0 \u00a0 entire NSH data (i.e., including the Base Header) excluding the \u00a0 \u00a0 \u00a0 Context Headers to be encrypted. which on the face of it includes the field that holds the MAC itself (and is not yet populated), i.e., is self-referential. I think we need to be much more precise about the construction of the AAD in both cases.\u00a0 It's possible that the HMAC construction for the no-encrypted-context-headers case can inherit a definition from the AAD description, but if not we'll need to have some more precision there as well. (2) In order for the MAC-only construction in \u00a77.2 to be compatible with the AEAD integrity tag construction, we would need to include the 64-bit AL after A.\u00a0 While HMAC is intrinsically immune to length-extension attacks, I think that having the explicit AL is useful to avoid any risk of malleability, since the same MAC_KEY is used for constructing both types of MACs. (3) Section 5.1 describes the Timestamp field as an \"unsigned 64-bit integer value\", which is inconsistent with the actual format given in Section 6. (4) Section 7.5 directs the verifier to check if \"the value of the newly generated digest is identical to the one enclosed in the NSH\".\u00a0 It is critical for the security of the system that this comparison be done in a constant-time manner that does not provide a side channel into whether the generated digest and the value in the NSH share a common substring. (5) Do the MAC context headers always have to be the last metadata entries in the packet (to simplify the cryptographic calculations)? Certainly the diagrams only show \"unencrypted context headers\" appearing prior to the MAC context header, so if we expect unencrypted context headers to appear after the MAC context header as well, we should be clear about that both in the figures and in the specification for how to prepare the AAD.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-09-13 06:54:22-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-13 05:17:34-07:00",
    "text": "Thank you for the work put into this document. Special thanks to Greg Mirsky for his shepherding especially about his summary of the WG consensus. Please find below some blocking DISCUSS point (which should be easy to fix), some non-blocking COMMENT points (but replies would be appreciated), and one nit. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == I failed to spot the order of the operations for the integrity and confidentiality operations, e.g., I did not find on what the HMAC is computed: in the unencrypted or encrypted field ? -- Section 5.1 -- What is the unit of \"key length\", I assume a length expressed in octets but it is not specified. -- Section 7.2 -- What is the \"A\" used in the HMAC computation ? The formula specifies HMAC-SHA-256-128() but what if another HMAC is used ? Section 7.3 use MAC() which is more flexible. As the MAC field is included in the integrity protected header, please specify the value of this field when computing the HMAC (I assume 0 but let's be clear) -- Section 7.5 -- What is the expected behavior when a NSH does not contain a \"MAC and Encrypted Metadata\" Context Header ? \u00a71 hints to packet drop ? Should there be a local policy for this case ?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-07-26 10:25:44-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-14 23:13:29-07:00",
    "text": "Enough other Area Directors have said, and I agree, that this should officially update  RFC 8300 , so I'd like to have the discussion.\u00a0 In particular, given that this was identified as a gap in  RFC 8300 , and since I don't see any explicit statement that this is meant to be an optional extension, shouldn't it be an update?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-09-18 14:14:55-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-13 12:02:24-07:00",
    "text": "** Section 4.6.\u00a0 This section explains that an upper NSH can be encapsulated in a lower NSH, and that \u201cthe Upper-NSH information is carried along the lower-level chain without modification.\u201d\u00a0 I read this to mean that the upper and lower NSH can independently be protected with different keys.\u00a0 The text even helpfully points out that \u201cKeying material used at the upper-level domain SHOULD NOT be the same as the one used by a lower-level domain.\u201d\u00a0 Such a construct suggests that there are multiple MAC/Encrypted Metadata context headers, one for the upper and another for the lower.\u00a0 However, Section 7.1 later notes that \u201cOnly one instance of \"MAC and Encrypted Metadata\" Context Header (Section 5) is allowed.\u201d\u00a0 This seems like conflict.\u00a0 What am I missing? ** Section 7.2.\u00a0 On computing the HMAC in an integrity only situation: -- This section defines the MAC as \u201cT = HMAC-SHA-256-128(MAC_KEY, A)\u201d.\u00a0 Previously, A was defined as the Additional Authenticated Data (per Section 4.2).\u00a0 Since this isn\u2019t the AEAD use case, there is no A. It seems that this should be something closer to: \u201cT = HMAC-SHA-256-128(MAC_KEY, )\u201d. -- The text would benefit from a description on how to serialize the packet for hashing.\u00a0 For example, Figure 6 and 7 are helpful logical descriptions of the integrity scope.\u00a0 However, the MAC field itself is depicted as part of the what should get hashed.\u00a0 Should that field be zeroed out? Removed?  ** Section 9. \u00a0  The attacks discussed in [ I-D.nguyen-sfc-security-architecture ] are \u00a0  handled owing to the solution specified in this document, except for \u00a0  attacks dropping packets.\u00a0  The above reference highlights the following attackers \u2013 \u201cThere are many types of compromised switches attack: packet dropping, packet duplicating, packet manipulating, incorrect forwarding,\u00a0 eavesdropping, weight adjusting, man-in-the-middle, state-spoofing, control-channel hijacking, etc.\u201d\u00a0 Per the security services in this document, it doesn\u2019t seem like all are mitigated by this draft as described above: -- packet dropping = noted as not being handled -- packet manipulating, eavesdropping, weight adjusting, man-in the-middle, state-spoofing, and control-channel hijacking = appear to be handled if both security services are applied -- packet duplicating = this draft doesn\u2019t not provide a standardized approach for mitigating this issue -- incorrect forwarding = doesn\u2019t appear to be mitigated.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-10-17 08:36:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 23:13:23-07:00",
    "text": "The new \"Segment Routing Header TLVs\" registry (\u00a78.2) includes a range \"for TLVs that may change en route\".\u00a0 However, I couldn't find a specification for these types of TLVs.\u00a0 The only clues come from \u00a74.3.1 (FIB Entry Is Locally Instantiated SRv6 SID), where it says: \u00a0  Processing this SID modifies the Segments Left and, if configured to \u00a0  process TLVs, it may modify the \"variable length data\" of TLV types \u00a0  that change en route.\u00a0 Therefore Segments Left is mutable and TLVs \u00a0  that change en route are mutable.\u00a0 The remainder of the SRH (Flags, \u00a0  Tag, Segment List, and TLVs that do not change en route) are \u00a0  immutable while processing this SID. I am balloting DISCUSS because the description of \"TLVs that may change en route\" is not clear or specific enough.\u00a0 I would like to see a clear specification of what \"TLVs that may change en route\" are, *AND* corresponding instructions to the Designated Experts-to-be.\u00a0  \u00a0  Some related questions that come to mind include: Where can these TLVs be  \u00a0  processed/changed?\u00a0 If the data is modified, what about the alignment,  \u00a0  should the Padding TLVs be also changed?\u00a0 If no data is left, can the TLV be  \u00a0  removed?\u00a0 The instructions above (for the SRV6 SID) seem generic enough to  \u00a0  apply to other potential future SIDs, what type of variation is expected?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-10-10 13:35:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 14:09:12-07:00",
    "text": "I find the new registries (not \"registers\", as in the titles of Sections 8.1 and 8.2) to be oddly defined, and would like to discuss that. In Section 8, you seem to be giving instructions to the designated expert to require an RFC.\u00a0 You also seem to be telling the DE to consult the 6man working group (or the residual mailing list, after the WG closes).\u00a0 So when you say \"Expert Review\", you're really saying at least \"Expert Review and RFC Required\", and possibly \"Expert Review and IETF Review\".\u00a0 I suggest that you instead go with \"IETF Review\" and eliminate the need for a designated expert.\u00a0 If you want to additionally require specific review on the 6man list, you can add that to the IETF Review, with something like \"IETF Review, with at least a two-week review on the 6man list,\" or some such.\u00a0 (You could also consider \"Standards Action\" if you want to require that the RFC be Standards Track and not, say, Experimental or Informational.)\u00a0 The point of having a DE is to handle cases when you are NOT necessarily using RFCs to do the registrations, and you don't have the consequent IETF review of things.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-18 10:39:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-03 19:52:30-07:00",
    "text": "(1) Section 2.1.2.1 says: \u00a0  Local configuration determines when to check for an HMAC and \u00a0  potentially indicates what the HMAC protects, and a requirement on \u00a0  where the HMAC TLV must appear (e.g. first TLV), and whether or not \u00a0  to verify the destination address is equal to the current segment. I'm uncomfortable about leaving so much of the semantics of a security mechanism up to the local configuration. Specifically, the \"potentially indicates what the HMAC protects\" and \"whether or not to verify the destination address is equal to the current segment\", which leaves some of the key security properties of the system in the hands of someone that is potentially quite inexperinced in reasoning about the relevant security properties. I do think we can still specify something useful and interoperable that still allows flexibility about when to check and where the TLV can appear.\u00a0 (This may in practice also allow flexibility about what it protects, if the semantics are something like \"it protects everything prior to it\" and we allow for other TLVs to appear after it, but the actual *rules* for what it protects would be well-specified.) (2) I also think we should discuss what is protected by the HMAC.\u00a0 I note in the COMMENT that this seems to be more about protecting the SRH contents than the packet payload, but at present there is no binding at all to the containing packet or flow, which seems to in effect present the SRH as a self-contained, \"signed\", policy blob, which can be detached from packet data and transferred at will.\u00a0 It's probably also best practice to include a fixed \"contxt string\" like \"IPv6 SRH HMAC\" even though the risk of key reuse and cross-protocol attacks seems quite small here. It's also pretty tempting to pull in the representation of the \"immutable TLVs\", though there are probably some tricky details to describing how to do that, and that can present complexity challenges if/when nodes not trusted with HMAC keys are expected to apply varying TLVs at runtime.\u00a0 (The lack of defined TLVs other than HMAC and padding make it hard for an outsider to gague the intent for TLV usage.) (3) I'm concerned that this mechanism may not be consistent with  BCP 107 's guidance on automated vs. manual key management, with respect to directly using the long-term HMAC key to key the HMAC.\u00a0 Most modern designs will introduce an intermediate key-derivation step that mixes some message- or flow-specific data into the intermediate key that is then used to key the per-message MAC.\u00a0 Section 5.5 seems to suggest that the IPv6 flow label may be usable (i.e., fixed within the domain for a given flow) for this purpose, but I may be missing a subtlety about intra- vs. inter-domain traffic, and it may not be feasible to involve a central controller into flow identifier assignment. If the HMAC is solely intended to make self-contained \"authorized policy blobs\" that are infrequently changing, then the direct use of the long-term key may not be as problematic as it first seems. Additionally, if the SDN-oriented or \"trusted key distribution protocol such as [ RFC6407 ]\" cases are used, then this is somewhat less of a concern, though there may still be key usage lifetime considerations to worry about and potentially force somewhat-rapid key turnover (i.e., weeks or months). (4) I'm not sure that the scoping of key IDs per destination node is consistent with the use cases depcicted.\u00a0 I mention this in the COMMENT section in a few places, but the short version is roughly \"if the HMAC is fixed for the life of the packet, then we can either have the key ID namespaced by destination address but only have one verifier, or we can have multiple verifiers on the path but the key ID space is global\".\u00a0 We do currently have text that talks about verification being performed at multiple points on the path, so I'm not sure which scenario is intended. (5) I think we need to have some discussion about key revocation/rotation.\u00a0 The mode of operation for the HMAC TLV that appears to be envisioned by this document is that there is a central trusted service that computes \"blessed\" segment routes with an accompanying HMAC \"signature\" (not a real signature, but a sign of aproval in some sense), and that the resulting token of (SRH including HMAC TLV) is distributed by SDN configuration.\u00a0 These SRH tokens are treated by many nodes as opaque blobs, applied to outgoing traffic according to the procedure configured alongside the token.\u00a0 Some other (trusted) nodes in the network may look inside the SRH to verify the MAC, and check that the rout in question should be coming from that direction, but those nodes may be a minority of nodes.\u00a0 In this scenario, we need to consider the behavior when the central controller changes what routes are to be used, and effectively wants to \"revoke\" the old ones and ensure that the deprecated routes are not in use in the SR domain.\u00a0 The only mechanism for doing so seems to be to rotate the HMAC key in question so as to discard all HMACs generated by the key in question (since keeping something akin to a CRL of \"revoked\" HMAC values seems infeasible in general); I think we should have some discussion about needing to do a key rotation to effectuate such \"revocation\" (that is, cryptographically ensure that previously configured/\"blessed\" routes are no longer in use).\u00a0 It would also be pretty easy to tie this in to text about recovering from a compromised HMAC key.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-09-17 00:45:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-05 05:12:21-07:00",
    "text": "I have several issues that appears to be serious enough that I really like some feedback on them prior to approving the document.    1. Section 2.1:    \t\u00a0  An implementation MAY limit the number and/or length of TLVs it \u00a0  processes based on local configuration.\u00a0 It MAY: \to\u00a0 Limit the number of consecutive Pad1 (Section 2.1.1.1) options to \u00a0 \u00a0 \u00a0 1, if padding of more than one byte is required then PadN \u00a0 \u00a0 \u00a0 (Section 2.1.1.2) should be used. \to\u00a0 Limit the length in PadN to 5. \to\u00a0 Limit the maximum number of non-Pad TLVs to be processed. \to\u00a0 Limit the maximum length of all TLVs to be processed. \tThe implementation MAY stop processing additional TLVs in the SRH \u00a0  when these configured limits are exceeded.   \tIsn't this repeating the same interoperability and extensibility issues we have for IPv6 extension headers in an IPv6 Routing header? Wouldn't it be better to tighten a bit the possibilities for the basic support of at least handling TLVs, and if anyone defines something larger they know this will be more uphill work to ensure that you get support for it. But it will making matching the constraints likely more easily to deploy as implementations haven't made different choices of what is required to support when it comes to handling TLVs and buffer them for example in their implementations.    2. Section 2.1.2.1 \u00a0  If HMAC verification fails, an ICMP error message (parameter problem, \u00a0  error code 0, pointing to the HMAC TLV) SHOULD be generated (but rate \u00a0  limited) and SHOULD be logged. Shouldn't it be made explicit that the packet should be discarded? Please clarify the text.  3. Section 5.3: 5.3.\u00a0 MTU Considerations \tAn SR Domain ingress edge node encapsulates packets traversing the SR \u00a0  Domain, and needs to consider the MTU of the SR Domain.\u00a0 Within the \u00a0  SR Domain, well known mitigation techniques are RECOMMENDED, such as \u00a0  deploying a greater MTU value within the SR Domain than at the \u00a0  ingress edges. I find this section very much lacking. Considering that the minimal usage of this RH is 24 bytes, and getting above 100 bytes of overhead is trivial. 3 segments plus the HMAC TLV is 96 bytes.  The text mentions well known techniques (Note plural) but suggests only one. Are the more that can be referenced?  The one mentioned requires one to calculate the worst case overhead for the SR domain for the this routing header. Then take the lowest available path MTU and subtract that worst case overhead to find the supported MTU. Then police that value at the ingresses to the SR domain to ensure consistent behavior that Path MTU discovery methods can work with.  What do you do if one of the path MTUs inside the SR domain is 1280?  This document do need to answer this question or I believe write an applicability statement restrict this to not work in such network where the 1280 minimal MTU can be ensured. As Joe Touch note in his TSV-ART review this is non trivial and I don't see punting on these MTU question will work in general:  https://mailarchive.ietf.org/arch/msg/tsv-art/cdMgmFS79lBr7oha9Z4S4qqqA8c",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-10-07 00:46:17-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-17 00:45:23-07:00",
    "text": "Thanks for resolving some of my discusses.  3. Section 5.3: 5.3.\u00a0 MTU Considerations \tAn SR Domain ingress edge node encapsulates packets traversing the SR \u00a0  Domain, and needs to consider the MTU of the SR Domain.\u00a0 Within the \u00a0  SR Domain, well known mitigation techniques are RECOMMENDED, such as \u00a0  deploying a greater MTU value within the SR Domain than at the \u00a0  ingress edges. I find this section very much lacking. Considering that the minimal usage of this RH is 24 bytes, and getting above 100 bytes of overhead is trivial. 3 segments plus the HMAC TLV is 96 bytes.  The text mentions well known techniques (Note plural) but suggests only one. Are the more that can be referenced?  The one mentioned requires one to calculate the worst case overhead for the SR domain for the this routing header. Then take the lowest available path MTU and subtract that worst case overhead to find the supported MTU. Then police that value at the ingresses to the SR domain to ensure consistent behavior that Path MTU discovery methods can work with.  What do you do if one of the path MTUs inside the SR domain is 1280?  This document do need to answer this question or I believe write an applicability statement restrict this to not work in such network where the 1280 minimal MTU can be ensured. As Joe Touch note in his TSV-ART review this is non trivial and I don't see punting on these MTU question will work in general:  https://mailarchive.ietf.org/arch/msg/tsv-art/cdMgmFS79lBr7oha9Z4S4qqqA8c",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-15 14:33:47-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 11:50:07-07:00",
    "text": "(1) Section 7.1.\u00a0 This section seems to be enumerating the attacks possible with source routing, and noting that the scope of these are limited to nodes inside the SR domain because of SRH requires ingress filtering.\u00a0 No issue with this position.\u00a0 This feedback is around the clarity of the attacks in question.\u00a0 The text currently says: (a) (from the CanSecWest reference in from  RFC5095 ) \u201cSuch attacks include bypassing filtering devices, reaching otherwise unreachable Internet systems, network topology discovery, bandwidth exhaustion, and defeating anycast\u201d (b) In addition, \u201cother known attacks on an IP network (e.g.\u00a0 DOS/DDOS, topology discovery, man-in-the-middle, traffic interception/siphoning)\u201d are also noted. -- Per (a), the issue is broader than \u201cbypassing filtering devices\u201d, it\u2019s also the \u201cbypassing of network management, auditing or security devices\u201d. -- Per (b), the enumeration of attacks using the parenthetical suggested that these attacks are generically possible on \u201cIP networks\u201d and not SRH specific.\u00a0 If that is the appropriate read, then somewhere in the earlier text it should be noted that SRH can also facilitate traffic steering for DDoS, eavesdropping and traffic manipulation through the manipulation (deletion, re-ordering) of the SRHs.\u00a0 If (b) is a complementary list to (a) on SRH specific list of attacks, then it needs to be reconciled for duplication with (a) (e.g., per \u201cbandwidth exhaustion\u201d of (a) and \u201cDOS/DDOS\u201d of (b), are they the same?).\u00a0 I think it is important to make clear what new attacks TTPs are possible with SRH even if the attack type is already possible through another TTPs on a generic IP network.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-12 19:20:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-12 13:13:29-07:00",
    "text": "Thanks for this document; it's clearly going to provide value, and it gives a pretty well-readable description of how things are expected to work.\u00a0 That said, there's a number of details that need to be worked out before publication... This document has six listed authors; per  RFC 7322 , documents listing more than five authors are unusual, and six is greater than five.\u00a0 Let's talk about the author count. \"optional TLV\" seems to be used in MPLS contexts as a technical term for \"comprehension-optional\", not in the \"optional to send\" sense; it's the counterpart of \"mandatory TLV\", and this terminology is even documented in the MPLS TLVs registry.\u00a0 It's my understanding that the LSP Capabilities TLV and the Detailed Interface and Label Stack TLV are intended to be comprehension-required (i.e., \"mandatory TLVs\"), and thus that we must not use the phrase \"optional TLV\" in their description. This would be made clear if we listed which range of values we intended to allocate a TLV type from, in the IANA considerations, but that remains unspecified at this time. In a similar vein (the \"comprehension-required\" behavior), there are a few places (Section 3 (twice), and Section 6; also Section 3 for the LAG Description Indicator flag; see COMMENT) where we state new normative language (\"MUST\") that is unenforceable, since it would need to apply to MPLS implementations that do not implement this specification. Fortunately, the comprehension-required TLV ranges provide this functionality for us without the need to use normative language. Section 4.2 has some conflicting \"MUST\"s about the ordering/presence of sub-TLVs in the DDMAP TLV (see COMMENT, and also the \"MANDATORY\" langauge in Figure 2). If I'm reading Section 5.1.2 correctly, the described procedure is only intended to apply when the \"G\" flag is present (as well as the \"I\" flag, the requirement for which is explicitly stated), but this is not explicitly stated.\u00a0 In particular, the text as written says it applies to all responders that \"understand the LAG Description Indicator flag\" with no mention of runtime check for the presence of that flag. I also worry that Sections 8, 9, and 10 are insufficiently clear about the encoding of the interface index value -- is it an integer in NBO, an opaque bitstring, or something else?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-03 09:16:44-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-12 19:20:49-07:00",
    "text": "Thanks for this document; it's clearly going to provide value, and it gives a pretty well-readable description of how things are expected to work.\u00a0 That said, there's a number of details that need to be worked out before publication... \"optional TLV\" seems to be used in MPLS contexts as a technical term for \"comprehension-optional\", not in the \"optional to send\" sense; it's the counterpart of \"mandatory TLV\", and this terminology is even documented in the MPLS TLVs registry.\u00a0 It's my understanding that the LSP Capabilities TLV and the Detailed Interface and Label Stack TLV are intended to be comprehension-required (i.e., \"mandatory TLVs\"), and thus that we must not use the phrase \"optional TLV\" in their description. This would be made clear if we listed which range of values we intended to allocate a TLV type from, in the IANA considerations, but that remains unspecified at this time. In a similar vein (the \"comprehension-required\" behavior), there are a few places (Section 3 (twice), and Section 6; also Section 3 for the LAG Description Indicator flag; see COMMENT) where we state new normative language (\"MUST\") that is unenforceable, since it would need to apply to MPLS implementations that do not implement this specification. Fortunately, the comprehension-required TLV ranges provide this functionality for us without the need to use normative language. Section 4.2 has some conflicting \"MUST\"s about the ordering/presence of sub-TLVs in the DDMAP TLV (see COMMENT, and also the \"MANDATORY\" langauge in Figure 2). If I'm reading Section 5.1.2 correctly, the described procedure is only intended to apply when the \"G\" flag is present (as well as the \"I\" flag, the requirement for which is explicitly stated), but this is not explicitly stated.\u00a0 In particular, the text as written says it applies to all responders that \"understand the LAG Description Indicator flag\" with no mention of runtime check for the presence of that flag. I also worry that Sections 8, 9, and 10 are insufficiently clear about the encoding of the interface index value -- is it an integer in NBO, an opaque bitstring, or something else?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-04 07:49:48-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-03 09:16:44-07:00",
    "text": "Thanks for the updates in the -07; we seem to be in agreement on the main path forward.\u00a0 That said, in Section 4.2 we still see that: \u00a0  Based on the procedures described above, every LAG member link will \u00a0  have a Local Interface Index Sub-TLV and a Multipath Data Sub-TLV \u00a0  entries in the DDMAP TLV.\u00a0 The order of the Sub-TLVs in the DDMAP TLV \u00a0  for a LAG member link MUST be Local Interface Index Sub-TLV \u00a0  immediately followed by Multipath Data Sub-TLV.\u00a0 A LAG member link \u00a0  MAY also have a corresponding Remote Interface Index Sub-TLV.\u00a0 When a \u00a0  [...] I think we need \"except as follows\" or similar at the end of the second sentence, since otherwise we go on to have a MUST that contradicts the \"MUST be Local Interface Index [...] immediately followed by Multipath Data\". (Also, we missed one instance of \"optional\" in Section 8: \"Local Interface Index Sub-TLV is an optional TLV\")",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-09-26 12:07:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-17 07:54:34-07:00",
    "text": "== Section 3.2 == \"A non-secure transport can be can be used for publishing telemetry \u00a0  data or other operational state that was specifically indicated to \u00a0  non-confidential in the data model in the Yang syntax.\" What kind of telemetry data is it that is of no potential interest to any eavesdropper? This is not my area of expertise so I'm having a hard time conceiving of what that could be. I'm also wondering, since I2RS agents and clients will have to support secure transports anyway (and RESTCONF can only be used over a secure transport), why can't they be used for all transfers, instead of allowing this loophole in the name of telemetry, which undoubtedly will end up being used or exploited for other data transfers? If the argument was that this loophole is needed for backwards compatibility with insecure deployments of NETCONF or something like that I think it would make more sense, but my impression from the text is that those will have to be updated anyway to conform to the requirements in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-09-27 06:37:29-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-26 12:07:25-07:00",
    "text": "Thanks for resolving my previous DISCUSS point. I have just one further point that hopefully will be easy to fix: Section 3.2 trails off in mid-sentence.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-08-17 19:45:00-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-17 14:11:08-07:00",
    "text": "In section 3.4, the text says that the requirements that the integrity protection mechanisms can actually provide integrity protection are SHOULD because some communication may occur over non-secure channels. That does not follow, since the rationale is about use, while the actual requirement is about capability.\u00a0 As currently written, it leaves it possible for people to select a protocol that cannot provide integrity protection at all. I think the SHOULDs in 14 and 15 need to be MUSTS. In the third paragaph of 3.2, Isn't the point to say that ephemeral data MUST be sent over a secure transport unless the data model explicitly labels it as safe for insecure transports? As written, it seems to leave room to send data that is not labeled as safe to also be sent over insecure transports.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-09-16 10:35:42-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-17 14:35:36-07:00",
    "text": "Thanks for your work on this draft.\u00a0 There may be some overlap in points, I tried to minimize them... ---- Section 3.1: I don't see any actual requirements for mutual authentication in this section, just requirements for identifiers.\u00a0 Did I miss something? Are all mutual auth schemes in scope?\u00a0 Are there any considerations for mutual authentication (passwords, keys, etc.)? ---- I share the same concern as others for secure transport, but since there are already discusses on that, I have one comment to add to the existing discusses below.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-29 05:09:00-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-28 14:31:42-07:00",
    "text": "Thanks for the major revision, this is a lot better.\u00a0 I have one discuss point and a bunch of comments. The discuss is: I think it's an error to mix the secure and insecure transports in one set of protocol requirements. And I would definitely put a DISCUSS on any protocol solution that aims to weaken the security of e.g. port 443 or equivalent. In other words, I think you need to rule out any protocol solutions that weaken the secure transports that you are re-using. I therefore suggest adding a new requirement along these lines: \"SEC-REQ-NN: While I2RS might need to make use of both secure and insecure transports, this MUST NOT be done in any way that weakens the secure transport protocol, either as used in I2RS, or especially not as used in other contexts that do not have this requirement for mixing secure and insecure modes of operation and that depend on security being as good as we can provide.\" So I'd like to discuss adding the above or similar.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-10 23:22:38-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-06 13:45:04-08:00",
    "text": "This is very much a \"discuss discuss\", and I am not strongly convinced that there is a problem here, but if there is a problem it is a fairly big one. This document defers creation of a downgrade protection mechanism for version negotiation; after all, if there is only one version in existence, there is nothing to negotiate.\u00a0 However, an effective downgrade protection mechanism requires support from all potentially affected parties in order to be reliable, so some careful thought is in order.\u00a0 If we limit ourselves to a mindset where QUIC versions are infrequent undertakings brought about by standards action (i.e., we don't have to worry until a \"v2\" exists), then deferring seems to be okay (but part of the Discuss is to confirm that my reasoning is valid). The main goal of downgrade protection is to be able to distinguish a node that only supports v1 (or in general, any single version, or set of versions that only has one overlapping version with the peer) from one that supports a different shared version but was tricked by an attacker into using v1 when it otherwise would have used a different version. I'll call that different version v2 for clarity.\u00a0 However, if the peer only supports v1, there's nothing to distinguish and nothing to negotiate; it suffices to ensure that all nodes that are capable of v2 support the downgrade protection scheme.\u00a0 That is, an attacker can only change the negotiated protocol version (as opposed to just causing connection failure, which can be done in many other ways) if there is some shared version other than v1 that would have been negotiated in the absence of the attacker.\u00a0 So, if v2 is definitly going to be defined+implemented before other versions, and all nodes that support v2 support downgrade protection, we are guaranteed that in any case where two peers would negotiate v2 in the absence of an attack, both peers support the downgrade protection mechanism and thus that mechanism will be effective in the face of an attack.\u00a0 Peers that don't support the mechanism only do v1 and so there is no downgrade possible when they are participating in the connection.\u00a0 (We would, of course, still need to be confident that we could define such a downgrade protection scheme in a backwards-compatible manner, though this seems like a fairly low bar given the extensibility provided by transport parameters and frame types.) However, it's not clear to me that this assumption holds that v2 is going to be the next version and that every node that implements v1 and some other version will definitely implement v2.\u00a0 In particular, we currently have a very open registration policy for new versions, and there may be a desire to have some custom version of QUIC, perhaps that only has a small difference from v1, and furthermore a desire to use that custom version when available but be able to use v1 when not available.\u00a0 There might be multiple such new versions in development in parallel, with no clear \"first new version\" tasked with the responsibility to develop a downgrade protection mechanism for global use.\u00a0 The interaction between multiple competing downgrade-protection mechanisms seems likely to become quite messy quite quickly, so I am inclined to see \"make each non-standards-track version specify their own downgrade protection\" as a non-starter. I think that the lack of a secure downgrade protection mechanism is fundamentally incompatible with an open procedure for creating new versions while claiming that the protocol is a secure protocol.\u00a0 While it would not be a pleasant choice, I think we might be forced to require standards action for new QUIC versions until we have a single global downgrade protection mechanism defined.\u00a0 Or perhaps I misunderstand the ecosystem that we are trying to produce, or am making erroneous assumptions.\u00a0 I'd love to hear more about how the WG decided to proceed with the current formulation, especially with regard to what consideration was given to non-standards-track new versions. The above notwithstanding, I support this protocol and I expect to change my position to Yes once this point is resolved in some manner.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-14 01:06:10-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-07 07:06:19-08:00",
    "text": "olding a discuss to verify the IANA question is standards action registries should mandate the experts review prior to the standards action.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-01-08 05:22:04-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-06 09:43:05-08:00",
    "text": "With so many \"Yes\" votes from other ADs, I feel like I'm swimming against the flow by raising a discuss ... Firstly, I would like the thank the authors and WG on such a well written document.\u00a0 I am\u00a0 supportive of this protocol and hope that it will be good for the Internet. However, I do have some discuss questions relating to the Spin Bit and the ability to manage and monitor networks.\u00a0 I appreciate that there has already been a lot of (presumably heated) discussion on the spin bit, which I've not read or participated in, but I am concerned about the operational manageability aspect of QUIC. Firstly, I have two comments on clarifying the spin bit behaviour/specification: 1) It would be helpful to clarify what the expected behaviour is for an implementation that chooses not to support the spin-bit.\u00a0 Does it just leave the bit set as 0, or is it meant to follow the same behaviour as if spin-bit is supported but disabled? 2) This may not be discuss worthy, but some of the spin bit behaviour is inconsistently defined between the quic transport and quic manageability drafts.\u00a0 Specifically: \u00a0 - The transport draft states that at least 1 in 16 connections \"MUST\" disable spinning, whereas the manageability draft states this as \"recommended\". \u00a0 - In the case that the spin bit is disabled, the transport draft uses \"RECOMMENDED\" to use a random value for each packet, or chosen independently for each connection.\u00a0 Whereas the manageability draft uses \"can\" and lists the two options in the opposite order. \u00a0  \u00a0 For this review, since it is in IESG review, I've presumed that the transport draft has the definitive definitions and the manageability draft is lagging. But my two main discuss questions/comments relate to whether the spin-bit, as specified in quic transport, achieves its goal.\u00a0 I appreciate that there are individuals who don't think that it is required at all, conversely some network operators believe that they will lose vital information needed to help manage their networks, and presumably we are trying to find a pragmatic compromise between these two positions. 1) I find it hard to understand why a server is allowed to independently decide whether or not to support the spin bit on a connection?\u00a0 Shouldn't the client (or administrator of the client system) that opened the connection be able to choose whether they want the RTT to be monitorable via the spin bit?\u00a0 What is the reasoning for allowing the server (or server administrator) to be able to independently be able to decide what is best for the client? 2) In the case that the spin-bit is disabled, I don't understand the benefit of injecting a random spin bit value in each packet rather than always setting it to a per connection random value.\u00a0 It seems that whether or not the randomness is injected, it is expected to be feasible to extract the RTT for those connections that are genuinely spinning the bit (or otherwise the spin bit is entirely pointless), but it just seems to make it computationally harder to extract the signal from the noise.\u00a0 Perhaps the goal here is reduce the ability for pervasive monitoring to occur, but that feels a bit like security through obscurity. Some enlightenment for these questions would be appreciated. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-15 16:30:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-11-17 09:22:44-08:00",
    "text": "Section 12 states the situation accurately \u2013 \u201cEach of the potential RAW use-cases will have security considerations from both the use-specific perspective.\u201d\u00a0 Where are these security and privacy considerations for these uses cases discussed?\u00a0 Are these in scope to solve for RAW?\u00a0 A select list to review would be: ** Section 3.*. Per the amusement park use case, what are the physical location tracking and surveillance considerations? ** Section 7.*.\u00a0 Per the vehicle platooning use case, what are the physical location tracking privacy considerations? ** Section 8.*. Per the edge robotics use case, what are the privacy considerations of the video surveillance? ** Section 9.*.\u00a0 Per the ambulance use case, what are the security considerations around exchanging health care information over a wireless WAN? A clearer distinction of what is to be addressed at the protocol level, and what seems like an application consideration is needed.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-01-11 10:09:54-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-09 13:51:25-08:00",
    "text": "Thanks for the work on this. I plan to ballot \"yes\", but have one item I think needs to be discussed first: The security considerations say that this extension adds no new considerations not already present in [ RFC5228 ], [ RFC5230 ], [ RFC5435 ], and [ RFC6131 ]. I'm not sure that that is true.  It seems like the ability to insert a copy of message into a mailbox might have security and/or privacy considerations. This seems analogous to the \"fileinto\" action. I looked for security considerations for that in  RFC 5228 . All I found was a statement that \"fileinfo\" can be dangerous, but no elaboration on the nature of the danger or how it might be mitigated. So while I agree that fcc would have similar considerations as \"fileinfo\", I'm not sure those considerations have been adequately documented.\u00a0 (I expect people will point me to something I missed, or where some other analogous feature is documented, in which case I will clear.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-03 20:35:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-30 18:55:29-07:00",
    "text": "This is an \"early warning\" discuss ballot, entered before I have done a full review of the document. As such, it is possible that the stated concern may in fact be a non-issue after closer examination, but the potential import of the concern seems to make it worth starting the discussion sooner rather than later. This document defines (among other things) a mechanism for carrying subscriber information in an NSH.\u00a0  RFC 8300  (NSH) notes both that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Metadata privacy and \u00a0  security considerations are a matter for the documents that define \u00a0  metadata format. and that: \u00a0 \u00a0 \u00a0 One useful element of providing privacy protection for sensitive \u00a0 \u00a0 \u00a0 metadata is described under the \"SFC Encapsulation\" area of the \u00a0 \u00a0 \u00a0 Security Considerations of [ RFC7665 ].\u00a0 Operators can and should \u00a0 \u00a0 \u00a0 use indirect identification for metadata deemed to be sensitive \u00a0 \u00a0 \u00a0 (such as personally identifying information), significantly \u00a0 \u00a0 \u00a0 mitigating the risk of a privacy violation.\u00a0 In particular, \u00a0 \u00a0 \u00a0 subscriber-identifying information should be handled carefully, \u00a0 \u00a0 \u00a0 and, in general, SHOULD be obfuscated. On the other hand, this document in its security considerations claims that: \u00a0  Data plane SFC-related security considerations, including privacy, \u00a0  are discussed in [ RFC7665 ] and [ RFC8300 ]. and does not seem to incorporate any discussion of the privacy and security considerations of the subscriber information metadata carried by the new format it conveys.\u00a0 Yes, it does note that all nodes with access to the information are part of the same trusted domain, but I do not think that is sufficient, especially given that personally identifiable information is often subject to strict compliance regimes. In short, 8300 and this document are referring to each other for privacy considerations, and the actual privacy considerations do not seem to be documented in either place. Additionally, I did not see any indication of how the subscriber-identifying information ought to be obfuscated (or an explanation of why it is okay to violate the SHOULD from 8300).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-03 20:36:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-11-03 20:35:55-08:00",
    "text": "Retaining my original Discuss position (without the \"early warning\" note), as it is the one that was supported by Martin D and Alvaro: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This document defines (among other things) a mechanism for carrying subscriber information in an NSH.\u00a0  RFC 8300  (NSH) notes both that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Metadata privacy and \u00a0  security considerations are a matter for the documents that define \u00a0  metadata format. and that: \u00a0 \u00a0 \u00a0 One useful element of providing privacy protection for sensitive \u00a0 \u00a0 \u00a0 metadata is described under the \"SFC Encapsulation\" area of the \u00a0 \u00a0 \u00a0 Security Considerations of [ RFC7665 ].\u00a0 Operators can and should \u00a0 \u00a0 \u00a0 use indirect identification for metadata deemed to be sensitive \u00a0 \u00a0 \u00a0 (such as personally identifying information), significantly \u00a0 \u00a0 \u00a0 mitigating the risk of a privacy violation.\u00a0 In particular, \u00a0 \u00a0 \u00a0 subscriber-identifying information should be handled carefully, \u00a0 \u00a0 \u00a0 and, in general, SHOULD be obfuscated. On the other hand, this document in its security considerations claims that: \u00a0  Data plane SFC-related security considerations, including privacy, \u00a0  are discussed in [ RFC7665 ] and [ RFC8300 ]. and does not seem to incorporate any discussion of the privacy and security considerations of the subscriber information metadata carried by the new format it conveys.\u00a0 Yes, it does note that all nodes with access to the information are part of the same trusted domain, but I do not think that is sufficient, especially given that personally identifiable information is often subject to strict compliance regimes. In short, 8300 and this document are referring to each other for privacy considerations, and the actual privacy considerations do not seem to be documented in either place. Additionally, I did not see any indication of how the subscriber-identifying information ought to be obfuscated (or an explanation of why it is okay to violate the SHOULD from 8300). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% To record some additional synthesis of the above (original) remark with my more thorough reading of the document: we are defining containers specifically to contain subscriber and performance policy identifiers/information.\u00a0 While the specific contents are out of scope for this document, we still are obligated to describe the general classes of issues that can arise due to conveying those types of information within a SFC domain.\u00a0 We should also give guidance on how to populate the contents of these context headers in a secure and privacy-supporting manner, including the use of indirect identification and obfuscation/encryption. Futhermore (and this part is not a discuss point but may lead to me switching my position to Abstain once the discusses are resolved), I have some misgivings about including subscriber identification information at all, and would prefer if it could instead be translated into the relevant policy information element(s) needed by the SFP in question before being applied to the NSH.\u00a0 For example, rather than saying \"this packet is from user X\" we could say \"this packet is part of quota bucket ABC (with bucket size Z) for time period Y\" to enforce per-user quota.\u00a0 While in this case the identifier would still ultimately lead back to an individual, the identifier would be rotated periodically, and it is possible to achieve some level of de-linkability as records age out (depending on how the \"ABC\" is generated, of course). I do recognize that even for non-quota use cases where a user is part of multiple distinct policy groups, the combination of those groups might still identify only a small anonymity set, but the overall privacy properties of such a design seem superior than consistent use of a persistent identifier or identifiers, in aggregate. I have an additional Discuss point after doing a more thorough review of the document -- I think there's a (minor) internal inconsistency within Section 3: \u00a0  Intermediary NSH-aware nodes have to preserve Subscriber Identifier \u00a0  Context Headers (i.e., the information can be passed to next hop NSH- \u00a0  aware nodes), but local policy may require an intermediary NSH-aware \u00a0  node to strip a Subscriber Identifier Context Header after processing \u00a0  it. since it seems to say that NSH-aware intermediary nodes both \"have to preserve\" and \"may strip\" a Service Identifier Context Header. Similar language is used to describe the Performance Policy Identifier Context Header, in Section 4, which would presumably receive a similar modification to the Subscriber Identifier case.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-10 06:41:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 20:36:05-08:00",
    "text": "Retaining my original Discuss position (without the \"early warning\" note), as it is the one that was supported by Martin D and Alvaro: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This document defines (among other things) a mechanism for carrying subscriber information in an NSH.\u00a0  RFC 8300  (NSH) notes both that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Metadata privacy and \u00a0  security considerations are a matter for the documents that define \u00a0  metadata format. and that: \u00a0 \u00a0 \u00a0 One useful element of providing privacy protection for sensitive \u00a0 \u00a0 \u00a0 metadata is described under the \"SFC Encapsulation\" area of the \u00a0 \u00a0 \u00a0 Security Considerations of [ RFC7665 ].\u00a0 Operators can and should \u00a0 \u00a0 \u00a0 use indirect identification for metadata deemed to be sensitive \u00a0 \u00a0 \u00a0 (such as personally identifying information), significantly \u00a0 \u00a0 \u00a0 mitigating the risk of a privacy violation.\u00a0 In particular, \u00a0 \u00a0 \u00a0 subscriber-identifying information should be handled carefully, \u00a0 \u00a0 \u00a0 and, in general, SHOULD be obfuscated. On the other hand, this document in its security considerations claims that: \u00a0  Data plane SFC-related security considerations, including privacy, \u00a0  are discussed in [ RFC7665 ] and [ RFC8300 ]. and does not seem to incorporate any discussion of the privacy and security considerations of the subscriber information metadata carried by the new format it conveys.\u00a0 Yes, it does note that all nodes with access to the information are part of the same trusted domain, but I do not think that is sufficient, especially given that personally identifiable information is often subject to strict compliance regimes. In short, 8300 and this document are referring to each other for privacy considerations, and the actual privacy considerations do not seem to be documented in either place. Additionally, I did not see any indication of how the subscriber-identifying information ought to be obfuscated (or an explanation of why it is okay to violate the SHOULD from 8300). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% To record some additional synthesis of the above (original) remark with my more thorough reading of the document: we are defining containers specifically to contain subscriber and performance policy identifiers/information.\u00a0 While the specific contents are out of scope for this document, we still are obligated to describe the general classes of issues that can arise due to conveying those types of information within a SFC domain.\u00a0 We should also give guidance on how to populate the contents of these context headers in a secure and privacy-supporting manner, including the use of indirect identification and obfuscation/encryption. Futhermore (and this part is not a discuss point but may lead to me switching my position to Abstain once the discusses are resolved), I have some misgivings about including subscriber identification information at all, and would prefer if it could instead be translated into the relevant policy information element(s) needed by the SFP in question before being applied to the NSH.\u00a0 For example, rather than saying \"this packet is from user X\" we could say \"this packet is part of quota bucket ABC (with bucket size Z) for time period Y\" to enforce per-user quota.\u00a0 While in this case the identifier would still ultimately lead back to an individual, the identifier would be rotated periodically, and it is possible to achieve some level of de-linkability as records age out (depending on how the \"ABC\" is generated, of course). I do recognize that even for non-quota use cases where a user is part of multiple distinct policy groups, the combination of those groups might still identify only a small anonymity set, but the overall privacy properties of such a design seem superior than consistent use of a persistent identifier or identifiers, in aggregate. I have an additional Discuss point after doing a more thorough review of the document -- I think there's a (minor) internal inconsistency within Section 3: \u00a0  Intermediary NSH-aware nodes have to preserve Subscriber Identifier \u00a0  Context Headers (i.e., the information can be passed to next hop NSH- \u00a0  aware nodes), but local policy may require an intermediary NSH-aware \u00a0  node to strip a Subscriber Identifier Context Header after processing \u00a0  it. since it seems to say that NSH-aware intermediary nodes both \"have to preserve\" and \"may strip\" a Service Identifier Context Header. Similar language is used to describe the Performance Policy Identifier Context Header, in Section 4, which would presumably receive a similar modification to the Subscriber Identifier case.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-11-15 22:28:18-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 07:45:02-08:00",
    "text": "This looks like a significant problem. If I have missed anything in any reference this might be very simple to resolve. However, based on this document and looking at  RFC 8300  I think this document is lacking in discussion of the packet size impact of using both dynamic size headers, as well as there are no limits to how many are added. Thus, there are significant risk for this header to increase the packet size so much that it doesn't fit the underlying layer. And as Section 5 in  RFC8300  identifies there are no general solution provided in NSH. Thus, I really think this issues needs some discussion. Even if the actual result of this is a requirement on the control plane, the issue exists in the data plane and thus warrants discussion in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-12-10 13:18:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 05:54:40-08:00",
    "text": "There is no framework or guidance to reason about or mitigate the security and privacy risks of embedding sensitive, user identifying information into the network.\u00a0 The document does fairly note that the other SFC headers also don\u2019t have protection mechanisms either, but they do not enable use identification or tracking. During response to IESG ballots prior to mine, two related points were made: ** Using  draft-ietf-sfc-nsh-integrity-00  to mitigate risks \u2013 this might help, but the maturity of this document would suggest that additional discussion is required before it could be evaluated as a solution. ** surveillance as a use case (lawful intercept as an SFC [2]) \u2013 reinforces why a privacy framework is needed ( RFC6973  and 8165 are helpful references here) [1]  https://mailarchive.ietf.org/arch/msg/sfc/24Q52inJTpacY1HOlCHU8VTUkIw/ [2]  https://mailarchive.ietf.org/arch/msg/sfc/Knc9goUyEjiMLWHmf0K-NbHTpC8/",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-12-21 03:06:07-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 02:08:59-07:00",
    "text": "# GEN AD review of  draft-ietf-lpwan-schc-over-nbiot-12 CC @larseggert ## Discuss ### Intended status SCHC is an IETF standard. The IETF should not standardize how another SDO should use SCHC in their architecture, unless that other SDO has specifically asked the IETF to do so. Has 3GPP done so? ### \"Abstract\", paragraph 1 ``` \u00a0 \u00a0  The 3rd Generation Partnership Project (3GPP) \u00a0 \u00a0  and the Narrowband Internet of Things (NB-IoT) architectures may \u00a0 \u00a0  adopt SCHC to improve their capacities. ``` Would 3GPP be surprised to see this recommendation by the IETF? Has this work item been liaised to and coordinated with 3GPP? Do they expect us to deliver it and do they agree on the content? ### Section 5.1, paragraph 1 ``` \u00a0 \u00a0  This section consists of IETF suggestions to the 3GPP. ``` The IETF isn't typically giving suggestions to other SDOs by publishing documents. We do that through liaison activities. Has this work item be liaised to 3GPP? Do they expect us to complete and publish the work so they can normatively refer to it?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-01-24 06:18:25-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-23 11:03:57-08:00",
    "text": "This is more for the shepherding AD than the authors/WG: in the discussion resulting from the Gen-ART review the author indicated that there would be another pass through the document to capitalize uses of normative must/should and add a reference to  RFC 8174 . That seems like the kind of thing where the WG should get another look at the changes to make sure everyone agrees on what the normative requirements were/are. Is that the plan?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-09-16 20:10:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-20 21:05:14-07:00",
    "text": "* Section 3.1. I might be missing something here but I think that the \"MUST be used\" in this session is wrong and must be relaxed by qualifying it. Here is why. In case the router does not advertise support by including the value 'Link Identifiers' in the Extension Data Item inside the Session Initialization Message, I feel that the modem MUST NOT send the Link Identifier Length Data Item as this will result in a Session Termination message from the router based on the rules specified in Section 12.1 of  RFC8175  due to the unknown data item.  If you agree with my assessment, I would suggest a change like this. If not, can you please clarify. OLD: \u00a0  It MUST be used during Session Initialization, contained in a Session \u00a0  Initialization Response Message, if the specified length is not the \u00a0  default value of 4 octets. NEW: \u00a0  If the router advertised support by including the value 'Link Identifiers' in the  \u00a0  Extension Data Item inside the Session Initialization Message, this data item  \u00a0  MUST be used during Session Initialization, contained in a Session \u00a0  Initialization Response Message, if the specified length is not the \u00a0  default value of 4 octets. If not, this Data Item MUST NOT be sent.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-25 19:41:57-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-16 18:32:50-07:00",
    "text": "Let's discuss whether the currently specified procedures for reconstructing the target URI from a request-target in absolute-form provide adequate security properties, at the origin server.\u00a0 I'm specifically concerned about taking the scheme directly from the request target, i.e., making the distinction between the \"http\" and \"https\" schemes.\u00a0 The simple procedure of \"take the scheme from the request-target\" would seem to allow for the client to cause the server to engage processing for the \"https\" origin without receiving the protection that https is supposed to provide.\u00a0 (The converse case does not immediately seem to present much risk but is probably worth preventing as well on general principles of retaining consistency.)\u00a0 I don't remember seeing any text that would require the server to validate the scheme from the request-target against the actual properties of the transport (or the configured fixed URI scheme as might be provisioned with a trusted outbound gateway, etc.)\u00a0 While we do reference \u00a77.4 of [Semantics] with a note that reconstructing the target URI is only part of the process of identifying a target resource, that part of [Semantics] does not mention scheme validation as part of rejecting misdirected requests. Does the origin server need to validate the scheme from an absolute-form request-target?\u00a0 What is the scope of consequences if it fails to do so?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-06-10 13:04:24-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-10 04:41:09-07:00",
    "text": "his document seems to have unresolved IANA issues, so I am holding a DISCUSSfor IANA until the issues are resolved.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-06-13 13:49:11-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-02 14:22:10-07:00",
    "text": "Many thanks for this work. I expect to ballot YES once we discuss and resolve the issue below. In Section 4.5, I understand the need to base the re-start of the media flow on a human user intervention, but I find it puzzling that this is framed in terms of \"restarting the call\" rather than \"restarting the flow.\" The recommendation in Section 8 is that senders MUST treat each session independently, but ending/restarting \"the call\" seems to assume that multiple flows will be treated together. One situation I'm thinking of is one where my audio and video traffic are in separate RTP flows and are routed along different paths for whatever reason. Some network problem is encountered in the video path, triggering a circuit breaker. The \"call\" doesn't necessarily need to be terminated and re-started, because my audio can continue just fine. This is another case where the application may not want to rely on a human user re-start (if you leave it up to me whether to re-start my video, I'll certainly try to re-start it right away). I think the text in this section needs to be re-phrased to separate the case where a circuit breaker triggering on a single 3-tuple causes a whole call to end (either because the call consisted of a single flow or because all of the flows were encountering congestion and it takes just one circuit breaker to trigger the end of it) from cases where it causes only that flow to be suspended, and reference Section 8 to make it clear that the unit of operation for \"ceasing\" and \"re-starting\" is a single flow unless the sender chooses to group flows. Furthermore (and this is not a DISCUSS point but I leave it here since it follows from the points above), the normative recommendation in the first paragraph here doesn't really follow from the discussion of restarting the call. The recommendation is not to automatically re-start until indications are received that congestion has improved, which is different from waiting until a human user re-starts. I think this would be clearer if the normative recommendation came first and the human user case was discussed afterward.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-06-13 15:10:41-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 05:03:13-07:00",
    "text": "This is about one point in section 7 (ECN) that I think is wrong but I would like to get some feedback from the authors: \"then ECN-CE marked packets SHOULD \u00a0  be treated as if they were lost when calculating if the congestion- \u00a0  based RTP circuit breaker\" (also section 5: \"The count of ECN-CE marked packets \u00a0  contained in those ECN feedback reports is counted towards the number \u00a0  of lost packets reported\") We are currently discussion mechanisms where the AQM in the congested network node sends\u00a0 much more CE markings than one would see loss (when using TCP) for the same level of congestion. When treating ECN-CE similar to loss, such a different behavior could trigger the circuit breaker unnecessarily. Potentially ECN-CE might not need to be considered here at all, because as long as there are (only) ECN-CE marks (and no loss) all data is transmitted correctly to the receiver and therefore there is no need to trigger a circuit breaker. Further also in section 7: \"ECN-CE marked packets SHOULD be treated as if they were lost for the \u00a0  purposes of congestion control\" This document should not impose any SHOULDs for congestion control as this doc is only about circuit breaker sand therefore the sentence above should be removed.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2016-04-26 15:09:09-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-19 18:19:50-07:00",
    "text": "I really like this specification, and have two questions I'd like to understand before balloting YES ... I'm looking at this text: 4.5.\u00a0 Ceasing Transmission \u00a0  What it means to cease transmission depends on the application.\u00a0 The \u00a0  intention is that the application will stop sending RTP data packets \u00a0  to a particular destination 3-tuple (transport protocol, destination \u00a0  port, IP address), until the user makes an explicit attempt to \u00a0  restart the call.\u00a0 It is important that a human user is involved in \u00a0  the decision to try to restart the call, since that user will \u00a0  eventually give up if the calls repeatedly trigger the circuit \u00a0  breaker.\u00a0 This will help avoid problems with automatic redial systems \u00a0  from congesting the network.\u00a0 Accordingly, RTP flows halted by the \u00a0  circuit breaker SHOULD NOT be restarted automatically unless the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^^^^^^^^^^ \u00a0  sender has received information that the congestion has dissipated, \u00a0  or can reasonably be expected to have dissipated.  \u00a0   and trying to understand why this is not MUST NOT. I'm trying to reconcile this with the  RFC 2119  definition of SHOULD NOT, which is 4. SHOULD NOT\u00a0  This phrase, or the phrase \"NOT RECOMMENDED\" mean that \u00a0  there may exist valid reasons in particular circumstances when the \u00a0  particular behavior is acceptable or even useful, but the full \u00a0  implications should be understood and the case carefully weighed \u00a0  before implementing any behavior described with this label. \u00a0   Could you help me understand when automatic restarts might be \"acceptable or even useful\"? Reading on, I'm wondering if this text is anticipating  \u00a0  It is recognised that the RTP implementation in some systems might \u00a0  not be able to determine if a call set-up request was initiated by a \u00a0  human user, or automatically by some scripted higher-level component \u00a0  of the system. \u00a0   but definitely want to understand what you're thinking here. I have a similar question about this text  \u00a0  ECN-CE marked packets SHOULD be treated as if it were lost for the \u00a0  purposes of congestion control, when determining the optimal media \u00a0  sending rate for an RTP flow.\u00a0 If an RTP sender has negotiated ECN \u00a0  support for an RTP session, and has successfully initiated ECN use on \u00a0  the path to the receiver [ RFC6679 ], then ECN-CE marked packets SHOULD \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^^^ \u00a0  be treated as if they were lost when calculating if the congestion- \u00a0  based RTP circuit breaker (Section 4.3) has been met.\u00a0  Could you help me understand why an implementation wouldn't do this?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-24 01:09:41-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 19:12:53-07:00",
    "text": "Thanks for this clear and concise document!\u00a0 I just have one concern, which will hopefully be easy to resolve (since there is a good chance that all the text necessary to do so is already written). As far as I can tell, the comment made by the secdir reviewer of draft-ietf-mpls-sfc-04  about circular references between that document and RFCs 7665 and 8300 regarding security properties, is also somewhat applicable to this document.\u00a0 I do recognize the validity of first paragraph of the security considerations here (the NSH is an opaque payload for MPLS), but that in and of itself does not present a security analysis of the NSH in the MPLS environment.\u00a0 The last paragraph of the security considerations of this document attempts to provide some analysis, but it seems to be incomplete and perhaps overly optimistic, particularly with respect to the use of MPLS with Inter-Carrier Interconnect and the processing of MPLS traffic from external interfaces.\u00a0 Is there any reason not to fully harmonize (i.e., synchronize) the security considerations of  draft-ietf-mpls-sfc  and draft-ietf-mpls-sfc-encapsulation ?\u00a0 (I guess the first paragraph of this document's security considerations doesn't apply to the other document, that allocates extended-special-purpose label values, but that's the only thing I saw.)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-05-19 02:39:04-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 03:16:11-07:00",
    "text": "Hi, Thanks for this short doc, and sorry for the discuss, but hopefully it is fairly easy to resolve ... I think that it would be helpful for this document to explicitly state how this attribute behaves in conjunction with the existing Administrative Group (color) TLV (1088).\u00a0 E.g., is the expectation that if this attribute is published then the 1088 attribute would also always be published (with the same first 32 bits)?\u00a0 Or is the expectation that this attribute can be published without the 1088 attribute being published at all? Similarly, if a client receives both attributes there are there any expectations to how it handles those, i.e., should it always use the new attribute in preference?\u00a0 Or otherwise, what should it do if the values were inconsistent between the two attributes? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-09-11 03:40:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-24 14:10:55-08:00",
    "text": "To make sure both  draft-ietf-i2rs-yang-network-topo  and  draft-ietf-i2rs-yang-l3-topology  are treated the same way, here is my DISCUSS. As background, email sent to I2RS/IESG on Jan 24th 2017 Let me repeat what I mentioned already on the I2RS mailing list: \u00a0 \u00a0 This document contains a YANG model, a generic YANG model that could be accessed by NETCONF, RESTCONF, or the future I2RS protocol. \u00a0 \u00a0 This document doesn't say (and that would be a mistake IMO if it would) that this YANG model can only be accessed by the I2RS protocol. \u00a0 \u00a0 Hence I'm advocating that the security considerations diligently follow  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines , and that they don't go in the I2RS protocol specific details. This comment was made for  draft-ietf-i2rs-yang-network-topo , but is equally applicable to this  draft-ietf-i2rs-yang-l3-topology  draft. I still maintain this point of view: it would be a mistake to limit a data model usage to a particular protocol. These topology documents are not I2RS YANG models, these are YANG models, which can be used in different contexts. I'm very concerned if we start having per-WG or per context data models in the IETF. Btw, I haven't seen a RFC specifying what the I2RS protocol is, only the requirements. We can't modify the current generic YANG security considerations for an I2RS control plane and a new datastore that are not yet specified. If you want to describe how I2RS will be using those topology YANG models (and any YANG models btw), then it's suitable to include this part of the I2RS protocol spec or part of an I2RS applicability statement. This is typically where you would describe some protocol specific information such as \"write contention for two clients writing a node using I2RS priority (linked to I2RS User-ID)\". Let me make my point differently. Let's assume for a moment that I2RS needs to use the IETF interface YANG model, does it mean that you will require RFC 7223bis with an updated security considerations? This can't be. I still think the generic YANG security guidelines is suitable, as it relates to IETF specified protocols NETCONF and RESTCONF. Addition of some generic information about the data model (not I2RS protocol) might be useful though. For example, text around \"there is a risk that a write to a topology may create a looping topology or overload a particular node\". Note that I don't think the the security considerations is the best section for this though. Regards, Benoit",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-09-27 02:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-11 03:40:07-07:00",
    "text": "Preliminary note: I hope I'm doing the right thing by updating this DISCUSS point as\u00a0 I understand that the document is back to the WG. However, since I reviewed the version 15, since some of my ballot points have been addressed (thank you), and since I wanted to share my feedback publicly, here is my feedback. Please follow the YANG security guidelines template at  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines \u00a0 \u00a0 \u00a0 \u00a0 There are a number of data nodes defined in this YANG module that are writable/creatable/deletable (i.e., config true, which is the default). These data nodes may be considered sensitive or vulnerable in some network environments. Write operations (e.g., edit-config) to these data nodes without proper protection can have a negative effect on network operations. These are the subtrees and data nodes and their sensitivity/vulnerability: \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 -- for all YANG modules you must evaluate whether any readable data -- nodes (those are all the \"config false\" nodes, but also all other -- nodes, because they can also be read via operations like get or -- get-config) are sensitive or vulnerable (for instance, if they -- might reveal customer information or violate personal privacy -- laws such as those of the European Union if exposed to -- unauthorized parties) \u00a0 \u00a0 \u00a0 \u00a0 Some of the readable data nodes in this YANG module may be considered sensitive or vulnerable in some network environments. It is thus important to control read access (e.g., via get, get-config, or notification) to these data nodes. These are the subtrees and data nodes and their sensitivity/vulnerability: \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 -- if your YANG module has defined any rpc operations -- describe their specific sensitivity or vulnerability. \u00a0 \u00a0 \u00a0 \u00a0 Some of the RPC operations in this YANG module may be considered sensitive or vulnerable in some network environments. It is thus important to control access to these operations. These are the operations and their sensitivity/vulnerability: \u00a0 \u00a0 \u00a0 \u00a0  I don't understand why the security considerations section of a YANG module document speaks about this: \u00a0 \u00a0 Rules expressed in NACM can be applied analogously also to other \u00a0 \u00a0 \u00a0  protocols that attempt access to YANG-defined data.\u00a0 In fact, it \u00a0 \u00a0 \u00a0  needs to be applied in the same way and should, like YANG, thus be \u00a0 \u00a0 \u00a0  considered independent of any particular protocol that is used to \u00a0 \u00a0 \u00a0  access YANG-defined data.\u00a0 Otherwise, access control rules defined by \u00a0 \u00a0 \u00a0  NACM could be very easily circumvented simply by using another access \u00a0 \u00a0 \u00a0  mechanism which does not enforce NACM.\u00a0 The alternative of mandating \u00a0 \u00a0 \u00a0  the introduction of mechanisms parallel to NACM that specify the same \u00a0 \u00a0 \u00a0  access control rules for other transports is clearly undesirable, as \u00a0 \u00a0 \u00a0  this would not only inhibit ease-of-use of systems that implement \u00a0 \u00a0 \u00a0  multiple protocols to access YANG data, but also open the specter of \u00a0 \u00a0 \u00a0  security holes due to inconsistencies in articulation and enforcement \u00a0 \u00a0 \u00a0  of rules across mechanisms that are essentially redundant. This is even confusing to speak about other protocols before/without specifying those protocols. You should remove this. OLD DISCUSS, FOR INFORMATION ONLY: To make sure both  draft-ietf-i2rs-yang-network-topo  and  draft-ietf-i2rs-yang-l3-topology  are treated the same way, here is my DISCUSS. As background, email sent to I2RS/IESG on Jan 24th 2017 Let me repeat what I mentioned already on the I2RS mailing list: \u00a0 \u00a0 This document contains a YANG model, a generic YANG model that could be accessed by NETCONF, RESTCONF, or the future I2RS protocol. \u00a0 \u00a0 This document doesn't say (and that would be a mistake IMO if it would) that this YANG model can only be accessed by the I2RS protocol. \u00a0 \u00a0 Hence I'm advocating that the security considerations diligently follow  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines , and that they don't go in the I2RS protocol specific details. This comment was made for  draft-ietf-i2rs-yang-network-topo , but is equally applicable to this  draft-ietf-i2rs-yang-l3-topology  draft. I still maintain this point of view: it would be a mistake to limit a data model usage to a particular protocol. These topology documents are not I2RS YANG models, these are YANG models, which can be used in different contexts. I'm very concerned if we start having per-WG or per context data models in the IETF. Btw, I haven't seen a RFC specifying what the I2RS protocol is, only the requirements. We can't modify the current generic YANG security considerations for an I2RS control plane and a new datastore that are not yet specified. If you want to describe how I2RS will be using those topology YANG models (and any YANG models btw), then it's suitable to include this part of the I2RS protocol spec or part of an I2RS applicability statement. This is typically where you would describe some protocol specific information such as \"write contention for two clients writing a node using I2RS priority (linked to I2RS User-ID)\". Let me make my point differently. Let's assume for a moment that I2RS needs to use the IETF interface YANG model, does it mean that you will require RFC 7223bis with an updated security considerations? This can't be. I still think the generic YANG security guidelines is suitable, as it relates to IETF specified protocols NETCONF and RESTCONF. Addition of some generic information about the data model (not I2RS protocol) might be useful though. For example, text around \"there is a risk that a write to a topology may create a looping topology or overload a particular node\". Note that I don't think the the security considerations is the best section for this though. Regards, Benoit",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-12-20 06:27:16-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-04 13:33:41-08:00",
    "text": "Thanks for your work on this draft. I have a couple of things I'd like to discuss that may require some additional text, but should be easy to resolve. 1. Privacy considerations - I don't see any listed and the YANG module include a few identifiers as well as ways to group devices.\u00a0 I think privacy considerations need to be added for use of this module. 2. Security - the network topology and inventory created by this module reveals information about systems and services.\u00a0 This could be very helpful information to an attacker and should also be called out as a security consideration. The access and transport of this information is covered though in the considerations, just listing this threat would be helpful. Thank you.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-07-26 11:26:59-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 00:18:42-07:00",
    "text": "Thanks for all the work that the authors and other contributors have put into this document. I have two comments that need to be addressed before publication, but they should both be very easy to fix. --------------------------------------------------------------------------- \u00a73.3: >\u00a0 If a publisher fails to serve the RPC request for one of the reasons >\u00a0 indicated in [I-D.draft-ietf-netconf-subscribed-notifications] >\u00a0 Section 2.4.6 or [ I-D.ietf-netconf-yang-push ] Appendix A, this will >\u00a0 be indicated by \"406\" status code transported in the HTTP response. This really isn't what 406 means. 406 means \"you sent one or more of the 'Accept', 'Accept-Charset', 'Accept-Encoding', or 'Accept-Language' header fields, and I can't generate a response that satisfies what you've asked for.\" For some of the errors listed in the two cited sections, there is a reasonable semantic mapping onto existing HTTP response codes; e.g. the \"no-such-subscription\" errors could all reasonably map on to HTTP 404.\u00a0 I'll note that  RFC 8040  section 7 performs exactly this kind of mapping, so the approach seems to be consistent with the way that RESTCONF has elected to use HTTP response codes. In fact, this document already maps from the cited errors to error tags already, and that table maps from error-tag to HTTP response codes, so fixing this should be the relatively straightforward exercise of updaing the tables in this section to also include the HTTP response code that  RFC 8040  maps to the indicated error-tag. For example: \u00a0 \u00a0  error identity\u00a0 \u00a0 \u00a0 \u00a0  uses error-tag\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  HTTP Response \u00a0 \u00a0  ---------------------- --------------\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ------------- \u00a0 \u00a0  dscp-unavailable\u00a0 \u00a0 \u00a0  invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 400 \u00a0 \u00a0  encoding-unsupported\u00a0  invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 400 \u00a0 \u00a0  filter-unsupported\u00a0 \u00a0  invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 400 \u00a0 \u00a0  insufficient-resources resource-denied\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 409 \u00a0 \u00a0  no-such-subscription\u00a0  invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 404 \u00a0 \u00a0  replay-unsupported\u00a0 \u00a0  operation-not-supported\u00a0 \u00a0 501 \u00a0 \u00a0  error identity\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 uses error-tag\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HTTP Response \u00a0 \u00a0  ----------------------\u00a0 \u00a0 \u00a0 --------------\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ------------- \u00a0 \u00a0  cant-exclude\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operation-not-supported 501 \u00a0 \u00a0  datastore-not-subscribable\u00a0 invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  400 \u00a0 \u00a0  no-such-subscription-resync invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  404 \u00a0 \u00a0  on-change-unsupported\u00a0 \u00a0 \u00a0  operation-not-supported 501 \u00a0 \u00a0  on-change-sync-unsupported\u00a0 operation-not-supported 501 \u00a0 \u00a0  period-unsupported\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 invalid-value\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  400 \u00a0 \u00a0  update-too-big\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 too-big\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  400 \u00a0 \u00a0  sync-too-big\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 too-big\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  400 \u00a0 \u00a0  unchanging-selection\u00a0 \u00a0 \u00a0 \u00a0 operation-failed\u00a0 \u00a0 \u00a0 \u00a0 500 However you choose to address this, if the error isn't related to any of the four header fields I mention above, then you can't specify the use of a 406. --------------------------------------------------------------------------- \u00a73.4: This section is unclear about how Server-Sent Events are to be used (in particular, they don't say anything about event type to be used). Based on the one example in Appendix A that shows SSE syntax, I'm assuming you probably do not intend to use SSE \"event type\" fields to distinguish between events in any way.\u00a0 This would mean that you need to specify that all SSE messages are sent with an event type of \"message,\" which the server may omit (as it is the default specified in the Server-Side Events specification).\u00a0 This means that clients will need to accept both: data: { data:\u00a0  \"ietf-restconf:notification\" : { data:\u00a0 \u00a0  \"eventTime\": \"2007-09-01T10:00:00Z\", data:\u00a0 \u00a0  \"ietf-subscribed-notifications:subscription-modified\": { data:\u00a0 \u00a0 \u00a0  \"id\": \"39\", data:\u00a0 \u00a0 \u00a0  \"uri\": \" https://example.com/restconf/subscriptions/22 \" data:\u00a0 \u00a0 \u00a0  \"stream-xpath-filter\": \"/example-module:foo\", data:\u00a0 \u00a0 \u00a0  \"stream\": { data:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ietf-netconf-subscribed-notifications\" : \"NETCONF\" data:\u00a0 \u00a0 \u00a0  } data:\u00a0 \u00a0  } data:\u00a0  } data: } ...and... event: message data: { data:\u00a0  \"ietf-restconf:notification\" : { data:\u00a0 \u00a0  \"eventTime\": \"2007-09-01T10:00:00Z\", data:\u00a0 \u00a0  \"ietf-subscribed-notifications:subscription-modified\": { data:\u00a0 \u00a0 \u00a0  \"id\": \"39\", data:\u00a0 \u00a0 \u00a0  \"uri\": \" https://example.com/restconf/subscriptions/22 \" data:\u00a0 \u00a0 \u00a0  \"stream-xpath-filter\": \"/example-module:foo\", data:\u00a0 \u00a0 \u00a0  \"stream\": { data:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ietf-netconf-subscribed-notifications\" : \"NETCONF\" data:\u00a0 \u00a0 \u00a0  } data:\u00a0 \u00a0  } data:\u00a0  } data: } It may be helpful to incorporate the SSE syntax into all of the notification examples in Appendix A (that is, all of the examples in A.2 and A.3). I would recommend a mix of examples with and without \"event: message\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-13 16:18:59-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-07 13:58:42-07:00",
    "text": "Thanks for the well-written document!\u00a0 I\u00a0 just have some boring housecleaning points that should be easy to resolve. Section 3.2 states: \u00a0  Subscribers can learn what event streams a RESTCONF server supports \u00a0  by querying the \"streams\" container of ietf-subscribed- \u00a0  notification.yang in \u00a0  [I-D.draft-ietf-netconf-subscribed-notifications].\u00a0 Support for the \u00a0  \"streams\" container of ietf-restconf-monitoring.yang in [ RFC8040 ] is \u00a0  not required.\u00a0 If it is supported, the event streams which are in the \u00a0  \"streams\" container of ietf-subscribed-notifications.yang SHOULD also \u00a0  be in the \"streams\" container of ietf-restconf-monitoring.yang. This \"SHOULD\" seems to be attempting to impose a normative requirement on specifications that implement draft-ietf-netconf-subscribed-notifications  and  RFC 8040  streams, without regard to whether they implement this specification.\u00a0 It seems better-placed in draft-ietf-netconf-subscribed-notifications. Similarly, when Section 4 writes: \u00a0  To meet subscription quality of service promises, the publisher MUST \u00a0  take any existing subscription \"dscp\" and apply it to the DSCP \u00a0  marking in the IP header. that seems to be duplicating a normative requirement from the core subscribed-notifications document.\u00a0 (And I'm sure Magnus will have further follow-up about how DSCP markings are per-connection for the stream transports we have available, as well.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-10 16:30:44-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:38:30-07:00",
    "text": "Per Section 9, [ draft-ietf-netconf-netconf-event-notifications ] and [ draft-ietf-netconf-subscribed-notifications ] mention concerns about a \u201cmalicious or buggy subscriber sends a number of establish-subscription requests\u201d in their Security Considerations.\u00a0 Is that not a concern here too?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-04-07 11:38:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-07 11:37:41-07:00",
    "text": "First off, this DISCUSS is NOT about questioning the rough consensus calls that the responsible Chair and AD have made, or wanting to change them, but about clarifying to avoid misinterpretations. Given the ongoing discussion about Extension Headers and controlled domains (for example [1] and [2]), the text should be very specific on what is expected and where.\u00a0 Because it is not, I think that this document is teetering along the line of having a \"high degree of technical maturity\", and not being ready for Internet Standard [ rfc6410 ]. Without further clarifications and guidance, this document also brings on unanticipated second order effects [ rfc3439 ] that can impact the direction, or even the viability, of future work in the IETF.\u00a0 Specifically, a straight forward interpretation of the text in Section 4 is the absolute prohibition to process, insert or delete EHs -- but discussion on the 6man mailing list seems to point at an understanding that the conditions inside a controlled domain may be different, for example (from Brian Carpenter [3]): ===== I've tried to say this before but I'm not sure people are getting it:  RFC2460bis, if approved as is, draws a line in the sand *for interoperability across the whole Internet*. There are reasons for this - PMTUD in any form, any future replacement for the unsuccessful IPsec/AH, and all the problems of deploying extension headers that are understood by some nodes and not by others.  There is no reason why a subsequent standards-track document cannot allow header insertion (and removal) within finite domains where the above issues do not apply. In fact, an improved version of  draft-voyer-6man-extension-header-insertion-00  could become exactly that. ===== [N.B.: I'm not implying that Brian's opinion represents consensus, that is not my call to make.] I'm pointing at an opinion (which I agree with) that recognizes the need to differentiate between contexts -- but the current text in rfc2460bis doesn't do that.\u00a0 I believe that this issue is significant (as reflected by the ongoing discussions) that that it should be resolved (by clarifying the text) before proceeding with the publication of this document as an Internet Standard.  To summarize, the text in this document has the second order effect of not leaving a clear path forward for extensions to IPv6 so that they adhere to the protocol's architecture, specially when applied to a controlled domain.\u00a0 At a minimum, I would like to see a clear path forward, whether that is in the form of an update for use of extensions in controlled domains, or a statement that this document just applies to IPv6 traffic intended to cross the Internet (as suggested at the 6man meeting in Chicago [4])...\u00a0 My opinion is that this document should not be published as an Internet Standard until the remaining open discussions are explicitly resolved and this document reflects that resolution. [1]  https://mailarchive.ietf.org/arch/msg/ipv6/UI0PfqrWco4Hpbvm8keGR8FabRg/?qid=9a6ba8e9777114e24a1e964336ed78f1 [2]  https://mailarchive.ietf.org/arch/msg/ipv6/OrLYxKumiKWLHGkeNamhq9pxutQ/?qid=63c159fe41c18653d9dc0be609f9e97f [3]  https://mailarchive.ietf.org/arch/msg/ipv6/REez0-lbebpo-Xem-xX_sWV0pf4/?qid=5cdab6c6085795129802ab622bb4159f [4]  https://www.ietf.org/proceedings/98/minutes/minutes-98-6man-00 ========== Related to the above, I also want to point out the lack of clarity in the text in Section 4. (IPv6 Extension Headers), which leaves itself open to interpretation and should be cleaned up. (A)\u00a0 The main piece of text that has been discussed now reads: \u00a0  With one exception, extension headers are not examined, processed, \u00a0  inserted, or deleted by any node along a packet's delivery path, \u00a0  until the packet reaches the node (or each of the set of nodes, in \u00a0  the case of multicast) identified in the Destination Address field of \u00a0  the IPv6 header.\u00a0 Note: If an intermediate forwarding node examines \u00a0  an extension header for any reason, it must do so in accordance with \u00a0  the provisions of [ RFC7045 ]. \u00a0  ... \u00a0  The exception referred to in the preceding paragraph is the Hop-by- \u00a0  Hop Options header, which carries information that may be examined \u00a0  and processed by every node along a packet's delivery path, including \u00a0  the source and destination nodes.\u00a0 The Hop-by-Hop Options header, \u00a0  when present, must immediately follow the IPv6 header.\u00a0 Its presence \u00a0  is indicated by the value zero in the Next Header field of the IPv6 \u00a0  header. \u00a0  NOTE: While [ RFC2460 ] required that all nodes must examine and \u00a0  process the Hop-by-Hop Options header, it is now expected that nodes \u00a0  along a packet's delivery path only examine and process the Hop-by- \u00a0  Hop Options header if explicitly configured to do so. While the first sentence seems clear on what this document wants forwarding nodes to do (or not), there are two notes that define exceptions: any forwarding node can examine the headers \"for any reason\", and, the Hop-by-Hop Options header doesn't really have to be examined and processed by everyone. This text needs some more work to at least not contradict itself: there is more than one exception, and they are not absolute, anyone can examine the headers \"for any reason\"... (B) As it stands, the note about the changed expectations for the Hop-by-Hop options header opens a significant door to work around the \"limitations\" of other options.\u00a0 For example, it would be relatively straight forward to define a new Hop-by-Hop option to carry any type of information that could then be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\".\u00a0 In the world of controllers and programmatic access to forwarding nodes, changing the explicit configuration on the fly to customize which nodes do what, is trivial. Is that the intent of this document, to provide a generic mechanism for cases that may need extension headers to be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\"?\u00a0 Will the WG/IETF be in a position to charter, adopt and/or publish these types of documents?\u00a0 I ask this question not only in the context of my concerns expressed above, but also because the definition of the Hop-by-Hop Option would seem to be able to handle anything (\"used to carry optional information that may be examined and processed by every node along a packet's delivery path\" - I didn't see any constraints), even if (for example) the Routing Header \"is used by an IPv6 source to list one or more intermediate nodes to be \"visited\" on the way to a packet's destination\" -- so it makes me wonder whether using the Hop-by-Hop Options header to carry (for example) routing information so that it can be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\" would pass the bar set in Section 4.8. (Defining New Extension Headers and Options): \u00a0  New hop-by-hop options are not recommended because nodes may be \u00a0  configured to ignore the Hop-by-Hop Option header, drop packets \u00a0  containing a hop-by-hop header, or assign packets containing a hop- \u00a0  by-hop header to a slow processing path.\u00a0 Designers considering \u00a0  defining new hop-by-hop options need to be aware of this likely \u00a0  behaviour.\u00a0 There has to be a very clear justification why any new \u00a0  hop-by-hop option is needed before it is standardized. In the context of a controlled domain, it should be relatively easy for the operator to account for those issues.\u00a0 So my interpretation of whether a Hop-by-Hop option is ok to carry (for example) routing information is a strong \"Yes!\".\u00a0 Whether my interpretation is what was intended or not, I believe the overall text could benefit from more clarity.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-04-07 11:38:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-07 11:38:16-07:00",
    "text": "First off, this DISCUSS is NOT about questioning the rough consensus calls that the responsible Chair and AD have made, or wanting to change them, but about clarifying to avoid misinterpretations. Given the ongoing discussion about Extension Headers and controlled domains (for example [1] and [2]), the text should be very specific on what is expected and where.\u00a0 Because it is not, I think that this document is teetering along the line of having a \"high degree of technical maturity\", and not being ready for Internet Standard [ rfc6410 ]. Without further clarifications and guidance, this document also brings on unanticipated second order effects [ rfc3439 ] that can impact the direction, or even the viability, of future work in the IETF.\u00a0 Specifically, a straight forward interpretation of the text in Section 4 is the absolute prohibition to process, insert or delete EHs -- but discussion on the 6man mailing list seems to point at an understanding that the conditions inside a controlled domain may be different, for example (from Brian Carpenter [3]): ===== I've tried to say this before but I'm not sure people are getting it:  RFC2460bis, if approved as is, draws a line in the sand *for interoperability across the whole Internet*. There are reasons for this - PMTUD in any form, any future replacement for the unsuccessful IPsec/AH, and all the problems of deploying extension headers that are understood by some nodes and not by others.  There is no reason why a subsequent standards-track document cannot allow header insertion (and removal) within finite domains where the above issues do not apply. In fact, an improved version of  draft-voyer-6man-extension-header-insertion-00  could become exactly that. ===== [N.B.: I'm not implying that Brian's opinion represents consensus, that is not my call to make.] I'm pointing at an opinion (which I agree with) that recognizes the need to differentiate between contexts -- but the current text in rfc2460bis doesn't do that.\u00a0 I believe that this issue is significant (as reflected by the ongoing discussions) that that it should be resolved (by clarifying the text) before proceeding with the publication of this document as an Internet Standard.  To summarize, the text in this document has the second order effect of not leaving a clear path forward for extensions to IPv6 so that they adhere to the protocol's architecture, specially when applied to a controlled domain.\u00a0 At a minimum, I would like to see a clear path forward, whether that is in the form of an update for use of extensions in controlled domains, or a statement that this document just applies to IPv6 traffic intended to cross the Internet (as suggested at the 6man meeting in Chicago [4])...\u00a0 My opinion is that this document should not be published as an Internet Standard until the remaining open discussions are explicitly resolved and this document reflects that resolution. [1]  https://mailarchive.ietf.org/arch/msg/ipv6/UI0PfqrWco4Hpbvm8keGR8FabRg/?qid=9a6ba8e9777114e24a1e964336ed78f1 [2]  https://mailarchive.ietf.org/arch/msg/ipv6/OrLYxKumiKWLHGkeNamhq9pxutQ/?qid=63c159fe41c18653d9dc0be609f9e97f [3]  https://mailarchive.ietf.org/arch/msg/ipv6/REez0-lbebpo-Xem-xX_sWV0pf4/?qid=5cdab6c6085795129802ab622bb4159f [4]  https://www.ietf.org/proceedings/98/minutes/minutes-98-6man-00 ========== Related to the above, I also want to point out the lack of clarity in the text in Section 4. (IPv6 Extension Headers), which leaves itself open to interpretation and should be cleaned up. (A)\u00a0 The main piece of text that has been discussed now reads: \u00a0  With one exception, extension headers are not examined, processed, \u00a0  inserted, or deleted by any node along a packet's delivery path, \u00a0  until the packet reaches the node (or each of the set of nodes, in \u00a0  the case of multicast) identified in the Destination Address field of \u00a0  the IPv6 header.\u00a0 Note: If an intermediate forwarding node examines \u00a0  an extension header for any reason, it must do so in accordance with \u00a0  the provisions of [ RFC7045 ]. \u00a0  ... \u00a0  The exception referred to in the preceding paragraph is the Hop-by- \u00a0  Hop Options header, which carries information that may be examined \u00a0  and processed by every node along a packet's delivery path, including \u00a0  the source and destination nodes.\u00a0 The Hop-by-Hop Options header, \u00a0  when present, must immediately follow the IPv6 header.\u00a0 Its presence \u00a0  is indicated by the value zero in the Next Header field of the IPv6 \u00a0  header. \u00a0  NOTE: While [ RFC2460 ] required that all nodes must examine and \u00a0  process the Hop-by-Hop Options header, it is now expected that nodes \u00a0  along a packet's delivery path only examine and process the Hop-by- \u00a0  Hop Options header if explicitly configured to do so. While the first sentence seems clear on what this document wants forwarding nodes to do (or not), there are two notes that define exceptions: any forwarding node can examine the headers \"for any reason\", and, the Hop-by-Hop Options header doesn't really have to be examined and processed by everyone. This text needs some more work to at least not contradict itself: there is more than one exception, and they are not absolute, anyone can examine the headers \"for any reason\"... (B) As it stands, the note about the changed expectations for the Hop-by-Hop options header opens a significant door to work around the \"limitations\" of other options.\u00a0 For example, it would be relatively straight forward to define a new Hop-by-Hop option to carry any type of information that could then be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\".\u00a0 In the world of controllers and programmatic access to forwarding nodes, changing the explicit configuration on the fly to customize which nodes do what, is trivial. Is that the intent of this document, to provide a generic mechanism for cases that may need extension headers to be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\"?\u00a0 Will the WG/IETF be in a position to charter, adopt and/or publish these types of documents?\u00a0 I ask this question not only in the context of my concerns expressed above, but also because the definition of the Hop-by-Hop Option would seem to be able to handle anything (\"used to carry optional information that may be examined and processed by every node along a packet's delivery path\" - I didn't see any constraints), even if (for example) the Routing Header \"is used by an IPv6 source to list one or more intermediate nodes to be \"visited\" on the way to a packet's destination\" -- so it makes me wonder whether using the Hop-by-Hop Options header to carry (for example) routing information so that it can be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\" would pass the bar set in Section 4.8. (Defining New Extension Headers and Options): \u00a0  New hop-by-hop options are not recommended because nodes may be \u00a0  configured to ignore the Hop-by-Hop Option header, drop packets \u00a0  containing a hop-by-hop header, or assign packets containing a hop- \u00a0  by-hop header to a slow processing path.\u00a0 Designers considering \u00a0  defining new hop-by-hop options need to be aware of this likely \u00a0  behaviour.\u00a0 There has to be a very clear justification why any new \u00a0  hop-by-hop option is needed before it is standardized. In the context of a controlled domain, it should be relatively easy for the operator to account for those issues.\u00a0 So my interpretation of whether a Hop-by-Hop option is ok to carry (for example) routing information is a strong \"Yes!\".\u00a0 Whether my interpretation is what was intended or not, I believe the overall text could benefit from more clarity.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-05-19 18:17:08-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-07 11:38:56-07:00",
    "text": "First off, this DISCUSS is NOT about questioning the rough consensus calls that the responsible Chair and AD have made, or wanting to change them, but about clarifying to avoid misinterpretations. Given the ongoing discussion about Extension Headers and controlled domains (for example [1] and [2]), the text should be very specific on what is expected and where.\u00a0 Because it is not, I think that this document is teetering along the line of having a \"high degree of technical maturity\", and not being ready for Internet Standard [ rfc6410 ]. Without further clarifications and guidance, this document also brings on unanticipated second order effects [ rfc3439 ] that can impact the direction, or even the viability, of future work in the IETF.\u00a0 Specifically, a straight forward interpretation of the text in Section 4 is the absolute prohibition to process, insert or delete EHs -- but discussion on the 6man mailing list seems to point at an understanding that the conditions inside a controlled domain may be different, for example (from Brian Carpenter [3]): ===== I've tried to say this before but I'm not sure people are getting it:  RFC2460bis, if approved as is, draws a line in the sand *for interoperability across the whole Internet*. There are reasons for this - PMTUD in any form, any future replacement for the unsuccessful IPsec/AH, and all the problems of deploying extension headers that are understood by some nodes and not by others.  There is no reason why a subsequent standards-track document cannot allow header insertion (and removal) within finite domains where the above issues do not apply. In fact, an improved version of  draft-voyer-6man-extension-header-insertion-00  could become exactly that. ===== [N.B.: I'm not implying that Brian's opinion represents consensus, that is not my call to make.] I'm pointing at an opinion (which I agree with) that recognizes the need to differentiate between contexts -- but the current text in rfc2460bis doesn't do that.\u00a0 I believe that this issue is significant (as reflected by the ongoing discussions) that that it should be resolved (by clarifying the text) before proceeding with the publication of this document as an Internet Standard.  To summarize, the text in this document has the second order effect of not leaving a clear path forward for extensions to IPv6 so that they adhere to the protocol's architecture, specially when applied to a controlled domain.\u00a0 At a minimum, I would like to see a clear path forward, whether that is in the form of an update for use of extensions in controlled domains, or a statement that this document just applies to IPv6 traffic intended to cross the Internet (as suggested at the 6man meeting in Chicago [4])...\u00a0 My opinion is that this document should not be published as an Internet Standard until the remaining open discussions are explicitly resolved and this document reflects that resolution. [1]  https://mailarchive.ietf.org/arch/msg/ipv6/UI0PfqrWco4Hpbvm8keGR8FabRg/?qid=9a6ba8e9777114e24a1e964336ed78f1 [2]  https://mailarchive.ietf.org/arch/msg/ipv6/OrLYxKumiKWLHGkeNamhq9pxutQ/?qid=63c159fe41c18653d9dc0be609f9e97f [3]  https://mailarchive.ietf.org/arch/msg/ipv6/REez0-lbebpo-Xem-xX_sWV0pf4/?qid=5cdab6c6085795129802ab622bb4159f [4]  https://www.ietf.org/proceedings/98/minutes/minutes-98-6man-00 ========== Related to the above, I also want to point out the lack of clarity in the text in Section 4. (IPv6 Extension Headers), which leaves itself open to interpretation and should be cleaned up. (A)\u00a0 The main piece of text that has been discussed now reads: \u00a0  With one exception, extension headers are not examined, processed, \u00a0  inserted, or deleted by any node along a packet's delivery path, \u00a0  until the packet reaches the node (or each of the set of nodes, in \u00a0  the case of multicast) identified in the Destination Address field of \u00a0  the IPv6 header.\u00a0 Note: If an intermediate forwarding node examines \u00a0  an extension header for any reason, it must do so in accordance with \u00a0  the provisions of [ RFC7045 ]. \u00a0  ... \u00a0  The exception referred to in the preceding paragraph is the Hop-by- \u00a0  Hop Options header, which carries information that may be examined \u00a0  and processed by every node along a packet's delivery path, including \u00a0  the source and destination nodes.\u00a0 The Hop-by-Hop Options header, \u00a0  when present, must immediately follow the IPv6 header.\u00a0 Its presence \u00a0  is indicated by the value zero in the Next Header field of the IPv6 \u00a0  header. \u00a0  NOTE: While [ RFC2460 ] required that all nodes must examine and \u00a0  process the Hop-by-Hop Options header, it is now expected that nodes \u00a0  along a packet's delivery path only examine and process the Hop-by- \u00a0  Hop Options header if explicitly configured to do so. While the first sentence seems clear on what this document wants forwarding nodes to do (or not), there are two notes that define exceptions: any forwarding node can examine the headers \"for any reason\", and, the Hop-by-Hop Options header doesn't really have to be examined and processed by everyone. This text needs some more work to at least not contradict itself: there is more than one exception, and they are not absolute, anyone can examine the headers \"for any reason\"... (B) As it stands, the note about the changed expectations for the Hop-by-Hop options header opens a significant door to work around the \"limitations\" of other options.\u00a0 For example, it would be relatively straight forward to define a new Hop-by-Hop option to carry any type of information that could then be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\".\u00a0 In the world of controllers and programmatic access to forwarding nodes, changing the explicit configuration on the fly to customize which nodes do what, is trivial. Is that the intent of this document, to provide a generic mechanism for cases that may need extension headers to be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\"?\u00a0 Will the WG/IETF be in a position to charter, adopt and/or publish these types of documents?\u00a0 I ask this question not only in the context of my concerns expressed above, but also because the definition of the Hop-by-Hop Option would seem to be able to handle anything (\"used to carry optional information that may be examined and processed by every node along a packet's delivery path\" - I didn't see any constraints), even if (for example) the Routing Header \"is used by an IPv6 source to list one or more intermediate nodes to be \"visited\" on the way to a packet's destination\" -- so it makes me wonder whether using the Hop-by-Hop Options header to carry (for example) routing information so that it can be \"examined, processed, inserted, or deleted by any node along a packet's delivery path\" would pass the bar set in Section 4.8. (Defining New Extension Headers and Options): \u00a0  New hop-by-hop options are not recommended because nodes may be \u00a0  configured to ignore the Hop-by-Hop Option header, drop packets \u00a0  containing a hop-by-hop header, or assign packets containing a hop- \u00a0  by-hop header to a slow processing path.\u00a0 Designers considering \u00a0  defining new hop-by-hop options need to be aware of this likely \u00a0  behaviour.\u00a0 There has to be a very clear justification why any new \u00a0  hop-by-hop option is needed before it is standardized. In the context of a controlled domain, it should be relatively easy for the operator to account for those issues.\u00a0 So my interpretation of whether a Hop-by-Hop option is ok to carry (for example) routing information is a strong \"Yes!\".\u00a0 Whether my interpretation is what was intended or not, I believe the overall text could benefit from more clarity.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-08 09:53:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-08 06:36:52-07:00",
    "text": "This security considerations section seems fairly unsatisfactory. First, you can't just point back to IPv4, which doesn't even have a security considerations section. Second, IPv6 actually has different security and privacy properties than IPv4 in a number of respects, so you actually need to document them. document needs to as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-21 15:38:56-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-08 09:53:56-07:00",
    "text": "This security considerations section seems fairly unsatisfactory. First, you can't just point back to IPv4, which doesn't even have a security considerations section. Second, IPv6 actually has different security and privacy properties than IPv4 in a number of respects, so you actually need to document them.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-04-22 07:30:47-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-13 06:28:26-07:00",
    "text": "I would also like to see an updated security considerations section specific to IPv6 and have the opportunity to review that prior to publication of this draft.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-04-19 04:31:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-12 08:34:24-07:00",
    "text": "My discuss is mainly on text in section 4.8 (also based on the tsv-art review -> Thanks Martin!): I find the recommendation to basically just not use hop-by-hop headers in section 4.8 extremely unsatisfying. Can we maybe do better? Wouldn't it be maybe time to just deprecate the current hop-by-hop number an assign a new one? I know that also has deployment problem but maybe it's worth a try. I guess the assignment could happen in a new document though, but the deprecation could be done here. This related to this comment from Martin's review, also proposing a potential way forward: \"- Section 4.8. \"Defining New Extension Headers and Options\": It says new hop-by-hop headers must never ever defined. This is problematic, as this closing the door forever, even if future instances of the IETF do would like to wish to define new hop-by-hop headers. A better way would have to say \"that new hop-by-hop headers must have IETF consensus\". - Section 4.8. \"Defining New Extension Headers and Options\": Also the \u201enot recommended\u201c to define new extension headers looks strange, especially with the phrase \"There has to be a very clear justification\". The term \"clear justification\" is not an exact engineering specification. Why not using \"technical protocol specification and real word use case required, plus IETF consensus\"?\" As a side note, there is at least one experimental RFC that defines a destination option to be inspected by a network device, given the know problems of hop-by-hop option which renders them unusable.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-04-22 04:48:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-19 04:31:38-07:00",
    "text": "I'm changing this discuss because I believe changes regarding any text in section 4.8 would mostly be editorial at this point if any. I would still like to see more background information explaining the situation and risks, rather than just giving a general recommendation that might even out-date in cases routers get updated accordingly in future. However, I holding this discuss, because the ECN issue I originally only raised as a question in the comment section really needs to be addressed. Hope to wrap this up soon.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-05-08 05:06:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-22 04:48:49-07:00",
    "text": "I'm changing this discuss because I believe changes regarding any text in section 4.8 would mostly be editorial at this point if any. I would still like to see more background information explaining the situation and risks, rather than just giving a general recommendation that might even out-date in cases routers get updated accordingly in future. However, I holding this discuss, because the ECN issue I originally only raised as a question in the comment section really needs to be addressed. Hope to wrap this up soon. It's about this text: Section 4.5: \"The number and content of the headers preceding the Fragment \u00a0 \u00a0 \u00a0 header of different fragments of the same original packet may \u00a0 \u00a0 \u00a0 differ.\u00a0 Whatever headers are present, preceding the Fragment \u00a0 \u00a0 \u00a0 header in each fragment packet, are processed when the packets \u00a0 \u00a0 \u00a0 arrive, prior to queueing the fragments for reassembly.\u00a0 Only \u00a0 \u00a0 \u00a0 those headers in the Offset zero fragment packet are retained in \u00a0 \u00a0 \u00a0 the reassembled packet.\" The ECN codepoint may differ in each fragment and  RFC3168  speficies handling for reassembly.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-05-19 12:35:36-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-08 05:06:57-07:00",
    "text": "Thanks for addressing my discuss. Text on  rfc3168  is fine! I'm also okay with the text on extension headers, however, I have one remaining processing question: Now the text uses similar but not the same wording as  RFC6564 .  RFC6564  says \"new IPv6 extension headers MUST NOT be created or specified, ...\" and this draft says \"Defining new IPv6 extension headers is not recommended, ...\" in not normative language. Is that on purpose? Does this draft need to absolete  RFC6564  or refer or whatever?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-23 07:43:56-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-16 20:40:27-08:00",
    "text": "A few super-boring inconsistencies that make the document unfit to  publish as-is but should be mostly trivial to resolve ((3) and (4) might be a little tedious but should be mechanical): (1) Section 3.3.1 says: \u00a0 \u00a0 \u00a0 be silently dropped if not recognized.\u00a0 The code points for \u00a0 \u00a0 \u00a0 experimental use are taken from the ranges previously called \u00a0 \u00a0 \u00a0 'Vendor Private Use', the remainder of which now form part of 'RFC \u00a0 \u00a0 \u00a0 Required'. but I don't think this sentence matches what's proposed in Section 6.\u00a0 I am seeing the code points for experimental use coming out of the range that is currently described as \"specification required\", with the entirety of the range currently described as \"vendor private use\" being converted to FCFS. (2) Section 4.1 says: \u00a0  Mandatory and optional are used to indicate whether a response is \u00a0  needed if a TLV or sub-TLV is not understood on pages 14 and 15 in \u00a0  Section 3 of  RFC 8029 . but I think the text being modified is on pages 15 and 16 of  RFC 8029 (the page numbers are in the footer, not the header, of the plain text output format). (3) Section 6.2.3 describes changes to the procedures for the Sub-TLVs for TLV 6 sub-registry, but the changes described assume that the registration procedures are as described by  RFC 8029 .\u00a0 However, the registration procedures have already been changed by  RFC 8611 , so the changes described no longer make sense.\u00a0 (E.g., there is not currently a \"specification required\" procedure active for any range of this sub-registry.)\u00a0 We do, however, still need to make some changes to the registration procedures, specifically to convert the \"Private Use\" ranges to FCFS and carve out the \"Experimental Use\" blocks. (4) Table 22 (for Sub-TLVs for TLV 27 Assignments) seems to be a copy of Table 20 and does not reflect the current state of the sub-registry in question.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-02-28 10:48:32-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-16 02:37:59-08:00",
    "text": "Hi, I have a couple of concerns regarding the change from part of the registry from \"Private Use\" to \"FCFS\": (1) Am I right in thinking that this could, at least in theory, break existing deployments?\u00a0 E.g., two separate implementations could both be using TLV value 31744 under \"private use\", whereas now they would both be expected to register that TLV with IANA under FCFS, and obviously only one of them would be able to get the registration?\u00a0 Are the authors/WG/ADs aware with high confidence that no such deployments exist? (2) I find the \"updates\" tag for RFCs to be somewhat ambiguous as to what it means.\u00a0 Specifically, is someone who implements  RFC 8611  obliged to also implement  draft-ietf-mpls-lsp-ping-registries-update  when this becomes an RFC?\u00a0 Or are they allowed to take the previous interpretation of the \"private use\" in the IANA registries?\u00a0 Probably too late to change this now, but I wonder if it would have been better to bis  RFC 8611  instead so that  RFC 8611  could have been formally obsoleted by  draft-ietf-mpls-lsp-ping-registries-update  instead. An alternative solution would be to keep the \"Private Use\" space as defined in  RFC 8611 , and allocate new space for FCFS (24 entries) from the 15,000 entry \"RFC Required\" section of the TLV Id space instead.\u00a0 These would seem to make the new allocation scheme in  draft-ietf-mpls-lsp-ping-registries-update  entirely backwards compatible with any existing deployments.\u00a0 Was this approach considered and dismissed for some reason? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 18:02:57-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 07:25:28-08:00",
    "text": "This is probably a minor point, but I'm putting it in the Discuss section because one of the possible answers would be very problematic and I can't rule that scenario out with just the information at hand.\u00a0 As such (and per https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ ) a response is greatly appreciated, to help clarify the intended meaning and thus what (if any) changes to the document should be made in response. In Section 4.2 we have a couple tables listing RECOMMENDED and OPTIONAL features for different types of DUT/SUT.\u00a0 Do these recommendations relate to what features should be tested, what features should be enabled for use in normal operation, what features should be implemented in devices, or something else?\u00a0 The latter options seem a bit far afield from the stated scope of this document, and the particular recommendations listed probably do not have IETF Consensus as to general applicability (most notably for SSL Inspection).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-09-12 04:21:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 01:16:36-08:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS points (probably easy to address but really important), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Thanks to Toerless for his deep and detailed IoT directorate review, I have seen as well that the authors are engaged in email discussions on this review: https://datatracker.ietf.org/doc/review-ietf-bmwg-ngfw-performance-13-iotdir-telechat-eckert-2022-01-30/ Special thanks to Al Morton for the shepherd's write-up including the section about the WG consensus.  I hope that this helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics The document obsoletes  RFC 3511 , but it does not include any performance testing of IP fragmentation (which  RFC 3511  did), which is AFAIK still a performance/evasion problem. What was the reason for this lack of IP fragmentation support ? At the bare minimum, there should be some text explaining why IP fragmentation can be ignored.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-09-12 03:11:02-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 05:27:09-08:00",
    "text": "This document needs TSV and ART people to help with straightening out a lot of issues related to TCP, TLS, and H1/2/3. Large parts of the document don't correctly reflect the complex realities of what \"HTTP\" is these days (i.e., that we have H1 and H2 over either TCP or TLS, and H3 over only QUIC.) The document is also giving unnecessarily detailed behavioral descriptions of TCP and its parameters, while at the same time not being detailed enough about TLS, H2 and esp. QUIC/H3. It feels like this stared out as an H1/TCP document that was then incompletely extended to H2/H3. Section 4.3.1.1. , paragraph 2, discuss: >\u00a0 \u00a0 The TCP stack SHOULD use a congestion control algorithm at client and >\u00a0 \u00a0 server endpoints.\u00a0 The IPv4 and IPv6 Maximum Segment Size (MSS) >\u00a0 \u00a0 SHOULD be set to 1460 bytes and 1440 bytes respectively and a TX and >\u00a0 \u00a0 RX initial receive windows of 64 KByte.\u00a0 Client initial congestion >\u00a0 \u00a0 window SHOULD NOT exceed 10 times the MSS.\u00a0 Delayed ACKs are >\u00a0 \u00a0 permitted and the maximum client delayed ACK SHOULD NOT exceed 10 >\u00a0 \u00a0 times the MSS before a forced ACK.\u00a0 Up to three retries SHOULD be >\u00a0 \u00a0 allowed before a timeout event is declared.\u00a0 All traffic MUST set the >\u00a0 \u00a0 TCP PSH flag to high.\u00a0 The source port range SHOULD be in the range >\u00a0 \u00a0 of 1024 - 65535.\u00a0 Internal timeout SHOULD be dynamically scalable per >\u00a0 \u00a0  RFC 793 .\u00a0 The client SHOULD initiate and close TCP connections.\u00a0 The >\u00a0 \u00a0 TCP connection MUST be initiated via a TCP three-way handshake (SYN, >\u00a0 \u00a0 SYN/ACK, ACK), and it MUST be closed via either a TCP three-way close >\u00a0 \u00a0 (FIN, FIN/ACK, ACK), or a TCP four-way close (FIN, ACK, FIN, ACK). There are a lot of requirements in here that are either no-ops (\"SHOULD use a congestion control algorithm\"), nonsensical (\"maximum client delayed ACK SHOULD NOT exceed 10 times the MSS\") or under the sole control of the stack. This needs to be reviewed and corrected by someone who understands TCP.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-10-27 07:27:52-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-02 21:24:01-08:00",
    "text": "I may be wandering into unfamiliar territory here, i.e., how benchmarking specs are typically written, but this is sufficiently confusing that I'd like to discuss it. I note that  RFC 3511 , which this document obsoletes, didn't cite  RFC 2119  ( BCP 14 ) but rather defined those same key words on its own.\u00a0 Then it used SHOULD rather liberally, in a way that seems kind of peculiar to me (especially compared to the text of Section 6 of  RFC 2119 ).\u00a0 Do any of them matter to the outcome of the benchmark being constructed or executed?\u00a0 If so and they would spoil the test, shouldn't they be MUSTs?\u00a0 If not, why include them?\u00a0 Or in the alternative, why might I, as someone setting up a test, legitimately do something contrary to the SHOULD in each case (which \"SHOULD\" expressly permits)? This document does cite  BCP 14  directly, and then seems to take that curious pattern to the next level.\u00a0 Among the 130+ SHOULDs in here, I'm particularly confused by stuff like this in Section 4.3.1: \u00a0  This section specifies which parameters SHOULD be considered while \u00a0  configuring clients using test equipment.\u00a0  I have no idea what this means to the test.\u00a0 If I've simply thought about these parameters, have I met the burden here? This in Section 4.3.1.1 (\"TCP Stack Attributes\") seems an odd thing to have to stipulate: \u00a0 The client SHOULD initiate and close TCP connections. Then Section 7.1.3, which contains subsections about each of the test parameters for the benchmark described in Section 7.1, consists of this text: \u00a0  In this section, the benchmarking test specific parameters SHOULD be \u00a0  defined. As I read it, this is a self-referential SHOULD about this document!\u00a0 I'm very confused.\u00a0 This happens again in Section 7.2.3, 7.3.3, etc., up to 7.9.3, and even Appendix A.3.\u00a0 I think in each case you just want: \u00a0  This section defines test-specific parameters for this benchmark.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-13 11:44:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-02 14:39:27-08:00",
    "text": "** A key element of successfully running the throughput tests described in Section 7, appears to be ensuring how to configure the device under test.\u00a0 Section 4.2. helpfully specifies feature sets with recommendations configurations.\u00a0 However, it appears there are elements of under-specification given the level of detail specified with normative language.\u00a0 Specifically: -- Section 4.2.1 seems unspecified regarding all the capabilities in Table 1 and 2.\u00a0 The discussion around vulnerabilities (CVEs) does not appear to be relevant to configuration of anti-spyware, anti-virus, anti-botnet, DLP, and DDOS.\u00a0  -- Recognizing that NGFW, NGIPS and UTM are not precise product categories, offerings in this space commonly rely on statistical models or AI techniques (e.g., machine learning) to improve detection rates and reduce false positives to realize the capabilities in Table 1 and 2.\u00a0 If even possible, how should these settings be tuned?\u00a0 How should the training period be handled when describing the steps of the test regime (e.g., in Section 4.3.4? Section 7.2.4?) ** Appendix A.\u00a0 The KPI measures don\u2019t seem precise here \u2013 CVEs are unlikely to be the measure seen on the wire.\u00a0 Wouldn\u2019t it be exploits associated with a particular vulnerability (that\u2019s numbered via CVE)?\u00a0 There can be a one-to-many relationship between the vulnerability and exploits (e.g., multiple products affected by a single CVE); or the multiple implementations of an exploit.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-22 14:28:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-13 11:44:43-07:00",
    "text": "(Updated Ballot) -- [per -13] Recognizing that NGFW, NGIPS and UTM are not precise product categories, offerings in this space commonly rely on statistical models or AI techniques (e.g., machine learning) to improve detection rates and reduce false positives to realize the capabilities in Table 1 and 2.\u00a0 If even possible, how should these settings be tuned?\u00a0 How should the training period be handled when describing the steps of the test regime (e.g., in Section 4.3.4? Section 7.2.4?) [per -14] Thank for explaining that the training phase would not be included in the threat emulating in your email response.\u00a0 Since the goal of these document is specify reproducible testing, the primary text I was look for was an acknowledgment that the detection performance of some systems may be affected by learning from prior traffic.\u00a0 Any state kept by such systems much be reset between testing runs.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-02 08:48:21-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-28 01:47:17-08:00",
    "text": "I think this should be an easy one to resolve: Section 7 says: \"The protection of UPN and UPA messages in this document follows [ RFC5213 ] and [ RFC7077 ].\" I'm not clear if \"follows\" means the same as \"MUST be protected using end-to-end security association(s) offering integrity and data origin authentication\" ( RFC5213 , section 4). I think it ought really, as otherwise this could subvert the security of PMIPv6. So wouldn't it make sense to be explicit that these new messages have the same MUST requirements as binding updates. Doing that by repeating the quoted text from 5213 would be a fine way to do that, but there may be better options.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-06-19 09:31:12-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-19 00:17:54-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-stamp-srpm-12 Thank you for the work put into this document.  Please find below two blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and one nit. Special thanks to Tommy Pauly for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 3 Probably easy to fix :-) `The Session-Reflector SHOULD use the received Destination Node Address as the Source Address in the IP header of the reply test packet`. I am sure that the authors do not want to do spoofing, i.e., add some text about \"only if the Destination Node Address is one of the node addresses\" or similar. ## Section 4.1.1 Please add text similar to \"All other bits are reserved and must be transmitted as 0 and ignored by the receiver\".",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-06-29 13:32:08-07:00",
    "end_reason": "discuss_updated",
    "start": "2023-06-20 18:29:25-07:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-stamp-srpm-13 CC @jgscudder Thanks for this document. Despite the lengthiness of my ballot and DISCUSS section, I think this document is in reasonably good shape and will be ready to go after one more good editing pass. Thanks for your work on it, and thanks in advance for helping me work through my DISCUSS points. ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 3, not an address of the Session-Reflector, really? The description \"transmit test packets to the Session-Reflector with a different destination address that is not matching an address of the Session-Reflector\" appears to be inaccurate, at least for the use case you've presented: loopback is by definition an address of the Session-Reflector, and indeed of every IP-enabled node, is it not? So it's not right to say that the DA is \"not matching an address of the Session-Reflector\". As far as I can tell by skimming the STAMP base spec, STAMP is basically a host function. Presumably any packet whose DA was not an address of the Session-Reflector wouldn't be delivered to the host stack, and consequently wouldn't be processed. So it seems that perhaps this functionality is only for use when the DA is set to loopback. Is that correct? Is the entire effect of the Destination Node Address TLV to tell the target what SA to use in its reply, and for session identification (although the latter appears to be an inessential use since SSID would do the same job)? Once I have more confidence I understand what's really going on here, I may have some further suggestions for how to edit for clarity. According to my current understanding, it seems to me as though something along the lines of \"The Session-Sender may need to transmit test packets to an address of the Session-Reflector which is not suitable for use as the Source Address of the reply test packet. This TLV allows the Session-Sender to request the Session-Reflector to use a different Source Address in its reply test packet\" might work. ### Section 6, \"limited domain\" I'm concerned with the reliance on \"limited domain\" without doing the work to define what's meant. \u00a0  The usage of STAMP protocol is intended for deployment in limited \u00a0  domains [ RFC8799 ]. \u00a0   RFC 8762  doesn't indicate this, or at least, it has no mention of such in its Security Considerations section nor occurrence of the string \"limited\" anywhere in the RFC. Further,  RFC 8799  isn't a good reference. It's not an IETF document and doesn't itself claim to define what a limited domain is. From the  RFC 8799  abstract: \"Finally, it shows the need for a precise definition of \"limited domain membership\"\". That is, it identifies the need for a definition but doesn't claim to supply one.  RFC 8799  does provide, in Section 6, some guidance that might be helpful in defining what is meant by a \"limited domain\" in a specific context -- but it is up to the document defining that context, to define what it means by \"limited domain\". Some of the underlying STAMP documents do provide context about their assumptions of the deployment environment which might broadly speaking fit the \"limited domain\" rubric -- but they do so in specific terms. It's regrettable that the IETF has no document that defines \"limited domain\", but the fact remains that we don't. This deficiency might not be problematic except that you lean on it quite heavily in the last paragraph of the section: \u00a0  The STAMP extensions defined in this document may be used for \u00a0  potential \"proxying\" attacks.\u00a0 For example, a Session-Sender may \u00a0  specify a return path that has a destination different from that of \u00a0  the Session-Sender.\u00a0 But normally, such attacks will not happen in an \u00a0  SR domain where the Session-Senders and Session-Reflectors belong to \u00a0  the same domain. \u00a0   The \"but normally\" sentence really cries out for some more precise definition of what you think the security context is. Maybe there is a reference within the STAMP or SR document set that you can reference to provide this context, but  RFC 8799  is not sufficient.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-08-15 11:06:06-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-29 13:32:08-07:00",
    "text": "Thanks for your work to address my previous DISCUSS and COMMENTs. Although you've worked to remove the reliance of \"Limited Domain\" (thank you), regrettably the new text introduces a new, and I think also problematic, reliance on the SR Domain concept. To quote from my earlier email, On Jun 22, 2023, at 1:09 PM, John Scudder\u00a0 wrote: In looking over the new version, it occurred to me that although the document is called \u201c... for Segment Routing Networks\u201d and although that was the use case that motivated it, the only elements whose applicability actually is limited to SR are the Return Path SR-MPLS Segment-List Sub-TLV and the Return Path SRv6 Segment-List Sub-TLV. All the rest are generically applicable. This is basically a good thing IMO \u2014 one likes to see specs whose applicability is greater than just the use case that led to their development \u2014 but it does mean that \"The usage of STAMP protocol is intended for deployment in SR domains [ RFC8402 ]\u201d isn't sufficient, I\u2019m afraid \u2014 whether the use case that led to the development was restricted to SR or not, one can easily see how (for example) a Return Address Sub-TLV could be used outside of an SR deployment. That use might be by design, or it might be by an attacker. To repeat the concern in different words: You\u2019ve rewritten the first paragraph of the Security Considerations as \u00a0 The usage of STAMP extensions defined in this document is intended \u00a0 for deployment in SR domains [ RFC8402 ].\u00a0 It is assumed that a node \u00a0 involved in STAMP protocol operation has previously verified the \u00a0 integrity of the path and the identity of the far-end Session- \u00a0 Reflector. This eliminates the reliance on the Limited Domains RFC (good) but you\u2019re improperly (I think) assuming that you can rely on the SR domain definition instead. This is still true even though you changed \u201cSTAMP protocol\u201d (the version I commented on in the quote above) to \u201cSTAMP extensions\u201d. Again, to repeat: I don\u2019t think it\u2019s either reasonable or desirable to restrict the extensions you\u2019ve defined to be only for use in an SR domain, and therefore, I think the SecCons can\u2019t rest on the foundation of the SR document set. If you did want to rest on that foundation, I think you would have to be much more prescriptive about saying the extensions MUST NOT be processed other than in an SR context (that\u2019s probably not the right wording) \u2014 but I think that would be undesirable, and I think if you did want to make that change, it would be a pretty fundamental change requiring a new WGLC.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-08-04 06:55:34-07:00",
    "end_reason": "position_updated",
    "start": "2023-08-04 03:27:43-07:00",
    "text": "# GEN AD review of  draft-ietf-ippm-stamp-srpm-17 CC @larseggert Thanks to Joel Halpern for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/crZp5rrOYaDNMcoM95b5pFQBReo ). ## Discuss Two issues that I think will be quick to fix: ### Section 4, paragraph 12 ``` \u00a0 \u00a0  other Return Path TLVs if present.\u00a0 A Session-Reflector that supports \u00a0 \u00a0  this TLV MUST reply using the Return Path received in the Session- \u00a0 \u00a0  Sender test packet, if possible. ``` \"MUST ... if possible\" is an odd construction. Please rephrase and  clarify the requirements level. ### Section 4.1.3, paragraph 16 ``` \u00a0 \u00a0  The SRv6 Segment List contains a list of 128-bit IPv6 addresses \u00a0 \u00a0  representing the SRv6 SIDs.\u00a0 Length of the Sub-TLV modulo MUST be 0. ``` Modulo *what*?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2023-07-10 08:24:54-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-22 07:27:26-07:00",
    "text": "I am balloting DISCUSS on this document because I do not believe the the document fully specifies the processing and behavior. It is sufficiently unclear in many places that I believe that it is not fully implementable by people not involved in its creation. Note that this was originally an Abstain, but on further consideration I feel it requires a DISCUSS. There are many examples of this, especially around the source and destination address text. For example: \"The Session-Sender may need to transmit test packets to the Session-Reflector with a different destination address that is not matching an address of the Session-Reflector e.g. when the STAMP test packet is encapsulated by a tunneling protocol e.g., encapsulated with an SR-MPLS Segment List and IPv4 header containing destination IPv4 address from 127/8 range or encapsulated with outer IPv6 header and Segment Routing Header (SRH) with inner IPv6 header containing IPv6 destination IPv6 address ::1/128.\" - I'm unable to parse this / how this is expected to work. If the sender sends packets to the reflector through a tunnel, isn't the packet decapsulated when it leaves the tunnel / link, and then the address should be that of the SR? Or are you saying that this is a function of the decapsulation, and whatever process does that should simply trust and process any STAMP packets, regardless of it if owns the address? It is also very unclear what exactly the behavior is intended to be for nodes when using \"different values of IPv4 destination address from 127/8 range may be used in the IPv4 header to measure different ECMP paths.\" - is the assumption that the Session-Reflector is listening on / will process any decapsulated packet destined to any address in 127/8? If so, that is really not clear. This text is also unclear: \"For security reasons (e.g., to avoid node discovery), the Session-Reflector SHOULD use the received Destination Node Address as the Source Address in the IP header of the reply test packet only if the Destination Node Address is one of the addresses on the node, instead of using its Node Address.\" - this sounds like a node should extract the packet, and use the received Destination Node Address as the Source Address if this address exists on the node. If this correct? If so, this is overriding the standard source address selection logic on the device, and can be used to cause packets to be emitted which bypass firewall filters (e.g: My management network is numbered out of 10/8, and I have firewall filters which only allow access to 10/8 from bastion stations. By using the described solution, I can send a STAMP packet to the node and set the Destination Node Address as 10.0.0.5 (an address on the device). This specifies that the Source Address of the return packet should be 10.0.0.5, regardless of if the packet is received on or processed by that interface. This allows filters which match on source address to be bypassed.) It is also unclear what you mean by \"e.g., to avoid node discovery\".  There is much in this document which is underspecified or hand-wavey, and, as such, I do not think that I can ballot No Objection in good faith.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-09-08 13:01:19-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-29 14:30:55-07:00",
    "text": "** Section 6. It may be inferred from the general requirements (Section 4.1) for \u00a0  provable ownership, provable binding, and provable registration, \u00a0  together with the identifier requirements (Section 4.2), that DRIP \u00a0  must provide: \u00a0  *\u00a0 message integrity \u00a0  *\u00a0 non-repudiation \u00a0  *\u00a0 defense against replay attacks \u00a0  *\u00a0 defense against spoofing Thanks for enumerating these highly desirable security properties as part of DRIP.\u00a0 A bit more clarifying language is needed to explain which communication paths in the DRIP architecture (Figure 3 and 4) have these properties and under what circumstances.\u00a0 Section 4.1 and 4.2 seem specific to properties between particular parties or messages.\u00a0 Likewise, subsequent text in this section such as \u201c\u2026 there may be caveats on the extent to which requirements can be satisfied \u2026\u201d seems to suggest these are not universal across the architecture.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-14 20:17:11-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-08 13:02:07-08:00",
    "text": "Secs 5.9.6 defines Maximum Reordering Tolerance with an example: \"The difference of sequence number values in \u00a0  consecutive packets at the Egress cannot be bigger than \u00a0  \"MaxMisordering + 1\".\" While this definition is actionable, it interacts uncomfortably with Maximum Consecutive Loss. If MCL < MRT, there are cases where it will violate MRT but not MCL, which would subvert the usually understood meaning of reordering. Moreover, if MaxMisordering is 3, the sequence 6, 4, 0 would not trigger this definition even though there is very significant reordering here. A better example would be \"When a packet arrives at the egress after a packet with a higher sequence number, the difference between the sequence number values cannot be bigger than \u00a0  \"MaxMisordering + 1\".\"",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-03-25 04:16:49-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-13 05:09:42-07:00",
    "text": "IANA Considerations need to mention that this document allows for Content-Disposition header field to be used in HTTP requests.  RFC 6266  only defined its use for HTTP responses. Also, the IANA Expert Reviewer has mentioned: I would like section 4.3. MANAGED-ID Property Parameter to clarify the scope of uniqueness of the MANAGED-ID values (e.g., globally unique like UID, unique per iCalendar component? unique per VEVENT?).",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-19 07:17:00-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-19 04:51:13-08:00",
    "text": "I think this is the first \"configure my DNS\" thing to come before the IESG since DPRIVE has gotten an output, so it seems fair to ask now: Why doesn't the DNS server information include a port now that we have both 53 and 853 as options?\u00a0 Without that, how is a host supposed to know which to use? Did the WG consider DPRIVE? If so, what was the conclusion? If not, what is the right thing to do? (Add the port no? Define a new DHCPv6 option for DNS/TLS? Something else?)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-09-08 02:55:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-22 06:26:51-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ipsecme-iptfs-13 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Tero Kivinen for the shepherd's detailed write-up including the WG consensus, alas the justification of the intended status is missing :-( Please note that Tatuya Jinmei is the Internet directorate reviewer (at my request) and you may want to consider this int-dir review as well: https://datatracker.ietf.org/doc/review-ietf-ipsecme-iptfs-13-intdir-telechat-jinmei-2022-08-18/ I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 6.1 ``` \u00a0  An AGGFRAG payload is identified by the ESP Next Header value \u00a0  AGGFRAG_PAYLOAD which has the value 0x5.\u00a0 The value 5 was chosen to \u00a0  not conflict with other used values.\u00a0 The first octet of this payload \u00a0  indicates the format of the remaining payload data. ``` This is in direct conflict with  RFC 4303  (see below) IMHO as 5 is already allocated to ST ( RFC 1819 , which is still 'current' even if it was never used). But ESP  RFC 4303  section 2.6 says that this is an IP protocol number (and 5 is already allocated by the IANA): ``` \u00a0  The Next Header is a mandatory, 8-bit field that identifies the type \u00a0  of data contained in the Payload Data field, e.g., an IPv4 or IPv6 \u00a0  packet, or a next layer header and data.\u00a0 The value of this field is \u00a0  chosen from the set of IP Protocol Numbers defined on the web page of \u00a0  the IANA, e.g., a value of 4 indicates IPv4, a value of 41 indicates \u00a0  IPv6, and a value of 6 indicates TCP. ``` I.e., either this document needs to formally update  RFC 4303  by allowing any number or another IP protocol number must be requested to the IANA. ### Section 2.1, generic tunnel capability  ``` \u00a0  Other non-IP-TFS uses of this AGGFRAG mode have been suggested, such \u00a0  as increased performance through packet aggregation, as well as \u00a0  handling MTU issues using fragmentation.\u00a0 These uses are not defined \u00a0  here, but are also not restricted by this document. ``` Moreover, while IPSECme charter includes: ``` The demand for Traffic Flow Confidentiality has been increasing in the user community, but the current method defined in  RFC4303  (adding null padding to each ESP payload) is very inefficient in its use of network resources. The working group will develop an alternative TFC solution that uses network resources more efficiently. ``` it says nothing about a generic tunnelling protocol, which is usually INTAREA topic, and I cannot refrain from thinking that this tunnelling mechanism could be used on any connection-less transport, e.g., UDP or IP. Hence, this DISCUSS point is only to initiate a discussion with IPSECME chairs and AD; Christian Hopps has already given some explanations when I deferred this I-D. I understand that I am in the rough here (no reaction on int-area and int-dir review is positive). ### Section 2.2.6 Please also mention hop-limit and  RFC 8200 . ### Absence of ICMP considerations Should there be an equivalent of section 6 of  RFC 4301  about ICMP ? As several unprotected packets can be bundled together, some guidance to the implementers will be welcome.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-09-04 17:43:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 18:22:06-07:00",
    "text": "## Discuss ### S6.1 * I think this document should get a separate protocol value from the IANA \u00a0 \"Protocol Numbers\" registry, since that's where 4303 S2.6 clearly says they \u00a0 values come from. \u00a0 The \"value of 41 indicates IPv6\" makes it pretty clear where this field \u00a0 gets its values from. \u00a0  https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-09-09 04:20:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-23 08:06:07-07:00",
    "text": "# GEN AD review of  draft-ietf-ipsecme-iptfs-14 CC @larseggert Thanks to Peter E. Yee for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/VKlfYh3uoGomO4_Lv8e6kltl36g ). ## Discuss ### Section 2.4.1, paragraph 3 ``` \u00a0 \u00a0  For similar reasons as given in [ RFC7510 ] the non-congestion- \u00a0 \u00a0  controlled mode should only be used where the user has full \u00a0 \u00a0  administrative control over the path the tunnel will take.\u00a0 This is \u00a0 \u00a0  required so the user can guarantee the bandwidth and also be sure as \u00a0 \u00a0  to not be negatively affecting network congestion [ RFC2914 ].\u00a0 In this \u00a0 \u00a0  case, packet loss should be reported to the administrator (e.g., via \u00a0 \u00a0  syslog, YANG notification, SNMP traps, etc.) so that any failures due \u00a0 \u00a0  to a lack of bandwidth can be corrected. ``` There is a lot more nuance and there are a lot more restrictions in  RFC7510  that also apply here. If a non-congestion-controlled mode is desired, especially without even using  RFC8084  circuit breakers, similar mandatory text needs to be crafted for this mechanism. (I would also strongly suggest to require circuit breakers here.) ### Section 2.4.2, paragraph 0 ``` \u00a0 2.4.2.\u00a0 Congestion-Controlled Mode ``` This mode adds a LOT of complexity to this mechanism. Is this really needed? Could not  RFC8229  be used instead of defining an entirely separate congestion control scheme for (padded/fragmented) ESP? ### Section 2.4.2.1, paragraph 1 ``` \u00a0 \u00a0  In additional to congestion control, implementations MAY choose to \u00a0 \u00a0  define and implement circuit breakers [ RFC8084 ] as a recovery method \u00a0 \u00a0  of last resort.\u00a0 Enabling circuit breakers is also a reason a user \u00a0 \u00a0  may wish to enable congestion information reports even when using the \u00a0 \u00a0  non-congestion-controlled mode of operation. ``` This makes no sense. If implemented in addition to CC, circuit breakers will never fire, because a functioning congestion control algorithm will always maintain a send rate below the circuit breaker threshold. What would make sense is to use circuit breakers in the non-congestion-controlled case, to provide a safety mechanism in cases the network provisioning changes for an active tunnel. ### Section 3.1, paragraph 0 ``` \u00a0 3.1.\u00a0 ECN Support ``` There is a lot more nuance to this, as described in RC6040. This document needs to follow that existing standard rather than define another variant. ### Section 6.1.2, paragraph 9 ``` \u00a0 \u00a0  RTT: \u00a0 \u00a0 \u00a0 \u00a0 A 22-bit value specifying the sender's current round-trip time \u00a0 \u00a0 \u00a0 \u00a0 estimate in microseconds.\u00a0 The value MAY be zero prior to the \u00a0 \u00a0 \u00a0 \u00a0 sender having calculated a round-trip time estimate.\u00a0 The value \u00a0 \u00a0 \u00a0 \u00a0 SHOULD be set to zero on non-AGGFRAG_PAYLOAD-enabled SAs.\u00a0 If the \u00a0 \u00a0 \u00a0 \u00a0 RTT is equal to or larger than 0x3FFFFF the value MUST be set to \u00a0 \u00a0 \u00a0 \u00a0 0x3FFFFF. ``` This can only encode RTTs of up to around four seconds. That is too little for Internet usage. (Same concern about other 22-bit microsecond values below.)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-08-18 09:48:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-09 20:01:05-07:00",
    "text": "One point which I think will be simple to address: (6) As malformed packets are sometimes an attack vector, it would be good to specify behavior in response to pathological BlockOffsets, for instance: - What if two BlockOffset fields disagree? e.g., with 500 byte outer packets, what if the sequence of block offsets is {0, 750, 100}? Does the third packet have 250 or 100 bytes of the first data block? Drop the packet, kill the SA, ignore one and accept the other, or something else? - What if a pad block is in a packet with a BlockOffset greater than the packet length? Would the receiver skip over the specified bytes in the subsequent packet, even though padding is supposed to only be at the end of packets?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-08-25 08:19:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 00:36:36-07:00",
    "text": "Section 7.1 creates an IANA registry with \"Expert Review\" rules.\u00a0 Of such a registry, Section 4.5 of  RFC 8126  says, among other things: \u00a0  The required documentation and review criteria, giving clear guidance \u00a0  to the designated expert, should be provided when defining the \u00a0  registry. This document doesn't do so.\u00a0 Is that guidance available somewhere else, or should some be added here?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-23 15:44:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-23 15:43:16-07:00",
    "text": "I am strongly supporting Lars' DISCUSS points (actually, enough that I decided to ballot discuss too), especially that around Section 2.4.1, paragraph 3: \u00a0  The packet send \u00a0  rate is constant and is not automatically adjusted regardless of any \u00a0  network congestion (e.g., packet loss). \u00a0  For similar reasons as given in [ RFC7510 ] the non-congestion- \u00a0  controlled mode should only be used where the user has full \u00a0  administrative control over the path the tunnel will take.\u00a0 This is \u00a0  required so the user can guarantee the bandwidth and also be sure as \u00a0  to not be negatively affecting network congestion [ RFC2914 ].\u00a0 In this \u00a0  case, packet loss should be reported to the administrator (e.g., via \u00a0  syslog, YANG notification, SNMP traps, etc.) so that any failures due \u00a0  to a lack of bandwidth can be corrected. This is a largely unrealistic requirement -- unless you are specifically meaning \"a bump-in-the-wire deployment over a point to point link\" users fairly much never have control over the path that the tunnel will take. At some point the primary path **will** go down, and the tunnel will route over some backup path, most likely at 3AM on the Sunday that the CEO's daughter is getting married... It what you are describing really is \"only ever use this as a bump-in-the-wire over a PtP interface\" or \"make sure that the configured bandwidth is many many magnitudes smaller than the smallest link in the network, even when congested\", then please state that instead. As written, this text seems dangerous: you are basically handing an enterprise network admin a DoS cannon and washing your hands of the consequences.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-25 07:23:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-23 15:44:16-07:00",
    "text": "I supporting Lars' DISCUSS points, especially that around Section 2.4.1, paragraph 3: \u00a0  The packet send \u00a0  rate is constant and is not automatically adjusted regardless of any \u00a0  network congestion (e.g., packet loss). \u00a0  For similar reasons as given in [ RFC7510 ] the non-congestion- \u00a0  controlled mode should only be used where the user has full \u00a0  administrative control over the path the tunnel will take.\u00a0 This is \u00a0  required so the user can guarantee the bandwidth and also be sure as \u00a0  to not be negatively affecting network congestion [ RFC2914 ].\u00a0 In this \u00a0  case, packet loss should be reported to the administrator (e.g., via \u00a0  syslog, YANG notification, SNMP traps, etc.) so that any failures due \u00a0  to a lack of bandwidth can be corrected. This is a largely unrealistic requirement -- unless you are specifically meaning \"a bump-in-the-wire deployment over a point to point link\" users fairly much never have control over the path that the tunnel will take. At some point the primary path **will** go down, and the tunnel will route over some backup path, most likely at 3AM on the Sunday that the CEO's daughter is getting married... It what you are describing really is \"only ever use this as a bump-in-the-wire over a PtP interface\" or \"make sure that the configured bandwidth is many many magnitudes smaller than the smallest link in the network, even when congested\", then please state that instead. As written, this text seems dangerous: you are basically handing an enterprise network admin a DoS cannon and washing your hands of the consequences.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-26 12:18:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 07:23:38-07:00",
    "text": "[ Chat with Christian Hopps on the telechat -- I explained my concerns and Christian will add some text around how to deploy this safely / some background context. Even if you are the network admin and in complete control of the network, having some \"here are some things to keep in mind when deploying, like that that will ALWAYS use the configured bandwidth so make sure you will always have that free during failures and congestion and things like that...\" type warnings are helpful. ] Clearing my discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-09-08 07:59:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 06:39:41-07:00",
    "text": "Thanks for working on this specification. I found this spec to be a mix of transport and non-transport related topics and had to think a bit more due to lack of rational behind choices made. I would like to discuss - why there is no normative text (MUST/MUST NOT) for non-congestion controlled mode over operation in this specification that prohibits the use of non-congestion controlled mode out side of controlled environment?  I am also supporting Lars's discuss on 3.1 ECN support.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-12 06:32:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-22 20:16:15-07:00",
    "text": "(A simple editorial fix) Per Section 5.8.2 of [ I-D.ietf-ace-oauth-authz ], the name of the parameter in the C-to-AS communication is \u201cace_profile\u201d (not \u201cprofile\u201d).\u00a0 The \u201cace_profile\u201d parameter is mistakenly referenced as \u201cprofile\u201d in the following places: -- Section 3.2.1:  \u00a0  The response MAY contain a \"profile\" parameter with the value \u00a0  \"coap_dtls\" to indicate that this profile MUST be used for \u00a0  communication between the client and the resource server.\u00a0  -- Section 3.3.1:  \u00a0  If the \u00a0  profile parameter is present, it is set to \"coap_dtls\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-27 10:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-09 20:27:45-07:00",
    "text": "Should be a couple easy ones: Section 2.2 discusses the \"AT_MAC attribute from the EAP-Request/AKA-Reauthentication\" in the context of computing the EAP-SIM Session-Id, but there is no such EAP-Request message for EAP-SIM.\u00a0 Presumably it should be \"EAP-Request/SIM/Re-authentication\", and a similar change in Session 2.3 (which would need to cover both the AKA and SIM cases)? We need some kind of a reference for PEAP.\u00a0 (Is draft-josefsson-pppext-eap-tls-eap  tolerable?)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-05-17 22:18:49-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-16 23:09:54-07:00",
    "text": "Thank you for the work put into this document. Please find below one blocking\u00a0 DISCUSS point and one non-blocking one. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == While I am an expert neither in multicast not in VPN, I wonder why this document is only about IPv4 and not a single word is written about IPv6.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-27 18:36:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-06 12:10:47-07:00",
    "text": "The Gen-ART reviewer caught this error which seems important to fix: Figure of Section 4.2: Type = 35 (IPv4 IGP-Prefix SID) ---> Type = 35 (IPv6 IGP-Prefix SID)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-08-08 15:13:18-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 19:22:16-07:00",
    "text": "This should be very easy to clear up * Section 4.3 Since this whole draft is about clarifying Sub-TLV length calculations I think this section needs to cover the length calculation for the unnumbered Adjacency Type (Adj. Type 0 in  RFC8287 ).",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-03-19 02:42:50-07:00",
    "end_reason": "position_updated",
    "start": "2018-03-07 14:01:09-08:00",
    "text": "I was very surprised to see the following in the security considerations section and would like to work with you on improvements. \u00a0  As an informational document specifying methods that use only \u00a0  existing standards and facilities, this document has no effect on \u00a0  security. Having watched many TRILL documents go by in the last 4 years, we didn't push too hard on security in some cases as a result of the restriction to a campus network.\u00a0 This particular document extends into multi-tenancy where there are certainly security considerations introduced to be able to provide isolation properties.\u00a0 MPLS offers no security and it is being used to join TRILL campuses as described int his draft.\u00a0 This is done without any requirement of an overlay protocol to provide security - why is that the case?\u00a0 Minimally, the considerations need to be explained.\u00a0 Ideally, a solution should be offered to protect tenants when TRILL campuses are joined.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-02-27 03:39:29-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-19 02:59:48-08:00",
    "text": "I agree with Alvaro and Suresh that this document doesn't seem to be very useful as a stand alone document. However, if published it should at least state requirements clearly. There is one specific transport requirement on timing as stated in David Black's transport review (Thanks!) that must be addressed before publication but other parts could also benefit from stating requirements explicitly and clearly (also see some comment in David's review). It also not clear what these use cases and potential requirements derived from them means in terms of needed protocol work in nvo3. From me it's not clear at all if nvo3 networks are actually that much different compared to existing virtual networks such that any additional protocol work is needed.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-09-15 06:58:37-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-14 21:09:10-07:00",
    "text": "* Section 3.1.2 : I am trying to understand why a minimum TTL decrement is expected here. I think the mandated behavior is incorrect and needs to be fixed.  \u00a0  For L3 service, Tenant Systems should expect the IPv4 TTL (Time to \u00a0  Live) or IPv6 Hop Limit in the packets they send to be decremented by \u00a0  at least 1. e.g. Consider two IPv6 end systems that are connected using an L3 service. If one of them is the router and another is a host on the same network a significant part of the Neighbor Discovery functions will stop working if the hop limit is decremented (from 255 to 254).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-05-30 06:29:26-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 09:24:06-08:00",
    "text": "Document:  draft-ietf-bier-ospf-bier-extensions-12.txt I have not yet reviewed this document in detail: \u00a0  Implementations must assure that malformed TLV and Sub-TLV \u00a0  permutations do not result in errors which cause hard OSPF failures. This is not an adequate security considerations section. What is your threat model? What attacks are possible? What are not? It may be the case that this is all covered in other documents, and you just need to point to them, but the reader doesn't know that, so this needs to be documented. Adam Montville's SECDIR review which makes some of the same points and lists a few specific items to examine.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-03-12 13:44:35-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 17:33:20-08:00",
    "text": "* Section 2.2 BIER MPLS Encapsulation Sub-TLV This should be straightforward to fix but it is not clear if the label range is allowed to wrap around (overflow) or not past the 20 bit space. e.g. is a Label=2^20-X with a MSI of X or larger legal? I was hoping that  RFC8296  would have covered this but unfortunately it leaves it to this document (and the IS-IS document) to specify.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-04-12 13:25:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-12 06:35:43-07:00",
    "text": "Thank you for the work on this document. Many thanks to Tim Bray for his ART ART review:  https://mailarchive.ietf.org/arch/msg/art/SKUKjoE9bPh62XsVezoD5mPAkz4/ , and to the authors for addressing Tim's comments. I have one question for consideration (which will not require any textual changes to the document): is \"Standard Track\" the proper track of RFC for this document? I am happy to be told by the authors, working group or responsible AD that yes - this has been discussed and the consensus was that \"Standard Track\" is the most appropriate track for this document. Normally I would look for such information in the shepherd write-up, but unfortunately I can't find my answer there, nor through my superficial archive search. Note I am not questioning the need for this document, which I understand has been discussed and has consensus, barely its track - doesn't this fit better as Informational, or even BCP (although I concur with Murray, BCP does not seem appropriate)? Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2017-08-04 09:49:46-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 10:20:05-07:00",
    "text": "I'll be a Yes after you help me figure this out, so this really is a request for Discussion ... In this text, \u00a0 \u00a0  HTTP/1.1 103 Early Hints \u00a0 \u00a0  Link: ; rel=preload; as=style \u00a0 \u00a0  Link: ; rel=preload; as=script \u00a0 \u00a0  HTTP/1.1 200 OK \u00a0 \u00a0  Date: Fri, 26 May 2017 10:02:11 GMT \u00a0 \u00a0  Content-Length: 1234 \u00a0 \u00a0  Content-Type: text/html; charset=utf-8 \u00a0 \u00a0  Link: ; rel=preload; as=style \u00a0 \u00a0  Link: ; rel=preload; as=script \u00a0 \u00a0   I see that the preload Links appear in both the 103 response and the 200 response. (1) I'm not sure why that makes sense (HTTP still requires reliable transport, no?), but  (2) more Discuss-worthy is that I'm not sure where the question of whether to include the Early Hinted header fields is addressed.  Probably related, but since I can't figure out the answer to (2), I'm confused about this, also - I'm assuming that the 200 response could have additional Links that weren't included in the 103 response, but I don't see that written down anywhere.  If this is an appeal to \"be liberal in what you accept\", that's an answer (and I'd clear if it is), but I wonder if it is helpful to the implementer to make this clearer than it was to me.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Stiemerling",
    "end": "2016-02-02 12:47:57-08:00",
    "end_reason": "position_updated",
    "start": "2016-01-07 07:14:21-08:00",
    "text": "This a placeholder Discuss to wait for an issue brought up in the last minute by one of the co-authors (Nico Williams). This DISCUSS will be held until the next telechat to give time to react for the authors. The next telechat for this document is January 21st.",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2023-03-20 23:11:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-11-30 07:19:52-08:00",
    "text": "Hi There, Firstly thanks for the document.\u00a0 I have two issues I'd like to discuss and see if we can find some clarity on. The first stems from  RFC8200  Section 4.8 Third Paragraph, which reads: New hop-by-hop options are not recommended because nodes may be \u00a0  configured to ignore the Hop-by-Hop Options header, drop packets \u00a0  containing a Hop-by-Hop Options header, or assign packets containing \u00a0  a Hop-by-Hop Options header to a slow processing path.\u00a0 Designers \u00a0  considering defining new hop-by-hop options need to be aware of this \u00a0  likely behavior.\u00a0 There has to be a very clear justification why any \u00a0  new hop-by-hop option is needed before it is standardized. I believe that the document potentially needs to spell out a clearer justification to meet the requirements laid out in the above text. The second question relates to dealing with IOAM in the context of SRv6.\u00a0 With the HbH option - this is processed on a hop-by-hop basis and, as per  RFC8200 , is placed directly after the IPv6 header.\u00a0 This I don't see as a problem.\u00a0 My question comes in the case of the destination option.\u00a0 In SRv6, where a SID is, for all intents and purposes, acting like an address - I'd like to see some text dealing with what happens when the DO is applied in the context of the SRv6 where the destination address is not a normal address - but rather an IPv6 SID.\u00a0  Does the router drop the entire packet?\u00a0 Does the router \"de-encap\" as if it were a tunneled packet? Basically - I see a situation where that could lead to undefined behavior that always makes me nervous.  Could the authors, therefore, expand slightly on how the destination option is handled in the context of SRv6 and its various flavors?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-03-06 02:17:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-29 04:53:22-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Marcus Ihlar for the shepherd's detailed write-up including the WG consensus *and* the justification of the intended status.  Please note that Dave Thaler is the Internet directorate reviewer (at my request) and you may want to consider this int-dir reviews as well when Tim will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-ippm-ioam-ipv6-options/reviewrequest/16642/ I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 5.1 ``` \u00a0 \u00a0 \u00a0 Operators of an IOAM \u00a0 \u00a0 \u00a0 domain SHOULD ensure that the addition of OAM information does not \u00a0 \u00a0 \u00a0 lead to fragmentation of the packet, e.g., by configuring the MTU \u00a0 \u00a0 \u00a0 of transit routers and switches to a sufficiently high value. ``` Should it be a MUST as IPv6 routers are unable to fragment an IPv6 packet ? Should \"e.g.\" be replaced by \"i.e.\" ?  Roman's DISCUSS points are also sensible.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2023-04-08 21:51:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-11-30 22:02:50-08:00",
    "text": "# Internet AD comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @ekline * Thanks to 6MAN chairs Bob, Ole, and Jen for their last-minute \u00a0 \"IPv6 Directorate\" reviews.\u00a0 Some of their comments are reflected below. * There was kind of leaning toward concluding that the rewriting of a \u00a0 Hop-by-Hop option's size was both against the spirit of  RFC 8200  and \u00a0 not actually against the letter.\u00a0 I'm not sure that's actually the case \u00a0 and so my biggest DISCUSS is this point (more below). ## Discuss ### S4 * I don't think the Incremental Trace Option is something that can be \u00a0 supported by current text in  RFC 8200 .\u00a0 While is makes sense to have this \u00a0 behavior described in  RFC 9197 , I don't think IPv6 HbH can support it. \u00a0 My rationale for seeing this as a protocol violation is as follows. \u00a0 \u00a0 -  RFC 8200  S4.2 says this about the on-path mutability bit and the \u00a0 \u00a0 \u00a0 expectations that result: \u00a0 \u00a0 \u00a0 \"\"\" \u00a0 \u00a0 \u00a0 The third-highest-order bit of the Option Type specifies whether or \u00a0 \u00a0 \u00a0 not the Option Data of that option can change en route to the \u00a0 \u00a0 \u00a0 packet's final destination.\u00a0 When an Authentication header is present \u00a0 \u00a0 \u00a0 in the packet, for any option whose data may change en route, its \u00a0 \u00a0 \u00a0 entire Option Data field must be treated as zero-valued octets when \u00a0 \u00a0 \u00a0 computing or verifying the packet's authenticating value. \u00a0 \u00a0 \u00a0 \"\"\" \u00a0 \u00a0 - Specifically, only the Option Data (not Option Length) is allowed to \u00a0 \u00a0 \u00a0 change.\u00a0 Any AH header, for example, would still have processed the \u00a0 \u00a0 \u00a0 entire option with only the Data being zeroed -- the existence of the \u00a0 \u00a0 \u00a0 option and the length of it would still have been part of the AH \u00a0 \u00a0 \u00a0 computation. \u00a0 Unless there's some misunderstanding here I think this option would need \u00a0 removing from the document. * I think text needs to be added to make it clear that whatever options are \u00a0 used they MUST be added, though not necessarily \"filled in\", by the \u00a0 originator of the packet (the node bearing the interface assigned the \u00a0 outermost Source Address). \u00a0 The reasoning here again is the defined behavior of AH processing.\u00a0 Any \u00a0 options, even on-path mutable ones, MUST be present in the Hop-by-Hop \u00a0 option when an AH is computed.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:31:37-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:30:36-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:31:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:31:37-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:32:07-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:31:49-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ```  First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:32:35-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:32:07-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document.  ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:47:35-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:32:35-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-08 12:28:24-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:47:35-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document.  ```  First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-05-05 13:49:57-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-08 12:28:24-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-10 CC @jgscudder ## DISCUSS Thanks for taking care of my previous DISCUSS! I'm so sorry to have to raise another one, related to the new text.  \u00a0  C1\u00a0 IOAM MUST be deployed as a limited domain feature as defined in \u00a0 \u00a0 \u00a0 [ RFC8799 ]. I applaud your desire to be prescriptive and concise. Unfortunately, I think there are a few problems here. First the small ones: you have  RFC 8799  as an Informative reference, which is problematic since you want to make adherence to it mandatory. But, if you move it to be a Normative reference (as seems indicated), then we encounter two further issues: first and less importantly, it\u2019s not an IETF document, so possibly needs to be treated as a downref?  But most importantly, as far as I can tell  RFC 8799  does not define \u201ca limited domain feature\u201d. It provides a taxonomy for talking about limited domains and various considerations, but nothing I would call a \u201cdefinition\u201d. I confess I\u2019ve only briefly reviewed 8799 just now, not fully re-read it, so maybe you will be able to point me to a clear and actionable definition, that an implementor of your spec could apply in order to comply with C1. If so, please do let me know what that definition is, and also update your reference to cite it specifically, rather than just the RFC number. In my own review of 8799, the closest I see is Section 6, \"Functional Requirements of Limited Domains\u201d. I will be a little surprised if you really want to require adherence requirements 1-11 in that section, though. Sadly, I suspect that you\u2019ll end up concluding that  RFC 8799  isn\u2019t fit for the purpose you\u2019re trying to use it for and that you\u2019ll need to write out in your own words what the specific requirements are for your case. It looks to me as though the taxonomy section of  RFC 8799  might be quite useful to you in that respect, indeed that seems to be partly what it\u2019s for: ``` A.9. Making Use of This Taxonomy This taxonomy could be used to design or analyze a specific type of limited domain. ``` It\u2019s unfortunate that we don\u2019t have a good, citable definition of \u201climited domain\u201d in our document set... but we don\u2019t. This might be merely because nobody has bothered to write it yet, although I think the real reason is more likely that it turns out to be a sticky problem to nail it down to a definition that is both general enough to be broadly applicable and specific enough to be actionable.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-01 19:01:11-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-22 12:09:24-08:00",
    "text": "Section 4 and  RFC9197  seem clear that IOAM traffic cannot leave the IOAM domain.\u00a0 However, this document seems to be suggesting behavior that violates this guidance.\u00a0 Specifically, in Section 5.1, it allows for the possibility of leaks per (a) and explicitly describe a use case where leaks are intentional (b). (a) Section 5.1.\u00a0 C3. \u00a0 \u00a0 \u00a0 IOAM domains MUST \u00a0 \u00a0 \u00a0 provide a mechanism to prevent data leaks or be able to ensure \u00a0 \u00a0 \u00a0 that if a leak occurs, network elements outside the domain are not \u00a0 \u00a0 \u00a0 affected (i.e., they continue to process other valid packets). (b) Section 5.1. C5. \u00a0 \u00a0 \u00a0 An Autonomous System (AS) that inserts and leaks the IOAM data \u00a0 \u00a0 \u00a0 needs to be easy to identify for the purpose of troubleshooting,... Furthermore, per (a), why are \u201cIOAM domains \u2026 provid[ing] a mechanism\u201d which suggests a feature rather than a required to explicitly prevent this behavior.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-13 12:15:36-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 10:40:00-07:00",
    "text": "I have a couple points for discussion, essentially relating to how much we're diverging from HTTP and to what extent the specifics of the divergence should be specifically mentioned in the document. (1) I'd like to dig a little more into the analogy with HTTP and whether we are artificially limiting ourselves: currently we only allow 0 or 1 content-codings to be specified, but per https://www.ietf.org/archive/id/draft-ietf-httpbis-semantics-19.html#name-content-encoding the HTTP ecosystem permits multiple codings to be applied in turn to the same representation.\u00a0 While the sensor data values are likely to be relatively small and applying multiple content-codings is not likely to be useful in such a scenario, this seems like something where we should only consciously diverge from HTTP, rather than inadvertently doing so. (2) Let's also discuss whether we want to reuse ABNF rule names from HTTP while having the rule content diverge, without specific enumeration of the divergence.\u00a0 So far I found instances where this document does not allow HTAB or obs-text in places that  draft-ietf-httpbis-semantics does, which may well be the right way to spell the rule, but seems to merit a little discussion.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-10-21 08:23:13-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 22:02:45-07:00",
    "text": "This should be easy to resolve: The SenML Labels registry specifies a column called \"EXT ID\" (or actually just \"EI\" in  RFC 8428 ) that is absent from the registrations in Section 8.\u00a0 If that column should be empty for these new registrations, that should be explicit rather than implicit.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-08-01 00:26:22-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-30 22:29:26-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of related issues that need to be cleared up before publication, but I expect that these should be easy to resolve. \u00a73.1: >\u00a0 The client initiates the flow by requesting a set of verification >\u00a0 codes from the authorization server by making an HTTP \"POST\" request >\u00a0 to the device authorization endpoint.\u00a0 The client constructs the >\u00a0 request with the following parameters, encoded with the \"application/ >\u00a0 x-www-form-urlencoded\" content type: This document needs a normative citation for this media type. My suggestion would be to cite REC-html5-20141028 section 4.10.22.6, as this appears to be the most recent stable description of how to encode this media type. I'd love to hear rationale behind other citations being more appropriate, since I'm not entirely happy with the one I suggest above (given that it's been superseded by HTML 5.2); but every other plausible citation I can find is even less palatable (with HTML 5.2 itself having the drawback of not actually defining how to encode the media type, instead pointing to an unstable, unversioned document). (Non-discuss comment: this passage could be made clearer by saying something like \"...parameters, sent as the body of the request, encoded with the...\") --------------------------------------------------------------------------- \u00a73.2: >\u00a0 In response, the authorization server generates a device verification >\u00a0 code and an end-user code that are valid for a limited time and >\u00a0 includes them in the HTTP response body using the \"application/json\" >\u00a0 format with a 200 (OK) status code. This needs to normatively cite  RFC 7159 .",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-08-01 17:43:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-01 00:26:22-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of related issues that need to be cleared up before publication, but I expect that these should be easy to resolve. \u00a73.1: >\u00a0 The client initiates the flow by requesting a set of verification >\u00a0 codes from the authorization server by making an HTTP \"POST\" request >\u00a0 to the device authorization endpoint.\u00a0 The client constructs the >\u00a0 request with the following parameters, encoded with the \"application/ >\u00a0 x-www-form-urlencoded\" content type: This document needs a normative citation for this media type. My suggestion would be to cite REC-html5-20141028 section 4.10.22.6, as this appears to be the most recent stable description of how to encode this media type. I'd love to hear rationale behind other citations being more appropriate, since I'm not entirely happy with the one I suggest above (given that it's been superseded by HTML 5.2); but every other plausible citation I can find is even less palatable (with HTML 5.2 itself having the drawback of not actually defining how to encode the media type, instead pointing to an unstable, unversioned document). (Non-discuss comment: this passage could be made clearer by saying something like \"...parameters, sent as the body of the request, encoded with the...\") --------------------------------------------------------------------------- \u00a73.2: >\u00a0 In response, the authorization server generates a device verification >\u00a0 code and an end-user code that are valid for a limited time and >\u00a0 includes them in the HTTP response body using the \"application/json\" >\u00a0 format with a 200 (OK) status code. This needs to normatively cite  RFC 8259 .",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-08-01 17:46:04-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-01 17:43:01-07:00",
    "text": "Thanks to the authors for addressing my comments and half of my DISCUSS. This final issue appears to remain unaddressed: \u00a73.1: >\u00a0 The client initiates the flow by requesting a set of verification >\u00a0 codes from the authorization server by making an HTTP \"POST\" request >\u00a0 to the device authorization endpoint.\u00a0 The client constructs the >\u00a0 request with the following parameters, encoded with the \"application/ >\u00a0 x-www-form-urlencoded\" content type: This document needs a normative citation for this media type. My suggestion would be to cite REC-html5-20141028 section 4.10.22.6, as this appears to be the most recent stable description of how to encode this media type. I'd love to hear rationale behind other citations being more appropriate, since I'm not entirely happy with the one I suggest above (given that it's been superseded by HTML 5.2); but every other plausible citation I can find is even less palatable (with HTML 5.2 itself having the drawback of not actually defining how to encode the media type, instead pointing to an unstable, unversioned document).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-10-19 14:49:34-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-01 17:46:04-07:00",
    "text": "Thanks to the authors for addressing my comments and half of my DISCUSS. This final issue appears to remain unaddressed: \u00a73.1: >\u00a0 The client constructs the request with the following parameters, >\u00a0 encoded with the \"application/x-www-form-urlencoded\" content type: This document needs a normative citation for this media type. My suggestion would be to cite REC-html5-20141028 section 4.10.22.6, as this appears to be the most recent stable description of how to encode this media type. I'd love to hear rationale behind other citations being more appropriate, since I'm not entirely happy with the one I suggest above (given that it's been superseded by HTML 5.2); but every other plausible citation I can find is even less palatable (with HTML 5.2 itself having the drawback of not actually defining how to encode the media type, instead pointing to an unstable, unversioned document).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-03 09:19:44-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-24 06:31:45-07:00",
    "text": "Let me preface this by noting that I'm not sure that all of these points are actionable; I would, however, like to discuss them. I'm really unhappy to not see any hard numbers on the entropy needed in a user code to provide a reasonable security margin with given parameters, and how it compares to the guessability bounds considered best practices in general (across protocols).\u00a0 For example, we think 128-bit symmetric keys are okay because an attacker has to put in 2**96 work to have a 2**-32 chance of guessing correctly via brute force; the rate limiting and finite lifetime on the user code places an artificial limit on the amount of work an attacker can \"do\", so if one uses a 8-character base-20 user code (with roughly 34.5 bits of entropy), the rate-limiting interval and validity period would need to only allow 5 attempts in order to get the same 2**-32 probability of success by random guessing. Section 5.1 would be a great place for such text, near the preexisting: \u00a0  The user code SHOULD have enough entropy that when combined with rate \u00a0  limiting and other mitigations makes a brute-force attack infeasible. We talk about \"the authorization server\", but any given *user* may have a relationship with multiple such ASes.\u00a0 Can the Introduction make it more clear that the AS is associated with the device/client, and as such the it may not be the user's most-trusted AS? It also seems like a large latent risk with this flow is when the verification_uri_complete response is used along with an AS that assumes an authenticated user making such a verification request has approved the authorization (i.e., without an explicit user interaction to confirm), when that AS uses cookies or other persistent state to keep the user authenticated across multiple requests.\u00a0 I could not find any MUST-level requirement for user interaction to confirm the device being authorized (even in Section 3.3, which covers the regular verificat_uri workflow!); please let me know if I missed something.\u00a0 I would like to see some explicit text that (matching the flow described in Section 3.1 that requires the user to input the code) explicit user approval of the authorization is required.\u00a0 (I do note that Section 5.3 has text about \"SHOULD display information about the device.) I'm also unhappy about the text in Section 1 that merely requires of the device the ability to \"make outbound HTTPS requests\", which leaves room for an awful lot of sins in certificate validation (and, potentially, ciphersuite selection).\u00a0 Can we get a MUST-level requirement for authenticating the server and a cite to  RFC 7525 ?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-27 16:10:55-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-03 09:19:44-07:00",
    "text": "[Updating to remove Discuss point addressed in the -12; no change to the ballot position text otherwise, even when non-Discuss comments are addressed] Let me preface this by noting that I'm not sure that all of these points are actionable; I would, however, like to discuss them. I'm really unhappy to not see any hard numbers on the entropy needed in a user code to provide a reasonable security margin with given parameters, and how it compares to the guessability bounds considered best practices in general (across protocols).\u00a0 For example, we think 128-bit symmetric keys are okay because an attacker has to put in 2**96 work to have a 2**-32 chance of guessing correctly via brute force; the rate limiting and finite lifetime on the user code places an artificial limit on the amount of work an attacker can \"do\", so if one uses a 8-character base-20 user code (with roughly 34.5 bits of entropy), the rate-limiting interval and validity period would need to only allow 5 attempts in order to get the same 2**-32 probability of success by random guessing. Section 5.1 would be a great place for such text, near the preexisting: \u00a0  The user code SHOULD have enough entropy that when combined with rate \u00a0  limiting and other mitigations makes a brute-force attack infeasible. We talk about \"the authorization server\", but any given *user* may have a relationship with multiple such ASes.\u00a0 Can the Introduction make it more clear that the AS is associated with the device/client, and as such the it may not be the user's most-trusted AS? It also seems like a large latent risk with this flow is when the verification_uri_complete response is used along with an AS that assumes an authenticated user making such a verification request has approved the authorization (i.e., without an explicit user interaction to confirm), when that AS uses cookies or other persistent state to keep the user authenticated across multiple requests.\u00a0 I could not find any MUST-level requirement for user interaction to confirm the device being authorized (even in Section 3.3, which covers the regular verificat_uri workflow!); please let me know if I missed something.\u00a0 I would like to see some explicit text that (matching the flow described in Section 3.1 that requires the user to input the code) explicit user approval of the authorization is required.\u00a0 (I do note that Section 5.3 has text about \"SHOULD display information about the device.)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-10-18 03:32:35-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-24 11:50:50-07:00",
    "text": "Please specify more clearly the (default) polling behavior to ensure that the polling does neither overload the network, nor the server, or is never terminated. Ideally provide default values and an upper bound for the polling frequency, as well as a timer to terminate polling if no reply is received (and no expiration time is given). See further details below. 1) Sec 3.3: \"until the user completes the interaction, the code expires, or another \u00a0  error occurs.\" What if not expiration time is given (as this optional) and no reply is ever received? 2) Sec 3.5: \"the client should stop polling and react accordingly, for \u00a0  example, by displaying an error to the user.\" Maybe: \"the client MUST stop polling and SHOULD react accordingly, for \u00a0  example, by displaying an error to the user.\" 3) sec 3.5 \"If no interval was provided, the client \u00a0  MUST use a reasonable default polling interval.\" Can you please provide a default number for a \"reasonable\" polling interval! And in best case an upper bound! 4) sec 3.5: \"...increasing the time between polls if a \u00a0  \"slow_down\" error is received. \" Maybe use a separate normative sentence instead: \"The client SHOUD increase the time between polls if a \u00a0  \"slow_down\" error is received.\" Or MUST? If so how much? Can you given further (default) guidance. 5) sec 3.5: \"Clients MAY then choose to \u00a0  start a new device authorization session.\" Maybe make it clear that polling is stopped \"Clients MUST stop polling but MAY then choose to \u00a0  start a new device authorization session.\" 6) sec 3.5: \"then the \u00a0  device MAY wait until notified on that channel that the user has \u00a0  completed the action before initiating the token request.\" Why not SHOULD (or MUST) here?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-08-29 09:49:57-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 13:13:22-07:00",
    "text": "Thanks for your work on this draft.\u00a0 I had the same concern as the SecDir reviewer in reading the draft, the concern about leaking traffic as a result of multiple tunnels is not addressed in the security considerations section.\u00a0 Hilary's writeup is quite helpful https://www.ietf.org/mail-archive/web/secdir/current/msg07446.html",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-05 04:47:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-31 14:48:58-07:00",
    "text": "1) This document should not recommend the use of MPTCP for tunneling, as TCP-in-TCP tunnels are generally not recommend if that can be avoided. Please remove the following part from section 3.2 and leave IP-level tunneling as the only option: \u2028\u201ePacket distribution can be done either at the transport level, e.g. using MPTCP \u2026\u201c  2) Further the following sentences also in section 3.2 should be revised:\u2028 \u201eFor example, high throughput services (e.g. \u00a0  video streaming) may benefit from per-packet distribution scheme, \u00a0  while latency sensitive applications (e.g.\u00a0 VoIP) are not be spread \u00a0  over different WAN paths.\u201c\u2028\u00a0   High throughput services only benefit from per-packet scheduling if the service requires higher throughput than one of the links can provide. Also video streaming may not be a good example here because high latency variations can lead to stalls. Therefore in general per-flow scheduling should be recommend for all traffic.  It could still be beneficial to schedule flows that require low latency over the link with the lower base latency, or maybe more important lower jitter, however, often it is not known to the network what the requirements on latency are for a given flow. Therefore is should probably be recommended to schedule all traffic on the \"better\" link (where better can be pre-configured knowledge or measured) as long as the bandwidth of the incoming traffic is smaller than the bandwidth of the that link, and only use a second link (with per-flow scheduling) if the capacity is required. 3) This document does not really normative specify the use of the newly defined options. It only gives an examples but it does not specify normatively any actions that need to performed on receipt of these options. How does the MAG know if the LMA does not support Multipath binding? An LMA that does not implement this spec will not send back an error message. Why are there two different options? What happens if one of the options is present in the Proxy Binding Update but not the other?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-08-16 18:52:36-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 13:23:05-07:00",
    "text": "Section 3.2.\u00a0 Traffic distribution schemes \"Per-packet management: the LMA and the MAG distribute packets, belonging to a same IP flow, over more than one bindings (i.e. more than one WAN interface).\" This immediately made my out-of-order-packets antenna pop up, so I read the section looking for mitigations. The very next sentence reads: \"Packet distribution can be done either at the transport level, e.g. using MPTCP or at When operating at the IP packet level, different packets distribution algorithms are possible. \" -- the fact that this sentence is a: malformed and b: hand-wavy did nothing to allay my concerns, so I read further: \"The distribution algorithm is left to implementer but whatever the algorithm is, packets distribution likely introduces packet latency and out-of-order delivery.\u00a0 LMA and MAG shall thus be able to make reordering before packets delivery.\" - I agree with the first sentence (although it is poorly worded), but the second sentence doesn't follow from the first; \"shall thus be able to\" implies that the prior text somehow provides a solution, not points out a problem (the sentence is also malformed)-- I think you mean something like \"The LMA and MAG thus need to be able reorder packets to their original order before delivery.\" This then continues with \"Sequence number can be can be used for that purpose, for example using GRE with sequence number option [ RFC5845 ].\" - I think that the actual reference should be  RFC2890 , but regardless of this, I don't think that what you are proposing works - \"The Sequence Number field is used to maintain sequence of packets **within** the GRE Tunnel.\" (from  RFC2890 , emphasis added). This means that sequence numbers are local to the tunnel, and (as I understand it) your solution involves diverse tunnels. Further, Section 2.2. Sequence Number says: \"The receiver may perform a small amount of buffering in an attempt to recover the original sequence of transmitted packets. In this case, the packet may be placed in a buffer sorted by sequence number.\" - if you are proposing using a single sequence number space for multiple tunnels, you will end up with sequence number space gabs, and lots of buffering, etc.  The section ends with: \"However, more detailed considerations on reordering\u00a0 and IP packet distribution scheme (e.g. definition of packets distribution algorithm) are out the scope of this document.\" - I think that, unless the prior paragraph is significantly reworked, it should not try and suggest any mitigations. The whole idea of striping packets of a flow across (notably) different transports seems like a really bad idea to me -- is it actually needed?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-05-09 08:54:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 22:00:28-07:00",
    "text": "Thanks for all the work everyone put into this document. I think it's great to have a solution defined for automating these kinds of operations, and look forward to widespread deployment of this technology. I do have a small number of comments that I think we need to close on prior to publication, and a handful of other suggestions of varying (but lesser) importance. --------------------------------------------------------------------------- This is a discuss because the current document attempts to override normative language in an external document. \u00a74.3: >\u00a0 In reference to Figure 4, the DOTS client sends two TCP SYNs and two >\u00a0 DTLS ClientHello messages at the same time over IPv6 and IPv4. This is problematic for the reason described in  RFC 8305  \u00a75 (\"In order to avoid unreasonable network load, connection attempts SHOULD NOT be made simultaneously\"). To be clear, my discuss is only on the fact that this document violates a normative statement in  RFC 8305 . The following comments are merely my thoughts on the best way to resolve this issue. It's also worth noting that  RFC 8305  is geared towards getting users the fastest possible response to a user action, while the text in DOTS implies that the selection of the \"most preferred\" connection is significantly more important (e.g., it talks about migrating from TCP to UDP, and performing periodic checks to enable such a migration). This factor, combined with the fact that this is not a transaction that involves user interactivity requirements, would seem to increase, rather than decrease, the desire to space out checks across the various transport/address-family pairs. My strong recommendation would be remove the specific description of happy-eyeballs-like behavior from this document, and to instead defer all such specification to the text in  RFC 8305 . I would further recommend specification of a \"Connection Attempt Delay\" (as that term is defined in  RFC 8305 ) that is substantially larger than those used for interactive connections: something on the order of 2 to 5 seconds would be my suggestion. Of course, be sure to adjust the example to match the specified handling. --------------------------------------------------------------------------- This is a discuss because it impacts interoperability. \u00a74.4.1: >\u00a0 target-uri:\u00a0  A list of Uniform Resource Identifiers (URIs) [ RFC3986 ] >\u00a0 \u00a0  identifying resources under attack. This definition needs to be clearer about what parts of the URI are used for what purposes. For example:  - The URI scheme can be taken to specify a 'target-protocol'  - The URI host can be taken to specify a 'target-fqdn' or 'target-prefix'  - The URI port (or scheme, if absent) can be taken to specify a \u00a0  'target-port-range' It is unclear whether this specification intends the URI to impact one, two, or all three of these. This can result in a client asking for one thing and the server doing something else. --------------------------------------------------------------------------- This is a discuss because it impacts interoperability. \u00a76: The handling of 64-bit values in Table 4 seems problematic. Section 3 specifies: >\u00a0 Representing these data >\u00a0 as CBOR data can either follow the rules in [ I-D.ietf-core-yang-cbor ] >\u00a0 or those in [ RFC7951 ] combined with JSON/CBOR conversion rules in >\u00a0 [ RFC7049 ]; both approaches produce a valid encoding. However, if we consider, say, mitigation-start: >\u00a0 +----------------------+-------------+-----+---------------+--------+ >\u00a0 | Parameter Name\u00a0 \u00a0 \u00a0  | YANG\u00a0 \u00a0 \u00a0 \u00a0 | CBOR| CBOR Major\u00a0 \u00a0 | JSON\u00a0  | >\u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Type\u00a0 \u00a0 \u00a0 \u00a0 | Key |\u00a0 \u00a0 Type &\u00a0 \u00a0  | Type\u00a0  | >\u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0  | Information\u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 | >\u00a0 +----------------------+-------------+-----+---------------+--------+ > ... >\u00a0 | mitigation-start\u00a0 \u00a0  | uint64\u00a0 \u00a0 \u00a0 |\u00a0 15 | 0 unsigned\u00a0 \u00a0 | String | If an implementation follows the first path ( draft-ietf-core-yang-cbor ), then this value is sent on the wire as a CBOR 64-bit unsigned integer type. If an implementation instead uses  RFC 7951  followed by  RFC 7049  \u00a74, the resulting value is encoded on the wire as a CBOR string. If this is the intention, then it represents a huge gotcha for implementors of both clients and of servers, as all implementations must be ready to accept both strings and 64-bit data types for these fields. If this is the intention, please add strongly-worded text warning implementors of this particular gotcha, since it's pretty non-obvious. It's worth noting that, while some implementations may set limits on the precision of JSON Numbers, and that such limits may be smaller than 64 bits, nothing in the format defined by  RFC 8259  has any such inherent limitations. There is a similar (but subtly different) problem with the handling of enumerations that may cause them to be encoded as either strings or as integers: >\u00a0 | status\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | enumeration |\u00a0 16 | 0 unsigned\u00a0 \u00a0 | String | If you choose to maintain the situation currently described in the document, then the table in section 9.6.1.2 needs to be updated to allow both formats; e.g.: >\u00a0 +----------------------+-------+-------+------------+---------------+ >\u00a0 | Parameter Name\u00a0 \u00a0 \u00a0  | CBOR\u00a0 | CBOR\u00a0 | Change\u00a0 \u00a0  | Specification | >\u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Key\u00a0  | Major | Controller | Document(s)\u00a0  | >\u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Value | Type\u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | >\u00a0 +----------------------+-------+-------+------------+---------------+ ... >\u00a0 | mitigation-start\u00a0 \u00a0  |\u00a0  15\u00a0 | 0 or 3|\u00a0 \u00a0 IESG\u00a0 \u00a0 |\u00a0  [RFCXXXX]\u00a0  |",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-02 05:06:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-01 07:32:28-07:00",
    "text": "Thank you for a well written document. Despite its length, it was a pleasure to read. I have a list of small issues/questions to discuss before I can recommend approval of this document. 1)  RFC 3986  must be Normative as you use URI syntax in the document. 2) In 4.4.1: base64url needs a Normative reference. Please point to section 5 of  RFC 4648 . 3) Also in the same section: \u00a0  A DOTS gateway MAY add the CoAP Hop-Limit Option \u00a0  [ I-D.ietf-core-hop-limit ]. Use of  RFC 2119  language makes this reference Normative. Which means that this document can't be published as an RFC until [ I-D.ietf-core-hop-limit ] is published as an RFC. 4) Later in the same section: \u00a0  If the request is missing a mandatory attribute, does not include \u00a0  'cuid' or 'mid' Uri-Path options, includes multiple 'scope' \u00a0  parameters, or contains invalid or unknown parameters, the DOTS \u00a0  server MUST reply with 4.00 (Bad Request).\u00a0 DOTS agents can safely \u00a0  ignore comprehension-optional parameters they don't understand. How can DOTS agents know which parameters are comprehension-optional? 5) In 4.4.2: \u00a0  The 'c' (content) parameter and its permitted values defined in \u00a0  [ I-D.ietf-core-comi ] can be used to retrieve non-configuration data Because you define syntax of the parameter by reference, this makes [ I-D.ietf-core-comi ] Normative. (It doesn't matter that the feature is optional. Implementors still need to look at [ I-D.ietf-core-comi ] to implement this aspect of your document.) If you don't want Normative dependency, you should fully specify syntax in your draft and keep the reference Informative. \u00a0  (attack mitigation status), configuration data, or both.\u00a0 The DOTS \u00a0  server MAY support this optional filtering capability.\u00a0 It can safely \u00a0  ignore it if not supported.\u00a0 If the DOTS client supports the optional \u00a0  filtering capability, it SHOULD use \"c=n\" query (to get back only the \u00a0  dynamically changing data) or \"c=c\" query (to get back the static \u00a0  configuration values) when the DDoS attack is active to limit the \u00a0  size of the response. 6) In 4.4.3: \u00a0 \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0  \"ietf-dots-signal-channel:mitigation-scope\": { \u00a0 \u00a0 \u00a0 \u00a0  \"scope\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"target-prefix\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"2001:db8:6401::1/128\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"2001:db8:6401::2/128\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ], \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"target-port-range\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"lower-port\": 80 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  }, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"lower-port\": 443 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  }, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"lower-port\": 8080 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ], \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"target-protocol\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 6 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ], \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"attack-status\": \"under-attack\" This value is invalid, as you define this attribute as numeric on the next page. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 } 7) In 7.1: \u00a0  When a DOTS client is configured with a domain name of the DOTS \u00a0  server, and connects to its configured DOTS server, the server may \u00a0  present it with a PKIX certificate.\u00a0 In order to ensure proper \u00a0  authentication, a DOTS client MUST verify the entire certification \u00a0  path per [ RFC5280 ].\u00a0 The DOTS client additionally uses [ RFC6125 ] \u00a0  validation techniques to compare the domain name with the certificate \u00a0  provided. I am glad that you are referencing  RFC 6125  here, but the description is not complete. Do you allow for wildcards in certificate subjectAltNames? Do you support CN-ID, DNS-ID, SRV-ID, URI-ID? I think you only want to support DNS-ID and possibly SRV-ID and CN-ID. This needs to be explicitly stated in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-18 03:24:04-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-02 05:06:03-07:00",
    "text": "Thank you for a well written document. Despite its length, it was a pleasure to read. I have a list of small issues/questions to discuss before I can recommend approval of this document. Based on\u00a0 I've updated my DISCUSS/comments: 1)-6) resolved 7) In 7.1: \u00a0  When a DOTS client is configured with a domain name of the DOTS \u00a0  server, and connects to its configured DOTS server, the server may \u00a0  present it with a PKIX certificate.\u00a0 In order to ensure proper \u00a0  authentication, a DOTS client MUST verify the entire certification \u00a0  path per [ RFC5280 ].\u00a0 The DOTS client additionally uses [ RFC6125 ] \u00a0  validation techniques to compare the domain name with the certificate \u00a0  provided. I am glad that you are referencing  RFC 6125  here, but the description is not complete. Do you allow for wildcards in certificate subjectAltNames? Do you support CN-ID, DNS-ID, SRV-ID, URI-ID? I think you only want to support DNS-ID and possibly SRV-ID and CN-ID. This needs to be explicitly stated in the document. 8) In Section 3: \u00a0  This document specifies a YANG module for representing DOTS \u00a0  mitigation scopes, DOTS signal channel session configuration data, \u00a0  and DOTS redirected signalling (Section 5).\u00a0 Representing these data \u00a0  as CBOR data can either follow the rules in [ I-D.ietf-core-yang-cbor ] \u00a0  or those in [ RFC7951 ] combined with JSON/CBOR conversion rules in \u00a0  [ RFC7049 ]; both approaches produce a valid encoding. This reads like there are 2 possible encodings, both of which are mandatory to implement. Firstly, I don't think that having 2 encodings is a good idea, but if the WG really needs this, I will remove this part of my DISCUSS. Secondly, this means that [ I-D.ietf-core-yang-cbor ] must be Normative.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-18 03:24:17-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-18 03:24:04-07:00",
    "text": "hank you for addressing my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-05-10 09:54:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 18:55:30-07:00",
    "text": "= Section 3 = \"By default, a DOTS signal channel MUST run over port number TBD as \u00a0  defined in Section 9.1, for both UDP and TCP, unless the DOTS server \u00a0  has a mutual agreement with its DOTS clients to use a different port \u00a0  number.\u00a0 DOTS clients MAY alternatively support means to dynamically \u00a0  discover the ports used by their DOTS servers (e.g., \u00a0  [ I-D.boucadair-dots-server-discovery ]).\" MUST implies an absolute requirement, so \"MUST ... unless\" is a problematic construction. Furthermore, it doesn't make sense together with \"MAY alternatively,\" which indicates that port number discovery is an alternative to the fixed to-be-assigned port.  I didn't have time to get very far into  draft-boucadair-dots-server-discovery , but it appears that it does not mandate support for any single discovery mechanism for clients and servers to support. If so, that \"alternatively\" seems like more of a problem, since it allows for there to be no interoperable mechanism for clients to discover server ports. I think maybe what was intended here was: s/MUST/SHOULD/ s/MAY alternatively/MAY additionally/ = Section 4.4.1 = (1) \"In deployments where server-domain DOTS gateways are enabled, \u00a0  identity information about the origin source client domain SHOULD be \u00a0  propagated to the DOTS server.\u00a0 That information is meant to assist \u00a0  the DOTS server to enforce some policies such as grouping DOTS \u00a0  clients that belong to the same DOTS domain, limiting the number of \u00a0  DOTS requests, and identifying the mitigation scope.\u00a0 These policies \u00a0  can be enforced per-client, per-client domain, or both.\u00a0 Also, the \u00a0  identity information may be used for auditing and debugging purposes.\" Does \"identity information\" just refer to cdid, or something else? (2) The constructions \"MUST ... (absent explicit policy/configuration otherwise)\" are problematic. I'm assuming these are meant to be SHOULDs. = Section 13.1 = I don't understand why  RFC 7951  is a normative reference but  draft-ietf-core-yang-cbor  is an informative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-05-01 07:42:22-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-30 09:27:28-07:00",
    "text": "1) Port usage (see section 3): The port request for DOTS was reviewed by the port expert team. Some members of the team where concerned about the assignment of a separate port number for DOTS as Coap is used and already has a designated port number. I believe that Coap is used as a transport in the case and DOTS provides a separate service compared to what Coap is usually used for, however, it is not clear why DOTS needs a designated port. Section 3 says that the port can either be preconfigured or dynamically detected, therefore it is not clear why a fixed port in needed (see also section 7.1. of  RFC7605 ). In the port review process the authored argued that a port is needed to differentiate the DOTS service in the network. However, this is not an endorsed usage for port numbers (see section 6.2. of  RFC7605 ). Further, I believe assigning a fixed port might actually add an attack vector for DOTS, either by DDoSing the respective port at the DOTS server, or any attempt to block DOTS traffic on the network from the DOTS client to the DOTS server. 2) Section 4.3 says: \"In reference to Figure 4, the DOTS client sends two TCP SYNs and two \u00a0  DTLS ClientHello messages at the same time over IPv6 and IPv4.\" However,  RFC8305  explicitly states that connection attempts SHOULD NOT be made simultaneously (see sec 5). Further Figure 4 shows a different order of request as recommended in the text (text says: \"UDP over IPv6, UDP over IPv4, TCP over IPv6, and finally TCP over IPv4\"). Also why are the UDP connection attempts repeated? I guess that is meant to be the retransmission of the DTLS Hello? However, usually you should receive the TCP SYNACK before you retransmit or in the best case even before you start the next connection attempt. Therefore that should be not displayed like this in the figure or needs further explanation. 3) Why are these statements SHOULDs and not MUSTs (see section 4.4)? \u00a0 \"DOTS agents SHOULD follow the data transmission guidelines discussed \u00a0  in Section 3.1.3 of [ RFC8085 ] and control transmission behavior by \u00a0  not sending more than one UDP datagram per round-trip time (RTT) to \u00a0  the peer DOTS agent on average.\" and \u00a0 \"If the DOTS client cannot maintain an RTT estimate, it \u00a0  SHOULD NOT send more than one Non-confirmable request every 3 \u00a0  seconds\" However, all communication pattern used by DOTS rely on a request/reply pattern and Coap specifies for this case that only one request can be outstanding at a time with an exponential backoff pattern for retransmission (see section 4.7 and 4.2 of  RFC7252 ) which therefore will be used in this case.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-20 08:57:45-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 07:42:22-07:00",
    "text": "1) Port usage (see section 3): The port request for DOTS was reviewed by the port expert team. Some members of the team were concerned about the assignment of a separate port number for DOTS as Coap is used and already has a designated port number. I believe that Coap is used as a transport in the case and DOTS provides a separate service compared to what Coap is usually used for, however, it is not clear why DOTS needs a designated port. Section 3 says that the port can either be preconfigured or dynamically detected, therefore it is not clear why a fixed port is needed (see also section 7.1. of  RFC7605 ). In the port review process the authored argued that a port is needed to differentiate the DOTS service in the network. However, this is not an endorsed usage for port numbers (see section 6.2. of  RFC7605 ). Further, I believe assigning a fixed port might actually add an attack vector for DOTS, either by DDoSing the respective port at the DOTS server, or any attempt to block DOTS traffic on the network from the DOTS client to the DOTS server. 2) Section 4.3 says: \"In reference to Figure 4, the DOTS client sends two TCP SYNs and two \u00a0  DTLS ClientHello messages at the same time over IPv6 and IPv4.\" However,  RFC8305  explicitly states that connection attempts SHOULD NOT be made simultaneously (see sec 5). Further Figure 4 shows a different order of request as recommended in the text (text says: \"UDP over IPv6, UDP over IPv4, TCP over IPv6, and finally TCP over IPv4\"). Also why are the UDP connection attempts repeated? I guess that is meant to be the retransmission of the DTLS Hello? However, usually you should receive the TCP SYNACK before you retransmit or in the best case even before you start the next connection attempt. Therefore that should be not displayed like this in the figure or needs further explanation. 3) Why are these statements SHOULDs and not MUSTs (see section 4.4)? \u00a0 \"DOTS agents SHOULD follow the data transmission guidelines discussed \u00a0  in Section 3.1.3 of [ RFC8085 ] and control transmission behavior by \u00a0  not sending more than one UDP datagram per round-trip time (RTT) to \u00a0  the peer DOTS agent on average.\" and \u00a0 \"If the DOTS client cannot maintain an RTT estimate, it \u00a0  SHOULD NOT send more than one Non-confirmable request every 3 \u00a0  seconds\" as well as in section 4.4.2.1: \u00a0 \"If the DOTS server cannot maintain an RTT \u00a0  estimate, it SHOULD NOT send more than one asynchronous notification \u00a0  every 3 seconds\" and again in section 4.4.2.2:  \"The frequency of polling the DOTS server to get the \u00a0  mitigation status SHOULD follow the transmission guidelines in \u00a0  Section 3.1.3 of [ RFC8085 ]. However, most of the communication pattern used by DOTS rely on a request/reply pattern and Coap specifies for this case that only one request can be outstanding at a time (until the reply is received or message is assumed to be lost) (see section 4.7 and 4.2 of  RFC7252 ) which therefore will be used in this case. Only migration updates are send without reply, and here a MUST would be more appropriate. Please also note that if there can only be one request outstanding (before a reply is received) it is also not possible that requests are received out of order (see e.g. 4.4.3: \"If UDP is used as transport, CoAP requests may arrive out-of-order.\"). 4)  draft-ietf-core-hop-limit  is used in section 10: \"The presence of DOTS gateways may lead to infinite forwarding loops, \u00a0  which is undesirable.\u00a0 To prevent and detect such loops, this \u00a0  document uses the Hop-Limit Option.\" This sounds like it should be required (and normative language should be used) and therefore  draft-ietf-core-hop-limit  should also be a normative reference.  Also  draft-ietf-core-comi  should probably another normative reference. 5)Section 4.5.2: You give recommendations for min and max in a note, however, these values should be specified normatively and in best with a MUST. 6) Section 4.7: \"the DOTS \u00a0  agent sends a heartbeat over the signal channel to maintain its half \u00a0  of the channel.\u00a0 The DOTS agent similarly expects a heartbeat from \u00a0  its peer DOTS agent\" and  \"DOTS servers MAY trigger their heartbeat requests immediately after \u00a0  receiving heartbeat probes from peer DOTS clients.\" Actually heartbeat should only be send in one direction (as the other end will send an ack) and the protocol should clearly specify which endpoint is responsible for triggering the ping. 7) sec 7.3:\"To avoid DOTS signal message fragmentation and the subsequent \u00a0  decreased probability of message delivery, DOTS agents MUST ensure \u00a0  that the DTLS record MUST fit within a single datagram.\" This should be handled by the DTLS record layer and not by DOTS that works on top of DTLS (actually Coap), therefor it seems straight to have a normative requirement here in the DOTS spec. Also note that the calculation provided is not valid for early data (0-RTT) as the hello messages could be transmitted in the same datagram. 8) Also sec 7.3: \"If the path \u00a0  MTU is not known to the DOTS server, an IP MTU of 1280 bytes SHOULD \u00a0  be assumed.\" \u00a0 Actually this is only true for IPv6. The later note mentions that the situation is different from IPV4, however, it should probably be made clear from the beginning that 1280 can only be assumed for IPv6. 9) sec 9.6: What's the registration policy for the newly created registries? 10) The document should more explicitly provide more guidance about when a client should start a session and what should be done (from the client side) if a session is detected as inactive (other than during migration which is discussed a bit in 4.7). Is the assumption to have basically permanently an active session or connect for migration and configuration requests separately at a time?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-05-21 20:37:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-30 20:06:51-07:00",
    "text": "This should be easy to clear up, but I would like to understand why this document needs to restate the motivation and describe the algorithm for happy eyeballs instead of simply stating that hosts should use  RFC8305  and then specify that UDP must be tried before TCP in each of the address families. If you do want to specify the whole algorithm here it needs to be more specific than \"in a manner similar to the Happy Eyeballs mechanism\" as it is not clear where it is similar (and where it will differ). It also looks like the example flow in Figure 4 is not consistent with the description before (TCP+IPv6 before UDP+IPv4)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-01-15 03:18:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-14 12:51:44-08:00",
    "text": "per media type suffix needs to be registered in ",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-01-16 06:16:40-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-15 03:18:17-08:00",
    "text": "This is a well written document. I have only a couple of minor issues I would like to discuss before recommending approval: 1) +per media type suffix needs to be registered in  2) In 9.1.1.2: should \"details\" element allow for language tag XML attribute? Should this element be allowed to appear multiple times with different language tags in order to allow for multiple human readable reasons (in different languages)?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-02-15 18:10:20-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-19 05:58:12-08:00",
    "text": "olding a DISCUSS pending expert reviews for media-type-structured-suffix, emergency-call-additional-data, and 'test' Sub-Services subregistry of URN Service Labels.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-09 20:22:07-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 09:27:48-07:00",
    "text": "There are both pretty minor points, in the grand scheme of things, but I do think it would be hazardous to publish the document without addressing them. The semantics surrounding the \"external_id_hash\" TLS extension seem insufficiently specified to admit interoperable implementation.\u00a0 In Section 3.2 we read that it \"carries a hash of the identity assertion that communicating peers have exchanged\", as if there was a single distinguished identity assertion for the session.\u00a0 But, if we read on, we learn that there is not one identity assertion, but (in the general case) two, one for each party, and that what seems to actually be intended is that each party sends the hash of the identity assertion corresponding to the sender's identity, with the requirements to send an empty external_id_hash if the party in question is not providing identity bindings.\u00a0 Additionally, the text about having an empty \"external_id_hash\" extension in ClientHello or ServerHello/EncryptedExtensions is written in a way that implies that all parties generate a ClientHello and all parties generate a ServerHello or EncryptedExtensions message, whereas these are actually conditional on whether the party is acting as (D)TLS client or server. Similarly, the current text for the last sentence of Section 3.2 (\"In TLS 1.3, the \"external_id_hash\" extension MUST be sent in the EncryptedExtensions message.\") can be (mis)read as implying that all EncryptedExtensions messages sent by TLS servers that implement this specification must include this extension, which would violate the TLS extension-negotiation model since it mandates the server sending an extension without regard to the client having indicated support for the extension.\u00a0 Perhaps \"MUST NOT be sent in the TLS 1.3 ServerHello message\" conveys the restriction more clearly? (A similar comment applies to the corresponding statement in Section 4.3, which interestingly enough already has a \"In TLS 1.3, the \"external_session_id\" extension MUST NOT be included in a ServerHello.\" disclaimer in addition to the problematic sentence.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-12 16:01:02-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 19:24:16-07:00",
    "text": "(1) Section 3.2.\u00a0 There are a few places where further clarity on error handling would be helpful:  -- Per \u201cA peer that receives an \"external_id_hash\" extension that does not match the value of the identity binding from its peer MUST immediately fail the TLS handshake with an error\u201d, which TLS error alert? -- Per \u201cA peer that receives an identity binding, but does not receive an \u2018external_id_hash\u2019extension MAY choose to fail the connection\u201d, if it does \u201cfail the connection\u201d, with which error alert?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-20 14:03:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-14 16:07:30-08:00",
    "text": "Roman's comment touched on a related point, but I'd like to (hopefully briefly) discuss the way we encode certain opaque protocol fields. There are some places where we clearly intend a hex representation (a string with a pattern that's marked out as pairs of hex digits), but there are others where we just say \"type string\" with no indication of encoding, and even a \"type binary\".\u00a0 If we want the specification to admit interoperable implementation we need to be more clear about what encoding we expect for all of these nodes.\u00a0 I have noted most (possibly all, but please double check) in the COMMENT section, with a preference for \"type binary\" where we don't need to apply regex restrictions.\u00a0 But that's just a personal preference, and choosing to use hex (or base64, or any other well-defined) encoding will suffice to resolve the discuss point.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-12-15 07:55:43-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-14 22:57:26-08:00",
    "text": "This should be easy to resolve, but we have to ask as it's pretty important: Question 7 of the shepherd writeup, about the authors and  BCP 78 /79, appears not to have been answered.\u00a0 Were these declarations made?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-07-06 07:25:19-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-02 03:49:27-07:00",
    "text": "I don't believe IANA Considerations section is correct: it points to a document that gets obsoleted by this one, yet the original document creates new subregistries. This makes the status of earlier established registries unclear. I think you should copy the original IANA registration section in its entirety and clearly mark new allocations in it.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2015-04-20 12:50:42-07:00",
    "end_reason": "position_updated",
    "start": "2015-02-04 15:52:55-08:00",
    "text": "I have one point to discuss that should be easy to resolve. = Section 6 = A bunch of places in this section reference the Create and Modify operations, neither of which are defined in Section 7. I think these are both meant to be Add operations? Or if not, a Modify operation needs to be defined and made distinct from Add.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-03-24 11:32:23-07:00",
    "end_reason": "position_updated",
    "start": "2015-02-18 14:05:10-08:00",
    "text": "-- Section 2 -- \u00a0  This document reuses terms from [ RFC3261 ], [ RFC5486 ], use cases and \u00a0  requirements documented in [ RFC6461 ] and the ENUM Validation \u00a0  Architecture [ RFC4725 ]. These are all listed as informative references.\u00a0 If you use terminology defined elsewhere, those references (3261 and 5486) need to be normative (they're required in order to understand the terms used in this doument). -- Section 4.11 -- \u00a0  At the time of this writing, a choice of transport protocol has been \u00a0  provided in SPP Protocol over SOAP document. This would be a good place for a reference to that draft.\u00a0 I think the reference is important, as you've made it MTI; I think it's a normative one.\u00a0 I don't think \"At the time of this writing\" is necessary, though if you really like it I don't object.\u00a0 It's also missing a \"the\" and some quotes, as thus: NEW \u00a0  One choice of transport protocol has been provided in the document \u00a0  \"SPP Protocol over SOAP\" [reference]. END -- Section 11.2 -- Why does the policy need to be RFC Required?\u00a0 Why not Expert Review?\u00a0 For that matter, why not FCFS?\u00a0 You can either point me at mailing list archives where this was discussed, or explain the necessity in response to this comment. While we're talking about OrgIdType, I don't think the document makes it clear what this is, and why new ones would be registered in the first place.\u00a0 Why would we ever need an OrgIdType Namespace other than \"iana-en\"?\u00a0 Shouldn't the document say something about that?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-02-05 05:58:26-08:00",
    "end_reason": "position_updated",
    "start": "2015-02-04 08:57:20-08:00",
    "text": "In section 8, would it be appropriate to require that the XML is well formed and validated to prevent application and security issues?\u00a0 I think a simple statement to that effect would be helpful in this document.  I'd be fine with seeing text in subsequent documents that tells you how to handle non-conformance to the schema or other issues that might result in a validation problem (if restrictions for this go beyond XML conformance).",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2017-10-09 10:46:31-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-27 17:16:05-07:00",
    "text": "This ballot position would be Please Educate Me, if that was a choice, but that's not a choice. I'm sure we can clear this quickly. And I found this document very easy to read as a reviewer - thanks for that. I found a couple of places where SHOULDs seemed at least under-specified, and this one looked important. In this text, \u00a0 LSP State Synchronization procedures are described in section 5.4 of \u00a0  [ I-D.ietf-pce-stateful-pce ].\u00a0 During State Synchronization, a PCC \u00a0  reports the state of its LSPs to the PCE using PCRpt messages, \u00a0  setting the SYNC flag in the LSP Object.\u00a0 For PCE-initiated LSPs, the \u00a0  PCC MUST also set the Create Flag in the LSP Object and MAY include \u00a0  the SPEAKER-ENTITY-ID TLV identifying the PCE that requested the LSP \u00a0  creation.\u00a0 At the end of state synchronization, the PCE SHOULD \u00a0  compare the reported PCE-Initiated LSPs with its configuration.\u00a0 For \u00a0  any mismatch, the PCE SHOULD send a PCInitiate message to initiate \u00a0  any missing LSPs and/or remove any LSPs that are not wanted. I\u2019m having a hard time understanding why a PCE would not compare reported PCE-Initiated LSPs with its configuration, which is allowed by the first SHOULD. Does that mean you thought it was important to TRY to synchronize, but you\u2019re not curious enough to check whether that worked?  I can imagine reasons why you wouldn't try to fix the LSPs that weren't synchronized, at least not immediately, but you might also give guidance about one or more reasons why you wouldn't try, to help implementers understand what not doing what the SHOULD means, and make informed choices for their implementations.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-18 13:44:57-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-16 21:27:27-08:00",
    "text": "Thanks to the authors and the participants of the CELLAR working group for the work that has gone into documenting the EBML format. I have a handful of comments that I believe need to be addressed prior to publication, and a handful of suggestions for improvement. --------------------------------------------------------------------------- Abstract: I see that the Introduction has been revised to address Ben Campbell's AD review comment regarding the document positioning itself as a general-purpose data format rather than being scoped to its use in Matroska. The Abstract still claims the much broader scope -- please update it to match the reduced scope in the Introduction. --------------------------------------------------------------------------- \u00a77.3: >\u00a0 A Float Element stores a floating-point number as defined in >\u00a0 [IEEE.754.1985]. This is not sufficiently precise to interoperate, as IEEE-754 defines multiple floating-point representations at each bit length. To differentiate from, e.g., decimal representation and arithmetic format (neither of which are probably what you want), please specify the use of \"binary interchange format\" (unless some other format is intended). --------------------------------------------------------------------------- \u00a714.1.3: >\u00a0 For String Elements and UTF-8 Elements the length of Element Data MAY >\u00a0 be reduced by adding Null Octets ... >\u00a0 Note that this method is NOT RECOMMENDED. These two normative statements conflict with each other: when using  RFC 2119 language, MAY is a very different level than \"NOT RECOMMENDED\" (which is equivalent to \"SHOULD NOT\"). Please pick one, and eliminate the other. --------------------------------------------------------------------------- \u00a717.1: >\u00a0 The VINT Data value of one-octet Element IDs MUST be between 0x01 and >\u00a0 0x7E.\u00a0 These items are valuable because they are short, and need to >\u00a0 be used for commonly repeated elements.\u00a0 Values from 1 to 126 are to >\u00a0 be allocated according to the \"RFC Required\" policy [ RFC8126 ]. This, combined with the values that are being registered, is extremely confusing, and I don't know how IANA is supposed to understand what's going on without reading and understanding the VINT bit encoding scheme (which is way too much to ask of them). This is because of the document-wide practice of speaking of IDs in their VINT-encoded values (e.g., 0xBF) instead of their data values (e.g., 63 or 0x3F), including in the initial registry in this section. Please either revise the prose to speak in terms of VINT-encoded values (e.g., \"MUST be between 0x81 and 0xFE\"), or revise the registration tables to indicate the VINT data values (e.g., \"0x3F\" for CRC-32).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-22 16:41:49-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 23:30:36-08:00",
    "text": "Section 7.7 says: \u00a0  A Master Element MUST declare a length in octets from zero to \u00a0  VINTMAX.\u00a0 The Master Element MAY also use an unknown length.\u00a0 See \u00a0  Section 6 for rules that apply to elements of unknown length. but the second sentence contradicts the immediately prior MUST.\u00a0 We need to resolve the internal inconsistency.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-12-29 06:06:44-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-19 06:02:21-08:00",
    "text": "1. Section 5: \u00a0  The Element ID is encoded as a Variable Size Integer. \u00a0 \u00a0 +-----------------------+-------------------------+---------------+ \u00a0 \u00a0 | VINT Length in octets |\u00a0 Range of Possible IDs\u00a0 | Number of IDs | \u00a0 \u00a0 +=======================+=========================+===============+ \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0  0x81 - 0xFE\u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  126 | \u00a0 \u00a0 +-----------------------+-------------------------+---------------+ \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0  0x407F - 0x7FFE\u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 16,256 | \u00a0 \u00a0 +-----------------------+-------------------------+---------------+ \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0  0x203FFF - 0x3FFFFE\u00a0  |\u00a0 \u00a0  2,080,768 | \u00a0 \u00a0 +-----------------------+-------------------------+---------------+ \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x101FFFFF - 0x1FFFFFFE |\u00a0  268,338,304 | \u00a0 \u00a0 +-----------------------+-------------------------+---------------+ To me it appears that this whole section can't decide if the Element ID is encoded integer using VINT or an VINT format octet sequence that is self describing in length? If it is the first then the above quoted table would to me state that the IDs are 1-126 for 1 octet, and the second two-octet 127-16382. But based on later section it is actually the later. As the ID values defined in Section 11.2 for the various elements are actually the encoded form rather than a representation of the Integer value encoded. This needs to be clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-14 12:16:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-30 18:33:28-07:00",
    "text": "(1) I want to check on the DTLS version compatibility of this protocol.\u00a0 If there is a DTLS version dependency, as I suspect, then we need to document it more clearly or remove it. In particular, the current specification has the Key Distributor sending the MediaKeys message before it sends the DTLS (server) Finished message (\u00a75.4), which requires that the HBH keys are available at that point.\u00a0 While the TLS exporter interface used by  RFC 5764  to output keys is an interface that DTLS 1.3 also supports, that may not be the whole story.\u00a0 In particular, in (D)TLS 1.3 the order of client and server Finished messages is reversed, so that the server Finished is sent before the client has authenticated.\u00a0 When combined with the fact that the TLS 1.3 exporter interface does not incorporate the transcript hash of the client's authentication messages, this seems to imply that the key distributor would be releasing HBH keys prior to the client's authentication and prior to the completion of the DTLS 1.3 handshake. The behavior of the TLS 1.3 exporter was considered safe for regular TLS+TCP since the server will abort the connection and not pass any application data if the client's Finished or authentication is invalid, but it poses problems for applications that use only the TLS handshake and do not use the TLS record protection to cover application data. (EAP-TLS is a notable recent example where the protocol had to be modified in order to be secure when used with TLS 1.3.)\u00a0 DTLS-SRTP is also an application that uses only the (D)TLS handshake, and I am worried that releasing HBH keys prior to authenticating the client will also prove problematic in this situation. (2) I'll also mention here so that the IESG can talk about it during our telechat (but with no intent to insist on a change): this document specifies a versioned protocol and creates a registry.\u00a0 Are we happy with the current Informational status, as opposed to Proposed Standard? I do see that the topic was touched on in the shepherd writeup, but the treatment there did not feel especially compelling to me.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-28 16:05:15-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-14 12:16:30-07:00",
    "text": "Thank you for the updates in the -10; they are improvements. I also see that we had enough discussion of Informational vs Standards-Track for this document, with no one really wanting to push for it to be a Proposed Standard. Unfortunately, I think there are still a couple places remaining that aren't quite compatible with DTLS 1.3, and so an additional revision will be required. Section 5.4 (1) \u00a0 \u00a0 When sending the ServerHello message, the Key Distributor MUST insert \u00a0 \u00a0 its own unique identifier in the external_session_id extension. This \u00a0 \u00a0 value MUST also be conveyed back to the client via SDP as a tls-id \u00a0 \u00a0 attribute. In (D)TLS 1.3, the external_session_id extension goes in the EncryptedExtensions message, not the ServerHello.\u00a0 One way to handle this scenario in a DTLS-version-agnostic manner would be NEW: \u00a0 \u00a0 The Key Distributor MUST report its own unique identifier in the \u00a0 \u00a0 \"external_session_id\" extension.\u00a0 This extension is sent in the \u00a0 \u00a0 EncryptedExtensions message in DTLS 1.3, and the ServerHello in \u00a0 \u00a0 previous DTLS versions.\u00a0 This value MUST also be conveyed back to \u00a0 \u00a0 the client via SDP as a tls-id attribute. (2) \u00a0 \u00a0 The Key Distributor MUST send a MediaKeys message to the Media \u00a0 \u00a0 Distributor as soon as a HBH encryption key is computed. The MediaKeys \u00a0 \u00a0 message includes the selected cipher (i.e. protection profile), MKI \u00a0 \u00a0 [ RFC3711 ] value (if any), SRTP master keys, and SRTP master salt values. \u00a0 \u00a0 The Key Distributor MUST use the same association identifier in the \u00a0 \u00a0 MediaKeys message as is used in the TunneledDtls messages for the given \u00a0 \u00a0 endpoint. \"As soon as a HBH encryption key is computed\" is too soon. The key is available before the endpoint is authenticated, and a properly operating DTLS-SRTP session should not send media before the mutual authentication has completed; sending the HBH encryption key \"when available\" would allow the media distributor (which has no visibility into when the DTLS handshake is completed) to send media even though the authentication is not complete.\u00a0 I think it would be more appropriate to say that the MediaKeys message is sent when the DTLS handshake is complete, which is unambiguous and a condition that is universally applicable to all DTLS versions.\u00a0 That might be written as something like NEW: \u00a0 \u00a0 The Key Distributor MUST send a MediaKeys message to the Media \u00a0 \u00a0 Distributor immediately after the DTLS handshake completes. The MediaKeys \u00a0 \u00a0 message includes the selected cipher (i.e. protection profile), MKI \u00a0 \u00a0 [ RFC3711 ] value (if any), SRTP master keys, and SRTP master salt values. \u00a0 \u00a0 The Key Distributor MUST use the same association identifier in the \u00a0 \u00a0 MediaKeys message as is used in the TunneledDtls messages for the given \u00a0 \u00a0 endpoint.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-05-05 03:09:00-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 04:28:23-07:00",
    "text": "Please discuss or address the following points with me before I can vote Yes on this document: 1) Page 28: UTF-8 upper-cased - UTF-8 needs a normative reference. Did you mean ASCII uppercasing, Unicode uppercasing or something else? This also needs a normative reference to UTF-8 ( RFC 3629 ). If you really meant Unicode uppercasing, then how can I verify that the algorithm specified in code in the same section is correct? Is it described in one of Unicode documents somewhere? 2) This is a nit, but I think an important one: In Section 11:  As with any compressed file formats, decompressor implementations should handle all compressed data byte sequences, not only those that conform to this specification, where non-conformant compressed data sequences should be discarded. Discarded? Does this mean ignoring data and just continuing or rejecting the whole payload?",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-05-20 09:05:41-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-05 03:40:09-07:00",
    "text": "Thank you for writing this specification. I am looking forward to recommending its approval soon. However, before doing so I would like to understand what the answer is to Paul Kyzivat's question regarding being an authoritative specification: It is unclear to me whether this document seeks to be an authoritative specification of the Brotli format, or simply an explanation of the format the supplements another specification. Do the authors have an answer?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-23 21:57:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-23 07:01:05-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-idr-bgp-ls-flex-algo-10 CC @evyncke Thank you for the work put into this document. It is important and easy to read (even if I may have missed some points, hence my DISCUSS ballot). Please find below one blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Jie Dong for the shepherd's detailed write-up including the WG consensus, alas there is no justification for the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 3.6 unknown ? ``` \u00a0 \u00a0 \u00a0 sub-TLV types: Zero or more sub-TLV types that are unknown or \u00a0 \u00a0 \u00a0 unsupported by the node originating the BGP-LS advertisement.\u00a0 The \u00a0 \u00a0 \u00a0 size of each sub-TLV type depends on the protocol indicated by the \u00a0 \u00a0 \u00a0 Protocol-ID field.\u00a0 For example, for IS-IS each sub-TLV type would \u00a0 \u00a0 \u00a0 be of size 1 byte while for OSPF each sub-TLV type would be of \u00a0 \u00a0 \u00a0 size 2 bytes. ``` How would an originating node know that some TLVs are unknown to it ? I am probably missing something obvious here, but some clarification text would be welcome. Or simply use 'unsupported'.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-08-23 05:42:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-23 05:41:39-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I found that document pretty easy to read, but there is one point that I think may be helpful to clarify, or otherwise an explanation as to why it shouldn't be clarified: In  draft-ietf-lsr-flex-algo-20 , when describing TLVs like \"IS-IS Flexible Algorithm Exclude Admin Group Sub-TLV\" it states: \u00a0  The IS-IS FAEAG Sub-TLV MUST NOT appear more than once in a single \u00a0  IS-IS FAD Sub-TLV.\u00a0 If it appears more than once, the IS-IS FAD Sub- \u00a0  TLV MUST be ignored by the receiver. However, I couldn't find any similar text in this document.\u00a0 My presumption would be that the FAD sub-TLVs cannot appear more then once, but this didn't obviously appear to be stated anywhere (maybe it is specified in the base BGP LS spec?).\u00a0 Does this need to be stated/clarified in this document at all?\u00a0 Also, is the expected behaviour clear if the FAD TLV is not well constructed? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-08-23 07:52:17-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-23 05:42:06-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I found the document to be pretty easy to read, but there is one point that I think may be helpful to clarify, or otherwise an explanation as to why it shouldn't be clarified: In  draft-ietf-lsr-flex-algo-20 , when describing TLVs like \"IS-IS Flexible Algorithm Exclude Admin Group Sub-TLV\" it states: \u00a0  The IS-IS FAEAG Sub-TLV MUST NOT appear more than once in a single \u00a0  IS-IS FAD Sub-TLV.\u00a0 If it appears more than once, the IS-IS FAD Sub- \u00a0  TLV MUST be ignored by the receiver. However, I couldn't find any similar text in this document.\u00a0 My presumption would be that the FAD sub-TLVs cannot appear more then once, but this didn't obviously appear to be stated anywhere (maybe it is specified in the base BGP LS spec?).\u00a0 Does this need to be stated/clarified in this document at all?\u00a0 Also, is the expected behaviour clear if the FAD TLV is not well constructed? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-08-24 08:41:49-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 07:30:28-07:00",
    "text": "Thanks for working on the this specification. I would like to discuss if Flexible Algorithm Unsupported sub-TLV type should be TBD when it is suggested to 1046 in section 5?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-01-31 14:09:41-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-31 14:07:22-08:00",
    "text": "* Section 4.3. * How is this Element ID (255) allocated? Is this going to have to come from the IEEE or is it part of an experimental range? * What is a \"single octet integer in little-endian format\"? Why does endianness matter for a single byte field? \"Element ID, Length, and ID Extension are all single octet integers in little-endian format.\"",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-02-02 01:11:57-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-31 14:09:41-08:00",
    "text": "* Section 4.3. * How is this Element ID (255) allocated? Is this going to have to come from the IEEE or is it part of an experimental range? I am just checking to make sure that we are not missing a required action for this. * What is a \"single octet integer in little-endian format\"? Why does endianness matter for a single byte field? \"Element ID, Length, and ID Extension are all single octet integers in little-endian format.\"",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-11-01 14:03:35-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-05 07:54:18-07:00",
    "text": "Given that the majority of the IESG has now ballotted abstain, I think we should at least discuss this. I'm marking my ballot DISCUSS until we have a chance to discuss this on a telechat. After we've done that, if Spencer still believes we should advance the document, I will withdraw my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2018-03-19 07:18:16-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-19 22:02:02-08:00",
    "text": "I am balloting DISCUSS because I believe that this document presents an incomplete and vague description of a specification, which (as is) won't result in consistent implementations.\u00a0 Consistency, through the specification of a standard algorithm is used as the basis to justify this work:\u00a0 \"To allow multi-vendor networks to have all routers delay their SPF computations for the same duration, this document specifies a standard algorithm.\"\u00a0  I am specifically and specially concerned about the fact that there are no defaults or even suggested values: \u00a0  This document does not propose default values for the parameters because \u00a0  these values are expected to be context dependent. Implementations are free  \u00a0  to propose their own default values. If the whole purpose of standardizing an algorithm is for different implementation to behave the same way and (specifically) \"to have all routers delay their SPF computations for the same duration\", then not defining defaults (and not being clear in the recommendations -- more on this below) makes the specification incomplete and vague! Section 6 tries to provide guidelines about defaults, but it falls short! \u00a0  In order to satisfy the goals stated in Section 2, operators are \u00a0  RECOMMENDED to configure delay intervals such that SPF_INITIAL_DELAY \u00a0  <= SPF_SHORT_DELAY and SPF_SHORT_DELAY <= SPF_LONG_DELAY. Why are the operators not REQUIRED to meet that relationship?\u00a0 Are there cases when it is ok not to follow those guidelines?\u00a0 Would (for example) the SPF_LONG_DELAY ever be less than SPF_INITIAL_DELAY? The other Normative Language in this section can't really be enforced, and provide (at best) very weak guidance.\u00a0  \u00a0  When setting (default) values, one SHOULD consider the customers and \u00a0  their application requirements, the computational power of the \u00a0  routers, the size of the network, and, in particular, the number of \u00a0  IP prefixes advertised in the IGP, the frequency and number of IGP \u00a0  events, the number of protocols reactions/computations triggered by \u00a0  IGP SPF (e.g., BGP, PCEP, Traffic Engineering CSPF, Fast ReRoute \u00a0  computations). \"SHOULD consider...\"\u00a0 How can this statement be Normatively enforced?\u00a0 Using \"SHOULD\" implies that it is ok to only partially consider the list you provided, or even a different set of criteria.\u00a0  Based on the suggestions above, I can't imagine how a vendor can set default values (even if \"free to propose their own\")...or how the average network operator could configure anything beyond the numbers that you mentioned as examples in the text.\u00a0 For example, the average network operator might ask: under the same circumstances, should my bigger routers (ones with presumably more computational power) have lower or higher delays with respect to my smaller routers?\u00a0 ... \u00a0  Note that some or all of these factors may change over the life of \u00a0  the network.\u00a0 In case of doubt, it's RECOMMENDED to play it safe and \u00a0  start with safe, i.e., longer timers. How can \"playing it safe\" be Normatively enforced? \u00a0  For the standard algorithm to be effective in mitigating micro-loops, \u00a0  it is RECOMMENDED that all routers in the IGP domain, or at least all \u00a0  the routers in the same area/level, have exactly the same configured \u00a0  values. [A similar statement is made in Section 7.] If it is so important, why is consistency not mandatory?\u00a0 IOW, why is it only \"RECOMMENDED\" and not \"REQUIRED\"?\u00a0 When is it ok to not do it? Back to the point of this DISCUSS, the importance of consistent values is clear!\u00a0 Based on the experience of existing implementations, please specify \"safe\" default values.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2018-03-13 09:38:57-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-20 15:02:14-08:00",
    "text": "While I agree with Alvaro's concerns, my concern is the appropriateness of this document as PS. This document should have a similar status as  RFC6976  (Informational) which also provided a mechanism that prevented transient loops saying \"the mechanisms described in this document are purely illustrative of the general approach and do not constitute a protocol specification\". Especially as this document compares itself to  RFC6976 , saying  RFC6976  is a \"full solution\". With a change of status to Informational, this document would be better scoped as providing guidance vs. a specification.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-11-01 07:32:00-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-31 19:56:48-07:00",
    "text": "This should be extremely straightforward: either there\u2019s a typo... or I simply don\u2019t understand.\u00a0 In the Abstract: \u00a0  Dissemination of Flow Specification Rules provides a Border Gateway \u00a0  Protocol extension for the propagation of traffic flow information \u00a0  for the purpose of rate limiting or filtering IPv4 protocol data \u00a0  packets. Is that supposed to say \u201cIPv6\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-16 01:45:18-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 10:26:51-08:00",
    "text": "A fairly minor point, but I think that allowing Type 13 (flow label) component values to be encoded as 2-byte quantities encourages the selection of non-random flow label values, and thus violates the guidance from  RFC 6437  that these values \"should be chosen such that their bits exhibit a high degree of variability\" and that \"third parties should be unlikely to be able to guess the next value that a source of flow labels will choose.\"\u00a0 While having the short 1-byte encoding for a flow label of 0 might be reasonable, a 2-byte label can represent at most 16 bits of the 20-bit identifier space, discouraging the use of the high 4 bits, when such bits of unpredictability are scarce already. Let's discuss how big an issue this is and what might be done to mitigate it. Please also confirm that we are providing all the information required of us by  RFC 5701  and 5575bis (see comments on Section 6.1); I am not sure whether I am reading the references correctly in these regards. There seems to be an error in the sample code (flow_rule_cmp_v6()): the snippet \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  if comp_a.offset < comp_b.offset: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  return A_HAS_PRECEDENCE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  if comp_a.offset < comp_b.offset: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  return B_HAS_PRECEDENCE duplicates the condition, whereas the condition should be swapped for correct operation.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-24 07:52:22-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 23:34:49-08:00",
    "text": "Thank you for the work put into this document. It is indeed due time to filter also those IPv6 packets ;-) Please find below one blocking DISCUSS point, some non-blocking COMMENT points, and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == I am puzzled by the absence of a flow spec for the first Next-Header being a specific value and by the absence of a flowspec for the occurence of any extension header in the extension header chain. Extension headers are an important difference compared to IPv4 and could be 'nasty' as well (e.g., hop-by-hop header). Why was this not considered by the authors ? Or is there another document in the WG to address this issue ?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-17 15:52:14-07:00",
    "end_reason": "position_updated",
    "start": "2018-12-19 10:36:12-08:00",
    "text": "Section 3.3's procedures for shortening domain names seem potentially problematic.\u00a0 While I can understand the desire to reduce the number of DNS queries, I'm not sure that it's really appropriate to place restrictions on what prefix lengths/boundaries can be used to divide administrative domains in a standards-track document.\u00a0 In particular, the IPv4 procedure only allows lengths that end on octet boundaries, which seems to ignore the possibility of using procedures from  BCP 20 .\u00a0 IPv6 is a somewhat different case, but my understanding is that in the general case prefix boundaries can land on arbitrary nibbles, and if we only look at a specific subset for NAPTR records we risk not matching up with reality.\u00a0 The lists in the fourth column of the table in Section 3.4 would presumably need to be revised as well, if this changes. From Section 5.2.1: \u00a0  We assume that if two organizations share parts of their DNS \u00a0  infrastructure, i.e., have common  in-addr.arpa . and/or  ip6.arpa . \u00a0  subdomains, they will also be able to operate a common ALTO server, Perhaps I am confused, but common subdomains in the reverse zones just implies a common IP address block.\u00a0 Why does it also imply a common DNS infrastructure? I also have a few points relating to the security of DNS and DNSSEC. From Section 6.1 \u00a0 \u00a0 \u00a0 However, it should also be noted that, if an attacker was able to \u00a0 \u00a0 \u00a0 compromise the DNS infrastructure used for cross-domain ALTO \u00a0 \u00a0 \u00a0 server discovery, (s)he could also launch significantly more \u00a0 \u00a0 \u00a0 serious other attacks (e.g., redirecting various application \u00a0 \u00a0 \u00a0 protocols). I'm not sure that this statement holds as strongly as one might like. In particular, this document is using the reverse zone (whereas normal ALTO usage would seem to only use the forward zone), and my understanding is that the management and operational practices for the reverse zone lag behind that of the forward zone.\u00a0 For example, I have encountered scenarios where I am issued an IPv4 address via DHCP that has no corresponding entry in the reverse zone, which broke some services for me at that site. \u00a0  Protection Strategies and Mechanisms \u00a0 \u00a0 \u00a0 The cross-domain ALTO server discovery procedure relies on a \u00a0 \u00a0 \u00a0 series of DNS lookups.\u00a0 If an attacker was able to modify or spoof \u00a0 \u00a0 \u00a0 any of the DNS records, the resulting URI could be replaced by a \u00a0 \u00a0 \u00a0 forged URI.\u00a0 The application of DNS security (DNSSEC) [ RFC4033 ] \u00a0 \u00a0 \u00a0 provides a means to limit attacks that rely on modification of the \u00a0 \u00a0 \u00a0 DNS records while in transit. [...] I think we need to have a discussion about the efficacy and availability of DNSSEC for the reverse zone (and how those compare to the forward zone).\u00a0 It seems that the situation is less bad than I feared when I deferred the ballot on this document, but perhaps still not in a great place.\u00a0 In particular, I see that IANA and the RIRs do sign their reverse zones, and at least some RIRs have self-service options for inserting DS records into those zones, but my understanding is that in practice signing of the reverse zone is not in great shape.\u00a0 That is, while the technical pieces are all available (and in particular the pieces at the top are all present), it's not currently in any significant usage due to a lack of compelling use case and interest among (e.g.) ISPs.\u00a0 This document does not really seem like it's providing a compelling enough use case to drive adoption, so I think we're forced to treat DNSSEC as not actually useful in practice for this scenario. Separately, there is the question of what trust anchor to use for DNSSEC in the reverse zone for private-use addresses (which can be properly used in multiple locations and have no single point of authority).\u00a0  RFC 7216  includes some text about this issue, which would probably be appropriate to adopt to this case as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-12-19 12:49:21-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3649 The security considerations for this document don't seem to be adequate. In general, the security of this mechanism seems to rely on DNSSEC, and yet it's not mandated. DETAIL S 6.1. >\u00a0   >\u00a0 \u00a0 \u00a0 \u00a0  However, it should also be noted that, if an attacker was able to >\u00a0 \u00a0 \u00a0 \u00a0  compromise the DNS infrastructure used for cross-domain ALTO >\u00a0 \u00a0 \u00a0 \u00a0  server discovery, (s)he could also launch significantly more >\u00a0 \u00a0 \u00a0 \u00a0  serious other attacks (e.g., redirecting various application >\u00a0 \u00a0 \u00a0 \u00a0  protocols). Hmm... Are there no settings in which ALTO servers give information that isn't something that is a subset of info in DNS? This seems like it needs more analysis. S 6.1. >\u00a0 \u00a0 \u00a0 \u00a0  certificate will contain the host name (CN).\u00a0 Consequently, only >\u00a0 \u00a0 \u00a0 \u00a0  the host part of the HTTPS URI will be authenticated, i.e., the >\u00a0 \u00a0 \u00a0 \u00a0  result of the ALTO server discovery procedure.\u00a0 The DNS/U-NAPTR >\u00a0 \u00a0 \u00a0 \u00a0  based mapping within the cross-domain ALTO server discovery >\u00a0 \u00a0 \u00a0 \u00a0  procedure needs to be secured as described above, e.g., by using >\u00a0 \u00a0 \u00a0 \u00a0  DNSSEC. This is not an acceptable description of how to use TLS. Given that you are using HTTPS, you need to cite 2818. And as this is a new application of HTTPS, you should be specifying modern TLS, i.e., mimimum 1.2 and 7525. S 6.4. >\u00a0 \u00a0 \u00a0 \u00a0  statement [ RFC5693 ] and/or discussed in the ALTO working group, >\u00a0 \u00a0 \u00a0 \u00a0  this scenario has not been identified as a relevant threat. >\u00a0   >\u00a0 \u00a0 \u00a0 Protection Strategies and Mechanisms >\u00a0 \u00a0 \u00a0 \u00a0  No protection mechanisms for this scenario have been provided, as >\u00a0 \u00a0 \u00a0 \u00a0  it has not been identified as a relevant threat.\u00a0 However, if a Another threat here is the disclosure of the exact query you are making to the ALTO server. An attacker might be interested in that, and it's not all manifest in the DNS query.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-07-26 11:46:21-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-12-05 08:05:13-08:00",
    "text": "* Section 5.1.2. I am having a hard time seeing how this can be implemented as described. \"Therefore, a dual stack or multihomed resource consumer SHOULD either always use the same address for contacting the resource directory and the resource providers, i.e., overriding the operating system's automatic source IP address selection\" What exactly is the mechanism to be used for the override? A policy table (manual or  RFC7078 )? I think it would be good if the document can provide an implementable description based on  RFC6724 . * Section 3.2.\u00a0 Step 1 \"Similarly, if AT=IPv6 and L < 32, the procedure aborts\u00a0 and indicates an \"invalid prefix length\" error to the caller.\" I am trying to understand why is this a limitation. An IPv6 prefix can certainly legally have a length of < 32.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-07-26 11:53:17-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-26 11:46:21-07:00",
    "text": "hanks for addressing my DISCUSS points in version -05.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-12-19 09:30:25-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-18 12:37:39-08:00",
    "text": "Note: I have not completed my review in detail (and so it may be answered further down), but I wanted to get this in early... I'm in no way an ALTO expert (I can barely spell it), so am hoping that I'm missing something obvious, but I'm really concerned by the scaling implications / cost shifting of this. Let's say this suddenly becomes very popular -- Apple includes this in the iOS App Store / iMessage app, or Chrome / Firefox decides to start doing this to find the best datacenter to send traffic to or something... Until the huge majority of ISPs start answering with these records for all of their subnets, it seems like there could be a sizable amount of traffic hitting a: the ISPs recursive servers, b: RIRs, and possibly c: AS112 servers. E.g: The address I get when I lookup  www.google.com  is 216.58.193.164. These are the lookups I'd need to do (I think!) if my $application (or, more worrying, framework / browser) were to use this: wkumari$ dig +nocomment +nostats +nocmd NAPTR  164.193.58.216.in-addr.arpa ; 164.193.58.216.in-addr.arpa .\tIN\tNAPTR 193.58.216.in-addr.arpa . 59\tIN\tSOA\t ns1.google.com .  dns-admin.google.com . 226022060 900 900 1800 60 wkumari$ dig +nocomment +nostats +nocmd NAPTR  193.58.216.in-addr.arpa ; 193.58.216.in-addr.arpa .\tIN\tNAPTR 193.58.216.in-addr.arpa . 59\tIN\tSOA\t ns1.google.com .  dns-admin.google.com . 225983176 900 900 1800 60 wkumari$ dig +nocomment +nostats +nocmd NAPTR  58.216.in-addr.arpa ; 58.216.in-addr.arpa .\t\tIN\tNAPTR 216.in-addr.arpa .\t1539\tIN\tSOA\t z.arin.net .  dns-ops.arin.net . 2017026288 1800 900 691200 10800 wkumari$ dig +nocomment +nostats +nocmd NAPTR  216.in-addr.arpa ; 216.in-addr.arpa .\t\tIN\tNAPTR 216.in-addr.arpa .\t1665\tIN\tSOA\t z.arin.net .  dns-ops.arin.net . 2017026288 1800 900 691200 10800  This is 4 lookups per host / app / connection hitting my recursive servers. In addition 2 of them hit Google's resolvers, and 2 hit ARINs. Yes, ARIN already gets many \"reverse\" queries, and my recursive already does lots of lookups, but the document doesn't (that I could see) discuss the potential fallout from potentially *lots* more load.  Caching is only slightly effective here -- there are many many subnets, and e.g the ARIN NoData,NoError response will be cached for 1800 seconds (30 minutes).  There are other examples -- for example, my laptop is currently on 192.168.0.65. If I try connect to 192.168.1.2 using an app which implements this, I'll have 4 queries hitting my recursive server (3 of which will get NXDOMAIN) and  192.in-addr.arpa . hitting ARINs servers. I'm assuming that I must be missing something obvious here, because I cannot see how the above sounds reasonable.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-02-09 09:01:34-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-02 11:01:27-08:00",
    "text": "There seems to be a bit of a disconnect between this text in 3.2: \"As specified in Section 3.4. , the Checksum Complement should only be used in unauthenticated mode.\" and this text in 3.4.1: \"A Checksum Complement MAY be used when authentication is enabled. In \u00a0  this case an intermediate entity can timestamp test packets and \u00a0  update their Checksum Complement field without modifying the HMAC.\" I can see why not to use the checksum complement in encrypted mode, but don't see why it can't be used in authenticated mode for TWAMP.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-11 01:26:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-10 05:06:30-07:00",
    "text": "Zahed is still on leave and has not had a chance to review Magnus' earlier DISCUSS. I deferred this document last time it was on the agenda, but since Zahed is still not back, I will put in a placeholder DISCUSS for him, so that he has a chance to complete his review. I apologize to the authors and the WG for doing this; these are exceptional circumstances. I will clear this placeholder DISCUSS as soon as Zahed is able to resume as AD (or Martin Duke indicates that he has reviewed Magnus' DISCUSS.) All that said, I do have one DISCUSS item: DOWNREF from this Standards Track doc to Informational  RFC7497 . I didn't see this called out in the Last Call, and it's also not a document we have in the DOWNREF registry already.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-21 00:14:45-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-11 01:26:47-07:00",
    "text": "DOWNREF from this Standards Track doc to Informational  RFC7497 . I didn't see this called out in the Last Call, and it's also not a document we have in the DOWNREF registry already.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-03-12 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-02-25 06:18:17-08:00",
    "text": "A) Section 8. Method of Measurement I think the metrics are fine, what makes me quite worried here is the measurement method. My concerns with it are the following. 1. The application of this measurement method is not clearly scoped. Therefore I will assume that across the Internet measurements are possible. However in that context I think the definition and protection against severe congestion has significant short comings. The main reason is that the during a configurable time period (default 1 s) the sender will attempt to send at a specified rate by a table independently on what happens during that second.  2. The algorithm for adjusting rate is table driven but give no guidance on how to construct the table and limitations on value changes in the table. In addition the algorithm discusses larger steps in the table without any reflection of what theses steps sides may represent in offered load.  3. Third the algorithms reaction to any sequence number gaps is dependent on delay and how it is related to unspecified delay thresholds. Also no text discussion how these thresholds should be configured for safe operation.  B) Section 8. Method of Measurement There are no specification of the measurement protocol here that provides sequence numbers, and the feedback channel as well as the control channel. Is this intended to use TWAMP?  From my perspective this document defines the metrics on standards track level. However, the method for actually running the measurements are not specified on a standards track level. No one can build implementation. And if the section is intended to provide requirements on a protocol that performs these measurements I think several aspects are missing. There appear several ways forward here to resolve this; one is to split out the method of measurement and define it separately to standard tracks level using a particular protocol, another is to write it purely as requirements on a measurement protocols.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-02-24 23:46:19-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-24 23:29:24-08:00",
    "text": "Several of the SHOULDs in this document are giving me trouble.\u00a0 There are two categories in particular: As described in  RFC 2119 , we typically use this sort of language to describe interoperability or security concerns.\u00a0 How are the SHOULDs in Section 9 related to interoperability or security?\u00a0 Rather, they seem to be describing issues of presentation. Since a SHOULD leaves an implementer with a choice, it's preferable to see prose explaining why one might deviate from the SHOULD advice.\u00a0 Thus, the SHOULDs in Sections 5.3 and 6.3 leave me wondering under what circumstances an implementer might legitimately choose to do something else.\u00a0 If there are none, should it be a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-02-25 07:21:11-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 23:46:19-08:00",
    "text": "Several of the SHOULDs in this document are giving me trouble.\u00a0 There are two main categories, one in particular I'd like to discuss: As described in  RFC 2119 , we typically use this sort of language to describe interoperability or security concerns.\u00a0 How are the SHOULDs in Section 9 related to interoperability or security?\u00a0 Rather, they seem to be describing issues of presentation.\u00a0 Or is this another instance of the \"operational advice\" exception that's come up on other operational advice documents?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-02-25 06:47:07-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 05:56:05-08:00",
    "text": "There were Internationalization issues raised by John Klensin and Patrik F\u00e4ltstr\u00f6m that need to bbe addressed, and I haven\u2019t seen a response to them yet.\u00a0 The primary one involves cross-cultural understanding of the meaning of emoji symbols, and, thus, weather it makes sense to use the emoji symbols themselves as protocol elements, rather than defining specific protocol elements and letting the implementation select emoji based on regional/cultural custom.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-12 12:39:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 14:47:00-08:00",
    "text": "I thought you were going to clean up whether the Content-Disposition was \"React\" or \"Reaction\" based on the gen-art review, but the document still seems internally inconsistent about it. https://mailarchive.ietf.org/arch/msg/gen-art/zun860KMrKdwqyKSWbrvWSPMuYM/ indicates that \"React\" was the intent, but Sections 2 and 4.1 still use \"Reaction\", while the IANA Considerations register \"React\".\u00a0 Section 3 uses lowercase \"reaction\" in the context of a \"Content-Disposition\" header field as well.\u00a0 Section 7 mentions a \"Reaction capability\".",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-07-12 00:47:35-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-05 09:38:32-07:00",
    "text": "I think the protocol specification is not complete: - What happens if none of the two S and C bits are set? - What happens if more the one sub-TLV is present? Actually I think that the protocol design is more complicated than needed and simplifying it would resolve these error cases. But as that's not a DISCUSS reason, please see more detailed comments below!",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-23 15:21:39-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 17:04:23-07:00",
    "text": "Thanks to everyone who has worked on this document. I generally agree with Benjamin's discuss points, and in particular agree with his comment that it's kind of hard to figure out how all these pieces work together. I have an additional issue that is somewhat related to some of the points he raised, but which is (I think) not completely covered. I'm really confused about what the purported privacy properties of this protocol are. In section 4.3 (which I *think* talks about globally-routable IP addresses, although this is a bit unclear), the document says: \u00a0  such an IID SHOULD guarantee a stable IPv6 address \u00a0  because each data link connection is uniquely identified by the pair \u00a0  of DSAP and SSAP included in the header of each LLC PDU in NFC (Aside: this \"should\" is a simple statement of fact, not a described behavior of the protocol, and so the use of RFC-2119-style all-caps is not appropriate.) The presence of \"a stable IPv6 address\" inherently implies the ability to track devices. Then, in section 7, I find the following text: \u00a0  ...the short address of \u00a0  NFC link layer (LLC) is not generated as a physically permanent value \u00a0  but logically generated for each connection.\u00a0 Thus, every single \u00a0  touch connection can use a different short address of NFC link with \u00a0  an extremely short-lived link. This text seems to imply that addressing information is, in general, not stable, which appears to flatly contradict the text in section 4.3. Please clarify, in section 4.3, what the duration of stability of these identifiers is.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:41:27-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 07:49:22-07:00",
    "text": "I support Benjamin's DISCUSS point about large antennas.  RFC 2119  specifies the keywords \"RECOMMENDED\" and \"NOT RECOMMENDED.\" This document uses these in verb form (\"RECOMMEND\" and \"NOT RECOMMEND\"). Please change these instances so that the actual 2119 keywords are used. = Section 4.8 = I think the Gen-ART reviewer's question about fragmentation is unresolved. How is interoperability achieved if some nodes implement MIUX and not FAR, and some nodes implement FAR and not MIUX? It seems as though IPv6-over-NFC needs to be restricted to nodes that support one or the other (presumably MIUX). = Section 5.1 and 7 = Per the Gen-ART review, one of these sections needs to say something about how connecting to the Internet potentially changes the threat model for devices that were perhaps not originally envisioned to connect to the Internet.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 12:07:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-11 18:24:12-07:00",
    "text": "In general, I'm worried that this document is so unreadable that I can't give it a proper review.\u00a0 I just don't have a clear picture of how all the pieces fit together, and which pieces are new as opposed to reused from other specifications.\u00a0 That said, here are my notes as they stand at present. If I understand correctly, the statements about \"distance of 10 cm or less\" and \"safe\" or \"secure communications\" apply only for usage compliant with the relevant legal regulations.\u00a0 We cannot expect attackers to abide by such regulations, and large (directional) antennas and/or high-power transmitters should be presumed to expand that distance by some factor, in adversarial environments. Section 4.3 should probably provide some guidance on choosing the PRF F().\u00a0 We are implicitly relying on  RFC 7217  for a lot of things, some of which 7127 doesn't even cover, and the suggested construction in  RFC 7127  may not still be best practice. I don't understand why MIUX is not mandatory (and thus we could get rid of all the \"FAR is NOT RECOMMENDED\" stuff).\u00a0 Is there known demand for IPv6 over NFC on devices that cannot do MIUX? Some section-by-section points as well: Section 3.1 \u00a0  peer mode is used for ipv6-over-nfc.\u00a0 In addition, NFC-enabled \u00a0  devices can securely send IPv6 packets to any corresponding node on \u00a0  the Internet when an NFC-enabled gateway is linked to the Internet. I don't see anything in the document that justifies the usage of \"securely\". Section 3.4 \u00a0  When the MIUX parameter is encoded as a TLV option, the TLV Type \u00a0  field MUST be 0x02 and the TLV Length field MUST be 0x02.\u00a0 The MIUX \u00a0  parameter MUST be encoded into the least significant 11 bits of the \u00a0  TLV Value field.\u00a0 The unused bits in the TLV Value field MUST be set \u00a0  to zero by the sender and ignored by the receiver.\u00a0 A maximum value Either the MIUX occupies 11 bits and there are five unused bits to be set to zero, or the four bits marked in the figure are 1011 and there is only one unused bit (singular) to be marked as zero.\u00a0 This needs to be more clear, as right now I can't tell what's intended. Section 4.4 How does a device know that the link-local address is a public address? Section 4.5 \u00a0  o\u00a0 When an NFC-enabled device (6LN) is directly connected to a 6LBR, \u00a0 \u00a0 \u00a0 an NFC 6LN MUST register its address with the 6LBR by sending a How does the device know that it's talking NFC to a 6LBR as opposed to some non-border-router peer?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-22 12:07:46-07:00",
    "text": "I attempted to review the changes from -13 to -17, as well as look at the -17 in isolation, though I do not really have enough time available to do a proper review before my term as AD expires. I'm still worried that in general this document doesn't give a clear picture of how all the pieces fit together, and which pieces are new as opposed to reused from other specifications. I do appreciate many of the updates made to streamline the introductory text and keep it focused on what is relevant for this document. I am also happy to see that use of MIUX has been made mandatory so that the L2CAP FAR is not needed.\u00a0 However, I do not see much justification for the MUST-level requirement that the MIUX value be exactly 0x480. Is there some reason to forbid the negotiation of larger link MTU, if both parties are capable?\u00a0 I would have expected only a requirement that the MIUX value be at least 0x480. Section 4.3 should probably provide some guidance on choosing the PRF F().\u00a0 We are implicitly relying on  RFC 7217  for a lot of things, some of which 7127 doesn't even cover, and the suggested construction in  RFC 7127  may not still be best practice. I think the figure in Section 3.4 that lays out the encoding of the MIUX TLV is incomplete or inaccurate -- e.g., the third field shows only four bits but the labels indicate it should occupy six bits, and the range of values for the fourth field indicates it should occupy eleven bits but the column labels give it only ten. A section-by-section point as well: Section 4.5 \u00a0  o\u00a0 When an NFC-enabled 6LN is directly connected to a an NFC-enabled \u00a0 \u00a0 \u00a0 6LBR, the NFC 6LN MUST register its address with the 6LBR by How does the device know that it's talking NFC to a 6LBR as opposed to some non-border-router peer?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-13 21:20:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-13 21:19:42-07:00",
    "text": "I am unable to adequately review this document because the first normative reference and hence this DISCUSS is incomplete. \u00a0  [LLCP-1.3] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"NFC Logical Link Control Protocol version 1.3\", NFC Forum \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Technical Specification , March 2016. Does not appear to be publicly available (the web site contains a single-page PDF which reads in part \"To view the complete specification, go to  http://nfc-forum.org/our-  work/specifications-and-application-documents/specifications/nfc-forum- technical-specifications/. Complete the license agreement, and then download the specification.\"). Please supply an unencumbered specification and then I can rereview. I have read S 3.4 repeatedly, but am unable to work out the mapping of an IPv6 datagram to LLCP. Please provide a diagram that shows how this works and then perhaps I can assist you with the text.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-03-13 21:20:18-07:00",
    "text": "I am unable to adequately review this document because the first normative reference and hence this DISCUSS is incomplete (ordinarily this would conflict with the DISCUSS guidelines, but I believe it is necessary in this case). \u00a0  [LLCP-1.3] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"NFC Logical Link Control Protocol version 1.3\", NFC Forum \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Technical Specification , March 2016. Does not appear to be publicly available (the web site contains a single-page PDF which reads in part \"To view the complete specification, go to  http://nfc-forum.org/our-  work/specifications-and-application-documents/specifications/nfc-forum- technical-specifications/. Complete the license agreement, and then download the specification.\"). Please supply an unencumbered specification and then I can rereview. I have read S 3.4 repeatedly, but am unable to work out the mapping of an IPv6 datagram to LLCP. Please provide a diagram that shows how this works and then perhaps I can assist you with the text.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-01-12 10:23:01-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 02:15:28-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-6lo-nfc-19 CC @evyncke Thank you for the work put into this document. It could indeed be useful and it would deserve a high quality specification. Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Carles Gomez for the shepherd's detailed write-up including the WG consensus *and* the justification of the intended status. But, the write-up is incorrect about the downward reference as  https://datatracker.ietf.org/doc/draft-ietf-6lo-nfc/references/  indicates  RFC 3756  is a downref... Please note that Pascal Thubert is the Internet directorate reviewer (at my request) and you may want to consider this int-dir reviews as well when Pascal will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-6lo-nfc/reviewrequest/16761/ I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Tagging of references I have not checked all references, but at least  RFC 3633  should not be normative but only informative. Moreover,  RFC3633  is obsoleted by  RFC 8415  for 4 years. ### Section 3.4 As far as I understand the document and its relationship with NFC standards, then it is not up to the IETF to use normative language around MIUX (specified by NFC), so, the \"MUST\" below should rather be \"is\". ``` \u00a0  When the MIUX parameter is used, the TLV Type field MUST be 0x02 and \u00a0  the TLV Length field MUST be 0x02.\u00a0 The MIUX parameter MUST be \u00a0  encoded into the least significant 11 bits of the TLV Value field. \u00a0  The unused bits in the TLV Value field MUST be set to zero by the \u00a0  sender and ignored by the receiver. ``` The \"MUST\" in `The MIUX value MUST be 0x480 to support the IPv6 MTU requirement (of 1280 bytes).` is of course fine. Finally, please add a normative reference to  RFC 8200 . ### Section 4.2 Is this section normative ? There is no  BCP14  words in it. If normative, then how is Network_ID derived from any NFC parameter? ### Section 4.3 While not really a DISCUSS point, what is the link between DHCP-PD and a LLA ? Remove the part about getting a prefix. What is a `secured and stable IID` ? Do the authors mean a 'random and stable IID'? ### Section 4.4 and 5 In section 4.4: `NFC supports mesh topologies but ...` In section 5: `An NFC link does not support a star topology or mesh network topology` So, is mesh supported or not ? ### Section 4.5 Is this section normative ? There is no  BCP14  terms. Is there a IANA registry for \"Dispatch\" values ? If so, then please add a reference. It *seems* that the length is 1 octet, please specify the length of the value. ### Section 4.6 Possibly due to my ignorance of  RFC 6282 , but this document refers to TCP (section 4.1) while  RFC 6282  only compresses UDP ?  Is `6-bit NFC link-layer` the same as the `6-bit SSAP` discussed before ? I guess so but I should not guess but be sure. ### Section 4.8 Is this section normative about multicast replication ? ### Section 5.1 ``` \u00a0  Two or more 6LNs may be connected with a 6LBR, but each connection \u00a0  uses a different subnet. ``` Unsure whether 'subnet' means 'IPv6 prefix' or 'link' ? `the 6LBR MUST ensure address collisions do not occur` how can this goal be achieved.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2023-01-18 02:39:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 13:07:33-08:00",
    "text": "I share other ADs' concern about availability of the NFC spec, however it is my understanding that Erik has had access to it, and I trust he was able to do a full review of the draft. Given that, I would ballot No Objection. However I have identified what I think is a simple typo, but important enough to warrant a blocking comment. Section 4.8: > Length: > > This is the length of this option (including the type and length fields) in units of 8 octets. The value of this field is 1 for 6-bit NFC node addresses. I believe you meant \"in octets\" or \"in units of 8 bits\", right?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-12-13 23:22:29-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 04:27:50-08:00",
    "text": "# GEN AD review of  draft-ietf-6lo-nfc-19 CC @larseggert ## Discuss ### Section 9, paragraph 2 ``` \u00a0 \u00a0  [LLCP-1.4] \"NFC Logical Link Control Protocol, Version 1.4\", NFC \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Forum Technical Specification , January 2021. ``` Eric raised this for -13 in 2019 already: this specification does not seem to be publicly available? Did the NFC forum share a copy with the IETF WG that you could forward to the IESG for our review?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-12-30 14:37:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-12-28 06:59:32-08:00",
    "text": "(Preliminary ballot from an incomplete review of the document, but shared here for early awareness) Multiple prior DISCUSes were filed on the basis of concerns that the base normative references were not available.\u00a0 In response, the \"NFC LLC v1.4\" specification was shared. However, it appears additional normative references are needed to evaluate the security claims of the protocol (NFC LLC v1.4). Section 7 of this I-D says: \u00a0  Ad-hoc secure data transfer can be established between two \u00a0  communication parties without any prior knowledge of the \u00a0  communication partner.\u00a0 Ad-hoc secure data transfer can be vulnerable \u00a0  to Man-In-The-Middle (MITM) attacks.\u00a0 Authenticated secure data \u00a0  transfer provides protection against Man-In-The-Middle (MITM) \u00a0  attacks.\u00a0 In the initial bonding step, the two communicating parties \u00a0  store a shared secret along with a Bonding Identifier.\u00a0 For all \u00a0  subsequent interactions, the communicating parties re-use the shared \u00a0  secret and compute only the unique encryption key for that session. \u00a0  Secure data transfer is based on the cryptographic algorithms defined \u00a0  in the NFC Authentication Protocol (NAP). This text is a cut-and-paste verbatim from Section 3.2.5 of NFC Forum LLC specification previously shared as part of the last telechat.\u00a0 However the NAP is defined in yet another NFC Forum document.\u00a0 How does one access that?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-02-02 13:01:22-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-30 14:37:17-08:00",
    "text": "(revised) Multiple DISCUSes were filed during the March 2019 telechat on the basis of concerns that the underlying normative references were not available.\u00a0 In response, the \"NFC LLC v1.4\" specification was shared in advance of the December 2022 telechat. However, it appears additional normative references are needed to evaluate the security claims of the protocol (NFC LLC v1.4). Section 7.1 of NFC LLC v1.4 says: Secure data transfer uses the NFC Authentication Protocol [NAP]. This subsection defines three processes: Security Setup, Bonding Process and Authentication Process. All three processes are mappings of the corresponding processes with the same names defined in [NAP]. Section 7 of this I-D says: \u00a0  Ad-hoc secure data transfer can be established between two \u00a0  communication parties without any prior knowledge of the \u00a0  communication partner.\u00a0 Ad-hoc secure data transfer can be vulnerable \u00a0  to Man-In-The-Middle (MITM) attacks.\u00a0 Authenticated secure data \u00a0  transfer provides protection against Man-In-The-Middle (MITM) \u00a0  attacks.\u00a0 In the initial bonding step, the two communicating parties \u00a0  store a shared secret along with a Bonding Identifier.\u00a0 For all \u00a0  subsequent interactions, the communicating parties re-use the shared \u00a0  secret and compute only the unique encryption key for that session. \u00a0  Secure data transfer is based on the cryptographic algorithms defined \u00a0  in the NFC Authentication Protocol (NAP). The described security properties appear to depend on the \u201cNFC Authentication Protocol\u201d (NAP) which is neither formally referenced with a normative reference (like the NFC LLC v1.4 specification) and does not appear to be available.\u00a0 It is challenging to evaluate the security claims without it. Thank you to the document authors for responding to a preliminary version of this DISCUSS position which said that it is not possible to share the NAP specification. See  https://mailarchive.ietf.org/arch/msg/6lo/ii9ANOvsJKr08kr7oOCWQ635GtI/ .\u00a0 If the specification is not available, it isn\u2019t clear how the IETF consensus review process is possible.\u00a0 The shepherd write-up says \u201cAccess to the NFC spec has been available for those that have needed it.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-02-28 04:23:07-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-04 18:19:22-08:00",
    "text": "Thanks for working on this specification. Thanks to Wesley Eddy for his excellent TSVART review.  As I agree with the points brought up by the TAVART reviewer, I would like to discuss why the points made by the reviewer should not be considered for this specification.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-21 07:16:29-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-19 23:37:31-07:00",
    "text": "The removal of IPv6 support from this document without it having a normative dependency on a document that describes use with IPv6 addresses causes me quite a bit of concern, on two fronts. I'm willing to be convinced that I'm off in the weeds, but right now I don't think we can publish the document. First: while I understand that the working group's intentions are genuine, this sets us up for a \"fail unsafe\" situation; if the working group, for whatever reason, does not progress the IPv6 counterpart of this protocol to an RFC, then the publication of this document will (retroactively) be in contravention of the architectural advice issued by the IAB: https://www.iab.org/documents/correspondence-reports-documents/2016-2/iab-statement-on-ipv6/ The second issue is the precedent of publishing an IPv4-only document in 2018, at a time that we're aggressively trying to ensure that everyone is designing their protocols in a way that supports IPv6 addresses. Even with a plan to fix the lack of IPv6 support, the publication of the document itself sets a bad example. I think the first issue could be solved by holding this document until at least a skeletal IPv6 approach is documented, and then creating a normative dependency from this document to that one. The second issue could be addressed by indicating that IPv6 is out of scope of this document only because it is addressed in [RFC xxxx] (the aforementioned IPv6 document).",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-02-07 14:33:36-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-07 07:43:03-08:00",
    "text": "I had the same logging question an Alexey and guessed (perhaps incorrectly) that this was to try and prevent DoSing the logging infrastructure by sending too many log messages. If this is the reason, I think that it should be better spelled out -- and if this is *not* the reason, I think that there needs to be a good explanation.  Note that I will happy clear as soon as someone says \"Yeah, we've heard and will deal with this\" -- I think that this is a fine document and that addressing this issue should be a minor change, but important enough for operational reasons that it needs to be discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-03-12 14:12:59-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-02 09:34:46-08:00",
    "text": "This spec enables an SC node to create new packets and therefore must provide congestion control consideration to avoid network overload from these packets, e.g. in the simplest case requiring a maximal sending rate/minimal time interval between to packets. I also requested an additional TSV-ART review for further feedback and recommendations for a potential solution.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-06-21 23:49:31-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-19 14:32:13-07:00",
    "text": "This document contains both the  RFC2119  boilerplate and specific definitions for MUST, SHOULD/RECOMMENDED and MAY. Even though the additional definitions are close enough to  RFC2119 , I think that one of them should be taken off to avoid any type of confusion. Note that the (new) definitions in this document are focused around \"metrics\", which would not apply to text such as (from 2.2) \"A traffic generator SHOULD be connected to all ports on the DUT. Two tests MUST be conducted...\".",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-07-06 09:19:37-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-14 08:20:17-07:00",
    "text": "Again, I don't really understand why any of these tests are specific for data center equipment. These tests can be applied to any equipment. I think the only point is that these tests are especially important to run for data center equipment but that doesn't change the fact that the test itself are not specific for data center equipment. The reason why it's a discuss this time, is that I further really don't understand why existing tests have to be specified again is this document even though a test for that case already exists that specifies exactly the same thing in another RFC; I'm talking about Section 5 on Head of Line Blocking that specifies the same test as in section 5.5 of  RFC2889  (there called Congestion Control which a confusing term because this doesn't address end-to-end congestion control, anyway...). I didn't check if that's also the case for any of the other tests.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-02-07 06:45:32-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-06 10:40:50-08:00",
    "text": "If I understand correctly, in JMAP transport confidentiality is required to use for requests and in WebSocket it is required to implement but not required to use. Which set of requirements applies to the binding specified in this document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-17 16:23:48-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-07 13:08:25-08:00",
    "text": "I support Alissa's Discuss and suggest an approach of making a definitive statement about \"wss://\" usage, akin to  RFC 8620 's \"All HTTP requests MUST use the 'https://' scheme\". I don't understand how adding a \"pushState\" value to the StateChange object (Section 4.2.4.1) that reflects the state of \"ALL of the data types in the account\" can work, if the regular StateChange and notification flows are not tied to a specific account (and in fact the example in Section 7.1.1 of  RFC 8620  includes state changes about multiple accounts in a single StateChange) but rather the authentication credentials.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-18 16:15:54-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-03 06:58:37-08:00",
    "text": "Section 5.2.\u00a0 Per \u201cSample video test sequences are available at: [xiph-seq] and [HEVC-seq].\u00a0 The following two video streams are the recommended minimum for testing: Foreman and FourPeople.\u201d, these test sequences seems underspecified. ** Is the \u201crecommended\u201d here intended to be normative?\u00a0 There is no  RFC2119  boiler plate in this document to guide the parsing of the text. ** From the text, there wasn\u2019t much precision in where to find these recommended videos (Foreman and FourPeople).\u00a0 At the url pointed to by [HEVC-seq], I found the filenames \u201cFourPeople_1280x720_60.yuv\u201d and \u201cforeman15_4000.yuv\u201d, is that them? ** Is it expected for  http://www.netlab.tkk.fi/~varun/test_sequences/foreman15_4000.yuv  to be 0 bytes?\u00a0 I tried on 03/03/2020 at ~0950 EST ** Give that that one of the recommended urls doesn\u2019t work even before this draft is published, I have great reservation with keeping a normative \u201crecommended\u201d to such external repositories.\u00a0 However, providing pointers to repositories of \u201csample video test sequences\u201d makes sense to me and is helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-10-07 17:09:54-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-07 14:15:12-07:00",
    "text": "\"If a Shutdown Communication longer than 128 octets is sent to a BGP \u00a0  speaker that implements [ RFC8203 ], then that speaker will treat it as \u00a0  an error, the consequence of which is a log message.\u00a0 For this \u00a0  reason, operators would be wise to keep shutdown communications to \u00a0  less than 128 octets when feasible.\" I have a similar question to what \u00c9ric asked. Doesn't the above mostly undercut the value of doing this bis at all? If operators can't expect longer messages to be understood, under what circumstances will they send them? I'm not at all steeped in BGP operations, but was it considered to instead add a new subcode to the BGP Cease NOTIFICATION subcode registry to capture this case (admin reset or shutdown with long shutdown message)? That way at least those who want to use it can differentiate between recipients that don't support  RFC 8203 , those that do, and those that support longer communications.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:21:41-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-07 17:09:54-07:00",
    "text": "\"If a Shutdown Communication longer than 128 octets is sent to a BGP \u00a0  speaker that implements [ RFC8203 ], then that speaker will treat it as \u00a0  an error, the consequence of which is a log message.\u00a0 For this \u00a0  reason, operators would be wise to keep shutdown communications to \u00a0  less than 128 octets when feasible.\" I have a similar question to what \u00c9ric asked. Doesn't the above mostly undercut the value of doing this bis at all? If operators can't expect longer messages to be understood, will they implement some kind of policy logic or heuristics to decide when to try to send them and when not? Otherwise, under what circumstances will they send them? Was it considered to instead add a new subcode to the BGP Cease NOTIFICATION subcode registry to capture this case (admin reset or shutdown with long shutdown message)? That way at least those who want to use it can differentiate between recipients that don't support  RFC 8203 , those that do, and those that support longer communications. I'm not at all steeped in BGP so I'm happy to drop this if it's unworkable, but I wanted to ask.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-15 16:17:43-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 15:15:03-08:00",
    "text": "Section 3 Security and Encryption: Though 6LoWPAN basic specifications do \u00a0 \u00a0 \u00a0 not address security at the network layer, the assumption is that \u00a0 \u00a0 \u00a0 L2 security must be present.\u00a0 In addition, application-level \u00a0 \u00a0 \u00a0 security is highly desirable.\u00a0 The working groups [IETF_ace] and \u00a0 \u00a0 \u00a0 [IETF_core] should be consulted for application and transport \u00a0 \u00a0 \u00a0 level security.\u00a0 The 6lo working group has worked on address \u00a0 \u00a0 \u00a0 authentication [ RFC8928 ] and secure bootstrapping is also being \u00a0 \u00a0 \u00a0 discussed in the IETF.\u00a0 However, there may be other security \u00a0 \u00a0 \u00a0 mechanisms available in a deployment through other standards such \u00a0 \u00a0 \u00a0 as hardware-level security or certificates for the initial booting \u00a0 \u00a0 \u00a0 process.\u00a0 Encryption is important if the implementation can afford \u00a0 \u00a0 \u00a0 it. With the exception of authentication and secure bootstrapping, this text is vague on what security properties are to be considered.\u00a0 Likewise, saying \u201cencryption\u201d is not informative as it can help provide specific (but unnamed) security properties.\u00a0 What is intended is not clear.\u00a0 Specifically: -- What is the \u201cL2 security\u201d that \u201cmust be present\u201d specifically?\u00a0 What properties are being addressed (e.g., confidentiality?\u00a0 Authenticity?) -- What is \u201capplication-level security\u201d that is \u201cdesirable\u201d? -- \u201cAffordability\u201d on what dimension per the supporting encryption?\u00a0 Is that a notional budget for the application, power/battery, etc?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-23 21:04:18-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-21 07:03:01-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3543 I only had a short time to read this, but I find myself confused about the COMSEC requirements here. There is no COMSEC requirement for the signaling channel in S 2.2. DATA-002 requires a secure COMSEC protocol for the data channel. SEC-001 and SEC-002 require \"peer mutual authentication\" and \"message confidentiality, integrity, and authentication\" according to \"industry best practices\". This doesn't seem to be a requirement which I can verify or evaluate. If \"industry best practices\" were to use raw TCP, would such an implementation be conformant. I think what needs to be required here is cryptographic authentication of both sides and of the messages on both channels. Generally I would prefer to require confidentiality on both, but I could maybe see an argument for why that wasn't needed. DETAIL S 2.2. >\u00a0 \u00a0 \u00a0 \u00a0  free to attempt abbreviated security negotiation methods supported >\u00a0 \u00a0 \u00a0 \u00a0  by the protocol, such as DTLS session resumption, but MUST be >\u00a0 \u00a0 \u00a0 \u00a0  prepared to negotiate new security state with the redirection >\u00a0 \u00a0 \u00a0 \u00a0  target DOTS server.\u00a0 The authentication domain of the redirection >\u00a0 \u00a0 \u00a0 \u00a0  target DOTS server MUST be the same as the authentication domain >\u00a0 \u00a0 \u00a0 \u00a0  of the redirecting DOTS server. what is an \"authentication domain\"? S 2.4. >\u00a0 \u00a0 \u00a0 SEC-002\u00a0 Message Confidentiality, Integrity and Authenticity: DOTS >\u00a0 \u00a0 \u00a0 \u00a0  protocols MUST take steps to protect the confidentiality, >\u00a0 \u00a0 \u00a0 \u00a0  integrity and authenticity of messages sent between client and >\u00a0 \u00a0 \u00a0 \u00a0  server.\u00a0 While specific transport- and message-level security >\u00a0 \u00a0 \u00a0 \u00a0  options are not specified, the protocols MUST follow current >\u00a0 \u00a0 \u00a0 \u00a0  industry best practices for encryption and message authentication. This is not a verifiable conformance requirement",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-03-18 02:39:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 09:53:24-08:00",
    "text": "Thanks for addressing the TSV-ART comments (and thanks Joe for the review)! In-line with Joe's comment, please see some additional comments below. 1) One minor edit is required still for SIG-002: for PLMTUD the correct reference is  RFC4821 , however, as commented by Joe  RFC1191  is less reliable and therefore usually not recommended. I would recommend to re-add a reference to  RFC4821  and no reference to  RFC1191  (or only with a warning that  RFC4821  is preferred due to ICMP blocking). Further, the correct reference for datagram PLMTUD is draft-ietf-tsvwg-datagram-plpmtud. 2) Also on this text in SIG-004: \"The heartbeat interval during active mitigation could be \u00a0 \u00a0 \u00a0 negotiable, but MUST be frequent enough to maintain any on-path \u00a0 \u00a0 \u00a0 NAT or Firewall bindings during mitigation.\u00a0 When TCP is used as \u00a0 \u00a0 \u00a0 transport, the DOTS signal channel heartbeat messages need to be \u00a0 \u00a0 \u00a0 frequent enough to maintain the TCP connection state.\" As Joe commented already, different heartbeats at different layers can be used at the same time for different purposes. You can use heartbeats at the application layer to check service availability while e.g. using a higher frequent heartbeat at the transport layer to maintain firewall and NAT state. The advantage to such an approach is that there is less application layer overhead/load e.g. in scenarios where it might be expensive to wake up the application or a server is already highly loaded. Also note that the\u00a0 time-outs values of NATs and firewalls on the path are usually unknown, therefore an application can never rely on heartbeats (no matter at which level) and must be prepared to try to reconnect on the application layer if the connection fails. Usually, the main reason for using heartbeats to maintain NAT or firewall state (vs. reconnect every time) in TCP is if the application is time-sensitive and a full TCP handshake takes too long for the desired service. I'm not sure that the case for DOTS, however, I understand it may be beneficial to have established state if an attack is on-going.  For UDP I guess it's more complicated in your case. Time-outs are usually very short, however, state is created with the first packet of a flow (as there is no handshake in UDP). As you don't see blocking if state is expired as new state is created immediately, it's kind of impossible to measure the configured time-out values. Only if the firewall is under attack it would start blocking UDP traffic that is has no state for yet. So I understand why it is desirable to maintain UDP state for you, however, I don't understand how you can know that your frequency is high enough to actually keep the state open. Note that TCP time-outs are usually in the order of hours, while UDP time-outs are usually in range of tens of seconds, and might expire even quicker if a system is under attack. If that is a scenario that is important for you, and assuming that not all time-outs values on the path can be known, I guess it would be recommendable to use TCP instead.  In any case this can not be a MUST requirement (as timers are usually not known). I would recommend to state something like:  \"MAY be frequent enough to maintain NAT or firewall state, if timer values are known, or if TCP is used, SHOULD use in addition TCP heartbeats\u00a0 to maintain the TCP connection state and reconnect immediately if a failure is detected.\" And also for this part it is different for TCP and UDP: \"Because heartbeat loss is much more likely during volumetric attack, DOTS \u00a0 \u00a0 \u00a0 agents SHOULD avoid signal channel termination when mitigation is \u00a0 \u00a0 \u00a0 active and heartbeats are not received by either DOTS agent for an \u00a0 \u00a0 \u00a0 extended period.\" If TCP would be used and no ACKs are received, TCP would try to retransmit a few times and some point terminate the connection. However, UDP is a connection-less protocol, there is nothing to terminate. Also note that for reliable transports, it is sufficient if one end-hosts sends heartbeats as the other end is required to acknowledge the reception on the transport layer (and if no ack is received the connection is terminated on the transport layer).  So I guess what you want to say above is that if a connection-less protocol is used, heartbeats should continuously be sent even if no heartbeats are received from the other end. However, I think you still need to define a termination criteria, as you for sure don't want to keep sending heartbeats forever. Also the next part: \"\u00a0 \u00a0 \u00a0 *\u00a0 To handle possible DOTS server restart or crash, the DOTS \u00a0 \u00a0 \u00a0 \u00a0  clients MAY attempt to establish a new signal channel session, \u00a0 \u00a0 \u00a0 \u00a0  but MUST continue to send heartbeats on the current session so \u00a0 \u00a0 \u00a0 \u00a0  that the DOTS server knows the session is still alive.\u00a0 If the \u00a0 \u00a0 \u00a0 \u00a0  new session is successfully established, the DOTS client can \u00a0 \u00a0 \u00a0 \u00a0  terminate the current session.\" There is nothing like connection re-establishing in UDP, you just keep sending traffic. While in TCP, as explained above, the connection will be terminated at the transport layer and there is no way to keep sending heartbeats on the \"old\" session. Or do have something like DTLS in mind in this case? 3) In SIG-006 you say: \"\u00a0 \u00a0 \u00a0 Due to the higher likelihood of packet loss during a DDoS attack, \u00a0 \u00a0 \u00a0 DOTS servers MUST regularly send mitigation status to authorized \u00a0 \u00a0 \u00a0 DOTS clients which have requested and been granted mitigation, \u00a0 \u00a0 \u00a0 regardless of client requests for mitigation status.\" Please note that this is only true if a not-reliable transport is used. If a reliable transport is used, data is received at the application level without loss (but maybe some delay) or the connection is terminated (if loss is too high to retransmit successfully).",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-03-05 16:03:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-21 06:11:05-08:00",
    "text": "I think SIG-002 is a bit underspecified. It points to  draft-ietf-intarea-frag-fragile  as the recommended mechanism for discovering PMTUD, but in fact  draft-ietf-intarea-frag-fragile  is designed to provide a list of potential solutions and recommendations for application and protocol developers (Section 7.1.). So I expect this document to specify what it intends to do for fragmentation instead of a vague reference.  IPv4 does not support a minimum PMTU of 576 as claimed here.  RFC791  clearly states that the minimum PMTU is 68 octets. I suggest rewording this to OLD: DOTS implementations MAY rely on a PMTU of 576 bytes for IPv4 datagrams, as discussed in [ RFC0791 ] and [ RFC1122 ]. NEW: DOTS implementations MAY assume on a PMTU of 576 bytes for IPv4 datagrams, as every IPv4 host must be capable of receiving a packet whose length is equal to 576 bytes as discussed in [ RFC0791 ] and [ RFC1122 ].",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-03-05 16:03:30-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-05 16:03:06-08:00",
    "text": "hanks for addressing my DISCUSS and COMMENTs.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-11-15 03:25:22-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-25 06:41:35-07:00",
    "text": "Section 2 (Review of Requirements from I2RS architecture document) presents a list of \u201crequirements distilled from [ RFC7921 ]\u201d, which I initially assumed to mean that this list may have been a summary of the requirements in  RFC7921 .\u00a0 However, I can\u2019t find them in  RFC7921 ; for example: \u00a0  1.\u00a0 The I2RS protocol SHOULD support a high bandwidth, asynchronous \u00a0 \u00a0 \u00a0  interface, with real-time guarantees on getting data from an I2RS \u00a0 \u00a0 \u00a0  agent by an I2RS client. \u2026\u201dhigh bandwidth\u201d and \u201creal-time\u201d don\u2019t even appear in  RFC7921 !\u00a0 While I understand that distilling is not the same as copying, the use of  rfc2119  language in this document makes me uncomfortable because it seems to be defining requirements that may or may not conflict with  RFC7921 . If the requirements in Section 2 do come from  RFC7921 , please put the appropriate pointers in (and even better, use the same language to avoid confusion).\u00a0 If by distilling the authors may have taken the liberty to interpret the requirements from  RFC7921 , please don\u2019t use  rfc2119  language.\u00a0 If there are new or different requirements, please point them out.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-10-27 07:41:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-27 05:02:45-07:00",
    "text": "-  \u00a0  The I2RS Working Group has chosen to use the YANG data modeling \u00a0  language [ RFC6020 ] as the basis to implement its mechanisms. I guess you mean  RFC 7950 . RFC7950  should be a normative reference. -\u00a0  I read the abstract and title: clearly this is about ephemeral state. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 I2RS Ephemeral State Requirements \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   draft-ietf-i2rs-ephemeral-state-19.txt Abstract \u00a0  The I2RS (interface to the routing system) Architecture document \u00a0  ( RFC7921 ) abstractly describes a number of requirements for ephemeral \u00a0  state (in terms of capabilities and behaviors) which any protocol \u00a0  suite attempting to meet the needs of I2RS has to provide.\u00a0 This \u00a0  document describes, in detail, requirements for ephemeral state for \u00a0  those implementing the I2RS protocol. And in section 2, I see requirements \"distilled\" (btw, I agree with Alvaro's DISCUSS) from  RFC7921  about the I2RS protocol, I2RS agent, I2RS client. Why (re-hashing) requirements not related to ephemeral?  What the goal of this section 2?  It seems more like adding confusing that being helpful. Too many requirements from different documents in I2RS: \"distilling\" them between documents is looking for troubles. note: section 9 title \" Pub/Sub Requirements Expanded for Ephemeral State\" and content area clear - I read REQ3 and 4 multiple times. Isn't REQ 3 a subset of REQ4? \u00a0 \u00a0 Ephemeral-REQ-03: Ephemeral state MUST be able to have constraints \u00a0 \u00a0 \u00a0  that refer to operational state, this includes potentially fast \u00a0 \u00a0 \u00a0  changing or short lived operational state nodes, \u00a0  Ephemeral-REQ-04: Ephemeral state MUST be able to refer to non- \u00a0  ephemeral state as a constraint.\u00a0 Non-ephemeral state can be \u00a0  configuration state or operational state. I should be missing something. Examples would help me. - Clarification:  Ephemeral-REQ-12: When a collision occurs as two clients are trying \u00a0  to write the same data node I2RS clients with the I2RS protocol, or NETCONF/RESTCONF clients? Note: multiple instances of \"clients\" (as opposed to I2RS clients) in the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-12-02 06:35:45-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-27 07:41:53-07:00",
    "text": "-\u00a0  I read the abstract and title: clearly this is about ephemeral state. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 I2RS Ephemeral State Requirements \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   draft-ietf-i2rs-ephemeral-state-19.txt Abstract \u00a0  The I2RS (interface to the routing system) Architecture document \u00a0  ( RFC7921 ) abstractly describes a number of requirements for ephemeral \u00a0  state (in terms of capabilities and behaviors) which any protocol \u00a0  suite attempting to meet the needs of I2RS has to provide.\u00a0 This \u00a0  document describes, in detail, requirements for ephemeral state for \u00a0  those implementing the I2RS protocol. And in section 2, I see requirements \"distilled\" (btw, I agree with Alvaro's DISCUSS) from  RFC7921  about the I2RS protocol, I2RS agent, I2RS client. Why (re-hashing) requirements not related to ephemeral?  What the goal of this section 2?  It seems more like adding confusing that being helpful. Too many requirements from different documents in I2RS: \"distilling\" them between documents is looking for troubles. note: section 9 title \" Pub/Sub Requirements Expanded for Ephemeral State\" and content area clear - I read REQ3 and 4 multiple times. Isn't REQ 3 a subset of REQ4? \u00a0 \u00a0 Ephemeral-REQ-03: Ephemeral state MUST be able to have constraints \u00a0 \u00a0 \u00a0  that refer to operational state, this includes potentially fast \u00a0 \u00a0 \u00a0  changing or short lived operational state nodes, \u00a0  Ephemeral-REQ-04: Ephemeral state MUST be able to refer to non- \u00a0  ephemeral state as a constraint.\u00a0 Non-ephemeral state can be \u00a0  configuration state or operational state. I should be missing something. Examples would help me.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-11-14 21:33:26-08:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 15:01:36-07:00",
    "text": "Document:  draft-bormann-hybi-ws-wk-00.txt \u00a0  It has always been possible to form \"ws\" and \"wss\" URIs in such a way \u00a0  that they map to well-known HTTP(S) URIs when using the procedure in \u00a0  Section 4 of [ RFC6455 ], so no new security considerations about this \u00a0  are created by now formally making the well-known URI mechanism \u00a0  available for \"ws\" and \"wss\", as well. \u00a0   \u00a0  However, with well-known URIs becoming available for the WebSocket \u00a0  protocol, applications that want to define well-known URI suffixes \u00a0  specifically for WebSocket use also need to consider whether the \u00a0  resources becoming available under the equivalent HTTP(S) URI formed \u00a0  by Section 4 of [ RFC6455 ] pose any information disclosure or other \u00a0  security considerations. I'm not sure I am persuaded by this. The issue is that clients assume that these URIs have elevated privilege, so if it's not the case that WebSockets servers behave this way, we can't retroactively declare it. Can you explain in more detail why you think this is safe?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-05-18 00:58:17-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-04 06:47:31-07:00",
    "text": "This is mainly a processing question, so probably more for the IESG to discuss than the authors: I understand the intention of obsoleting  RFC4757  to declare that the algorithms described should not be used anymore, however,  rfc4757  is an informational implementation description which is probably still deployed. Obsoleting an informational implementation description seems a bit weird. Just would like to double-check with the rest of the IESG if that action appropriate...? Also obsoleting and moving to historic is not the same thing. The document says: \"This document recommends the reclassification of [ RFC4757 ] as Historic.\" One of the two actions (obsoleting or moving to historic) is enough. While I think moving to historic might actually be more appropriate than obsoleting an implementation description, it should only be moved to historic if this is not used and deployed anymore. Also moving to historic also requires a status change action.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-12-19 06:36:21-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-29 11:58:08-08:00",
    "text": "= Section 3.1 = I think there is a lack of clarity in the recommendations here, because \"such attributes\" aren't listed out anywhere and then later it's not clear what the \"mentioned attributes\" are referring to. I've proposed some edits below to try to clarify what I think the recommendations are saying -- does this capture the intent?  OLD However, certain SDP attributes may \u00a0  lead to call failures when forwarded by a media relay.\u00a0 Such \u00a0  attributes SHOULD NOT be forwarded.\u00a0 One notable example is the \u00a0  'rtcp' [ RFC3605 ] attribute, that UAC may make use of to explicitly \u00a0  state the port they're willing to use for RTCP.\u00a0 Considering the \u00a0  B2BUA would relay RTCP messages, the port as seen by the other UAC \u00a0  involved in the communication would differ from the one negotiated \u00a0  originally, and it MUST be rewritten accordingly.\u00a0 Apart from the \u00a0  mentioned attributes, B2BUAs SHOULD forward all other SDP attributes \u00a0  they don't have a reason not to forward, in order to avoid breaking \u00a0  additional functionality endpoints may be relying on. NEW However, certain SDP attributes may \u00a0  lead to call failures when forwarded by a media relay. One notable example is the \u00a0  'rtcp' [ RFC3605 ] attribute, that UAC may make use of to explicitly \u00a0  state the port it is willing to use for RTCP. Assuming that the \u00a0  B2BUA would relay RTCP messages, the port as seen by the other UAC \u00a0  involved in the communication would differ from the one negotiated \u00a0  originally. The 'rtcp' attribute MUST be rewritten accordingly, rather than being forwarded.\u00a0 Any other attributes known to the B2BUA to cause call failures when forwarded SHOULD NOT be forwarded. B2BUAs SHOULD forward all other SDP attributes in order to avoid breaking additional functionality endpoints may be relying on. = Section 3.2 = (1) \"It is worthwile to point out that such a B2BUA may not necessarily \u00a0  forward all the packets it receives, though.\u00a0 Selective Forwarding \u00a0  Units (SFU) [ RFC7667 ], for instance, may aggregate or drop incoming \u00a0  RTCP messages, while at the same time originating new ones on their \u00a0  own.\u00a0 For the messages that are forwarded and/or aggregated, though, \u00a0  it's important to make sure the information is coherent.\" I don't see much beyond this text that discusses the implications of dropping and aggregating RTCP messages. Is this written down in another document? If not, I'm wondering about what happens with RTCP information aside from identifiers, SSRCs, and sequence numbers in these cases. E.g., if a B2BUA drops one RTCP message containing an  RFC 7002  block but forwards the next one containing such a block, won't the interval and the discard count reported to the receiver be wrong? I assume there are a lot of cases involving XR blocks where this could be a problem, but this document doesn't address those cases. (2) \"SR:\u00a0 [ RFC3550 ] \u00a0 \u00a0 \u00a0 If the B2BUA has changed the SSRC of the sender RTP stream a \u00a0 \u00a0 \u00a0 Sender Report refers to, it MUST update the SSRC in the SR packet \u00a0 \u00a0 \u00a0 header as well.\u00a0 If the B2BUA has changed the SSRCs of other RTP \u00a0 \u00a0 \u00a0 streams too, and any of these streams are addressed in any of the \u00a0 \u00a0 \u00a0 SR report blocks, it MUST update the related values in the SR \u00a0 \u00a0 \u00a0 report blocks as well.\u00a0 If the B2BUA has also changed the base RTP \u00a0 \u00a0 \u00a0 sequence number when forwarding RTP packets, then this change \u00a0 \u00a0 \u00a0 needs to be properly addressed in the 'extended highest sequence \u00a0 \u00a0 \u00a0 number received' field in the Report Blocks.\" Why is the recommendation about the extended highest sequence number received not also a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-20 04:23:52-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-29 05:14:39-08:00",
    "text": "intro: Including the LI example in section 1 seems wrong given  RFC2804 . And I don't see why you need it if there are other justifications that are not controversial in the IETF. Why not just delete that? (The problem with including that justification in a standards track document is that doing so goes entirely against  RFC2804 .) But this should be an easy fix, via a revised ID or RFC editor note.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-08-29 14:19:29-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 23:37:07-07:00",
    "text": "Thanks to everyone who invested time in developing this mechanism. I have two blocking comments that should be quite easy to resolve. --------------------------------------------------------------------------- \u00a75: >\u00a0 MASA URI is \"https://\" iauthority \"/.well-known/est\". This doesn't make sense: iauthority is a component of IRIs, not of URIs. In URIs this is simply an \"authority.\" It's not simply a terminology distinction: converting from an iauthority to an authority requires idna encoding. Please consult with an IRI expert (which I do not consider myself to be) to work out the proper terminology and procedures here.\u00a0 If you need help finding an expert, please let me know and I'll track someone down for you. --------------------------------------------------------------------------- \u00a75.8: >\u00a0 Rather than returning the audit log as a response to the POST (with a >\u00a0 return code 200), the MASA MAY instead return a 201 (\"Created\") >\u00a0 RESTful response ([ RFC7231 ] section 7.1) containing a URL to the >\u00a0 prepared (and easily cachable) audit response. The DISCUSS portion of my comment on this text is that it is unclear about how the URL is to be returned. It can just as easily be interpreted as returning it in a \"Location\" header field as it could as returning it in the response body -- or maybe somewhere else entirely (e.g., a link relation).\u00a0 This ambiguity will cause an interop issue. Please be explicit about precisely how the value is conveyed. While not part of the DISCUSS, I also have a fairly serious comment on the phrasing and citation of\u00a0 \"return a 201 (\"Created\") RESTful response ([ RFC7231 ] section 7.1)\". Section 7.1 points to the top-level discussion of Control Data header fields, rather than any general discussion of RESTful responses.\u00a0 It's worth noting that the term \"RESTful\" never appears in  RFC 7231 , so it's really unclear what section this was attempting to target. Perhaps 6.3.2?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-11 06:23:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-11 06:20:30-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. 1) In Section 5: \u00a0  o\u00a0 In the language of [ RFC6125 ] this provides for a SERIALNUM-ID \u00a0 \u00a0 \u00a0 category of identifier that can be included in a certificate and \u00a0 \u00a0 \u00a0 therefore that can also be used for matching purposes.\u00a0 The \u00a0 \u00a0 \u00a0 SERIALNUM-ID whitelist is collated according to manufacturer trust \u00a0 \u00a0 \u00a0 anchor since serial numbers are not globally unique. I think now you are just inventing things. Please define what exactly SERIALNUM-ID is. Cut & paste text from  RFC 6125 , if needed. 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? 3) In 5.8 \u00a0  This is done with an HTTP GET using the operation path value of \u00a0  \"/.well-known/est/requestauditlog\". Here you say to use HTTP GET. \u00a0  The registrar SHOULD HTTP POST the same registrar voucher-request as But you only define how to use POST. I think the first \"GET\" is supposed to be \"POST\". 4) In 5.8.1: Format of different fields is not defined, so this is not interoperable. 5) In 8.1: \u00a0  This document extends the definitions of \"est\" (so far defined via \u00a0   RFC7030 ) in the \" https://www.iana.org/assignments/well-known-uris/ \u00a0  well-known-uris.xhtml\" registry as follows: \u00a0  o\u00a0 add /.well-known/est/requestvoucher (see Section 5.5 ) \u00a0  o\u00a0 add /.well-known/est/requestauditlog (see Section 5.7) The .well-known URIs IANA registry doesn't list anything below the first level (i.e. \"est\" in your case). So I think you really want to have 2 IANA actions here: a) Add the reference to this document as another reference for \"est\". b) create a new registry of \"est\" URIs and add your 2 URIs above to it and also populate other entries from the original EST RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-15 02:30:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-11 06:23:05-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) In Section 5: \u00a0  o\u00a0 In the language of [ RFC6125 ] this provides for a SERIALNUM-ID \u00a0 \u00a0 \u00a0 category of identifier that can be included in a certificate and \u00a0 \u00a0 \u00a0 therefore that can also be used for matching purposes.\u00a0 The \u00a0 \u00a0 \u00a0 SERIALNUM-ID whitelist is collated according to manufacturer trust \u00a0 \u00a0 \u00a0 anchor since serial numbers are not globally unique. I think now you are just inventing things. Please define what exactly SERIALNUM-ID is. Cut & paste text from  RFC 6125 , if needed. 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? 3) In 5.8 \u00a0  This is done with an HTTP GET using the operation path value of \u00a0  \"/.well-known/est/requestauditlog\". Here you say to use HTTP GET. \u00a0  The registrar SHOULD HTTP POST the same registrar voucher-request as But you only define how to use POST. I think the first \"GET\" is supposed to be \"POST\". 4) In 5.8.1: Format of different fields is not defined, so this is not interoperable. 5) In 8.1: \u00a0  This document extends the definitions of \"est\" (so far defined via \u00a0   RFC7030 ) in the \" https://www.iana.org/assignments/well-known-uris/ \u00a0  well-known-uris.xhtml\" registry as follows: \u00a0  o\u00a0 add /.well-known/est/requestvoucher (see Section 5.5 ) \u00a0  o\u00a0 add /.well-known/est/requestauditlog (see Section 5.7) The .well-known URIs IANA registry doesn't list anything below the first level (i.e. \"est\" in your case). So I think you really want to have 2 IANA actions here: a) Add the reference to this document as another reference for \"est\". b) create a new registry of \"est\" URIs and add your 2 URIs above to it and also populate other entries from the original EST RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-16 09:14:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-15 02:30:30-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) In Section 5: \u00a0  o\u00a0 In the language of [ RFC6125 ] this provides for a SERIALNUM-ID \u00a0 \u00a0 \u00a0 category of identifier that can be included in a certificate and \u00a0 \u00a0 \u00a0 therefore that can also be used for matching purposes.\u00a0 The \u00a0 \u00a0 \u00a0 SERIALNUM-ID whitelist is collated according to manufacturer trust \u00a0 \u00a0 \u00a0 anchor since serial numbers are not globally unique. I think now you are just inventing things. Please define what exactly SERIALNUM-ID is. Cut & paste text from  RFC 6125 , if needed. 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? 3) Resolved 4) In 5.8.1: Format of different fields is not defined, so this is not interoperable. 5) In 8.1: \u00a0  This document extends the definitions of \"est\" (so far defined via \u00a0   RFC7030 ) in the \" https://www.iana.org/assignments/well-known-uris/ \u00a0  well-known-uris.xhtml\" registry as follows: \u00a0  o\u00a0 add /.well-known/est/requestvoucher (see Section 5.5 ) \u00a0  o\u00a0 add /.well-known/est/requestauditlog (see Section 5.7) The .well-known URIs IANA registry doesn't list anything below the first level (i.e. \"est\" in your case). So I think you really want to have 2 IANA actions here: a) Add the reference to this document as another reference for \"est\".  -- This was addressed. b) create a new registry of \"est\" URIs and add your 2 URIs above to it and also populate other entries from the original EST RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-16 09:22:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-16 09:14:15-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) Resolved 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? \u2014 I couldn\u2019t quite figure out what was changed from wdiff. I don\u2019t think this was addressed. 3) Resolved 4) In 5.8.1: Format of different fields is not defined in enough details, so this is not interoperable. Please specify what format is used for dates and nonces. 5) Resolved",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-17 04:17:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-16 09:22:17-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) Resolved 2) Resolved 3) Resolved 4) In 5.8.1: Format of different fields is not defined in enough details, so this is not interoperable. Please specify what format is used for dates and nonces. 5) Resolved",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-10-16 03:42:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-17 04:17:15-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) Resolved 2) Resolved 3) Resolved 4) In 5.8.1: Format of different fields is not defined in enough details, so this is not interoperable. Are numeric fields always represented as JSON numbers? 5) Resolved",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-10-16 07:49:58-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 13:42:22-07:00",
    "text": "I apologize if I'm misunderstanding how this works, but I didn't see much discussion in the document about the implications of the manufacturer going out of business. Specifically, it seems like if a device ships with BRSKI as its only available mechanism for bootstrapping and the manufacturer goes out of business before the device is enrolled, the ability for the device to function securely on the network may be significantly impaired if not impossible. It seems like this document needs to make clear to manufacturers that a fallback manual enrollment mechanism of some sort needs to be implemented along with BRSKI in order to avoid this situation. = Section 1.3.1 = \"But this solution is not exclusive to large equipment: it is intended \u00a0  to scale to thousands of devices located in hostile environments, \u00a0  such as ISP provided CPE devices which are drop-shipped to the end \u00a0  user.\" I don't quite understand how this squares with the scope limitation described in Section 1 and Section 9. If the whole network is professionally managed by the ISP, what part would be the \"hostile environment\"?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:49:43-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-16 07:56:11-07:00",
    "text": "Apologies for the multiple emails, I failed to realize there was a new Gen-ART review for this document. The follow-up from the Gen-ART review seems to indicate that a YANG doctor review of this document is needed and/or that the YANG issues raised by Tom Petch need fixing. Is there a plan to get either of those done?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-17 07:08:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 22:30:04-07:00",
    "text": "(1) The text of the document suffers from lack of clarity throughout about whether the nonce-ful operation is mandatory or not, with several figures and discussions making declarative statements about nonce usage and others saying that nonce usage is optional. (See COMMENT.) (2) There also seems to be internal inconsistency about the proximity assertion process (and, any sort of assertion in a voucher-request at all, it seems).\u00a0 I've tried to note some locations in the Comment section. (3) There are other internal inconsistencies as well, including about section references for when various behaviors occur (see COMMENT). (4) In Section 5.6.1 \u00a0  The pledge MUST verify that the voucher nonce field is accurate and \u00a0  matches the nonce the pledge submitted to this registrar, or that the \u00a0  voucher is nonceless (see Section 7.2). Is the pledge supposed to accept a nonceless voucher in response to a nonce-ful voucher request? (5)  RFC7951  is cited for the audit log response, but I cannot find the underlying YANG module that is JSON-encoded using the  RFC 7951 procedures. Furthermore, I don't think the \"nonce\" handling (with explicit \"NULL\" string where base64-encoded binary data might be expected) would be consistent with the 7951 rules. (5) the new /enrollstatus EST endpoint seems under-specified. (6) In Section 7.2: \u00a0  The pledge can choose to accept vouchers using less secure methods. \u00a0  These methods enable offline and emergency (touch based) deployment \u00a0  use cases: \u00a0  1.\u00a0 The pledge MUST accept nonceless vouchers.\u00a0 This allows for a use It's very unclear to me what this \"MUST\" means, especially so given that the entire section 7 is declared to be non-normative.\u00a0 Is it that the client \"can choose\" whether it \"MUST accept nonceless vouchers\"? That would seem to make the MUST basically ineffective. More broadly, if the entire Section 6 is non-normative, why is there any normative language in it? (7) the new /enrollstatus and /voucher_status well-known EST endpoints are not registered in Section 8.1 (7.1) I think we also need to register the \"urn:ietf:params:xml:ns:yang:ietf-mud-brski-masa\"\u00a0 XML namespace. (8) The versioning mechanism for Pledge BRSKI Status Telemetry is underspecified, including the interaction with new registered values. (9) The versioning mechainsm for the MASA audit log response is underspecified, including whether a registry of field names is appropriate. (10) The term PKIX seems to be incorrectly used a few times; it refers to the Internet PKI, and so things like a private PKI internal to a manufacturer would probably not be best described as such.\u00a0 Such private PKIs can of course still reuse the protocols and mechanisms developed for PKIX, and it's accurate to describe them as such. (11) In a few places we describe the voucher-request in terms of its YANG structure but do not say that it has to be wrapped in a signed CMS object as is done for the  RFC 8366  voucher. (12) Maybe this is a \"discuss discuss\", but why do we need SHA-1 in the domainID calculation? (13) In Section 5.5.1: \u00a0  As described in [ RFC8366 ] vouchers are normally short lived to avoid \u00a0  revocation issues.\u00a0 If the request is for a previous (expired) \u00a0  voucher using the same registrar then the request for a renewed \u00a0  voucher SHOULD be automatically authorized.\u00a0 The MASA has sufficient I don't understand what \"for a previous (expired) voucher\" means. Is it something like \"containing the same content as a previous voucher request for which a voucher was issued\", with the presumption that the voucher expired before the pledge could successfully imprint, so it needs to try again?\u00a0 Or does this extend to longer timescales, like a device that gets deployed for a couple years and is\u00a0 then reset to factory settings and has to rebootstrap but is still by the same registrar? (14) In Section 5.6: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 The server MUST answer with a suitable 4xx \u00a0  or 5xx HTTP [ RFC2616 ] error code when a problem occurs.\u00a0 In this \u00a0  case, the response data from the MASA MUST be a plaintext human- \u00a0  readable (ASCII, English) error message containing explanatory \u00a0  information describing why the request was rejected. It seems hard to support this stance on internationalization in 2019. (15) In Section 5.9.4: \u00a0  To indicate successful enrollment the client SHOULD re-negotiate the \u00a0  EST TLS session using the newly obtained credentials.\u00a0 This occurs by \u00a0  the client initiating a new TLS ClientHello message on the existing \u00a0  TLS connection.\u00a0 The client MAY simply close the old TLS session and \u00a0  start a new one.\u00a0 The server MUST support either model. Is this supposed to be sending a new TLS ClientHello in the application data channel or as a new handshake message (aka \"renegotiation\")?\u00a0 The latter is not possible in TLS 1.3 and is generally disrecommended anyways even in TLS 1.2.\u00a0 I would strongly suggest to remove the \"renegotiation\" option and just leave \"close the connection and start a new connection/handshake\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-17 18:25:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-17 07:08:34-07:00",
    "text": "Thanks for the time and attention to detail put into addressing my previous Discuss and Comment points.\u00a0 I have one new Discuss-level point and one that I think may have been missed (probably because I inadvertently numbered two points with the same number). (16) The audit log response (Section 5.8.1) describes the nonce as a JSON string, but the  RFC 8366  nonce is a binary value.\u00a0 I think we need to describe some mapping procedure (such as always base64-encoding as is done for domainID, even if the original nonce is itself base64-encoded random data) in order to be fully functional. % (1) The text of the document suffers from lack of clarity throughout about % whether the nonce-ful operation is mandatory or not, with several % figures and discussions making declarative statements about nonce usage % and others saying that nonce usage is optional. (See COMMENT.) [keep in mind when reading] % (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-23 22:35:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-17 18:25:00-07:00",
    "text": "Thanks for the time and attention to detail put into addressing my previous Discuss and Comment points.\u00a0 I have one new Discuss-level point and one that I think may have been missed (probably because I inadvertently numbered two points with the same number). (16) The audit log response (Section 5.8.1) describes the nonce as a JSON string, but the  RFC 8366  nonce is a binary value.\u00a0 I think we need to describe some mapping procedure (such as always base64-encoding as is done for domainID, even if the original nonce is itself base64-encoded random data) in order to be fully functional. % (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-28 20:53:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-23 22:35:24-07:00",
    "text": "Thanks for the time and attention to detail put into addressing my previous Discuss and Comment points.\u00a0 I have one new Discuss-level point and one that I think may have been missed (probably because I inadvertently numbered two points with the same number). (16) The audit log response (Section 5.8.1) describes the nonce as a JSON string, but the  RFC 8366  nonce is a binary value.\u00a0 I think we need to describe some mapping procedure (such as always base64-encoding as is done for domainID, even if the original nonce is itself base64-encoded random data) in order to be fully functional. % (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object. Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-20 14:31:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-28 20:53:53-07:00",
    "text": "% (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object. The -29 reworks the definition of the 'nonce' field to be: \u00a0 \u00a0 \u00a0 strong random or pseudo-random number nonce (see [ RFC4086 ] section \u00a0 \u00a0 \u00a0 6.2).\u00a0 As the nonce is usually generated very early in the boot \u00a0 \u00a0 \u00a0 sequence there is a concern that the same nonce might generated \u00a0 \u00a0 \u00a0 across multiple boots, or after a factory reset.\u00a0 Difference \u00a0 \u00a0 \u00a0 nonces MUST NOT generated for each bootstrapping attempt, whether \u00a0 \u00a0 \u00a0 in series or concurrently.\u00a0 The freshness of this nonce mitigates \u00a0 \u00a0 \u00a0 against the lack of real-time clock as explained in Section 2.6.1. This needs to either be \"Different nonces MUST be generated\" or \"the same nonce MUST NOT be reused\"; this mashup is no good. Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-03 10:43:47-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-20 14:31:04-08:00",
    "text": "Thanks for providing a clear specification of the /enrollstatus EST endpoint in the -30.\u00a0 The following two points still seem unaddressed, though. The -29 reworks the definition of the 'nonce' field to be: \u00a0 \u00a0 \u00a0 strong random or pseudo-random number nonce (see [ RFC4086 ] section \u00a0 \u00a0 \u00a0 6.2).\u00a0 As the nonce is usually generated very early in the boot \u00a0 \u00a0 \u00a0 sequence there is a concern that the same nonce might generated \u00a0 \u00a0 \u00a0 across multiple boots, or after a factory reset.\u00a0 Difference \u00a0 \u00a0 \u00a0 nonces MUST NOT generated for each bootstrapping attempt, whether \u00a0 \u00a0 \u00a0 in series or concurrently.\u00a0 The freshness of this nonce mitigates \u00a0 \u00a0 \u00a0 against the lack of real-time clock as explained in Section 2.6.1. This needs to either be \"Different nonces MUST be generated\" or \"the same nonce MUST NOT be reused\"; this mashup is no good. Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-24 11:25:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-01-03 10:43:47-08:00",
    "text": "I think we're down to just: Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-30 17:03:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-24 11:25:17-08:00",
    "text": "Thanks for the updated examples using the allocated MASA URL extension OID! Unfortunately, I think there are still some inconsistencies in the examples to resolve: The MASA cert/key is identical to the \"manufacturer key pair for IDevID signatures\" (C.1.1 and C.1.2).\u00a0 (It shows the MASA Subject CN, so maybe  just the included file was typo'd?)\u00a0 The example IDevID cert shows an issuer name that doesn't match the cert given. (Also the MASA cert doesn't have a randomized serial number but the registrar one does.) The registrar-to-MASA voucher request in C.2.2 seems to have a CMS SignedData with the SignerIdentifier identifying the \"Unstrung Fountain Root\" (i.e,. the root CA used for these examples) instead of the expected \" fountain-test.example.com \".\u00a0 Am I misreading the ASN.1 dump? (We do seem to send both certificates.) The voucher response from MASA to Registrar seems to be signed by the \" highway-test.example.com  CA\" (which would be the \"manufacturer key pair for IDevID signatures\" that we don't have in the -35 since the MASA certificate is repeated), not the MASA's cert from C.1.1.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-02 18:56:08-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-30 17:03:27-07:00",
    "text": "Thanks for the updates leading to the -39; I believe we're almost there! Unfortunately, it seems that the \"pinned-domain-cert\" in the issued voucher is the registrar's cert, not the CA cert.\u00a0 (Given that the documented workflow is to extract this CA cert from the registrar-voucher-request CMS object, and the registrar-voucher-request in our examples does include both the registrar cert and the CA cert, I wonder if this reflects a bug in the code itself used to generate the examples, in that it picks the wrong cert?)\u00a0 My understanding is that the protocol requires this field to be populated by a CA cert, and the registrar's cert is not a CA cert. I am very hopeful that we can just regenerate the voucher without having to redo the rest of the examples, since we have all the keys and certificate enshrined in the document already, and my apologies for not noticing whether this issue was present in previous revisions as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-08-30 00:47:09-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 03:25:08-07:00",
    "text": "Thank you (and so many friends in the authors' list!) for the work put into this document; it took a while to get to this stage ;-) The intersection with MUD is also a nice feature. I have a couple of DISCUSSes (probably easy to fix) and _several_ COMMENTs and some nits (after a couple of nits, I stopped marking them). I also stopped writing COMMENTs after section 5.3. Regards, -\u00e9ric == DISCUSS == TLS is assumed to be used but I failed to find WHICH version of TLS MUST be used. The only reference in the reference section is version 1.2. Probably worth to refer to this version in the text as well and use version 1.3 of TLS. -- Section 2.3.1 -- Does the \"serial number\" need to be unique per vendor ? I guess so then I strongly suggest to use a different word than \"serial number\" (e.g. unique device ID) as a vendor can have multiple products in its portfolio, each having a different set of unique \"serial numbers\". -- Section 3.3 -- The example 1 does not include the mandatory (per YANG module) serial-number. It should also state that the cert is not included for saving space in this document. -- Section 4.1 -- There are TWO back-off mechanisms: one for the method and one for the proxy but no description on how those mechanisms interact together. -- Section 4.3 -- Probably a naive question about GRASP (that I do not know), but in the example there is \"IPPROTO_TCP, 80\" that seems to indicate the use of plain HTTP and no TLS at all. Is it an issue ? Is there a reason why IPv6 ULA are used rather than the documentation prefix ?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-07-15 02:43:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-11 06:40:28-07:00",
    "text": "Hi,  A. This is really a discuss discuss. With to little time to dig into the details it appears that this protocol is making i hack of its interface towards the its transport. It appears to attempt to use an HTTP rest interface, but then it is also have a lot of talking about requirement for the TLS connection underlying the HTTP. So to illustrate the issue I see here is what happens if one like to use QUIC as the underlying transport for the rest interface rather than TCP/TLS? So can this document achieve a clearer interface to the lower layers so that it will be simpler to move the protocol to another underlying version of the HTTP \"transport\"?  B. Section 5.6:  The server MUST answer with a suitable 4xx \u00a0  or 5xx HTTP [ RFC2616 ] error code when a problem occurs. Referencing  RFC 2616  that has been obsolete by  RFC 7230  and companions. I do note that there are no normative reference for that part in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-10 09:14:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 09:13:50-07:00",
    "text": "I support Eric\u2019s Discuss position. Also a big thanks to Christian Huitema\u2019s thorough SECDIR reviews and the associated improvements made as a result.\u00a0 I have a few more items:  (1) Section 5.7.\u00a0 The format of a pledge status telemetry message seems underspecified.  ** what are all of the fields (e.g., version appears in the example but no the text) ** what are the field formats (e.g., the format of the status field is inferred from the unlabeled example ** which fields are mandatory? ** Per the JSON snippet, is that normative is some way in describing the format? ** Also, how does a server receiving the telemetry messages behave when receiving unexpected JSON attributes?  (2) Section 5.8.1.\u00a0 The format of the MASA audit log seems underspecified.\u00a0 Is the JSON snippet presented here normative to describe the MASA audit log response? (3) Why is Section 7.x in this document if it explains how to use BRSKI but is considered non-normative?  -- How should implementers take this language? -- Why are normative sections, like Section 11, discussing it? (4) Thank you for documenting \u201cmanufacturer control issues\u201d in Sections 10.3 and 10.4.\u00a0 It helpfully lays justifies the current design approach.\u00a0 I strongly concur with the premise that \u201cfacilitate[ing] a few new operat[i]onal modes without making any changes to the BRSKI protocol\u201d is exactly what is needed.\u00a0  My concern is that even with the current applicability statement in Section 9, the current text appears to have only standardized the first part of the lifecycle that BRSKI equipment might see -- equipment on first sale as long as the manufacturer supports it or stays in business.\u00a0 The text doesn\u2019t appear to cover the practical aspects of the proposed mitigations in Section 10.5 or the situations described in Section 10.3/10.4 \u2013 various situations possible in the full lifecycle usage of a BRSKI device and needed support the \u201cadditional operational modes\u201d.\u00a0 Specifically: ** There appears to be little discussion on how owners/manufacturers/vendors can facilitate second sale/used equipment beyond narrative words (in Section 10.3 and 10.4) ** There is appears to be little discussion on how to practically implement a MASA (i.e., the offline use case).\u00a0 For example, (Per Section 10.5) \u201cA manufacturer could provide a mechanism to manage the trust anchors and built-in certificates (IDevID) as an extension.\u00a0 This is a substantial amount of work, and may be an area for future standardization work\u201d.\u00a0 Without the ability to change anchors on the device the additional operational modes such as offline mode seems challenging.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-16 18:08:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 09:14:30-07:00",
    "text": "I support Eric\u2019s Discuss position. Also a big thanks to Christian Huitema\u2019s thorough SECDIR reviews and the associated improvements made as a result.\u00a0 I have a few more items:  (1) Section 5.7.\u00a0 The format of a pledge status telemetry message seems underspecified.  ** what are all of the fields (e.g., version appears in the example but no the text) ** what are the field formats (e.g., the format of the status field is inferred from the unlabeled example ** which fields are mandatory? ** Per the JSON snippet, is that normative is some way in describing the format? ** Also, how does a server receiving the telemetry messages behave when receiving unexpected JSON attributes?  (2) Section 5.8.1.\u00a0 The format of the MASA audit log seems underspecified.\u00a0 Is the JSON snippet presented here normative to describe the MASA audit log response? (3) Why is Section 7.x in this document if it explains how to use BRSKI but is considered non-normative?  -- How should implementers take this language? -- Why are normative sections, like Section 11, discussing it? (4) Thank you for documenting \u201cmanufacturer control issues\u201d in Sections 10.3 and 10.4.\u00a0 It helpfully lays justifies the current design approach.\u00a0 I strongly concur with the premise that \u201cfacilitate[ing] a few new operat[i]onal modes without making any changes to the BRSKI protocol\u201d is exactly what is needed.\u00a0  My concern is that even with the current applicability statement in Section 9, the current text appears to have only standardized the first part of the lifecycle that BRSKI equipment might see -- equipment on first sale as long as the manufacturer supports it or stays in business.\u00a0 The text doesn\u2019t appear to cover the practical aspects of the proposed mitigations in Section 10.5 or the situations described in Section 10.3/10.4 \u2013 various situations possible in the full lifecycle usage of a BRSKI device and needed support the \u201cadditional operational modes\u201d.\u00a0 Specifically: ** There appears to be little discussion on how owners/manufacturers/vendors can facilitate second sale/used equipment beyond narrative words (in Section 10.3 and 10.4) ** There is appears to be little discussion on how to practically implement a MASA (i.e., the offline use case).\u00a0 For example, (Per Section 10.5) \u201cA manufacturer could provide a mechanism to manage the trust anchors and built-in certificates (IDevID) as an extension.\u00a0 This is a substantial amount of work, and may be an area for future standardization work\u201d.\u00a0 Without the ability to change anchors on the device the additional operational modes such as offline mode seems challenging.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-05 15:21:22-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-16 18:08:51-07:00",
    "text": "One remaining item of clarity in the Section 7 from my previous DISCUSS position: ** Section 7.\u00a0 Per \u201cThis section is considered non-normative in the generality of the protocol.\u00a0 Use of the suggested mechanism here MUST be detailed in specific profiles of BRSKI, such as in Section 9.\u201d -- Can you please clarify \u201cnon-normative in the generality of the protocol\u201d?\u00a0 If I take the perspective of an implementer, it seems like a black-and-white issue \u2013 either this section is normative or not (I either have to conform or not).\u00a0  -- what this MUST is requiring isn\u2019t clear.\u00a0 Practically, why would using any of these mechanisms in this section require further elaboration? I\u2019d offer an alternative introduction to this section to address these ambiguities: OLD \u00a0  A common requirement of bootstrapping is to support less secure \u00a0  operational modes for support specific use cases.\u00a0 The following \u00a0  sections detail specific ways that the pledge, registrar and MASA can \u00a0  be configured to run in a less secure mode for the indicated reasons. \u00a0  This section is considered non-normative in the generality of the \u00a0  protocol.\u00a0 Use of the suggested mechanism here MUST be detailed in \u00a0  specific profiles of BRSKI, such as in Section 9. NEW A common requirement of bootstrapping is to support less secure operational modes for support specific use cases.\u00a0 This section suggests a range of mechanisms that would alter the security assurance of BRSKI to accommodate alternative deployment architectures and mitigate lifecycle management issues identified in Section 10.4 \u2013 10.7.\u00a0 They are presented here as informative (non-normative) design guidance for future standardization activities.\u00a0 It would be expected that subsets of these mechanisms could be profiled with an accompanying applicability statements similar to the one described in Section 9.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-06-21 11:15:41-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-19 12:07:17-07:00",
    "text": "* Section 4.2. I found the explanation to be useful but the prefix that was not selected seems to be wrong (a prefix with non-zero bits past the prefix length does not really make sense). The prefix that is adjacent to 64:ff9b::/96 is actually 64:ff9a:ffff::/48 and not 64:ff9a:ffff:ffff::/48 as described in the document. This means that most of the text that follows is incorrect. i.e. The range will be 64:ff9a:ffff:: - 64:ff9b::ffff:ffff and not 64:ff9a:ffff:ffff:: - 64:ff9b::ffff:ffff P.S.: I thought hard about whether this should be a DISCUSS or a COMMENT but I decided to go with a DISCUSS because I think it really needs to be fixed",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-01-04 06:28:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 18:30:13-08:00",
    "text": "** Section 4.2.1. The example has a few easy to fix issues: --\u00a0 Typo in JSON.\u00a0 Missing comma between array elements in \u201cids\u201d OLD \u00a0 \u00a0 \u00a0 \"ids\" : [ \u00a0 \u00a0 \u00a0 \u00a0 \"Gc0854fb9fb03c41cce3802cb0d220529e6eef94e\" \u00a0 \u00a0 \u00a0 \u00a0 \"not-a-blob\" \u00a0 \u00a0 \u00a0 ], NEW \u00a0 \u00a0 \u00a0 \"ids\" : [ \u00a0 \u00a0 \u00a0 \u00a0 \"Gc0854fb9fb03c41cce3802cb0d220529e6eef94e\", \u00a0 \u00a0 \u00a0 \u00a0 \"not-a-blob\" \u00a0 \u00a0 \u00a0 ], -- The second request (\u201cR2\u201d) sets properties of \u201cdata:asText\u201d and \u201cdata:asBase64\u201d.\u00a0 However, the response only returns a value for \u201cdata:asText\u201d.\u00a0 Shouldn\u2019t it have returned the same data in both formats? ** Section 5 \u00a0  If a server might sometimes return all names empty rather than \u00a0  putting a blobId in the notFound response to a Blob/get, then the \u00a0  server SHOULD always return the same type of response, regardless of \u00a0  whether a blob exists but the user can't access it, or doesn't exist \u00a0  at all.\u00a0 This avoids leaking information about the existence of the \u00a0  blob. Can these behaviors be clarified?\u00a0  -- If this text introducing a new, normative behavior that if a blobId is not found or the user isn\u2019t authorized, a get query response could just be both an empty \u201clist\u201d and \u201cnotFound\u201d?\u00a0 I don\u2019t see that described elsewhere. -- The consistency in behavior for not found and or not authorized makes sense exactly for the reason described.\u00a0 Therefore, why the SHOULD?\u00a0 What would be the circumstances where leaking the existence of the blob is acceptable?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-06-29 16:12:53-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-28 20:41:18-07:00",
    "text": "I do think this is a good mechanism to transition from IPv4-only OSPFv2 to dual-stack capable OSPFv3 and I intend to switch to a Yes once my discuss points are addressed.  * The calculation for the checksum field in the OSPFv3 packet is not specified in this document. The  RFC5340  checksum calculation uses the IPv6 pseudo-header mechanism for upper layer checksums as specified in Section 8.1 of  RFC2460 . Since that obviously won't work here (as there are no source and dest IPv6 addresses) some different mechanism needs to be specified here. * (based on the above) Why doesn't this document update  RFC5340 ?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-10 18:06:01-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 22:55:28-07:00",
    "text": "In Section 3.3: \u00a0  The SHA-3 hash algorithms have a significantly different structure \u00a0  than the SHA-2 hash algorithms.\u00a0 One of the benefits of this \u00a0  differences is that when computing a shorter SHAKE hash value, the \u00a0  value is not a prefix of the result of computing the longer hash. I did not think this was the case -- the sponge construction seems to only use the 'd' parameter to truncate the output stream, but 'd' does not seem to otherwise cause the output stream to vary.\u00a0 Indeed, Section 4 of FIPS-202 concludes: % Note that the input d determines the number of bits that Algorithm 8 % returns, but it does not affect their values. Am I misunderstanding what the quoted statement is trying to convey?",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2017-03-31 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2016-10-24 08:03:37-07:00",
    "text": "sorry we came to some comclusions on the basis of late review that make this hard to advance without correcting. this will be withdrawn from this review cycle.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-01-29 18:26:22-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-24 06:52:32-08:00",
    "text": "* Section 3.2. This should be easy to resolve but I would like this to be disambiguated before publication.  RFC5844  specifies *two* different options for UDP encapsulation IPv4-UDP and IPv4-UDP-TLV. Please clarify which of these modes is intended when the Tunnel-Type is 4 4: PMIPv6-UDP.\u00a0 This refers to the UDP tunneling encapsulation \u00a0 \u00a0 \u00a0 \u00a0  described in [ RFC5844 ].",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-03-07 08:54:37-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-06 19:18:26-08:00",
    "text": "Comparing the requirements in  RFC 8300  Section 8.1 under \"Single Domain Boundary\" and the text in Section 15 of this document, it seems that the mechanism specified in this document is not subject to the same normative requirements as specified for the administrative boundaries of a network where MPLS is used as the transport encapsulation for NSH. What is the reasoning for that? I would have expected to see similar normative requirements here as in  RFC 8300  Section 8.1.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-07 15:18:57-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-06 20:52:43-08:00",
    "text": "Thank you for this easy-to-read document!\u00a0 The design is pretty elegant, but I think there are a few places that remain insufficiently specified so as to admit interoperable implementation. In particular, I don't think the TTL-handling behavior for the SF Label in the \"label stacking\" case is completely specified, though an apparent typo in Section 7 (see COMMENT) makes it hard to tell what was intended. In Section 8, we see that: \u00a0  When an SFF receives a packet containing an MPLS label stack, it \u00a0  checks whether it is processing an {SFP, SI} label pair for label \u00a0  swapping or a {context label, SFI index} label pair for label \u00a0  stacking. [...] What data source is consulted to make this check?\u00a0 The control plane? Is this distinction made on a per-node basis or a per-packet basis or otherwise?\u00a0 My first thought was that it's per-SFC-Context-Label, but we're not guaranteed that those values will be interpretable equivalently in the swapping or stacking usages, IIUC. I also support Alissa's DISCUSS (and the secdir reviewer makes similar comments).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-09 16:33:05-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-07 06:07:59-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5624 I have what may be a simple question or a real interop problem, as noted below. Hopefully it's the former and we can resolve it quickly. DETAIL S 13. >\u00a0 \u00a0 \u00a0 \u00a0  and defined in [ RFC8300 ]. >\u00a0   >\u00a0 \u00a0 \u00a0 Metadata:\u00a0 The actual metadata formatted as described in whatever >\u00a0 \u00a0 \u00a0 \u00a0  document defines the metadata.\u00a0 This field is end-padded with zero >\u00a0 \u00a0 \u00a0 \u00a0  to three octets of zeroes to take it up to a four octet boundary. >\u00a0   What happens if the packet gets lost? Is there an ACK? How often should I send it?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-03-09 01:36:27-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 06:21:58-08:00",
    "text": "First part is a formality discuss that likely is fairly easy to resolve So this document uses formal syntax, however it does not explicitly reference which. So I noticed  RFC 5228  that do reference  RFC 4234  which is now obsolete, and the current in force version of ABNF is  RFC 5234 . Also as no WSP are included in the rules, this document appears to use ABNF to express  RFC 5228  grammar and not parsing syntax. So please clarify prior to the usages what the formal language is and what it represents.  So this needs to be done prior to Section 5. But, can you please check that you actually have the same level of\u00a0 formal syntax in Section 5 that goes through  RFC 8580  as what is in Section 8. Otherwise please clarify both.  Secondly, I do consider the defining text first paragraph of in Section 4.1 so hard to interpret that it must be fixed prior to publication. So although you already are going to address it based on discussion of Martin Duke's comment, I want to hold a discuss on this.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-07-12 07:46:59-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-21 06:01:01-08:00",
    "text": "(1) There are a bunch of places in this document that place normative requirements on \"the IP stack\" or \"IP stacks.\" This seems too broad to me -- aren't these meant to apply to IP stacks that implement the new API? It seems like  RFC 5014  was more careful in its use of normative language and I think that care is warranted here as well. (2)  RFC 7721  defines a bunch of address types that are somewhat overlapping with the definitions here.  RFC 4941  and  RFC 8064  provide recommendations for configuration of different address types. How do the address types and recommendations in this document intersect with the address types and recommendations in those documents?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-01 06:02:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 05:47:16-08:00",
    "text": "As mentioned by the TSV-ART review (Thanks Magnus!) and confirmed by Danny Moses in his response to the TSV-ART review (\"There were several discussions as to whether this draft should specify Socket extensions or provide guidelines for an API provided by the network stack to applications. The decision, eventually, was that since IETF does not specify the Socket API, we should not specify Socket extensions, but rather, provide guidelines for such functionality. \"), I don't think this document should specify an socket API. Further I don't necessarily think the API approach taken is correct. First section 3.3. says:  \u00a0 \"IP address type selection is made on a per-socket granularity. \u00a0  Different parts of the same application may have different needs. \u00a0  For example, the control-plane of an application may require a Fixed \u00a0  IP Address in order to stay reachable, whereas the data-plane of the \u00a0  same application may be satisfied with a Session-lasting IP Address.\" However, Fixed IP Address (as defined in section 3.2) cannot be configured on a per socket-basis as the application needs the same IP address for multiple socket connections. Further, section 3.5. says.  \"Extending this further by adding more flags does not work when a \u00a0  request for an address of a certain type results in requiring the IP \u00a0  stack to wait for the network to provide the desired source IP prefix \u00a0  and hence causing the setsockopt() call to block until the prefix is \u00a0  allocated (or an error indication from the network is received).\" However, later on section 6.1. it says: \u00a0 \"setsc() MAY block the invoking thread if it triggers the TCP/IP stack \u00a0  to request a new IP prefix from the network to construct the desired \u00a0  source IP address.\" Therefore, I really don't understand why a new flag in setsockopt() can not be used. I propose to remove all socket API specifications from this document and only discuss requirements\u00a0 (as indicated by Danny). That would basically mean to remove sections 3.5, 4.1, and 6.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-05 07:21:47-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 21:35:09-07:00",
    "text": "I would like to discuss a little bit exactly what we want to happen to the metadata attached to  RFC 7776 .\u00a0 It seems reasonable to apply the same \"the logical updated version of the document has this new text not this old text\" treatment we are giving the body contents to the bits at the top of the first page (to the extent that it is reasonable to do at all, viz. Magnus's Discuss).\u00a0 But are we also asking for any of the \"live\" metadata in the indices associated with the RFC Series to change, even though that would bring them in conflict with the immutable RFC artifacts?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-09-05 00:10:29-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-04 07:07:32-07:00",
    "text": "I don't understand why not a replacement for  RFC7776  was produced instead of this soup that is not readable. Publishing this in this form is providing very mixed messages to the community where we (IESG) apparently are aiming for readability and ease of comparing older and newer documents, but can't be bothered to ensure that is produced when it comes to the process documents. Also  RFC 7776  appears to be very self contained and with removal of content that will be even more true.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-09-27 07:39:55-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-19 03:22:42-08:00",
    "text": "1. The examples. In the AUTH48 for the RESTCONF RFC, the example YANG module discussion came up (again).\u00a0 And the examples in  draft-ietf-i2rs-yang-l3-topology  were also discussed. Here is the feedback from one YANG doctor, from a couple of days ago. Look at this: \u00a0  module example-ietf-ospf-topology { \u00a0 \u00a0  ... \u00a0 \u00a0  namespace \u00a0 \u00a0 \u00a0  \"urn:ietf:params:xml:ns:yang:example-ietf-ospf-topology\"; \u00a0 \u00a0  ... \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0  \"This module defines a model for OSPF network topologies. \u00a0 \u00a0 \u00a0 \u00a0 Copyright (c) 2017 IETF Trust and the persons identified as \u00a0 \u00a0 \u00a0 \u00a0 authors of the code.  They are using the IANA-controlled namespace w/o registering it. This module *really* looks like a proper normative module, rather than an example.\u00a0 They went to far in trying to mimic a real module. It is clear that we need more guidelines in 6087 for how to write example modules. I was going to ask if this module passed YANG doctor review - then I checked and saw that version -02 was reviewed, which didn't include this example.\u00a0 How should we (the YANG doctors) handle such a case? In this case they should: \u00a0 1.\u00a0 change the name to example-ospf-topology \u00a0 2.\u00a0 change the namespace to urn:example:ospf-topology \u00a0 3.\u00a0 remove the top-level statements: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 organization, contact, revision \u00a0 4.\u00a0 change the top-level description to what the text in the draft \u00a0 \u00a0 \u00a0 says: \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \"This module is intended as an example for how the \u00a0 \u00a0 \u00a0 \u00a0  Layer 3 Unicast topology model can be extended to cover \u00a0 \u00a0 \u00a0 \u00a0  OSFP topologies.\"; (same for the other example module) As I mentioned to the authors, respective chairs and AD already, we should follow the decision in this NETMOD email thread https://www.ietf.org/mail-archive/web/netmod/current/msg17428.html This will hopefully resolve fast. Once settled, the examples should be updated. 2. The security considerations should be better aligned with  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines , as mentioned by others. 3. Carl Moberg, as YANG doctor, reviewed v1 of the draft. https://www.ietf.org/mail-archive/web/yang-doctors/current/msg00031.html I'm waiting for final blessing on v8 any time soon. Hence this late DISCUSS. 4. \u00a0 \u00a0 \u00a0  leaf-list router-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type inet:ip-address; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id for the node\"; \u00a0 \u00a0 \u00a0 \u00a0  } We don't want to wait for  https://tools.ietf.org/html/draft-ietf-rtgwg-routing-types-00  (btw, we should expedite this publication), but any good reason why this is aligned with its definition? \u00a0 \u00a0 typedef router-id { \u00a0 \u00a0 \u00a0  type yang:dotted-quad; \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0  \"A 32-bit number in the dotted quad format assigned to each \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 router. This number uniquely identifies the router within an \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Autonomous System.\"; \u00a0 \u00a0  }",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-12-13 00:58:03-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-09-27 07:39:55-07:00",
    "text": "Preliminary note: I hope I'm doing the right thing by updating this DISCUSS point as\u00a0 I understand that the document is back to the WG. However, since I reviewed the version 11, since some of my ballot points have been addressed (thank you), and since I wanted to share my feedback publicly, here is my feedback. 1. The examples. In the AUTH48 for the RESTCONF RFC, the example YANG module discussion came up (again).\u00a0 And the examples in  draft-ietf-i2rs-yang-l3-topology  were also discussed. Here is the feedback from one YANG doctor, from a couple of days ago. Look at this: \u00a0  module example-ietf-ospf-topology { \u00a0 \u00a0  ... \u00a0 \u00a0  namespace \u00a0 \u00a0 \u00a0  \"urn:ietf:params:xml:ns:yang:example-ietf-ospf-topology\"; \u00a0 \u00a0  ... \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0  \"This module defines a model for OSPF network topologies. \u00a0 \u00a0 \u00a0 \u00a0 Copyright (c) 2017 IETF Trust and the persons identified as \u00a0 \u00a0 \u00a0 \u00a0 authors of the code.  They are using the IANA-controlled namespace w/o registering it. This module *really* looks like a proper normative module, rather than an example.\u00a0 They went to far in trying to mimic a real module. It is clear that we need more guidelines in 6087 for how to write example modules. I was going to ask if this module passed YANG doctor review - then I checked and saw that version -02 was reviewed, which didn't include this example.\u00a0 How should we (the YANG doctors) handle such a case? In this case they should: \u00a0 1.\u00a0 change the name to example-ospf-topology \u00a0 2.\u00a0 change the namespace to urn:example:ospf-topology \u00a0 3.\u00a0 remove the top-level statements: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 organization, contact, revision \u00a0 4.\u00a0 change the top-level description to what the text in the draft \u00a0 \u00a0 \u00a0 says: \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \"This module is intended as an example for how the \u00a0 \u00a0 \u00a0 \u00a0  Layer 3 Unicast topology model can be extended to cover \u00a0 \u00a0 \u00a0 \u00a0  OSFP topologies.\"; (same for the other example module) As I mentioned to the authors, respective chairs and AD already, we should follow the decision in this NETMOD email thread https://www.ietf.org/mail-archive/web/netmod/current/msg17428.html This will hopefully resolve fast. Once settled, the examples should be updated. 4. \u00a0 \u00a0 \u00a0  leaf-list router-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type inet:ip-address; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id for the node\"; \u00a0 \u00a0 \u00a0 \u00a0  } My initial DISCUSS was: We don't want to wait for  https://tools.ietf.org/html/draft-ietf-rtgwg-routing-types-00  (btw, we should expedite this publication), but any good reason why this is aligned with its definition? \u00a0 \u00a0 typedef router-id { \u00a0 \u00a0 \u00a0  type yang:dotted-quad; \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0  \"A 32-bit number in the dotted quad format assigned to each \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 router. This number uniquely identifies the router within an \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Autonomous System.\"; \u00a0 \u00a0  } My NEW DISCUSS: since is in IETF LC and on the telechat on Oct 12th, it makes sense to import its router-id",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-12-14 03:33:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-12-13 00:58:03-08:00",
    "text": "Here is another validation issue, on the latest v13, that must be corrected. Actually multiple mistakes, all with the same root cause. Note that those warnings were reported in the datatracker: \u00a0  - Yang catalog entry for ietf-l3-unicast-topology-state@2017-11-15.yang \u00a0  - Yang catalog entry for ietf-l3-unicast-topology@2017-11-15.yang Thanks to Michal, here is the detailed explanation. Hi Benoit,  firstly, you see the output only with -V because it changes verbosity to 'warnings' instead of the default one 'errors'. So, the warnings are valid and the when conditions are wrong. In short, in these cases the local module is not ietf-l3-unicast-topology, but ietf-network (despite being defined in ietf-l3-unicast-topology) - \"ietf-network:network-types/l3-unicast-topology\" should be \"ietf-network:network-types/ietf-l3-unicast-topology:l3-unicast-topology\" or even \"network-types/ietf-l3-unicast-topology:l3-unicast-topology\". To explain, here is the (long) justification. I will use the first warning as an example, all the other warnings are caused by the same mistake. We are dealing with a when condition \"nw:network-types/l3-unicast-topology\" in an augment \"/nw:networks/nw:network\" in the module ietf-l3-unicast-topology. As per [1], the context node of the XPath expression (when condition) is the augment target node \"/nw:networks/nw:network\". If you notice, the warning warns about not finding the node \"l3-unicast-topology\", not \"nw:network-types\". So, what node is actually referenced by \"l3-unicast-topology\"? Looking at [2], second bullet point, the namespace (prefix) should that of the \"current node\". Sadly, there is no (I have found none) formal definition of \"current node\" but I dared to assume it to be the node returned by the \"current()\" [3] function. As was said at the beginning, the \"initial context node\" is \"/nw:networks/nw:network\". Finally, we can now decide that \"l3-unicast-topology\" actually takes the prefix of the module \"ietf-network\" and there is no such node, this node is defined in the module \"ietf-l3-unicast-topology\". I hope it is clear now. Kind regards, Michal [1]  https://tools.ietf.org/html/rfc7950#page-137 [2]  https://tools.ietf.org/html/rfc7950#section-6.4.1 [3]  https://tools.ietf.org/html/rfc7950#section-10.1.1 On Tuesday, December 12, 2017 16:49 CET, Benoit Claise\u00a0 wrote:    > Hi Radek, > > I'm looking at warnings for  > ietf-l3-unicast-topology-state@2017-11-15.yang and  > ietf-l3-unicast-topology-state@2017-11-15.yang > See  http://www.claise.be/IETFYANGPageCompilation.html > > Here is something interesting: the warnings only appear with the -V option. > > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint  > ietf-l3-unicast-topology@2017-11-15.yang > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint -i  > ietf-l3-unicast-topology@2017-11-15.yang > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint -i -V  > ietf-l3-unicast-topology@2017-11-15.yang > warn: Schema node \"l3-unicast-topology\" not found  > (ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/network\". > warn: Schema node \"l3-unicast-topology\" not found  > (../ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/network/node\". > warn: Schema node \"l3-unicast-topology\" not found  > (../ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/ietf-network:network/link\". > warn: Schema node \"l3-unicast-topology\" not found  > (../../ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/ietf-network:network/ietf-network:node/termination-point\". > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint -v > yanglint 0.13.79 > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ > > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint  > ietf-l3-unicast-topology-state@2017-11-15.yang > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint -i  > ietf-l3-unicast-topology-state@2017-11-15.yang > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ yanglint -i -V  > ietf-l3-unicast-topology-state@2017-11-15.yang > warn: Schema node \"l3-unicast-topology\" not found  > (ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/network\". > warn: Schema node \"l3-unicast-topology\" not found  > (../ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/network/node\". > warn: Schema node \"l3-unicast-topology\" not found  > (../ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/ietf-network:network/link\". > warn: Schema node \"l3-unicast-topology\" not found  > (../../ietf-network:network-types/l3-unicast-topology) with context node  > \"/ietf-network:networks/ietf-network:network/ietf-network:node/termination-point\". > warn: Schema node \"l3-unicast-topology\" not found  > (ietf-network-state:network-types/l3-unicast-topology) with context node  > \"/ietf-network-state:networks/network\". > warn: Schema node \"l3-unicast-topology\" not found  > (../ietf-network-state:network-types/l3-unicast-topology) with context  > node \"/ietf-network-state:networks/network/node\". > warn: Schema node \"l3-unicast-topology\" not found  > (../ietf-network-state:network-types/l3-unicast-topology) with context  > node \"/ietf-network-state:networks/ietf-network-state:network/link\". > warn: Schema node \"l3-unicast-topology\" not found  > (../../ietf-network-state:network-types/l3-unicast-topology) with  > context node  > \"/ietf-network-state:networks/ietf-network-state:network/ietf-network-state:node/termination-point\". > bclaise@bclaise-VirtualBox:~/ietf/YANG-all$ > > Should we pay attention to those? > > Regards, Benoit ==================================================== Preliminary note: I hope I'm doing the right thing by updating this DISCUSS point as\u00a0 I understand that the document is back to the WG. However, since I reviewed the version 11, since some of my ballot points have been addressed (thank you), and since I wanted to share my feedback publicly, here is my feedback. 1. The examples. In the AUTH48 for the RESTCONF RFC, the example YANG module discussion came up (again).\u00a0 And the examples in  draft-ietf-i2rs-yang-l3-topology  were also discussed. Here is the feedback from one YANG doctor, from a couple of days ago. Look at this: \u00a0  module example-ietf-ospf-topology { \u00a0 \u00a0  ... \u00a0 \u00a0  namespace \u00a0 \u00a0 \u00a0  \"urn:ietf:params:xml:ns:yang:example-ietf-ospf-topology\"; \u00a0 \u00a0  ... \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0  \"This module defines a model for OSPF network topologies. \u00a0 \u00a0 \u00a0 \u00a0 Copyright (c) 2017 IETF Trust and the persons identified as \u00a0 \u00a0 \u00a0 \u00a0 authors of the code.  They are using the IANA-controlled namespace w/o registering it. This module *really* looks like a proper normative module, rather than an example.\u00a0 They went to far in trying to mimic a real module. It is clear that we need more guidelines in 6087 for how to write example modules. I was going to ask if this module passed YANG doctor review - then I checked and saw that version -02 was reviewed, which didn't include this example.\u00a0 How should we (the YANG doctors) handle such a case? In this case they should: \u00a0 1.\u00a0 change the name to example-ospf-topology \u00a0 2.\u00a0 change the namespace to urn:example:ospf-topology \u00a0 3.\u00a0 remove the top-level statements: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 organization, contact, revision \u00a0 4.\u00a0 change the top-level description to what the text in the draft \u00a0 \u00a0 \u00a0 says: \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \"This module is intended as an example for how the \u00a0 \u00a0 \u00a0 \u00a0  Layer 3 Unicast topology model can be extended to cover \u00a0 \u00a0 \u00a0 \u00a0  OSFP topologies.\"; (same for the other example module) As I mentioned to the authors, respective chairs and AD already, we should follow the decision in this NETMOD email thread https://www.ietf.org/mail-archive/web/netmod/current/msg17428.html This will hopefully resolve fast. Once settled, the examples should be updated. 4. \u00a0 \u00a0 \u00a0  leaf-list router-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type inet:ip-address; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id for the node\"; \u00a0 \u00a0 \u00a0 \u00a0  } My initial DISCUSS was: We don't want to wait for  https://tools.ietf.org/html/draft-ietf-rtgwg-routing-types-00  (btw, we should expedite this publication), but any good reason why this is aligned with its definition? \u00a0 \u00a0 typedef router-id { \u00a0 \u00a0 \u00a0  type yang:dotted-quad; \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0  \"A 32-bit number in the dotted quad format assigned to each \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 router. This number uniquely identifies the router within an \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Autonomous System.\"; \u00a0 \u00a0  } My NEW DISCUSS: since is in IETF LC and on the telechat on Oct 12th, it makes sense to import its router-id",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-12-17 06:44:24-08:00",
    "end_reason": "position_updated",
    "start": "2017-12-14 03:33:04-08:00",
    "text": "We're making progress. Thanks. >> >> 4. >> >>\u00a0 \u00a0 \u00a0 \u00a0  leaf-list router-id { >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type inet:ip-address; >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id for the node\"; >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } >> >> My initial DISCUSS was: We don't want to wait for >>  https://tools.ietf.org/html/draft-ietf-rtgwg-routing-types-00  (btw, we  >> should expedite this publication), but any good reason why this is  >> aligned with its definition? >>\u00a0 \u00a0 \u00a0 typedef router-id { >>\u00a0 \u00a0 \u00a0 \u00a0  type yang:dotted-quad; >>\u00a0 \u00a0 \u00a0 \u00a0  description >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"A 32-bit number in the dotted quad format assigned to each >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 router. This number uniquely identifies the router within an >>\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Autonomous System.\"; >>\u00a0 \u00a0 \u00a0  } >> >> My NEW DISCUSS: since is in IETF LC and on the telechat on Oct 12th,  >> it makes sense to import its router-id > >\u00a0 This is only used in the example.\u00a0 The point of the example is to > show how the model can be extended, not to define something normative, hence > I don't think there is a need to introduce a dependency here which would > only be distracting. >  Can you help me understand how this is an example? Section 5 \u00a0  module: ietf-l3-unicast-topology \u00a0 \u00a0  augment /nw:networks/nw:network/nw:network-types: \u00a0 \u00a0 \u00a0  +--rw l3-unicast-topology! \u00a0 \u00a0  augment /nw:networks/nw:network: \u00a0 \u00a0 \u00a0  +--rw l3-topology-attributes \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--rw name?\u00a0  string \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--rw flag*\u00a0  l3-flag-type \u00a0 \u00a0  augment /nw:networks/nw:network/nw:node: \u00a0 \u00a0 \u00a0  +--rw l3-node-attributes \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--rw name?\u00a0 \u00a0 \u00a0 \u00a0 inet:domain-name \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--rw flag*\u00a0 \u00a0 \u00a0 \u00a0 node-flag-type \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--rw router-id*\u00a0  inet:ip-address \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--rw prefix* [prefix] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--rw prefix\u00a0 \u00a0 inet:ip-prefix \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--rw metric?\u00a0  uint32 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--rw flag*\u00a0 \u00a0  prefix-flag-type And section 6: \u00a0 \u00a0  grouping l3-node-attributes { \u00a0 \u00a0 \u00a0  description \"L3 node scope attributes\"; \u00a0 \u00a0 \u00a0  container l3-node-attributes { \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Containing node attributes\"; \u00a0 \u00a0 \u00a0 \u00a0  leaf name { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type inet:domain-name; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Node name\"; \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0  leaf-list flag { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type node-flag-type; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Node flags\"; \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0  leaf-list router-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type inet:ip-address; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id for the node\"; \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0  list prefix { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  key \"prefix\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"A list of prefixes along with their attributes\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  uses l3-prefix-attributes; \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } A different view at  https://www.yangcatalog.org/yang-search/yang_tree.php?module=ietf-l3-unicast-topology#",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-06-30 14:15:32-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-21 05:42:08-07:00",
    "text": "* Section 4 Since this behavior is clearly forbidden in  RFC8200  there is no need to add a special case for this (as middleboxes perform any number of transformations that not standards compliant). Given that safe header insertion/deletion is a hard problem that has not been solved, I would remove this text or significantly augment it to describe potential issues that may occur due to header insertion/deletion (similar to the sections related to 6lowpan and translation). \u00a0  o\u00a0 Extension Header insertion or deletion: Although such behavior is \u00a0 \u00a0 \u00a0 not endorsed by current standards, it is possible that Extension \u00a0 \u00a0 \u00a0 Headers could be added to, or removed from the header chain.\u00a0 The \u00a0 \u00a0 \u00a0 resulting packet may be standard-formed, with a corresponding \u00a0 \u00a0 \u00a0 Type-P.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-04-27 05:30:38-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-11 11:26:01-07:00",
    "text": "This document should be informational. I don't see any reason that this document must be cited normatively by all following document of this wg (as indicated in the shepherd write-up) and even if so that does not justify publication as Standards track if the information in the document is only informational.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-11-23 03:13:14-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-19 05:47:40-08:00",
    "text": "I have what I think should be an easily fixed thing I'd like to discuss. Shouldn't there be some text about privacy considerations here?\u00a0 If a MIB has some privacy sensitive value and that is now exported in push mode, that may produce unexpected results.\u00a0 I think implementers might at least need to have some ability to filter values for privacy reasons and that that is something that ought be called out here. One might also want to modify values, e.g. mask IP address bits or modify addresses in other ways, or to zero out values. Again, you probably should say something about that since the receiver of the data might not expect that they get filtered data instead of raw data. (So this could also touch on interop.) I think you could just say the above couple of things, say in section 10.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-07-26 05:56:29-07:00",
    "end_reason": "position_updated",
    "start": "2018-01-18 07:34:42-08:00",
    "text": "The security considerations of this document are inadequate. My review turns up at least the following potential issues which do not seem to be addressed or even discussed: - Amplification: this protocol does not appear to verify that the \u00a0 sender of the query actually owns the IP it claims. Because \u00a0 responses are much larger than queries, this allows for an amplification \u00a0 attack, especially if the client is able to send a query that elicits \u00a0 multiple replies. One defense here would be to fill the rest of the packet \u00a0 with zeroes, thus somewhat reducing the amplification factor. Access \u00a0 control would also help. - Forgery of responses: because the query id is so short, an attacker \u00a0 can generally produce a message which has a nontrivial chance of \u00a0 corresponding to an extant query. This could be addressed by having \u00a0 a query ID that was large and random. - Anyone on-path can forge responses. In addition, Section 9.4 seems inadequate. Isn't it generally the case that who is sending to who is sensitive? This seems like a fairly serious privacy obstacle to using this protocol at all. It seems like many of the issues I raise above would be fixed or at least mitigated by having some sort of access control mechanism.\u00a0 I understand why it might be the case that it's not practical to have full communication security between the links (though it would of course be desirable), but it's not clear to me why arbitrary people should be allowed to instantiate queries.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-04-09 08:26:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-01-24 06:32:43-08:00",
    "text": "Thanks for this well written document! However, I think there are a few things that need clarification. I also agree with Ekr's discuss and the tsv-art review (Thanks Brian!) and would like to see stronger access control (as least MUST filter instead of SHOULD). Further, the IANA section is not fully specified. Sec 8.2 doesn't define a registration policy. Sec 8.1. says \"Any additions to \u00a0  this registry are required to fully describe the conditions under \u00a0  which the new Forwarding Code is used.\" which sounds like  RFC8126  \"Specification Required\" which would however include expert review. Is an expert review require/desired here? Also, I think the entry in the port registry should be updated to point to this RFC and reassign the port to the IESG as maintainer of this RFC. Further, based on the feedback provided by the tsv-art review (Thanks Brian again!): How does a receiver distinguish between mtrace version 1 and mtrace2? And also on use of UPD ports: Section 3 says: \"The source port is uniquely selected by the local host operating \u00a0  system.\u00a0 The destination port is the IANA reserved Mtrace2 port \u00a0  number (see Section 8).\" This sounds like the IANA assigned port is used as destination for all mtrace messages including a reply. If that would be the case, you don't have to carry the mtrace client's port #. Can you please clarify? Section 5.2 needs a bit of clarification. This says: \"If no Reply is received at a \u00a0  certain hop, the hop count can continue past the non-responding hop, \u00a0  in the hopes that further hops may respond.\u00a0 These attempts should \u00a0  continue until the [Mtrace Reply Timeout] timeout has occurred.\" This seems to be contradicting. If no Reply is received that means the Mtrace Reply Timeout has occurred, so how and when should you try further attempts. Also I think it would be good to clarify that only one Request MUST be sent at once. I assume that is how Mtrace Reply Timeout is used to rate limit requests (while traditional traceroute often sends multiple packets with different TTLs at once). Right?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-08-07 09:28:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 11:18:35-07:00",
    "text": "The specification has not been properly vetted against the I-D Checklist. The draft header indicates that this document obsoletes  RFC3044  and  RFC3187 , but the abstract doesn't mention this, which it should. Listing of obsoleted documents in the Abstract is specified by the ID-Checklist document (\u00a73, 1.D, first bullet),",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-03-30 16:48:03-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-14 02:29:17-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-opsawg-add-encrypted-dns-11 CC @evyncke Thank you for the work put into this document. Once the trivial DISCUSS is addressed, I will be happy to ballot a YES. Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Bernie Volz for the shepherd's detailed write-up including the WG consensus even if the justification of the intended status is rather vague.  Other thanks to Tatuya Jinmei, the Internet directorate reviewer (at my request), please consider this int-dir review: https://datatracker.ietf.org/doc/review-ietf-opsawg-add-encrypted-dns-10-intdir-telechat-jinmei-2023-03-09/  (and I have read Med's replies and resolution of the issues) I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### What to do with non-permitted DHCP option ? Sections 3.1 and 3.2 contain text like `Permitted DHCPv6 options in the DHCPv6-Options Attribute are maintained by IANA in the registry created in Section 8.4.1.` but I was unable to find anywhere in the document what is the expected behaviour of a RADIUS client receiving a non-permitted DHCP option ? At the bare minimum, I would expect the I-D to mention \"non-permitted DHCP options MUST silently be ignored by the RADIUS client\" Or did I fail to find a similar statement in the text ?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-08-20 13:30:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 18:56:17-08:00",
    "text": "(1) Controllers and other nodes. Background: This document defines the new SFC NLRI, which has two distinct route types, originated by either a node hosting an SFI or a Controller.\u00a0 Each route type has a specific function and it is reasonable to expect that the originators represent different nodes in the network, with different functions, location, etc..\u00a0 BGP Capabilities Advertisement doesn't have a route type granularity; instead, a BGP speaker known to support the SFC NLRI could originate any type of route. The facts above open the possibility that any node in the network can originate an SFPR and take over an SFP.\u00a0 \u00a73.2.2 does a very good job of explaining the potential existence of multiple Controllers and even offers the appropriate tie breaker to take control of the SFP: \"MUST use the SFPR with the numerically lowest SFPR-RD\".\u00a0  The document proposes no mitigation to the possibility of any node (a rogue node, for example) issuing SFPRs.\u00a0 The assumption (\u00a72.2) of \"BGP connectivity between the Controllers and all SFFs\" introduces also the ability to locate a rogue controller anywhere; I interpret \"BGP connectivity\" to include the presence of a router reflector (for example), which then allows distribution of SFPRs without going through a central policy point.  On one hand I think this condition is a feature (the Controller can be anywhere), but the case of a rogue node that wants to act as a controller is not considered. To address this issue, I would like to see text that (1) acknowledges the issue (maybe in the security considerations section), and (2) discusses operational considerations for the placement, control, filtering, etc. of Controllers and the corresponding UPDATES from them and/or other nodes in the network.\u00a0 IOW, the considerations around proper initial setup of the system should be clear. (2) New Flow Specification Traffic Filtering Action \u00a77.4 (Flow Spec for SFC Classifiers) defines a new Traffic Filtering Action to be used with the Flow Specification NLRI.\u00a0 rfc5775bis allows for any combination of Traffic Filtering Actions to be present, but this document says that \"other action extended communities MUST NOT be present\".\u00a0 I believe that specifying the use of treat-as-withdraw is ok as a case of Traffic Filtering Action Interference -- I just say \"ok\" because it is not clear to me (nor explained anywhere) why other Traffic Filtering Actions cannot be used; for example, I could imagine rate-limiting the traffic into an SFP. What concerns me more (and the reason for this DISCUSS point) is that  rfc5575 -only implementations will not consider the new Traffic Filtering Action, but could, depending on the components encoded in the NLRI, take actions based on other Traffic Filtering Actions.\u00a0 The result can then be an inconsistent application of Traffic Filtering Actions in the network -- for example, some nodes may want to drop the matching traffic (traffic-rate of 0), while others may want to have the same traffic entering an SFP. What are the operational considerations of using the new Traffic Filtering Action in a network where \"legacy\" (rfc5575bis-only) nodes exist?\u00a0 Is there a potential migration path?\u00a0 What might be the impact?\u00a0 How can correct operation be verified? (3) Use of the Control Plane This last point is not specifically for the authors, but for the Responsible AD and the Chairs for the sfc WG (cc'd). The SFPRs are built on, among other things, knowledge of the SFT(s) supported at a specific node.\u00a0 I note that only one Special Purpose SFT is defined in this document.\u00a0 The lack of SFT definitions means that no actual SFP can be instantiated.\u00a0 IOW, without additional work to define new SFTs it seems to me that the control plane as specified in this document cannot be used. :-( I couldn't find any related work (referencing this document) where new SFTs are proposed/defined.\u00a0 What are the plans to develop that work?\u00a0 Is there interest in the sfc WG to take advantage of the control plane?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-21 14:12:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-18 15:01:48-08:00",
    "text": "Section 3.2.1.3 seems to talk about intermingling SFIR-RDs and SFIR Pool Identifiers in a common list, but I do not see how it's defined to intermingle the (six-octet) Pool Identifier Value with the (eight-octet) RDs. Section 3.1 seems to allow multiple SFIRs associated with a given RD, but the rest of the document seems to assume that any RD has at most one associated SFIR (as is stated explicitly for SFPRs).\u00a0 (A few specific mentions in the COMMENT.) Within my own limited understanding, it seems like this document is expanding the boundaries of the SFC Architecture in ways not envisioned by  RFC 7665  or 8300, and the shepherd writeup is pretty quiet on to what extent this architectural change is accepted by the WG (as opposed to being contained to just the BGP control plane mechanism).\u00a0 I'd like to get a positive affirmation from someone more familiar with the discussions that this is moving the architecture in the right direction with respect to things like: - the introduction of the Service Function Type intermediate \u00a0 classification - the more prominent treatment of looping, jumping, and branching as \u00a0 operations within a single SFP without reclassification by using the \u00a0 \"Change Sequence\" SFT entries to indicate these behaviors within the \u00a0 SFP definition itself (I note that  RFC 7665  does not mention \"jump\" at all) - the introduction of \"gaps\" in the SI sequence of a given SFP With respect to SFT in particular, it sounds like this is intended to help with scalability, which makes the genart reviewer's comment about lack of implementation experience particularly poingant.\u00a0 It seems like SFIR pools perform a similar role, though of course not identical; I didn't get a clear sense of why pools without SFTs are insufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-21 15:15:12-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-21 14:12:34-07:00",
    "text": "I think we may still need some text changes to clarify how the joint list of SFIR-RD and SFIR Pool Identifier Extended Communities is constructed and interpreted, and potentially need to register an RD Type matching the other (TBD6+TBD7) values we allocate. (I'm also not entirely clear how the IPv6 addresses interact with 8-byte RDs.) A longer description of these topics is written up at https://mailarchive.ietf.org/arch/msg/bess/wVDRF4ni0bGhNazvWoFi8BwJ_Vg/ but is not quite appropriate for this standalone context.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-08-25 05:10:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 11:15:00-08:00",
    "text": "* Section 9 cites a number of references (which cite additional references) on BGP security.\u00a0 My summary of the highlights is: (1)  RFC4271  => TCP MD5 ( RFC2385 ) is a MUST  (2)  RFC4271  => consider  RFC 3562  for key management guidance (3) ietf-idr-tunnel-encaps => caution on Tunnel Encapsulation attribute (4)  rfc4364  => TCP MD5 is a non-rfc2119 \u201cshould\u201d (5)  rfc4364  => don\u2019t make connections with untrusted peers (6)  RFC7432  => references the utility of TCP-AO ( RFC5925 ) - Could the text articulate more clearly de-conflict (1), (4) and (6) \u2013 what is the recommended approach? - a discuss-discuss \u2013 Given the green field nature of this specification (the shepherd\u2019s report notes no implementation) and the assumed SFC deployment model (not the internet; a single provider\u2019s operational domain where key management should be easier), could a more robust transport security option such as BGP over IPSec be RECOMMENDED?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-10-31 04:05:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-28 01:23:41-07:00",
    "text": "Below is Sue Hares' OPS DIR review. I would like to DISCUSS some points. I'm of two minds. On one side, I read: \u00a0 \u00a0 \u00a0  The scope of this memo is limited to these three areas of \u00a0 \u00a0 \u00a0  experimentation.\u00a0 This memo expresses no view on the likely outcomes \u00a0 \u00a0 \u00a0  of the proposed experiments and does not specify the experiments in \u00a0 \u00a0 \u00a0  detail.\u00a0 Additional experiments in these areas are possible, e.g., on \u00a0 \u00a0 \u00a0  use of ECN to support deployment of a protocol similar to DCTCP \u00a0 \u00a0 \u00a0  [ I-D.ietf-tcpm-dctcp ] beyond DCTCP's current applicability that is \u00a0 \u00a0 \u00a0  limited to data center environments.\u00a0 The purpose of this memo is to \u00a0 \u00a0 \u00a0  remove constraints in standards track RFCs that stand in the way of \u00a0 \u00a0 \u00a0  these areas of experimentation. On the other side: \u00a0  An Experimental RFC MUST be published for any protocol \u00a0  or mechanism that takes advantage of any of these enabling updates. Btw, the MUST is just plain wrong, as Ben mentioned. So, if you go in the direction of providing requirements for the experiments (as opposed to just removing the specification constraints), then I agree with Sue. The document title goes in the direction: if it would say something such as \"Removing constraints to the ECN experimentation\", that would be a different story. Reviewer: Susan Hares Review result: Has Issues This is an OPS-DIR Review which focus the work on issues in deployed technology based on this RFC. Summary: Has issues as guide to experimental RFC .\u00a0 To me these operational issues General comment: Thank you david for addressing this Area.\u00a0 Better ECN control is critical to many portions of the network. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  My comments on this draft are because I \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  really hope you can do quality experiments. How this might be resolved: if there is a operational guidelines section (or separate document), that covered: a) how to set-up and determine if a ECT(1) experiment success or fails b) how to manage your ECT(1) experiment in your network. c) how to manage and detect if your ECT experiment is running into problems with other IETF technology (TRILL, MPLS VPNs, IPVPNs, BIER and NV03 technology). d) Recommending a monitoring structure (e.g. yang modules, netconf/restconf and monitoring tools0 Major issues: #1 There is nothing in this document which provide guidelines to the authors of experimental RFCs based in this draft on specific ways to \u00a0 \u00a0 monitor the ECN experiments, report the ECN experimental data, or disable \u00a0 \u00a0 the experimental data.\u00a0  If the success or failure of an experiment is \u00a0 \u00a0 based on \"popular vote\" determined by deployment, then say state this \u00a0 \u00a0 point.\u00a0 I personally would object to that \u00a0  because you cannot tell if a limited experiment in a specific location (E.g. \u00a0  a data center) might be successful in another location. \u00a0 If the success or failure of an experimental RFC is based on a specific set \u00a0 of criteria for ECN, then it would be good to give an operational suggestion \u00a0 on how to: a) design an experiment, b) run an experiment and collect data, \u00a0 and c) report ths  data in order to standardize the ECN experiments using ECT(1).  page 10 section 4.2 last 2 paragraphs in sentence, hinted that you have an  experiment in mind without specifying the experiment's success or failure  criteria other than popular vote.\u00a0 Is this true?\u00a0 if it is, this is  problematic.\u00a0 If I misunderstood your text, then please have someone re-read the text. I have read lots of papers on ECN. 2) No discussion was given on how the TCP layer experimentation would impact routing layer handdlng of ECN. For example, the trill WG has the draft draft-ietf-trill-ecn-support.  Automated tunnel set-up for MPLS VPNS or IP VPNS may look at the ECN ECT(0)\u00a0 or ECT(1).\u00a0 TRILL's ECN supports the layer-2 within the data centers.\u00a0 Some IP VPNS or MPLS VPNS may be needed for the data-center to business site  or data-center backup traffic.  As written, this draft allows loosening of the  RFC3168  draft but does not  provide guidelines\u00a0 for network interaction. 3)\u00a0 Some networks also use the diff-service markings to guide traffic in the network. \u00a0 \u00a0 This document does not suggest an operational check list on how to design \u00a0 \u00a0 an experiment that supports or does not support these markings. 4) Modern operational IETF protocols and data modules for automating the tracking of these experiments should be suggests",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-18 18:13:46-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-30 10:48:56-07:00",
    "text": "This may just be a philosophical discussion, but if  RFC 8231  marks the PLSP-ID value of 0 as \"reserved\" and we are making use of the extension point, do we need to have an Updates: relationship with 8231?\u00a0 This seems particularly poigniant given that we have to explicitly override the  RFC 8231  error handling, with some text in the second paragraph of Section 4. What kind of feature negotiation is available to check support prior to using this flag?\u00a0 After all, if the peer does not implement this document it will not implement the override of 8231 error handling and will respond with errors when the D flag is set (or the PLSP-ID of 0 used).\u00a0 If we have to just \"try it and fall back to not using it if we get errors\", that has some associated security considerations as well. What can we say about authorization policy on the PCC?\u00a0 Alvaro touched on this in his Comment, but I think it's important enough to be Discuss-level.\u00a0 Since this policy is the key factor to the security posture of this extension, not only does it seem like there MUST be the ability to configure the policy, but it also seems like we should be able to give some guidance on typical use cases (where the authors believe the security properties to be reasonable).\u00a0 Other use cases might require an additional level of analysis by those proposing to deploy the solution.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-09-20 08:19:12-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-13 13:13:57-07:00",
    "text": "Thanks for a simple, clear document.\u00a0 This should be really, really easy to sort out: \u2014 Section 1 \u2014 \u00a0  Documents defining a new message type MUST define the \u00a0  usage of the corresponding Flag Bits. Indeed, and we do this frequently in the IETF.\u00a0 How do we make sure that future documents comply with this?\u00a0 I think we need to put this sentence in the registry of PIM Message Types, by adding something to Section 7, in addition to just changing the reference pointer to point here.\u00a0 I\u2019ve incorporated that into my suggestion for the registry table, below. \u2014 Section 7 \u2014 Wow.\u00a0 Table 1 looks very confusing to me.\u00a0 I did get what you\u2019re doing, but I had to stare at it for a while, and it\u2019s better not to make people work that hard.\u00a0 Might this work better?: NEW \u00a0  Assignments into this registry MUST define the usage of the Flag Bits \u00a0  in addition to defining the Type. \u00a0 \u00a0 Type\u00a0 \u00a0 \u00a0  Flag Bits\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Reference \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Hello\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC3973 ][ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ][ RFC7761 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Register\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC7761 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Register Stop\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC7761 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  3\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Join/Prune\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ][ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ][ RFC7761 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Bootstrap\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-6\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC5059 ][ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  7\u00a0 \u00a0 \u00a0 \u00a0 No-Forward\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC5059 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  5\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Assert\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ][ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ][ RFC7761 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  6\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Graft\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC3973 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  7\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Graft-Ack\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC3973 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  8\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Candidate RP Advertisement\u00a0 [ RFC7761 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC7761 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0  9\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 State Refresh\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC3973 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC3973 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0 10\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DF Election\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC5015 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-3\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC5015 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  4-7\u00a0 \u00a0 \u00a0 Subtype\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC5015 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0 11\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ECMP Redirect\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ RFC6754 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-7\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC6754 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0 12\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 PIM Flooding Mechanism\u00a0 \u00a0 \u00a0 [ RFC8364 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  0-6\u00a0 \u00a0 \u00a0 (Reserved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC8364 ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  7\u00a0 \u00a0 \u00a0 \u00a0 No-Forward\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC8364 ] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0 13.0-13.15\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Unassigned\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [this document] \u00a0 \u00a0 14.0-14.15\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Unassigned\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [this document] \u00a0 \u00a0 15.0-15.15\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Unassigned\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [this document] \u00a0  --------------------------------------------------------------------- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Table 1: Updated PIM Message Types Registry END",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-07-19 14:06:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-03 14:18:31-07:00",
    "text": "I will apologize in advance because this document may be sort of a casualty of this DISCUSS. I should have raised my point below at least two years ago if not four years ago when the first iana-* YANG module was registered, but the thought did not occur to me until now.  It gives me some pause to see the name \"iana\" embedded in the file name, module name, namespace, and prefix of the module being defined in Sec. 2.12. I realize there is precedent here, but I question whether tying these kinds of modules specifically to IANA as the protocol parameter registry operator by name puts them on the most stable deployment footing under all possible circumstances. I am personally pleased as punch with the service we get from IANA, but that doesn't mean \"IANA\" will always be the name of the registry operator. The more modules that get created with this embedding, the more of them that may need to change in the unlikely event that the name of the registry operator changes. Lots of RFCs would need to change too, but embedding the name extends the potential problem to the modules themselves. It wasn't clear to me whether there is some ops-area-wide convention around the embedding of \"iana\" in the names of modules to be maintained by IANA. I don't see this specifically referenced in  RFC 7950  or  RFC 6020 . So I'd like to discuss whether a different naming convention could be established and used in this document and others going forward.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-08-02 18:18:21-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-03 13:21:16-07:00",
    "text": "Section 2.1 describes a scheme wherein an IGP may generate events that cause BFD sessions to be created/destroyed; this effectively is proxying commands from IGP over the local BFD API, which brings the authentication and authorization of the IGP into scope, even if the local BFD configuration access is authenticated.\u00a0 (That is, the proxying component is always authenticated, but now bears responsibility for performing authentication/authorization/sanity checks on commands before proxying them.)\u00a0 Since IGP security is a topic for elsewhere, the changes to this document seem scoped to documenting the requirements on the IGP/local proxy for these checks, and arguably for only allowing authenticated IGP events to create authenticated BFD sessions (though arguably not as well, for the latter, since this is a YANG model document and not an architecture document).",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-07-04 11:17:08-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-04 10:17:20-07:00",
    "text": "Don't panic, this should be an easy DISCUSS to clear, but I think it important for interoperability. In multiple places, you have: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions-up? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions-down? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions-admin-down? I'm a little confused by the meaning of the counters, and didn't see them clearly defined anywhere. Apologies if I missed it... Are \"number-of-sessions-admin-down\" included in \"number-of-sessions-down\"?  Is 'number-of-sessions' always equal to 'number-of-sessions-up' + 'number-of-sessions-down', or is it always equal to 'number-of-sessions-up' + 'number-of-sessions-down' + 'number-of-sessions-admin-down', or are there other cases? E.g: I have created 10 sessions (because I have 10 interfaces). 5 of them are down because there is no peer, 3 of them I've configured to be down (admin down), and so 2 of them are up. What should be in each of: number-of-sessions? number-of-sessions-up? number-of-sessions-down? number-of-sessions-admin-down?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-04-12 10:44:34-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-07 19:04:37-07:00",
    "text": "Section 2.3: \u00a0  EVPN Network OAM mechanisms MUST provide in-band monitoring \u00a0  capabilities. As such, OAM messages MUST be encoded so that they \u00a0  exhibit identical entropy characteristics to data traffic in order \u00a0  that they share the same fate. It\u2019s not obvious to me what you mean by \u201cidentical entropy characteristics to data traffic\u201d. Surely, different flows may have different entropy characteristics, so, *which* data traffic? Similarly, with which data traffic are you saying the OAM messages must share fate?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-31 14:47:43-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-12-28 14:29:34-08:00",
    "text": "This is cool stuff.\u00a0 I assure you I'm going to ballot \"Yes\" after what's below is cleared up. There's no IANA Considerations section.\u00a0 Was this intentional?\u00a0 I ask for a few reasons: (1) It's expected (required?), with no actions for IANA, to expressly include a section that says so.\u00a0 It's conspicuously missing here. (2) Why is there no registry for custom properties?\u00a0 I can see that Section 4.5 takes a run at dealing with the collision risk by SHOULDing a particular way of naming custom properties, but it feels to me like a registry is the right way to deal with this.\u00a0 As a consumer of this work, I might not want to reveal (via names) which DNS implementation I'm using, for example. (3) I have a similar question about groups in Section 4.4.2; \"nodnssec\" is an example of something that we might want to register with global semantics, or more generally, that some values might be common in implementations and therefore worth documenting. (4) Do we need a registry of names that are special in the context of catalog zones, e.g., \"zones\", \"ext\", \"group\", \"version\", \"coo\", \"invalid\"? Separately: What action should be taken if a nameserver is already authoritative for a zone (say, is a primary), yet it receives a catalog update that now contains that same zone?\u00a0 This seems like a possible attack that should be discussed.\u00a0 I guess the second-last paragraph of Section 7 covers this, though indirectly.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2023-02-14 10:57:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-31 14:47:43-08:00",
    "text": "This is cool stuff.\u00a0 I assure you I'm going to ballot \"Yes\" after what's below is cleared up. There's no IANA Considerations section.\u00a0 Was this intentional?\u00a0 I ask for a few reasons: (1) It's expected (\"should\", per  BCP 26 ), with no actions for IANA, to expressly include a section that says so.\u00a0 It's conspicuously missing here. (2) Why is there no registry for custom properties?\u00a0 I can see that Section 4.5 takes a run at dealing with the collision risk by SHOULDing a particular way of naming custom properties, but it feels to me like a registry is the right way to deal with this.\u00a0 As a consumer of this work, I might not want to reveal (via names) which DNS implementation I'm using, for example. (3) I have a similar question about groups in Section 4.4.2; \"nodnssec\" is an example of something that we might want to register with global semantics, or more generally, that some values might be common in implementations and therefore worth documenting. (4) Do we need a registry of names that are special in the context of catalog zones, e.g., \"zones\", \"ext\", \"group\", \"version\", \"coo\", \"invalid\"? Separately: What action should be taken if a nameserver is already authoritative for a zone (say, is a primary), yet it receives a catalog update that now contains that same zone?\u00a0 This seems like a possible attack that should be discussed.\u00a0 I guess the second-last paragraph of Section 7 covers this, though indirectly.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-07 07:46:54-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-03 20:05:35-08:00",
    "text": "# Sec AD review of  draft-ietf-dnsop-dns-catalog-zones-08 CC @paulwouters Please refer to  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/  for more information about how to handle DISCUSS and COMMENT positions.  This review uses the format specified in  https://github.com/mnot/ietf-comments/  which allows automated tools to process items (eg to produce github issues) Note that I am a happy user of catalog zones since a few months. While I originally thought this seemed like an \"if all you have is a DNS hammer\" solution, it actually has some very clear advantages over other configuration synchronization methods. Thanks for this work, I am a fan! I do have some issues I'd like to discuss though :) ## DISCUSS ### Section 4.3.1 Versioning What should one do if the version supported is lower than the version of zone received? Attempt to understand it? preventively fail? Are version 1 and 2 compatible? In what ways are they not? Should perhaps version 1 catalog zones always be ignored ? ### Group Properties It seems like Section 4.4.2 defines \"group properties\" that are standardized, while Section 4.5 specifies Private Use group properties. But there is actually no registry created for Group Properties, and no definitions other than \"examples\" are given. This makes the status of, for example \"nodnssec\", unclear. Is this a custom (eg bind implementation only) property or is this really a custom private use entry, in which case the example is bad as it belongs under .bind.ext. Since \"nodnssec\" seems a real use case, why does this document not create an IANA registry for Catalog Zone Group Properties and places \"nodnssec\" in it? ### 5.3 \"MUST be removed\"? ``` \u00a0 \u00a0 \u00a0 \u00a0 Only when the zone was configured from a specific catalog zone, \u00a0 \u00a0 \u00a0 \u00a0 and the zone is removed as a member from that specific catalog \u00a0 \u00a0 \u00a0 \u00a0 zone, the zone and associated state (such as zone data and DNSSEC \u00a0 \u00a0 \u00a0 \u00a0 keys) MUST be removed. ``` What is \"removed\" here? I think perhaps it should be limited to \"MUST no longer be served\". For example, it would be bad if the operator made an error, and ended up briefly removing the zone and \"removing\" (aka destroying) some private DNSSEC keys, complicating the zone restoration. Also, perhaps the implementation wants to simply keep the state on disk but move it to a /var/lib/xxx/zones/archived/ directory. The use of \"remove\" sounds like that might not be allowed. ### Operational Considerations What are the risks and benefits of Extension group properties? Should one try to standardize these instead? Why is this document not doing that based on its operational experience with eg bind and knot and powerdns ? ### Security Considerations Dealing with high value domains eg  gmail.com  is missing. If a large DNS hoster would enable catalog zones for its customers, how can it prevent rogue takeovers? If fully automated, it can never be safely deployed. If each zone needs a manual check, well than we don't really have \"catalog zones\" auto-populating name servers. Is there an expectation that nameservers can do some authorization call before adding a new domain that is already delegated elsewhere? Eg if GoDaddy uses catalog zones, and I am their tiny customer with \" nohats.ca \" and then add a new zone \" gmail.com \", that could cause a significant disruption. Especially if the malicious person would create another domain that depends on \" gmail.com \" in such a way that GoDaddy's servers will start sending \" gmail.com \" data in their additional data reply for other domains. The section only has a \"consumer(s) MAY \", which in my opinion, is far too weak as a security control. As the above example shows, it is just too easy to start poisoning nameservers via implementations that skip this one MAY clause in the Security Considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-10-18 07:02:16-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-11 06:32:41-07:00",
    "text": "This document is still in IETF last call until tomorrow. So it seems just slightly premature for us to approve it with the consensus bit set to Yes. I looked around but did not see any email indicating why this popped up on a telechat before the LC ended.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-06-22 07:34:48-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-19 15:17:48-07:00",
    "text": "This should be easy to fix, but needs to be fixed before the draft progresses: Section 7 establishes a new IANA registry under the Label Distribution Protocol (LDP) Parameters page. Unless I missed something (which happens) it doesn't specify the registration policy as required by  BCP26 . Please see  RFC 5226  section 4.1 for details.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-02 01:47:08-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 09:51:14-07:00",
    "text": "This is really a discuss discuss. With a specification required policy for entries, I think it is quite important to make it clear who has change control over the entries in the registries. I would very much recommend that the information required for a registry entry has an explicit change control field. That field should also note the change probably should reside with the body who own the specification that is referenced in the registry entry.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-19 17:46:32-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-15 13:17:21-07:00",
    "text": "An easy fix but a necessary one: This document makes use of  BCP 14  language without citing  BCP 14 .\u00a0 (I fully blame Jeff for this oversight.)",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-19 21:53:21-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 19:22:54-07:00",
    "text": "The grouping semantics here are problematic. Section 4.1 talks about LS to associate ANC streams with other streams. LS is strictly a synchronization construct, not used to otherwise state relationships between streams. More importantly, there's nothing that prevents it being used to synchronize an arbitrary number of video streams with each other. The problem that arises is best illustrated by this example, where I'm going to transmit two video streams, each with their own ANC data, but need them to be synchronized (e.g., perhaps I'm going to have two border-less screens physically right next to each other for a double-wide image, and synchronization is important to avoid tearing): \u00a0 \u00a0 \u00a0 \u00a0 v=0 \u00a0 \u00a0 \u00a0 \u00a0 o=Al 123456 11 IN IP4  host.example.com \u00a0 \u00a0 \u00a0 \u00a0 s=Professional Networked Media Test \u00a0 \u00a0 \u00a0 \u00a0 i=A test of synchronized video and ANC data \u00a0 \u00a0 \u00a0 \u00a0 t=0 0 \u00a0 \u00a0 \u00a0 \u00a0 a=group:LS V1 V2 M1 M2 \u00a0 \u00a0 \u00a0 \u00a0 m=video 50000 RTP/AVP 96 \u00a0 \u00a0 \u00a0 \u00a0 c=IN IP4 233.252.0.1/255 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:96 raw/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:96 sampling=YCbCr-4:2:2; width=1280; height=720; depth=10 \u00a0 \u00a0 \u00a0 \u00a0 a=mid:V1 \u00a0 \u00a0 \u00a0 \u00a0 m=video 50002 RTP/AVP 96 \u00a0 \u00a0 \u00a0 \u00a0 c=IN IP4 233.252.0.1/255 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:96 raw/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:96 sampling=YCbCr-4:2:2; width=1280; height=720; depth=10 \u00a0 \u00a0 \u00a0 \u00a0 a=mid:V2 \u00a0 \u00a0 \u00a0 \u00a0 m=video 50010 RTP/AVP 97 \u00a0 \u00a0 \u00a0 \u00a0 c=IN IP4 233.252.0.2/255 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:97 smpte291/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:97 DID_SDID={0x61,0x02};DID_SDID={0x41,0x05} \u00a0 \u00a0 \u00a0 \u00a0 a=mid:M1 \u00a0 \u00a0 \u00a0 \u00a0 m=video 50012 RTP/AVP 97 \u00a0 \u00a0 \u00a0 \u00a0 c=IN IP4 233.252.0.2/255 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:97 smpte291/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:97 DID_SDID={0x61,0x02};DID_SDID={0x41,0x05} \u00a0 \u00a0 \u00a0 \u00a0 a=mid:M2 If the recipient of these mutually synchronized streams needs to reintegrate the ANC data into the video for offloading to an HDMI connection, how does it know which ANC stream to insert into which video stream? There needs to be some additional association mechanism here. You can either add an attribute to the smpte291 media sections that clearly indicates which video stream they correspond to, or you can include the smpte291 packets in the same stream as the corresponding video, like so: \u00a0 \u00a0 \u00a0 \u00a0 v=0 \u00a0 \u00a0 \u00a0 \u00a0 o=Al 123456 11 IN IP4  host.example.com \u00a0 \u00a0 \u00a0 \u00a0 s=Professional Networked Media Test \u00a0 \u00a0 \u00a0 \u00a0 i=A test of synchronized video and ANC data \u00a0 \u00a0 \u00a0 \u00a0 t=0 0 \u00a0 \u00a0 \u00a0 \u00a0 m=video 50000 RTP/AVP 96 97 \u00a0 \u00a0 \u00a0 \u00a0 c=IN IP4 233.252.0.1/255 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:96 raw/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:97 smpte291/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:96 sampling=YCbCr-4:2:2; width=1280; height=720; depth=10 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:97 DID_SDID={0x61,0x02};DID_SDID={0x41,0x05} \u00a0 \u00a0 \u00a0 \u00a0 m=video 50002 RTP/AVP 96 97 \u00a0 \u00a0 \u00a0 \u00a0 c=IN IP4 233.252.0.1/255 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:96 raw/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=rtpmap:97 smpte291/90000 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:96 sampling=YCbCr-4:2:2; width=1280; height=720; depth=10 \u00a0 \u00a0 \u00a0 \u00a0 a=fmtp:97 DID_SDID={0x61,0x02};DID_SDID={0x41,0x05} (See  RFC4733  for an example of a payload that performs stream association in this fashion)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-13 07:43:58-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-13 06:23:06-07:00",
    "text": "I support Roman's Discuss. I am sympathetic to the tsv-art reviewer's concerns that this document is focused on video technology of 5 years ago and may lack relevant in the current world.\u00a0 I don't intend to hold a Discuss point for any specific resolution, but I do think the IESG should discuss whether this concern affects the value of publishing this document as an RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-21 18:40:32-08:00",
    "end_reason": "position_updated",
    "start": "2019-06-11 18:24:35-07:00",
    "text": "(1) I worry that the level of detail in the in the Compression Performance Evaluation (Section 4.1) is insufficient for implementation.\u00a0 Specifically: (a) Per \u201cInitially, for the codec selected as a reference one (e.g., HEVC or VP9), a set of 10 QP quantization parameter) values should be specified (in a separate document on Internet video codec testing) and corresponding quality values should be calculated.\u201d -- How should a set of QPs be specified? --How should the quality values be calculated? -- What does the text \u201c(in a separate document on Internet video codec testing)\u201d mean? (b) Per \u201cA list of video sequences that should be used for testing as well as the 10 QP values for the reference codec are defined in a separate document \", what document is that?\u00a0 Is it  draft-ietf-netvc-testing ? (2) Per the Security Considerations Section (Section 5) -- What does \u201ccodec implementation (for both an encoder and a decoder) should cover the worst case of computational complexity, memory bandwidth, and physical memory size\u201d mean? -- Please add additional language that codec should be written in a defensive style as they will be processing untrusted input.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-02-27 11:46:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2023-02-27 11:45:08-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop (I guess this is true but maybe you should review 7761 to make sure this is true!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: ``` Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message. ```",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-02-27 11:46:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2023-02-27 11:46:17-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop. (I guess this is true but maybe you should review 7761 to make sure!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: ``` Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message. ```",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-02-27 11:46:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2023-02-27 11:46:30-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop. (I guess this is true but maybe you should review 7761 to make sure!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: ``` Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message. ``` x",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-01 17:12:13-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-27 11:46:55-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop. (I guess this is true but maybe you should review 7761 to make sure!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: \u00a0  Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-03-02 02:28:39-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-28 02:24:56-08:00",
    "text": "# GEN AD review of  draft-ietf-pim-null-register-packing-14 CC @larseggert Thanks to Behcet Sarikaya for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/EyaOvVl155DHm7IhDZUBHOqRijY ). ## Discuss ### Section 7, paragraph 2 ``` \u00a0 \u00a0  For IPv6 PIM Packed Null-Register messages or PIM Packed Register- \u00a0 \u00a0  Stop messages, the DR MUST perform Path MTU Discovery.\u00a0 For IPv4, the \u00a0 \u00a0  DR SHOULD perform Path MTU Discovery.\u00a0 This allows the DR to fragment \u00a0 \u00a0  packets as needed.\u00a0 However, in order to avoid fragmentation \u00a0 \u00a0  altogether, a DR sending packed registers SHOULD limit the number of \u00a0 \u00a0  records such that the message can fit within the Path MTU.\u00a0 A record \u00a0 \u00a0  consists of a Group Address and Source Address pair. ``` *How* is the DR supposed to perform PMTUD? If this is defined in another PIM doc, please normatively reference that. Otherwise, specify here. Also, isn't the goal of PMTUD is to avoid fragments, not to allow \"the DR to fragment packets as needed\"?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2023-03-26 16:55:00-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-01 00:17:46-08:00",
    "text": "Feel free to set me straight here if I'm wrong, but: Section 2 says: \"This section allocates a bit ...\" Doesn't this mean either (a) there should be a registry for these bits, and if there is, there should be one or more corresponding IANA actions; or (b) this document should update  RFC 7761  so that the allocation of a previously reserved bit is discoverable somehow?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-03-09 00:17:57-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-27 04:47:03-08:00",
    "text": "Hi, Thanks for this document.\u00a0 I've flagged this as discuss because I found part of the spec to by unclear: (1) p 3, sec 3.\u00a0 PIM Packed Null-Register message format \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |PIM Ver| Type\u00a0 |Subtype|\u00a0 FB\u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Checksum\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0  Group Address[1]\u00a0  (Encoded-Group format)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0  Source Address[1]\u00a0 (Encoded-Unicast format)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0  Group Address[N]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 . \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0  Source Address[N]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Figure 2: PIM Packed Null-Register message format I'm not familiar with PIM, but it wasn't clear to me how the receiver infers how many addresses are in the message.\u00a0 E.g., I note that the Join/Prune Message Format contains a count \"Num Groups\", but conversely the \"Hello Message Format\" does not include a count of options.\u00a0 Hence, I presume that the N, the address count, is inferred by the packet length?\u00a0 If so, would that be worth stating here (and in section 4)?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-03-02 04:04:20-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-28 11:54:06-08:00",
    "text": "Thanks for working on this document. I would like to discuss - what is the \"P\" bit in section 2 and what is \"FB\" in section 3? without proper description of those fields this specification will be confusing to be implemented. May be I have missed something in the referenced specifications, in that case I would prefer to have the references properly stated here. I also support Lars's and Rob's discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-06-13 23:43:46-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-19 02:37:42-07:00",
    "text": "Has a  RFC6390  performance directorate review done for the 2.X metrics? It should. See  http://www.ietf.org/iesg/directorate/performance-metrics.html I guess that the metrics will be recorded in the future (See  draft-ietf-ippm-metric-registry-06 ), right?  For example, Flow Completion Time and Packet Loss Synchronization are new, I believe. And some other metrics are already documented in  RFC6390  compliant documents. Pointers should be provided. See  https://tools.ietf.org/html/draft-ietf-xrblock-independent-burst-gap-discard-01#appendix-A  for an example",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-30 13:23:50-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-09 15:15:22-07:00",
    "text": "The situation w.r.t. MOP values 5, 6, and 7 seems inconsistent to me. We are not allocating them, but we are changing the  RFC 6550  behavior in the presence of at least one of them (but are not currently claiming to Update 6550).\u00a0 I have some further thoughts in the COMMENT section, but I don't think the current state is consistent enough to be approved as-is.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-11-11 08:27:05-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-02 10:27:44-07:00",
    "text": "Now that I know that an IANA registry exists for MOP, codepoint 7 should be included in the IANA considerations for the \"Mode of Operation\" Registry.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 11:29:08-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 19:08:01-07:00",
    "text": "In Section 3.1.2, we say that: \u00a0  o\u00a0 If the target SID (2001:db8:B:4::) is not locally instantiated, \u00a0 \u00a0 \u00a0 the packet is discarded However,  RFC 8754  \u00a74.3.2 seems to say that the next header is processed in this case.\u00a0  Only if the target SID is both not locally instantiated and does not represent a local interface will the packet be discarded, if I understand correctly.\u00a0 (Similarly for the analogous statement in \u00a73.2.2.) There's also quite a few other internal incosistencies in this document, such as copy/paste chunks that refer to \"N4\" as executing a given SID in a scenario where it is actually a different node doing so, many instances where a given IP address or SID does not match up with the addressing structure listed in Section 1.3, places where we seem to say that an SR ingress node can be a classic IPv6 node that lacks SRv6 capabilities, etc.\u00a0 Individually, many of these would be nit-level (and indeed are called out specifically in the NITS section of my ballot comment), but collectively they seem to indicate a document that is not yet in publishable state.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-06-02 11:50:09-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-01 14:48:10-07:00",
    "text": "Thank you for the work put into this document. It is comforting (even if not surprising) that the simple \"good old\" ping/traceroute work on a SRv6 network ;-) Thanks to Carlos Bernardos for his INT-REVIEW at  https://datatracker.ietf.org/doc/review-ietf-6man-spring-srv6-oam-10-intdir-telechat-bernardos-2021-05-28/ Thanks to Ole Tr\u00f8an for his shepherd document even if I regret the lack of justification for 'standards track'. Especially, because the abstract is mainly about ping/traceroute, hence should be informational but the O-flag is indeed standard track. So, all in all, this is OK. Please find below two blocking but trivial DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated), and one nit. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2.1 -- As \"a penultimate segment SHOULD NOT be a Penultimate Segment Pop (PSP) SID\" is normative, then the network programming  RFC 8986  should be a normative reference. Trivial to fix. -- Section 9.2 -- Trivial to fix,  RFC 8174  should be normative.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-01-31 13:16:51-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 18:48:03-07:00",
    "text": "I can't get past the feeling this document is really two different documents mashed together. One is a Standards Track, 6man document, that defines the O-flag. All the meat of that document is in \u00a72.1 and \u00a72.2, it would make a nice, compact, readable 3 or 4 page RFC (maybe a little more once all the boilerplate was in). The other is an Informational, SPRING document, that talks about use cases at some length. It seems both cruel and counterproductive to force SRv6 implementors who are implementing the O-flag to read through the entire balance of the document just to be sure they haven't missed something important. Remember these documents will live a long time, and it seems irresponsible to clutter the essential document set with inessential use cases. My suggestion is to split the document as outlined above.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-06-02 09:47:03-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-24 11:52:38-07:00",
    "text": "I would like to clarify that when the pseudocode says \"Send the copied packet, along with a timestamp to the OAM process for telemetry data collection and export,\" that this \"process\" is colocated on the router, and that this process further digests the data so that there is much less than 1 packet going out of the box per O-bit packet processed. If there is a case where each O-bit packet generates an entire packet going off the router to a controller or external OAM process, there are extremely unfortunate corner cases that are not sufficiently mitigated by rate-limiting.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-10 11:47:01-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 18:42:57-07:00",
    "text": "The privacy implications of the O-flag needs to be more clearly articulated.\u00a0 It provides a dual use capability -- there is tangible benefit for OAM use cases, but also reduces the friction for surveillance uses cases. The SECDIR review ( https://mailarchive.ietf.org/arch/msg/secdir/FeTu7x7-okw7w7-T6dZRFhJHpAo/ ) pointed this out in -09.\u00a0 The changes made to the Security Considerations in -10 were helpful, but primarily focused on reiterating the security assumptions of the SR domain boundary and the degree of protection of the SRH.\u00a0  My recommendation would be for an explicit Privacy Considerations section with the following (approximate) text: NEW 7.\u00a0 Privacy Considerations The per-packet marking capabilities of the O-flag provides a granular mechanism to collect telemetry.\u00a0 When this collection is deployed by an operator with knowledge and consent of the users, it will enable a variety of diagnostics and monitoring to support the OAM and security operations use cases needed for resilient network operations.\u00a0 However, this collection mechanism will also provide an explicit protocol mechanism to operators for surveillance and pervasive monitoring use cases done contrary to the users\u2019 consent.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-12-19 07:36:32-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-17 19:49:29-08:00",
    "text": "I think this should be easy to clear up but I think the following text is vague and needs be clarified \"\u00a0 Among relay addresses that have an equivalent preference as described \u00a0  above, a Happy Eyeballs algorithm for AMT MUST use the Destination \u00a0  Address Selection defined in Section 6 of [ RFC6724 ], as required by \u00a0  [ RFC8305 ].\" Does this mean that the addresses are sorted as defined in Section 6 of [ RFC6724 ] or as defined in Section 4 of [ RFC8305 ] that defines further steps on top of RC6724 including ordering by RTTs, address family interleaving etc. I think this needs to be stated explicitly.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-21 19:01:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 07:07:13-07:00",
    "text": "Let's discuss whether we need to be a bit more clear about what behavior should be expected when the exclude-lite leaf has value true vs. false -- the apparent inconsistency between \"exclude\" in the leaf name and the positive verb \"track\" in the description left me confused.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-07-21 01:36:48-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 02:55:15-07:00",
    "text": "Hi, I appreciate that this YANG model has already passed a YANG doctor review, but this discuss is to understand the reasoning as to why both IGMP snooping and MLD snooping are in the same YANG module, yet have top level features to separate their functionality. \u00a0 \u00a0 4. IGMP and MLD Snooping YANG Module \u00a0 \u00a0 \u00a0 feature igmp-snooping { \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Support IGMP snooping.\"; \u00a0 \u00a0 \u00a0 \u00a0 reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"RFC 4541\"; \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 feature mld-snooping { \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Support MLD snooping.\"; \u00a0 \u00a0 \u00a0 \u00a0 reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"RFC 4541\"; \u00a0 \u00a0 \u00a0 } It seems strange to me to have the entire YANG Model split under two separate feature statements. I believe that it would have been better to split this into two separate YANG models, both following the same structure.\u00a0 Possibly, a common YANG module could have been used to share groupings and definitions, but even then duplicating the contents of the model so that the description statements could be correct/accurate would be more helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-16 20:44:50-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-14 15:52:18-08:00",
    "text": "[[ discuss ]] [ section 4.1 ] * I haven't tried to read the IEEE documents referenced here, but I'm \u00a0 hoping this question can be easily addressed by those who have. \u00a0 Can this Destination MAC rewriting (\"replace ... with alternate values\") \u00a0 ever affect IP and IP-related traffic that might carry MAC addresses, \u00a0 like ARP or NDP? \u00a0 If there could be impact to MAC-carrying traffic like ARP/NDP then it \u00a0 seems likely that more text is required here about that interaction \u00a0 (and I should probably figure out how to go read those references \u00a0 documents/clauses).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-04-11 08:51:53-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 19:10:22-07:00",
    "text": "\u00a76: >\u00a0 \u00a0 \u00a0 \u00a0  If the type is given as an UUID or a string, it is interpreted >\u00a0 \u00a0 \u00a0 \u00a0  as a W3C regular expression, which matches a resource of type >\u00a0 \u00a0 \u00a0 \u00a0  'yang:uuid' or 'string' if the given regular expression >\u00a0 \u00a0 \u00a0 \u00a0  matches the resource string. This needs a citation for what is meant by \"W3C regular expression.\" I'm making a wild guess that this refers to the regular expressions defined for use with XSD? If so, the reference is presumably this document: https://www.w3.org/TR/xmlschema11-2/",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-11 12:18:07-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-08 13:44:43-07:00",
    "text": "I think we may need to double-check that the example in Appendix C is fully compliant with the main spec.\u00a0 In particular, are the  elments properly sorted?\u00a0 (I'm less sure whether the  time needs to match a\u00a0 or whether the  is good enough for that.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-25 07:41:37-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-04 14:09:40-07:00",
    "text": "(1) Section 3.5, Alarm Life-Cycle.\u00a0 The text states that \u201cA server SHOULD describe how long it retains cleared/closed alarms: until manually purged or if it has an automatic removal policy.\u201d How is this retention policy described?\u00a0 Is that in scope for this document? (2) Section 4.2, Alarm Inventory.\u00a0 The text states that \u201cA server MUST implement the alarm inventory in order to enable controlled alarm procedures in the client.\u201d What is the expected server behavior if a client sends an alarm type not in the inventory (and it isn\u2019t part of the dynamic addition process)? (2) Section 10, Security Considerations.\u00a0 It seems like \u201c/alarms/alarm-list/alarm/set-operator-state\u201d should be listed as an operation in the YANG model that presents a security issues (just like \u201cpurge-alarms\u201d).\u00a0 Consider if one altered the operator alert state causing the alarm management procedures to miss an alert (e.g., setting an alert to \u201cclosed\u201d before any action is taken). (3) Section 10, Security Considerations.\u00a0 I don\u2019t know must about the implementations, but wouldn\u2019t compressing alerts (per compress-alarms and compress-shelved-alarms operations) remove them from consideration by alarm management procedures?\u00a0 If so, these would be a sensitive operation that would need to be listed as the concern equivalent to the current text for purge-alarms.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-07-06 07:16:39-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-05 05:09:32-07:00",
    "text": "This document really needs some discussion of the interoperability implications of this change. Assuming I understand correctly, it is not possible to use this mechanism with any existing content type, because receiving implementations will expect to see a multipart and thus refuse to accept the message. Is that correct? If so, it seems like a limitation which needs to be called out explicitly",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-19 11:08:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 11:24:20-08:00",
    "text": "I have some questions and comments about the text below, which seems like it creates significant scope for interoperability failures: \"Where the benefits of directly using a secondary unit in a SenML pack \u00a0  outweigh the above considerations, the use of secondary units in \"u\" \u00a0  fields MAY be enabled by indicating a new SenML version that \u00a0  specifically allows this and/or by using a field with a label name \u00a0  that ends with the \"_\" character (\"must-understand\" field) whose \u00a0  definition specifically allows this.\u00a0 The definition of these \u00a0  versions and fields is outside the scope of the present \u00a0  specification; one such definition is proposed in \u00a0  [ I-D.bormann-core-senml-versions ].\" Do I understand correctly that this allows secondary units in (1) SenML packs that use some version number besides 10, and (2) SenML fields named with \"_\" that are in packs where the version number is 10? What is the motivation for providing two different mechanisms to signal that secondary units are in use? I.e., why isn't one or the other of these mechanisms sufficient? Without defining either a new version that supports secondary units or fields with \"_\", I don't understand how this update to  RFC 8428  is complete enough to be implementable. It says other versions and fields are out of scope, but don't some need to be defined in order for the normative MAY in this text to be actionable?  The label names registry policy is Expert Review, which does not require formal documentation of the registry entry. Where is the \"definition [that] specifically allows this\" expected to occur? Presumably some implementations are already using SenML. What is an implementation supposed to do if it encounters a label name containing \"_\" that it does not understand in a version 10 pack? It looks like this text went in a week ago but it's a pretty significant change to the extensibility story for SenML, so I'm wondering if the WG had a chance to come to consensus on it? I'm not super familiar with SenML so apologies if the answers to some of these questions are obvious.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-19 08:50:40-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-18 16:22:25-08:00",
    "text": "\u00a0  +-----------+-------------------+-------+-----------+-----+---------+ \u00a0  | secondary | description\u00a0 \u00a0 \u00a0  | SenML |\u00a0 \u00a0  scale | off | refer-\u00a0 | \u00a0  | unit\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | unit\u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | set | ence\u00a0 \u00a0 | \u00a0  +-----------+-------------------+-------+-----------+-----+---------+ \u00a0  [...] \u00a0  | km\u00a0 \u00a0 \u00a0 \u00a0 | kilometer\u00a0 \u00a0 \u00a0 \u00a0  | km\u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 1000 |\u00a0  0 | RFCthis | The associated SenML unit would be just 'm', not 'km'.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-09 20:00:31-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 15:55:04-08:00",
    "text": "Section 11.2 of the IANA considerations lists an actual OID value to use for the \"sip.clue\" media feature tag, but the IANA last call review indicates that the decimal value for sip.clue will be assigned at registration, so it is incorrect to claim that it will be 1.3.6.1.8.4.29. Squatting on the next available codepoint like this is quite risky and I really want to discourage this practice.\u00a0 We had a lot of trouble in TLS recently with *three* different extensions attempting to use the same codepoint, which was not fun to resolve.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-06-29 09:24:57-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-28 18:28:54-07:00",
    "text": "These should be easy to fix: - This draft pretty clearly updates  RFC 5545 . But it isn't marked as doing so. - Sections 8.3 and 8.4 define new registries, but do not state a registration policy. They refer to  RFC 5545  section 8.2.6. That section talks about registering new values, but does not appear to talk about new registries. I think it's likely that the registration procedures from 5545 section 8.2.1 actually apply. If so, these sections should cite that.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-06-29 10:15:19-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-28 17:45:21-07:00",
    "text": "This should be really easy to clear...  Thank you for addressing the SecDir reviewers comments.\u00a0 I'd like to see the updated text added in the editor's version of the draft that addresses the secdir review.\u00a0 In particular, the email thread just says that text was added to cover possible new threats and I'd like to see that and the new privacy considerations section. https://www.ietf.org/mail-archive/web/secdir/current/msg06636.html",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-29 09:40:09-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-29 03:54:15-07:00",
    "text": "- I think adding some privacy considerations to this would be good, either as new text or via references.\u00a0 Did the WG consider privacy issues? Some that occur to me are: \u00a0  - names, descriptions and identifiers here are all ones that \u00a0 \u00a0  might allow (re)identification in unexpected ways \u00a0  - the UID property in particular probably ought be random and \u00a0 \u00a0  probably ought not be re-used for anything else, some  RFC2119 \u00a0 \u00a0  SHOULD statements about that would seem like they'd be good. \u00a0  - doing a refresh against a calendar at the expected frequency \u00a0 \u00a0  could be a good way to re-identify someone - if I can read the \u00a0 \u00a0  expected frequency and some IP address connects (even all over \u00a0 \u00a0  TLS) at about that regularity then I can be reasonably sure \u00a0 \u00a0  that the client is someone subscribed to that address, and \u00a0 \u00a0  maybe use that to track a person's movement across various \u00a0 \u00a0  networks. (That's different from the text in section 7 which \u00a0 \u00a0  assumes that the URL is what's tracked, but the connection \u00a0 \u00a0  can be just as revealing, for some calendars.) I'm not trying to insist all that analysis be documented in this draft but I would hope that the WG have considered the issues and how best to document those and have a plan to do that. (If I'm told such a plan exists and what it is, I'll clear.) This is related to, but a little different from, Kathleen's discuss, depending on the added privacy considerations text which I've not managed to find in the secdir review thread.\u00a0 But this should be as easily cleared I'd guess.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-09-27 10:26:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-09-26 11:01:36-07:00",
    "text": "I'm uncertain what section 2.1.3. actually recommends. My understanding is that it is recommend to still send retransmit some message even if the Rl was reached and to that every 30s basically forever. First of all I think this still needs a termination criteria when to stop to try to retransmit finally. And the I don't understand why this is needed, instead of e.g. just using a larger Rl value? Can you please clarify!",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-02-14 03:14:48-08:00",
    "end_reason": "position_updated",
    "start": "2017-09-27 10:26:12-07:00",
    "text": "I'm uncertain what section 2.1.3. actually recommends. My understanding is that it is recommend to still retransmit some message even if the Rl was reached and to do that every 30s basically forever. First of all I think this still needs a termination criteria when to stop to try to retransmit finally. And then I don't understand why this is needed, instead of e.g. just using a larger Rl value? Can you please clarify!",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-12-13 02:47:36-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-12-12 14:17:05-08:00",
    "text": "his is generally a fine document, but it needs a few minor changes that need doing before it is approved for publication:",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-12-14 05:03:03-08:00",
    "end_reason": "position_updated",
    "start": "2017-12-13 02:47:36-08:00",
    "text": "This is generally a clearly written document, but it needs a few minor changes before I can recommend its approval for publication. 1) In Section 3.2: \u00a0  o\u00a0 When a router receives multiple overlapping ranges, it MUST \u00a0 \u00a0 \u00a0 conform to the procedures defined in \u00a0 \u00a0 \u00a0 [ I-D.ietf-spring-conflict-resolution ]. RFC 2119  keyword usage makes the reference a Normative reference, yet it is currently listed as informative. 3.4.\u00a0 SRMS Preference TLV \u00a0  The Segment Routing Mapping Server Preference TLV (SRMS Preference \u00a0  TLV) is used to advertise a preference associated with the node that \u00a0  acts as an SR Mapping Server.\u00a0 The role of an SRMS is described in \u00a0  [ I-D.ietf-spring-segment-routing-ldp-interop ]. As draff-ietf-spring-segment-routing-ldp-interop needs to be read in order to understand what SR Mapping Server is, this reference must also be Normative. \u00a0 SRMS preference is defined in [ I-D.ietf-spring-conflict-resolution ]. This just confirms that this reference must be Normative. 2) In Section 3.1: \u00a0  When multiple SR-Algorithm TLVs are received from a given router, the \u00a0  receiver SHOULD use the first occurrence of the TLV in the Router \u00a0  Information LSA.\u00a0 If the SR-Algorithm TLV appears in multiple Router \u00a0  Information LSAs that have different flooding scopes, the SR- \u00a0  Algorithm TLV in the Router Information LSA with the area-scoped \u00a0  flooding scope SHOULD be used.\u00a0 If the SR-Algorithm TLV appears in \u00a0  multiple Router Information LSAs that have the same flooding scope, \u00a0  the SR-Algorithm TLV in the Router Information (RI) LSA with the \u00a0  numerically smallest Instance ID SHOULD be used and subsequent \u00a0  instances of the SR-Algorithm TLV SHOULD be ignored. In the last 2 sentences: why are you using SHOULD (twice) instead of MUST? This seems to affect interoperability. (I think there is similar text in another section.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-02-03 04:14:33-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-16 06:57:16-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-opsec-indicators-of-compromise-03 CC @evyncke Thank you for the work put into this document. It is interesting and an easy read and so refreshing to read the British \"defense\" ;-) Once my DISCUSS is cleared, I intend to ballot a YES. Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Jen Linkova for the shepherd's detailed write-up including the WG consensus (always low response rate in OPSEC) *and* the justification of the intended status.  Other thanks to Dave Thaler, the Internet directorate reviewer (at my request), please consider this int-dir review: https://datatracker.ietf.org/doc/review-ietf-opsec-indicators-of-compromise-03-intdir-telechat-thaler-2023-01-13/ Dave has raised interesting issues in the text, notably linked to IP addresses, that I fully second; _I have yet to read any reply from the authors_, but the review was posted just before the week-end and we are on the blue Monday. I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 3.1 no IPv6 data I am *really* surprised to only see IPv4 addresses in the numbers, even if today AlienVault has 7k IPv6 addresses as IoC vs. 3M IPv4 addresses. Please include some IPv6 statistics. I appreciate that this issue does not really comply to a DISCUSS point but it is so easy to address and I would like to start a discussion with the authors and the AD.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-23 19:49:53-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-23 19:49:02-08:00",
    "text": "lease update to reflect the changes made in draft-ietf-calext-eventpub-extensions(e.g., there is no longer STRUCTURED-LOCATION and VLOCATION plays a similarrole).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-02 15:27:59-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 19:49:53-08:00",
    "text": "lease update to reflect the changes made in draft-ietf-calext-eventpub-extensions-17(e.g., there is no longer STRUCTURED-LOCATION and VLOCATION plays a similarrole).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-11-29 10:59:15-08:00",
    "text": "(1)  RFC 8300  is pretty clear that \"Metadata privacy and security considerations are a matter for the documents that define metadata format.\"\u00a0 Some of the metadata context headers defined in this document clearly have privacy considerations that need to be documented (e.g., policy ID and source/destination group serve to concretely identify flows that are related in some way), though some may not have much that needs documenting (e.g., the forwarding context metadata seems to just be extracting out information that is already present in the packet being wrapped).\u00a0 Regardless, we need to have some discussion of the privacy and security considerations of the new metadata context headers, even if that is just \"no new considerations\" for some of them. (2) I think we need to discuss the Flow ID context header further.\u00a0 Is it intended to just be a container to hold a flow identifier already present in the contained packet (such as the IPv6 Flow Label or MPLS Entropy Label that are called out), or can it also be used to apply a new flow identifier at the SFC layer? The named examples of a flow ID are both 20 bits long; if that is an exhaustive listing, shouldn't we update the figure accordingly (to include Length=3, four leading bits of padding, and a trailing byte of padding)?\u00a0 If that is not an exhaustive listing and longer flow identifiers are expected, how do we know what length of flow identifier is being conveyed? (3) If we are to allow for specifying the \"logical grouping of source and/or destination objects\" in \u00a74.6 (emphasis on \"and/or\"), but the context header always conveys both a source group and dest group field, do we need to reserve a dedicated value for \"no group information specified\"?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:38:22-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-29 02:59:01-08:00",
    "text": "Thank you for the work on this document. I have some comments, mostly having to do with clarifications and improvement of text for readability. I'd like answers to two main points: first - I believe the lack of normative references to the documents that define the fields this document registers into IANA is important enough to warrant some discussion. Second - I'd like some clarification about interoperability. More details below. Francesca 1. ----- \u00a0 \u00a0 \u00a0 Tenant ID: Represents an opaque value pointing to Orchestration \u00a0 \u00a0 \u00a0 system-generated tenant identifier.\u00a0 The structure and semantics \u00a0 \u00a0 \u00a0 of this field are deployment specific. FP: I am worried about interoperability, as the field is defined as deployment specific. Could you clarify why you don't think this is an issue? Also, please add a normative reference to the section and document defining tenant identification. 2. ---- Section 4.3 FP: Same comment as above for Node ID: please add a reference and explain interoperability, as this is defined as deployment specific. 3. ----- Sections 4.4, 4.5 FP: I do think these fields need references to the documents they are defined in. (I am aware section 2.1 and the normative references should help, but I think it would be much clearer to have direct links to the right place in the text.) For Flow ID, if I understand correctly, this document defines it high level and gives examples of what value it can take. I would clarify that in the first paragraph of the section (as you do for Section 4.6), instead of having the references only in the \"Length\" paragraph.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-11 05:35:42-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 14:38:22-08:00",
    "text": "Thank you for the work on this document. I have some comments, mostly having to do with clarifications and improvement of text for readability. I'd like answers to two main points: first - I believe the lack of normative references to the documents that define the fields this document registers into IANA is important enough to warrant some discussion. Second - I'd like some clarification about interoperability. More details below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0 \u00a0 \u00a0 Tenant ID: Represents an opaque value pointing to Orchestration \u00a0 \u00a0 \u00a0 system-generated tenant identifier.\u00a0 The structure and semantics \u00a0 \u00a0 \u00a0 of this field are deployment specific. FP: I am worried about interoperability, as the field is defined as deployment specific. Could you clarify why you don't think this is an issue? Also, please add a normative reference to the section and document defining tenant identification. 2. ---- Section 4.3 FP: Same comment as above for Node ID: please add a reference and explain interoperability, as this is defined as deployment specific. 3. ----- Sections 4.4, 4.5 FP: I do think these fields need references to the documents they are defined in. (I am aware section 2.1 and the normative references should help, but I think it would be much clearer to have direct links to the right place in the text.) For Flow ID, if I understand correctly, this document defines it high level and gives examples of what value it can take. I would clarify that in the first paragraph of the section (as you do for Section 4.6), instead of having the references only in the \"Length\" paragraph.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-31 00:49:09-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-11 05:35:42-08:00",
    "text": "Thank you for the work on this document, and for partly addressing my previous DISCUSS. I only have the one point about interoperability left, which I believe requires some additional clarification in the text. More details below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0 \u00a0 \u00a0 Tenant ID: Represents an opaque value pointing to Orchestration \u00a0 \u00a0 \u00a0 system-generated tenant identifier.\u00a0 The structure and semantics \u00a0 \u00a0 \u00a0 of this field are deployment specific. FP: I am worried about interoperability, as the field is defined as deployment specific. Could you clarify why you don't think this is an issue? Please see the telechat minutes for more details about the discussion and context of this comment:  https://www6.ietf.org/iesg/minutes/2021/narrative-minutes-2021-12-02.txt",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-01-11 06:43:43-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 11:28:01-08:00",
    "text": "1. I notice that in his RTGDIR review of version 08 [*], Stig Venaas suggested some improvements to the security considerations section. This was subsequently discussed and Yuehua Wei proposed some new text [**] for version 09. That text isn\u2019t present, and I don\u2019t see any further resolution on the mailing list either. I\u2019d appreciate it if the topic were closed by either adding the proposed text, or some other text to resolve Stig\u2019s concern, or explanation of why no change was made. [*]  https://datatracker.ietf.org/doc/review-ietf-sfc-nsh-tlv-08-rtgdir-lc-venaas-2021-09-29/ [**]  https://mailarchive.ietf.org/arch/msg/sfc/Q2Snf_ZLTkJ1augbaWpmNYlwFBU/ 2. In \u00a78.2, the two first references, [GROUPBASEDPOLICY] and [GROUPPOLICY] are deficient. At a minimum, a reference should provide enough information to allow a reader to straightforwardly determine how to retrieve it. This is true even if it\u2019s not an openly-available online source. These two references have less than the bare bones, I don\u2019t know how to find them or refer to them.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-01-27 11:51:35-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 22:34:21-08:00",
    "text": "I'm having trouble understanding the first thing you've got in Section 7.\u00a0 You have one table of assignments to make, but you're referencing two distinct sub-registries under \"Network Service Header (NSH) Parameters\", namely \"NSH MD Class\" and \"NSH IETF-Assigned Optional Variable-Length Metadata Types\".\u00a0 There doesn't appear to be a \"metadata context type registry\".\u00a0 I think this change clarifies what you mean, but please tell me if I'm wrong: OLD: \u00a0  IANA is requested to assign the following types from the \"NSH IETF- \u00a0  Assigned Optional Variable-Length Metadata Types\" (0x0000 IETF Base \u00a0  NSH MD Class) registry available at [IANA-NSH-MD2]: \u00a0  This document defines the following new values (Table 1) in the \u00a0  Network Service Header (NSH) metadata context Type registry: NEW: \u00a0  IANA is requested to assign the following types (Table 1) from the IETF \u00a0  Review range in the \"NSH MD Class\" sub-registry of the \"Network Service \u00a0  Header (NSH) Parameters\" registry:",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-04-26 08:36:42-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 09:39:51-07:00",
    "text": "Setting this ballot as DISCUSS for now, pending the resolving of Ben's DISCUSS items. Donald Eastlake communicated changes that will resolve these, so waiting on that new ID.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-05-10 07:30:16-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-06 08:30:30-07:00",
    "text": "I will be switching to \"Yes\" once one issue mentioned below is discussed: I would like to have a quick discussion about your versionning model: \u00a0  struct { \u00a0 \u00a0 \u00a0  uint8 major; \u00a0 \u00a0 \u00a0  uint8 minor; \u00a0  } TB_ProtocolVersion; What is the significance of \"major\" and \"minor\" versions? Any rules on what kind of changed would require increment of the \"major\" version. Any restrictions on what must remain the same when the \"major\" (or \"minor\") version gets incremented? Any requirements on backward compatibility when only the \"minor\" version is incremented?",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2015-10-19 09:18:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-16 15:18:09-07:00",
    "text": "First,\u00a0 I have a number of specific comments.\u00a0  Some of these are hazards to technical interoperability; I've tried to include those in my discuss - but the general point is that it is very hard to tell a number of details because the structure is assumed.\u00a0  Having read this document, I do not think that I could properly implement DNCP from scratch. Obviously, I can guess at the answers - but that doesn't let everyone interoperate well.\u00a0  Examples include: a) What is a topology graph?\u00a0 When is it created, modified, or destroyed?\u00a0 Is it a conceptual artifact constructed from the various TLVs?\u00a0 I think a quick paragraph describing it would help. b) How are peer relationships discovered and established and destroyed?\u00a0 I really can't tell from the draft and even a quick scan of  RFC 6206  doesn't give any hints. c) It looks like the TLVs are sent one after another in a datagram or stream across a socket.\u00a0 The closest I see to any detail is \"TLVs are sent across the transport as is\".\u00a0  d) As far as I can tell, Trickle is used to decide basically how often to send information - but the details of this and the interactions aren't clear to me. I suspect that there are dependencies on the HNCP draft that would make this a lot easier to understand but since we want it to progress separately, the document does need to stand alone. Although not noted in the Shepherd's report, I did have a thorough Routing Directorate review done and the draft was improved from that. 8) In Sec 4.6 \"\u00a0  o\u00a0 The origination time (in milliseconds) of R's node data is greater \u00a0 \u00a0 \u00a0 than current time in - 2^32 + 2^15.\"\u00a0 Since origination time hasn't yet been introduced, I'm going on an assumption that it means when R's node data was originated from R.\u00a0 So - this requirement is saying that R's node data must have been generated in the future (but already known by the local node)??? 9) In Sec 4.6 \"They MAY be removed immediately after the topology graph traversal\"\u00a0 The DNCP nodes can be removed from what??\u00a0 The topology graph?\u00a0 From some type of received TLV??\u00a0 How would they be added back in later? 11) In sec 6.1: \"Trickle-driven status updates (Section 4.3) provide a mechanism for \u00a0  handling of new peer detection on an endpoint, as well as state \u00a0  change notifications.\"\u00a0  Nothing in Sec 4.3 talked about a mechanism for detecting new peers on an endpoint.\u00a0 It is entirely possible that Trickle does provide this (but what about the modes where Trickle isn't used/needed??) but there needs to be a description of how new peer detection is done - even if it's just a pointer to Trickle RFCs. 12) In Sec 6.1.4: \"\u00a0  On receipt of a Network State TLV (Section 7.2.2) which is consistent \u00a0  with the locally calculated network state hash, the Last contact \u00a0  timestamp for the peer MUST be updated.\"\u00a0  Could you add some rationale for why this is needed?\u00a0 I suspect that part of my confusion is that the \"locally calculated network state hash\" could mean two different things.\u00a0 Is it the hash computed by the local node on the data received in the Network State TLV to validate that the Network State TLV is not corrupted?\u00a0 Or is it the hash computed by the local node on its arbitrarily wide 1-hash tree that represents the local node's network state?\u00a0  Since the term is never defined, it's hard to guess here.\u00a0 The bottom of Sec 7.2.2 uses \"current locally calculated network state hash\" to refer to, I believe, the latter. 13) In Sec 6.2: \"normally form peer relationships with all peers.\"\u00a0 Where is forming a peer relationship defined?\u00a0 Is this tied solely to Trickle instances?\u00a0 What about with reliable unicast  where presumably Trickle isn't used between peers as the Overview states \"If used in pure unicast mode with unreliable transport, Trickle is also used between peers\"? 14) In Sec 7: \"\u00a0  For example, type=123 (0x7b) TLV with value 'x' (120 = 0x78) is \u00a0  encoded as: 007B 0001 7800 0000.\u00a0 If it were to have sub-TLV of \u00a0  type=124 (0x7c) with value 'y', it would be encoded as 007B 0009 7800 \u00a0  0000 007C 0001 7900 0000.\"\u00a0  In this case, the padding between the TLV's value and the sub-TLV is included but the padding after the sub-TLV is not.\u00a0 What would happen if there were multiple sub-TLVs??\u00a0 Would the padding between those sub-TLVs be included? Also related :\"In this case the length field includes the length of the original TLV, the  length of the padding that are inserted before the embedded TLVs and the length of the  added TLVs.\"\u00a0 Here, the phrase \"length of the TLV\" means different things.\u00a0 In the first case, \"length of the original TLV\" means the \"length of the value in the encapsulating TLV\".\u00a0 In the second case, \"length of the added TLVs\" appears to mean the length of the sub-TLVs  including the type/length header.\u00a0 As I mentioned above, I can't tell what happens to the  padding in between sub-TLVs.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2015-10-20 06:51:59-07:00",
    "end_reason": "position_updated",
    "start": "2015-10-19 09:18:42-07:00",
    "text": "Thank you very much for addressing my previous Discuss points and comments.\u00a0 On a fresh read of the updated draft, I have the following one minor point (but it matters for interoperability with DNCP profiles): 1) End of Sec 4.4, can you clarify what the behavior is for unrecognized TLV that is included in the Node Data field of a Node State TLV?\u00a0 I assume that its meaning is not processed, but it is included in the computation of the Node State Hash? I've also read this draft too many times at this point to be certain that I've picked up all the points of unclarity.\u00a0 I've requested another Routing Directorate review, from a new reviewer, so I may be modifying my ballot again before the telechat on Thursday.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-10-20 13:39:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-09-17 02:10:33-07:00",
    "text": "Other ADs focused on the protocol specific points. So let me focus on something else. The applicability section doesn't answer my questions: when to (re-)use this protocol? Note that the write-up mentioned ANIMA. I see the protocol description: \u00a0  DNCP is designed to provide a way for each participating node to \u00a0  publish a set of TLV (Type-Length-Value) tuples, and to provide a \u00a0  shared and common view about the data published by every currently or \u00a0  recently bidirectionally reachable DNCP node in a network. I see, under the applicability section, under which conditions to use it. Basically, suitable to exchange any TLV tuples, infrequently.  However, this applicability section doesn't tell me when to re-use DNCP (or define a profile for it). What about the environment: home network versus LAN versus WAN? How big can the network be? Does the technology matter?  Regarding transport, it's basically any transport, unicast or multicast, right? (DNCP can be used in networks where only unicast transport is available.\u00a0 While DNCP uses the least amount of bandwidth when multicast is utilized) All devices in a DNCP network must be DNCP node? I have a DNCP network with profile 1, can I use the same DNCP network with profile 2? IANA and enterprise specific TLVs? UDP is fine as a transport? What if I know my topology already (I see later: \"may use multicast for Trickle-based shared state dissemination and topology discovery\")  etc.\u00a0  Just reading the intro and the applicability, I scratched my head: it's so generic, should I even consider it for ANIMA? A few paragraphs, somewhere in the document, would solve my DISCUSS: - this protocol should be used to exchange the following type of data ... - it's envisioned that this generic state synchronization protocol will be used in the following environments ... - potential DNCP-based protocols include ...",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-11-01 16:08:48-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-20 13:39:41-07:00",
    "text": "Other ADs focused on the protocol specific points. So let me focus on something else. The applicability section doesn't answer my questions: when to (re-)use this protocol? Note that the write-up mentioned ANIMA. I see the protocol description: \u00a0  DNCP is designed to provide a way for each participating node to \u00a0  publish a set of TLV (Type-Length-Value) tuples, and to provide a \u00a0  shared and common view about the data published by every currently or \u00a0  recently bidirectionally reachable DNCP node in a network. However, this applicability section doesn't tell me when to re-use DNCP (or define a profile for it). I see an effort to address my discuss in the appendix B of draft version 11. Thanks  What would solve my DISCUSS is an applicability section that would contain  a high level set of criteria that would briefly explain whether DNCP is applicable for  the specifications I have in mind. The first 2 paragraphs of section 1.1 is a good start,  then it goes considerations about Trickle, the interval A_NC_I, etc ... and you lose the  readers.\u00a0  Something like: \u00a0  DNCP is designed to provide a way for each participating node to \u00a0  publish a set of TLV (Type-Length-Value) tuples, and to provide a \u00a0  shared and common view about the data published by every currently or \u00a0  recently bidirectionally reachable DNCP node in a network. \u00a0  [As an example of what I'm expected, see below.  \u00a0 \u00a0 Btw, I have no idea if this text is correct or complete, but that's besides the point]  \u00a0  DNCP works with profiles in which you have the flexibility to specify: \u00a0  - the appropriate transport: the available options are TCP and UDP (see  \u00a0  section appendix B for the tradeoffs) \u00a0  - the transport security: TLS or DTLS, see appendix B).  \u00a0  - If service discovery is required, an optional multicast service can be defined.\u00a0   \u00a0  - TO BE COMPLETED \u00a0  DNCP is applicable to LAN, WAN, or even the Internet.  \u00a0  DNCP can exchange enterprise specific TLV or an IANA registry could be specified \u00a0  DNCP specific extensions are possible. \u00a0  TO BE COMPLETED   \u00a0  DNCP limitations:\t \t- Data published limited to 64kB \t- Doesn't work for SCTP, DCCP  \u00a0 \u00a0 \u00a0 \u00a0 - All devices in the network must be DNCP node? \u00a0 \u00a0 \u00a0 \u00a0 - TO BE COMPLETED  To summarize, I need the 2 min elevator pitch of when (not) to use DNCP.",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2015-09-30 05:39:43-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-15 07:02:16-07:00",
    "text": "I have no objections to the publication of this document, but I do have a couple of points that I want to discuss... * The spec says that all TLVs are transmitted every time any value in the TLV set changes. Section 1 says that a delta synchronization scheme is not defined.\u00a0 What is the justification for not using a delta synchronization approach?\u00a0 The ordering of the TLVs needed to compute the hash can be done at the receiver and a delta approach would minimize bandwidth consumption.\u00a0 I think it would be useful to provide some justification in the spec for the design decision made to not use a delta synchronization approach. * Section 4.4 says that all responses are sent unicast, even for requests received via multicast over a multi-access medium. Was consideration given to use multicast responses and supporting message suppression on other nodes? Or, was the design decision made to ensure that all nodes responded with their TLV set to the requester?\u00a0 Either approach may be reasonable, but there is no justification given. * When responding to a multicast request over a multi-access medium, why is the randomization of the transmit time only a SHOULD?\u00a0 I would think that needs to be a MUST.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-09-29 09:03:26-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-16 12:46:07-07:00",
    "text": " I just have one thing I'd like to discuss that should be easy enough to resolve. Section 8 mentions that DTLS or TLS MAY be used and that it is up to the DNCP profile.\u00a0 I'd be interested to see the security considerations that would lead to a recommendation of using session transport for the DNCP profiles.\u00a0 If it is in another RFC, could you add a pointer?\u00a0 If it is not, could this be added to the security considerations section since it could be an important consideration?",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-09-17 07:33:45-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-15 20:42:24-07:00",
    "text": "This should be an easy Discuss to ... discuss ... I'm looking at this text: \u00a0  If keep-alives specified in Section 6.1 are NOT sent by the peer \u00a0  (either the DNCP profile does not specify the use of keep-alives or \u00a0  the particular peer chooses not to send keep-alives), some other \u00a0  existing local transport-specific means (such as Ethernet carrier- \u00a0  detection or TCP keep-alive) MUST be used to ensure its presence. \u00a0   and wondering if using TCP keep-alive for liveness detection is realistic in the use cases this specification is expecting to address.  Unless I missed something, the default TCP keep-alive interval is still two hours (that's been true since  RFC 1122 , and also true in the relatively recent version of Linux I'm using). If that's OK, I'll clear. If you're assuming a keep-alive interval that's shorter, lots of implementations allow you to tune this, but it seems like the specification should say something about that. Given that the other example of \"transport-specific means\" is Ethernet carrier-detection, which would be orders of magnitude faster, I thought I should ask.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-14 05:51:36-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-11 18:42:38-07:00",
    "text": "\u00a0  The \"aes128gcm\" content coding uses a fixed record size.\u00a0 The final \u00a0  encoding consists of a header (see Section 2.1) and zero or more \u00a0  fixed size encrypted records; the final record can be smaller than \u00a0  the record size. This restriction seems to be an artifact of your previous design which used short records as an end marker.\u00a0 With the new padding delimeter structure (which I note is isomorphic to the TLS 1.3 structure), I'm not seeing any reason to require that the records be fixed length (as they are not in TLS). I didn't see any discussion of this point in the thread where this structure was designed, so I'd like to get confirmation that the WG considered this point and decided to continue with the above restriction. I'll clear this discuss upon either such confirmation or removal of the restriction.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-14 05:51:49-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-14 05:51:36-07:00",
    "text": "\u00a0  The \"aes128gcm\" content coding uses a fixed record size.\u00a0 The final \u00a0  encoding consists of a header (see Section 2.1) and zero or more \u00a0  fixed size encrypted records; the final record can be smaller than \u00a0  the record size. This restriction seems to be an artifact of your previous design which used short records as an end marker.\u00a0 With the new padding delimeter structure (which I note is isomorphic to the TLS 1.3 structure), I'm not seeing any reason to require that the records be fixed length (as they are not in TLS). I didn't see any discussion of this point in the thread where this structure was designed, so I'd like to get confirmation that the WG considered this point and decided to continue with the above restriction. I'll clear this discuss upon either such confirmation or removal of the restriction. UPDATE: James Manger points out that you need fixed record sizes for random access and header-freeness, though not for security. I will clear this.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-08-22 13:10:44-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 00:10:54-07:00",
    "text": "In Section 3.2, there's this field definition: \u00a0  Reserved\u00a0 \u00a0 \u00a0 \u00a0 This field SHOULD be ignored by the receiver. I'm worried about interoperability here.\u00a0 \"SHOULD\" allows a choice.\u00a0 As written, I would be within the protocol if I decided to interpret this field, even if the other participants put junk here.\u00a0 Wouldn't it be better to say this is a \"MUST\", or require that it be all zero bits (at least in this version)?\u00a0 If you really think this needs to be a \"SHOULD\", I suggest explaining the choice that's being made available to an implementer here.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-09-08 02:29:23-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 03:37:05-07:00",
    "text": "Hi, I had a couple of minor discuss comments to clarify a couple of points that seemed unclear: 1) Definition of Sequence Number: \u00a0  Sequence Number An optional 32-bit sequence number starting from 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  and increasing by 1 for each following monitored \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  packet from the same flow at the encapsulating node. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The Sequence Number, when combined with the Flow ID, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  provides a convenient approach to correlate the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  exported data from the same user packet. Please can you clarify.\u00a0 Is this every packet in the flow (presumably not)?\u00a0 Does monitored packet means just those with the DEX option?\u00a0 Could it include other packets  2. Optional field ordering. \u00a0  Optional fields The optional fields, if present, reside after the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Reserved field.\u00a0 The order of the optional fields is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  according to the respective bits that are enabled in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the Extension-Flags field.\u00a0 Each optional field is 4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  octets long. Please can clarify that the order is from most significant bit to least significant bit of the option field. 3. Allocation is based on the \"RFC \u00a0  Required\" procedure, as defined in [ RFC8126 ]. Given the number of extensions is so limited, is RFC required (e.g. allows ISE) really a strict enough allocation policy? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-23 05:25:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 06:34:56-07:00",
    "text": "It isn\u2019t clear whether DEX can be exported outside of the IOAM domain.\u00a0 If it can, more is needed to describe the implications.\u00a0 There are the following related statements: (a) Section 3.1.2 says: \u00a0  Exported packets SHOULD NOT be exported over a path or a tunnel that \u00a0  is subject to IOAM direct exporting. (b) Section 6 says: \u00a0  IOAM is assumed to be deployed in a restricted administrative domain, \u00a0  thus limiting the scope of the threats above and their affect.\u00a0 This \u00a0  is a fundamental assumption with respect to the security aspects of \u00a0  IOAM, as further discussed in [ RFC9197 ]. \u00a0   (c) Section 6 says: \u00a0  Although the exporting method is not within the scope of this \u00a0  document, any exporting method MUST secure the exported data from the \u00a0  IOAM node to the receiving entity.\u00a0 Specifically, an IOAM node that \u00a0  performs DEX exporting MUST send the exported data to a pre- \u00a0  configured trusted receiving entity.\u00a0 Furthermore, an IOAM node MUST \u00a0  gain explicit consent to export data to a receiving entity before \u00a0  starting to send exported data. Statement (b) is the usual caveat that IOAM traffic stays inside the domain.\u00a0 However, this new option type is something different \u2013 there are the packets themselves and the telemetry generated from them (i.e., the export packets).\u00a0 Statement (c) is clear and helpful but doesn\u2019t resolve if these entities are in the IOAM domain.\u00a0 Statement (a) seems to mitigation for not creating loops but like (c) silent on clarifying whether in the IOAM domain. If export can only happen in the IOAM domain, consider adding something as simple as the following in the Security Considerations: NEW: DEX exporting MUST NOT be to entities outside of the IOAM domain.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-09-19 14:08:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 14:19:53-07:00",
    "text": "Thanks for working on this specification.  Thanks to Colin Perkins for his valuable TSVART review. I find the TSVART early reviewer's concern on rate limiting the exported traffic triggered by DEX Option-type as only protection mechanism ( https://mailarchive.ietf.org/arch/msg/tsv-art/1WNgYWGJmxLd4f3RAiDk-LJ-S8Y/ ) very valid but haven't seen it addressed. In this discuss, I would like to bring back attention to that concern and would like to discuss why there should not be a circuit breaker kind of functionality required here? I also think this specification should be explicit about not exporting IOAM data to any receiver outside of IOAM limited domain. Hence supporting Roman's discuss. for example - The introduction section can state- OLD text- \u00a0  A \u00a0  \"receiving entity\" in this context can be, for example, an external \u00a0  collector, analyzer, controller, decapsulating node, or a software \u00a0  module in one of the IOAM nodes. New text- \u00a0  A \u00a0  \"receiving entity\" in this context can be, for example, an external \u00a0  collector, analyzer, controller, decapsulating node, or a software \u00a0  module in one of the IOAM nodes with in IOAM limited domain.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-04-05 05:04:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-05 04:39:15-07:00",
    "text": "There might be a serious issue in label definition. 5.1.3.\u00a0 Label Parameter \u00a0  The 'label' parameter indicates the name of the channel.\u00a0 It \u00a0  represents a label that can be used to distinguish, in the context of \u00a0  the WebRTC API [WebRtcAPI], an RTCDataChannel object from other \u00a0  RTCDataChannel objects.\u00a0 This parameter maps to the 'Label' parameter \u00a0  defined in [ I-D.ietf-rtcweb-data-protocol ].\u00a0 The 'label' parameter is \u00a0  optional.\u00a0 If it is not present, then its value defaults to the empty \u00a0  string. \u00a0 label-opt\u00a0 \u00a0 \u00a0  = \"label=\" quoted-string \u00a0 quoted-string\u00a0  = DQUOTE *(quoted-char / escaped-char) DQUOTE \u00a0 quoted-char\u00a0 \u00a0  = SP / quoted-visible \u00a0 quoted-visible\u00a0 = %x21 / %x23-24 / %x26-7E ; VCHAR without \" or % \u00a0 escaped-char\u00a0 \u00a0 = \"%\" HEXDIG HEXDIG I interpret that as the intention is to enable the SDP Attribute to carry the label as defined in W3C API. That value is in the current candidatate specification an  https://www.w3.org/TR/webrtc/  as an USVSsting ( https://heycam.github.io/webidl/#idl-USVString ). And in the reference version of the WebRTC API as an DOMstring. Both are not limited to ASCII and may contain any Unicode characters. Thus the escaping mechanism defined appear to be insufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-08 00:50:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-05 05:04:28-07:00",
    "text": "There might be a serious issue in label definition. 5.1.3.\u00a0 Label Parameter \u00a0  The 'label' parameter indicates the name of the channel.\u00a0 It \u00a0  represents a label that can be used to distinguish, in the context of \u00a0  the WebRTC API [WebRtcAPI], an RTCDataChannel object from other \u00a0  RTCDataChannel objects.\u00a0 This parameter maps to the 'Label' parameter \u00a0  defined in [ I-D.ietf-rtcweb-data-protocol ].\u00a0 The 'label' parameter is \u00a0  optional.\u00a0 If it is not present, then its value defaults to the empty \u00a0  string. \u00a0 label-opt\u00a0 \u00a0 \u00a0  = \"label=\" quoted-string \u00a0 quoted-string\u00a0  = DQUOTE *(quoted-char / escaped-char) DQUOTE \u00a0 quoted-char\u00a0 \u00a0  = SP / quoted-visible \u00a0 quoted-visible\u00a0 = %x21 / %x23-24 / %x26-7E ; VCHAR without \" or % \u00a0 escaped-char\u00a0 \u00a0 = \"%\" HEXDIG HEXDIG I interpret that as the intention is to enable the SDP Attribute to carry the label as defined in W3C API. That value is in the current candidatate specification an  https://www.w3.org/TR/webrtc/  as an USVSsting ( https://heycam.github.io/webidl/#idl-USVString ). And in the reference version of the WebRTC API as an DOMstring. Both are not limited to ASCII and may contain any Unicode characters. Thus the escaping mechanism defined appear to be insufficient.  I think the \"quoted-string\" need a definition of what type of string this truly are so that it is clear what a character in the string is.  In addition the specification of escaping is undersspecified. I would recommend at least adding discussion of the need and how to escape DQUOTE and % that can be relatively common operations.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-25 11:13:05-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-09 12:58:56-07:00",
    "text": "(1) Section 5.2.1.\u00a0 The ABNF of stream-id of \u201cdcsa-value = stream-id \u2026\u201d does not appear to be defined explicitly or by reference in the draft. (2) Section 6.6, \u201c\u2026 the offerer SHALL include previously negotiated SDP attributes \u2026 associated with the channel\u201d.\u00a0 What is the behavior of the receiver if the attributes included by the offerer are NOT those that were previously negotiated?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-06-28 18:24:22-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 15:43:42-07:00",
    "text": "After further reflection, I think we need to resurrect the discussion sparked by DKG's last-call review.\u00a0 Specifically, in Section 5 when we consider the case that there is not a directory service/repository available, we give guidance to \"the recipient\" and \"recipients\".\u00a0 But in at least some cases, there are two tiers of recipients/relying parties, that have different properties, as in the web PKI situation. Specifically, web server operators rely on root CAs to certify the certificates that they present to TLS clients.\u00a0 But we also consider the TLS clients themselves, which may not have a direct path to receiving the updated root CA self-signed certificate, and because of the different ways these different types of recipient rely on root CA information, the order in which they update can cause breakage.\u00a0 We do not necessarily need to present a clear solution that will always avoid this breakage, but I do think we need to at least discuss the possibility of such scenarios. To consider a concrete case, consider a system with a TLS client (\"A\"), a TLS server (\"B\"), and the root CA (\"C\").\u00a0 C issues (potentially via intermediates) an end-entity certificate for B, and we consider a case where A initiates TLS connections to B.\u00a0 Initially, C has the root CA/key at C1, and is initiating a transition to C2; before the transition both A and B have C1 in their trusted store.\u00a0 When A receives C2, it can perform the requisite validation and add C2 to its trust store for use potentially validating incoming certificate chains.\u00a0 When B receives C2, it can similarly perform the requisite validation and add C2 to its trust store, but B's trust store is used for validating *outgoing* certificate chains, not (just) incoming ones.\u00a0 If B were to keep C2 in its trust store and construct an outgoing certificate chain based on C2 (and omitting oldWithNew and newWithOld), before A has received C2, then the TLS handshake fails! If A had access to C2, or to oldWithnew/NewWithOld, then it would still be able to validate B's certificate chain, but this document (and  RFC 4210 ) do not give guidance that B should transmit newWithOld to A, leaving open this scenario for breakage. My current inclination is to add some text to this document acknowleding the potential for a chain of relying parties, and recommending that the \"intermediate parties\" in the scenario make newWithOld/oldWithNew available until the notAfter time from oldWithNew, but I am of course open to further discussion/suggestions. Separately, I just want to quickly check that the id-ce-hashOfRootKey OID has been properly allocated and recorded, as I couldn't find evidence to indicate that in a quick search.\u00a0 I assume this is the origin of the CTIA acknowledgment that Alissa mentions, but there's not quite enough there to connect the dots.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-12-12 13:28:09-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-12 14:56:29-07:00",
    "text": "This is a generally well written document, but it seems to be defining protocol, or at least required practices for interoperability. Why is it informational?\u00a0 If it really does make sense for it to be informational, I think a paragraph explaining why would be helpful. The 2nd paragraph in section 1 seems to attempt that, but the explanation leads me again to think that informational is not the right status. \"Guidelines that...should adhere to\" to increase interoperability doesn't sound informational.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-10-13 03:04:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-13 03:04:13-07:00",
    "text": "[sorry for coming late to the party] One point I would like to DISCUSS: I wonder if this document is not already obsolete, now that we have the new FETCH/iPATCH/PATCH methods ( draft-ietf-core-etch )? Should we expect an update document for the new mappings? Don't we at least want a reference to  draft-ietf-core-etch , expressing it's not covered.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-10-13 03:36:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-13 03:04:50-07:00",
    "text": "[sorry for coming late to the party] One point I would like to DISCUSS: I wonder if this document is not already obsolete, now that we have the new FETCH/iPATCH/PATCH methods ( draft-ietf-core-etch )? Should we expect an update document for the new mappings? Don't we need at least want a reference to  draft-ietf-core-etch , expressing it's not covered.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-10-13 06:30:20-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-13 03:36:38-07:00",
    "text": "[sorry for coming late to the party] One point I would like to DISCUSS: I wonder if this document is not already obsolete, now that we have the new FETCH/iPATCH/PATCH methods ( draft-ietf-core-etch )? Should we expect an update document for the new mappings? Don't we need at least a reference to  draft-ietf-core-etch , expressing it's not covered?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-09-27 12:03:56-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-26 11:02:42-07:00",
    "text": "This is one discuss point with 2 questions.\u00a0 The second part is what's discussable and the first should be easy to fix either with the text provided or something similar. 1. In Section 10.1, this is more of a security than a privacy consideration as this is \"network reconnaissance\".\u00a0 This is a typical pre-cursor to an attack one the the attacker has gathered more information on the network. \u00a0  From a privacy perspective, they can be \u00a0  used to gather detailed information about the resources hosted in the \u00a0  constrained network.  How about: \u00a0  This can be \u00a0  used to gather detailed information about the resources hosted in the \u00a0  constrained network, as siting with network reconnaissance. then for the last sentence: \u00a0  If privacy is a concern, for \u00a0  example whenever the HTTP request transits through the public \u00a0  Internet, the request SHOULD be transported over a mutually \u00a0  authenticated and encrypted TLS connection. How about: \u00a0  If confidentiality of the network is a concern, for \u00a0  example whenever the HTTP request transits through the public \u00a0  Internet, the request SHOULD be transported over a mutually \u00a0  authenticated and encrypted TLS connection.  The word privacy here is confusing, so it's better to state exactly the issue. More importantly, if you can do network reconnaissance, what's to stop the attacker from using this new method of connecting?\u00a0 Some mention of this threat should be explicitly stated, maybe section 10.1 is the best place to do that, expanding on the existing text with another sentence.\u00a0  2. (Really part of #1, but a separate point) Could transforms of URIs result in successful attacks?\u00a0 I would think that would be the highest security consideration.\u00a0 Although  RFC7230  includes similar considerations, the mapping aspect of this draft could open up new attack possibilities, especially if a media type mapping is used.\u00a0 If there is an attack possible in the IoT space that is not in the HTTP world (device specific, or related to size constraints and coding), an intrusion prevention system monitoring the HTTP traffic before it is transformed would not pick it up and the attack traffic would evade detection.\u00a0 I think this merits mention and some text in the draft.\u00a0 Please let me know if it is elsewhere and another pointer is all that is needed. Thank you.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2016-10-03 20:41:06-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-27 15:28:50-07:00",
    "text": "This is going to be a Yes position after we talk, of course ... Someone can tell me to relax, but I found this text \u00a0  When found in a Hosting HTTP URI, the scheme (i.e., \"coap\" or \u00a0  \"coaps\"), the scheme component delimiter (\":\"), and the double slash \u00a0  (\"//\") preceding the authority MAY be omitted.\u00a0 In such case, a local \u00a0  default - not defined by this document - applies. \u00a0  So,  http://p.example.com/hc/s.coap.example.com/foo  could either \u00a0  represent the target coap:// s.coap.example.com/foo  or \u00a0  coaps:// s.coap.example.com/foo  depending on application specific \u00a0  presets. \u00a0   worrisome - is it saying that if you leave off the scheme, you don't know whether the resulting mapped URI is coap:// or coaps://? If so, how critical is it that this isn't deterministic?  Can the HTTP client tell whether the result used coaps://?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-02 06:09:00-08:00",
    "end_reason": "position_updated",
    "start": "2016-09-27 10:18:13-07:00",
    "text": "I don't get why you don't at least RECOMMEND that HTTP requests need to be authenticated? And I don't get why you don't REQUIRE HC implementations support some form(s) of strong-ish user authentication. We are seeing fairly major botnets being built from the kinds of device that might use CoAP and (with careless implementations all around) this could provide a nice way to expose those to the Internet. Isn't a good bit more caution needed in what we describe here? Note: I'm not saying HTTP authentication, nor specifically TLS client auth.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-10-05 07:44:28-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-27 16:17:38-07:00",
    "text": "Thanks for this well written draft. I do have a concern about some missing behavior. When an IPv6 literal is used the percent encoded square brackets need to be reverted to their non-percent-encoded form on the HTTP server in order to be compliant with  RFC7252  that uses IP-literal from  RFC3986  for the host component. This is not specified anywhere in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-11 21:03:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-06 10:41:04-07:00",
    "text": "Inclusion of an \"implementation requirement\" column in the IANA registries implies a need for a defined procedure to make changes to existing registrations.\u00a0 With only a \"specification required\" procedure, it seems there would need to be a \"change controller\" column as well. Furthermore, is it expected that anyone with any specification could set, e.g., an implementation requirement of \"MUST\"?\u00a0 It seems like this attribute might be better left for the RFCs defining the protocol, to be modified by an updating RFC... If we are to retain the Implementation Status appendix in the final RFC, the boilerplate will need some changes, and I think those changes should get review prior to AUTH48.\u00a0 For example, \"at the time of posting of this Internet-Draft\" will make no sense in an RFC, and the relationship to  RFC 7942  is not quite as clear given that we diverge from its recommendations.\u00a0 \"[A]ssist the IETF in its decision process\" does not seem to apply after the IETF has made its decision, though the disclaimer about endorsement seems highly important to retain. This seems to be related to Roman's Discuss point, but the document seems to be inconsistent as to the primary purpose of the mechanism -- Section 1.1 says that it is to verify \"authenticity\" of a stand-alone zone, whereas the Introduction implies that \"integrity\" is primary (with authenticity as an add-on \"when used in combination with DNSSEC), and the Abstract refers to \"accuracy and completeness\".\u00a0 In particular, it is easy to read references to \"integrity\" (and, indeed, the Abstract itself) as referring to something akin to a transport checksum instead of a cryptographic message integrity code.\u00a0 I think the document needs to be much more clear, and consistent, about what properties it aims to provide.\u00a0 (I do not believe that the \"authenticity\" property can be provided without DNSSEC, and Roman covers the cryptographic integrity case in his ballot position.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-12 09:23:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-05 19:47:01-07:00",
    "text": "Section 6.1.\u00a0  My read of the text is that the security properties are intended to be independent of the transport protocol.\u00a0 With that assumption and the validation procedures in Section 4, I need help understanding the security properties the client can rely on in the absence of DNSSEC.\u00a0 Consider the following scenarios and attacker types; and the assurances a client could have when retrieving the zone file from the server: With an on-path attacker (and trusted server hosting the zone file) ** No DNSSEC; No Secure transport = integrity: NO; authenticity = NO ** No DNSSEC; Secure transport = integrity: YES (from the on-path attacker); authenticity = NO ** DNSSEC = integrity: YES; authenticity = YES With a rogue server hosting the zone file (but is not the operator of the zone) ** No DNSSEC; No Secure transport = integrity: NO; authenticity = NO ** No DNSSEC/Secure transport = integrity: NO; authenticity = NO ** DNSSEC = integrity: YES; authenticity = YES The text states that: The zone digest allows the recipient of a zone to verify its \u00a0  integrity.\u00a0 In conjunction with DNSSEC, the recipient can \u00a0  authenticate that it is as published by the zone originator. Can the means to realize integrity without DNSSEC unless there is a reliance on transport security of some form be clarified.\u00a0 Minimally, it seems like this section needs cautionary text (likely with normative language) to the effect of \u201cZONEMD information from zone files lacking DNSSEC support or that were shared over \u2018unsecure transport\u2019 cannot be relied upon for cryptographic integrity assurance.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-01-06 09:47:08-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 03:42:07-08:00",
    "text": "Hi, A trivial discuss that should hopefully be easy to resolve, and it is plausible that the resolution may end up being in the QUIC transport document: In this document, the unused bits are defined as: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Figure 4: Version Negotiation Packet \u00a0  Only the most significant bit of the first byte of a Version \u00a0  Negotiation packet has any defined value.\u00a0 The remaining 7 bits, \u00a0  labeled Unused, can be set to any value when sending and MUST be \u00a0  ignored on receipt. In the QUIC transport document, they are defined as this: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Figure 14: Version Negotiation Packet \u00a0  The value in the Unused field is selected randomly by the server. \u00a0  Clients MUST ignore the value of this field.\u00a0 Servers SHOULD set the \u00a0  most significant bit of this field (0x40) to 1 so that Version \u00a0  Negotiation packets appear to have the Fixed Bit field. I would have expected that these two should be consistent as to whether the Fixed Bit SHOULD be set to 1 or not.\u00a0 Given  draft-thomson-quic-bit-grease-00 , it might be better if the SHOULD is removed from QUIC transport, but I will defer to the experts here. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-01-30 07:06:55-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-09 08:45:27-08:00",
    "text": "I agree with the Gen-ART reviewer that based on its content and the definitions provided in  RFC 2026 , this document should be a BCP, not a Proposed Standard. I don't think the rationale provided to the OpsDir reviewer justifies it being a Proposed Standard.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-09 06:47:47-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-05 08:00:36-07:00",
    "text": "section 9: First, thanks for this, good to see it here. Second, is \"might need to be removed\" sufficient in the 2nd para? I don't think it is really. Wouldn't it be better to say something more like \"unless other information (e.g. a user preference) is available, such attributes MUST be removed\"? If so, then I'd also add the list of attributes or property values that are ok to leave in, or the list that MUST be removed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-19 15:14:35-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-19 15:14:10-08:00",
    "text": "It looks like the indentation in the example MAIN PROGRAM in Appendix C is incorrect, or at least confusing, in the \"do forever\" loop therein. Specifically, assuming semantic whitespace as in Python, we never actually perform grasp negotiation for the \"good_peer in peers\" case. Additionally, I think we may have a risk of getting stuck in a loop making no progress so long as good_peer remains in the set of discovered peers but does not have enough resources available for our request/negotiation to succeed.\u00a0 I think we want to clear out good_peer if a negotiation fails to avoid that scenario.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-26 19:48:07-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-19 15:14:35-08:00",
    "text": "It looks like the indentation in the example MAIN PROGRAM in Appendix C is incorrect, or at least confusing, in the \"do forever\" loop therein. Specifically, assuming semantic whitespace as in Python, we never actually perform grasp negotiation for the \"good_peer in peers\" case. Additionally, I think we may have a risk of getting stuck in a loop making no progress so long as good_peer remains in the set of discovered peers but does not have enough resources available for our request/negotiation to succeed.\u00a0 I think we want to clear out good_peer if a negotiation fails, to avoid that scenario.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-27 05:05:26-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-18 18:13:53-08:00",
    "text": "** Section 3.1 and 3.2.  (a) (Section 3.1) \u201c\u2026 the secure bootstrap process itself may include special-purpose ASAs that run in a constrained insecure mode.\u201d,  (b) (Section 3.2) \u201c \u2026 the ACP formation process itself may include special-purpose ASAs that run in a constrained insecure mode.\u201d What is meant by \u201cspecial-purpose\u201d (i.e., how is that different than an ASA that isn\u2019t special purpose) and what are the security properties of a \u201cconstrained insecure mode\u201d?\u00a0 Is this text saying that the secure bootstrapping and ACP formation might not always be done securely? (b) reads like it could be DULL-GRAP (Section 2.5.2 of  draft-ietf-anima-grasp ) but it isn\u2019t clear.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-10 04:38:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-10 04:36:02-07:00",
    "text": "Hi, Thank for you this YANG module.\u00a0 It is great to see IETF progressing publishing more YANG configuration/management models, to thank you for the time and effort that have put into this. I support Roman's discuss regarding the security considerations, but would also like to add one of my own: In my experience, having some instance data examples (e.g., see Appendix D of  RFC 8022 ) greatly helps readers understand the structure of the YANG module and get a good feel for how the YANG model is used.\u00a0 Was adding instance data examples considered for this document?\u00a0 Do the authors that think it would be possible to add some examples? I've also added some comments on the YANG model below that probably need to be addressed but I didn't want to overload the main discuss point. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-10-23 11:51:51-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-10 04:38:11-07:00",
    "text": "Hi, Thank for you this YANG module.\u00a0 It is great to see IETF progressing publishing more YANG configuration/management models, to thank you for the time and effort that you have put into this. I support Roman's discuss regarding the security considerations, but would also like to add one of my own: In my experience, having some instance data examples (e.g., see Appendix D of  RFC 8022 ) greatly helps readers understand the structure of the YANG module and get a good feel for how the YANG model is used.\u00a0 Was adding instance data examples considered for this document?\u00a0 Do the authors that think it would be possible to add some examples? I've also added some comments on the YANG model below that probably need to be addressed but I didn't want to overload the main discuss point. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-20 03:46:13-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-08 15:36:53-07:00",
    "text": "** Section 11.\u00a0 Thanks for enumerating the sensitive read operations.\u00a0 It looks like the sensitive writes aren\u2019t described.\u00a0 Wouldn\u2019t it be a problem for arbitrary writes to occur to /rt:routing/mpls/*?\u00a0 I recommend using the \"template language\" of \"There are a number of data nodes defined in these YANG modules that are writable/creatable/deletable ... These are the subtrees and data nodes and their sensitivity/vulnerability:\" to provide this easy fix.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-01-12 02:55:33-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-22 04:36:16-08:00",
    "text": "# GEN AD review of  draft-ietf-cdni-additional-footprint-types-05 CC @larseggert Thanks to David Schinazi for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/-wFk1qr6NmJErpMO7olE-DGXdEA ). ## Discuss Should this document also update  RFC 9241 ?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-11-10 03:17:45-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-12-15 03:41:20-08:00",
    "text": "(1) The IPR declaration says that license terms will be available \"later.\" As things stand, I don't understand how the WG can have made an informed decision in that case. I looked at the archive and saw essentially no discussion, other than the announcement. I also looked at the application and it's not crystal clear to me at least that none of the claims are relevant. The shepherd write-up also doesn't help me, but of course there may have been discussion in a f2f meeting that is documented in minutes or something - I've not checked for such, or I may have missed out on some list traffic. Anyway, the DISCUSS is to ask did I miss stuff and if not how can WG participants have rationally considered an IPR declaration if the licensing information will only arrive \"later\" after the document is approved to become an RFC?\u00a0 (Note: If I am explicitly told that this was considered and participants were ok with the declaration even as-is, then I'll clear.)  (2) So I can see at least two ways in which this kind of thing can be done and you don't clearly say which this supports. Option (a) would be for the gaining DNS operator to provide new public keys to the losing operator for inclusion before a transfer so that continuity is maintained during the transfer. Option (b) would be where the KSK private material is not known by either operator, but e.g. by the registrant. In the case of option (b) the DNSKEY would be transferred from the losing to the gaining DNS operator. (And the arrow in Figure 1 would be in the other direction.) I think you need to be clear about which of these cases is actually being supported and about the overall sequence of events needed. (If you tell me that you really want to do whatever is in draft-koch, then that's fine but then this draft is probably premature and draft-koch would need to be a normative ref.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-02 13:08:54-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-10 03:17:45-08:00",
    "text": "(1) The IPR declaration says that license terms will be available \"later.\" As things stand, I don't understand how the WG can have made an informed decision in that case. I looked at the archive and saw essentially no discussion, other than the announcement. I also looked at the application and it's not crystal clear to me at least that none of the claims are relevant. The shepherd write-up also doesn't help me, but of course there may have been discussion in a f2f meeting that is documented in minutes or something - I've not checked for such, or I may have missed out on some list traffic. Anyway, the DISCUSS is to ask did I miss stuff and if not how can WG participants have rationally considered an IPR declaration if the licensing information will only arrive \"later\" after the document is approved to become an RFC?\u00a0 (Note: If I am explicitly told that this was considered and participants were ok with the declaration even as-is, then I'll clear.)",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-01-08 23:34:03-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-01-08 23:33:22-08:00",
    "text": "Thanks to everyone who is put work into defining this mechanism. I think it will be very useful to have a solution for integrating push mechanisms into SIP networks. I've identified three issues that I think need to be addressed in the current document before it can move forward, and a fourth serious flaw that I call out in my comments below. --------------------------------------------------------------------------- It's nice that this document has considered the impact of inbound mid-dialog messages in long-lived dialogs. However, it appears to have a major hole in it: handing of outbound messages for the purpose of maintaining soft-state in those dialogs isn't handled correctly. In particular: networks that deploy this mechanism will cause SUBSCRIBE dialogs to time out and be destroyed while they are a still in use. Additionally, if  RFC 4028  (session timers) is negotiated, then INVITE dialogs will suffer the same fate. I can think of a couple of ways for these situations to be handled, but they need explicit text in the document. One approach would be to specify that the User Agent selects its requested \"Expires\" value in its registration to be the smallest value before its set of subscriptions and session timers needs to be refreshed. This would cause a push notification to happen to prevent registration timeout, and the client could refresh the other soft state at that time. Complications arise if the registrar responds with a 483 (Interval too Brief), and we'd need to find a solution for that. Another approach would be for the clients to refresh all soft state whenever they send a registration, and set the timeout for that soft state to be equal to or greater than the registration timeout. A complication could arise if the notifier or the peer in an invite dialog shortens the requested time, and we'd need to find a solution for that. A third approach would be getting the proxy involved in some way -- either by requiring it to observe subscription and session timer timeouts and requiring it to send push notifications prior to their expiration, or by an explicit communication between the UA and the proxy that indicates when the next push notification should be scheduled. If the latter approach is taken, I would suggest that it needs to be taken for REGISTER messages as well. I really don't think this mechanism is feasibly deployable without a solution to this problem. --------------------------------------------------------------------------- \u00a74.1: >\u00a0 For privacy and security reasons, the UA MUST NOT include the SIP URI >\u00a0 parameters defined in this document in non-REGISTER request, to >\u00a0 prevent the PNS information associated with the UA from reaching the >\u00a0 remote peer. This seems to ignore the availability of Contact URI parameters via  RFC 3680 subscriptions. This would seem to impose a requirement on Registrars to strip this information before making it available to any other party (which, in turn, requires that the system have explicit Registrar *and* Proxy support). As far as I can tell, the system so far has not required explicit proxy support (and there's certainly no mechanism built-in that ensures that a proxy has any special handling regarding this mechanism). If the PNS information is sensitive, and cannot be allowed to leak out to other users, then we need some way to ensure the registrar has provided positive confirmation that it will not do so before allowing it to come into possession of them. --------------------------------------------------------------------------- \u00a74.2: >\u00a0 The UA can do so by only including the pn-provider >\u00a0 SIP URI parameter in the SIP Contact header field URI of the REGISTER >\u00a0 request, but without including the pn-prid SIP URI parameter. Unless I'm mistaken, this is a barrier to interoperation. It's not 100% clear, but I suspect the intended implication is that the pn-provider parameter here will contain a single value? The syntax of the parameter certainly seems to imply that. This seems to be a pretty big problem, since it presupposes that the client will know which PNSes the Proxy supports.\u00a0 Consider, for example, an iOS client that can use any of  RFC 8030 , FCM, and APN (cf  https://firebase.google.com/docs/cloud-messaging/ios/client ). If the client doesn't know a priori what the proxy supports (and this entire section only makes sense if that's true), then it won't know which of those three services to indicate in its REGISTER request. If it guesses wrong, this mechanism simply fails. I think you need a different discovery mechanism here -- either have one that has the client offering multiple PNS protocols and the proxy responding with one, or have one in which the proxy indicates all of its supported services in a response, and the client chooses one to use in its next REGISTER message.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-03-01 09:15:06-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-08 23:34:03-08:00",
    "text": "Thanks to everyone who is put work into defining this mechanism. I think it will be very useful to have a solution for integrating push mechanisms into SIP networks. I've identified three issues that I think need to be addressed in the current document before it can move forward, and a fourth serious flaw that I call out in my comments below. --------------------------------------------------------------------------- It's nice that this document has considered the impact of inbound mid-dialog messages in long-lived dialogs. However, it appears to have a major hole in it: handing of outbound messages for the purpose of maintaining soft-state in those dialogs isn't handled correctly. In particular: networks that deploy this mechanism will cause SUBSCRIBE dialogs to time out and be destroyed while they are still in use. Additionally, if  RFC 4028  (session timers) is negotiated, then INVITE dialogs will suffer the same fate. I can think of a couple of ways for these situations to be handled, but they need explicit text in the document. One approach would be to specify that the User Agent selects its requested \"Expires\" value in its registration to be the smallest value before its set of subscriptions and session timers needs to be refreshed. This would cause a push notification to happen to prevent registration timeout, and the client could refresh the other soft state at that time. Complications arise if the registrar responds with a 483 (Interval too Brief), and we'd need to find a solution for that. Another approach would be for the clients to refresh all soft state whenever they send a registration, and set the timeout for that soft state to be equal to or greater than the registration timeout. A complication could arise if the notifier or the peer in an invite dialog shortens the requested time, and we'd need to find a solution for that. A third approach would be getting the proxy involved in some way -- either by requiring it to observe subscription and session timer timeouts and requiring it to send push notifications prior to their expiration, or by an explicit communication between the UA and the proxy that indicates when the next push notification should be scheduled. If the latter approach is taken, I would suggest that it needs to be taken for REGISTER messages as well. I really don't think this mechanism is feasibly deployable without a solution to this problem. --------------------------------------------------------------------------- \u00a74.1: >\u00a0 For privacy and security reasons, the UA MUST NOT include the SIP URI >\u00a0 parameters defined in this document in non-REGISTER request, to >\u00a0 prevent the PNS information associated with the UA from reaching the >\u00a0 remote peer. This seems to ignore the availability of Contact URI parameters via  RFC 3680 subscriptions. This would seem to impose a requirement on Registrars to strip this information before making it available to any other party (which, in turn, requires that the system have explicit Registrar *and* Proxy support). As far as I can tell, the system so far has not required explicit proxy support (and there's certainly no mechanism built-in that ensures that a proxy has any special handling regarding this mechanism). If the PNS information is sensitive, and cannot be allowed to leak out to other users, then we need some way to ensure the registrar has provided positive confirmation that it will not do so before allowing it to come into possession of them. --------------------------------------------------------------------------- \u00a74.2: >\u00a0 The UA can do so by only including the pn-provider >\u00a0 SIP URI parameter in the SIP Contact header field URI of the REGISTER >\u00a0 request, but without including the pn-prid SIP URI parameter. Unless I'm mistaken, this is a barrier to interoperation. It's not 100% clear, but I suspect the intended implication is that the pn-provider parameter here will contain a single value? The syntax of the parameter certainly seems to imply that. This seems to be a pretty big problem, since it presupposes that the client will know which PNSes the Proxy supports.\u00a0 Consider, for example, an iOS client that can use any of  RFC 8030 , FCM, and APN (cf  https://firebase.google.com/docs/cloud-messaging/ios/client ). If the client doesn't know a priori what the proxy supports (and this entire section only makes sense if that's true), then it won't know which of those three services to indicate in its REGISTER request. If it guesses wrong, this mechanism simply fails. I think you need a different discovery mechanism here -- either have one that has the client offering multiple PNS protocols and the proxy responding with one, or have one in which the proxy indicates all of its supported services in a response, and the client chooses one to use in its next REGISTER message.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-01-10 09:45:53-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-09 04:00:05-08:00",
    "text": "I am generally excited about addition of push notifications to SIP. I have a couple of comments (and a few less serious ones) that I would like to discuss before recommending approval of this document: 10.\u00a0 pn-provider, pn-param and pn-prid URI Parameters for Apple Push \u00a0 \u00a0  Notification service \u00a0  When the Apple Push Notification service (APNs) is used, the PNS- \u00a0  related SIP URI parameters are set as described below. \u00a0  The value of the pn-provider URI parameter is \"apns\". \u00a0  Example: pn-provider = apns Spaces are not allowed in URIs unencoded, so your example is misleading. I suggest you change it to \"pn-provider=apns\" (i.e. delete space before and after \"=\"). Similar comment about 2 other parameter examples defined in this section. 10.\u00a0 pn-provider, pn-param and pn-prid URI Parameters for Apple Push \u00a0 \u00a0  Notification service \u00a0  The value of the pn-param URI parameter is a string that is composed \u00a0  by two values, separated by a period (.): Team ID and Topic.\u00a0 The \u00a0  Team ID is provided by Apple and is unique to a development team. I assume it doesn't contain any periods? \u00a0  The Topic consists of the Bundle ID, which uniquelly identifies an \u00a0  appliciation, and a service value that identifies a service \u00a0  associated with the application, separated by a period (.).\u00a0 For VoIP \u00a0  applications the service value is \"voip\". How many periods are used in the value? If your example below is correct, can you clarify that Bundle ID itself contains periods? \u00a0  Example: pn-param = DEF123GHIJ.com.yourcompany.yourexampleapp.voip",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-26 01:42:24-07:00",
    "end_reason": "position_updated",
    "start": "2019-01-06 15:28:56-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5114 DETAIL S 5.3.2. >\u00a0 \u00a0 \u00a0 request) addressed towards a SIP UA, if the Request-URI of the >\u00a0 \u00a0 \u00a0 request contains a pn-provider, a pn-prid and a pn-param (if required >\u00a0 \u00a0 \u00a0 for the specific PNS provider) SIP URI parameter, the proxy requests >\u00a0 \u00a0 \u00a0 a push notification towards the UA, using the PRID included in the >\u00a0 \u00a0 \u00a0 pn-prid SIP URI parameter and the PNS identified by the pn-provider >\u00a0 \u00a0 \u00a0 SIP URI parameter. Maybe I'm missing something, but this seems like it leaves open the possibility for the PRID to not match the rest of the URI. E.g., suppose that  a@example.com  and  b@example.com  both register with the same proxy/registrar pair with PRIDa and PRIDb respectively. What stops the registrar from generating (or forwarding) a call to a@example.com , PRIDb? And what happens if that happens? S 5.3.2. >\u00a0 \u00a0 \u00a0 also present (and has not expired) in the REGISTER response, the >\u00a0 \u00a0 \u00a0 proxy can forward the SIP request towards the UA, using normal SIP >\u00a0 \u00a0 \u00a0 procedures.\u00a0 If the contact of the REGISTER request does not match >\u00a0 \u00a0 \u00a0 the Request-URI of the SIP request to be forwarded, or if the contact >\u00a0 \u00a0 \u00a0 was not present in the REGISTER response, the proxy MUST reject the >\u00a0 \u00a0 \u00a0 SIP request with a 404 (Not Found) response.\u00a0 This can happen if the How does this happen? I.e., how does the the REGISTER get correlated with the SIP request to be forwarded in order to execute this requirement? S 6.1. >\u00a0 \u00a0 \u00a0 and be able to find and retrieve that information when it receives a >\u00a0 \u00a0 \u00a0 mid-dialog request.\u00a0 This section defines such mechanism.\u00a0 The UA and >\u00a0 \u00a0 \u00a0 proxy procedures in this section are applied in addition to the >\u00a0 \u00a0 \u00a0 generic procedures defined in this specification. >\u00a0   >\u00a0  6.1.\u00a0 SIP UA Behavior This section needs some kind of diagram that explains what the mechanism is. I've read it a bunch of times, and I still don't understand it. S 6.2.1. >\u00a0 \u00a0 \u00a0 generated key as the value to the associated 2xx REGISTER response. >\u00a0   >\u00a0 \u00a0 \u00a0 The PURR value MUST be generated in such a way so that it cannot be >\u00a0 \u00a0 \u00a0 used to retrieve information about the user or associate it with >\u00a0 \u00a0 \u00a0 registrations.\u00a0 It can be generated e.g., by utilizing a >\u00a0 \u00a0 \u00a0 cryptographically secure random function. This seems to weak. I assume you also don't want it to be possible to determine that two PURRs correspond to the same user. Also who must be able to use it in this way. Presumably the proxy can? Why is this not a requirement for say PRID? S 13. >\u00a0 \u00a0 \u00a0 specification.\u00a0 Web push permits the sending of a push message >\u00a0 \u00a0 \u00a0 without a payload without encryption. >\u00a0   >\u00a0  13.\u00a0 Security Considerations >\u00a0   >\u00a0 \u00a0 \u00a0 Different mechanisms exist for authenticating and authorizing devices You need to discuss the security implications of knowledge of the push parameters (principally PRID). What happens if an attacker learns htem?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-08-23 09:47:00-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-01 12:51:11-07:00",
    "text": "In Section 2.2, it seems like we could do much better with the URL guidance. I commented on this last time but the same problem still exists in this version. Right now the guidance amounts to: \"include a URL, make sure it's a permalink, but we can't tell you how to find or construct a permalink reliably, so ask IANA, but we don't tell you how to ask.\" If we're far enough away from having a standard way to find or construct permalinks that we can't say anything more specific about how authors might figure out what to include, then I think it's preferable to just tell people to include a URL for the registry in question and note that IANA will confirm whether to replace it with a permalink as part of its document processing. Asking authors to have an additional back-and-forth with IANA because we don't have an easy way for authors to identify permalinks seems like a waste of time for both sides.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-06-02 01:13:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2014-11-25 05:59:58-08:00",
    "text": "I initially wanted to go for \"no-record\" and wait for the discussion during the IESG telechat to give my final ballot. I was convinced it was not the right approach. So here is my DISCUSS, expressing that I want to discuss this document with the IESG. High level summary: The two issues that an IANA considerations section writer care about are: 1. Determining the right procedure (FCFS, Expert Review, etc...). This is relatively easy 2. What should the IANA considerations section contain? Give us a check list. \u00a0 \u00a0 All of us start from examples. This is what we need. \u00a0 \u00a0 I see those examples in section 4.X. Good: You can expect IETF draft authors to use those examples, as starting points. However, with the current document organization and with the (lack of)  RFC 2119  language, it's not too clear to the readers what the checklist is to write an IANA considerations section. Example \"change control policy and a change controller\". This is missing from the few examples I checked, and it's no clear from the text either if it's a MAY/SHOULD/MUST. So mixed feelings about this document. Not sure it's well organized for the intended audience: \"Guidelines for Writing an IANA Considerations Section in RFCs \".",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-06-02 01:15:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-02 01:13:45-07:00",
    "text": "I spent quite some time on this one, as I hope this document with ease my live, i.e. reduce my AD load. Re-reading the entire document, I updated my old DISCUSS/COMMENT. Section 1.2 \"For more information\" \u00a0  IANA maintains a web page that includes current important information \u00a0  from IANA.\u00a0 Document authors should check that page for additional \u00a0  information, beyond what is provided here. I still don't get how this URL in section 1.2 should/will be used. - Will it contain important aspects of this BCP, as the paragraph says \"current important information\"? If yes, why not point to the BCP directly. - Will it contain some \"additional information, beyond what is provided here\" (\"More information\" is the section title). So this BCP is not complete? So we will have a BCP that points to an URL that would contain some additional guidelines (quoting you = \"important information\"), but we can't tell you right what this is? Basically, what additional type of information do you anticipate on that link, and what is \"current\" in \"current important information\"? What if the guidelines on that URL contradicts the BCP? I guess I simply don't understand what this URL is for?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-09-21 05:59:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-02 01:15:12-07:00",
    "text": "I spent quite some time on this one, as I hope this document with ease my live, i.e. reduce my AD load. Re-reading the entire document, I updated my old DISCUSS/COMMENT. Section 1.2 \"For more information\" \u00a0  IANA maintains a web page that includes current important information \u00a0  from IANA.\u00a0 Document authors should check that page for additional \u00a0  information, beyond what is provided here. I still don't get how this URL in section 1.2 should/will be used. - Will it contain important aspects of this BCP, as the paragraph says \"current important information\"? If yes, why not point to the BCP directly. - Will it contain some \"additional information, beyond what is provided here\" (\"More information\" is the section title). So this BCP is not complete? So we will have a BCP that points to an URL that would contain some additional guidelines (quoting you = \"important information\"), but we can't tell you right what this is? Basically, what additional type of information do you anticipate on that link, and what is \"current\" in \"current important information\"? What if the guidelines on that URL contradict the consensus-base BCP? I guess I simply don't understand what this URL is for?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-09-21 23:25:48-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-09-21 05:59:16-07:00",
    "text": "My previous DISCUSS mentioned that I don't understand \"current important information\" in section 1.2 I disagree that\u00a0 \"includes current *important* information from IANA.\" This sounds like this URL is more important the BCP. If it's important, it should be in the bis document. This URL \"only\" contains: current clarifications, minor updates, and summary guidance. I see this sentence... \u00a0 \u00a0 \u00a0  Any significant updates to the \u00a0 \u00a0 \u00a0  best current practice will have to feed into updates to  BCP 26  (this \u00a0 \u00a0 \u00a0  document), which is definitive. \"significant updates\" contradicts \"current important information\".\u00a0 Ok, it depends how you read those two terms . Proposal. OLD: \u00a0  IANA maintains a web page that includes current important information \u00a0  from IANA.\u00a0 Document authors should check that page for additional \u00a0  information, beyond what is provided here: current clarifications, \u00a0  minor updates, and summary guidance.\u00a0 Any significant updates to the \u00a0  best current practice will have to feed into updates to  BCP 26  (this \u00a0  document), which is definitive. NEW: \u00a0  IANA maintains a web page that includes additional clarification \u00a0  information, beyond what is provided here, such as minor updates and  \u00a0  summary guidance. Document authors should check that page.  \u00a0  Any significant updates to the best current practice will have to feed  \u00a0  into updates to  BCP 26  (this document), which is definitive.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-09-22 00:27:30-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-21 23:25:48-07:00",
    "text": "My previous DISCUSS mentioned that I don't understand \"current important information\" in section 1.2 I disagree that\u00a0 \"includes current *important* information from IANA.\" This sounds like this URL is more important the BCP. If it's important, it should be in this document or a bisbis document. As far as I can tell (I've been trying to get some clarifications with my previous DISCUSSes, and the home page is still empty), this URL will \"only\" contain: current clarifications, minor updates, and summary guidance. I see this sentence... \u00a0 \u00a0 \u00a0  Any significant updates to the \u00a0 \u00a0 \u00a0  best current practice will have to feed into updates to  BCP 26  (this \u00a0 \u00a0 \u00a0  document), which is definitive. \"significant updates\" contradicts \"current important information\".\u00a0 Ok, it depends how you interpret those two terms . Proposal. OLD: \u00a0  IANA maintains a web page that includes current important information \u00a0  from IANA.\u00a0 Document authors should check that page for additional \u00a0  information, beyond what is provided here: current clarifications, \u00a0  minor updates, and summary guidance.\u00a0 Any significant updates to the \u00a0  best current practice will have to feed into updates to  BCP 26  (this \u00a0  document), which is definitive. NEW: \u00a0  IANA maintains a web page that includes additional clarification \u00a0  information, beyond what is provided here, such as minor updates and  \u00a0  summary guidance. Document authors should check that page.  \u00a0  Any significant updates to the best current practice will have to feed  \u00a0  into updates to  BCP 26  (this document), which is definitive.",
    "type": "Discuss"
  },
  {
    "ad": "Pete Resnick",
    "end": "2015-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2014-11-24 16:35:45-08:00",
    "text": "2.1/2.2 - You rightly point out in 2.1 that the terminology has been inconsistent in the past. But then you go ahead in 2.2 and use the two most confusing terms that you could use (\"registry\" for the grouping and \"sub-registry\" for the thing that contains the namespace). Please come up with terminology for this version of the document and stick to it. I would very much prefer \"Category\" (or \"Grouping\") for the grouping and \"Registry\" for the thing that contains the namespace. The documentation requirement should be for the Registry name, and, if desired, the Category (or Grouping) into which the Registry goes. The grouping can be identified by name or (if it already exists) by URL. If you insist on using the terms \"registry\" and \"sub-registry\" (and I implore you not to), please at least define those terms in terms of category, grouping, and namespace. In any event, please do not update this document without fixing the problem. 2.2 - The size/format section makes it confusing as to whether you're defining technical *protocol* requirements (which don't belong in the registry definition) or requirements for the registry itself (i.e., how things are displayed or stored by IANA). I particularly don't like giving UTF8 as an example. If the thing in the registry is a text string, then \"Z\u00fcrich\" is a fine entry, whether it is stored in the registry at IANA with the second character as U+00FC or U+0075 U+0308 (however encoded); the registry should point back elsewhere in the document to define the encoding requirements or the normalizations that might be used. However, if the thing in the registry is a specific UTF8-encoded octet-string, then what should appear in the registry should either contain \"0xC3 0xBC\" or it should contain \"0x75 0xCC 0x88\" and not appear as \"\u00fc\". The paragraph should make that clear. In the example, I'm not clear on what \"under the FooBar option\" means. That sounds like there is a Category called \"FooBar Options\" somewhere, but I don't think that's what you mean.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-01 16:56:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2014-11-24 07:14:20-08:00",
    "text": "There're 5 points here, but they should each be v.\u00a0 quickly handled I figure. (1) 2.2: the MUSTs here are overstated. These are desirable and not necessary. And we know such MUSTs will not be honoured and we constantly survive that with nothing bad happening other than a bit more work for a few folks. I'd say loose the MUSTs. In general the same tendency is visible throughout - that is, a tendency to impose a slightly too high burden on authors via the use of 2119-like language and I can see that causing trouble later for no good reason maybe. I think an editing pass to tone that down in general would be great and would significantly impove the document. (The discuss will clear if the 2.2 stuff is handled, the rest are almost all borderline already.) (2) 5.2, last para: would we be better off if we got agreement from the other streams that the IESG handles all DEs? I think that's worth thinking about, 'cause it'd be fine for IRTF I think and afaik that's the only real case at the moment. And the IRSG haven't had to do such things. And it'd be simpler I think. But if this is a bad plan, that's ok I'll clear this bit. (3) Section 8 says: \"In no case is it reasonable to leave documentation pointers to the obsoleted document for any registries or registered items that are still in current use.\" We had a nice big discussion about this back a year or two ago and there were two sides to the argument as I recall. On what basis can the authors now say that this is quite so clear? The strong counter argument to this is that developers do not start from IANA, they start from RFCs. (4) 9.1: Why do IANA prefer that empty sections be left in documents? I prefer getting rid of them myself and haven't heard the logic behind that change. (Or maybe I wasn't paying attention, in which case apologies:-) (5) 9.2: that's news to me, how much of this is there?\u00a0 I think having IANA be making policy is not necessarily a good plan, though I see this was in 5226. Should we change this now or not? (Just asking but if we think \"yes\" then we migth need another LC I guess. If the answer is \"no\" then this discuss point goes away.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-02 06:24:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-01 16:56:34-07:00",
    "text": "(I just checked my ancient discuss points. It seems to me that they're still valid, though I may re-word some. That'll be tomorrow though but in the meantime please consider that I consider these as still discuss-worthy, and we can start discussing during the day before the telechat. I didn't  check the comments at all yet.) There're 5 points here, but they should each be v.\u00a0 quickly handled I figure. (1) 2.2: the MUSTs here are overstated. These are desirable and not necessary. And we know such MUSTs will not be honoured and we constantly survive that with nothing bad happening other than a bit more work for a few folks. I'd say loose the MUSTs. In general the same tendency is visible throughout - that is, a tendency to impose a slightly too high burden on authors via the use of 2119-like language and I can see that causing trouble later for no good reason maybe. I think an editing pass to tone that down in general would be great and would significantly impove the document. (The discuss will clear if the 2.2 stuff is handled, the rest are almost all borderline already.) (2) 5.2, last para: would we be better off if we got agreement from the other streams that the IESG handles all DEs? I think that's worth thinking about, 'cause it'd be fine for IRTF I think and afaik that's the only real case at the moment. And the IRSG haven't had to do such things. And it'd be simpler I think. But if this is a bad plan, that's ok I'll clear this bit. (3) Section 8 says: \"In no case is it reasonable to leave documentation pointers to the obsoleted document for any registries or registered items that are still in current use.\" We had a nice big discussion about this back a year or two ago and there were two sides to the argument as I recall. On what basis can the authors now say that this is quite so clear? The strong counter argument to this is that developers do not start from IANA, they start from RFCs. (4) 9.1: Why do IANA prefer that empty sections be left in documents? I prefer getting rid of them myself and haven't heard the logic behind that change. (Or maybe I wasn't paying attention, in which case apologies:-) (5) 9.2: that's news to me, how much of this is there?\u00a0 I think having IANA be making policy is not necessarily a good plan, though I see this was in 5226. Should we change this now or not? (Just asking but if we think \"yes\" then we migth need another LC I guess. If the answer is \"no\" then this discuss point goes away.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-07 16:22:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-02 06:24:24-07:00",
    "text": "This is all updated based on re-reading -15. (1) 2.3 last para: huh? do we really use and want this? I'd say delete it. What is the reason for adding this since the last time this was in IESG review? (Sorry I don't recall it being discussed, but I assume it was.) (2) 5.2, last para: would we be better off if we got agreement from the other streams that the IESG handles all DEs? I think that's worth thinking about, 'cause it'd be fine for IRTF I think and afaik that's the only real case at the moment. And the IRSG haven't had to do such things. And it'd be simpler I think. But if this is a bad plan, that's ok I'll clear this bit. This hasn't been discussed that I recall, but I'd still like to check. (Incidentally the text in -15 does impose on other streams when it says that they have to specify how DEs are handled, so the IETF stream is impinging on others already.) (3) Section 8 says: \"In no case is it reasonable to leave documentation pointers to the obsoleted document for any registries or registered items that are still in current use.\" We had a nice big discussion about this back a few years ago and there were two sides to the argument as I recall.\u00a0 On what basis can the authors now say that this is quite so clear? The strong counter argument to this is that developers do not start from IANA, they start from RFCs. (4) 9.2: that's news to me, how much of this is there?\u00a0 I think having IANA be making policy is not necessarily a good plan, though I see this was in 5226. Should we change this now or not? (Just asking but if we think \"yes\" then we migth need another LC I guess. If the answer is \"no\" then this discuss point goes away.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-08-05 05:30:06-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-07 16:22:15-07:00",
    "text": "This is all updated based on re-reading -15. (1) 2.3 last para: huh? do we really use and want this? I'd say delete it. What is the reason for adding this since the last time this was in IESG review? (Sorry I don't recall it being discussed, but I assume it was.) points (2)-(4) cleared.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-04-27 07:23:51-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-27 03:32:00-07:00",
    "text": "DISCUSS-DISCUSS: No action for the authors at this point in time. Reading from the document objectives, from the abstract: \u00a0  This document gives an overview and context of a protocol suite \u00a0  intended for use with real-time applications that can be deployed in \u00a0  browsers - \"real time communication on the Web\". \u00a0  It intends to serve as a starting and coordination point to make sure \u00a0  all the parts that are needed to achieve this goal are findable, and \u00a0  that the parts that belong in the Internet protocol suite are fully \u00a0  specified and on the right publication track. Reading this, I was thinking: great, I will have the full overview. With \"deployed\", \"starting and coordination point to make sure that all the parts ...\" I will have some\u00a0 focus on the operational aspects, basically, how should operators operate theses browser-embedded applications. Now, reading further ... \u00a0  This document is intended to serve as the roadmap to the WebRTC \u00a0  specifications.\u00a0 It defines terms used by other parts of the WebRTC \u00a0  protocol specifications, lists references to other specifications \u00a0  that don't need further elaboration in the WebRTC context, and gives \u00a0  pointers to other documents that form part of the WebRTC suite. ... I thought: Ok, if not covered here, at least I will have a pointer to another operational document. But wait: \u00a0  By reading this document and the documents it refers to, it should be \u00a0  possible to have all information needed to implement an WebRTC \u00a0  compatible implementation. So is this only about implementation? I like this document very much as it explains all the RTCWEB pieces in one location. However, there is one important piece missing: the network management considerations. See  https://datatracker.ietf.org/doc/html/rfc5706#appendix-A This is where I'm coming from, discussing some more with Warren (this a cut and past from this ballot): \u00a0 \u00a0 [ Edit: So, after more thought (and some discussion) I think that it would be useful for the document to at least note the fact that technologies like this mean that some of the existing operational practices may need to change. For example, many enterprises perform QoS based upon the fact that certain types of devices live in certain subnets (e.g many phones get placed in a specific VLAN using LLDP or CDP). With more real time content coming from browsers, these matching practices break, and so operators may not be able to QoS mark / prioritize traffic accordingly. Perhaps something like: \"One of the implications of a solution like WebRTC is that more real-time traffic will be sourced from computers (and not dedicated devices like telephones or videoconferencing devices). This may have implications for operators performing QoS marking and prioritization\" ? This isn't really specific to webrtc, but rather to a more general set of solutions like softphones and the like, but is accelerated by WebRTC. ] In light of the previous discussions about  draft-mm-wg-effect-encrypt-11 , the operators are used to manage voice, video, gaming a certain way, with their operational current practices. Now, their current practices might not work any longer. What should they do now in term of monitoring, troubleshooting, QoS, SLA monitoring, etc these days with WebRTC? While we should add this note (or a similar one) in the doc, I'm wondering: where are (should be) those operational aspects discussed, if not here? I've seen  https://tools.ietf.org/html/draft-ietf-tsvwg-rtcweb-qos-18 , not sure it's appropriate. Anyway, it's now in a RFC-editor state. I could have requested a specific manageability doc in the charter. Too late now.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-08-10 07:41:57-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-22 04:16:19-07:00",
    "text": "Your citation to ICE is to 5245-bis, but at least the JSEP editor consensus was that WebRTC depended on 5245, so this needs to be resolved one way or the other.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-04-18 00:46:31-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-08 11:29:13-07:00",
    "text": "I will move to No Objection once my comments are discussed. They should be easy to address. In Section 7: \u00a0 \u00a0  Access Control\u00a0 USER-NODE-MATCH.\u00a0 Note that this matches the SIP AOR \u00a0 \u00a0 \u00a0 against the rfc822Name in the X509v3 certificate.\u00a0 The rfc822Name \u00a0 \u00a0 \u00a0 does not include the scheme so that the \"sip:\" prefix needs to be \u00a0 \u00a0 \u00a0 removed from the SIP AOR before matching. In general the advice of stripping \"sip:\" is misleading, because URIs might have %-encoding, which is not present in rfc822Name, which is an email address. I think adding text that %-encoding should be decoded would be a good idea. Also, the first reference to rfc822Name (earlier in the document) needs a normative reference to  RFC 5280 .",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-04-13 00:37:20-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-12 03:03:36-07:00",
    "text": "# GEN AD review of  draft-ietf-oauth-dpop-14 CC @larseggert ## Discuss ### Section 12.7.1, paragraph 3 ``` \u00a0 \u00a0  However, the initial registration of the nonce claim by [OpenID.Core] \u00a0 \u00a0  used language that was contextually specific to that application, \u00a0 \u00a0  which was potentially limiting to its general applicability. \u00a0  \u00a0 \u00a0  This specification therefore requests that the entry for nonce in the \u00a0 \u00a0  IANA \"JSON Web Token Claims\" registry [IANA.JWT] be updated as \u00a0 \u00a0  follows to reflect that the claim can be used appropriately in other \u00a0 \u00a0  contexts. ``` Is OpenID as the change controller OK with the IETF changing the IANA registry in this way?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-04-10 14:32:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-10 14:31:50-07:00",
    "text": "Thanks to everyone who worked on this document. This issue should be trivial to fix, but it's still a blocker. \u00a72.1: >\u00a0 \u00a0  Special-Use algorithm IDs span from 0xFA (250) to 0xFE (254). \u00a77: >\u00a0 In addition IANA is asked to register the following address space for >\u00a0 \"Special-Use\": > >\u00a0 \u00a0 Algorithm\u00a0  Digest\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Signature\u00a0 \u00a0 \u00a0  Specification >\u00a0 \u00a0 Suite\u00a0 \u00a0 \u00a0  Algorithm\u00a0 \u00a0 \u00a0  Algorithm\u00a0 \u00a0 \u00a0  Pointer >\u00a0 \u00a0 Identifier >\u00a0 +------------+---------------+--------------+-----------------------+ >\u00a0 | 0xFB-0xFE\u00a0 | Special-Use\u00a0  | Special-Use\u00a0 | This Document\u00a0 \u00a0 \u00a0 \u00a0  | >\u00a0 +------------+---------------+--------------+-----------------------+ The ranges here do not match ([0xFA - 0xFE] != [0xFB-0xFE]). Presuming that the text in Section 2.1 is what was intended, this issue impacts all of the tables in section 7.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-04-15 15:07:10-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 14:32:16-07:00",
    "text": "Thanks to everyone who worked on this document. This issue should be trivial to fix, but it's still a blocker. \u00a72.1: >\u00a0 \u00a0  Special-Use algorithm IDs span from 0xFA (250) to 0xFE (254). \u00a77: >\u00a0 In addition IANA is asked to register the following address space for >\u00a0 \"Special-Use\": > >\u00a0 \u00a0 Algorithm\u00a0  Digest\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Signature\u00a0 \u00a0 \u00a0  Specification >\u00a0 \u00a0 Suite\u00a0 \u00a0 \u00a0  Algorithm\u00a0 \u00a0 \u00a0  Algorithm\u00a0 \u00a0 \u00a0  Pointer >\u00a0 \u00a0 Identifier >\u00a0 +------------+---------------+--------------+-----------------------+ >\u00a0 | 0xFB-0xFE\u00a0 | Special-Use\u00a0  | Special-Use\u00a0 | This Document\u00a0 \u00a0 \u00a0 \u00a0  | >\u00a0 +------------+---------------+--------------+-----------------------+ The ranges here do not match ([0xFA-0xFE] != [0xFB-0xFE]). Presuming that the text in Section 2.1 is what was intended, this issue impacts all of the tables in section 7.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-04-15 23:40:14-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 10:48:01-07:00",
    "text": "his is a fine document and sorry for nit-picking, but why is this document \"Updates: 8208\" instead of \"Obsolete: 8208\"?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-09-18 13:27:46-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 16:11:53-07:00",
    "text": "I do have a concern about error handling that should be pretty simple to fix. * Section 3 The document needs to specify the error handling on the receiver when the SCSI-TLV length is not a multiple of 4 octets. Are the following SCSI-TLVs processed or is everything ignored? Is there an error message sent?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-01-11 07:21:44-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 05:42:07-08:00",
    "text": "s per IANA: I don't see any discussion of the 3gpp2 URN namespace on the urn@ietf.org mailing list. Did I miss it?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 10:41:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-03 01:53:12-08:00",
    "text": "The IANA Considerations section seems incomplete. Looking over the registries at https://www.iana.org/assignments/alto-protocol/alto-protocol.xhtml  and comparing against the mechanisms defined in this document, it seems that we need to register the \"ane-path\" Cost Metric.\u00a0 More worryingly, there is no registry on that page in which the \"array\" cost mode could be registered, and it seems that using any value other than \"numerical\" or \"ordinal\" would violate a \"MUST\" in \u00a710.5 of  RFC 7285 .\u00a0 This seems to present some procedural difficulties, especially now that this document is targeting Experimental status rather than Proposed Standard (which, to be clear, I think was the right thing to do).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-26 12:55:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-30 07:33:47-08:00",
    "text": "Thanks for documenting the increased risk of exposing sensitive topology information and the potentially of this data being exploited for a highly targeted DoS attack in Section 11.\u00a0 While this significant problem is documented, the mitigation for this fundamental issue is underspecified.\u00a0 The security of this extension is predicated on the ANE obfuscation procedures, but those specifics are not provided. In my review, there doesn\u2019t appear to be wide operational usage or implementations of this extension to inform these obfuscation procedures.\u00a0 Furthermore, it appears that these procedures remain an open research question.\u00a0 I appreciate the helpful references to the academic papers in Section 11 ([NOVA], [RESA][ MERCATOR])\u00a0 but their practical applicability to the generic capability provided by this extension appears to be difficulty to align and be caveated.\u00a0 For example, [RESA] and [MERCATOR] made what appear to be significant assumptions on their approaches, \u201cIn this paper, we assume a semi-honest security model, i.e., the aggregator and all member networks will not deviate from the security protocol, but merely try to gather information during the execution of the protocol\u201d.\u00a0  I believe this document needs to be provide a stronger applicability statement constraining where it can be fielded and what assumptions are made about the trust models.\u00a0 Additionally, given the uncertainty on the generic feasibility of obfuscation, this document should be published as experimental.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-02 16:53:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-26 12:55:49-08:00",
    "text": "(Updated ballot to make the remaining issues clear) Thanks for the update in -20 and in particular all of the new language in the Security considerations to discuss applicability and obfuscation procedures.\u00a0  In these edits in response to the earlier DISCUSS text, the following sentence was introduced into Section 11: For settings where the ALTO server and client are not\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  in the same trust domain, Digital Right Management (DRM) techniques\u00a0 \u00a0 \u00a0 \u00a0 \u00a0   and legal contracts protecting the sensitive Path Vector information\u00a0 \u00a0 \u00a0 \u00a0   MUST be applied. It appears to be trying to provide guidance on how to ensure that only the expected ALTO clients get the sensitive path information in the case where the server and clients are in different trust domains.\u00a0 This new language contains normative guidance to using DRM techniques.\u00a0 Given this is a normative \u201cMUST\u201d, the specifics of \u201cDRM techniques\u201d is under-specified.\u00a0 Independent of that, DRM techniques I quickly think of provides object security (i.e., embedding a security envelope of some form directly in the data it is trying to protect).\u00a0 How would that mesh with the specified format for the path information in this document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-16 20:32:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 14:36:17-08:00",
    "text": "As Mirja maybe already noted, Section 3.4.3 says: \u00a0  Section 8.3 of the RTP Specification [ RFC3550 ] recommends using a \u00a0  single SSRC space across all RTP sessions for layered coding.\u00a0 Based \u00a0  on the experience so far however, we recommend to use a solution with \u00a0  explicit binding between the RTP streams that is agnostic to the used \u00a0  SSRC values.\u00a0 That way, solutions using multiple RTP streams in a This sounds an awful lot like we're trying to update the recommendations from  RFC 3550 , and looks like different text than was discussed in Mirja's ballot thread.\u00a0 Let's discuss whether the formal Updates: mechanism is appropriate here or we should consider rewording.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-25 07:48:24-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 08:37:09-07:00",
    "text": "** Section 6.4.2.\u00a0 My read of Figure 3 is that the suggested architecture can be incrementally deployed.\u00a0 My other read is that it appears that this staged deployment isn\u2019t safe outside of controlled environments (i.e., for the Internet) until after phase 1.\u00a0 Assuming this is accurate, please add clear normative language that partial roll-outs of the L4S architecture MUST NOT occur outside of controlled environment until .",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-10 07:02:12-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 11:14:00-08:00",
    "text": "In Section 3.1 there is a Version field. What are the condition(s) for bumping this version number? What backward compatibility guaranties are expected (if any)? How would version negotiation be done?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-08-02 07:11:54-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-29 10:15:06-07:00",
    "text": "This is a fine document, but I have one possible issue that I would like to quickly discuss before recommending approval of this document: Looking at the example in Section 3:  \u00a0  { \u00a0 \u00a0  \"version\": \"1.0\", \u00a0 \u00a0  \"publication\": \"YYYY-MM-DDTHH:MM:SSZ\", \u00a0 \u00a0  \"description\": \"RDAP service provider bootstrap values\", \u00a0 \u00a0  \"services\": [ \u00a0 \u00a0 \u00a0  [ \u00a0 \u00a0 \u00a0 \u00a0  [\"YYYY\"], Values like YYYY are not distinguishable from TLD values registered in . All numeric values (ASNs or ranges of ASNs), as well as IPv4/IPv6 addresses are syntactically distinguishable from TLDs, but values registered in this document are not. Is this a problem? My concern is about fetching JSON from\u00a0  and misinterpreting it as valid data from the registry established in this document or vice versa. \u00a0 \u00a0 \u00a0 \u00a0  [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \" https://example.com/rdap/ \" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  ], \u00a0 \u00a0 \u00a0  [ \u00a0 \u00a0 \u00a0 \u00a0  [\"ZZ54\"], \u00a0 \u00a0 \u00a0 \u00a0  [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \" http://rdap.example.org/ \" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  ], \u00a0 \u00a0 \u00a0  [ \u00a0 \u00a0 \u00a0 \u00a0  [\"1754\"], \u00a0 \u00a0 \u00a0 \u00a0  [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \" https://example.net/rdap/ \", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \" http://example.net/rdap/ \" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0  ] \u00a0 \u00a0 }",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-06-02 07:47:14-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 23:16:15-07:00",
    "text": "Paul said: > I think that SHOULD can be a MUST. Although one could question the 2119 usage as it seems to be a directive to a document author and not a protocol action. So I would also be okay with lowercasing this. I'm ambivalent about the first sentence, but I concur strongly with the second; use of  BCP 14  language to establish a requirement against some future document seems quite unconventional to me.\u00a0 Can we talk about why this is necessary and/or appropriate?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-03 08:16:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 20:11:26-07:00",
    "text": "Probably an easily answered issue, but I am not too familiar with ALTO. \u00a0 \u00a0  The string MUST be no more than 32 characters, and it MUST NOT contain characters other than [...] Are there implementations that already deployed a cost string with more than 32 characters or characters not in this newly imposed set of characters? What should happen if that is in use? That is, is this protocol modification potentially breaking interoperability with older implementations?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-05-31 06:00:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-25 08:05:27-07:00",
    "text": "Hi, This is a \"discuss\" discuss, as in I'm not sure the document is wrong, but I thought that it would be helpful to flag this for further discussion. In  RFC 7285 , cost-mode is defined as a field that MUST take one of two string values, either \"numerical\" or \"ordinal\".\u00a0 I'm not really familiar with  RFC 7285 , and in particular, whether a receiver is required to explicitly check that the received data must take one of these two values, or whether a reasonable implementation could check for a single value, and if doesn't match that value assume that it must be the other value (since there are only two allowed values).\u00a0 Obviously, moving to more than two values could then cause this assumption to break in existing implementations.\u00a0 Was this issue considered and discussed by the WG?\u00a0 It looks like alto does support a versioning mechanism (i.e., by defining new media types) that might allow the definition of this field to be upgraded in a safer way.\u00a0 Was that approach considered? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-29 14:40:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 08:46:14-07:00",
    "text": "Section 4.3. In order to coexist safely with other Internet traffic, a scalable \u00a0  congestion control MUST NOT tag its packets with the ECT(1) codepoint \u00a0  unless it complies with the following bulleted requirements: Based on the use of \u201cMUST NOT\u201d, my read of this text is that all subsequent list items must comply with this list.\u00a0 List items #3, 5 and 6 include SHOULD clauses.\u00a0 How an implementer mix the \u201cMUST\u201d and and SHOULD clause? As simply fix might be to drop the \"MUST NOT\" in the preamble to the bulleted list.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-06-05 05:42:24-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-17 08:28:24-07:00",
    "text": "Hopefully this will be an easy DISCUSS to clear. Partially guided by some of the discussion that has already happened, it seems like there are three places where authentication/identity validation occurs in the MUD flow: the (CMS) signature alongside the MUD file, the TLS connection used to retrieve the MUD file, and the binding between the MUD URL and the device itself.\u00a0 The last one seems pretty important, especially given some of the points in Ekr's DISCUSS about limiting damage in case of compromised/malicious device.\u00a0 The security considerations already give some coverage in the first paragraph, but basically limited to the \"manufacturer\" groupings, and only covers the usage of the certificate extension for binding a MUD URL to a specific device.\u00a0 There's also some related text when considering what to do if the MUD URL for a given MAC address changes, but I didn't see any coverage for the general case.\u00a0 The entity using the MUD contents needs to be aware of the provenance of the URL and the risks of using a \"spoofed\" MUD from an attacker.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-04-15 04:32:40-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-15 04:31:28-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3106 The threat model for MUD doesn't seem clear, at least to me. It seems like there are at least two potential threat models:\u00a0 - Telling the network how to configure access control to prevent the device from being compromised - Telling the network how to configure access control the limit the damage in case a device is compromised (e.g., avoiding its use in a botnet).\u00a0 Are both of these in scope? If so, the latter seems to need substantially more analysis -- and perhaps mechanism -- because it seems relatively easy for the attacker to evade access control limits once it has replaced the firmware on the device (as noted below). In either case, the document needs to be clear about this, whether in the security considerations or elsewhere. IMPORTANT >\u00a0 \u00a0 \u00a0 The certificate extension is described below. >\u00a0   >\u00a0 \u00a0 \u00a0 The information returned by the MUD file server (a web server) is >\u00a0 \u00a0 \u00a0 valid for the duration of the Thing's connection, or as specified in >\u00a0 \u00a0 \u00a0 the description.\u00a0 Thus if the Thing is disconnected, any associated >\u00a0 \u00a0 \u00a0 configuration in the switch can be removed.\u00a0 Similarly, from time to IMPORTANT: What does \"disconnected\" mean in this context? Does a reboot count? What if I am wireless? This is a critical question if MUD is intended as an access control mechanism. Say that an attacker compromises the firmware for a device and then forces a reboot followed by a 2 hour pause before the wireless NIC is activated. Will this result in configuration removal? If so, MUD seems of limited use, because it can then make itself appear to be a new device with a new MUD configuration. (This is of course true in general in a wireless context if the firmware can change the client's L2 address). >\u00a0 \u00a0 \u00a0 \u00a0  https://example.com/lightbulbs/colour/v1 >\u00a0   >\u00a0 \u00a0 \u00a0 The MUD URL identifies a Thing with a specificity according to the >\u00a0 \u00a0 \u00a0 manufacturer's wishes.\u00a0 It could include a brand name, model number, >\u00a0 \u00a0 \u00a0 or something more specific.\u00a0 It also could provide a means to >\u00a0 \u00a0 \u00a0 indicate what version the product is. IMPORTANT: Are you just using \"identify\" loosely here? I see how it can be *based* on those characteristics, but absent a schema it doesn't seem like the MUD controller can infer any of those characteristics from the URL. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 -in mudfile -binary -outform DER - \\ >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 -certfile intermediatecert -out mudfile.p7s >\u00a0   >\u00a0 \u00a0 \u00a0 Note: A MUD file may need to be re-signed if the signature expires. >\u00a0   >\u00a0  12.2.\u00a0 Verifying a MUD file signature IMPORTANT: This seem underspecified. Is the intention that these certificates will be rooted in the WebPKI? Something else? I realize that IETF tends to be kind of vague about where trust anchors come from, but at the end of the day its hard to see how to implement this interoperably without some more guidance.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-06-05 00:46:18-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-15 04:32:40-07:00",
    "text": "Re-posted due to pilot error. Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3106 The threat model for MUD doesn't seem clear, at least to me. It seems like there are at least two potential threat models:\u00a0 - Telling the network how to configure access control to prevent the device from being compromised - Telling the network how to configure access control the limit the damage in case a device is compromised (e.g., avoiding its use in a botnet).\u00a0 Are both of these in scope? If so, the latter seems to need substantially more analysis -- and perhaps mechanism -- because it seems relatively easy for the attacker to evade access control limits once it has replaced the firmware on the device (as noted below). In either case, the document needs to be clear about this, whether in the security considerations or elsewhere. IMPORTANT >\u00a0 \u00a0 \u00a0 The certificate extension is described below. >\u00a0   >\u00a0 \u00a0 \u00a0 The information returned by the MUD file server (a web server) is >\u00a0 \u00a0 \u00a0 valid for the duration of the Thing's connection, or as specified in >\u00a0 \u00a0 \u00a0 the description.\u00a0 Thus if the Thing is disconnected, any associated >\u00a0 \u00a0 \u00a0 configuration in the switch can be removed.\u00a0 Similarly, from time to IMPORTANT: What does \"disconnected\" mean in this context? Does a reboot count? What if I am wireless? This is a critical question if MUD is intended as a post-compromise mechanism. Say that an attacker compromises the firmware for a device and then forces a reboot followed by a 2 hour pause before the wireless NIC is activated. Will this result in configuration removal? If so, MUD seems of limited use, because it can then make itself appear to be a new device with a new MUD configuration. (This is of course true in general in a wireless context if the firmware can change the client's L2 address). >\u00a0 \u00a0 \u00a0 \u00a0  https://example.com/lightbulbs/colour/v1 >\u00a0   >\u00a0 \u00a0 \u00a0 The MUD URL identifies a Thing with a specificity according to the >\u00a0 \u00a0 \u00a0 manufacturer's wishes.\u00a0 It could include a brand name, model number, >\u00a0 \u00a0 \u00a0 or something more specific.\u00a0 It also could provide a means to >\u00a0 \u00a0 \u00a0 indicate what version the product is. IMPORTANT: Are you just using \"identify\" loosely here? I see how it can be *based* on those characteristics, but absent a schema it doesn't seem like the MUD controller can infer any of those characteristics from the URL. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 -in mudfile -binary -outform DER - \\ >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 -certfile intermediatecert -out mudfile.p7s >\u00a0   >\u00a0 \u00a0 \u00a0 Note: A MUD file may need to be re-signed if the signature expires. >\u00a0   >\u00a0  12.2.\u00a0 Verifying a MUD file signature IMPORTANT: This seem underspecified. Is the intention that these certificates will be rooted in the WebPKI? Something else? I realize that IETF tends to be kind of vague about where trust anchors come from, but at the end of the day its hard to see how to implement this interoperably without some more guidance.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-13 14:26:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 15:51:34-08:00",
    "text": "The following points notwithstanding, I'm excited to see this mechanism get specified and am looking forward to balloting Yes once my concerns are resolved.\u00a0 Thank you for writing this document (and implementing it, etc.)! There seems to be an internal inconsistency in the normative guidance for how long a given cookie value should be accepted.\u00a0 Section 4.3 says that \"[t]he DNS Server SHOULD allow Cookies within 1 hour period in the past and 5 minutes into the future to allow operation of low volume clients and some limited time skew between the DNS servers in the anycast set\" (before going on to recommend that the server generates a new cookie if it receives one from the client that is more than half an hour old).\u00a0 In contrast, Section 5 says \"[t]he operator SHOULD wait at least longer than the period clients are allowed to use the same Server Cookie, which SHOULD be half an hour, see Section 4.3\".\u00a0 If I'm reading correctly the \"1 hour\" in Section 4.3 is supposed to line up with the \"half an hour\" in Section 5, but does not. Also, as was mentioned in the secdir review thread, I think we should clearly state what properties we require of a MAC in order to be a useful server cookie (including why the chosen inputs are the right thing to MAC!)\u00a0 That is, what message is being authenticated, and why is that a useful message to authenticate? I will also take this opportunity to consult the CFRG on the suitability of SipHash-2-4 for its stated purpose, though I do not feel a strong need to delay IESG approval of this document until a positive answer is received.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-11-27 14:41:40-08:00",
    "text": "(0) As written, the validation procedures for the authority token contain a gaping security hole.\u00a0 In particular, \u00a76 has us use the public key of the certificate referenced by the token's \"x5u\" parameter, without checking that that \"x5u\" value (or the certificate it references) is a trusted issuer of authority tokens.\u00a0 This in essence boils down to \"go fetch a certificate from an attacker provided location and verify that the signature over the attacker-provided token was made by that attacker-provided certificate\".\u00a0 This is trivial for an attacker to achieve and provides no security value.\u00a0 We need to know that the token issuer is trusted and authorized to issue this class of token. The companion document  draft-ietf-acme-authority-token  does describe the need for this mutual trust relationship, but it is negligent for us to provide a step-by-step procedure here that omits this step. (1) Related to my discuss on  draft-ietf-acme-authority-token , we should be clear on which document is the authoritative specification for \"token-authority\" usage; at present the description seems to be split across the two documents. (2) Section 3 \u00a0  The format of the string that represents the TNAuthList MUST be \u00a0  constructed as a base64 [ RFC4648 ] encoding of the TN Authorization \u00a0  List certificate extension ASN.1 object.\u00a0 The TN Authorization List \u00a0  certificate extension ASN.1 syntax is defined in [ RFC8226 ] section 9. Does it need to be the (base64 encoding of the) DER encoding of the ASN.1 object?\u00a0 Or do we allow less stringent ASN.1 encoding rules? (Similarly in \u00a75.4.) (3) I think my discuss point on  draft-ietf-acme-authority-token  about how the issuer is identified will also apply (with slight modification) to this document -- in \u00a75.1 we have text that indicates either \"iss\" or \"x5u\" identifies the issuer, which I do not believe to be accurate. (4) This document claims to define the \"atc\" claim, but draft-ietf-acme-authority-token  also claims to do so.\u00a0 I note that the IANA registration is currently in the other document, but this one has a more accurate/fleshed-out description of the contents, including the various keys that are present in the JSON object.\u00a0 (The other document says it's an \"array\", not an object!) (5) The end of \u00a75.5 has some guidance on HTTP response codes in various failure cases.\u00a0 The proposed behavior provides a trivial side channel to an attacker as to whether a given account ID exists (404 vs 403), and I think we should avoid providing such a side channel, returning 403 for most failures. (6) The validation procedure in \u00a76 just says to check that the \"fingerprint\" claim is \"valid\".\u00a0 I think we should be more specific and say that it must match the account key of the client making the request.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-10-20 12:47:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-11-26 23:52:31-08:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS point (but trivial to fix), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Rich Salz for the shepherd's write-up about the WG consensus (and I noted the mix of STIR & ACME). I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == A very trivial one: please use the more recent  BCP14  template (incl.  RFC 8174 ) ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:36:39-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-30 03:23:14-08:00",
    "text": "Thank you for the work on this document. Many thanks to Sean Turner for his in-depth review, which uncovered a number of points worth fixing:  https://mailarchive.ietf.org/arch/msg/art/6gRj3ieBe2mIdCa10IfOIoFf7Eg/ Additionally, I have one more non blocking comment below. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-06-30 09:11:33-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:36:39-08:00",
    "text": "Thank you for the work on this document. Many thanks to Sean Turner for his in-depth review, which uncovered a number of points worth fixing:  https://mailarchive.ietf.org/arch/msg/art/6gRj3ieBe2mIdCa10IfOIoFf7Eg/ Additionally, I have one more non blocking comment below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-10-23 08:35:48-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 21:30:43-08:00",
    "text": "A couple of easy but necessary ones: Please use the correct  BCP 14  boilerplate in Section 2, and I believe those references need to be normative. Also, I think this document, like  draft-ietf-acme-authority-token , needs a normative reference to  RFC 4648  if it's going to use base64url().",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-07 18:50:09-08:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 09:10:25-07:00",
    "text": "Picking up a Discuss for Francesca: Many thanks to Sean Turner for his in-depth review, which uncovered a number of points worth fixing:  https://mailarchive.ietf.org/arch/msg/art/6gRj3ieBe2mIdCa10IfOIoFf7Eg/ Additionally, I have one more non blocking comment below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-15 08:41:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-03-15 08:37:29-07:00",
    "text": "ext about mandatory to implement charset encodings or charset auto-discovery need to be added back to the document.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-23 08:02:16-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-15 08:41:56-07:00",
    "text": "Text about mandatory to implement charset encodings or charset auto-discovery need to be added back to the document. Alvaro: I think you are correct. I've added an RFC Editor note.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-31 16:23:32-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-06 12:46:45-07:00",
    "text": "If we are providing BCP-level requirements for time-based loss detection via absence of protocol-level acknowledgment, for new protocols, it seems appropriate to mandate that the acknowledgment signal is reliable, i.e., not spoofable by at least an off-path attacker, and ideally not spoofable by an on-path attacker either.\u00a0 I would love for this to be a cryptographically protected mechanism, but expect that I can't get away with mandating something that strong, and that something with \"enough bits of entropy\" will suffice.\u00a0 (I'd prefer \"enough\" to be 128 but could perhaps be persuaded that a lower value is appropriate as a minimum requirement.) Point S.3 in Section 3 indicates that \"[t]he requirements in this document apply only to endpoint-to- endpoint unicast communication. Reliable multicast (e.g., [ RFC5740 ]) protocols are explicitly outside the scope of this document.\"\u00a0 This limitation of scope should be reflected in the document's title, Abstract, and Introduction. I would also like to get an explicit confirmation that the various (non-)requirements on the details of exponential backoff and reduced weighting for old FT samples are as-intended (see COMMENT). Specifically, are there limitations on the base of the exponent for the exponential backoff, and is there a requirement to give more recent FT samples more precedence than older FT samples when computing an RTO estimate?",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2023-02-02 07:20:01-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-02 00:50:07-08:00",
    "text": "Thanks for the solid work on this document. One comment that I'd like to discuss, I believe the reference to ietf-shmoo-remote-fee should be normative, since this document makes reference to a long term commitment to free remote participation, and to my knowledge absent the shmoo-remote-fee document that isn't a commitment that is codified.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-11-29 18:21:24-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-29 07:52:55-08:00",
    "text": "Holding a discuss until the Gen-art conversation on minimum size of the fressness token resolves.\u00a0 Will switch to a yes once that is resolved. https://www.ietf.org/mail-archive/web/gen-art/current/msg13942.html",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-11-26 03:04:38-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-17 09:40:46-08:00",
    "text": "This is a well written document, so thank you for that. I've noticed that Benjamin already found typos that I found and raised one of the same questions, but I think this is important enough to be addressed before I recommend approval of this document. Specifically: In Section 3.1: \u00a0  o\u00a0 Domain Name (0 or more octets) - A Fully Qualified Domain Name \u00a0 \u00a0 \u00a0 used for Split DNS rules, such as \" example.com \", in DNS \u00a0 \u00a0 \u00a0 presentation format and optionally using IDNA [ RFC5890 ] for \u00a0 \u00a0 \u00a0 Internationalized Domain Names. Do you mean A-label or U-label form here? \u00a0 \u00a0 \u00a0 Implementors need to be careful \u00a0 \u00a0 \u00a0 that this value is not null-terminated.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-11-20 14:29:52-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-11-20 14:06:33-08:00",
    "text": "I hope I'm just missing something obvious here, but this seems like it may cause a significant security issue.    Lots of \"regular\" users use VPNs for access the Internet, either to bypass censorship / content restrictions, or to improve their privacy. These are not \"corporate\" / \"enterprise\" VPNs, but rather public ones - and sometimes they are run by people I wouldn't entirely trust. What is to stop one of these VPN providers setting: INTERNAL_DNS_DOMAIN( www.paypal.com ) INTERNAL_DNSSEC_TA(43547,8,1,B6225AB2CC613E0DCA7962BDC2342EA4...) or, better yet: INTERNAL_DNS_DOMAIN(com) INTERNAL_DNSSEC_TA(43547,8,1,B6225AB2CC613E0DCA7962BDC2342EA4...) and so being able to spoof DNSSEC for  paypal.com  / all of .com? This is especially worrying if something like DANE is ever deployed... The draft *does* says: \"Other generic or public domains, such as top-level domains, similarly SHOULD NOT be whitelisted.\" - this doesn't really answer the above. 1: It is increasingly hard to know what is a \"real\" TLD (.internal? .bank? .home?) 2: How do I programatically tell if  www.foo.net  is a \"public domain\"? What is a public domain anyway? How is an implementer supposed to address this?  It also says: \"Any updates to this whitelist of domain names MUST happen via explicit human interaction to prevent invisible installation of trust anchors.\" Is my auntie really expected (or competent) to understand what \"Your VPN provider, TrustVPN wants to whitelist com. Do you want to allow this? [Y/N]\" means?  I'm hoping that I'm completely misunderstanding what the INTERNAL_DNSSEC_TA bit does - please help allay my fears...",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-12-04 10:18:32-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-20 14:29:52-08:00",
    "text": "I hope I'm just missing something obvious here, but this seems like it may cause a significant security issue.    Lots of \"regular\" users use VPNs for access the Internet, either to bypass censorship / content restrictions, or to improve their privacy. These are not \"corporate\" / \"enterprise\" VPNs, but rather public ones - and sometimes they are run by people I wouldn't entirely trust. What is to stop one of these VPN providers setting: INTERNAL_DNS_DOMAIN( www.paypal.com ) INTERNAL_DNSSEC_TA(43547,8,1,B6225AB2CC613E0DCA7962BDC2342EA4...) or, better yet: INTERNAL_DNS_DOMAIN(com) INTERNAL_DNSSEC_TA(43547,8,1,B6225AB2CC613E0DCA7962BDC2342EA4...) and so being able to spoof DNSSEC for  paypal.com  / all of .com? This is especially worrying if something like DANE is ever deployed... The draft *does* says: \"Other generic or public domains, such as top-level domains, similarly SHOULD NOT be whitelisted.\" - this doesn't really answer the above. 1: It is increasingly hard to know what is a \"real\" TLD (.internal? .bank? .home?) 2: How do I programatically tell if  www.foo.net  is a \"public domain\"? What is a public domain anyway? How is an implementer supposed to address this?  It also says: \"Any updates to this whitelist of domain names MUST happen via explicit human interaction to prevent invisible installation of trust anchors.\" Is my auntie really expected (or competent) to understand what \"Your VPN provider, TrustVPN wants to whitelist com. Do you want to allow this? [Y/N]\" means?  I'm hoping that I'm completely misunderstanding how the INTERNAL_DNSSEC_TA bit works. Also, some of the DNS behavior is handwavey - I think that the document really should be reviewed by DNSOP, but will leave it to Eric to make that call.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-02-01 14:57:39-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-17 14:31:52-08:00",
    "text": "A significant portion of this specification depends on knowing the label stack depth limits in the network, but \u00a75.2 declares the mechanism out of scope: \u00a0  In order to accurately pick \u00a0  the delegation hops, the ingress needs to be aware of the label stack \u00a0  depth push limit of each of the transit LSRs prior to initiating the \u00a0  signaling sequence.\u00a0 The mechanism by which the ingress or controller \u00a0  (hosting the path computation element) learns this information is \u00a0  outside the scope of this document. I think that not defining the mechanism in this document is ok -- but not having one means that important parts of this specification can't work.\u00a0 Please point at where such a mechanism is specified, or at least provide examples.\u00a0  The Shepherd's writeup says that \"implementation plans and implementations\" are known so I think that this should be an easy point to address.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-10-24 18:48:48-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-24 16:24:36-07:00",
    "text": "RFC 3326  doesn't specify what the receiver will do if two reason values have the same protocol value. Are we reasonably sure that existing implementations of SIP won't throw an error if they get this, or does there need to be some sort of negotiation mechanism?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-10-27 13:38:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-25 14:13:58-07:00",
    "text": "I understand the document is changing an existing MUST, and the change itself seems fine. But I do wonder about the operational effect of this. What if a sip stack complying to this new RFC talks to an old sip stack complying to the old RFC. Is it known what the most widely used sip stacks do in the case of receiving a duplicate message for the same protocol? Will it just ignore the duplicate ? If so, should this document specify that the order of these might be important ? Will it fail the entire sip packet? If so, should this document specify to only use this when the other end is known to implement this RFC? Should there be a fallback mechanism that will only sent the 1 most important \"reason\" if it looks the other end is failing on our message with multiple reasons? The WG might have experience or testing that is not obvious to me (or other readers of the document). Perhaps a short Operational Considerations Section would be appropriate ?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-03-12 03:45:35-07:00",
    "text": "I agree with Ben's first 2 DISCUSS points. ********************************************************************** * Note, that I am conducting an experiment when people aspiring to be* * Area Directors get exposed to AD work (\"AD shadowing experiment\"). * * As a part of this experiment they get to review documents on IESG\u00a0 * * telechats according to IESG Discuss criteria document and their\u00a0 \u00a0 * * comments get relayed pretty much verbatim to relevant editors/WGs. * * As an AD I retain responsibility in defending their position when\u00a0 * * I agree with it.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  * * Recipients of these reviews are encouraged to reply to me directly *  * about perceived successes or failures of this experiment.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 * ********************************************************************** The following comments were provided by Francesca Palombini . My comments are marked with [[Alexey:]] below. Francesca would have balloted *DISCUSS* on this document. She wrote: Discuss: Either I am missing something about \"unirectional\" and \"bidirectional\" definition (which I read as can either be present in only one direction request/response or both), or the following sections are wrong: section 5.1 - assuming it is Content-Format, the option is bidirectional, it can be set either in a request or response, for example a PUT request can contain a Content-Format section 5.4 - Size1 and Size2 are bidirectional, and can be used both in req and resp (see  RFC7959  sect 4) Section 5.5 - ETag is also Bidirectional (see  RFC7252  section 5.10.6.1 and 5.10.6.2) There are more options being defined and not specified in the document:  https://www.iana.org/assignments/core-parameters/core-parameters.xhtml#option-numbers  for example, Hop-Limit is one. There needs to be some discussion about those, or some considerations on those being out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-15 16:19:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-10 11:56:00-07:00",
    "text": "Section 5.2 claims that Uri-Host and URI-Port are unidirectional from server to client and \"[are] never found in client requests\", which seems to contradict Section 5.10.1 of  RFC 7252 .\u00a0 It seems like maybe this section is supposed to only cover Max-Age, with Uri-Host and Uri-Port rolled into Section 5.3 along with Uri-Path and Uri-Query? Similarly, Section 5.4 says that size1 and size2 are unidirectional (only in requests), which does not seem to be accurate given my reading of RFCs 7252 and 7599. I also think that we need some further discussion (e.g., in the security considerations) about how the base LPWAN SCHC document assumes that MAC-layer LPWAN security mechanisms are in use, but that CoAP is not restricted to such contexts.\u00a0 What additional security considerations are relevant when this compression is used for CoAP without LPWAN MAC-layer cryptographic protection? Perhaps not really a Discuss on this document, but what is the planned disposition of the tsv-art reviewer's comments regarding draft-ietf-lpwan-ipv6-static-context-hc  and UDP Options?\u00a0 I did not see anything pertinent in the mailarchive.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-10 18:18:11-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-15 16:19:41-07:00",
    "text": "I don't think we quite managed to catch all the collatoral damage from my previous discuss points on the -13.\u00a0 In particular, while Sections 5.x no longer attempt to discuss directionality of CoAP Options, there are some in-passing references to them in Section 3.1: - There's a claim that URI-Path (though, spelled as \"URI-path\") is not \u00a0 present in the response, which is incorrect. - There's a reference to a nonexistent \"Content\" option as being present \u00a0 only in a response, but the \"Content-Format\" option is allowed in both \u00a0 requests and responses.\u00a0 (See, e.g., the PUT method for use of \u00a0 Content-Format in a request.) - The \"Accept\" option is referenced as only being present in requests. \u00a0 This seems to be accurate as far as I can see in  RFC 7252 , though in \u00a0 light of the near-complete removal of such references from this \u00a0 document, perhaps it should also be removed. While the expanded security considerations do cover several important points, I think it's important to specifically state that the  RFC 8724 procedures assume that SCHC is implemented on top of LPWAN technologies that implement security mechanisms.\u00a0 I think we also need to specify that either (a) this assumption remains for the CoAP usage of SCHC, or that (b) CoAP has use cases outside of LPWAN, and when SCHC is used in those non-LPWAN cases, the attacks (such as are now described in the -15) are more readily performed than in the secure LPWAN environment when no other integrity protection mechanism is in place for the compressed packets. As Francesca noted on the -13, we need to acknowledge that there are and will be in the future CoAP options that are not included in this document and provide some indication of how they might be handled. Whether that's to define new compression rules/guidance for them, always send them as full residuals, or some other behavior can be decided in the future on a per-option basis, but we can give some guidance here on how we plan to support extensibility of options. --- The -15 introduced some new text in the Introduction: \u00a0  CoAP is an End-to-End protocol at the application level, so CoAP \u00a0  compression requires to install common Rules between two hosts and IP It's not entirely clear to me that this is true, given that CoAP proxies are a first-class protocol feature.\u00a0 OSCORE is probably fair to describe as end-to-end, but CoAP itself may not be. Also, the new examples in Section 2 are sufficiently hard to follow that I can't be sure the figures and the prose descriptions are internally consistent.\u00a0 (See COMMENT for a few more specifics.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-01 19:04:09-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-10 18:18:11-08:00",
    "text": "This point from my previous review does not seem to be addressed: While the expanded security considerations do cover several important points, I think it's important to specifically state that the  RFC 8724 procedures assume that SCHC is implemented on top of LPWAN technologies that implement security mechanisms.\u00a0 I think we also need to specify that either (a) this assumption remains for the CoAP usage of SCHC, or that (b) CoAP has use cases outside of LPWAN, and when SCHC is used in those non-LPWAN cases, the attacks (such as are now described in the -15) are more readily performed than in the secure LPWAN environment when no other integrity protection mechanism is in place for the compressed packets. I'm also still a bit confused by the examples in Section 2 -- the prose says: \u00a0  In the first example, Figure 1, a Rule compresses the complete header \u00a0  stack from IPv6 to CoAP.\u00a0 In this case, SCHC C/D (Static Context \u00a0  Header Compression Compressor/Decompressor) is performed at the \u00a0  device and the application.\u00a0 The host communicating with the device \u00a0  does not implement SCHC C/D. but the figure itself shows a box for SCHC in the NGW, and does not show such a box in the Application.\u00a0 How is the figure consistent with the quoted prose?\u00a0 (The new paragraph added after the figure seems to match up more naturally with the figure; was the paragraph before the figure intended to be deleted?)",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-03 07:09:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-12 03:00:23-07:00",
    "text": "Reviewing this document and its application to compress case two and three stacks in Figure 1, i.e. with some end-to-end encryption appears to significantly change an assumption from the SCHC for IPv6/UDP. Namely, the assumption about context establishment. In normal SCHC the contexts are established between the Device and the NGW. In these end-to-end encrypted case the context establishing party for the COAP compression is the APP and the APP layer in the device. This difference appear completely ignored in this document. I think this is a significant difference as having the device and NGW run a protocol for establishing context over the L2 or L3 with the local context knowledge is fairly straightforward. However, in this case when the COAP peer on the internet side of the NGW this determination and configuration is a different matter.  From my perspective some more discussion of the fact that this is a different context and that it have different challenges in establishing the context should be made clear in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-10 19:51:22-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-10 19:50:32-07:00",
    "text": "**\u00a0 Section 9. (as Paul Wouters mentioned in his SECDIR review, thanks Paul!) Per \u201cThis document does not have any more Security consideration than the ones already raised on [ I-D.ietf-lpwan-ipv6-static-context-hc ]\u201d, this reference in Section 12 (Security Considerations) contains the statement that \u201cSCHC is expected to be implemented on top of LPWAN technologies, which are expected to implement security measures.\u201d, is that assumption valid here?\u00a0 If it is not, what are the implications? ** Section 9.\u00a0 Per \u201cThe size of the Initialisation Vector residue size must be considered carefully. A too large value has a impact on the compression efficiency and a too small value will force the device to renew its key more often.\u201d, can you be a bit clearer on the tradeoff: -- how small is still acceptable given the security properties that still need to be preserved in the AEAD nonce? -- Given a particular smaller size, what factors would would influence more frequent key renewal?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-13 06:22:10-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-10 19:51:22-07:00",
    "text": "**\u00a0 Section 9. (as Paul Wouters mentioned in his SECDIR review, thanks Paul!) Per \u201cThis document does not have any more Security consideration than the ones already raised on [ I-D.ietf-lpwan-ipv6-static-context-hc ]\u201d, this reference in Section 12 (Security Considerations) contains the statement that \u201cSCHC is expected to be implemented on top of LPWAN technologies, which are expected to implement security measures.\u201d, this assumption doesn't necessarily seem valid here?\u00a0 What are the implications? ** Section 9.\u00a0 Per \u201cThe size of the Initialisation Vector residue size must be considered carefully. A too large value has a impact on the compression efficiency and a too small value will force the device to renew its key more often.\u201d, can you be a bit clearer on the tradeoff: -- how small is still acceptable given the security properties that still need to be preserved in the AEAD nonce? -- Given a particular smaller size, what factors would would influence more frequent key renewal?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-12-16 06:58:03-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-15 13:19:02-08:00",
    "text": "A small question before I go to \"Yes\": RFC 2595  Section 2.4 says: \u00a0  - Matching is case-insensitive. This document does not.\u00a0 Was that dropped intentionally?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-02 15:16:56-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 14:40:15-07:00",
    "text": "Should we say something about which order the sorting criteria are applied (first to last vs last to first) when multiple sortItems are specified in a query? I recognize that in the HATEOS model, the actual JSONPaths reported by the server should be used by the client to determine what a given sort property does, but it also seems like it would be confusing for this document to specify (e.g.) an \"email\" property with specific JSONPath, and then have a server go off and use \"email\" to mean something else, even if that is just the addition of \"pref\" as discussed at the end of Section 2.3.1.\u00a0 Do we want to try to have the properties defined by this document be universally defined and encourage the use of new/different property names for variations on them?\u00a0 (The answer may well be \"no\", but the answer is not intuitively clear to me.)\u00a0 To put it another way, is the list in Section 2.3.1 normative, or just an example?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-02 15:55:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 06:33:26-07:00",
    "text": "** Canonical Reference for JSONPath.\u00a0 Section 2.1/2.3.1 describes field(s) whose syntax is in JSONPath.\u00a0 The shepherd\u2019s note acknowledges that there is no good reference for JSONPath.\u00a0 Nevertheless, the text needs to be clearer on where to turn to for guidance. (1) Section 2.3.1 says: \u201cSuch a reference could be \u00a0  expressed by using a JSONPath.\u00a0 The JSONPath in a JSON document \u00a0  [ RFC8259 ] is equivalent to the XPath [ W3C.CR -xpath-31-20161213] in a \u00a0  XML document.\u00a0  (2) The JSONPaths are provided according to the Goessner v.0.8.0 \u00a0  specification [GOESSNER-JSON-PATH].  (3) Further documentation about \u00a0  JSONPath operators used in this specification is included in \u00a0  Appendix A. Taking the perspective of the implementer, which of these three resources is canonical for understanding JSONPath: (a) [ W3C.CR -xpath-31-20161213] = a reference marked normative that has nothing to do with JSON but suggests equivalence through a few examples. (b) [GOESSNER-JSON-PATH] = a reference marked as informative which is being used to describe the normative mapping between JSONPaths of the RDAP fields in the text, and is the actual description of the JSONPath syntax.\u00a0 The shepherd\u2019s note points out the difficulty of using this as a normative reference (c) Appendix A = self-contained text which describes JSONPath independent of (a) and (c).\u00a0 As an aside, I\u2019m not sure of the completeness of this write-up. Additionally, the IETF is currently considering it\u2019s own version of JSONPath --  https://datatracker.ietf.org/doc/charter-ietf-jsonpath/ IMO, the fig leaf of citing [ W3C.CR -xpath-31-20161213] is inappropriate (as in, it isn\u2019t the actual reference) and unnecessary (as in, it\u2019s just there to meet the letter of having a normative reference).\u00a0 I recommend being practical about the need: -- Use language to the effect of saying the \u201cJSONPath used here is a flavor defined in XXX\u201d -- Make \u201cXXX\u201d be Appendix A. -- Bolster Appendix A to say something to the effect of \u201cthis version of JSONPath is inspired by [ W3C.CR -xpath-31-20161213] (informative reference) and an articulation of what is used in production [GOESSNER-JSON-PATH] (informative reference)\u201d; and where necessary, add more language around the syntax. This approach will also allow for new JSONPath WG to define a variant which is not strictly compatible (if that\u2019s where the work goes). I\u2019m open to an alternative approach.\u00a0 I just want to end up with a single clear reference of where to read about this documents particular JSONPath syntax. ** Section 2.4.\u00a0 Does this specification provide any normative guidance of \u201ccursor\u201d beyond an opaque value constrained by ABNF?\u00a0 The text notes the notion of \u201coffsets\u201d, \u201climits\u201d, and \u201ckeys\u201d, Base64, CSV but these appear to be referenced as examples.\u00a0 However, Appendix B contains normative language around \u201climit\u201d and \u201coffset\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-12-01 05:36:52-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-28 13:08:51-08:00",
    "text": "# Sec AD review of  draft-ietf-ipsecme-ikev2-multiple-ke-10 CC @paulwouters Please refer to  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ for more information about how to handle DISCUSS and COMMENT positions. This review uses the format specified in  https://github.com/mnot/ietf-comments/  which allows automated tools to process items (eg to produce github issers) Let me first apologize to Valery for not getting to review this document earlier. He surely reminded me enough times to do it before it landed at the IESG. This is a very well written document. Thanks to everyone involved. While I have a few DISCUSS comments, these should be easy to address or convince me why no changes are required. Note to self (and Valery):  draft-kampati-ipsecme-ikev2-sa-ts-payloads-opt  needs to be updated to support this document. It currently only supports sending one KE payload. ## DISCUSS ### IANA entries mentions in the Introduction ? Shouldn't the introduction mention this draft introduces the IKE_FOLLOWUP_KE Exchange and the STATE_NOT_FOUND Notify Message Type, along with additional entries to the (now renamed) Key Exchanges Methods registry? ### Additional key exchanges DoS ? The following paragraph raised an issue for me: ``` \u00a0  If the responder selects NONE for some Additional Key Exchange types \u00a0  (provided they are proposed by the initiator), then the corresponding \u00a0  IKE_INTERMEDIATE exchanges MUST NOT take place. ```\u00a0 \u00a0  If the initiator's local policy requires at least one Additional Key Exchange, an attacker sending back a quick reply with only NONE replies would be a DoS. I think similar to like the original IKE_SA_INIT, perhaps we need to give some advise that if the local policy would lead to permanent failure, that it should wait for other (more legitimate) responses to this IKE_SA_INIT ? ### ADDITIONAL_KEY_EXCHANGE ``` \u00a0  After IKE SA is created the window size may be greater than one and \u00a0  multiple concurrent exchanges may be in progress, it is essential to \u00a0  link the IKE_FOLLOWUP_KE exchanges together ``` I had some trouble figuring out why these are needed. For Child SA rekeys, these would not be needed, because we would have an old SPI and MSGID that would make the order obvious. But for adding addtional Child SA's, we have no old SPI. But we have a new SPI on the initiator (and then a new SPI on the responder in the answer. Since these are coupled by MSGID, I wonder if ADDITIONAL_KEY_EXCHANGE is really needed? Looking at the useful appendix examples, I realise that the IKE_FOLLOWUP_KE exchange does not have an SA payload so no SPI, so it makes sense to me now. Perhaps a sentence in the document would be useful to explain this? I still do not know why not to use the SPI as value for ADDITIONAL_KEY_EXCHANGE instead of an opaque linking blob? The SPI is traditionally our linking blob. Could the IKE_FOLLOWUP_KE set the SPI value in the IKE header instead of using a new ADDITIONAL_KEY_EXCHANGE payload and use that with the MSGID as linking blob? ### State loss issue ```\u00a0 \u00a0   \u00a0  After receiving this notification the initiator MAY start \u00a0  a new CREATE_CHILD_SA exchange which may eventually be followed by \u00a0  the IKE_FOLLOWUP_KE exchanges, to retry the failed attempt.\u00a0 If the \u00a0  initiator continues to receive STATE_NOT_FOUND notifications [...] ``` How could this happen? If the state was lost, eg due to reboot, there would need to come a new IKE SA, that can then send a new CREATE_CHILD_SA. I don't see how that could lead to another STATE_NOT_FOUND. But the paragraph then also continues with \"and delete [the] IKE SA\". But this IKE SA is brand new?  I would just remove this entire paragraph as I think this cannot happen. Or at least it is not a special case and existing abort code handles this already. ### IKE session resumption Should there be a section updating  RFC 5723  Section 5.1, or is the method there specified quantum-safe if the initial IKE SA was protected using this document's mechanism? See  https://www.rfc-editor.org/rfc/rfc5723.html#section-5.1 I think the IKE resumption can work \"as normal\", as no KE payload is involved in the resumption, but it would be nice if a sentence somewhere in this document could confirm this.  Also  RFC 5723  states: ``` The keys and cryptographic protection algorithms should be at \u00a0 \u00a0 \u00a0 least 128 bits in strength. ``` IF we live in Grover universe, perhaps that should be 256 bits in strength? And since we are making things quantum safe with this document, perhaps we should then at least state session tickets should be 256 bits. Note if we do, then this document must Update:  RFC 5723 . Perhaps this note on 5723 can be added in the Security Considerations Section paragraph that talks about Grover and Shor. ### non-fatal NO_PROPOSAL_CHOSEN? ``` \u00a0  In this case, the responder may respond with \u00a0  non-fatal error such as NO_PROPOSAL_CHOSEN notify message type. ```\u00a0 \u00a0   Technically, this error is non-fatal. But in this context, wouldn't it be fatal if the responder insists on additional exchanges during the initial exchange and the initiator doesn't suppor this? It is sort of a lame duck IKE SA ? :) Also the \"may\" responder is unclear to me. What other response could there be and why? ### misplaced text? ``` \u00a0  Note that if the initial IKE SA is used to transfer sensitive \u00a0  information, then this information will not be protected using the \u00a0  additional key exchanges [...] ``` This paragraph appears in the Section \"Interaction with Childless IKE SA\", but should probably be moved to the Security Considerations section. ### IKE_FOLLOWUP_KE name I find the name IKE_FOLLOWUP_KE a little confusing, as this exchange applies to IKE and IPsec SA rekey negotiations. Why is it not called FOLLOWUP_ADDITIONAL_KE ? Or CREATE_CHILD_SA_FOLLOWUP(_KE) (a sort of bad name too but that at least follows the bad name from the original IKEv2 spec) ### authentication ? ```  \u00a0 \u00a0 \u00a0 \u00a0 This document does not address authentication since it is less urgent \u00a0 \u00a0 \u00a0 \u00a0 at this stage. ``` While true, it does state that PPKs can be used. It might also want to say that no IKE protocol level changes would be needed for authentication. A new  RFC 7427 Digital Signature algorithm that is quantum-safe could be defined for X.509 and would become available immediately without any IKEv2 level changes. So in a way, this issue will be addressed but no IKEv2 document is needed for that. Perhaps this can be clarified in the draft? Related to this is text in the Security Considerations: ``` \u00a0  In particular, the authenticity of the SAs established \u00a0  under IKEv2 is protected using a pre-shared key, RSA, DSA, or ECDSA \u00a0  algorithms. ```  This text is also incorrect as  RFC 7427  allows us to use post-quantum authentication algorithms that have a SubjectPublicKeyInfo (SPKI) definition. There might not be any now, but there will presumbly be some in the future. ### AH Section 4 lists AH. Is there much point in using this document when deploying AH? The idea was the protect against _future_ quantum computers breaking encryption, not MITM style packet modification. So using AH (or ESP_NULL) with this document seems pointless :) And the Security Considerations kind of agree with me here: ``` \u00a0  Until quantum computers \u00a0  become available there is no point in attacking the authenticity of a \u00a0  connection because there are no possibilities for exploitation. ```",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-11-28 09:00:44-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 09:36:35-07:00",
    "text": "A fairly minor point, really, but several of the nodes within \"container error-performance-statistics\" discuss \"the interval\" or \"a fixed measurement interval\".\u00a0 These values are not interoperable unless the interval (or the way to determine it) is specified.\u00a0 My understanding is that normally this sort of counter would be using the interval since last startup, and would also track the time of last discontinuity (i.e., startup), but I am not really an expert in this area.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-05-31 20:37:40-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 14:31:35-07:00",
    "text": "(1) Given the two key security threats identified in Section 11 -- that authorized nodes can issue requests with artificially high priority in order to get better treatment, and that unauthorized intermediaries can modify the priorities that senders set -- I don't see how it is legitimate to claim that either 5.1 or 5.2 are appropriate use cases for DRMP. The spec seems to assume that this mechanism will only be used in scenarios where nodes and agents have some out-of-band trust relationship established with each other (the shepherd write-up talks about a \"trusted environment\"), but that is certainly not the case in many disaster and emergency scenarios. If that really is a limitation on the scope of applicability of this mechanism, that should be stated in the document, and those use cases should either be removed or modified to explain the limitations on their applicability.\u00a0  (2) Section 6 says: \t\u00a0  \"The mechanism for how the agent determines which requests are \u00a0 \u00a0 \u00a0  throttled is implementation dependent and is outside the scope of \u00a0 \u00a0 \u00a0  this document.\" How is a node supposed to determine how to set its priorities if each agent makes implementation-specific decisions about what those priorities mean? I understood the document to be saying that Diameter applications would have to define what he priority levels mean within their own contexts, but then I would have expected the interpretation of priorities amongst all nodes and agents implementing the same application to be the same.  (3) Section 8 says:  \t\"Diameter nodes SHOULD use the PRIORITY_10 priority as this default value.\" \u00a0   If the determination of the priority schemes are all application-specific, how is it appropriate for this spec to define what the default priority should be for all applications? Shouldn't applications specify their own defaults?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-05-10 09:51:59-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 19:30:51-07:00",
    "text": "I have a few concerns that I think need some discussion.  1) Priority between applications: The fact that agents can apply priority for messages from multiple applications without knowledge of those applications seems dangerous. Let's say application A is a critical infrastructure application, and application B is not. But clients for application B might set requests to have a higher priority than do clients for application A.\u00a0 Further, application B could become a DoS vector for application A. One potential (and likely half-baked) way to mitigate this would be to say that nodes that are not \"application aware\" can only apply priority among messages for the same application. 2) Priority between clients of the same application: If you have multiple clients for the same application, don't they need to use the same prioritization strategy? How is this to be managed? 3) Out of order requests: The draft explicitly allows agents to re-route and even explicitly re-order messages. Is it safe to have a non-application aware node change the order of messages? 4) I am nervous about the idea that clients and servers would use a generic message priority mechanism to manage the allocation of resources that result from a requests and answers. It seems like that should be based on application specific rules and information. (Now, if the point is that these same AVPs might be used in an application according to application specific rules, that might be okay--but then you might run into issues where application-agnostic agents don't know the difference.)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-05-10 07:07:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-05-04 04:13:19-07:00",
    "text": "I fully agree with all discuss comments made by Ben and Alissa. However, the summary here might be that this information might simply be not very useful for the uses cases described. And there might be other mechanisms that do not require any trust and that can address the uses cases easier and more appropriate such a simply prioritization of a certain application in the request handler/request agent or relative priorities within one application (on sent-out).  However, the one part that does actually concern me is: \"When using DRMP priority information, Diameter nodes MUST use the \u00a0  default priority for transactions that do not have priority specified \u00a0  in a DRMP AVP.\" This part seems dangerous and I would proposed to instead basically have to different queues: one if a priority is defined and another one for requests without priority indication to make sure that requests out of the second queue will be served at some point in time and cannot be starved by other low priority requests completely.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-05-11 10:34:17-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-10 07:07:56-07:00",
    "text": "I fully agree with all discuss comments made by Ben and Alissa. However, the summary here might be that this information might simply be not very useful for the uses cases described. And there might be other mechanisms that do not require any trust and that can address the uses cases easier and more appropriate such a simply prioritization of a certain application in the request handler/request agent or relative priorities within one application (on sent-out).  However, the one part that does actually concern me is: \"When using DRMP priority information, Diameter nodes MUST use the \u00a0  default priority for transactions that do not have priority specified \u00a0  in a DRMP AVP.\" This part could lead to starvation of requests that do not define a priority, e.g. because there are not supporting it (yet). However these starved requests could effectively have a higher priortiy than the request that they get starved by.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-05-29 05:12:12-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-08 16:27:58-07:00",
    "text": "The following text in section 4 seems to indicate that scheduling is done on a per-packet basis: \"When there is a \u00a0  datagram to be sent to a destination, the source router acquires a \u00a0  path from the Multi-path Routing Set (MAY be Round-Robin, or other \u00a0  scheduling algorithms).\" This seems not appropriate as e.g. TCP packets routed on links with largely different delays may suffer performance. ECMP usually hashes the 5-tuple or 6-tuple (incl. DiffServ Codepoint) to setup state and routes all packets belonging to the same flow on the same route. I recommend to apply the same here. Also related is this text in section 8.4 that should explain Round-Robin on a per flow basis instead. Further this should only be an example scheduling alogirthm while text belong seems to assume that Round-Robin is always used. \"If a matching Multi-path Routing Tuple is obtained, the Path Tuples \u00a0  of the Multi-path Routing Tuple are applied to the datagrams using \u00a0  Round-robin scheduling.\u00a0 For example, there are 2 path Tuples \u00a0  (Path-1, Path-2) for destination router D. A series of datagrams \u00a0  (Packet-1, Packet-2, Packet-3, ... etc.) are to be sent router D. \u00a0  Path-1 is then chosen for Packet-1, Path-2 for Packet-2, Path-1 for \u00a0  Packet 3, etc.\u00a0 Other path scheduling mechanisms are also possible \u00a0  and will not impact the interoperability of different \u00a0  implementations.\" Related is this text in section 8.4.: \"If datagrams without source routing header need to be forwarded using \u00a0  multiple paths (for example, based on the information of DiffServ \u00a0  Code Point [ RFC2474 ])\" RFC2474  does not specify any application requirements on multipath use and as such the DiffServe field should not be used to determine if the flow can be routed on multiple paths. The ability to profit from multipath routing depends not only on the application and protocols used but also on the characteristics of the multipath link(s); so it's hard to make any implicit assumptions here. However, if routing would only be recommended on a per-flow basis this problem does not occur and the brackets above could be remove. Further, if routed on a per flow basis would be done, DiffServ could actually be used to decide which path to use, if e.g. one path has a lower delay, but that seem to need further discussion as well.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-22 18:05:36-08:00",
    "end_reason": "position_updated",
    "start": "2021-08-25 23:59:54-07:00",
    "text": "I think there's an issue with the pseudocode in Figure 6.\u00a0 While I understand that it's pseudocode, any reasonable interpretation I can come up with for the \"~\" and \"&=\" operators seems to result in performing an operation logically equivalent to: X = AdjacentBits[SI] Packet->BitString = Packet->BitString & ~X & X that can be optimized to Packet->BitString = 0 and I do not think that the only bits that are supposed to be set in the outgoing packet/packet copy are the ones for which DNC is set -- bits that we did not find in our BIFT should remain set in outgoing packets. (Slightly more detail in the COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-08-25 09:13:56-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-25 06:50:38-07:00",
    "text": "Hi, I would like to please double check with the authors, responsible AD, and IESG that publishing this as standards track is the right choice (as opposed to experimental). From the first line of the introduction: \"BIER-TE is based on architecture, terminology and packet formats with \u00a0  BIER as described in [ RFC8279 ] and [ RFC8296 ]. Both  RFC 8279  and  RFC 8296  are experimental RFCs, hence (1) I wanted to check that by publishing this draft as Std Track, that this draft isn't being built on an unstable footing. This draft has a normative reference to  RFC 8279 , but only an informative reference to  RFC 8296 . Hence, I further wanted to check: (2) Should  RFC 8296  really be a normative reference? (3) The IETF LC announcement didn't seem to flag the downref to  RFC 8279 .\u00a0  RFC 8067  says that is not strictly required, but in this case I think that would have been useful. I can see from the document history that the WG has flip-flopped on whether this document should be experimental or stds track, but I couldn't quickly find this discussion, and it wasn't covered in shepherds writeup.\u00a0 If it is possible for someone to provide a quick summary as to why it is okay and right to publish this as standards track that would be appreciated.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-06-11 05:35:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-06-10 14:56:44-07:00",
    "text": "This should be simple to resolve - the use of the SR-TE term is out-of-alignment with other drafts, spring and idr. Suggest: Segment Routing Traffic Engineering/s/Segment Routing Policy and SRTE/s/SR Policy.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-06-22 12:00:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 05:35:17-07:00",
    "text": "This should be simple to resolve - the use of the SR-TE term is out-of-alignment with other drafts, spring and idr. Suggest: Segment Routing Traffic Engineering/s/Segment Routing Policy and SRTE/s/SR Policy. And this should be obvious, the abstract justifies the need for this document because routers assume RSVP-TE on a link based on an OSPF advertisement. But that's an implementation shortcut and needs to be noted as that. Sure, it was ok when everything was RSVP/RSVP-TE. But let's not make it a \"BCP\". This needs to be corrected to say \"Some implementations..\". I would suggest aligning this abstract with the ISIS draft and move this paragraph to later in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-06-23 03:42:49-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 07:32:00-07:00",
    "text": "I found parts of this document hard to understand, but I'm not familiar with the specifics of the protocols. This discuss is in the vein of \"I think that folks might struggle to implement this correctly/consistently\".\u00a0  In particular I had some questions/concerns about section 5 which, if clarified, would probably help this document. In Section 5: \u00a0  The ASLA sub-TLV is an optional sub-TLV and can appear multiple times \u00a0  in the OSPFv2 Extended Link TLV and OSPFv3 Router-Link TLV.\u00a0 The ASLA \u00a0  sub-TLV MUST be used for advertisement of the link attributes listed \u00a0  at the end on this section if these are advertised inside OSPFv2 \u00a0  Extended Link TLV and OSPFv3 Router-Link TLV.\u00a0 It has the following \u00a0  format: I think that it would be useful to clarify when/why the ASLA sub-TLV can be included multiple times.\u00a0 I.e. when different applications want to control different link attributes. \u00a0  Standard Application Identifier Bits are defined/sent starting with \u00a0  Bit 0.\u00a0 Undefined bits which are transmitted MUST be transmitted as 0 \u00a0  and MUST be ignored on receipt.\u00a0 Bits that are not transmitted MUST \u00a0  be treated as if they are set to 0 on receipt.\u00a0 Bits that are not \u00a0  supported by an implementation MUST be ignored on receipt. It was not clear to me what it means if the SABM (or UDABM) fields are entirely empty.\u00a0 This paragraph states that they are treated as if they are 0, but sections 8 and 11 imply that if the field is omitted then it acts as if all applications are allowed.\u00a0 Section 12.2 implies that if the field is omitted then it is as if all applications are allowed unless there there is another ASLA with the given application bit set, in which case it is treated as being a 0 again.\u00a0 I think that this document would be helped if the specific behaviour was defined in section 5, retaining the justification/clarification in the subsequent sections. It is also not entirely clear to me exactly how the bits are encoded on the wire.\u00a0 My assumption is that if bit 0 is set, then this would sent the highest bit of the first byte.\u00a0 E.g. 0x80?\u00a0 Is that correct?\u00a0 If not, then I think that the document needs more text, if so, then an example of the encoding may still aid readability. \u00a0  User Defined Application Identifier Bits have no relationship to \u00a0  Standard Application Identifier Bits and are not managed by IANA or \u00a0  any other standards body.\u00a0 It is recommended that bits are used \u00a0  starting with Bit 0 so as to minimize the number of octets required \u00a0  to advertise all UDAs. Doesn't this need more constraints to ensure easy interop (i.e. bits default to 0).\u00a0 Otherwise, it would seem that anyone is allowed to put any value in this field that they like that could harm interop, or otherwise it might be tricky to compare a 4 byte UDABM to an 8 byte UDABM? \u00a0  This document defines the initial set of link attributes that MUST \u00a0  use the ASLA sub-TLV if advertised in the OSPFv2 Extended Link TLV or \u00a0  in the OSPFv3 Router-Link TLV.\u00a0 Documents which define new link \u00a0  attributes MUST state whether the new attributes support application \u00a0  specific values and as such MUST be advertised in an ASLA sub-TLV. \u00a0  The link attributes that MUST be advertised in ASLA sub-TLVs are: I think that I get what this means, but I find the last two sentences slightly jarring given than the ASLA TLV is optional.\u00a0 Perhaps predicate both of these constraints with \"(if supproted)\".\u00a0 E.g., something like,   Documents which define new link  attributes MUST state whether the new attributes support application  specific values and as such MUST be advertised in an ASLA sub-TLV (if supported).  The link attributes that MUST be advertised in ASLA sub-TLVs (if supported) are: Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-07-11 06:19:58-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-09 10:53:58-07:00",
    "text": "Section 2.1 says:  \"The scoping of Token Binding key pairs generated by Web browsers for \u00a0  use in first-party and federation use cases defined in this \u00a0  specification (Section 5), and intended for binding HTTP cookies, \u00a0  MUST be no wider than the granularity of \"effective top-level domain \u00a0  (public suffix) + 1\" (eTLD+1).\u00a0 I.e., the scope of Token Binding key \u00a0  pairs is no wider than the scope at which cookies can be set (see \u00a0  [ RFC6265 ]), but MAY be more narrow if cookies are scoped more \u00a0  narrowly.\" My reading of  RFC 6265  is that it does not actually forbid cookie setting at a scope wider than eTLD+1, although I could be reading Section 5.3 of that document wrong. That section says that if the user agent is configured to reject public suffixes, then there is a case where a set-cookie request should be ignored. If the intent here is to normatively restrict the scope of Token Binding key pairs to eTLD+1 regardless of whether the user agent restricts cookies to that scope, that needs to be stated clearly. I kind of hate to say this but with the way this is phrased I also think you need a normative reference for the concept of \"effective top-level domain.\" (I suspect this would be considered a downref and may not already be in the downref registry, but I'm not one to make a fuss about that.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-06-26 11:42:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-09 13:37:48-07:00",
    "text": "I plan to ballot \"YES\", but I want to clear up once concern first: After reading section 6 several times, I don't know what it means. I think it's hard enough to understand that implementers will not interpret it in a consistent way. It's entirely possibly this is \"just me\", but I want to discuss it before progressing. I think this can be fixed easily with either some clarification text, or an argument that the issue is, in fact, \"just me\". In particular, the 2nd paragraph is pretty convoluted, but even after several readings the best I can get out of it is \"Servers that use token-binding with native clients should let them use token-binding\", which I suspect is not the (entire) point.\u00a0 Since these \"native applications\" are described as using HTTP, it's not obvious to me what is different for them. Additionally, I assumed \"native applications\"\u00a0 to mean non-browser, yet the third paragraph talks about \"such implementations\" but uses a browser-based example. Is there a different meaning intended?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-11 22:44:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-07 11:05:30-07:00",
    "text": "This document states: \"This document does not introduce any privacy or security issues not \u00a0  already present in the ALTO protocol.\" This may be true, but it's not obvious it is, because when questions are asked together, that's more of a privacy signature than independently. So, suppose that application A asks for metric A and application B asks for metric B and application C asks for A and B. If these applications are mixed behind a CGN, with single queries then you don't know whether you have some A clients and some B clients, but if you do multi-query, it's clear these are C clients. This is a potentially serious issue if (for instance) Bittorrent always asks for a very distinguished set of parameters, so an ALTO server might use this to find Bittorrent clients.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-12 07:37:04-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-11 22:44:33-07:00",
    "text": "This document states: \"This document does not introduce any privacy or security issues not \u00a0  already present in the ALTO protocol.\" This may be true, but it's not obvious it is, because when questions are asked together, that's more of a privacy signature than independently. So, suppose that application A asks for metric A and application B asks for metric B and application C asks for A and B. If these applications are mixed behind a CGN, with single queries then you don't know whether you have some A clients and some B clients, but if you do multi-query, it's clear these are C clients. This is a potentially serious issue if (for instance) Bittorrent always asks for a very distinguished set of parameters, so an ALTO server might use this to find Bittorrent clients. I don't think any normative change to the protocol is required here, but I do think you need to accurately characterize the situation.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-25 10:43:54-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-12 07:37:04-07:00",
    "text": "This document states: \"This document does not introduce any privacy or security issues not \u00a0  already present in the ALTO protocol.\" This may be true, but it's not obvious it is, because when questions are asked together, that's more of a privacy signature than independently. So, suppose that application A asks for metric A and application B asks for metric B and application C asks for A and B. If these applications are mixed behind a CGN, with single queries then you don't know whether you have some A clients and some B clients, but if you do multi-query, it's clear these are C clients. This is a potentially serious issue if (for instance) Bittorrent always asks for a very distinguished set of parameters, so an ALTO server might use this to find Bittorrent clients. I don't think any normative change to the protocol is required here, but I do think you need to accurately characterize the situation. Something like the following text should be fine \"The privacy and security properties of the mechanism specified in this document are generally similar to those already present in the ALTO protocol. However, because queries for multiple metrics represent a stronger fingerprinting signal than queries for a single metric, implementations of this protocol may leak more information about the ALTO client than would occur with a succession of individual queries; although in many cases it would already be possible to link those queries by using the source IP address or other existing information. \"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-25 07:23:37-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-25 05:13:28-07:00",
    "text": "This is a very boring, almost-trivial discuss point, but the document seems to have an internal inconsistency to resolve before publication: Section 3.1 says that the typecnt \"MUST NOT be zero\", but Section 3.2 says: \u00a0  A TZif data block consists of seven variable-length elements, each of \u00a0  which is series of zero or more items.\u00a0 [...] This is in conflict with the above \"MUST NOT be zero\" for typecnt. I don't have a better suggestion than adding a parenthetical \"(except for the local time records, which as mentioned above cannot have zero items)\", even though I acknowledge that it is pretty awkward.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-23 08:58:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-08-26 14:28:55-07:00",
    "text": "There seems to be an internal inconsistency regarding the format of the data payload: at the start of Section 4 we see that \"When present, the data field contains a list of identifiers or assignments in the form <>[=<>],<>[=<>],...\u00a0 where <> is the ASCII name of a system or peer variable specified in  RFC 5905  and <> is expressed as a decimal, hexadecimal or string constant in the syntax of the C programming language\", but later on we see that the Read Status reply \"contains a list of binary-coded pairs <> <>, one for each currently defined association.\u00a0 The \"binary-coded\" (with, apparently, implicit length) seems at odds with the ASCII key/value assignment pairs. The description of the Configure(8) command as \"The command data is parsed and applied as if supplied in the daemon configuration file\" lacks any reference to what that format is or how one might know what format the peer expects.\u00a0 This does not seem sufficiently specified so as to admit interoperable implementation. The description of the Read MRU(10) command also seems underspecified. What name=value pairs affect the selection of records (and how)?\u00a0 Is there a particular name used with name=value pair for the returned nonce, or how is the returned nonce framed?\u00a0 If it's implementation-specific, say so. The only currently specified authentication scheme for these commands appears to be DES-CBC-MAC, from Appendix C of  RFC 1305 .\u00a0 ( RFC 5905 suggests that existing implementations, however, use a different keyed-MD5 scheme that is similarly flawed.)\u00a0 As a CBC-MAC, this mechanism is subject to an extension attack, allowing an attacker to observe an existing valid packet and construct a forged packet with valid MAC by appending additional data at the end.\u00a0 This, therefore, fails to actually provide the key property of authentication.\u00a0 There are additional fundamental issues with the NTP authentication format (independently of the DES-CBC-MAC scheme), which may not quite rise to DISCUSS-level, and accordingly are listed in the COMMENT section.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 10:27:22-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-23 08:58:12-07:00",
    "text": "[updating version to which ballot position applies, since the -10 does not seem to have addressed the core topics.\u00a0 \u00a0 Furthermore, a 20- or 24-**bit** authenticator will have its own problems to cover, though 20- or 24-**byte** authenticators would be more reasonable.] There seems to be an internal inconsistency regarding the format of the data payload: at the start of Section 4 we see that \"When present, the data field contains a list of identifiers or assignments in the form <>[=<>],<>[=<>],...\u00a0 where <> is the ASCII name of a system or peer variable specified in  RFC 5905  and <> is expressed as a decimal, hexadecimal or string constant in the syntax of the C programming language\", but later on we see that the Read Status reply \"contains a list of binary-coded pairs <> <>, one for each currently defined association.\u00a0 The \"binary-coded\" (with, apparently, implicit length) seems at odds with the ASCII key/value assignment pairs. The description of the Configure(8) command as \"The command data is parsed and applied as if supplied in the daemon configuration file\" lacks any reference to what that format is or how one might know what format the peer expects.\u00a0 This does not seem sufficiently specified so as to admit interoperable implementation. The description of the Read MRU(10) command also seems underspecified. What name=value pairs affect the selection of records (and how)?\u00a0 Is there a particular name used with name=value pair for the returned nonce, or how is the returned nonce framed?\u00a0 If it's implementation-specific, say so. The only currently specified authentication scheme for these commands appears to be DES-CBC-MAC, from Appendix C of  RFC 1305 .\u00a0 ( RFC 5905 suggests that existing implementations, however, use a different keyed-MD5 scheme that is similarly flawed.)\u00a0 As a CBC-MAC, this mechanism is subject to an extension attack, allowing an attacker to observe an existing valid packet and construct a forged packet with valid MAC by appending additional data at the end.\u00a0 This, therefore, fails to actually provide the key property of authentication.\u00a0 There are additional fundamental issues with the NTP authentication format (independently of the DES-CBC-MAC scheme), which may not quite rise to DISCUSS-level, and accordingly are listed in the COMMENT section.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-22 10:27:22-07:00",
    "text": "[updating version to which ballot position applies, since the -11 does not seem to have addressed the core topics.\u00a0 \u00a0 Furthermore, a 20- or 24-**bit** authenticator will have its own problems to cover, though 20- or 24-**byte** authenticators would be more reasonable.] There seems to be an internal inconsistency regarding the format of the data payload: at the start of Section 4 we see that \"When present, the data field contains a list of identifiers or assignments in the form <>[=<>],<>[=<>],...\u00a0 where <> is the ASCII name of a system or peer variable specified in  RFC 5905  and <> is expressed as a decimal, hexadecimal or string constant in the syntax of the C programming language\", but later on we see that the Read Status reply \"contains a list of binary-coded pairs <> <>, one for each currently defined association.\u00a0 The \"binary-coded\" (with, apparently, implicit length) seems at odds with the ASCII key/value assignment pairs. The description of the Configure(8) command as \"The command data is parsed and applied as if supplied in the daemon configuration file\" lacks any reference to what that format is or how one might know what format the peer expects.\u00a0 This does not seem sufficiently specified so as to admit interoperable implementation. The description of the Read MRU(10) command also seems underspecified. What name=value pairs affect the selection of records (and how)?\u00a0 Is there a particular name used with name=value pair for the returned nonce, or how is the returned nonce framed?\u00a0 If it's implementation-specific, say so. The only currently specified authentication scheme for these commands appears to be DES-CBC-MAC, from Appendix C of  RFC 1305 .\u00a0 ( RFC 5905 suggests that existing implementations, however, use a different keyed-MD5 scheme that is similarly flawed.)\u00a0 As a CBC-MAC, this mechanism is subject to an extension attack, allowing an attacker to observe an existing valid packet and construct a forged packet with valid MAC by appending additional data at the end.\u00a0 This, therefore, fails to actually provide the key property of authentication.\u00a0 There are additional fundamental issues with the NTP authentication format (independently of the DES-CBC-MAC scheme), which may not quite rise to DISCUSS-level, and accordingly are listed in the COMMENT section.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-12-10 07:55:39-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 12:48:34-07:00",
    "text": "I find myself in agreement with Eric Vyncke's remarks about a document claiming to provide \"current but historic\" protocol details.\u00a0 Is this because NTPv3 is still in use?\u00a0 But the title talks about NTPv4.\u00a0 Shouldn't this document have \"Historic\" status?\u00a0 The shepherd writeup says that's the intent, but that's not what the document's title page says. Let's sort this out.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-04-09 02:00:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 05:29:55-07:00",
    "text": "Section 4.1:  \u00a0  The offerer and answerer MUST NOT include the max-retr or the max- \u00a0  time attribute parameters in the 'dcmap' attribute.  This is just an example of a issue that is exists in basically all of the  RFC 2119  terminolgy using sentences in this section. The formulation is that the offerer or answerer must do something with attributes or parameters of the dcmap attribute. However, it is not stated to be specific to the dcmap attribute that specifically specify something for a T.140 SCTP stream. I think that scope restriction needs to be made more explicit for these  RFC 2119  statements. Else they would have applicability as soon as one support this specification.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-04-09 09:26:00-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-04 18:02:27-07:00",
    "text": "I am confused as to the expected/allowed behavior regarding the cps attribute parameter. In  RFC 4103  Section 6 it says receivers MUST be able to handle temporary bursts over the cps rate but senders MUST stay below the rate. In section 5.3 it says senders \u201ccan\u201d (probably need a 2119 word here) buffer blocks to stay below cps. There is a 500ms limit so this has its limitations. Shouldn\u2019t the buffer time be unbounded if characters are coming in at a rate above cps? Meanwhile in section 4.2.1 it suggests that receivers use sendOnly or inactive (I presume these are the right direction values) to effectively flow control the incoming data. 4566bis seems to only envision this at the start of a channel. What is the impact of pending data if the directionality of the channel changes? How does this interact with the maximum buffer time? I suggest 4.2.1 be clearer on what actions a cps sender and receiver MAY/SHOULD/MUST take, and make sure there aren\u2019t contradictory requirements.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-12-01 02:53:50-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-12-01 02:52:49-08:00",
    "text": "s advised by the MIB doctors,\u00a0 draft-ietf-softwire-mesh-mib-04 (and draft-ietf-softwire-dslite-mib too btw) should be moved under mib-2?",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-12-17 01:47:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-12-01 02:53:50-08:00",
    "text": "s advised by the MIB doctors,\u00a0 draft-ietf-softwire-mesh-mib-04 (and draft-ietf-softwire-dslite-mib too btw) must be moved under mib-2",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-12-19 14:02:19-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-17 01:47:59-08:00",
    "text": "From the diff, I spotted that you imported smi-2. It should be mib-2 So basically, you haven't checked that your MIB module compiles :-( http://www.ibr.cs.tu-bs.de/bin/smitools.cgi Your request has been processed by the command timeout 10 smilint -s -e -l 6 mibs/SOFTWIRE-MESH-MIB 2>report.txt You can access any intermediately created files, the processing report (which might be empty if no errors or warnings have been found), and output files (in case of a conversion request) for reading and download from a temporary server directory for approx. 24 hours. While processing your request the following errors and/or warnings have been found: mibs/SOFTWIRE-MESH-MIB:4: [2] {import-failed} identifier `smi-2' cannot be imported from module `SNMPv2-SMI' mibs/SOFTWIRE-MESH-MIB:56: [2] {bad-identifier-case} `XXX' should start with a lower case letter mibs/SOFTWIRE-MESH-MIB:56: [2] {object-identifier-not-prefix} Object identifier element `XXX' name only allowed as first element mibs/SOFTWIRE-MESH-MIB:56: [1] {object-identifier-unknown} unknown object identifier label `mib-2' mibs/SOFTWIRE-MESH-MIB:19: [2] {module-identity-registration} illegal module identity registration mibs/SOFTWIRE-MESH-MIB:121: [5] {index-exceeds-too-large} warning: index of row `swmEncapsEntry' can exceed OID size limit by 136 subidentifier(s) mibs/SOFTWIRE-MESH-MIB:221: [5] {index-exceeds-too-large} warning: index of row `swmBGPNeighborEntry' can exceed OID size limit by 135 subidentifier(s)",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-04-05 07:23:58-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-04 16:23:49-07:00",
    "text": "Ignas balloted NoObj; I'll be the baddie. Section 6.\u00a0 Manageability Considerations says: --- Each document that introduces a new path setup type to PCEP must \u00a0  include a manageability section.\u00a0 The manageability section must \u00a0  explain how operators can manage PCEP with the new path setup type. \u00a0  It must address the following questions, which are generally \u00a0  applicable when working with multiple path setup types in PCEP. \u00a0  o\u00a0 What are the criteria for when devices will use the new path setup \u00a0 \u00a0 \u00a0 type in PCEP, and how can the operator control this? \u00a0  o\u00a0 How can the network be migrated to the new path setup type, and \u00a0 \u00a0 \u00a0 are there any backwards compatibility issues that operators need \u00a0 \u00a0 \u00a0 to be aware of? \u00a0  o\u00a0 Are paths set up using the new path setup type intended to coexist \u00a0 \u00a0 \u00a0 with other paths over the long term and, if so, how is this \u00a0 \u00a0 \u00a0 situation managed with PCEP? ---- So, I see lots of open questions, but no answers to any of these....",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-11-07 16:09:34-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-26 01:02:45-07:00",
    "text": "I have two discuss points, both much more of interest if this spec is implemented within an MUA, which is not the use-case that the authors are (very reasonably) mainly interested in handling. (1) This needs to say to never send client state (cookies etc.) esp for the case the client is an MUA. (2) The ability to cause the POST to match such a broad range of web forms seems wrong. Surely there's no need for that? Can't you limit the set of post data that are allowed to be emitted in some way to get rid of that aspect? I can't imagine such flexibility is really needed for just this.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-14 22:38:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-01 18:16:44-07:00",
    "text": "Perhaps the most minor thing that could be Discuss-level, and should be trivial to resolve, but: The \"i-e\" leaf in groupings prefix-ipv4-std and neighbor does not say whether boolean value true corresponds to internal or external.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-15 14:40:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-01 13:28:36-07:00",
    "text": "Section 7.\u00a0 A DISCUSS for discussion.\u00a0 Thanks for this enumeration of writeable and readable nodes which could be considered sensitive.\u00a0 Per the list of nodes that could expose the topology of the network, wouldn\u2019t the following also have sensitive topology information: -- /isis/local-rib -- /isis/hostnames Furthermore, shouldn\u2019t the log files also be protected as the errors or status posted there could also leak topology information: -- /isis/spf-log -- /isis/lsp-log",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-10-04 08:32:39-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-15 17:37:12-08:00",
    "text": "I support Stephen's DISCUSS. I'm also wondering, if all of these identifiers are already in common use in MIPv6 without a standard, if there is some privacy improvement that standardization could contribute (e.g., encrypting the identifiers, or requiring transport encryption, or limiting their transmission to the initial binding, or ... other ideas the community may come up with). The benefit of\u00a0 just standardizing the options as-is seems outweighed by the potential privacy risks as this spec is defined. I'm also confused about the identifier types that do not uniquely identify one node, since I thought that was the point of these options. How are they meant to be used in MIPv6? Would you have multiple mobile node identity options in a single packet that, together, uniquely identify a node? I think this requires some elaboration in the text.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-03-19 03:17:48-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-04 08:32:39-07:00",
    "text": "I have updated my DISCUSS position. Thanks for addressing my question about identifier types that do not uniquely identify one node. I previously supported Stephen's DISCUSS and I don't think the issues he raised have been addressed. The argument the document gives for standardizing options for privacy-sensitive identifiers is that it \"will avoid additional look-up steps.\" Why is this sufficient justification given the slippery slope that Stephen describes?\u00a0  In my previous ballot I was also wondering if all of these identifiers are already in common use in MIPv6 without a standard, if there is some privacy improvement that standardization could contribute. I see the new requirement for payload encryption, but nothing about, e.g., encrypting the identifiers, or limiting their transmission to the initial binding, or generating a different cryptographic identifier for each new network attachment. So the benefit of\u00a0 just standardizing the options as-is still seems outweighed by the potential privacy risks as this spec is defined.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-08-30 12:58:09-07:00",
    "end_reason": "position_updated",
    "start": "2017-02-15 19:47:24-08:00",
    "text": "The security considerations says some of these identifiers can carry sensitive information, and when they do you should encrypt. This leaves it to the reader to decide which might be sensitive. The draft should tell the reader which ones the working group thinks are sensitive, keeping in mind that if an identifier is sometimes sensitive, it usually needs to be treated as if always sensitive. (It's hard for deployed code to figure out when it is or isn't sensitive.)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-02-16 04:57:21-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-10 09:08:02-08:00",
    "text": "I would realy like to see the following changes in the security considerations section: OLD \"If used in the MNID extension as defined in this \u00a0  document, the packet including the MNID extension should be encrypted \u00a0  so that personal information or trackable identifiers would not be \u00a0  inadvertently disclosed to passive observers.\" NEW \"If used in the MNID extension as defined in this \u00a0  document, the packet including the MNID extension SHOULD be encrypted \u00a0  so that personal information or trackable identifiers would not be \u00a0  inadvertently disclosed to passive observers.\" Or even better make it a MUST? Is there a reason for only having a SHOULD? as well as the following change: OLD \"Moreover, MNIDs containing sensitive identifiers might only be used \u00a0  for signaling during initial network entry. \" NEW \"Moreover, MNIDs containing sensitive identifiers MUST only be used \u00a0  for signaling during initial network entry and MUST NOT be leaked to \u00a0  other networks.\"",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-31 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2017-02-15 17:27:02-08:00",
    "text": "I don't consider that merely mentioning that there are some privacy issues (maybe) is nearly sufficient here.\u00a0 Instead I would argue that any of these identifier types that could have privacy implications need to be specifically justified or else dropped. By specifically justified, I mean that there ought be an argument (and a fairly holistic one) that the Internet is better, and not worse, if we define a codepoint that allows MIPv6 (and later, other protocols) to use that identifier.\u00a0 I do accept that my position is perhaps innovative, in terms of IETF processes, so I'll split the discuss into two parts, one process oriented and mostly for the IESG, and the second relating to the content of the draft. (1) For the IESG: is it ok that we introduce (codepoints for) a slew of new long-term stable privacy-sensitive identifiers just because they might someday be needed, or do we need to have specific justification for defining such things? I would argue the latter, but that may need us to validate that there is IETF consensus for that somehow, and perhaps in the meantime hold on to this draft. Part of my reasoning is that once we define such codepoints (e.g. for IMSIs) then that inevitably means that other protocols, and not just MIPv6, will do the same eventually, so accepting this draft basically means accepting that we end up commonly and perhaps carelessly, passing such highly-sensitive information about on the Internet in many protocols and in many contexts.\u00a0 My argument here I think does adhere to various of our BCPs that do argue for security and privacy, but I do also accept that this may be novel and to some extent goes against another of our generally accepted ideas which is that we benefit from folks documenting things even if those things are sub-optimal in various ways. So I'd argue this is a real case for an IESG discussion - I know what I think, but what do the rest of you think? (2) For the authors: to the extent you are willing to, and want to get ahead of the discussion on point (1) above, can you in fact provide an argument, for each of the identifiers here that have privacy-sensitivity, that the Internet is better overall if we define these codepoints knowing that if we do define a way to represent e.g. an IMSI in MIPv6 that is likely to be copied elsewhere? Note for the authors: I think it's entirely fine for you to do nothing pending the discussion of point (1) above, if that's your preference.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-03-12 01:31:36-07:00",
    "end_reason": "position_updated",
    "start": "2018-12-05 07:23:52-08:00",
    "text": "I am balloting DISCUSS because I think that there are some technical and clarity issues that makes understanding, and potentially implementing this document hard.\u00a0 I also want to discuss the \"backwards compatibility\" and the use of TLVs as sub-TLVs in PCEP as introduced in this document. (1) MSD Definition.\u00a0 The MSD may be learned from a variety of sources, including the SR-PCE-CAPABILITY sub-TLV defined in this document.\u00a0 It is important then for the MSD to be defined consistently everywhere.\u00a0 Please use the BMI-MSD definition from  rfc8491 . (2) Ability to signal the MSD per link, not just per node.\u00a0 Clearly the calculation of paths through specific links (using an Adjacency SID, for example) would require that information (if different/lower from what the node may support). Note that \u00a76.1 seems to assume that the MSD will normally be advertised through different mechanisms, and it uses that to work around the fact that there's no link-specific information: \"Furthermore, whenever a PCE learns the MSD for a link via different means, it MUST use that value for that link regardless of the MSD value exchanged in the SR-PCE-CAPABILITY sub-TLV.\"\u00a0 However, the text doesn't mandate the IGP/BGP-LS information to be available to the PCE.\u00a0 IOW, as written, the specification can't guarantee the proper calculation of paths that require the PCE to consider link MSDs. (3) Extensibility to advertise other MSD-Types. [This point is not DISCUSS-worthy, but I'm including it here since I'm already talking about the MSD.] rfc8491  (aka  I-D.ietf-isis-segment-routing-msd ) and  I-D.ietf-ospf-segment-routing-msd  encode the MSD advertisement as a pair: MSD-Type and MSD-Value, with the expectation that \"new MSD-Types will be defined to signal additional capabilities, e.g., entropy labels, SIDs that can be imposed through recirculation, or SIDs associated with another data plane such as IPv6.\"\u00a0 IOW, the encoding is reusable with other dataplanes.\u00a0 I peeked into  draft-negi-pce-segment-routing-ipv6  [*] and i don't see anything in there that couldn't be signaled using the SR-PCE-CAPABILITY sub-TLV defined here (+ the MSD_Value).\u00a0 I think this is important for consistency. [*] I realize that  draft-negi-pce-segment-routing-ipv6  is not even a WG document, but it is the only potential reference I found to what a different dataplane might look line. (4) \u00a76.2.2 (Interpreting the SR-ERO): \u00a0 o\u00a0 If the subobjects contain NAI only, then the PCC first converts \u00a0 \u00a0  each NAI into a SID index value by looking it up in its local \u00a0 \u00a0  database, and then proceeds as above. I believe that this step in the interpretation of the SR-ERO is not properly specified. Which \"local database\" are you referring to?\u00a0 \u00a76.2.2.1 mentions the SR-DB (when talking about errors)...but the specification should be clear about which database and what the specific procedure is. For example, what is the specific process that the PCC needs to follow to convert a Node ID/IP address to the SID/MPLS label?\u00a0 What if the SR-DB doesn't contain an SID associated to the specific Node ID/IP address?\u00a0 How should the router react to that?\u00a0 This case is not covered in the Error Handling section (6.2.2.1) either. A pointer to the SR-DB (as defined in  I-D.ietf-spring-segment-routing-policy ) is not enough because it is composed of optional information (according to the description in \u00a73 (Segment Routing Database)).\u00a0 This document should be specific about what information must be contained in the SR-DB for the conversion to be successful. The requirement of the information to be contained in the SR-DB makes  I-D.ietf-spring-segment-routing-policy  a Normative reference. (5) \u00a77 (Backward Compatibility)\u00a0 \"Some implementations, which are compliant with an earlier version of this specification...\"  I understand that there may be implementations that are non-compliant with this specification out in the field.\u00a0 However, why is this document making accommodations for them?\u00a0 Not only are these implementations not compliant with this document, but are also non compliant with  rfc8408 , which implies the use of a new sub-TLV per PST. I didn't find a discussion on the mailing list related to this issue.\u00a0 Specifying alternate behavior to accommodate non-compliant implementations is not the best way to define new functionality.\u00a0 If the support for those old implementations was an imperative then the new functionality should have been fully specified to seamlessly interoperate with what is already deployed.\u00a0 The current result is two ways to do the same thing... While I would prefer for this \"backwards compatibility\" not to be built into the specification, I am looking for discussion in the WG and a better justification that the current one (which can be reduced to \"non-compliant implementations exist, so we need to fit them in here somehow\"). (6) sub-TLV Space for the PATH-SETUP-TYPE-CAPABILITY TLV rfc8408  failed to set up a sub-TLV registry for the PATH-SETUP-TYPE-CAPABILITY TLV.\u00a0 The bigger issue is that it also doesn't say that other PCE TLVs can be used as sub-TLVs (nor does it prohibit that).\u00a0 The Type for the SR-PCE-CAPABILITY sub-TLV is allocated from the PCEP TLV Type Indicators registry, making it a TLV.\u00a0 I also couldn't find any mention of sub-TLVs in  rfc5440 , or the potential intent to have a single space from which both TLVs and sub-TLVs could come. The question is: are all TLVs (defined in the PCEP TLV Type Indicators registry) able to be used as sub-TLVs?\u00a0 This question is general, but also specific to the PATH-SETUP-TYPE-CAPABILITY TLV.\u00a0 At a minimum, it should be made clear which can be used with the PATH-SETUP-TYPE-CAPABILITY TLV -- because this is the first document to define a new PST and sub-TLV, it seems appropriate to Update  rfc8408  here...but  rfc5440  may also need an Update.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-02 09:25:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 19:19:44-08:00",
    "text": "Thanks to Wes for his SECDIR review:  https://datatracker.ietf.org/doc/review-ietf-jmap-quotas-07-secdir-lc-hardaker-2022-11-17/ Some of his feedback seems to have already made it into the latest version of the document. I feel the types of quota limits has an interoperability issue ? There are three limits: limit, warnLimit and softLimit. First, it would make sense to rename the confusingly named \"limit\" to hardLimit. I was puzzled about warnLimit not being the same as softLimit. What other things does softLimit do than warn the user? Well, that is explained below this and turns out to be \"whatever the mailserver wants this to be\". This is not good for user expectations, unless they would get a detailed description along with the warning what things will get blocked at the softLimit level, as there is no longer a universal concept of what would happen at the softLimit level. The examples in the document do not seem to use the description field for this required user feedback. So when I get a warning from softLimit from Hotmail, this could cause different limitations from when I get a warning from Gmail. But as far as I can tell, the warning appears identical if the softLimit is hit? Or did I miss where custom text can be given to the enduser for such triggers?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-02-27 11:39:52-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 13:01:52-08:00",
    "text": "olding a DISCUSS pending the outcome of the discussion stemming from the DE's review. See https://www.ietf.org/mail-archive/web/clue/current/msg05066.html",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-01-19 07:08:00-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 12:47:55-08:00",
    "text": "I plan to ballot \"yes\" for this, but there's an issue in section 9 that I think needs to be fixed first: In the second paragraph, the draft says \"CLUE endpoints MUST support RTP/ SAVPF and DTLS-SRTP keying [ RFC5764 ].\" But the framework draft goes further by saying that media MUST be secured, and that DTLS-SRTP SHOULD be used unless the media is secured by some other mechanism. I think that readers will expect the mapping spec to be authoritative about that sort of thing. It's likely to be misleading to have it mention the requirement to support RTP/SAVPF and DTLS-SRTP without also mentioning the MUST be secured, SHOULD be used requirements. This can easily be fixed by mentioning the additional requirements and citing the framework.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-11-12 16:21:36-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-20 10:27:15-07:00",
    "text": "There's a couple points (describe further in the comment section) that I'd like to get a bit more clarity on: (1) the semantics of admin-group hex strings of length smaller than 11 (2) the units for the te-bandwidth numerical values (and in what cases no units are needed), and for performance-metrics-*-way-bandwidth values (3) whether threshold-accelerated-advertisement's use of relative vs. absolute values requires any special handling (4) whether we want to specify any requirements/error-handling/etc. when there is potential for \"nonsense\" configuration, such as a max-constraint being configured as numerically smaller than a min-constraint (5) what the \"variation\" in the te-packet-types module's leafs is intending to measure.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-11-17 17:51:13-08:00",
    "end_reason": "position_updated",
    "start": "2019-11-12 16:21:36-08:00",
    "text": "Thank you for the updates in the -12; they're some good improvements! I think I am still looking for a little more clarity on one point, though it can probably be addressed with an RFC-Editor note: (1) the semantics of admin-group hex strings of length smaller than 11 In the -12 we now have: \u00a0 typedef admin-group { \u00a0 \u00a0 type yang:hex-string { \u00a0 \u00a0 \u00a0 /* 01:02:03:04 */ \u00a0 \u00a0 \u00a0 length \"1..11\"; \u00a0 \u00a0 } \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \"Administrative group/Resource class/Color representation in \u00a0 \u00a0 \u00a0  hex-string type. \u00a0 \u00a0 \u00a0  The Most Significant Byte (MSB) is the farthest to the \u00a0 \u00a0 \u00a0  left in the byte sequence.\"; \u00a0 \u00a0 reference \"RFC3630 and  RFC5305 \"; \u00a0 } This description still feels potentially ambiguous as to how to interpret a byte sequence with fewer than four bytes -- does \"MSB\" mean \"MSB of the input string\" or \"MSB of the full-width value\"? I suggest adding\u00a0 \"Leading zero bytes in the configured value may be omitted for brevity.\" (but anything with similar clarifying value would be fine).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2017-12-18 16:55:45-08:00",
    "end_reason": "position_updated",
    "start": "2017-12-13 19:27:39-08:00",
    "text": "Why is this document not in the Standards Track?\u00a0 I ask because I think that the definition of a well-known community (one which has \"global significance and their operations shall be implemented in any community-attribute-aware BGP speaker\" [ rfc1997 ], in other words, everywhere!) should result in a Standards Track specification, and not in an Informational document.\u00a0 I couldn't find any specific justification for the status in the writeups (Shepherd or Ballot), nor a related discussion in the archive. To resolve this DISCUSS, I would prefer to see a change in the status, but will yield to WG consensus (so a pointer to that discussion would be enough).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-10-08 07:54:16-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 11:21:18-07:00",
    "text": "Thank you for the work on this document. Many thanks to Harald Alvestrand for the ART ART review:  https://datatracker.ietf.org/doc/review-ietf-regext-epp-registry-maintenance-17-artart-lc-alvestrand-2021-09-13/ . I agree with his comments, and thank you to the authors for working with him to fix those points. I will hold a DISCUSS until the update answering the two first comments about \"weak definitions\", the \"formatting issues\" comment, and the date-format comment is published. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-09 17:18:27-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 23:30:01-07:00",
    "text": "It's possible that I just misunderstand what is required to go where, but for several (possibly only CSV?) elements, the body text claims that \"[t]he attribute \"isRequired\" MUST equal \"true\".\" but the corresponding examples do not consistently list the \"isRequired\" attribute. (Sometimes they do, but not always.)\u00a0 Shouldn't the examples be consistent with the protocol requirements?\u00a0 I note some examples in my COMMENT section but this should not be treated as an exhaustive list. A similar property (again, if I understand correctly) holds for the \"parent\" attribute of various elements (which is definitely only a thing for the CSV objects).. The claim in the IANA Considerations regarding \"URI assignments have been registered by the IANA\", accompanied by specific URN namespace/schema values, is codepoint squatting, in the absence of a disclaimer about being \"requested values\".\u00a0 The registration policy is only Specification Required, so there is no formal guarantee that we can actually get these values. At least one of the examples shows RSA/MD5 DNSSEC key records.\u00a0 RSA/MD5 usage is specifically disallowed (see  RFC 6944  and  RFC 8624 ); please replace with a more modern algorithm.\u00a0 (One location noted in the COMMENT, along with some SHA-1 usage that should probably go as well.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-04-27 05:15:39-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-25 08:53:08-07:00",
    "text": "** Section 1.2. \u00a0  When both vulnerability and software inventory \u00a0  information is available from the same location, both sbom and vuln \u00a0  nodes MUST indicate that. What are \u201csbom and vuln nodes\u201d?\u00a0 Those names don\u2019t map to YANG model described in Section 3.\u00a0 Is this \u201csbom-url\u201d and \u201cvuln-url\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-02-12 05:33:01-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-18 12:23:19-08:00",
    "text": "FC 2119 and RFC 8174 need to be normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-17 17:27:30-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-19 17:54:18-08:00",
    "text": "I see that Ben has already asked about the SHOULDs (vs. MUSTS) for secure key exchange and prevention from disclosure, in Section 4.1, but I will make that a Discuss point.\u00a0 If these are to remain SHOULD, we should say  something about in what case(s) MUST would not be appropriate. I'm also concerned that there is too much intermingling of general BCP-worthy advice with implementation-specific knowledge for publication as BCP in the current form.\u00a0 I've tried to note instances of this in the comment section, but for example this includes talking about the \"key file\" and the format of the configuration file.\u00a0 In a similar vein, it's unclear that the guidance in Appendix A will age well, at least without a more explicit disclaimer (including disclaimer of normativity) -- e.g,. are the -4 and -6 modifiers to restrict still needed or best practice?\u00a0 IIRC a recent update on my FreeBSD machine updated ntp.conf to just use basic restrict stanzas without an IP version. I'm also surprised to see no discussion of the (non-)applicability of IPsec for NTP traffic, when authenticity or access control is required.\u00a0 (E.g., where IP acls are discussed in Section 5.1)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-12-19 17:49:08-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3844 I notice that a number of the recommendations here differ from those in NDSS16. In particular the following recommendations from that paper do not seem to appear: - Do not put INIT in the reference ID on restart - Do not send KoD - Disable fragmentation - Randomize source ports I'm not saying that all of these recommendations need to be in this document, but I am curious why they are not and would tend to think that one should document why they are not. DETAIL S 2.1. >\u00a0 \u00a0 \u00a0 response to a small query, which makes it more attractive as a vector >\u00a0 \u00a0 \u00a0 for distributed denial-of-service attacks.\u00a0 (NTP Control messages are >\u00a0 \u00a0 \u00a0 discussed further in Section 3.4).\u00a0 One documented instance of such >\u00a0 \u00a0 \u00a0 an attack can be found here [1], and further discussion in [IMC14] >\u00a0 \u00a0 \u00a0 and [NDSS14].\u00a0 Mitigating source address spoofing attacks should be a >\u00a0 \u00a0 \u00a0 priority of anyone administering NTP. what does this text mean? What practices can I engage in as an NTP server that mitigate source spoofing attacks? The next paragraph seems to largely talk about traffic *sources*. Is the assumption that the NTP server is supposed to do  BCP 38  filtering? That seems not that effective. As a smaller point, I see that this text says \"should\", not SHOULD. Is that a mistake or is this intended not to have any normative force? S 3.2. >\u00a0 \u00a0 \u00a0 [ RFC5905 ].\u00a0 It is RECOMMENDED that that NTP users select an >\u00a0 \u00a0 \u00a0 implementation that is actively maintained.\u00a0 Users should keep up to >\u00a0 \u00a0 \u00a0 date on any known attacks on their selected implementation, and >\u00a0 \u00a0 \u00a0 deploy updates containing security fixes as soon as practical. >\u00a0   >\u00a0  3.2.\u00a0 Use enough time sources I note that you don't seem to be recommending that people use Chronos ( http://wp.internetsociety.org/ndss/wp- content/uploads/sites/25/2018/02/ndss2018_02A-2_Deutsch_paper.pdf), which, as I understand it, is compatible with existing NTP servers but far more resistant to spoofing. Is there a reason why? Assuming that there is a good reason, that seems like it should be covered here. S 3.2. >\u00a0 \u00a0 \u00a0 See Section 3.7.1 for more information. >\u00a0   >\u00a0 \u00a0 \u00a0 Operators SHOULD monitor all of the time sources that are in use.\u00a0 If >\u00a0 \u00a0 \u00a0 time sources do not generally agree, find out the cause and either >\u00a0 \u00a0 \u00a0 correct the problems or stop using defective servers.\u00a0 See >\u00a0 \u00a0 \u00a0 Section 3.5 for more information. It's not really possible to evaluate this advice without any description of the threat model, which is pretty sketchily covered below. In particular, if an attacker controls my network, then it's basically like having one NTP server, no matter how many people I am talking to, and even an inaccurate but secure server (e.g., tlsdate) is superior. S 11.3. >\u00a0 \u00a0 \u00a0 [10]  https://support.ntp.org/bin/view/Support/ConfiguringNTP >\u00a0   >\u00a0  Appendix A.\u00a0 NTP Implementation by the Network Time Foundation >\u00a0   >\u00a0 \u00a0 \u00a0 The Network Time Foundation (NTF) provides the reference >\u00a0 \u00a0 \u00a0 implementation of NTP, well-known under the name \"ntpd\".\u00a0 It is What makes this the reference implementation? Generally, the IETF does not bless specific implementations as reference implementations unless they themselves appear in the RFC (as with Opus).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-09-09 05:13:49-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-29 17:06:34-07:00",
    "text": "I have concerns about the interoperability of this mechanism as defined. Section 6 indicates that GMs may introduce ack jitter of \"a few seconds,\" and that the GCKS should wait \"several seconds\" for receipt. These are both very subjective terms, and it would be perfectly reasonable for a GM implementor to decide that \"a few seconds\" is up to, say 10; while a GCKS implementor might reasonably think that \"several seconds\" is as short as, say, five. The result is two compliant implementations that don't actually interop under most circumstances. Please define a hard maximum amount of jitter that GMs can be expected to introduce \"e.g., several seconds, but no more than five\"), and advise that the GCKS wait a specific slightly longer amount (e.g., six seconds, which is five plus more than enough to accommodate a reasonable RTT).",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-02-23 16:34:15-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 15:40:30-08:00",
    "text": "This is probably just my own ignorance, but I see two potential problems in Sec 4.1. - 'The identity of \"ipskx\" as sent on the wire is ImportedIdentity, i.e., the serialized content of ImportedIdentity is used as the\u00a0 content of PskIdentity.identity in the PSK extension.' IIUC ImportedIdentity has a maximum length of 2^17 + 2. But the Identity field in the PSK option has a maximum length of 2^16-1. I presume this never actually happens, but the spec should handle the boundary condition, perhaps by limiting the first two fields of Imported Identity to sum to 2^16-5 bytes or something. - It says 'Endpoints SHOULD generate a compatible \"ipskx\" for each target ciphersuite they offer.' but then the example shows two ciphers that equire only one derived key. Do you mean \"hash algorithm\" instead of \"ciphersuite\"? TLS_AES_128_GCM_SHA256 and TLS_CHACHA20_POLY1305_SHA256 are different ciphersuites according to  RFC 8446 .",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-07 06:08:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-06 04:10:44-08:00",
    "text": "Preliminary DISCUSS, I am likely to Defer the document, as I have more detailed comments. Routing decisions, discovery of endpoints to contact for forwarding and retry strategies are listed as out-of-scope for this document. This is not sufficient for writing an interoperable implementation, unless there is a separate document that provides such details.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-10 03:57:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-07 06:08:06-08:00",
    "text": "I am looking forward for this document to be finished and approved as an RFC. Before I can recommend this, I have several DISCUSS points and comments that I would like to address: 1) Routing decisions, discovery of endpoints to contact for forwarding and retry strategies are listed as out-of-scope for this document. This is not sufficient for writing an interoperable implementation, unless there is a separate document that provides such details. Below I describe 3 relevant places in the text and suggest some possible ways of addressing my DISCUSS: 5.4. Bundle Forwarding \u00a0  Step 2: The bundle protocol agent MUST determine whether or not \u00a0  forwarding is contraindicated (that is, rendered inadvisable) for \u00a0  any of the reasons listed in Figure 4. In particular: \u00a0 \u00a0  . The bundle protocol agent MAY choose either to forward the \u00a0 \u00a0 \u00a0 \u00a0 bundle directly to its destination node(s) (if possible) or to \u00a0 \u00a0 \u00a0 \u00a0 forward the bundle to some other node(s) for further \u00a0 \u00a0 \u00a0 \u00a0 forwarding. The manner in which this decision is made may \u00a0 \u00a0 \u00a0 \u00a0 depend on the scheme name in the destination endpoint ID and/or Lack of this information (how node to forward to are discovered) would prevent interoperability. (By comparison, SMTP specification which has somewhat similar design contains information about how next nodes to forward to are selected.) I think you need to create a new section in this document specifying requirements on URI scheme documents and include this as a MUST level requirement there. (If you already have a document that does this, you can just normatively point to it.) \u00a0 \u00a0 \u00a0 \u00a0 on other state but in any case is beyond the scope of this \u00a0 \u00a0 \u00a0 \u00a0 document. If the BPA elects to forward the bundle to some other \u00a0 \u00a0 \u00a0 \u00a0 node(s) for further forwarding but finds it impossible to \u00a0 \u00a0 \u00a0 \u00a0 select any node(s) to forward the bundle to, then forwarding is \u00a0 \u00a0 \u00a0 \u00a0 contraindicated. \u00a0 \u00a0  . Provided the bundle protocol agent succeeded in selecting the \u00a0 \u00a0 \u00a0 \u00a0 node(s) to forward the bundle to, the bundle protocol agent \u00a0 \u00a0 \u00a0 \u00a0 MUST subsequently select the convergence layer adapter(s) whose \u00a0 \u00a0 \u00a0 \u00a0 services will enable the node to send the bundle to those \u00a0 \u00a0 \u00a0 \u00a0 nodes.\u00a0 The manner in which specific appropriate convergence \u00a0 \u00a0 \u00a0 \u00a0 layer adapters are selected is beyond the scope of this \u00a0 \u00a0 \u00a0 \u00a0 document. Similar to the above: lack of description of how convergence layers are discovered (for example this might include discovery using DNS or something else) or, alternatively, a mandatory to implement convergence layer would affect interoperability. I think you need to add this as a requirement to section 7 (\"Services Required of the Convergence Layer\"). Also having some (even non normative) information about which convergence layer to select if multiple are available would be useful. \u00a0 \u00a0 \u00a0 \u00a0 If the agent finds it impossible to select any \u00a0 \u00a0 \u00a0 \u00a0 appropriate convergence layer adapter(s) to use in forwarding \u00a0 \u00a0 \u00a0 \u00a0 this bundle, then forwarding is contraindicated. \u00a0  Step 5: When all selected convergence layer adapters have informed \u00a0  the bundle protocol agent that they have concluded their data \u00a0  sending procedures with regard to this bundle, processing may depend \u00a0  on the results of those procedures.\u00a0 If completion of the data \u00a0  sending procedures by all selected convergence layer adapters has \u00a0  not resulted in successful forwarding of the bundle (an \u00a0  implementation-specific determination that is beyond the scope of \u00a0  this specification), then the bundle protocol agent MAY choose (in \u00a0  an implementation-specific manner, again beyond the scope of this \u00a0  specification) to initiate another attempt to forward the bundle. Similar to the above: retries affect interoperability and should be documented as description of a convergence layer document. I think you need to add this as a requirement to section 7 (\"Services Required of the Convergence Layer\"). \u00a0  In that event, processing proceeds from Step 4 of Section 5.4. 2) As pointed out by Benjamin Schwartz: In Section 5.4.2 Consistency: This section relies on the presence of a Previous Node block, but nothing in the forwarding procedure instructs any agent to add a Previous Node block. Correctness: If two nodes both opt to return failed bundles, how are they to avoid a ping-pong loop? 3) As pointed out by Benjamin Schwartz: In Section 5.6 Error handling: What about CBOR parsing failures?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-20 03:29:34-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-10 03:57:49-08:00",
    "text": "I am looking forward for this document to be finished and approved as an RFC. Before I can recommend this, I have several DISCUSS points and comments that I would like to address: 1) Retry strategies are listed as out-of-scope for this document. This is not sufficient for writing an interoperable implementation, unless there is a separate document that provides such details. Below I describe 1 remaining relevant place in the text and suggest some possible ways of addressing my DISCUSS: \u00a0  Step 5: When all selected convergence layer adapters have informed \u00a0  the bundle protocol agent that they have concluded their data \u00a0  sending procedures with regard to this bundle, processing may depend \u00a0  on the results of those procedures.\u00a0 If completion of the data \u00a0  sending procedures by all selected convergence layer adapters has \u00a0  not resulted in successful forwarding of the bundle (an \u00a0  implementation-specific determination that is beyond the scope of \u00a0  this specification), then the bundle protocol agent MAY choose (in \u00a0  an implementation-specific manner, again beyond the scope of this \u00a0  specification) to initiate another attempt to forward the bundle. Similar to the above: retries affect interoperability and should be documented as description of a convergence layer document. I think you need to add this as a requirement to section 7 (\"Services Required of the Convergence Layer\"). \u00a0  In that event, processing proceeds from Step 4 of Section 5.4. [Two other cases were addressed in -23] 2) [Addressed in -23] 3) [Addressed in -23]",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-11-30 10:38:23-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-06 03:04:13-08:00",
    "text": "\u00a710.3/\u00a710.4: \u00a0  The registration policy for this namespace is changed to \"Standards \u00a0  Action\". Given the limited number of bits available, the allocation \u00a0  should only be granted for a standards-track RFC approved by the \u00a0  IESG. The original BP work ( rfc5050 ) is a product of the IRTF.\u00a0 The new registration policy blocks the ability for anyone outside the IETF to register new values.\u00a0 I understand the need to conserve resources, and the intent to Obsolete  rfc5050  in a separate document, which should mean that future work on the BP is done in the IETF.\u00a0 That process hasn't been done yet. I am balloting DISCUSS on this point of the process so that the needed steps can catch up and the group of documents can progress together. [Note that changing the registration policy to allow work from outside the IETF to use the registries would also lead me to clear this DISCUSS.\u00a0 However, I don't think that is necessary.]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-23 18:23:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-05 19:17:07-08:00",
    "text": "I support Roman's Discuss. (1) It's not clear to me that we should be defining new (near-)application-layer protocols on the standards track without mandatory security mechanisms.\u00a0 Even  draft-ietf-dtn-bpsec  defines a \"BPSec threat model\" that is largly the same as the  RFC 3552  threat model, in which the network is completely untrusted and to provide end-to-end communications we must supply additional security mechanisms, yet BPSec is not required to implement or use.\u00a0 I could perhaps see room for allowing waypoint nodes that do not act as endpoints to remain security-unaware, but the justification for security-unaware endpoints seems quite lacking. (2) The state machine for transitions between singleton EID and non-singleton EID seems highly unclear to be usable in a globally synchronized manner (I refer specifically to the text in Section 4.1.5.2: \"A node's membership in a given singleton endpoint MUST be sustained at least until the nominal operation of the Bundle Protocol no longer depends on the identification of that node using that endpoint's ID\").\u00a0 Distinction between singleton-EID and non-singleton EID may need to be made an explicit protocol element. (3) The forwarding procedure in Section 5.4 refers to a \"data label extension block (to be defined in a future document)\" with no reference; it doesn't really seem like this sort of speculative forward-looking statement is appropriate in a Proposed Standard. (4) We discuss using a Previous Node block to \"return a bundle to sender\" when forwarding failed, but do not discuss whether Previous Node should be added (or updated or removed) on transmission, receipt, or both. (5) The extensibility story seems incompletely described: what should an implementation do upon receiving a bundle with an unrecognized control flag bit set, or a block with an unrecognized control flag set? (6) The use of absolute times for creation timestamps suggests a strong dependence on accurate time (for nodes that do not acknowledge their lack of an accurate clock); the consequences of the failure of accurate time should be discussed in the security considerations section. (7) Section 4.1.6 should make a statement regarding whether leap seconds are included or excluded from the count of seconds since the DTN epoch. (8) The definition of Fragment offset needs to specify whether the lowest allowed byte index is zero or 1 (I believe zero, from other discussion). (9) Bundle status reports are only defined to include the creation timestamp of the bundle whose status is being reported on, but not the sequence number thereof.\u00a0 Since we allow nodes without accurate clocks to use a creation timestamp of zero and rely solely on the sequence number to identify bundles, it seems that the status reports for such bundles are effectively useless without the sequence number information. (10) Please resolve the internal inconsistency in Section 10.6 that simultaneously claims that potential bundle protocol URI scheme types are integers of undefined length and only have 255 available codepoints (i.e., definite length).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-30 14:08:31-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-23 18:23:33-07:00",
    "text": "[Retaining (1) as placeholder for ongoing discussions; (11) is new] (1) It's not clear to me that we should be defining new (near-)application-layer protocols on the standards track without mandatory security mechanisms.\u00a0 Even  draft-ietf-dtn-bpsec  defines a \"BPSec threat model\" that is largly the same as the  RFC 3552  threat model, in which the network is completely untrusted and to provide end-to-end communications we must supply additional security mechanisms, yet BPSec is not required to implement or use.\u00a0 I could perhaps see room for allowing waypoint nodes that do not act as endpoints to remain security-unaware, but the justification for security-unaware endpoints seems quite lacking. (11) The ABNF for the \"dtn\" URI scheme does not seem to allow for a URI of \"dtn:none\".\u00a0 We may need to consult the ART ADs to determine how problematic this is, as this is a bit outside my area of expertise.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-04 06:49:15-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-06 07:20:16-08:00",
    "text": "olding discuss to ensure IANA is satisfied.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-29 05:34:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 06:49:15-08:00",
    "text": "Holding discuss to ensure IANA is satisfied. Taking over Mirja's discuss. There need to be a requirement on all convergence layers to provide congestion control or some other type of rate control.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-10-30 10:13:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-29 05:34:43-07:00",
    "text": "olding discuss to ensure IANA is satisfied, which they are pending 2 minor editorial fixes.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-02-03 03:08:33-08:00",
    "text": "I looked up  RFC 4838  and there is a section on congestion control, however it only says: \"Congestion control is an ongoing research topic.\" Unfortunately this document also doesn't give any further advise about congestion control but as a PS it really should. I understand that the bundle protocol is basically an application layer protocol on top of a transport that should care about congestion control, however, the document doesn't talk much about anything related to that underlying protocol. It would be important to specify requirements for the underlying transport protocol, indicating that is must be congestion controlled or rate limited (see  RFC8085  as a reference for rate limiting of (uni-direction) UDP-based protocols). Further this sentence in Sec 5.1 needs more clarification: \u201cFor this reason, the generation of status reports MUST be \u00a0  disabled by default and enabled only when the risk of excessive \u00a0  network traffic is deemed acceptable.\u201d It is not clear when it makes sense to enable and if enables one should probably also implement some filtering and rate limiting.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-24 11:17:50-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 17:00:40-08:00",
    "text": "** Section 4.1.5.1. Can the permissible schemes for the Endpoint ID URL be clarified. Initially the text says: The scheme identified by the < scheme name > in an endpoint ID is a \u00a0  set of syntactic and semantic rules that fully explain how to parse \u00a0  and interpret the SSP. The set of allowable schemes is effectively \u00a0  unlimited. Any scheme conforming to [URIREG] may be used in a bundle \u00a0  protocol endpoint ID. [URIREG] would suggest that any schema in IANA \"Uniform Resource Identifier (URI) Schemes\" Registry\u2019 is valid.\u00a0 However, later, the text says: The first item of the array SHALL be the code number identifying the \u00a0  endpoint's URI scheme [URI], as defined in the registry of URI \u00a0  scheme code numbers for Bundle Protocol maintained by IANA as \u00a0  described in Section 10. [URIREG]. This text suggests that the new Bundle Protocol URI Scheme Type registry should govern the EID schemes.\u00a0 However, then the text again cites URIREG.\u00a0 Perhaps the intent is that URI's valid per [URIREG] would be registered in the new bundle protocol registry and values in this new registry would be used.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-11-09 20:48:00-08:00",
    "end_reason": "position_updated",
    "start": "2017-10-10 17:48:00-07:00",
    "text": "draft-ietf-teas-gmpls-scsi  creates an IANA table \"Generalized SCSI (Switching Capability Specific Information) TLVs Types\" with a registration policy of \"Specification Required.\" This document adds a value to this registry, and goes on to claim: \u00a0  The registration procedure for this registry is Standards Action as  \u00a0  defined in [ RFC8126 ].  \"Standards Action\" is not the same as \"Specification Required.\" Since *this* document is not defining the registry, it should not reiterate the policy -- in particular because the policy can get out of sync if specified in multiple locations, as in this case.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-10-31 07:23:16-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 08:24:19-07:00",
    "text": "I appreciate the new text in Section 2.7, but I'm still a little unclear on the ABNF that is specified. As far as I can tell the relevant line from the original ABNF in  RFC 3261  is: \u00a0 \u00a0  algorithm\u00a0 \u00a0 \u00a0 \u00a0 =\u00a0 \"algorithm\" EQUAL ( \"MD5\" / \"MD5-sess\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / token ) And what it is being replaced with is: \u00a0  algorithm = \"algorithm\" EQUAL ( \"MD5\" / \"SHA-512-256\" / \"SHA-256\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / token ) \u00a0  Each one of these algorithms might have a \"-sess\" variant, e.g., \u00a0  MD5-sess, SHA-256-sess, etc, as defined in [ RFC7616 ] But the point of ABNF is to formally specify the syntax, so just having the note after the definition that says there might be -sess variants leaves it unclear whether those -sess variants are expected in the \"algorithm=\" line. And if it is valid for them to appear, they need to be formally included in the ABNF line, I think.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-05-08 12:21:37-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 17:01:26-07:00",
    "text": "Thanks for everyone's work on this document. \u00a73.1: >\u00a0 \u00a0  Availability (4 octets): a 32-bit floating point number describes  >\u00a0 \u00a0  the decimal value of availability requirement for this bandwidth  >\u00a0 \u00a0  request. The value MUST be less than 1and is usually expressed in  >\u00a0 \u00a0  the value of 0.99/0.999/0.9999/0.99999.  \"32-bit floating point number\" is not sufficiently precise to specify the encoding of this field. Presumably, this is intended to use IEEE 754-2008 32-bit binary interchange format. Please specify this, and add a normative citation for IEEE 754-2008.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-02 17:58:18-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-09 10:37:33-07:00",
    "text": "As the genart review notes, when Section 3.2 says: \u00a0  When a node does not support the Availability TLV, the node SHOULD \u00a0  generate a PathErr message with the error code \"Extended Class-Type \u00a0  Error\" and the error value \"Class-Type mismatch\" (see [ RFC2205 ]). is attempting to place a normative requirement on implementations that do not implement this specification, which cannot possibly work. The appropriate thing to do here is to say something like \"as described in Section Y of [RFC XXXX], a node that does not support the Availability TLV will [behave in this fashion]\", with no normative language.\u00a0 (Also, the  RFC 2205  reference is not very helpful to me; as far as I can tell it is just providing information about how to encode a PathErr but does not tell me anything about the specific error code and value indicated.) I'll also hold a placeholder discuss point to wait for the [IEEE754] reference for the floating-point format.\u00a0 (I think that format is not a great fit for this application, for many of the reasons that Magnus notes, but  RFC 8330  has kind of forced us into keeping it.)",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-04-30 02:10:17-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-08 03:13:24-07:00",
    "text": "Section 3.1: \u00a0 \u00a0 \u00a0 Availability (4 octets): a 32-bit floating point number describes  \u00a0 \u00a0 \u00a0 the decimal value of availability requirement for this bandwidth  \u00a0 \u00a0 \u00a0 request. The value MUST be less than 1and is usually expressed in  \u00a0 \u00a0 \u00a0 the value of 0.99/0.999/0.9999/0.99999.  It appears that this format has some very clear limitations when it comes to store availability numbers. Assuming that this 32-bit float is an IEEE-754 representation which should be explicitly stated.  In that case representing availabilities higher than 0.999999 starts to introduce significant errors in relation to intended precision. Intended value Error\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Actual value 0.999999\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 -1.3278961181640625E-8\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0.999998986721038818359375 0.9999999\u00a0 \u00a0 \u00a0 \u00a0 -1.920928955078125E-8\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0.99999988079071044921875 0.99999999\u00a0 \u00a0 \u00a0 1E-8\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1 (Which is not allowed) So at a minimal the limitations for what is practical to express needs to be provided. Secondly, are this range sufficient in all cases?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-05-10 09:31:36-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-24 16:20:57-07:00",
    "text": "I have a few important items I believe needs fixing, but I believe those are still fairly easy to address. #1 payload format of ENCDNS_DIGEST_INFO I believe the proposed syntax for ENCDNS_DIGEST_INFO in this document should not be specified this way. Depending on the use of this payload, it has a different field construction. That is, we have two different kinds of ENCDNS_DIGEST_INFO, which would make defining this field (eg in C headers or in a class object) impossible without splitting it into two different names and definitions. Either all the fields must be identical, with optional 0 lengths field omitted, or the draft should define ENCDNS_DIGEST_INFO_REQUEST and ENCDNS_DIGEST_INFO_RESPONSE with their different field types. This can be further seen by the difficulty to read the examples in the appendici with the ENCDNS_DIGEST_INFO() syntax. If one ENCDNS_DIGEST_INFO type is used, I think the syntax for both request and response should be:  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-----------------------------+-------------------------------+ |R|\u00a0 \u00a0 \u00a0 \u00a0  Attribute Type\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Length\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | +-+-----------------------------+---------------+---------------+ | Num Hash Algs |\u00a0 ADN Length\u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | +---------------+---------------+\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  + ~\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Authentication Domain Name\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ~ +-------------------------------+-------------------------------+ | Digest Hash Alg Identifier\u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ~ +-------------------------------+\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  + ~\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Certificate Digest\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ~ +-------------------------------+-------------------------------+ (eg as the current \"response\" version) And Num Hash Algs, ADN Length and Digest Hash Alg Identifier are mandatory fields in both the request and the response. I would also always list these 3 fields in the presentation format of ENCDNS_DIGEST_INFO() as used in the appendici examples. I would rename \"Hash Alg Identifier\" to \"Digest Hash Alg Identifier\" to make it more obvious that is what the hash algorithm is for. #2 Updates  RFC 8598 \u00a0 \u00a0 \u00a0 \u00a0 Note: [ RFC8598 ] requires INTERNAL_IP6_DNS (or INTERNAL_IP4_DNS) \u00a0 \u00a0 \u00a0 \u00a0 attribute to be mandatory present when INTERNAL_DNS_DOMAIN is \u00a0 \u00a0 \u00a0 \u00a0 included. This specification relaxes that constraint This clearly updates  RFC8598 , but the document is lacking an Update: clause. Please add the Update clause and mention the update in the abstract/introduction. #3 Security Considerations \u00a0 \u00a0 \u00a0 \u00a0 The initiator may trust the encrypted DNS resolvers supplied by \u00a0 \u00a0 \u00a0 \u00a0 means of IKEv2 from a trusted responder more than the locally \u00a0 \u00a0 \u00a0 \u00a0 provided DNS resolvers, especially in the case of connecting \u00a0 \u00a0 \u00a0 \u00a0 to unknown or untrusted networks (e.g., coffee shops or hotel \u00a0 \u00a0 \u00a0 \u00a0 networks). This does not seem to be a \"Security Consideration\". Also, before this draft, receiving an (unencrypted) DNS server supplied by IKEv2 would also be more trusted. In general, VPN clients trust the \"VPN provided nameserver\" more than the local network one, irrespective of transport encryption. Perhaps this sentence can just be deleted? #4 Appendix A.2 and A.3 \u00a0 \u00a0 \u00a0 \u00a0 Legacy VPN service providers usually preserve end-users' data \u00a0 \u00a0 \u00a0 \u00a0 confidentiality by sending all communication traffic through an \u00a0 \u00a0 \u00a0 \u00a0 encrypted tunnel. What is \"legacy\" about this? I do not understand the point that A.2 is trying to make?  Similarly, I don't understand Appendix A.3. The VPN service is not involved in \"allowing\" an application to send traffic through the tunnel. It is the VPN client that decided whether or not to send its traffic through the tunnel or not. Also VPNs typically are configured to be either split-tunnel or not. This can be, be hardly ever is, dynamic. I don't understand what A.3 is trying to convey as example use related to the encrypted dns capability of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-04-27 06:54:13-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-27 02:19:22-07:00",
    "text": "Hi, Thanks for this document. This should be a trivial discuss to resolve, and only flagging it as a discuss because I think that it makes the spec unclear (or wrong): (1) p 4, sec 3.1.\u00a0 ENCDNS_IP* Configuration Payload Attributes \u00a0  *\u00a0 IP Address(es) (variable) - Includes one or more IP addresses that \u00a0 \u00a0 \u00a0 can be used to reach the encrypted DNS resolver identified by the \u00a0 \u00a0 \u00a0 Authentication Domain Name.\u00a0 For ENCDNS_IP4 this field contains \u00a0 \u00a0 \u00a0 one or more 4-octet IPv4 addresses, and for ENCDNS_IP6 this field \u00a0 \u00a0 \u00a0 contains one or more 16-octet IPv6 addresses. Shouldn't this be zero or more IP addresses?\u00a0 Otherwise, the example that only contains a domain and no IP address appears to be invalid.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-04-28 05:16:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-26 16:15:02-07:00",
    "text": "Thanks for working on this specification.  I don't have transport related issues on this specification. However, this specification relaxes constrains imposed by  RFC8598  but references it informatively. I think it should reference  RFC8598  as normative reference and also should clearly indicate that in the document header and abstract. I am assuming this is an oversight but want to discuss it.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-03-24 09:26:54-07:00",
    "end_reason": "position_updated",
    "start": "2015-11-18 09:02:41-08:00",
    "text": "It has been pointed out during the processing of this document (and other similar ones,  draft-ietf-ospf-sbfd-discriminator , for example) that the functionality provided is only the advertisement of S-BFD discriminators, but not a mechanism to map these discriminators to specific applications or use-cases in the nodes.\u00a0 That mapping has been declared out of scope. However, the Base S-BFD draft ( draft-ietf-bfd-seamless-base ) assumes that the advertisers of the multiple discriminators will in fact provide the ability for the mapping.\u00a0 Specifically, the base S-BFD document reads in Section 3. (Seamless BFD Overview): \u00a0  An S-BFD module on each network node allocates one or more S-BFD \u00a0  discriminators for local entities, and creates a reflector BFD \u00a0  session.\u00a0 Allocated S-BFD discriminators may be advertised by \u00a0  applications (e.g., OSPF/IS-IS).\u00a0 Required result is that \u00a0  applications, on other network nodes, possess the knowledge of the \u00a0  mapping from remote entities to S-BFD discriminators. This text reads to me that S-BFD is expecting the mapping to be somehow provided by the \"applications (e.g., OSPF/IS-IS)\".\u00a0 There's no other explicit discussion about the mapping in that document. I'm putting a DISCUSS on this document to hold its processing while the requirements from the S-BFD point of view are clarified.\u00a0 The answer to that question should be a discussion in the BFD WG (cc'd in this message), in coordination with the providers of the advertisements (so far the isis, ospf and l2tpext WGs have active drafts in this area). One possible outcome of this required discussion is clearly that the mapping is in fact outside the scope of advertising protocols (such as IS-IS).\u00a0 Other possible outcomes may require this document to be modified.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-04-15 05:52:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-13 05:15:35-07:00",
    "text": "Despite many objections to publishing this specification I believe we should run the experiment. I will vote \"Yes\" once DISCUSS-points are addressed. I would rather see this experiment being done and fail (or better - succeed), than to block publication of this document because it is not perfect. As per Sean Leonard/Ned Freed: There's also - as noted by Sean Leonard - a technical glitch in the current specification: The local-part is not the correct input to the hash function. A canonicalization step is needed because all of these addresses are equivalent: (1)  first.last@example.com (2) first . last @example.com (3) \"first.last\"@example.com (4) \"\\f\\i\\r\\s\\t.last\"@example.com (2) is equivalent to (1) because CWS has no semantics, (3) is equivalent to (1) because the enclosing quotes are not properly part of the address, and (4) is equivalent to (1) because quoted-pairs are semantically equivalent to just the quoted character.   I believe this is the entire list, so the obvious canonicalization to use on the local-part portion of an address prior to hashing is:   (a) If the local-part is unquoted remove any whitespace (CFWS) around \".\"s. (b) Remove any enclosing double quotes. (c) Remove any literal quoting.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-04-19 10:42:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-15 05:52:42-07:00",
    "text": "NOTE to editors: I am in the process of editing this text. There might be a couple of extra DISCUSS points that I will add. I will send the updated version once done. And thank you for addressing my earlier comments in -09. Despite many objections to publishing this specification I believe we should run the experiment. I will vote \"Yes\" once DISCUSS-points are addressed. I would rather see this experiment being done and fail (or better - succeed), than to block publication of this document because it is not perfect. As per Sean Leonard/Ned Freed: There's also - as noted by Sean Leonard - a technical glitch in the current specification: The local-part is not the correct input to the hash function. A canonicalization step is needed because all of these addresses are equivalent: (1)  first.last@example.com (2) first . last @example.com (3) \"first.last\"@example.com (4) \"\\f\\i\\r\\s\\t.last\"@example.com (2) is equivalent to (1) because CWS has no semantics, (3) is equivalent to (1) because the enclosing quotes are not properly part of the address, and (4) is equivalent to (1) because quoted-pairs are semantically equivalent to just the quoted character.   I believe this is the entire list, so the obvious canonicalization to use on the local-part portion of an address prior to hashing is:   (a) If the local-part is unquoted remove any whitespace (CFWS) around \".\"s. (b) Remove any enclosing double quotes. (c) Remove any literal quoting.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-04-23 08:19:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-19 10:42:05-07:00",
    "text": "NOTE to editors: Thank you for addressing my earlier comments in -09. If you need any more specific suggestions about text being added/deleted/updated, please let me know. Despite many objections to publishing this specification I believe we should run the experiment. I will vote \"Yes\" once DISCUSS-points are addressed. I would rather see this experiment being done and fail (or better - succeed), than to block publication of this document because it is not perfect. 1). As per Sean Leonard/Ned Freed: There's also - as noted by Sean Leonard - a technical glitch in the current specification: The local-part is not the correct input to the hash function. A canonicalization step is needed because all of these addresses are equivalent: (1)  first.last@example.com (2) first . last @example.com (3) \"first.last\"@example.com (4) \"\\f\\i\\r\\s\\t.last\"@example.com (2) is equivalent to (1) because CWS has no semantics, (3) is equivalent to (1) because the enclosing quotes are not properly part of the address, and (4) is equivalent to (1) because quoted-pairs are semantically equivalent to just the quoted character.   I believe this is the entire list, so the obvious canonicalization to use on the local-part portion of an address prior to hashing is:   (a) If the local-part is unquoted remove any whitespace (CFWS) around \".\"s. (b) Remove any enclosing double quotes. (c) Remove any literal quoting. 2). Ned Freed wrote: > First, there's no way to define a mapping of local-parts to a new set of > identifiers *without* effectively interpreting the local-part! If you define > the mapping as the draft currently does, implicit in that definition is that > local-parts are case-sensitive. And similarly, if you convert the local-part to > lower (or upper) case, you're now assuming the local-part is case-insensitive. > > And in the case of EAI, without some sort of normalization you're assuming that > different UTF-8 representations of the same string of characters correspond to > different recipients. (Which, as Harald Alvestrand and I both pointed out on > the IETF list, is technically untenable and needs to be addressed. My > suggestion was and is to specify that the same case-folding and normalization > algorithm used for IDNs also be employed here.) RFC 6532  and Section 10.1 of  RFC 6530  recommend using NFC Unicode Normalization Form. (This is similar to what IDN recommends, although there is no standard mapping there.) I think it would be reasonable for this document to say SHOULD apply NFC before hashing.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-04-27 06:42:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-23 08:19:49-07:00",
    "text": "NOTE to editors: Thank you for addressing my earlier comments in -09 and -10. Despite many objections to publishing this specification I believe we should run the experiment. I will vote \"Yes\" once DISCUSS-points are addressed. I would rather see this experiment being done and fail (or better - succeed), than to block publication of this document because it is not perfect. Ned Freed wrote: > So when a domain owner publishes such records in the DNS, a reasonable way to > look at it is that they are effectively saying, \"Everyone is allowed to > interpret the local-parts of our addresses as specified in this document in > this one narrow context.\" I'm pretty confident there's nothing in any standard > that forbids such a delegation of authority. > > And once you realize this is what is going on, not only does it become clear > that this draft is *not* violating the longstanding rules about local-part > interpretation, it casts the decision not to normalize the local-parts to lower > (or upper) case in an entirely different light. By choosing not to normalize > this specification is effectively restricting its own applicability to domains > with case-sensitive local parts. That is, IMO, a highly suboptimal choice - the > overwhelming majority of domains treat the local part in a case-insensitive > fashion, and so should the mechanism specified in this draft. > > Or, to put this another way, the inherent limitations of using the DNS to > provide the mapping from address to PGP key restricts the domain of > applicability of this specification to domains with particular local-part > policies, and the way in which the local-part to DNS mapping is specified > determines which policies the specification supports. And while it seems > logical to support a policy that's known to be in wide use, the specification > also needs to be very clear that domains that employ case-sensitive local-parts > MUST NOT avail themselves of this mechanism. I don't think I agree on \"MUST NOT\" here, because I think an email owner can publish the preferred form (which can be lowercased) or even multiple common forms of the email address. E.g. I can publish DNS records for  alexey.melnikov@isode.com ,  Alexey.Melnikov@isode.com  and  ALEXEY.MELNIKOV@isode.com , but not others. > What needs to happen here is that the specification be revised to make it clear > that this is what is going on: That by publishing such records a domain is > granting a limited right to interpret the local parts of its addresses. I agree with this. A sentence or two on this would suffice.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-05-03 00:47:08-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-27 06:42:05-07:00",
    "text": "NOTE to editors: Thank you for addressing my earlier comments in -09 and -10. Despite many objections to publishing this specification I believe we should run the experiment. I will vote \"Yes\" once DISCUSS-points are addressed. I would rather see this experiment being done and fail (or better - succeed), than to block publication of this document because it is not perfect. Ned Freed wrote: > So when a domain owner publishes such records in the DNS, a reasonable way to > look at it is that they are effectively saying, \"Everyone is allowed to > interpret the local-parts of our addresses as specified in this document in > this one narrow context.\" I'm pretty confident there's nothing in any standard > that forbids such a delegation of authority. > > And once you realize this is what is going on, not only does it become clear > that this draft is *not* violating the longstanding rules about local-part > interpretation, it casts the decision not to normalize the local-parts to lower > (or upper) case in an entirely different light. By choosing not to normalize > this specification is effectively restricting its own applicability to domains > with case-sensitive local parts. That is, IMO, a highly suboptimal choice - the > overwhelming majority of domains treat the local part in a case-insensitive > fashion, and so should the mechanism specified in this draft. > > Or, to put this another way, the inherent limitations of using the DNS to > provide the mapping from address to PGP key restricts the domain of > applicability of this specification to domains with particular local-part > policies, and the way in which the local-part to DNS mapping is specified > determines which policies the specification supports. And while it seems > logical to support a policy that's known to be in wide use, the specification > also needs to be very clear that domains that employ case-sensitive local-parts > MUST NOT avail themselves of this mechanism. I don't think I agree on \"MUST NOT\" here, because I think an email owner can publish the preferred form (which can be lowercased) or even multiple common forms of the email address. E.g. I can publish DNS records for  alexey.melnikov@isode.com ,  Alexey.Melnikov@isode.com  and  ALEXEY.MELNIKOV@isode.com , but not others. > What needs to happen here is that the specification be revised to make it clear > that this is what is going on: That by publishing such records a domain is > granting a limited right to interpret the local parts of its addresses. On a second thought, there is no obvious place to put this text. Besides, the document disallows mangling of local-parts, so \"granting a limited right to interpret\" doesn't mean much other than \"this email address might exist\". I agree with this. A sentence or two on this would suffice.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-16 05:09:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 05:59:44-07:00",
    "text": "I have a few small points (one is confusing enough to warrant a quick discussion), but they affect clarity of the specification: In Section 5: \u00a0  o\u00a0 OTL (3 bits) : Length of OTD field as an unsigned 3-bit integer, \u00a0 \u00a0 \u00a0 encoding the length of the field in hex digits.\u00a0 If OTL == 0, the \u00a0 \u00a0 \u00a0 OTD field is not present.\u00a0 The value of OTL MUST NOT exceed the \u00a0 \u00a0 \u00a0 value of DTL plus one. \u00a0 \u00a0 \u00a0 *\u00a0 For example, DTL = 0b0000 means the deadline time in the 6LoRHE \u00a0 \u00a0 \u00a0 \u00a0  is 1 hex digit (4 bits) long.  Ok, so 0b0000 ==> (0 + 1) * 4, means 4 bits. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 OTL = 0b111 means the \u00a0 \u00a0 \u00a0 \u00a0  origination time is 7 hex digits (28 bits) long. Is my math wrong or is your example wrong? 0b111 == 7. So (7 + 1) * 4 would be 32 bits.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 10:52:15-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:59:16-07:00",
    "text": "The Gen-ART reviewer made the following observation, which I'd like to discuss: There is a serious problem with the last 5 paragraphs of section 8, \"Synchronization Aspects\":\u00a0 they seem to assume that the time representation for the Deadline Time and Origination Time values will wrap around, that is, that the representation is the absolute value modulo the size of the field.\u00a0 In addition, there is a lack of clarity how the new epoch point will be chosen after the value wraps around. This seems to contradict the earlier sections of the document which speak of the values as if they are always to be considered as absolute values on a time scale selected by the TU field, viz., either the NTP time scale (in seconds) or the network's ASN numbering. It's possible that four of these paragraphs are intended to only apply to the use of TU = 00, the NTP time scale, and perhaps that usage of the header is understood not to be completely specified yet. However, the final paragraph discusses TU = 10 (the ASN time scale), and claims that wrapping of the DT value is intended.\u00a0 This is relevant to current implementations. Some sort of resolution of this is needed; as the document stands it is self-inconsistent.\u00a0 One possible resolution would be to omit these paragraphs.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-05-12 06:54:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-12 06:53:07-07:00",
    "text": "This should be easy to explain and clear up, bit I have to ask, as I don\u2019t see anything about it in the document: what deters entities from using this with a short deadline time in order to get expedited delivery, when they don\u2019t need it?\u00a0 How does this help a network if, ultimately, every transmission specifies a very short delivery time?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-08 19:03:58-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-12 06:54:16-07:00",
    "text": "This should be easy to explain and clear up, but I have to ask, as I don\u2019t see anything about it in the document: what deters entities from using this with a short deadline time in order to get expedited delivery, when they don\u2019t need it?\u00a0 How does this help a network if, ultimately, every transmission specifies a very short deadline time?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-09-03 01:11:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-13 06:41:03-07:00",
    "text": "The security consideration section have significant short comings as this mechanism enables multiple ways to attack both the packet and the system to my understanding. I would appreaciate your clarifications on these matters.  First of all by changing the dead-line so that it gets dropped because it is already late, alternatively move the deadline time out further in time (later), so that the forwarders may deliver it so late that the receiver considers it to late.  Secondly, there is the question if extensive use of this header will cause overload or affect the scheduling of packet transmission affect other traffic negatively. There appear to exist potential for new ways of bad interflow interactions here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-29 07:00:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-16 06:22:32-07:00",
    "text": "I support Magnus\u2019s DISCUSS #1 (and perhaps we are noting the same thing) The current Security Considerations text needs explicit discussion of the impact of the deadline being manipulated.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-08 13:11:41-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-21 05:51:36-07:00",
    "text": "Please use YANG security considerations template from  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines .\u00a0 Specifically (as a DISCUSS item): ** (Per the template questions \u201cfor all YANG modules you must evaluate whether any readable data\u201d) Would factory-default contain any sensitive information in certain network environments where the ACLs should be more restrictive that world readable for everyone? Per \u201cThe operational disruption caused by setting the config to factory default contents varies greatly depending on the implementation and current config\u201d, it seems like it could be worse than just an operational disruption.\u00a0 Please note that a default configuration could be insecure or not have security controls enabled whereby exposing the network to compromise.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-01-17 08:30:22-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-05 03:43:36-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-dmm-srv6-mobile-uplane-23 CC @evyncke Thank you for the work put into this document. I always like the use of innovative technologies. Please find below two blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Sri Gundavelli for the shepherd's detailed write-up including the very descriptive WG consensus ***but*** the justification of the intended status is plain wrong as it is about the original intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Intended status  The shepherd's write-up is about a standard track intended status, but this document text & meta-data say informal. I know the sad history of the intended status as well as that the IETF Last Call was done a 2nd time for 'informational', but I am afraid that the shepherd's write-up must be updated. ### Section 2.2 What is \"gNB\" ? (I know the term, but a reference and definition should be given) Unsure how to parse the bullet list as `SRH[n]: A shorter ` appears in the middle of apparently a single list. Or is it two lists ? Then what is the relationship with the 2nd list ? (possibly just a formatting issue).",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-03-17 18:13:18-07:00",
    "end_reason": "position_updated",
    "start": "2023-01-18 18:46:33-08:00",
    "text": "# Sec AD review of  draft-ietf-acme-subdomains-06 CC @paulwouters Please refer to  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ for more information about how to handle DISCUSS and COMMENT positions. This review uses the format specified in  https://github.com/mnot/ietf-comments/ which allows automated tools to process items (eg to produce github issues) ## DISCUSS ### Zone bondary implications ``` \u00a0  the ACME client need only fulfill an \u00a0  ownership challenge against an ancestor domain identifier. ``` This document seems to have a \"Public Suffix List\" issue and no Security Considerations to cover this. PSL is mentioned in  RFC 8555 , but limited to the context of wildcards. The draft hints at the server being able to allow or not allow subdomain issuance but provides little guidance.\u00a0 I think at minimum, advise should be given not to allow issuance where it crosses a label that is present in the Public Suffix List (PSL). Additionally, it could say this should not be allowed for the root one or TLD zones, and that care should be taken with Empty Non Terminals (ENS), eg \" co.uk \". Currently, for a TLD to obtain a rogue certificate, it has to take over a child zone by issuing new NS records or issue a (DNSSEC signed) A or AAAA record directly into the child domain abusively crossing the zone cut. These are auditable or rejectable as these DNSSEC keys are not used fo subdomains in normal deployment. With this document, they just need to issue a TXT record into their own zone, which is indistinguishable from a normal operation of a DNSSEC zone key signing its own zone content. So I believe some security guidance here would be useful. ### Post compromise security This document allows an authorization object to be used in the future for additional sub/super domain ACME certificates. This does seem like a new security concern without a matching security consideration. While without this document, abuse could happen for an individual domain, this can now be extended to all domains under or one or more levels above it. An attacker could copy this object and use it at a much later date to issue fraudulent certificates for many subdomains. Related: Is there a way to indicate with ACME that this object should be de-authorized, to gain some post compromise security? I did not see anything listed in the security considerations of  RFC8555 . I did not see any recommendations for the expire: field in  RFC 8555 's Security Considerations Section. ### Wildcards? It is unclear to me how DNS wildcards, eg \"*.nohats.ca\" should be handled? Do they fall within the permissions granted by \"subdomainAuthAllowed\"?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-05-19 05:52:01-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-16 11:44:56-07:00",
    "text": "This is a generally a well written document and I don't object to its publication. However I have several minor but important points which should be easy to address: In Section 2.1: \u00a0 Reference to the certificate corresponding to the private key used to sign this object (field \"c\"). The value of this field MUST be a URL of type \"rsync\" or \"http(s)\" You need to have Normative references for the corresponding URI RFCs:  RFC 5781  for rsync URIs and  RFC 7230  for http/https URIs. \u00a0 that points to a specific resource certificate in an RPKI repository [ RFC6481 ]. Any non URL-safe characters (including semicolon \";\" and plus \"+\") must be URL encoded. This really need a Normative reference to  RFC 3986 . \u00a0 The signature itself (field \"b\"). This MUST be the last field in the list. The signature is the output of the signature algorithm using the appropriate private key and the calculated hash value of the object as inputs. The value of this field is the digital signature in base64 encoding [ RFC4648 ]. As  RFC 4648  specifies 2 base64 alphabets, you need to include section number. I think you meant Section 4 (and not Section 5).",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-05-19 05:33:40-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-18 08:50:55-07:00",
    "text": "I'd like to check one thing - this may be needed for strict compliance with RPKI thing but it seems kinda weird to also impose that here, but anyway... Is 3.2 step 1 needed?\u00a0 That seems like useless complexity here.\u00a0 If it is needed, how does the verifier check that it's really a single-use? I don't see the point TBH.",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-05-18 21:08:30-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-17 20:37:41-07:00",
    "text": "Thank you for putting substantial effort into this document. I have a few discusses. I hope they can be resolved quickly. In Section 2.1. The reference to the aligned certificate\u00a0 which has the same private key that signed the RPSL object is mandatory, and defined by a RSYNC URL or a HTTP(S) URL. My question surrounds the \"or\". The architecture of RPKI (IIRC) is centered around RSYNC, and thus SIA/AIA values MUST have a RSYNC URL, and MAY have other types. By this are you leaving it to the issuing party to control the RPKI Distribution mechanisms of the Replying Party? I am quite comfortable with \"or\" personally, however this facet of fetching the RPSL Certificate to validate the private key usage is seemingly orthogonal to the RPKI architecture of RSYNC preferred and should be called out if 'or' is the clear intention. Or, has the consensus of the WG moved on from being wedded to RSYNC? If it is truely \"or\", my observation is that the use of the RPKI repository is one of\u00a0 convenience, and that should be called out, in fact it does appear that any valid certificate bearing  RFC3779  extensions could be used to validate the digital signature associated with the RPSL object provided the relying party has trust anchor material that leads to the corresponding EE certificate and therefore private key. Is this observation correct? The Signature expiration time field (\"x\") currently has no time constraints, and I'm very surprised that it is optional with the text in s2.5, given that the expiration time, by my reading, could not be beyond the 'not after' time of the corresponding certificate. Can you please instruct me as to what the consensus position on this was? A criticism of many IRRs is that data becomes stale. have the signature expiration time field could aide in data freshness models and reduce load on automated import and validation of these RPSL signatures. And lastly, IRRs tend to run over the (legacy?) whois port 43 that doesn't provide channel layer security. This means that while signature provide a means of detecting modification it may not stop a a MiTM event where the entire object is omitted. Do you agree? if so that might be appropriate for the Security Considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-05-09 15:43:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-09 15:35:36-07:00",
    "text": "I would like to ballot YES on this document, but I would like to discuss the following: Sorry for being DownRef police, but  RFC 7918  is clearly Normative (because there is a SHOULD level requirement), but it is listed as Informative reference. It would be a DownRef once it is made Normative, unless the procedure in  RFC 8067  is used. Is  RFC 7918  a suitable DownRef?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-05-11 07:34:22-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-09 15:43:00-07:00",
    "text": "(I just updated both my DISCUSS and my comment section.) I would like to ballot YES on this document, but I would like to discuss the following: Sorry for being DownRef police, but  RFC 7918  is clearly Normative (because there is a SHOULD level requirement), but it is listed as Informative reference. It would be a DownRef once it is made Normative, unless the procedure from  RFC 8067  is used. Is  RFC 7918  a suitable DownRef? Is it widely implemented?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-11-09 08:00:48-08:00",
    "end_reason": "position_updated",
    "start": "2017-05-06 13:31:08-07:00",
    "text": "S 9 mandates  RFC 7250 : \u00a0  o\u00a0 Raw public keys [ RFC7250 ] which reduce the size of the \u00a0 \u00a0 \u00a0 ServerHello, and can be used by servers that cannot obtain \u00a0 \u00a0 \u00a0 certificates (e.g., DNS servers on private networks). This needs to be updated to indicate that the client MUST NOT offer 7250 unless it has a preconfigured SPKI, otherwise you're going to have interop problems.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-07-31 14:28:25-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-09 20:43:10-07:00",
    "text": "I do have a concern regarding section 7.3 as it is not clear what really is being requested on the DHCP front here. While using an IP address or an FQDN are generally both possible choices while providing configuration options using DHCP, the use of FQDNs for acquiring trusted DNS servers seems problematic. We have spent a great deal of effort writing up some of the potential issues in Section 8 of  RFC7227 . It would be good if you can take a look and clarify what is required from a potential new DHCP option and how the failure modes are expected to be handled.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-10-19 08:39:11-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-22 04:52:34-07:00",
    "text": "\"Each NTP clock has a set of N IP addresses. The assumption is that \u00a0 \u00a0 \u00a0 the server information, including its multiple IP addresses is \u00a0 \u00a0 \u00a0 known to the NTP clients.\" A protocol specification should not make this assumption but describe a mechanism how a client gets to know about these IP addresses. However, this draft does not read like a protocol specification anyway; it rather reads like an informational document leaveraging existing mechanisms to use multiples pathes (see further below).  Further, this draft claims in the abstract that this mechanism could enhance security which is not further discussed (should be added to the security considerations section!). However, I would guess that it depends on the choosen combining algorithm if it enhances security or not (or even worsens it). If so that really needs to be further discussed!",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-02-23 14:00:03-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-18 21:38:06-07:00",
    "text": "There are a number of things I\u2019d like to discuss, because I find them not understandable.\u00a0 Perhaps it\u2019s simply because I\u2019m not a codec expert, but, while I understand that this is written for readers who will actually be implementing he FFV1 codec, some of them will also not be \u201cexperts\u201d.\u00a0 That said, I\u2019m sure some of this is just a case of \u201cgive Barry some clue and it\u2019s fine.\u201d \u2014 Section 2.1 \u2014 You use the term \u201csymbol\u201d here and later, without defining it, and I don\u2019t know what it is.\u00a0 A byte?\u00a0 A character?\u00a0 A string of bits?\u00a0 What length? \u2014 Section 3.8.1.1 \u2014 I\u2019m not sure how to interpret the stuff in this section.\u00a0 First, I don\u2019t know why there are seven \u201cfigures\u201d, with no captions nor other explanation.\u00a0 Second, I\u2019m having trouble making sense out of things like this: \u00a0  S_(i + 1, C_(i)) =\u00a0 zero_state_(S_(i, C_(i)))\u00a0 AND \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 l_(i) =\u00a0 L_(i)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 AND \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 t_(i) =\u00a0 R_(i) - r_(i)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <== \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 b_(i) =\u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <==> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 L_(i) <\u00a0 R_(i) - r_(i) Can you explain how this is meant to be read?\u00a0 Maybe it\u2019s just me, and maybe after you explain it I\u2019ll whack myself on the head and say, \u201cDoh!\u201d Third, you say, \u201cS_(0, i) is the i-th initial state,\u201d but you haven\u2019t previously introduced the term \u201cstate\u201d, and I don\u2019t know what it means. \u2014 Section 3.8.1.2 \u2014 \u00a0  \"get_rac\" returns a boolean, computed from the bytestream as \u00a0  described in Section 3.8.1.1. I see nothing in Section 3.8.1.1 that describes get_rac. \u2014 Section 3.8.1.3 \u2014 \u00a0  At keyframes all Range coder state variables are set to their initial \u00a0  state. What does \u201cat keyframes\u201d mean? \u2014 Section 3.8.1.5 \u2014 This is just a list of numbers with no explanation.\u00a0 It needs text explaining what it means. \u2014 Section 3.8.2.2 \u2014 \u00a0  The level is identical to the predicted one. \u00a0  The run and the first different level are coded. What does \u201clevel\u201d mean?\u00a0 It\u2019s not defined anywhere. \u2014 Section 4.3.1 \u2014 \u00a0  \"reserved_for_future_use\" has semantics that are reserved for future \u00a0  use. Yes, that seems rather obvious, though it\u2019s oddly worded.\u00a0 But then you say what to do with \u201cthis value\u201d, and nowhere do you say what the value is.\u00a0 How does one know?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-12-01 13:59:51-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-07 08:51:26-07:00",
    "text": "A simple clarification. Section 6. \u00a0  Implementations of the FFV1 codec need to take appropriate security \u00a0  considerations into account, as outlined in [ RFC4732 ] RFC4732  only covers DoS.\u00a0 A buffer overflow (as described in the subsequent text of this paragraph) in a codec implementation could have dramatically more significant consequences for the endpoint (or the services it provides) than a DoS.\u00a0 It could potentially lead to arbitrary remote code execution on the system (barring defensive mitigations provided by sandboxing in the app, OS execution protections; and/or end-point protection software) which pretty much enables an attacker to do anything of their choosing on the system.\u00a0 Please note that.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-29 08:39:35-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-26 19:14:59-07:00",
    "text": "I agree with Mirja that reiterating the privacy considerations of explicit tracking of group membership (with pointer to the relevant IGMP/MLD protocol documents) would be worthwhile. Normally I would leave this as a Comment on the assumption that the privacy considerations are already documented in the protocol specification that documents explicit tracking, but I could not find such a document (with privacy considerations listed) in a quick search; I found  RFC 6636  and  draft-ietf-pim-explicit-tracking  but probably missed a few others. Let's talk about what the current state actually is, and where it's best to document the privacy considerations (which is not necessarily this document, a priori).",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-10 11:00:55-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 13:31:30-08:00",
    "text": "Hello, Thanks for your work on this draft.\u00a0 Could you please update the Security Considerations to use the current template?\u00a0 I believe this is the current, but that should be confirmed: https://tools.ietf.org/html/draft-ietf-netmod-rfc6087bis-10#page-52",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-17 21:26:15-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-09 11:47:44-07:00",
    "text": "As was the case for Murray, I'm unconvinced that I have understood what Section 3 intended to convey.\u00a0 However, I am balloting Discuss because my current best understanding is for a statement that seems inconsistent with my understanding of how the partial response mechanism works.\u00a0 In particular, how would the topmost objects be returned according to different field sets, if there's only a single query parameter and (I assume) all topmost objects are the results of the same single query?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-09-06 11:17:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-05 14:22:20-07:00",
    "text": "Probably I'm just not properly aware of details in the referenced RFCs, but I had a few questions that came to mind. [ section 2 ] * How are multiple keys encoded in a fieldSet parameter value?\u00a0 An example \u00a0 would be welcome. * What should be done with a query containing an empty fieldSet? \u00a0 E.g. ...?...&foo=bar&fieldSet=&baaz=quux [ section 2.1 ] * How much data transfer is actually saved if servers are supposed to send \u00a0 these subsetting_metadata structures in every response?\u00a0 Are we just \u00a0 swapping data bytes transferred for meta-data bytes transfered?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-05-10 22:19:13-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-10 22:17:11-07:00",
    "text": "Looking at the Shepherd write up and the Ballot, I see no mention of the normative reference to  RFC 7348 , which is informational and part of the Independent Submission stream. As I mention in my comments below, I don't fully follow the technical contents of this document, but this seems like a red flag to me and -- as far as I can tell -- it hasn't been discussed yet. It's possible that the reference just ended up in the wrong section (and should actually be informative), but it's not immediately obvious on a casual examination whether that's true.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-05-11 06:47:19-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-10 22:19:13-07:00",
    "text": "Looking at the Shepherd write up and the Ballot, I see no mention of the normative reference to  RFC 7348 , which is informational and part of the Independent Submission stream. As I mention in my comments below, I can't fully follow the technical contents of this document, but this seems like a red flag to me and -- as far as I can tell -- it hasn't been discussed yet. It's possible that the reference just ended up in the wrong section (and should actually be informative), but it's not immediately obvious on a casual examination whether that's true.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2017-05-05 13:40:29-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-11 16:43:32-07:00",
    "text": "First, thank you for a clearly written document that contained enough context to trigger my hazy memory of some of the technical details. My concern is around this paragraph in the Introduction: \"The MPLS label value in the Ethernet A-D route can be set to the \u00a0  VXLAN Network Identifier (VNI) for VXLAN encap, and this VNI may have \u00a0  a global scope or local scope per PE and may also be equal to the \u00a0  VPWS service instance identifier set in the Ethernet A-D route. \" First, I recognize that folks have implemented and deployed EVPN with VXLAN. That's fine.\u00a0 There is an ISE  RFC 7348  that describes VXLAN.\u00a0  Depending on what you (authors, shepherd, AD, WG) decide to do about the rest of my concern, it is likely that this should be normative references - which would be a downref. Second, the paragraph here isn't really adequate to describe how to implement the functionality.\u00a0  I don't see how: \u00a0 \u00a0 a) The ingress PE decides which VNIs it can send based upon the VNI=MPLS_label \u00a0 \u00a0 \u00a0 \u00a0 from the egress.\u00a0  Is there an assumption that VXLAN allows sending all VNIs across \u00a0 \u00a0 \u00a0 \u00a0 the particular VPWS, whether port-based, VLAN-based, etc? \u00a0 \u00a0 b) Is there an assumption that the egress PE-advertised MPLS label also indicates the \u00a0 \u00a0 \u00a0 \u00a0  VNI to be used?\u00a0 That seems like another mode, like the VLAN-based service, except \u00a0 \u00a0 \u00a0 \u00a0  it is perhaps VNI + VLAN-based service? Please don't take this Discuss as a reason to remove the paragraph and the implied functionality. If it's implemented and deployed (and I think it is) - then what I really want is to just have it adequately written down so that others can interoperably implement.\u00a0 The downref to VXLAN should just be a matter of process nuisance (i.e. another IETF Last Call and handling any concerns).",
    "type": "Discuss"
  },
  {
    "ad": "Adrian Farrel",
    "end": "2014-10-28 14:58:45-07:00",
    "end_reason": "position_updated",
    "start": "2014-10-16 03:30:09-07:00",
    "text": "I welcome this document and think it is a useful addition to the canon. However, John Scudder did a Routing Directorate review during the IETF  last call period and emailed his comments to the authors and to the  GROW mailing list. I have seen no response to this directly or on the GROW list. Therefore, from a process point of view, I adopt all of John's comments as a Discuss even though many of the points are small and would normally be just Comments. - Throughout the document, various terms are used to describe what  RFC  \u00a0 4271  calls a \"route\". The definition given in  RFC 4271  is: \u00a0  Route \u00a0 \u00a0 \u00a0 A unit of information that pairs a set of destinations with the \u00a0 \u00a0 \u00a0 attributes of a path to those destinations.\u00a0 The set of \u00a0 \u00a0 \u00a0 destinations are systems whose IP addresses are contained in one \u00a0 \u00a0 \u00a0 IP address prefix carried in the Network Layer Reachability \u00a0 \u00a0 \u00a0 Information (NLRI) field of an UPDATE message.\u00a0 The path is the \u00a0 \u00a0 \u00a0 information reported in the path attributes field of the same \u00a0 \u00a0 \u00a0 UPDATE message. \u00a0 That is, one NLRI plus its path attributes, as carried in an UPDATE, \u00a0 is a \"route\". I would suggest adopting this term, or \"BGP route\" if  \u00a0 you prefer, instead of terms such as \"NLRI UPDATE message\", \"NLRI  \u00a0 message\", \"prefix UPDATE message\", and even just plain \"NLRI\" and  \u00a0 \"message\". Also some, but not all, of the uses of \"prefix\". I think \u00a0 doing so will make the document clearer, more readable, and more  \u00a0 technically accurate. A simple search for the terms I've called out \u00a0 should show most of them so I won't enumerate them here unless you  \u00a0 ask me to (feel free, if you want).  - Reference [RS-ARCH] is a dead link. I found a live copy at \u00a0  http://www.cs.usc.edu/assets/003/83191.pdf . It might be worth  \u00a0 checking with the authors of RS-ARCH to ask what a good archival \u00a0 reference is. - S. 4.2 talks about scaling. I'm trying to make sense of the analysis: \u00a0  Regardless of any Loc-RIB optimization technique is implemented, the \u00a0  route server's control plane bandwidth requirements will scale \u00a0  according to O(P * N), where P is the total number of unique paths \u00a0  received by the route server and N is the total number of route \u00a0  server clients.\u00a0  \u00a0 So far so good. (Except nit: there seems to be a word missing, such \u00a0 as \"whether\" as in \"Regardless of whether any Loc-RIB...\") \u00a0  In the case where P_avg (the arithmetic mean number \u00a0  of unique paths received per route server client) remains roughly \u00a0  constant even as the number of connected clients increases, this \u00a0  relationship can be rewritten as O((P_avg * N) * N) or O(N^2).\u00a0  \u00a0 I don't see where the second factor of N comes from. You're basically \u00a0 expanding the P in the first expression as P_avg * N -- but why? I \u00a0 think this would only apply if add-path all-paths was chosen as the \u00a0 path hiding mitigation strategy -- but this is not touched on in \u00a0 route-server-operations, only in ix-bgp-route-server, and besides that \u00a0 the beginning of the paragraph implies you're analyzing the multiple  \u00a0 Loc-RIB strategy, so I don't guess all-path is what you were thinking \u00a0 of. If you're not doing all-path, the O(N^2) analysis is wrong AFAICT. \u00a0 To see this, consider that the inbound routes require O(P_avg * N) \u00a0 which is just O(N), but the number of routes you're going to advertise \u00a0 is bounded by the size of the Internet routing table, which is a  \u00a0 constant for purposes of this analysis, so also O(N). In and out are \u00a0 summed, not multiplied, so the whole thing works out to be O(N), not \u00a0 O(N^2). \u00a0 So I think this needs to either be corrected, or the assumptions need \u00a0 to be better explained. Moving on: \u00a0  This \u00a0  quadratic upper bound on the network traffic requirements indicates \u00a0  that the route server model will not scale to arbitrarily large \u00a0  sizes. \u00a0 If you continue to think this sentence is warranted, I think it should \u00a0 be better quantified. Of course nothing can scale to *arbitrarily* \u00a0 large sizes, but that still leaves a lot to the imagination. I would \u00a0 think it would be beneficial for an IX operator reading this document \u00a0 to be able to have some idea of how practical the limitation is. Since \u00a0 the analysis in question is looking at control traffic bandwidth \u00a0 consumption, it wouldn't be too onerous to throw some simple \u00a0 assumptions up against it -- for example, \"if we suppose a RS receives \u00a0 on average 100,000 routes from each client with a rate of change of 10 \u00a0 routes/second, sends on average 1,000,000 routes to each client with a \u00a0 rate of change of 100 routes/second, and that each route consumes on \u00a0 average 50 bytes in a BGP UPDATE message, simple arithmetic shows that \u00a0 a GigE connection to that RS will be fully saturated by the time the \u00a0 number of clients reaches 25,000.\" (Which does not seem like a very  \u00a0 practical limitation, the RS will hit a CPU or memory bottleneck \u00a0 first.) \u00a0 Anyway, maybe you will decide on reconsideration of the big-O analysis \u00a0 that this bit is not needed at all, which would be OK with me. - S 4.2.2.1,  \u00a0  If the route server \u00a0  operator has prior knowledge of interconnection relationships between \u00a0  route server clients, then the operator may configure separate Loc- \u00a0  RIBs only for route server clients with unique outbound routing \u00a0  policies. \u00a0 It wasn't obvious to me what \"outbound\" applies to -- the client? The \u00a0 RS? -- and for that matter why an inbound policy (on the RS) might not \u00a0 apply. Possibly this could be remedied by simply dropping the  \u00a0 adjective \"outbound\". - S. 4.2.1.2, \u00a0  destination splitting would require significant co-ordination \u00a0  between the route server operator and each route server client \u00a0 It's not clear to me why it would \"require significant co-ordination\", \u00a0 depending on what resource you're trying to conserve. Two examples of  \u00a0 how you could avoid coordination while still getting benefit: You \u00a0 could have clients send all their routes to all the RSes, but have \u00a0 RSes filter out the prefixes they don't care about. This gives the RS \u00a0 most of the CPU benefit it would have gotten had the client done the  \u00a0 filtering (prefix filtering is cheap), almost all the memory benefit  \u00a0 (the filtered routes need not be retained in the Adj-RIB-In), and  \u00a0 around half the control traffic bandwidth benefit. The client incurs \u00a0 cost to send duplicate routes that are going to be discarded by the  \u00a0 RS, but the client is presumably not the bottleneck resource. Or \u00a0 better still, the RS could use ORF towards the clients to control \u00a0 what routes the clients will send. - S. 4.6.1, \u00a0 OLD: \u00a0  Prefixes sent to the route server are tagged with specific [ RFC1997 ] \u00a0  or [ RFC4360 ] BGP community attributes \u00a0 I don't think the naked references scan well as adjectives in this  \u00a0 context. I suggest \u00a0 NEW: \u00a0  Prefixes sent to the route server are tagged with specific standard \u00a0  [ RFC1997 ] or extended [ RFC4360 ] BGP community attributes - Also in S. 4.6.1, \u00a0 OLD: \u00a0  As both standard and extended BGP communities values are restricted \u00a0  to 6 octets \u00a0 Actually standard communities are restricted to less than that. \u00a0 Perhaps reword as \u00a0 NEW: \u00a0  As both standard and extended BGP communities values are restricted \u00a0  to 6 octets or fewer - Also in S. 4.6.1, \u00a0  route server operator should take care to ensure \u00a0  that the predefined BGP community values mechanism used on their \u00a0  route server is compatible with [ RFC4893 ] 4-octet autonomous system \u00a0  numbers. \u00a0  \u00a0 I suspect an RS operator reading this might be left scratching his or \u00a0 her head and asking \"what does it mean for me to be compatible with  \u00a0  RFC4893  in this context\"? It would be kind to offer them some \u00a0 guidance, since after all this is a guidance document. - S. 4.7: Where you say \"non-commutative\" I think you mean \"non- \u00a0 transitive\". - S. 4.7: \u00a0  Problems of this form can be dealt with using [ RFC5881 ] bidirectional \u00a0  forwarding detection. \u00a0 It's not clear to me how certain non-transitive forwarding failures \u00a0 can be dealt with using BFD. To take an example, suppose clients A, B \u00a0 and C peer with RS. The IX fabric has a failure such that A and B can \u00a0 both reach RS, but not each other. C has connectivity to everyone.  \u00a0 Prefix X is advertised to RS by both B and C. For whatever reason, RS \u00a0 selects X via B to advertise to A. Even if A runs BFD towards B, at  \u00a0 best A can determine that the route from RS can't be used. A isn't  \u00a0 able to fail over to C's route as it would in the full-mesh case, \u00a0 since it's not aware of it. Depending on A's other connectivity, this \u00a0 may result in sub-optimal routing towards X, or complete loss of  \u00a0 connectivity to X. \u00a0 It's beyond the scope of the draft to solve this problem, but the text \u00a0 could be made more accurate. A minimal fix would be \u00a0  Problems of this form can be partially mitigated using [ RFC5881 ]  \u00a0  bidirectional forwarding detection. \u00a0 although you might want to go on a bit longer to explain what problems \u00a0 can't be mitigated. - S. 4.8: \u00a0  This problem is not specific to route servers and it can also be \u00a0  implemented using bilateral peering sessions.\u00a0 However, the potential \u00a0  damage is amplified by route servers because a single BGP session can \u00a0  be used to affect many networks simultaneously. \u00a0 This is true, but there is a more severe way RSes aggravate the \u00a0 problem: In a full mesh, a router can (and usually does) directly \u00a0 enforce a \"no third-party next hops\" policy against its peers. An RS \u00a0 peer by definition cannot enforce this policy against the RS, so the \u00a0 RS is the only place it can be enforced. - S. 4.8: \u00a0  Route server operators SHOULD check that the BGP NEXT_HOP attribute \u00a0  for NLRIs received from a route server client matches the interface \u00a0  address of the client.\u00a0 If the route server receives an NLRI where \u00a0  these addresses are different \u00a0 so far so good (modulo my first comment about the use of \"NLRI\", of \u00a0 course), but: \u00a0  and where the announcing route server \u00a0  client is in a different autonomous system to the route server client \u00a0  which uses the next hop address,  \u00a0 Is the RS sincerely expected to enforce the above? I suppose it could \u00a0 be implemented automatically although imperfectly, by noticing that  \u00a0 multiple clients are in the same neighbor AS and noticing when they  \u00a0 use each other as third-party next hops, but AFAIK people generally  \u00a0 don't try to figure this out, they just do what you've said in the  \u00a0 preceding sentence -- make sure the NH matches the interface address. \u00a0 If you really do propose that the RS should allow third-party next  \u00a0 hops but only from clients in a common AS, I think you should talk  \u00a0 about it specifically and in more detail. If you didn't really mean \u00a0 that, then I suggest you drop the clause.  - S. 5: \u00a0  On route server installations which do not employ path hiding \u00a0  mitigation techniques, the path hiding problem outlined in section \u00a0  Section 4.1 can be used in certain circumstances to proactively block \u00a0  third party prefix announcements from other route server clients. \u00a0 I don't understand what this means. Specifically, I don't know what it \u00a0 means to \"proactively block third party prefix announcements\" or for  \u00a0 that matter, even what you mean by \"third party prefix announcements\" \u00a0 in this context. (As a term of art, I normally understand \"third party \u00a0 announcement\" in a BGP context to mean announcing a third-party next  \u00a0 hop as you discuss in S. 4.8). I also don't know what the \"certain \u00a0 circumstances\" are, quite likely these should be given at least a  \u00a0 little color if not entirely spelled out. \u00a0 Also, a nit -- the xref expansion has put \"section section\" into your \u00a0 text. - S. 7: \u00a0  BIRD, OpenBGPD and Quagga, whose open source BGP implementations \u00a0  include route server capabilities  \u00a0 Great, cool, but: \u00a0  which are compliant with this \u00a0  document. \u00a0 I'm not sure what it actually means to be \"compliant\" with a document \u00a0 that \"describes operational considerations\". Perhaps just drop the  \u00a0 phrase?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-26 17:59:11-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-07 07:02:49-08:00",
    "text": "We say that we adhere to the guidelines of  RFC 3552 , yet we do not mention that it may be impossible to achieve our goals \"in the face of a highly capable adversary, such as the one envisioned by the Internet Threat Model of  BCP 72  [ RFC3552 ] that can arbitrarily drop or delay any or all traffic\" (to quote from a recent DetNet RFC that does cover this topic,  RFC 8939 ).\u00a0 I think that in order to fully adhere to  RFC 3552 , we need to be more explicit about how we have to assume a reduced attacker capability set in order to make any progress at all.\u00a0 A good place for this discussion would be near where we state that security a DetNet starts with a scrupulously well-designed and well-managed engineered network in Section 1 -- the goal of having the well-managed network is to exclude some of the more powerful adversary capabilities from the Internet Threat Model.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-02-02 02:13:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-22 06:11:58-08:00",
    "text": "Section 3.1: \u00a0  A DetNet system security designer relies on the premise that any \u00a0  resources allocated to a resource-reserved (OT-type) flow are \u00a0  inviolable, in other words there is no physical possibility within a \u00a0  DetNet component that resources allocated to a given flow can be \u00a0  compromised by any type of traffic in the network; this includes both \u00a0  malicious traffic as well as inadvertent traffic such as might be \u00a0  produced by a malfunctioning component, for example one made by a \u00a0  different manufacturer. Can we really ensure that a malfunctioning component can't compromise the resources of another one. The most simple example I would have is a router with a malfunction rewriting the destination address or flow label of a packet causing the packet to change the flow it is belonging too, thus if occurring for any significant amount of packets causing overflow in the next hop router when the original and the remarked flow compete for the same resources assigned. The only way to ensure that this happens is to verify a strong header integrity protection at each point a decision on how to forward, classify or remark the flow is done. So Section 3.3 indicate that this is an issue, but only discusses how it can be solved over ethernet. This issue hasn't been well handled in either the MPLS or IP detnet data planes as no additional mechanism was required to ensure this criteria is meet.  So I think the requirement that also malfunctions in equipment don't result in flow violations is hard, and will require that the already approved data plane specification needs additional mechanism that verify all data used on each occasion the data is used. Neither MPLS nor IP as currently specified fulfill this, not even against non-malicious malfunctions or corruption type malfunctions. Then we have those malfunction that breaks the network or where control plane information provided is being corrupted.  I have only looked a bit deeply on one type of malfunction that I know that can occur. I convinced that this document will indicate a number of additional potential ways things can go wrong that can't be determined without additional mechanisms and likely additional per packet fields. Thus, I think we need to discuss if the security properties matches the actual approved data plane, or if the property is so important that the data plane specification is moved back to the WG to be fixed?  I would also recommend that you don't indicate that a different manufacturer can be blamed. Isn't a malfunction going to occur where they occur, it is not like a single vendor network will be without malfunctions due to hardware issue, nor have its set of software bugs.  Section 9.1: \u00a0  The IP protocol has a long history of security considerations and \u00a0  architectural protection mechanisms.\u00a0 From a data plane perspective \u00a0  DetNet does not add or modify any IP header information, so the \u00a0  carriage of DetNet traffic over an IP data plane does not introduce \u00a0  any new security issues that were not there before, apart from those \u00a0  already described in the data-plane-independent threats section \u00a0  Section 5, Security Threats. The above requirement from Section 3.1 in regards to IP header fields used for flow classification are not automatically fulfilled without additional mechanisms. Thus, I would claim that DETNET unless Section 3.1 requirement is minimized will require support for a strong integrity mechanism over all headers. So if this needs to be keyed or not is totally dependent on if malicious modifications of packet headers needs to be taken into account or not.  Section 9.2:  Same as previous issue but for integrity over the MPLS headers.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-02-03 08:00:54-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-06 14:34:41-08:00",
    "text": "** Section 5.1 and Figure 1.\u00a0 Thanks for separating the different kinds of attackers.\u00a0 As it relates to \u201cinternal vs external\u201d where are the details of what DetNet traffic is encrypted or authenticated to create a distinction between internal and external; and to rule out certain attack to external actors per Figure 1? ** I may not fully understand the architecture, but these threats and mitigations didn\u2019t seem to align: --\u00a0 Section 7.1.\u00a0 Per path redundancy being able to mitigate Section 5.2.7 (time sync), which is just reference to  RFC7384 , how does a  RFC8655  style PREOF mitigate a grandmaster time source attack per Section 3.2.10 of  RFC7384 ?\u00a0 Is the intent here that all  RFC7384  attacks are mitigated? -- Section 7.5.\u00a0 \u201cReconnaissance attacks (Section 5.2.6) can be mitigated by using encryption\u201d seems like too strong of a statement.\u00a0 Some traffic analysis should be still be possible. -- Section 7.6.\u00a0 Per \u201cThese mechanisms can be used to mitigate various attacks on the controller plane as described in Section 5.2.5 \u2026\u201d, can it be clarified how these security properties will protect against controller compromise (Section 5.2.5.2).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-25 19:24:49-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-16 13:33:08-07:00",
    "text": "Thank you for this quite masterfully done mammoth undertaking!\u00a0 I expect to ballot Yes pending discussion of one point. I'm looking at the following text in Section 4.3.4 relating to how to handle certificate validation failures for https: \u00a0  If the certificate is not valid for the URI's origin server, a user \u00a0  agent MUST either notify the user (user agents MAY give the user an \u00a0  option to continue with the connection in any case) or terminate the \u00a0  connection with a bad certificate error.\u00a0 [...] Given the discussion up in \u00a73.5 about requirements to \"notify\" the user vs requiring \"confirmation\" from the user, I don't think that just \"MUST notify the user\" is sufficient to prevent the user-agent from continuing, since it is sufficient to just write a log entry as the means to notify the user.\u00a0 Is the intent to require confirmation of the action to continue in the face of such an error (which, again per \u00a73.5 could be a pre-configured confirmation)?\u00a0 An intent to require \"confirmation\" (vs mere \"notification\") seems consistent with the subsequent text placing requirements on automated clients and would be more consistent with my understanding of general IETF consensus for securing protocols",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-25 16:01:48-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-22 07:22:14-07:00",
    "text": "olding off on approval until a second IANA expert chimes in.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 17:54:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-14 23:54:22-08:00",
    "text": "The volume of my comments notwithstanding, this document was actually quite nice to read.\u00a0 I think that these discuss points, at least, should be fairly straightforward to resolve. (1) In a number of places we have text roughly of the form: \u00a0 \u00a0 String values based on a\u00a0 from   MUST NOT be used, as these values are less concise than \u00a0 \u00a0 their index value equivalent. This seems like it could have some nasty interactions with updates to the IANA registry in question, especially if consumers attempt to enforce the MUST NOT.\u00a0 Consider a version scheme \"foo\", used by an implementation M to emit CoSWID tags.\u00a0 Implementation M is old and predates \"foo\"'s registration, so it uses the text form.\u00a0 Implementation N postdates \"foo\"'s registration and knows to use the integer form for encoding it.\u00a0 But if N insists on the integer form for decoding, it will reject M's tags, and needlessly so.\u00a0 So I think we need a warning that the \"MUST NOT\" is only for encoding, and that decoders MUST accept both forms (at least for names not listed in this document). (2) Section 4.1 contains SHOULD-level guidance to use the \"semver\" version scheme when the value matches the semantic versioning syntax.\u00a0 That seems like it would be highly problematic if the version number only happens to match the syntax by accident and does not actually match the semantic versioning semantics.\u00a0 Shouldn't we be giving recommendations based on the underlying (intended) semantics rather than just the syntax? (A similar concern might apply to the recommendation to use any scheme other than \"alphanumeric\", but there are not really well-known semantics for the \"alphanumeric\" syntax such that expectations of semantics would fail to be met if the wrong version scheme was assigned.) (3) The integer values assigned to link ownership values disagree between Table 5 and the CDDL.\u00a0 (The IANA registry guidance matches Table 5.) I did not attempt to obtain a copy of ISO/IEC 19770-2:2015 to confirm whether it uses integer identifiers that we want to maintain compatibility with -- the prose in \u00a74.3 is a little unclear as to whether such compatibility is relevant since it only talks about \"values\" that are to match. (4) It's quite possible that I'm just confused about one or both of the statements in question, but it seems like there may be some inconsistency between \u00a72.7's \"This specification does not define how to resolve an XPath query in the context of CBOR\" and \u00a75.2's \"This XPath is evaluated over SWID or CoSWID tags found on a system\" (with, IIRC, a couple other relevant mentions elsewhere).\u00a0 My understanding is that a CoSWID tag is intrinsically represented in a CBOR form, so I'm not sure how one could cause an XPath evaluation to match without having defined semantics for evaluating that query in a CBOR context. (5) There are a couple of references to first-come, first-served allocations for SWID index value registrations (e.g., \u00a72's \"new constructs are assigned a unique index value on a first-come, first- served basis\", \u00a76.2.1's \"New index values will be provided on a First Come First Served as defined by [ BCP26 ]\", but I do not see any direction to IANA to create a registry using such an allocation policy for any range of the registry in question.\u00a0 It seems like this indicates some internal inconsistency to be resolved, but I'm not entirely sure what the proper resolution is. (6) Section 6.2.2 attempts to provide a namespaced scheme for distributed allocation of unique (collision-free) names for private-use index values, but I do not think it admits a unique partition into \"domain.prefix\" and \"name\" by treating U+002D HYPHEN-MINUS as a separator, since that character is valid in both LDH hostnames and in NMTOKEN names.\u00a0 This makes it impossible to guarantee uniqueness, since we could have different partitionings of the same consolidated name into the underlying components. (7) We seem to have conflicting statements in \u00a77 about how a signed CoSWID tag is represented.\u00a0 First we say that \"[a] CoSWID tag MUST be wrapped in a COSE Single Signer Data Object (COSE_Sign1) that contains a single signature and MUST be signed by the tag creator\", but just a few paragraphs later we say that \"[t]he COSE_Sign structure that allows for more than one signature to be applied to a CoSWID tag MAY be used\", but following the MAY would violate the MUST.\u00a0 Furthermore(!), the last paragraph of the section says only that \"[a] CoSWID SHOULD be signed, using the above mechanism\", which again is in conflict with the MUST.\u00a0 (Section 8 goes on to admit the possibility of unsigned tags as well as both forms of signed tag, and Section 9 includes \"a signature provided by the supplier if present in the CoSWID tag\".) (8) Table 1 seems to be missing an entry for $$resource-collection-extension, defined in \u00a72.9.2 and appearing in multiple other locations.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-03-21 05:55:01-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 02:28:41-08:00",
    "text": "Hi, Sorry, but I have a couple of issues that it would be helpful to discuss ... 1.\u00a0 While an attempt to align \u00a0  SWID and CoSWID tags has been made here, future revisions of ISO/IEC \u00a0  19770-2:2015 or this specification might cause this implicit \u00a0  information model to diverge, since these specifications are \u00a0  maintained by different standards groups. This text concerns me, in that it seems that the IETF is expecting or allowing the SWID and CoSWID specification to diverge. Would it be possible to have stronger text here? E.g., to indicate:  - the intent is to keep the two spec's consistent.  - nothing should be added to CoSWID without working with ISO/IEC to update CoSWID  - if SWID evolves then CoSWID should be similarly updated. Or, otherwise, are ISO/IEC okay with the IETF effectively forking their specification in future? 2. \u00a0  [SEMVER]\u00a0  Preston-Werner, T., \"Semantic Versioning 2.0.0\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 . I want to check whether this URL is stable enough for a normative reference.\u00a0 During the YANG Semver work we discovered, that despite the Semver specification stating that is follows the Semver rules, in fact it doesn't! Specifically, the specification has been updated without changing the version number.\u00a0 The proposed solution for the YANG semver draft was to reference a specific data and revision of the \"YANG Semver 2.0.0\" specification in github.  the YANG Semver 2.0.0 specification on a given data. \u00a0  [semver]\u00a0  \"Semantic Versioning 2.0.0 (text from June 19, 2020)\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 . Would doing something similar be wise here? Thanks, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-07 11:22:11-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-19 00:14:08-07:00",
    "text": "Thanks to everyone who contributed to this document. --------------------------------------------------------------------------- \u00a79 defines a URI fragment identification scheme that is intended to apply to senml+xml / sensml+xml. Since this uses the \"+xml\" structured syntax suffix, it has to comply with the fragment identifier considerations associated with that suffix. See: https://www.iana.org/assignments/media-type-structured-suffix/media-type-structured-suffix.xhtml In particular, +xml has requirements around citing section 5 of  RFC 7303 (which this document doesn't), as well as requiring support for element() fragments; e.g.: \u00a0 coap:// example.com/temp#element(/1/3) must be allowed as an alias for \u00a0 coap:// example.com/temp#rec=3 If you want to restrict other aspects of XPointerFramework fragment identifiers, I believe you'll have to say so explicitly.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-05-18 09:31:33-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-15 22:13:41-07:00",
    "text": "Hopefully this is easy to address: \u00a74.7\u00a0 talks about how SenML can also be used to configure parameters and controlling actuators. That capability has some rather significant security implications, but I failed to find mention of it in the security considerations. That needs to be explicitly discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-05-18 05:16:27-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-18 19:33:08-07:00",
    "text": "I agree with Ben's DISCUSS. Additionally, I have serious reservations about introducing the concept of \"base fields\" that apply to subsequent array elemnets unless overridden.\u00a0 It seems to violate an abstraction barrier for at least some of the serialization formats, and prevents snippets from being composable and commutable absent the resolution/normalization process.\u00a0 It does not seem like the markup language and the document contain suffient safeguards against misuse to prevent security holes (both sensor data and commands could be misinterpreted).\u00a0 It seems that some substantially expanded text should be added on the hazards of the non-resolved format and giving guidance on when resolution/normalization must be performed in order to avoid correctness and security issues. There also seem to be sizeable risks associated with the semantics for time values.\u00a0 In particular, both with the use of an implicit-\"now-ish\", and with positive and negative values being interpreted with respect to a different absolute time base.\u00a0 (The involvement of base time is a further complication -- I do not remember any discussion of the interaction of a (positive) base time and a negative regular time, for example.\u00a0 I also do not remember any discussion of how the \"now-ish\" semantics make it actively harmful to do things like store-and-forward or archive SenML data (again, absent normalization), or what sort of granularity the \"now-ish\" semantics are expected to adhere to.\u00a0 (Is \"yesterday\" still considered \"roughly now\"?)\u00a0 I understand the desire for this sort of semantics, but the current specification seems to leave many potential problems exposed.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-12-15 07:16:48-08:00",
    "end_reason": "position_updated",
    "start": "2016-08-30 05:25:33-07:00",
    "text": "Thanks for this document. I have today reviewed both  draft-ietf-dnsop-maintain-ds  and  RFC 7344 , and personally find the recommendations and actions reasonable. I do have a similar concern as Robert did in his Gen-ART review, however, in making sure that the change to 7344 is properly highlighted. We should talk about this on the call on Thursday.",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2016-09-28 10:00:52-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-31 09:54:47-07:00",
    "text": "lace holder for the discussion of a standards action for 7344 discussion",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2016-12-12 23:14:28-08:00",
    "end_reason": "position_updated",
    "start": "2016-09-28 10:00:52-07:00",
    "text": "Place holder for the discussion of a standards action for 7344 discussion I'm taking this off agendas until I get an update and the standards action.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-12-15 07:27:34-08:00",
    "end_reason": "position_updated",
    "start": "2016-08-29 06:09:25-07:00",
    "text": "Overall, this draft seems like a very useful and helpful draft.\u00a0 In reading it, I would like to see some security considerations around the methods in section 3, in particular section 3.2, which is the loosest.\u00a0 Just seeing that the domain has been transferred seems like a risky check to rely on to me.\u00a0 The risks of using these proposed methods should be stated.\u00a0 Thanks.",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-12-15 07:43:35-08:00",
    "end_reason": "position_updated",
    "start": "2016-08-30 18:00:33-07:00",
    "text": "Thanks for writing this and I think its useful for DNSSEC adoption, my DISCUSS is as follows. I have a concern about changing the status of  RFC7344  in this document from informational to standards track, especially given that this document builds on, or as I see it updates, 7344. This will surely be raised on the telechat. Especially given I still see gaps in the larger picture, such as: \u00a0 \"In this case there is a possibility of setting up some kind of authentication mechanism and submission mechanism \u00a0  that is outside the scope of this document..\" for enabling DNSSEC via CDS/CDNSKEY Can you please promote the first 2 paragraphs of the security considerations section to either the abstract or introduction. When reading this document I had almost exactly those words echoing in my head, and having them up front would better set the scene for why this document should exist - since you have written them already.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 11:02:39-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-01 08:52:08-07:00",
    "text": "Section 6.10.4: \"The value of the Interface Identifier is left for future definitions.\" I don't understand how this is usable without some definition. I.e., if I assign every interface ID in my ACP to be 0, it's not going to work. Could you elaborate about what is expected in this field?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-08-12 20:46:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-08-12 08:42:37-07:00",
    "text": "I still have more to review here -- I'm about \u2153 of the way through -- but I wanted to get this in sooner, rather than waiting. This DISCUSS should be easy to resolve: it's mostly that I find the text in Section 6.5 related to Bob and Alice to be confusing and unclear.\u00a0 I see that EKR also found it so and asked for the step-by-step diagram, which does help.\u00a0 But I find the whole Bob/Alice thing to be messy and wish you could instead use some functionally descriptive terms for the roles, rather than using arbitrary names that aren't meaningful and lead the reader to say, \"Wait, which one is Bob now?\" Specifically: \u2014 Section 6.5 \u2014 \u00a0 \u00a0 \u00a0 The node with the \u00a0 \u00a0 \u00a0 lower Node-ID in the ACP address of its ACP certificate becomes \u00a0 \u00a0 \u00a0 Bob, the one with the higher Node-ID in the certificate Alice.\u00a0 A \u00a0 \u00a0 \u00a0 peer with an empty ACP address field in its ACP certificate \u00a0 \u00a0 \u00a0 becomes Bob (this specification does not define such peers, only \u00a0 \u00a0 \u00a0 the interoperability with them). What\u2019s with \u201cbecomes Bob\u201d and \u201cAlice\u201d here?\u00a0 Without any introduction I don\u2019t know what\u2019s going on.\u00a0 Do you mean something like, \u2018One node has a lower Node-ID in the ACP address of its ACP certificate than the other.\u00a0 For this discussion, we will call that node \u201cBob\u201d, and the other \u201cAlice\u201d.\u2019 ?\u00a0 Or do you mean something else?\u00a0 And then what does the next sentence mean? \u00a0  For example, originally Bob could have been the initiator of one ACP \u00a0  secure channel protocol that Bob prefers and the security association \u00a0  succeeded.\u00a0 The roles of Bob and Alice are then assigned and the \u00a0  connection setup is completed. Again I\u2019m confused: you\u2019re talking about Bob doing something, and *then* the role of Bob is assigned?\u00a0 What does that mean?\u00a0 How can we talk about Bob doing something before we know who Bob is? And are there no more descriptive terms to use here, as opposed to \u201cBob\u201d and \u201cAlice\u201d?\u00a0 Something like \u201cinitiator\u201d and \u201cresponder\u201d, or whatever, which might be easier to follow? I also have an easy-to-address issue here: \u2014 Section 6.7.3.1.2 \u2014 \u00a0  The IKEv2 Diffie-Hellman key exchange group 19 (256-bit random ECP), \u00a0  listed as a SHOULD, is to be configured, along with the 2048-bit MODP \u00a0  (group 14). I don\u2019t understand the requirement level here, because I\u2019m not sure what \u201cis to be configured\u201d means.\u00a0 You mention \u201cSHOULD\u201d, but then \u201cis to be configured\u201d seems to say that it has to be supported.\u00a0 And you seem to be saying that he same requirement, whatever it is, applies to both group 19 and group 14... but I\u2019m not certain about that.\u00a0 Can you please rephrase this to make the requirements clearer?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-09-11 08:35:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 20:46:02-07:00",
    "text": "This DISCUSS should be easy to resolve: it's mostly that I find the text in Section 6.5 related to Bob and Alice to be confusing and unclear.\u00a0 I see that EKR also found it so and asked for the step-by-step diagram, which does help.\u00a0 But I find the whole Bob/Alice thing to be messy and wish you could instead use some functionally descriptive terms for the roles, rather than using arbitrary names that aren't meaningful and lead the reader to say, \"Wait, which one is Bob now?\" Specifically: \u2014 Section 6.5 \u2014 \u00a0 \u00a0 \u00a0 The node with the \u00a0 \u00a0 \u00a0 lower Node-ID in the ACP address of its ACP certificate becomes \u00a0 \u00a0 \u00a0 Bob, the one with the higher Node-ID in the certificate Alice.\u00a0 A \u00a0 \u00a0 \u00a0 peer with an empty ACP address field in its ACP certificate \u00a0 \u00a0 \u00a0 becomes Bob (this specification does not define such peers, only \u00a0 \u00a0 \u00a0 the interoperability with them). What\u2019s with \u201cbecomes Bob\u201d and \u201cAlice\u201d here?\u00a0 Without any introduction I don\u2019t know what\u2019s going on.\u00a0 Do you mean something like, \u2018One node has a lower Node-ID in the ACP address of its ACP certificate than the other.\u00a0 For this discussion, we will call that node \u201cBob\u201d, and the other \u201cAlice\u201d.\u2019 ?\u00a0 Or do you mean something else?\u00a0 And then what does the next sentence mean? \u00a0  For example, originally Bob could have been the initiator of one ACP \u00a0  secure channel protocol that Bob prefers and the security association \u00a0  succeeded.\u00a0 The roles of Bob and Alice are then assigned and the \u00a0  connection setup is completed. Again I\u2019m confused: you\u2019re talking about Bob doing something, and *then* the role of Bob is assigned?\u00a0 What does that mean?\u00a0 How can we talk about Bob doing something before we know who Bob is? And are there no more descriptive terms to use here, as opposed to \u201cBob\u201d and \u201cAlice\u201d?\u00a0 Something like \u201cinitiator\u201d and \u201cresponder\u201d, or whatever, which might be easier to follow? I also have a few easy-to-address issues here: \u2014 Section 6.7.3.1.2 \u2014 \u00a0  The IKEv2 Diffie-Hellman key exchange group 19 (256-bit random ECP), \u00a0  listed as a SHOULD, is to be configured, along with the 2048-bit MODP \u00a0  (group 14). I don\u2019t understand the requirement level here, because I\u2019m not sure what \u201cis to be configured\u201d means.\u00a0 You mention \u201cSHOULD\u201d, but then \u201cis to be configured\u201d seems to say that it has to be supported.\u00a0 And you seem to be saying that he same requirement, whatever it is, applies to both group 19 and group 14... but I\u2019m not certain about that.\u00a0 Can you please rephrase this to make the requirements clearer? \u2014 Section 6.7.5 \u2014 \u00a0  A baseline ACP node MUST support IPsec natively and MAY support IPsec \u00a0  via GRE.\u00a0 If GRE is supported, it MAY be preferred over native IPec. But Section 6.7.3.2 says: \u00a0  If IKEv2 initiator and responder support IPsec over GRE, it has to be \u00a0  preferred over native IPsec. Which is it?\u00a0 \u201cMAY\u201d be preferred?\u00a0 Or \u201chas to be preferred\u201d? \u2014 Section 6.10.6 \u2014 \u00a0  IANA is asked need to assign a new \"type\" for each new addressing \u00a0  sub-scheme.\u00a0 With the current allocations, only 2 more schemes are \u00a0  possible, so the last addressing scheme MUST provide further \u00a0  extensions (e.g., by reserving bits from it for further extensions). I don\u2019t understand the first sentence.\u00a0 It doesn\u2019t parse, for one thing, so please fix that.\u00a0 And it would be better to clearly match it with the corresponding request in the IANA Considerations section. For the second sentence (the DISCUSS part), I\u2019m very skeptical that this is the right approach: if you\u2019re already acknowledging that \u201conly\u201d 2 schemes are possible now, it seems time *now* to prepare the way for additional ones, rather than waiting.\u00a0 What\u2019s the reasoning for putting in a warning rather than just doing it, especially as you\u2019re setting up a new registry anyway?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-16 15:42:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-01 17:29:51-07:00",
    "text": "This is a really exciting protocol to read about -- the prospect of dropping a bunch of just-manufactured devices in place, spinning up a registrar (and maybe a MASA), and getting a control plane like magic is pretty impressive.\u00a0 That said, I don't believe that this document is ready to publish as-is.\u00a0 I have a list of specific points below for discussion, but it may be more effective to strip down the document a lot (providing a well-defined core protocol and leaving out speculative future work, along the lines of Alissa's comments) and only then start to work on specific rough spots. In particular, in its current form, it's not clear to me why this document is targeting the standards-track -- there are lots of places where determinations of what works best or how to do some things is left for future work.\u00a0 Are there lots of implementations or consumers clamoring for this stuff that it makes sense to go for PS as opposed to Experimental (so as to figure out what works and nail down a slimmer protocol for the standards track)?\u00a0 I see in A.4 that the choice of RPL was motivated by experience with a pre-standard version of ACP; it would have been great to hear more about those deployments in an Implementation Status section (per RFC 7942 ) or the Shepherd writeup. I also think the document needs to be more clear about what security properties it does or does not intend to provide: we hear in the abstract and introduction that ACP will be \"secure\" (and similar platitudes are repeated throughout), but we don't really get a sense of the specifics until Section 4, with ACP5.\u00a0 This has a MUST for authenticated and \"SHOULD (very strong SHOULD)\" be encrypted.\u00a0 But text elsewhere in the document seems to be using \"secure\" to also mean encrypted, and there is even one place that flatly asserts that \"ACP mandates the use of encryption\".\u00a0 This internal inconsistency needs to be resolved, at a minimum, and ideally the intended posture more clearly conveyed.\u00a0 (It's also not really stated under what cases encryption would not be used, so that the \"very strong SHOULD\" could not be a MUST.) Section 3.2 claims that the ACP provides \"additional security\" for bootstrap mechanisms due to the hop-by-hop encryption.\u00a0 But in what sense is actual additional security gained?\u00a0 Against an attacker with what capabilities?\u00a0 If there is security gain from such hop-by-hop encryption, doesn't that point to a weakness in the bootstrap scheme? I think there needs to be some justification of why rfc822Name is chosen over a more conventional structure in the otherName portion of the subjectAltName, which is explicitly designed to be extensible. The requirement in Section 6.1.2 for CRL and OCSP checks seem impossible to satisfy for a greenfield node without non-ACP connectivity, as it must join the ACP domain (and supposedly validate the CRL and OCSP validity before doing so) before establishing an ACP link with its peer, but cannot validate anything with no connectivity. Throughout, the document seems to implicitly conflate authentication with authorization.\u00a0 I understand that the main authorization check is just the domain membership test in Section 6.1.2; nonetheless, as a pedagogical matter I cannot support propagating their conflation. In a few places, the MTI cryptographic mechanisms are under-specified, whether the cipher mode for IKE or the TLS ciphersuites.\u00a0 I have attempted to note these locations in my section-by-section comments. Section 6.11.1.14 places a normative (\"SHOULD\") requirement on the RPL root, but if I understand correctly the RPL root is automatically determined within the ACP, and thus the operator does not a priori know which node will become the RPL root.\u00a0 Am I misunderstanding, or is this effectively placing this requirement on all ACP nodes? The IANA considerations specifically do register SRV.est in the GRASP Objective Names Table, and then follows up with a paragraph that this is only a \"proposed update\".\u00a0 I don't know if there's actually anything problematic here, but the document does need clarity on what is proposed for future work and what is to be done now.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-22 08:50:22-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-16 15:42:01-07:00",
    "text": "[trimming to just the topics still under discussion; no change to the text of the remaining items even though some changes have been made to the document] I think there needs to be some justification of why rfc822Name is chosen over a more conventional structure in the otherName portion of the subjectAltName, which is explicitly designed to be extensible. In a few places, the MTI cryptographic mechanisms are under-specified, whether the cipher mode for IKE or the TLS ciphersuites.\u00a0 I have attempted to note these locations in my section-by-section comments. Section 6.11.1.14 places a normative (\"SHOULD\") requirement on the RPL root, but if I understand correctly the RPL root is automatically determined within the ACP, and thus the operator does not a priori know which node will become the RPL root.\u00a0 Am I misunderstanding, or is this effectively placing this requirement on all ACP nodes?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-01 15:36:19-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 16:46:20-07:00",
    "text": "Hopefully just a couple easy ones... I made a pass over Ekr's ballot comments (nominally on the -16, though some of the quoted text doesn't seem to match up with that version). We're generally in good shape there, but I wanted to check on the point regarding a \"downgrade defense on the meta-negotiation between the protocols\", which in theory would allow an attacker to force the use of IPsec or DTLS or whatever other protocol has a weakness.\u00a0 It seems like there may have been some confusion about DULL vs ACP GRASP in play here, especially with respect to when there might be the possibility of multiple secure channels.\u00a0 My current understanding is that there is not a major issue here, but let's confirm that: DULL GRASP runs only over a local link (using link-local addresses), and as currently defined has the option of flooding advertisements that use either DTLS or IKEv2 to establish the ACP secure channel.\u00a0 DULL GRASP has no cryptographic protections at all, so if there is somehow (e.g., on a multi-access link) an attacker on the link, they could drop or rewrite some announcements to force either DTLS or IKEv2 to be used for secure channel establishment even if the other would normally have been preferred.\u00a0 On directly-connected wired links, such tampering may be unlikely (but not beyond the capabilities of, e.g., a nation-state or well-funded attacker, especially for, e.g., long fiber runs.)\u00a0 By itself, this is not useful, since both DTLS and IKEv2+ESP are believed to be secure, but if some future vulnerability is discovered the downgrade might allow for the vulnerability to be exploited in cases it would not otherwise have been usable.\u00a0 Countermeasures to allow detection of this kind of tampering are possible -- include as part of the DTLS or IKEv2 exchange (or the first operation after it) a preference-ordered list of supported secure channel mechanisms, and bail out if the mechanism being used is not the most-preferred shared mechanism -- but will still fail if the vulnerability in question is sufficiently severe to allow handshake forgery. ACP GRASP is different, in that it (1) runs over the ACP, so any on-path attack to drop/rewrite GRASP would have as a prerequisite an attacker in the ACP, and (2) unicast GRASP is protected end-to-end by TLS.\u00a0 However, it seems like broadcast/flooded ACP GRASP objectives will only have the hop-by-hop ACP protection and so would in theory also be subject to a downgrade attack if there was an in-ACP on-path attacker.\u00a0 It also seems like there's a general expectation that ACP services will run over TLS, and the option of \"TLS *or* DTLS (or something else)\" is not expected to be common, so the existence of a downgrade to a different protocol is rare as well. While I would like to be able to defend against downgrade attacks by an in-ACP on-path attacker, I recognize that it's a defensible position to take that we assume all entities in the ACP to remain secure and just accept the corresponding risks in the case of compromise.\u00a0 Similarly, for \"big iron\" router deployments, physical links are the norm and the DULL GRASP downgrade attack may not be a practical concern; I would again like to have the mechanisms in place to be able to detect downgrade if, for example, deployments broaden to the use of radio technologies, but the absence of such a mechanism does not seem like a critical flaw at this time.\u00a0 So, to be clear, the DISCUSS here is just to be sure that we're all on the same page as to what point Ekr was making and the current state of affairs; given my current understanding, I'm not holding a DISCUSS point for \"add the downgrade-detection mechanism\" (though I do encourage it). It looks like Section 6.1.3 is missing a \"rule 6: verify that the acp-address/prefix in the certificate matches the address being used to talk to the peer\", if I'm reading between the lines properly.\u00a0 (If not, and this is just skew introduced by editing, my comments about references to a non-existent rule 6 apply, see COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-08-01 16:56:34-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D9959 I found this document extremely hard to follow due to a large number of grammar errors. It really needs a very thorough copy-edit pass, which I believe is beyond the RFC-editor's usual process. Ideally, the WG would do this. DETAIL S 6.1.1. >\u00a0 \u00a0 \u00a0 each other.\u00a0 See Section 6.1.2.\u00a0 Acp-domain-name SHOULD be the FQDN >\u00a0 \u00a0 \u00a0 of a DNS domain owned by the operator assigning the certificate. >\u00a0 \u00a0 \u00a0 This is a simple method to ensure that the domain is globally unique >\u00a0 \u00a0 \u00a0 and collision of ACP addresses would therefore only happen due to ULA >\u00a0 \u00a0 \u00a0 hash collisions.\u00a0 If the operator does not own any FQDN, it should >\u00a0 \u00a0 \u00a0 choose a string (in FQDN format) that intends to be equally unique. These rules do not seem to be strong enough. Unless you have disjoint trust anchors, there is a potential for cross-domain attac. S 6.1.2. >\u00a0 \u00a0 \u00a0 See section 4.2.1.6 of [ RFC5280 ] for details on the subjectAltName >\u00a0 \u00a0 \u00a0 field. >\u00a0   >\u00a0  6.1.2.\u00a0 ACP domain membership check >\u00a0   >\u00a0 \u00a0 \u00a0 The following points constitute the ACP domain membership check of a What is the relationship of these rules to the existing 5280 rules? S 6.1.2. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 The peer has proved ownership of the private key associated with >\u00a0 \u00a0 \u00a0 \u00a0  the certifictes public key. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 The peer's certificate is signed by one of the trust anchors >\u00a0 \u00a0 \u00a0 \u00a0  associated with the ACP domain certificate. So you don't allow chaining? It seems later that you say you do, but this language prohibits it. S 6.1.3.1. >\u00a0 \u00a0 \u00a0 The objective value \"SRV.est\" indicates that the objective is an >\u00a0 \u00a0 \u00a0 [ RFC7030 ] compliant EST server because \"est\" is an [ RFC6335 ] >\u00a0 \u00a0 \u00a0 registered service name for [ RFC7030 ].\u00a0 Future backward compatible >\u00a0 \u00a0 \u00a0 extensions/alternatives to [ RFC7030 ] may be indicated through >\u00a0 \u00a0 \u00a0 objective-value.\u00a0 Future non-backward compatible certificate renewal >\u00a0 \u00a0 \u00a0 options must use a different objective-name. EST runs over HTTPS. What is the certificate that the server presents? S 6.4. >\u00a0 \u00a0 \u00a0 information in the ACP Adjacency table. >\u00a0   >\u00a0 \u00a0 \u00a0 The ACP is by default established exclusively between nodes in the >\u00a0 \u00a0 \u00a0 same domain.\u00a0 This includes all routing subdomains.\u00a0 Appendix A.7 >\u00a0 \u00a0 \u00a0 explains how ACP connections across multiple routing subdomains are >\u00a0 \u00a0 \u00a0 special. I must be missing something, but how do you know what the routing domain is of an ACP node? I don't see it in the message above. Is it in some common header? S 6.5. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 Once the first secure channel protocol succeeds, the two peers >\u00a0 \u00a0 \u00a0 \u00a0  know each other's certificates because they must be used by all >\u00a0 \u00a0 \u00a0 \u00a0  secure channel protocols for mutual authentication.\u00a0 The node with >\u00a0 \u00a0 \u00a0 \u00a0  the lower Node-ID in the ACP address becomes Bob, the one with the >\u00a0 \u00a0 \u00a0 \u00a0  higher Node-ID in the certificate Alice. A ladder diagram would really help me here, because I'm confused about the order of events. As I understand it, Alice and Bob are both flooding their AN_ACP objectives. So, Alice sees Bob's and starts trying to connect to Bob. But Bob may not have Alice's objective, right? So, in the case you describe below, she just has to wait for it before she can try the remaining security protocols? I note that you have no downgrade defense on the meta-negotiation between the protocols, so an attacker could potentially force you down to the weakest joint protocol. Why did you not provide a defense here? S 6.7.1.1. >\u00a0 \u00a0 \u00a0 To run ACP via IPsec natively, no further IANA assignments/ >\u00a0 \u00a0 \u00a0 definitions are required.\u00a0 An ACP node that is supporting native >\u00a0 \u00a0 \u00a0 IPsec MUST use IPsec security setup via IKEv2, tunnel mode, local and >\u00a0 \u00a0 \u00a0 peer link-local IPv6 addresses used for encapsulation.\u00a0 It MUST then >\u00a0 \u00a0 \u00a0 support ESP with AES256 for encryption and SHA256 hash and MUST NOT >\u00a0 \u00a0 \u00a0 permit weaker crypto options. This is not sufficient to guarantee interop. Also, this is an odd cipher suite chioice. \u00a0 \u00a0 Why are you requiring AES-256 rather than AES-128? \u00a0 \u00a0 Why aren't you requiring AES-GCM? \u00a0 \u00a0 Why aren't you requiring specific key establishment methods (e.g., ECDHE with P-256...) S 6.7.2. >\u00a0   >\u00a0 \u00a0 \u00a0 To run ACP via UDP and DTLS v1.2 [ RFC6347 ] a locally assigned UDP >\u00a0 \u00a0 \u00a0 port is used that is announced as a parameter in the GRASP AN_ACP >\u00a0 \u00a0 \u00a0 objective to candidate neighbors.\u00a0 All ACP nodes supporting DTLS as a >\u00a0 \u00a0 \u00a0 secure channel protocol MUST support AES256 encryption and MUST NOT >\u00a0 \u00a0 \u00a0 permit weaker crypto options. This is not sufficiently specific to guarantee interoperability. Which cipher suites? Also, why are you requiring AES-256 and not AES-128? S 6.7.3. >\u00a0   >\u00a0 \u00a0 \u00a0 A baseline ACP node MUST support IPsec natively and MAY support IPsec >\u00a0 \u00a0 \u00a0 via GRE.\u00a0 A constrained ACP node that can not support IPsec MUST >\u00a0 \u00a0 \u00a0 support DTLS.\u00a0 An ACP node connecting an area of constrained ACP >\u00a0 \u00a0 \u00a0 nodes with an area of baseline ACP nodes MUST therefore support IPsec >\u00a0 \u00a0 \u00a0 and DTLS and supports threefore the baseline and constrained profile. These MTIs do not provide interop between constrained and baseline nodes, because a baseline node might do IPsec and the constrained node DTLS. S 6.10.2. >\u00a0 \u00a0 \u00a0 \u00a0  hash of the routing subdomain SHOULD NOT be assumed by any ACP >\u00a0 \u00a0 \u00a0 \u00a0  node during normal operations.\u00a0 The hash function is only executed >\u00a0 \u00a0 \u00a0 \u00a0  during the creation of the certificate.\u00a0 If BRSKI is used then the >\u00a0 \u00a0 \u00a0 \u00a0  BRSKI registrar will create the domain information field in >\u00a0 \u00a0 \u00a0 \u00a0  response to the EST Certificate Signing Request (CSR) Attribute >\u00a0 \u00a0 \u00a0 \u00a0  Request message by the pledge. you need to lay out the security assumptions here. It's not difficult to create a new domain with the same 40bit hash. If you have a private CA, this probably isn't an issue, but if you are sharing a public CA, it would allow me to produce a domain with other people's addresses. S 8.1.1. >\u00a0 \u00a0 \u00a0 configured to be put into the ACP VRF.\u00a0 The ACP is then accessible to >\u00a0 \u00a0 \u00a0 other (NOC) systems on such an interface without those systems having >\u00a0 \u00a0 \u00a0 to support any ACP discovery or ACP channel setup.\u00a0 This is also >\u00a0 \u00a0 \u00a0 called \"native\" access to the ACP because to those (NOC) systems the >\u00a0 \u00a0 \u00a0 interface looks like a normal network interface (without any >\u00a0 \u00a0 \u00a0 encryption/novel-signaling). This seems pretty unclear. Is the idea that you connect natively to the ACP Connect node and then it forwards your packets over the ACP? Does that mean they need to be GRASP or whatever? I think that's what you are saying below. S 8.1.5. >\u00a0 \u00a0 \u00a0 interface is physically protected from attacks and that the connected >\u00a0 \u00a0 \u00a0 Software or NMS Hosts are equally trusted as that on other ACP nodes. >\u00a0 \u00a0 \u00a0 ACP edge nodes SHOULD have options to filter GRASP messages in and >\u00a0 \u00a0 \u00a0 out of ACP connect interfaces (permit/deny) and MAY have more fine- >\u00a0 \u00a0 \u00a0 grained filtering (e.g., based on IPv6 address of originator or >\u00a0 \u00a0 \u00a0 objective). Given that this is an important security requirement, it seems like it should be a normative requirement that it be filtered. S 9.1. >\u00a0 \u00a0 \u00a0 same trust anchor, a re-merge will be smooth. >\u00a0   >\u00a0 \u00a0 \u00a0 Merging two networks with different trust anchors requires the trust >\u00a0 \u00a0 \u00a0 anchors to mutually trust each other (for example, by cross-signing). >\u00a0 \u00a0 \u00a0 As long as the domain names are different, the addressing will not >\u00a0 \u00a0 \u00a0 overlap (see Section 6.10). Why does it require the *trust anchors* to trust each other? Can't the endpoints just have the union of the trust anchors. This is way underspecified for actual implementation. S 10.2.1. >\u00a0 \u00a0 \u00a0 registrar can rely on the ACP and use Proxies to reach the candidate >\u00a0 \u00a0 \u00a0 ACP node, therefore allowing minimum pre-existing (auto-)configured >\u00a0 \u00a0 \u00a0 network services on the candidate ACP node.\u00a0 BRSKI defines the BRSKI >\u00a0 \u00a0 \u00a0 proxy, a design that can be adopted for various protocols that >\u00a0 \u00a0 \u00a0 Pledges/candidate ACP nodes could want to use, for example BRSKI over >\u00a0 \u00a0 \u00a0 CoAP (Constrained Application Protocol), or proxying of Netconf. I am finding it very difficult to work out the security properties of this mechanism and the security considerations do not help. What can a malicious registrar do? For that matter, you say \"uncoordinated\", so does that mean anyone in the ACP can just decide to be a registrar? S 11. >\u00a0   >\u00a0  11.\u00a0 Security Considerations >\u00a0   >\u00a0 \u00a0 \u00a0 An ACP is self-protecting and there is no need to apply configuration >\u00a0 \u00a0 \u00a0 to make it secure.\u00a0 Its security therefore does not depend on >\u00a0 \u00a0 \u00a0 configuration. This is not true. You need to configure the trust anchor and the domain name. S 11. >\u00a0 \u00a0 \u00a0 \u00a0  all products. >\u00a0   >\u00a0 \u00a0 \u00a0 There is no prevention of source-address spoofing inside the ACP. >\u00a0 \u00a0 \u00a0 This implies that if an attacker gains access to the ACP, it can >\u00a0 \u00a0 \u00a0 spoof all addresses inside the ACP and fake messages from any other >\u00a0 \u00a0 \u00a0 node. You need to be clear that the security is just group security and that any compromised ACP node compromises the entire system.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-10-07 17:07:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-13 01:19:01-07:00",
    "text": "[ section 2 ] * \"It is the approximate IPv6 counterpart of the IPv4 private address \u00a0 ([ RFC1918 ]).\" \u00a0 I understand the intent but I don't think this statement is complete. I \u00a0 think we shouldn't let this sentence out into the wild as is since it could \u00a0 be read without any context nor even any pretense of interest in nuance. \u00a0 May I suggest: \u00a0 \"It is often thought of as the approximate IPv6 counterpart of the IPv4 \u00a0 private address space ([ RFC1918 ]), though it is in fact meaningfully \u00a0 different in important and subtle ways [and upon which this document relies].\" [ section 6.10.2 ] * Please clarify the table at the end of this section.\u00a0 It looks like only \u00a0 two Types are listed, but should all 4 bit values be present?\u00a0 Where are the \u00a0 Z, F, and V bits in the address? \u00a0 I realize these are defined in the following sections, so it probably \u00a0 suffices to say something like \"The Z, F, and V bits are allocated from \u00a0 within the sub-scheme portion of the address according to the following \u00a0 sections...\" or something. \u00a0 Unassigned/unused Type values should maybe be listed in the table as \u00a0 \"Reserved\"? [ section 8.1.3 ] * Why is an RIO for ::/0 with a lifetime of 0 required?\u00a0 Doesn't it suffice \u00a0 it set the default router lifetime to 0?\u00a0 Separately, are all nodes required \u00a0 to be Type C?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-14 20:02:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 20:01:33-07:00",
    "text": "** As normative behavior is specific for BRSKI (e.g., Section 6.1.5 and 6.1.5.5), please make it a normative reference ** Figure 2\u2019s definition of acp-address is \u2018acp-address = 32HEXLC | \"0\"\u2019.\u00a0 The following text references a 32HEXDIG but that isn\u2019t in the definition of acp-address. -- Section 6.1.2.\u00a0 \u2018Nodes complying with this specification MUST be able to receive their ACP address through the domain certificate, in which case their own ACP domain certificate MUST have the 32HEXDIG \"acp-address\" field.\u2019 -- Section 6.1.3.\u00a0 \u2018The candidate peer certificate's acp-node-name has a non-empty acp-address field (either 32HEXDIG or 0, according to Figure 2).\u2019 ** Precision in bounding the cipher selection.  -- Section 6.7.2.\u00a0 Per \u201cSymmetric encryption for the transmission of secure channel data MUST use encryption schemes considered to be security wise equal to or better than AES256\u201d, which property of AES-256 is being considered for this assessment? -- Section 6.8.2.\u00a0 Per \u201cTLS for GRASP MUST offer TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 and TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 and MUST NOT offer options with less than 256bit AES or less than SHA384\u201d, please state this more precisely. -- Is it that AES-128 shouldn\u2019t be used or that that AES-256 has a certain key strength to which to adhere to? -- Is it that SHA-224 or SHA256 shouldn\u2019t be used (staying in the SHA-2 family) or is it a certain number of bits of security ? ** The text specifies the need for physical controls.\u00a0 Please be more specific on the appropriate degree of that physical control or how that decision should be made; and explicitly explain threat of concern. -- Section 8.1.1.\u00a0 \u201cThus, the ACP connect interface and NOC systems connected to it needs to be physically controlled/secured.\u201d -- Section 8.1.5.\u00a0 \u201c\u2026 the ACP connect link and the nodes connecting to it must be in a contiguous secure\u00a0  environment, hence assuming there can be no physical attack against the devices.\u201d ** (\u201cdiscuss discuss\u201d) Section 8.1.2.\u00a0 What is the normative behavior being specified in this section?\u00a0 Specifically, what is the additional or more restrictive behavior for the circumstance is where an ACP node is virtualized. ** Section 8.2.1.\u00a0 (I\u2019m no ABNF expert \u2026) Per the ABNF in Figure 17, the \u201c//=\u201d notation isn\u2019t valid.\u00a0 I think you want: OLD \u00a0 \u00a0  method //= [ \"DTLS\",\u00a0 \u00a0 port ] NEW \u00a0 \u00a0  method =/ [ \"DTLS\",\u00a0 \u00a0 port ] ** Section 10.2.1.\u00a0 Per \u201cAn attacker will not be able to join the ACP unless having a valid domain certificate, also packet injection and sniffing traffic will not be possible due to the security provided by the encryption protocol.\u201d, please be clearer: -- on path attacker = no packet injection -- on path attacker = only traffic analysis when sniffing -- compromised node = can inject traffic ** Section 11.\u00a0 Per \u201can ACP is self-protecting and there is no need to apply configuration to make it secure\u201d, if this assertion is going to be made: -- please specify the security services/properties in a normative section (not in the informative text in Section 10). -- please also be clear on what configuration is being referenced. ** Section 11.\u00a0 Per the list of factors on which ACP depends, it seems like the following are missing: -- the security properties of the enrollment protocol  -- that the security considerations of EST and BRSKI apply (or if not, why not)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-08-10 18:29:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 20:02:50-07:00",
    "text": "** As normative behavior is specific for BRSKI (e.g., Section 6.1.5 and 6.1.5.5), please make it a normative reference ** Figure 2\u2019s definition of acp-address is \u2018acp-address = 32HEXLC | \"0\"\u2019.\u00a0 The following text references a 32HEXDIG but that isn\u2019t in the definition of acp-address. -- Section 6.1.2.\u00a0 \u2018Nodes complying with this specification MUST be able to receive their ACP address through the domain certificate, in which case their own ACP domain certificate MUST have the 32HEXDIG \"acp-address\" field.\u2019 -- Section 6.1.3.\u00a0 \u2018The candidate peer certificate's acp-node-name has a non-empty acp-address field (either 32HEXDIG or 0, according to Figure 2).\u2019 ** Precision in bounding the cipher selection.  -- Section 6.7.2.\u00a0 Per \u201cSymmetric encryption for the transmission of secure channel data MUST use encryption schemes considered to be security wise equal to or better than AES256\u201d, which property of AES-256 is being considered for this assessment? -- Section 6.8.2.\u00a0 Per \u201cTLS for GRASP MUST offer TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 and TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 and MUST NOT offer options with less than 256bit AES or less than SHA384\u201d, please state this more precisely. -- Is it that AES-128 shouldn\u2019t be used or that that AES-256 has a certain key strength to which to adhere to? -- Is it that SHA-224 or SHA256 shouldn\u2019t be used (staying in the SHA-2 family) or is it a certain number of bits of security ? ** The text specifies the need for physical controls.\u00a0 Please be more specific on the appropriate degree of that physical control or how that decision should be made; and explicitly explain threat of concern. -- Section 8.1.1.\u00a0 \u201cThus, the ACP connect interface and NOC systems connected to it needs to be physically controlled/secured.\u201d -- Section 8.1.5.\u00a0 \u201c\u2026 the ACP connect link and the nodes connecting to it must be in a contiguous secure\u00a0  environment, hence assuming there can be no physical attack against the devices.\u201d ** (\u201cdiscuss discuss\u201d) Section 8.1.2.\u00a0 What is the normative behavior being specified in this section?\u00a0 Specifically, what is the additional or more restrictive behavior for the circumstance is where an ACP node is virtualized. ** Section 8.2.1.\u00a0 (I\u2019m no ABNF expert \u2026) Per the ABNF in Figure 17, the \u201c//=\u201d notation isn\u2019t valid.\u00a0 I think you want: OLD \u00a0 \u00a0  method //= [ \"DTLS\",\u00a0 \u00a0 port ] NEW \u00a0 \u00a0  method =/ [ \"DTLS\",\u00a0 \u00a0 port ] ** Section 10.2.1.\u00a0 Per \u201cAn attacker will not be able to join the ACP unless having a valid domain certificate, also packet injection and sniffing traffic will not be possible due to the security provided by the encryption protocol.\u201d, please be clearer: -- on path attacker = no packet injection -- on path attacker = only traffic analysis when sniffing -- compromised node = can inject traffic ** Section 11.\u00a0 Per \u201can ACP is self-protecting and there is no need to apply configuration to make it secure\u201d, if this assertion is going to be made: -- please specify the security services/properties in a normative section (not in the informative text in Section 10). -- please also be clear on what configuration is being referenced. ** Section 11.\u00a0 Per the list of factors on which ACP depends, it seems like the following are missing: -- the security properties of the enrollment protocol  -- that the security considerations of EST and BRSKI apply (or if not, why not)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:14:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-10 18:29:12-07:00",
    "text": "(pruned down to the remaining issue) ** Section 11.\u00a0 Per the list of factors on which ACP depends, it seems like the following are missing: -- the security properties of the enrollment protocol -- that the security considerations of EST and BRSKI apply (or if not, why not)",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-06-08 17:40:03-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-06 10:34:46-07:00",
    "text": "I'm balloting DISCUSS, but I think that this should be relatively simple to address: The document says things like:\"Today, the management and control plane of networks typically runs in the global routing table, which is dependent on correct configuration and routing.\" and \"Context separation improves security, because the ACP is not \u00a0  reachable from the global routing table. \" The term \"global routing table\" is widely used and understood to mean the global BGP routing table, or Internet global routing table. I understand that you are using it in the \"default VRF\" meaning, but I think that it is really important to clarify / disambiguate this the first time you use it.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-05-04 23:08:44-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-01 23:46:33-07:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Greg Mirsky for the shepherd's detailed write-up including the WG consensus ***and*** the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric # DISCUSS (blocking) As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is just a request to have a discussion on the following topics: ## Section 3 This is probably due to my lack of knowledge about NSH... So, a simple discussion over email will probably be enough to clear my DISCUSS points. RFC 9197  has an incremental tracing (section 4.4.1), how does it impact the length of the IOAM header in this case? Assuming that this header size is increased, I suggest to add some text about increasing the length field of IOAM header. `When a packet with IOAM is received at an NSH based forwarding node such as an Service Function Forwarder (SFF) that does not understand IOAM header, it SHOULD drop the packet.` is actually a copy of  RFC 8300  ```\u00a0  Packets with Next Protocol values not supported SHOULD be silently dropped \u00a0 \u00a0 \u00a0 by default, although an implementation MAY provide a configuration \u00a0 \u00a0 \u00a0 parameter to forward them. ``` and not a new behaviour. So, let's rather be clear and use a structure like \"Per section 2.2 of  RFC 8300 , ...\" followed by the  RFC 8300  text. While very similar to Jim Guichard's DISCUSS point, it is related to another part of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Jim Guichard",
    "end": "2023-05-04 15:27:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-28 12:29:29-07:00",
    "text": "- Section 3:  \u00a0  The IOAM-Data-Fields MUST follow the definitions corresponding to \u00a0  IOAM-Option-Types (e.g., see Section 5 of [ RFC9197 ] and Section 3.2 \u00a0  of [ I-D.ietf-ippm-ioam-direct-export ]) The above reference to  RFC9197  is incorrect although a simple fix. The IOAM-Option-Types are defined in Section 4 of that document not Section 5. Adding a DISCUSS as this reference is important enough to not just be a comment. Note that the same incorrect reference is used later on in Section 3 and must be corrected also.  - Section 3: \u00a0  The operator MUST ensure that all nodes along the service path support IOAM.\u00a0 Otherwise \u00a0  packets with IOAM are likely to be dropped per [ RFC8300 ]. This text needs clarification as  RFC8300  says nothing about IOAM specifically and dropping of OAM packets is discussed in that RFC here ->  https://www.rfc-editor.org/rfc/rfc8300#:~:text=O%20bit%3A%20%20Setting,disabled%20by%20default . The authors should clarify exactly what they mean by the above text and clarify what specifically in  RFC8300  would cause packets to be dropped if a node does not support IOAM.  - IANA Considerations: The text says \"IANA is requested to allocate protocol numbers for the following \"NSH Next Protocol\" related to IOAM\" but there is no reference to the correct registry. NSH Next Protocol allocations can be found here: https://www.iana.org/assignments/nsh/nsh.xhtml#next-protocol  and they are part of the Network Service Header (NSH) Parameters registry. Please provide an accurate reference to the Network Service Header (NSH) Parameters registry for IANA. - Section 5: Another incorrect reference needs to be corrected. \"For additional IOAM related security considerations, see Section 10 in [ RFC9197 ].\". It is actually section 9 of that RFC so please correct the reference.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-05-05 02:42:02-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-02 05:52:37-07:00",
    "text": "Hi, Thanks for this document. A couple of discuss points that I raised only because I find the spec to be unclear which should be be easy to clarify: (1) p 2, sec 3.\u00a0 IOAM encapsulation with NSH \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The operator MUST \u00a0  ensure that all nodes along the service path support IOAM. Is it actually 'all nodes along the service path' or \"SFC aware nodes along the service path\" that MUST support IOAM? (2) p 3, sec 3.\u00a0 IOAM encapsulation with NSH \u00a0 \u00a0 \u00a0 IOAM HDR Len:\u00a0 8 bit Length field contains the length of the IOAM \u00a0 \u00a0 \u00a0 \u00a0  header in 4-octet units. Does this mean quantized to 4 byte units, or that the actual length in bytes is 4 * \"Hdr Len\" field?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-05-04 13:49:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-01 07:36:02-07:00",
    "text": "(revised ballot) ** Section 5. \u00a0  IOAM is considered a \"per domain\" feature, where one or several \u00a0  operators decide on leveraging and configuring IOAM according to \u00a0  their needs. This seems like an an expansion of the applicability statement of IOAM.\u00a0 I don\u2019t see reference to multiple operators in Section 3 of  RFC9197 .\u00a0 Please explicitly cite the  RFC9197  applicability statement to be clear that scope is not being expanded and and consider if discussion of multiple operators is needed.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-03-14 10:51:33-07:00",
    "end_reason": "position_updated",
    "start": "2018-03-07 23:36:39-08:00",
    "text": "\u00a75 contains the following uses of \"SHOULD NOT\": >\u00a0 \u00a0  *\u00a0 The 'Partial IV' parameter.\u00a0 The value is set to the Sender >\u00a0 \u00a0 \u00a0 \u00a0 Sequence Number.\u00a0 All leading zeroes SHALL be removed when >\u00a0 \u00a0 \u00a0 \u00a0 encoding the Partial IV.\u00a0 The value 0 encodes to the byte >\u00a0 \u00a0 \u00a0 \u00a0 string 0x00.\u00a0 This parameter SHALL be present in requests.\u00a0 In >\u00a0 \u00a0 \u00a0 \u00a0 case of Observe (Section 4.2.3.4) the Partial IV SHALL be >\u00a0 \u00a0 \u00a0 \u00a0 present in responses, and otherwise the Partial IV SHOULD NOT >\u00a0 \u00a0 \u00a0 \u00a0 be present in responses.\u00a0 (A non-Observe example where the >\u00a0 \u00a0 \u00a0 \u00a0 Partial IV is included in a response is provided in >\u00a0 \u00a0 \u00a0 \u00a0 Section 7.5.2.) > >\u00a0 \u00a0  *\u00a0 The 'kid' parameter.\u00a0 The value is set to the Sender ID.\u00a0 This >\u00a0 \u00a0 \u00a0 \u00a0 parameter SHALL be present in requests and SHOULD NOT be >\u00a0 \u00a0 \u00a0 \u00a0 present in responses.\u00a0 An example where the Sender ID is >\u00a0 \u00a0 \u00a0 \u00a0 included in a response is the extension of OSCORE to group >\u00a0 \u00a0 \u00a0 \u00a0 communication [ I-D.tiloca-core-multicast-oscoap ]. As far as I can tell, both \"SHOULD NOT\" instances describe behavior that is unnecessary but benign. This usage is inconsistent with the definition of \"SHOULD NOT\" in  RFC 2119 : 4. SHOULD NOT\u00a0  This phrase, or the phrase \"NOT RECOMMENDED\" mean that \u00a0  there may exist valid reasons in particular circumstances when the \u00a0  particular behavior is acceptable or even useful, but the full \u00a0  implications should be understood and the case carefully weighed \u00a0  before implementing any behavior described with this label. If the implications are simply \"this is unnecessary but benign,\" then implementors have no real implications to weigh, and the described behavior doesn't rise to the level of \"SHOULD NOT\". If the implications are stronger than that, then *this* document doesn't contain enough information for implementors to perform such an evaluation. In the former case, you can clear this discuss by changing \"SHOULD NOT\" to \"will not typically\". In the latter case, you can clear this discuss by adding enough information for implementors to be able to make an educated weighing of implications. I'm also open to other proposals that remedy this use of 2119 language.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-09 15:11:23-08:00",
    "end_reason": "position_updated",
    "start": "2018-03-07 18:58:36-08:00",
    "text": "https://mozphab-ietf.devsvcdev.mozaws.net/D3075 DISCUSS My overall concern with this document is that I am unable to evaluate the security properties of the system. I have described a number of issues below, but the basic problem is that this sort of partial protection is extremely hard to reason about and the security considerations do not do an adequate job of evaluating the impact of proxies modifying these values. I am similarly concerned about the HTTP mapping and link section which seems extremely sketchy and has essentially no security analysis, and yet potentially have a lot of landmines. At minimum, this document needs to walk through the implications of modifications by the proxy to every unprotected field in the pure CoAP context as well as the HTTP context (if you want to retain that binding). \u00a0  are given in Appendix A.\u00a0 OSCORE does not depend on underlying \u00a0  layers, and can be used anywhere where CoAP or HTTP can be used, \u00a0  including non-IP transports (e.g., [ I-D.bormann-6lo-coap-802-15-ie ]). \u00a0   IMPORTANT: This document claims to be applicable to protocols other than COAP, in particular HTTP. Has this been reviewed by the HTTP working group? Martin Thomson's review suggests that this is out of step with HTTP practice. \u00a0  IDs MUST be long uniformly random distributed byte strings such that \u00a0  the probability of collisions is negligible. IMPORTANT: I don't understand how this paragraph and the previous paragraph interact. You say that the maximum length is 7 octets in the previous paragraph, which I don't think qualifies as \"long\". \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0  1 | If-Match\u00a0 \u00a0 \u00a0 \u00a0 | x |\u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0  3 | Uri-Host\u00a0 \u00a0 \u00a0 \u00a0 |\u00a0  | x | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0  4 | ETag\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | x |\u00a0  | IMPORTANT: Why do you think that it's not important to have integrity protection for Uri-Host and Uri-port? \u00a0  Outer option message fields (Class U or I) are used to support proxy \u00a0  operations. IMPORTANT: This seems problematic because the proxy cannot verify class I fields. \u00a0  layer only, and not the Messaging Layer (Section 2 of [ RFC7252 ]), so \u00a0  fields such as Type and Message ID are not protected with OSCORE. \u00a0   IMPORTANT: This seems extremely hard to reason about. What are the implications of the proxy being able to change these? \u00a0  o\u00a0 request_piv: contains the value of the 'Partial IV' in the COSE \u00a0 \u00a0 \u00a0 object of the request (see Section 5). \u00a0 \u00a0 \u00a0  IMPORTANT: I think what I am getting here is that the request_piv is used to verify that the request and response match. However, I do not see this explicitly stated anywhere, and it's not clear to me how the client is supposed to recover the request_piv and the text is pretty unclear here? Is the external_aad carried somewhere in the message? Am I supposed to reconstruct it from the message id? \u00a0  For responses, the message binding guarantees that a response is not \u00a0  older than its request.\u00a0 For responses without Observe, this gives \u00a0   IMPORTANT: I am not sure that this is true. What happens of the counterparty lies? What is your threat model? \u00a0  An extension of OSCORE may also be used to protect group \u00a0  communication for CoAP [ I-D.tiloca-core-multicast-oscoap ].\u00a0 The use \u00a0  of OSCORE does not affect the URI scheme and OSCORE can therefore be \u00a0  used with any URI scheme defined for CoAP or HTTP.\u00a0 The application \u00a0  decides the conditions for which OSCORE is required. This is pretty surprising to just drop in here. Multicast has totally different security properties from non-multicast.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-09-26 02:55:52-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 16:41:41-07:00",
    "text": "The Security Considerations is worrisome, as it points to  RFC 5440 ; Section 10.2, which basically recommends TCP-MD5: \u00a0  At the time of writing, TCP-MD5 [ RFC2385 ] is the only available \u00a0  security mechanism for securing the TCP connections that underly PCEP \u00a0  sessions. \u00a0  As explained in [ RFC2385 ], the use of MD5 faces some limitations and \u00a0  does not provide as high a level of security as was once believed.\u00a0 A \u00a0  PCEP implementation supporting TCP-MD5 SHOULD be designed so that \u00a0  stronger security keying techniques or algorithms that may be \u00a0  specified for TCP can be easily integrated in future releases. \u00a0  The TCP Authentication Option [TCP-AUTH] (TCP-AO) specifies new \u00a0  security procedures for TCP, but is not yet complete.\u00a0 Since it is \u00a0  believed that [TCP-AUTH] will offer significantly improved security \u00a0  for applications using TCP, implementers should expect to update \u00a0  their implementation as soon as the TCP Authentication Option is \u00a0  published as an RFC. \u00a0  Implementations MUST support TCP-MD5 and should make the security \u00a0  function available as a configuration option. TCP-AO has now been published as an RFC for quite some time, so it's probably not really appropriate to just point to a document which recommends TCP-MD5.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-03-25 06:11:23-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 19:18:30-07:00",
    "text": "Section 4.5.2: \u00a0  Implementations which choose to generate an alert instead, MUST \u00a0  generate error alerts to avoid attacks where the attacker repeatedly \u00a0  probes the implementation to see how it responds to various types of \u00a0  error.\u00a0 Note that if DTLS is run over UDP, then any implementation I just don\u2019t understand this, despite having hopped over to  RFC 8446  Sections 6 and 6.2. Is the intention that \u201cerror alert\u201d implies closure of the association? That doesn\u2019t seem to be exactly what 8446 says \u2014 it says the receiver of the alert closes the connection, but it doesn\u2019t mandate this for the sender (except in the case of \u201cfatal alert\u201d messages, where \u201cfatal\u201d seems like the exception that proves the rule).  It may be that \u201ceveryone knows\u201d an error alert is the same as termination, but it\u2019s not obvious in the plain English of the text I reviewed. Or maybe I\u2019m barking up the wrong tree and this isn't what the text quoted above is even driving at.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-04-08 13:21:11-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 14:41:54-07:00",
    "text": "In Sec 5.8.2, it is a significant change from DTLS 1.2 that the initial timeout is dropping from 1 sec to 100ms, and this is worthy of some discussion. This violation of  RFC8961  ought to be explored further. For a client first flight of one packet, it seems unobjectionable. However, I'm less comfortable with a potentially large server first flight, or a client second flight, likely leading to a large spurious retransmission. With large flights, not only is a short timeout more dangerous, but you are more likely to get an ACK in the event of some loss that allows you to shortcut the timer anyway (i.e. the cost of long timeout is smaller) Relatedly, in section 5.8.3 there is no specific recommendation for a maximum flight size at all. I would think that applications SHOULD have no more than 10 datagrams outstanding unless it has some OOB evidence of available bandwidth on the channel, in keeping with de facto transport best practice. Finally, I am somewhat concerned that the lack of any window reduction might perform poorly in constrained environments. Granted, doubling the timeout will reduce the rate, but when retransmission is ack-driven there is essentially no reduction of sending rate in response to loss. I want to emphasize that I am not looking to fully recreate TCP here; some bounds on this behavior would likely be satisfactory. Here is an example of something that I think would be workable. It is meant to be a starting point for discussion. I've asked for some input from the experts in this area who may feel differently. - In general, the initial timeout is 100ms. - The timeout backoff is not reset after successful delivery. This allows the \"discovery\" in bullet 1 to be safely applied to larger flights. - For a first flight of > 2 packets, the sender MUST either (a) set the initial timeout to 1 second OR (b) retransmit no more than 2 packets after timeout. - flights SHOULD be limited to 10 packets - on timeout or ack-indicated retransmission, no more than half (minimum one) of the flight should be retransmitted The theory here is that it's responsive to RTTs > 100ms, but small flights can be more aggressive, and large flows are likely to have ack-driven retransmission.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-19 15:22:24-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 09:52:19-07:00",
    "text": "I support Roman's discuss. I don't think this document is sufficiently clear about the limits of the scope of what it's trying to do. An ideal solution in this space would protect both the confidentiality of device configuration in transit and the authenticity (and authorization status) of configuration to be used by the device.\u00a0 This document makes no real effort to do the latter, with the device accepting any configuration file that comes its way and is encrypted to the device's key (or not encrypted, as the case may be), and with no attempt to keep the device's public key secret (which is just as well). I would expect some disucssion of this being highly desirable, but also requiring more complicated machinery (per, e.g., BRSKI and other voucher-based methods) and that this document aims to provide something much simpler, at the cost of only providing limited protection. However, even the confidentiality protection has only a limited realm of applicability, and it seems to fall apart in some plausible threat models. The security considerations rightly note that an attacker with physical access can likely extract the device private key, retrieve the encrypted configuration file, and decrypt the configuration contents.\u00a0 However, I don't think this possibility is necessarily limited to an attacker with physical access.\u00a0 An attacker on the network in the IXP/POP has several routes to getting attacker-controlled configuration on the device, whether by uploading to the configuration server, spoofing the DHCP response to point to the attacker's configuration server, rewriting traffic between the device and the configuration server, etc.\u00a0 Once the attacker has configuration on the device, they have a foothold by which to gain remote access and use whatever interfaces the device provides for decrypting configuration files and learning their contents (potentially even by installing a \"backdoor-type\" access mechanism and then running the normal install process for the legitimate encrypted configuration, and using the backdoor to return and retrieve the plaintext configuration information). While this level of attacker control taking over a device in the process of being installed is not a new attack with the encrypted configuration, it does still limit the extent to which confidentiality protection for configuration data is actually achievable, and I don't think the current document text provides an accurate description of the risk and what protection is provided.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-18 15:19:40-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-05-18 15:19:21-07:00",
    "text": "** Section 3.2.\u00a0 If keying material is being distributed as a certificate, do the expected behaviors of certificate process apply?\u00a0 For example, how is expiration handled? --\u00a0 If a customer downloads a certificate from the publication server and it is expired, what should be done? -- If a certificate is loaded in the TPM of the device, should the client stop accepting configurations if it expires? ** Section 4.3.\u00a0 \u201cAfter retrieving the config file, the device needs to determine if it is encrypted or not.\u00a0 If it is not encrypted, the existing behavior is used.\u201d\u00a0 What downgrade protection is assumed or recommended here.\u00a0 A rogue data center employee could re-target a DHCP response to a server of choice which provides only unencrypted, tainted configuration.\u00a0 It would seem that a device expecting an encrypted configuration should not accepted unencrypted ones (or at least this should be a policy consideration).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-06-24 07:06:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-18 15:19:40-07:00",
    "text": "** Section 3.2.\u00a0 If keying material is being distributed as a certificate, do the expected behaviors of certificate process apply?\u00a0 For example, how is expiration handled? --\u00a0 If a customer downloads a certificate from the publication server and it is expired, what should be done? -- If a certificate is loaded in the TPM of the device, should the client stop accepting configurations if it expires? ** Section 4.3.\u00a0 \u201cAfter retrieving the config file, the device needs to determine if it is encrypted or not.\u00a0 If it is not encrypted, the existing behavior is used.\u201d\u00a0 What downgrade protection is assumed or recommended here.\u00a0 A rogue data center employee could re-target a DHCP response to a server of choice which provides only unencrypted, tainted configuration.\u00a0 It would seem that a device expecting an encrypted configuration should not accepted unencrypted ones (or at least this should be a policy consideration).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-05 07:46:13-08:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 07:16:02-08:00",
    "text": "Please let me know if I've misunderstood the test execution protocol incorrectly: Section 6.\u00a0 Per the paragraph \u201cThe evaluation of the test cases are intended to carry out in a controlled lab environment \u2026 It is important to take appropriate caution to avoid leaking non-responsive traffic from unproven congestion avoidance techniques onto the open Internet\u201d, this is good guidance in general case.\u00a0 However, in the case of this document how applicable is it?\u00a0 Didn\u2019t Section 3 (\u201cWe, therefore, recommend that a cellular network simulator is used for the test cases defined in this document \u2026\u201d and practically establish it can\u2019t be done without simulation with the scenario of the underground mine) and Section 4 (\u201cWe recommend to carry out the test cases as defined in this document using a simulator, such as [NS-2] or [NS-3]).\u00a0  If all the testing is supposed to be in a simulator how is it leaking out onto the internet?\u00a0 As far as I can tell, this helpful text is common in RMCAT document, but in this case could it please be tailored for the proposed testing regime.\u00a0  Perhaps something on the order adding text on the order of \u201cGiven the difficulty of deterministic wireless testing, it is RECOMMENDED and expected that the tests described in this document would be done via simulation.\u00a0 However,\u00a0 \u201d",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-03-09 13:08:41-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-08 17:15:36-08:00",
    "text": "Thanks for your work on this document. I'd like to discuss what it says about ISOC's role. In \u00a73.11 regarding ISOC, we have \u00a0  Internet standardization is an organized activity of the Internet \u00a0  Society (ISOC), with the Board of Trustees being responsible for \u00a0  ratifying the procedures and rules of the Internet standards process \u00a0  [ISOCIETF]. Looking at ISOCIETF, I don\u2019t see this in plain language anywhere. The strings \u201crules\u201d and \u201cratify\u201d don\u2019t appear, and \u201cprocedure\u201d doesn\u2019t appear anywhere relevant. The primary relevant section is \u00a74, \u201cISOC's Role in the IETF Standards Process\u201d, which lists several specifics in the first paragraph: \u00a0  ISOC plays a small role in the IETF standards process.\u00a0 In \u00a0  particular, ISOC assists the standards process by appointing the IETF \u00a0  NomCom chair and by confirming IAB candidates who are put forward by \u00a0  the IETF NomCom, as described in [ RFC8713 ], and by acting as the last \u00a0  resort in the appeals process, as described in [ RFC2026 ]. There are also indirect things mentioned later (liaisons, indirect support programs). But none of these things seem to rise to the level of \u201cratifying the procedures and rules of the Internet standards process.\u201d We also have, in \u00a76 of ISOCIETF, some words about the IETF Trust, ending in \u00a0 \u00a0 \u00a0 One of the IETF \u00a0  Trust's trustees is appointed by the ISOC's Board of Trustees. This, again, doesn\u2019t seem to rise to the level of \u201cratifying the procedures and rules of the Internet standards process.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-03-10 07:53:27-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-08 23:17:06-08:00",
    "text": "his doc has a DOWNREF to Informational draft-iab-rfcedp-rfced-model,which I failed to include in the Last Call message.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-09 14:40:57-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 12:59:19-08:00",
    "text": "A minor note, but IMO an important one: The document says it is about the production of \"IETF standards\", which I believe is a term being used colloquially. I would like the Introduction to be a bit more clear about whether the scope of this is (1) Production of Standards Track documents; (2) Production of IETF stream documents; or (3) Production of RFCs If (1) or (2), the text about the IRTF stream in (3.7) is out of scope. If the answer is (3), there ought to be an ISE section and a sentence about the IAB stream. Regardless of which, as this is an introductory document, the introduction would usefully help to disambiguate those concepts.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-03-11 16:01:31-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-03-10 08:02:53-08:00",
    "text": "Huge apologies on DISCUSSing this so late in the process. I completely missed this until it was pointed out. I have 2 issues, one is editorial, but sufficiently important that it reaches DISCUSS level.  The document uses the singular Editor and Author (and similar) -- it does says: \"This document refers to individual roles in the singular, such as \"a Document Editor.\" and then mentions that \"many roles are filled by more than one person at the same time\" with a reasonable justification for this. I'd like to DISCUSS this decision -- I've very concerned that newcomers to the process (and outsiders) will search for things like \"IETF author\" or \"editor\" or similar (e.g Chair), and only read the descriptions, not the terminology / disclaimer at the top. Again, I understand that this was done for clarity, but suspect that the audience was for the IETF community, and the potential for confusion by outsiders and newcomers was not considered. I think that the (much messier) \"The Document Editor(s) or Author(s)\" or \"The Document Editors or Authors\" or similar. In addition, a related issue is: \"When a document is composed and edited mainly by an individual, they may be referred to as the Document Author.\" This very strongly implies (or even states) that, if there is more than one person writing this, then they are not authors / that you cannot have more than one person being referred to as Document Authors. This certainly doesn't agree with my understanding.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-03-13 14:30:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-11 16:01:31-08:00",
    "text": "Thank you for addressing my concerns. Also: Argh! I replied to Rich thanking him for the changes, but forgot to actually remove the DISCUSS position; apologies for the delay.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-09-17 15:25:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-27 08:24:44-07:00",
    "text": "Hopefully this first point is simple to resolve (whether by changing text or merely un-confusing me).\u00a0 The other ones may require some actual discussion, though. Section 6.6.1.2 has: \u00a0  After a DSO Session is ended by the server (either by sending the \u00a0  client a Retry Delay message, or by forcibly aborting the underlying \u00a0  transport connection) the client SHOULD try to reconnect, to that \u00a0  service instance, or to another suitable service instance, if more \u00a0  than one is available. which seems to contradict the text from Section 3: %\u00a0 [...] Given that these fatal error %\u00a0 conditions signify defective software, and given that defective %\u00a0 software is likely to remain defective for some time until it is %\u00a0 fixed, after forcibly aborting a connection, a client SHOULD refrain %\u00a0 from automatically reconnecting to that same service instance for at %\u00a0 least one hour. Given some other mentions in the document about aborting the connection, it may be that I am just reading the \"refrain from reconnecting for an hour\" more strongly than I should be. Is Section 5.1.2 expected to be considered an \"application protocol profile\" that defines the use of TLS 1.3 0-RTT data for DSO?\u00a0 (If so, I do not personally feel that it provides adequate treatment to be considered as such.) I should probably leave this to my (transport-area?) colleagues to discuss further, but I'm not sure that the interaction of this mechanism with high-RTT connections is fully covered -- for example, the inactivity timeout in Section 6.4(.x) could behave poorly when the timeout is set to a smaller value than the RTT, as the server would potentially end up starting the \"forcibly abort\" process (and potentially causing the client to lose for an hour) because the server's timer starts when it sends the DSO response that initiates its idea of the session, and would not recieve graceful shutdown messages from a properly-behaving client in time. I'm not sure that the behavior specified in Section 7.1.2 is entirely safe. Consider when a client sends a DSO keepalive to try to request a DSO session, but subsequently sends EDNS(0) TCP Keepalive (whether \"just in case\" or for some other reason).\u00a0 The Server will receive the DSO keepalive and respond, creating a session, but the EDNS(0) TCP Keepalive is already in flight.\u00a0 I don't remember seeing any text that prevents this client behavior explicitly, but that seems like the right sort of thing to do.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-01 08:52:07-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-17 15:25:26-07:00",
    "text": "Thank you for resolving most of my DISCUSS points (the additional clarification about when the one-hour retry does (not) apply in particular is helpful even if not strictly needed).\u00a0 However, it seems that my point about an \"application protocol profile\" for TLS 1.3 0-RTT was deferred until the resolution of a different thread covering 0-RTT, but that we never picked it back up.\u00a0 I think this document's profile needs to provide greater clarity about what specific messages are (or are not) allowed in 0-RTT data, i.e., listing permitted TLVs and having a column in the registry for whether a TLV is 0-RTT-safe.\u00a0 For example, Retry Delay simply cannot appear in a DSO message that is eligible for 0-RTT, so it accordingly cannot appear in a 0-RTT message, while EncryptionPadding should be safe to appear [as an additional TLV], provided there is a suitable primary TLV to attach it to.\u00a0 On first look [after long absence], the keepalive TLV should be safe to use as a 0-RTT primary TLV, since it elicits a response and only affects the current connection.\u00a0 Anyway, my main point here is that we need to place the burden of analysis on a TLV's safety on the authors of the spec introducing that TLV, and not on implementors or users of the protocol.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-07-30 12:25:44-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-30 11:12:34-07:00",
    "text": "In addition to the bullet point in the 6.2 that was flagged by Spencer, I would like to discuss the content of secton 5.4.\u00a0 DSO Response Generation. I understand the desire to optmize for the case where the application knows that no data will be sent as reply to a certain message. However, TCP does not have a notion of message boundaries and therfore cannot and should not act based on the reception of a certain message. Indicating to the TCP that an ACK can be set immediately in an specfic situation is also problematic as ACK processing is part of the TCP's internal machinery. However, why it is important at all that an TCP-level ACK is send out fast than the delayed ACK timer? The ACK receiver does not expose the information when an ACK is received to the application and the delayed ACK timer only expires if no further data is received/send by the ACK-receiver, therefore this optimization should not have any impact in the application performance. I would just recomend to remove this section and any additional discussion about delayed ACKs. Please note that the problem described in [NagleDA] only occurs for request-repsonse protocols where not further request can be sent before the response is received. This is not the case in this protocol.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-07-30 13:19:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-30 12:25:44-07:00",
    "text": "1) In addition to the bullet point in the 6.2 that was flagged by Spencer, I would like to discuss the content of secton 5.4.\u00a0 DSO Response Generation. I understand the desire to optmize for the case where the application knows that no data will be sent as reply to a certain message. However, TCP does not have a notion of message boundaries and therfore cannot and should not act based on the reception of a certain message. Indicating to the TCP that an ACK can be set immediately in an specfic situation is also problematic as ACK processing is part of the TCP's internal machinery. However, why it is important at all that an TCP-level ACK is send out fast than the delayed ACK timer? The ACK receiver does not expose the information when an ACK is received to the application and the delayed ACK timer only expires if no further data is received/send by the ACK-receiver, therefore this optimization should not have any impact in the application performance. I would just recomend to remove this section and any additional discussion about delayed ACKs. Please note that the problem described in [NagleDA] only occurs for request-repsonse protocols where not further request can be sent before the response is received. This is not the case in this protocol. 2) Furthe regarding keep-alives in sec 6.5.2: \"For example, a hypothetical keepalive interval \u00a0  value of 100ms would result in a continuous stream of at least ten \u00a0  messages per second, in both directions, to keep the DSO Session \u00a0  alive.\" This does not seems correct. There should be at max one keep-a-lives message in flight. Thus the keep-lives timer should be restarted when the keep-alive reply was receiced.  Also: \"And, in this extreme example, a single packet loss and \u00a0  retransmission over a long path could introduce a momentary pause in \u00a0  the stream of messages, long enough to cause the server to \u00a0  overzealously abort the connection.\" This doesn't really make sense to me: As I said, TCP will retransmit and the keep-alives timer should not be running until the reply is receiced. if you want to abort the connection based on keep-alives quickly before the TCP connection indicates you a failure, you need to wait at minimum for an interval that is larger than the TCP RTO (with is uaually 3 RTTs).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-12-06 14:08:59-08:00",
    "end_reason": "position_updated",
    "start": "2018-07-30 13:19:15-07:00",
    "text": "1) In addition to the bullet point in the 6.2 that was flagged by Spencer, I would like to discuss the content of section 5.4.\u00a0 (DSO Response Generation). I understand the desire to optimize for the case where the application knows that no data will be sent as reply to a certain message, however, TCP does not have a notion of message boundaries and therefore cannot and should not act based on the reception of a certain message. Indicating to the TCP that an ACK can be set immediately in an specific situation is also problematic as ACK processing is part of the TCP's internal machinery. However, why it is important at all that an TCP-level ACK is send out fast than the delayed ACK timer? The ACK receiver does not expose the information when an ACK is received to the application and the delayed ACK timer only expires if no further data is received/send by the ACK-receiver, therefore this optimization should not have any impact in the application performance. I would just recommend to remove this section and any additional discussion about delayed ACKs. Please note that the problem described in [NagleDA] only occurs for request-response protocols where no further request can be sent before the response is received. This is not the case in this protocol (as pipelining is supported). 2) Further regarding keep-alives: in sec 6.5.2: \"For example, a hypothetical keepalive interval \u00a0  value of 100ms would result in a continuous stream of at least ten \u00a0  messages per second, in both directions, to keep the DSO Session \u00a0  alive.\" This does not seems correct. There should be at max one keep-alives message in flight. Thus the keep-laives timer should only be restarted after the keep-alive reply was received.  Also: \"And, in this extreme example, a single packet loss and \u00a0  retransmission over a long path could introduce a momentary pause in \u00a0  the stream of messages, long enough to cause the server to \u00a0  overzealously abort the connection.\" This doesn't really make sense to me: As I said, TCP will retransmit and the keep-alive timer should not be running until the reply is received. If you want to abort the connection based on keep-alives quickly before the TCP connection indicates you a failure, you need to wait at minimum for an interval that is larger than the TCP RTO (with is uaually 3 RTTs) which means you basically need to know the RTT. Also sec 7.1: \"If the client does not generate the \u00a0 \u00a0 \u00a0 mandated keepalive traffic, then after twice this interval the \u00a0 \u00a0 \u00a0 server will forcibly abort the connection.\" Why must the server terminate the connection at all if the client refuses to send keep-alives? Isn't that what the inactivity timer is meant for? Usually only the endpoint that initiates the keep-alive should terminate the connection if no response is received. 3) There is another contraction regarding the inactive timer: Sec 6.2 say \"A shorter inactivity timeout with a longer keepalive interval signals \u00a0  to the client that it should not speculatively keep an inactive DSO \u00a0  Session open for very long without reason, but when it does have an \u00a0  active reason to keep a DSO Session open, it doesn't need to be \u00a0  sending an aggressive level of keepalive traffic to maintain that \u00a0  session.\" which indicates that the client may leave the session open longer than indicated by the inactive timer of the server. However section 7.1.1 say that the client MUST close the connection when the timer is expired.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2018-08-02 06:43:10-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-26 21:28:46-07:00",
    "text": "I really like this document, and think it's headed the right direction. Of course I have four pages of comments, because reasons, but the only part I'm really confused about is this one ... I would have thought that if you end up with a different endpoint because your anycast address now resolves differently, the new endpoint would have to have shared a lot of state with the previous endpoint, for this to work: \u00a0 When an anycast service is configured on a particular IP address and \u00a0  port, it must be the case that although there is more than one \u00a0  physical server responding on that IP address, each such server can \u00a0  be treated as equivalent.\u00a0 If a change in network topology causes \u00a0  packets in a particular TCP connection to be sent to an anycast \u00a0  server instance that does not know about the connection, the normal \u00a0  keepalive and TCP connection timeout process will allow for recovery. What I would have expected to happen, is that the new endpoint sees a packet arrive that's not on a synchronized TCP connection, and immediately responds with a RST (reset), rather than the normal keepalive and TCP connection timeout process happening. That's also the way I'm reading  https://tools.ietf.org/html/rfc7828#section-3.6 . Is that not the way it's working for anycast these days?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-27 05:21:24-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 21:25:55-07:00",
    "text": "An easy item to address.\u00a0 Per Section 5,\u00a0 \u201cSpecifically, TE traffic may be delivered to the wrong tail-end router, which could lead to suboptimal routing or even traffic loops\u201d, the impact could also include providing access to an attacker.\u00a0 Perhaps: OLD: Specifically, TE traffic may be delivered to the wrong tail-end router, which could lead to suboptimal routing or even traffic loops. NEW: Specifically, TE traffic may be delivered to the wrong tail-end router, which could lead to suboptimal routing; traffic loops; or expose the traffic to attacker inspection or modification.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2021-02-23 12:56:07-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 06:16:52-07:00",
    "text": "Let's resolve the document status issue -- it was last-called as Proposed Standard, it's listed as Informational, but it seems like it should be a BCP. I support Rob's DISCUSS and I believe the  RFC 8174  boilerplate should be used.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-02-09 23:41:21-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 04:16:07-07:00",
    "text": "Thank you for the work put into this easy-to-read document.  I support Erik Kline's DISCUSS points.  Please find below a couple of non-blocking COMMENT points and one nit but please also check: -\u00a0 Suresh Krishnan's IoT directorate review:   https://datatracker.ietf.org/doc/review-ietf-v6ops-cpe-slaac-renum-05-iotdir-telechat-krishnan-2020-10-21/ - Sheng Jiang's Internet directorate review:    https://datatracker.ietf.org/doc/review-ietf-v6ops-cpe-slaac-renum-05-intdir-telechat-jiang-2020-10-19/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == As observed by Sheng in his review and by Rob Wilton, the use of normative-looking \"MUST\" is unusual in an informational document even with the section 2 about requirement languages as the use of uppercase could confuse the reader; or at least limit their use in the L-* text in section 3. Also, note that  RFC 2119  has been updated by  RFC 8174 .\u00a0 The precedent set by  RFC 7084  seems a bad one. I will trust the responsible AD decision on this topic.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-24 22:21:34-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-21 22:37:27-07:00",
    "text": "[ section 3.2 ] * I absolutely agree in principle at these other lifetimes should be updated \u00a0 to the shorter of the two applicable lifetimes, but I'm worried that this \u00a0 text is not sufficiently precise.\u00a0 Specifically, this recommendation only \u00a0 applies to options that depend in any way on the change in the delegated \u00a0 prefix, yes?\u00a0 Perhaps just this qualifier is sufficient? \u00a0 For example, none of these comparative lifetime recommendations apply to \u00a0 a stable ULA for a router that meets requirements ULA-[1..5] and chooses \u00a0 to advertise a ULA /48 RIO and maybe even a ULA DNS server, I think. \u00a0 That being said, should this document also be saying that the ULA-derived \u00a0 options SHOULD prefer the ND_{P,V}_LIMIT lifetime values, in case a reboot \u00a0 causes a new ULA to be generated (i.e. the one supposedly in stable storage \u00a0 is lost or otherwise unrecoverable)?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-02-22 02:20:32-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-19 11:49:24-07:00",
    "text": "Hi, Hopefully this isn't hard to resolve, but I don't understand the meaning of the text in section 2: \u00a0 \u00a0 2.\u00a0 Requirements Language \u00a0 \u00a0 \u00a0  Take careful note: Unlike other IETF documents, the key words \"MUST\", \u00a0 \u00a0 \u00a0  \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \u00a0 \u00a0 \u00a0  \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are not used as \u00a0 \u00a0 \u00a0  described in [ RFC2119 ].\u00a0 This document uses these keywords not \u00a0 \u00a0 \u00a0  strictly for the purpose of interoperability, but rather for the \u00a0 \u00a0 \u00a0  purpose of establishing industry-common baseline functionality.\u00a0 As \u00a0 \u00a0 \u00a0  such, the document points to several other specifications (preferable \u00a0 \u00a0 \u00a0  in RFC or stable form) to provide additional guidance to implementers \u00a0 \u00a0 \u00a0  regarding any protocol implementation required to produce a \u00a0 \u00a0 \u00a0  successful CE router that interoperates successfully with a \u00a0 \u00a0 \u00a0  particular subset of currently deploying and planned common IPv6 \u00a0 \u00a0 \u00a0  access networks. \u00a0 \u00a0 \u00a0  Note: the aforementioned terms are used in exactly the same way as in \u00a0 \u00a0 \u00a0  [ RFC7084 ], with the above explanation copied verbatim from \u00a0 \u00a0 \u00a0  Section 1.1 of [ RFC7084 ]. This paragraph tells me how these words are not used. But it doesn't seem to explain how they are meant to be interpreted. My only assumption is that these words have no special meaning in this document at all, but they than raises the question as to why not to write them all in lower case.\u00a0 Alternatively, following the standard  RFC 2119  rules and boilerplate would also seem to make sense ...",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-04-22 14:27:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 07:11:27-08:00",
    "text": "I am balloting DISCUSS because I believe that the document is missing important considerations/details related to the operation of Babel in a network.\u00a0 I hope these points should be easy to address. This draft describes destination-first forwarding.\u00a0 If I understand correctly, for the table in \u00a74: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  destination\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 source\u00a0 \u00a0  next-hop \u00a0 \u00a0 \u00a0  2001:DB8:0:1::/64\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ::/0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 A \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ::/0\u00a0 \u00a0  2001:DB8:0:2::/64\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 B ...and the example presented of a \"source 2001:DB8:0:2::42 and destination 2001:DB8:0:1::57\", the result is that the packet is forwarded to A.\u00a0 Is this the correct interpretation?\u00a0 If so, then I believe there are important assumptions made that are not mentioned.\u00a0  In line with this document being \"applicable to small networks\" (\u00a71),  BCP 84 /\u00a74.3 recommends the following:  \u00a0  For smaller edge networks that use provider-based addressing and \u00a0  whose ISPs implement ingress filters (which they should do), the \u00a0  third option is to route traffic being sourced from a given \u00a0  provider's address space to that provider. Given that the draft provides no details, I assume that being \"compatible with [ BCP84 ]\" (\u00a71) means at least that Babel nodes aim to \"route traffic being sourced from a given provider's address space to that provider\". (a) While I understand the table above is just an example, it can be interpreted as indicating that B is the provider that assigned the 2001:DB8:0:2::/64 prefix.\u00a0 If traffic sourced from that prefix is sent to A, then there's a good chance that the packet will be dropped (in line with  BCP 84 ,  BCP 38 , etc.). Maybe the table is not intended to illustrate the routing table at a multihomed edge router. Still, it shows how easy it is to define a policy that may not result in the expected behavior because of the destination-first operation.\u00a0 Please add some guidance on the advertisements and how they may interact in the routing table.\u00a0  Note that what I'm asking for may just be a good example of what to do/not to do.\u00a0  rfc8678 /\u00a75 presents an example of how the forwarding table is constructed based on a set of routes -- something like that would be great! (b) How is the source address selected by the host?\u00a0  rfc8678  uses guidance from  rfc8028  and other RFCs as part of a set of \"Mechanisms for Hosts To Choose Good Default Source Addresses in a Multihomed Site\".\u00a0  rfc8678  significantly differs from this document in that it assumes source-first forwarding when discussing the selection of the source address.\u00a0 Are any of the recommendations in  rfc8678  applicable here? I may be missing something, but it seems to me that the current standards-based recommendations/mechanisms don't easily apply to this specification.\u00a0 I don't think there's anything wrong with doing things a different way -- but I expect those differences to be explicitly explained. SS-ROUTING suggests a trial-and-error mechanism: for \"destination addresses...the sending host tries them all...similarly, all possible source addresses are tried in turn.\"\u00a0 Is that the expectation here? Even though this document is about Babel and not the host, I would like to see a (short) discussion about how the host is expected to behave (or what it needs to consider) in light of the destination-first operation.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-05 01:32:40-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 23:48:21-08:00",
    "text": "Thank you for the work put into this document. The document is easy to read albeit not always clear and specific (see later). The topic of source address dependent routing is really critical for IPv6 deployment, so, I really appreciate your work on the topic Please find below one blocking DISCUSS point (trivial to fix), some non-blocking COMMENT points, and some nits. I also second Warren's DISCUSS on the lack of clarity in the section 4 example I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Please update IPv6 reference from  RFC 2460  to  RFC 8200 : I told you that this was an easy to fix DISCUSS point",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-04-21 08:18:36-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 17:24:14-08:00",
    "text": "I am concerned about the congestion implications of this architecture. If there are P prefixes in the network, the number of TLVs exchanged potentially goes from P to P^2. Perhaps this is an unrealistic use case. But are there any safeguards in the protocol against this happening (e.g. limitations on size/freq of updates?) Or ought there to be some operational guidance to be somewhat selective about source prefixes?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-04-21 10:15:57-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 05:08:14-08:00",
    "text": "Please see the comment below for further description. My specific discuss issue relates to clarifying the indexes of the 'source' and 'route' tables to indicate whether they are replacing the 'prefix-len' elements of the existing 3 tuple indexes, or adding additional elements to the existing index, effectively making them 5 tuple indexes.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-04-21 07:46:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 15:24:31-08:00",
    "text": "I apologize for being rushed, and not balloting earlier, but I feel like I must have missed something fundamental here. The example in Section 4 (Data Forwarding) illustrates an issue, but doesn't actually *state* which (A or B) next hop will be used.  The text then says that: \"A Babel implementation MUST choose routing table entries by using the so-called destination-first ordering,\". I interpret this to mean that the packet \"with source 2001:DB8:0:2::42 and destination 2001:DB8:0:1::57\" should use next-hop A. This means that you will be sending the packet to the destination with no regard for if the provider connected to next-hop A carries/announces 2001:DB8:0:2::/64. If if it doesn't, this will look like a spoofing attack, and the ISP will (rightly) drop it.  The only way that I can see this working is if: 1: destination routes never point \"outside\" the network (and so will never hit inbound  BCP38  filters) or 2: destination routes always \"match\" - if you install x:y:z::/q pointing at next-hop A, you also install the same router pointing at next-hop B (this is pointless). Please help me understand what I'm missing here -- routing on destination to an ISP (which is what I'm assuming based on the \"small networks\" statement) seems like it will route packets with ISP B sources addresses to ISP A, running into  BCP38 /anti-spoofing filters.  BCP84  also covers a number of scenarios - it sounds like you are referring to Section 4.3.\u00a0 Send Traffic Using a Provider Prefix Only to That Provider, but that is exactly what is not happening above. Again, I'm assuming that I'm just missing something blindingly obvious here, but it would be good to figure out what, so the document can be clarified and others don't fall into the same trap...",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-06-29 15:23:42-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-05 02:55:14-07:00",
    "text": "Thank you for writing this document on this important issue. I want to recommend its approval as an RFC and will do so  shortly, but a Gen-ART review from Paul Kyzivat  inspired me to read the document, and I have  some comments. I'm not necessarily looking for  document changes, but I am looking for some responses  to Paul's or my comments, to make sure we all agree that we are doing this right. Specifically, > A detailed description of how these oscillations can occur > can be found in [ RFC3345 ]; the description of how a node would > locally detect such condition is outside the scope of this document. I am not an expert on this topic, but I'd like to understand the nature of such detection algorithms. How hard problem is that? What is required? I'm not looking for specifying or even referring to the algorithm here, but it would be beneficial at least for this reader to understand the nature of the class of solutions referred to here. Are solutions algorithmically computable? Heuristic? Dependent on specific configurations? Vendor solutions exist but aren't documented. > When the ADD-PATH Capability is also received from > the IBGP peer with the \"Send/Receive\" field set to 1 (receive > multiple paths) or 3 (send/receive multiple paths) for the same\u00a0 SAFI>, then the following procedures shall be followed: >  > If the peer is a route reflection client, the route reflector SHOULD > advertise to the peer the Group Best Paths (or the Available Paths) > received from its non-client IBGP peers.\u00a0 Depending on the > configuration, the route reflector MAY also advertise to the peer the > Group Best Paths (or the Available Paths) received from its clients. I am picking this text excerpt as an example. Like Paul, some of this language makes me slightly uncomfortable, and it would be good to understand what the aim is. If the intent is to describe a procedure that can be followed and fully specified, the expectations on the text are different from an informative description of the kinds of things an implementation could do. In the above text, there's quite a lot of imprecision. That may be fine, but I wanted to check that this is the case. For instance, why is a \"shall\" (and in lowercase) followed by a set of \"SHOULD\"s and \"MAY\"s? Is there any guidance on when the \"SHOULD\"s should be followed? There seems to be thinking behind, could that be documented? What kind of configuration issues affect the decisions?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-05-24 11:51:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-23 20:29:36-07:00",
    "text": "Blocking Issue 1: I am truly concerned that the shepherd's write up implies that there has been a failure by some authors to comply with IETF IPR rules laid out in  BCP 79 . I do not believe the IETF can publish a document under such circumstances. Blocking Issue 2: This document is at odds with  BCP 72 , and is inappropriate for publication with its current security considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-05-25 07:36:26-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-24 11:51:49-07:00",
    "text": "[removed issue regarding author IPR declarations based on\u00a0 and ] Blocking Issue: This document is at odds with  BCP 72 , and is inappropriate for publication with its current security considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-05-25 07:33:42-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-23 23:38:04-07:00",
    "text": "I agree with Adam's discuss and in particular the point about Security Considerations. I am holding this discuss independently so I can review those when they exist.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-05-25 07:27:32-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-24 08:49:12-07:00",
    "text": "I agree that there needs to be security considerations and have the following suggestions to help fill in that section. I think I caught the added considerations, but please expand on it if I've missed something. The draft seems to enable methods to gather information on connected links and the available bandwidth. That should be mentioned as a vulnerability, exposing path information (connections/links and bandwidth).\u00a0 This is a consideration in other IS-IS RFCs and is specific to the TLVS and subTLVs of this draft as well as far as I can tell, but please correct me if I am missing something.  The use of the Sub-TLV identifiers provide path information that should be a security consideration in the write up: \u00a0  o\u00a0 IPv4 Interface Address (sub-TLV 6 defined in [ RFC5305 ]) \u00a0  o\u00a0 IPv6 Interface Address (sub-TLV 12 defined in [ RFC6119 ]) \u00a0  o\u00a0 Link Local/Remote Identifiers (sub-TLV 4 defined in [ RFC5307 ]) Within a single operator environment, the concerns are mitigated, but not eliminated since it does not appear that encryption is used. The following text from  RFC7917  seems like a useful addition to these security considerations along with an explanation of what is possibly exposed with this draft (above): \u00a0  Security concerns for IS-IS are already addressed in [ISO10589], \u00a0  [ RFC5304 ], and [ RFC5310 ] and are applicable to the mechanisms \u00a0  described in this document.\u00a0 Extended authentication mechanisms \u00a0  described in [ RFC5304 ] or [ RFC5310 ] SHOULD be used in deployments \u00a0  where attackers have access to the physical networks, because nodes \u00a0  included in the IS-IS domain are vulnerable.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-12 20:11:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 21:20:31-07:00",
    "text": "As Roman notes, the conversion of secp256k1 to not-recommended in the -07 was incomplete: Table 2 and the prose below it still need to be adjusted.\u00a0 (Putting this in the discuss section so I remember to double-check it when the new revision arrives.) Also, I think we need to more strongly reiterate the cross-algorithm risk, specifically mentioned in Section 2.1.1 of draft-ietf-cose-rfc8152bis-algs-09 , regarding an attacker changing headers from secp256r1 to secp256k1 (or vice versa), and that the only known way to deal with this attack is to limit any given protocol participant to using at most one of the two curves.\u00a0 (AFAIK neither 'alg' nor 'crv' are required to be protected elements, so while limiting this curve to the ES256K algorithm helps in many cases, is not a fail-safe.) Finally, my apologies for not catching this earlier, but the COSE charter says that the WG deliverable to \"define the algorithms needed for W3C Web Authentication for COSE\" is to be an Informational document. It looks like we didn't notice that when the WG -00 was submitted and it has just been carried through unchanged.\u00a0 (Note, however, that the requested values for ES256K and secp256k1 are in the \"Standards Action\" range and would not be available for an informational document.)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-10-06 04:52:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-05 07:17:09-07:00",
    "text": "I am balloting DISCUSS because I believe that operational and security considerations need to be addressed or at least mentioned. I believe these points should be easy to address with some additional text. (1) When is a router's participation in a particular Flex-Algorithm advertised? It seems to me that there might be a \"chicken-and-egg\" problem that should at least be mentioned in the Operational Considerations.\u00a0 Let me explain: \u00a711: \u00a0  When a router is configured to support a particular Flex-Algorithm, \u00a0  we say it is participating in that Flex-Algorithm. \u00a75: \u00a0  To guarantee loop-free forwarding for paths computed for a particular \u00a0  Flex-Algorithm, all routers that (a) are configured to participate in \u00a0  a particular Flex-Algorithm, and (b) are in the same Flex-Algorithm \u00a0  definition advertisement scope MUST agree on the definition of the \u00a0  Flex-Algorithm.\u00a0 The following procedures ensure this condition is \u00a0  fulfilled. These statements make it look like support for a particular Flex-Algorithm is advertised when the routing process is enabled -- because the router is \"configured to support/participate\".\u00a0 However, at this point, the router may not have received a FAD for the Flex-Algorithm it is advertising support for. Besides the number of the Flex-Algorithm, the participation advertisement implies support for a specific Metric-Type and Calc-Type.\u00a0 But, again, nodes may be advertising this support blindly if the FAD is not known yet. Presumably, the operator configures support for a specific Flex-Algorithm with a FAD in mind.\u00a0 IOW, there should be no surprises.\u00a0 However, I would like to see the relationship between the support/participation configuration and the FAD components explicitly called out. Note that this issue is related to the ability of an attacker to hijack a particular Flex-Algorithm, but oriented at the ability of the operator to cause harm to their network. (2) Related to the point above.  What should a node configured to advertise support for a specific Flex-Algorithm do if it receives a FAD that it cannot support?\u00a0 For example, if the calc-type is unknown or unsupported. [\u00a713 already addresses the case of an unsupported metric-type.] (3) The Security Considerations section says that the attacks listed can be addressed through authentication.\u00a0 However, it fails to consider what a rogue node (one that is authenticated and taken over by an attacker) can do.\u00a0  This type of attack is not preventable through authentication, and it is not different from advertising any other incorrect information through IS-IS/OSPF.\u00a0 It should be mentioned in the Security Considerations section. Also, the effect of a hijacked/modified FAD may result in traffic not being delivered at all -- for example, by using an unsupported Metric-Type or Calc-Type.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-10-27 06:53:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-10-27 06:52:21-07:00",
    "text": "Thank you for this draft. I plan to recommend its approval, but first I would like to ensure that the issues raised by Dale Worley in his Gen-ART review are addressed satisfactorily and in consultation with the working group, to ensure that the document is as clear as possible. Specifically, the questions about XEIDs and the definition of a peer and a DDT node at least need to be worked through. (I\u2019m not necessarily asking for text changes, but looking for convergence in the discussion so that we are on the same page about what is meant.)",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-02-01 13:30:26-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-27 06:53:00-07:00",
    "text": "Thank you for this draft. I plan to recommend its approval, but first I would like to ensure that the issues raised by Dale Worley in his Gen-ART review are addressed satisfactorily and in consultation with the working group, to ensure that the document is as clear as possible. Specifically, the questions about XEIDs and the definition of a peer and a DDT node at least need to be worked through. (I\u2019m not necessarily asking for text changes, but looking for convergence in the discussion so that we are on the same page about what is meant. And I see the discussion is already ongoing -- thanks for that.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-20 03:48:51-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-27 05:44:20-07:00",
    "text": ".4.1: RSA-SHA1 is not the right choice today, shouldn'tthis be RSA-SHA256?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-04-12 18:03:48-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-12 17:28:05-07:00",
    "text": "- There are unresolved and substantive Last Call comments which the document does not address. For example, I have a hard time reading \"Not at all\" as effectively addressing concerns that the document implicitly weakens the critically important principles that  RFC 7258  lays down. While feedback to improve this specific situation has been solicited from Martin, it has been scantly more than a day since that request has been made. I don't think we're in a position to move the document forward with the current slate of unresolved Last Call comments. - The IETF as a whole does not have consensus on the document. For a document with such wide-reaching remit -- spanning network layers 3 through 7 -- the IETF-wide discussion has garnered an unclear mix of support and objection, and at fairly low volume (once we discount personnel directly involved in the progression of the document). If I count correctly, we have support for a document that fills this niche from Badri and Elliot, the most tepid statement of support I've seen in quite a while from Stuart (which itself concedes that the document diverges in tone and content from prior IETF statements on related topics), and rather strong statements of opposition from Martin and Christian. The objections by both Martin and Christian are substantive and structural; and many of the primary concerns they express appear to remain unresolved. I understand the temptation to dismiss many of the objecting comments about structure and tone as editorial in nature; but this document lands squarely in the middle of a policy area in which the IETF (and the IAB in particular) has written extensively and carefully, in at least RFCs 1984, 2804, 7258, and 7754, among probably others that escape my notice at the moment; and this also includes IAB statements on the topic, such as . Due to this factor, I believe that obtaining IETF consensus on tone rather than merely technical content is warranted in this case.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-04-12 19:59:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-12 18:03:48-07:00",
    "text": "- There are unresolved and substantive Last Call comments which the document does not address. For example, I have a hard time reading \"Not at all\" as effectively addressing concerns that the document implicitly weakens the critically important principles that  RFC 7258  lays down. While feedback to improve this specific situation has been solicited from Martin, it has been scantly more than a day since that request has been made. I don't think we're in a position to move the document forward with the current slate of unresolved Last Call comments. - The IETF as a whole does not have consensus on the document. For a document with such wide-reaching remit -- spanning network layers 3 through 7 -- the IETF-wide discussion has garnered an unclear mix of support and objection, and at fairly low volume (once we discount personnel directly involved in the progression of the document). If I count correctly, we have support for a document that fills this niche from Badri and Elliot, the most tepid statement of support I've seen in quite a while from Stuart (which itself concedes that the document diverges in tone and content from prior IETF statements on related topics), and rather strong statements of opposition from Martin and Christian. The objections by both Martin and Christian are substantive and structural; and many of the primary concerns they express appear to remain unresolved. I understand the temptation to dismiss many of the objecting comments about structure and tone as editorial in nature; but this document lands squarely in the middle of a policy area in which the IETF (and the IAB in particular) has written extensively and carefully, in at least RFCs 1984, 2804, 7258, and 7754, among probably others that escape my notice at the moment; and this also includes IAB statements on the topic, such as . Due to this factor, I believe that obtaining IETF consensus on tone rather than merely technical content is warranted in this case. ____ Addendum: Some of the documents that \"escape[d] my notice\" above include RFCs 1958 and 3274 (and in particular sections 4.1.1 and 4.1.2 of the latter document).",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-02-05 17:00:00-08:00",
    "end_reason": "position_updated",
    "start": "2017-04-12 19:59:38-07:00",
    "text": "- There are unresolved and substantive Last Call comments which the document does not address. For example, I have a hard time reading \"Not at all\" as effectively addressing concerns that the document implicitly weakens the critically important principles that  RFC 7258  lays down. While feedback to improve this specific situation has been solicited from Martin, it has been scantly more than a day since that request has been made. I don't think we're in a position to move the document forward with the current slate of unresolved Last Call comments. - The IETF as a whole does not have consensus on the document. For a document with such wide-reaching remit -- spanning network layers 3 through 7 -- the IETF-wide discussion has garnered an unclear mix of support and objection, and at fairly low volume (once we discount personnel directly involved in the progression of the document). If I count correctly, we have support for a document that fills this niche from Badri and Elliot, the most tepid statement of support I've seen in quite a while from Stuart (which itself concedes that the document diverges in tone and content from prior IETF statements on related topics), and rather strong statements of opposition from Martin and Christian. The objections by both Martin and Christian are substantive and structural; and many of the primary concerns they express appear to remain unresolved. I understand the temptation to dismiss many of the objecting comments about structure and tone as editorial in nature; but this document lands squarely in the middle of a policy area in which the IETF (and the IAB in particular) has written extensively and carefully, in at least RFCs 1984, 2804, 7258, and 7754, among probably others that escape my notice at the moment; and this also includes IAB statements on the topic, such as . Due to this factor, I believe that obtaining IETF consensus on tone rather than merely technical content is warranted in this case. ____ Addendum: Some of the documents that \"escape[d] my notice\" above include RFCs 1958 and 3724 (and in particular sections 4.1.1 and 4.1.2 of the latter document).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-03-15 13:53:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-03-15 06:44:34-07:00",
    "text": "I have only made it through Section 2.1.6 of this document, but I'm not sure if I'll have time to read the rest before the telechat, so I'm putting in what I have now for my ballot. My apologies for this. = Section 2.1.6.2 = \"Once the \u00a0  content is encrypted, the Mobile carrier loses the option to redirect \u00a0  the traffic leaving the option to block the customer's request and \u00a0  cause a bad customer experience untill the blocking reason can be \u00a0  conveyed by some other means.\" If all that is encrypted is the application payload, why does the mobile carrier lose the option of being able to do this based on the 5-tuple? This seems to me to be a false statement, or it is assuming some conditions which need to be made more clear.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-04-12 03:11:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-03-15 13:53:01-07:00",
    "text": "= Section 2.1.6.2 = \"Once the \u00a0  content is encrypted, the Mobile carrier loses the option to redirect \u00a0  the traffic leaving the option to block the customer's request and \u00a0  cause a bad customer experience untill the blocking reason can be \u00a0  conveyed by some other means.\" If all that is encrypted is the application payload, why does the mobile carrier lose the option of being able to do this based on the 5-tuple? This seems to me to be a false statement, or it is assuming some conditions which need to be made more clear.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-02-08 05:26:34-08:00",
    "end_reason": "position_updated",
    "start": "2017-04-12 03:11:17-07:00",
    "text": "I have cleared my original DISCUSS point from my earlier review -- I get what the text is saying now, although I still think the \"lose the option\" language implies some entitlement to the option in the first place, which seems inappropriate. But given the reviews from Martin Thomson and Christian Huitema, it's not clear to me that this document represents the consensus view of the IETF community. Kathleen's response to Martin reinforces the point that we were discussing in the first ballot cycle, which is that this document is written for and represents operators, not the broader array of Internet interests. Yet the suggestion to state that fact up front in the document was not adopted. Having had some more time to review this document than I had in the previous ballot cycle, I also am finding myself in agreement with significant portions of the reviews from Martin and Christian. Reading their reviews helped crystallize a lot of the difficulty I had in parsing this document the first time around.  I understand the rationale that led to this document being written and I think there is a version of this document that could be written that would achieve the original goals while giving the subject matter a readable, neutral treatment. Such a version would be a useful contribution. But I don't think this document achieves that. In particular, there are four things that I think it would need to do to achieve that: 1. State the analysis in a neutral way. As I had mentioned in one of the email threads for the previous ballot cycle, I believe this document could be written in a neutral way -- e.g., \u201cService providers currently do X. It is implemented using Y mechanism. Encryption at Z layer breaks current implementations.\u201d -- but it is not. Instead it characterizes many of the practices described as \"optimizations\" or \"features\" or \"enrichment\" and states service providers' claims about what these practices accomplish (e.g., \"maximize QOE\") as facts rather than stating them as the reasons given by service providers for why they engage in the practices. This is why in the previous round I suggested the disclaimer at the top of the document to say that the document is giving a view from service providers; that apparently didn't go anywhere, so the other option is to describe each technique neutrally, or explain with each technique that the characterization of the benefits is from the view of the operator. Martin's comments about being clear about who is benefitting point this out as well. 2. Limit the discussion to techniques presently being affected and those effects. There is a bunch of extemporizing about future possible impacts (e.g., in Sec. 2.7, 4.1.2, 4.1.3.1, 5.7, 7, 8). It's very hard to characterize future implications, who will bear the \"cost\" for what, whether increases in user complaints to various parties are \"worth it,\" etc., in a way that is perceived as neutral by all affected parties. Better not to make predictions if the goal is to give a neutral treatment of network functions being impacted today. 3. Acknowledge the controversy. Many of the practices described in this document are controversial, and have been for a long time. There is nothing wrong with that. I agree with Christian that it would be better to state an understanding of that head-on rather than leave it to the reader to decide whether any particular characterization of something described implies an endorsement of it. This has been done before, even in potentially controversial documents that this document references, e.g.  RFC 3135 . 4. Structure the document in a way that is consistent and logical with minimal repetition. It seems like there are multiple ways that this could be done. Organizing based on use case (per Christian) and then discussing techniques used within each use case is one way; organizing based on technique while mentioning the goals for which each technique is employed is another. At present the document is jumble of these.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-02-07 21:04:26-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-11 09:27:23-07:00",
    "text": "I do not believe that this document represents IETF Consensus, largely for the reasons indicated by Martin Thomson and Christian Huitema on the IETF list recently. Specifically, this document, while perhaps not saying anything actually false, essentially only presents the perspective of operators and service providers. In many cases, those interests are adverse to those of users -- and in many cases encryption is used specifically to prevent operators from providing the \"services\" and \"enhancements\" contemplated by this document.\u00a0 For these reasons, I don't believe that the uncritical treamtent of these activities presented in this document should be published as an RFC that claims to have IETF Consensus. I have made specific comments below that indicate some of the more serious issues, but the problems here are systematic and require more than simple edits. S 1. \u00a0  draft includes a collection of \u00a0  current security and network management functions The functions presented here in many cases go far beyond security and management. For instance, header enrichment is neither, except by stretching the definition of \"management\" to breaking. S 2. \u00a0  middle boxes were in use to perform functions that range from load \u00a0  balancing techniques to monitoring for attacks or enabling \"lawful \u00a0  intercept\", such that described in [ETSI101331] and [CALEA] in the \u00a0  US. I'm not sure why you are mentioning CALEA here. As far as I can tell, the CALEA requirements only apply to carriers who have access to the keying material. \u00a0  The loss of access to these fields may \u00a0  prompt undesirable security practices in order to gain access to the \u00a0  fields in unencrypted data flows. As Martin Thomson indicates, this feels like a threat. S 2.1. As Martin and Christian indicate, this QUIC material is entirely speculative and extremely controversial and you should remove it. \u00a0  Additionally, a system that is able to encode the identity of the \u00a0  pool server in plain text information available in each incoming \u00a0  packet is able to provide stateless load balancing. This doesn't have to be in plaintext because the pool load balancer has a relationship with the servers. We already have designs for this for QIC. \u00a0  Current protocols, such as TCP, allow the development of stateless \u00a0  integrated load balancers by availing such load balancers of \u00a0  additional plain text information in client-to-server packets.\u00a0 (In \u00a0  case of TCP, such information can be encoded by having server- \u00a0  generated sequence numbers, mss values, lengths of the packet sent, \u00a0  etc.) How does this help the load balancer direct traffic. S 2.2. \u00a0  Internet traffic surveys are useful in many well-intentioned \"Well-intentioned\" is pretty tendentious here. \u00a0  pursuits, such as CAIDA data [CAIDA] and SP network design and \u00a0  optimization. I'd be interested in hearing which CAIDA studies are impacted by content encryption. Do you have citations? S 2.3.2.1. There are two kinds of caching potentially in play: - Explicit caches - Intercepting caches At this point, what ISPs primarily run is intercepting caches, and there's a lot of evidence that they contribute to bustage and ossification, as well as being a primary tool for ISPs to use to mess with people's traffic in ways that users clearly don't want (ad/tracking injection, etc.).\u00a0 So, I don't think an IETF consensus document should suggest that we are sad to be breaking them. S 2.3.2.2. The presentation here seems biased given that it does not acknowledge that one of the primary reasons that ISPs do traffic class discrimination is to prioritize favored rather than disfavored traffic, regardless of user preferences. I don't believe that the IETF has taken a position for net neutrality, but I'm also pretty sure we don't have consensus against it. S 2.5.3. Currently, the mobile network service provider redirects the customer \u00a0  using HTTP redirect to a page which educates the customer on the \u00a0  reason for the blockage and provide steps to proceed.\u00a0 Once the HTTP \u00a0  header and content are encrypted, the Mobile carrier loses the option \u00a0  to intercept the traffic and perform an HTTP redirect.\u00a0 With current \u00a0  solution options, this leaves only the option to block the customer\u2019s \u00a0  request and cause a bad customer experience until the blocking reason \u00a0  can be conveyed by some other means. This is pretty tendentious. It's not at all clear to me that the customer thinks that having their traffic intercepted is a better experience. S 2.6.2. Zero-rating is absolutely possible in the face of encryption. Facebook Free Basics supports this. https://info.internet.org/en/blog/2015/09/24/enhancing-security-and-privacy-of-free-basics/ S 2.6.5. Header insertion is also used for tracking and advertising. S 2.7. This should be clearer about the impact of encryption at various layers. Most of the things you want to do here will work fine with HTTPS. S 2.8. \u00a0  When utilizing increased encryption, application server operators \u00a0  should expect to be called upon more frequently to diagnose problems Why would this be true? As far as I can tell, pretty much only if they are screwing with the traffic in ways that the user would prefer they not. S 3.3.1. \u00a0  The general monitoring needs for data replication are described in \u00a0  this subsection. It's not at all obvious these are needs. S 4.1.1. A lot of these monitoring applications could also be characterized as the employer conducting surveillance on its employees. S 4.2. As far as I know, the MITM techniques used by middleboxes are not described in 7457. You also need to cover the fact that these MITM are a threat to user security because they are often so badly implemented. \u00a0  Restrictions on traffic to approved sites: Web proxies are sometimes \u00a0  used to filter traffic, allowing only access to well-known sites \u00a0  found to be legitimate and free of malware on last check by a proxy \u00a0  service company.\u00a0 This type of restriction is usually not noticeable \u00a0  in a corporate setting, but may be to those in research who are \u00a0  unable to access colleague\u2019s individual sites or new web sites that \u00a0  have not yet been screened. I'm not sure why this would be not noticeable in a corporate setting. I, for one, notice it on airplanes. S 5.3. It's pretty odd to talk about phishing without acknowledging that by far the largest anti-phishing platform (Safe Browsing) operates in the client, not be network interception. S 7.1 This entire section is pretty confusing. Issues include: - There is real debate about whether performance-enhancing proxies \u00a0 really work (see Mathis's comments at IETF). - Content replication needs a lot more than just being able to see \u00a0 ACKs. - \"trusted\" proxies? Trusted by who? This whole architectural structure of having invisible proxies messing with the transport stream is a total violation of the E2E argument, so I don't see how one could think that describing it as if it were positive can have IETF consensus. I also notice that this section and the sectoin below describe things that a lot of users don't want as \"features\" S 7.3. \u00a0 \u00a0 \u00a0  Content/Application based Prioritization of Over-the-Top (OTT) \u00a0 \u00a0 \u00a0  services - each application-type or service has different \u00a0 \u00a0 \u00a0  delay/loss/throughput expectations, and each type of stream will \u00a0 \u00a0 \u00a0  be unknown to an edge device if encrypted; this impedes dynamic- \u00a0 \u00a0 \u00a0  QoS adaptation. I think there's a lot of debate about whether we *want* networks to try to accommodate new traffic classes. This has lead to a lot of problems under the heading of \"ossification\" \u00a0 \u00a0 \u00a0 \u00a0 While CDNs that de-encrypt flows or split-connection proxy \u00a0 \u00a0 \u00a0  (similar to split-tcp) could be deployed closer to the edges to \u00a0 \u00a0 \u00a0  reduce control loop RTT, with transport header encryption, such \u00a0 \u00a0 \u00a0  CDNs perform optimization functions only for partner client \u00a0 \u00a0 \u00a0  flows; thus content from Small-Medium Businesses (SMBs) would not \u00a0 \u00a0 \u00a0  get such CDN benefits. Huh? Lots of SMBs use this kind of CDN. That's how e.g., Cloudflare works. Heck the IETF uses it. S 8. \u00a0  In the best case scenario, engineers and other innovators would work \u00a0  to solve the problems at hand in new ways rather than prevent the use \u00a0  of encryption.\u00a0 It will take time to devise alternate approaches to \u00a0  achieve similar goals. Much of the context of this debate is about whether operators not being able to do the things in this document is a problem. \u00a0  It is well known that national surveillance programs monitor traffic \u00a0  for terrorism [JNSLP] I concur with Martin's objection to the use of the loaded word \"terrorism\" here. Given  RFC 2804  and the IETF's clear position on protocol design, this discussion of balance between surveillance and user security seems completely outside the IETF consensus.   \u00a0  Open questions: As the use of encryption increases, does passive \u00a0  monitoring become limited to metadata analysis?\u00a0 What metadata should \u00a0  be left in protocols as they evolve to also protect users privacy? Huh? Coming as this does in the context of surveillance, 2804 is clear. It might be the case that there are good reasons to avoid encrypting metadata for the purposes of network monitoring by carriers, but I think the IETF consensus is clearly not to do so to enable surveillance.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-02-28 06:53:21-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-07 21:04:26-08:00",
    "text": "I have completely re-reviewed the latest version. First, I want to thank you for toning down some of the material that I was concerned about. Unfortunately, the fundamental concern that motivated my DISCUSS remains: I do not believe that this document matches the consensus of the IETF community. Specifically, this document takes at face value a large number of claims about the necessity/value of certain practices that either are controversial within the IETF or that there is, I believe, rough consensus to be actively bad, and that in many cases, encryption is specifically designed to prevent. I have noted a number of these below, but I do not believe that this is an exhaustive list (going through my previous DISCUSS, I see that I noted a number of these but that still appear to be unaddressed.) DISCUSS \u00a0  session encryption that deployed more easily instead of no \u00a0  encryption. \u00a0   I think I understand what you are saying here, but the term \"breakable\" seems very unfortunate, especially in the context of this document. The only such shift I am aware of that has received acceptance in IETF is one from always requiring fully authenticated encryption to allowing unauthenticated encryption, which you document in the next paragraph. I recognize that there are other perspectives (e.g., those in draft-rhrd) but those are pretty far from IETF consenus. Accordingly, I think you should remove this sentence. \u00a0  motivation outside of privacy and pervasive monitoring that are \u00a0  driving end-to-end encryption for these content providers. \u00a0   This section seems kind of confusing, at least as applied to HTTP. There are three kinds of cache in HTTP: - Reverse proxy caches (the kind CDNs run) - Explicit forward proxy caches - \"Transparent\" intercepting caches The first of these move to HTTPS just fine and that's typically how CDNs do it.\u00a0 Explicit forward proxy caches are largely going away, but part of the point of this kind of end-to-end encryption is to hide data from those caches.\u00a0 Transparent intercepting caches that the user didn't opt into are a bad thing, so having them go away is a positive. \u00a0  document existing practices, the development of IETF protocols \u00a0  follows the guiding principles of [ RFC1984 ] and [ RFC2804 ]. \u00a0   This is pretty opaque in this context. It should explicitly state that the IETF's position is that we do not engineer for these use cases, not just to cite the RFCs. \u00a0  based billing, or for other reasons, possibly considered \u00a0  inappropriate by some.\u00a0 See  RFC7754  [ RFC7754 ] for a survey of \u00a0  Internet filtering techniques and motivations.\u00a0 This section is I don't think this accurately represents the RFC, which makes clear that the IAB consensus is that filtering is bad: \" From a technical perspective, there are no perfect or even good solutions -- there is only least bad.\u00a0 On that front, we posit that a hybrid approach that combines endpoint-based filtering with network filtering may prove least damaging.\u00a0 An endpoint may choose to participate in a filtering regime in exchange for the network providing broader unfiltered access.\" \u00a0  detect or prevent attacks as well as to guarantee service level \u00a0  expectations.\u00a0 In some cases, alternate options are available when \u00a0  encryption is in use, but techniques like that of data leakage \u00a0   These certainly are use cases, but you really need to acknowledge that it's also a form of user surveillance. \u00a0  Some DLP tools intercept traffic at the Internet gateway or proxy \u00a0  services with the ability to man-in-the-middle (MiTM) encrypted \u00a0  session traffic (HTTP/TLS).\u00a0 These tools may use key words important \u00a0  to the enterprise including business sensitive information such as \u00a0  trade secrets, financial data, personally identifiable information \u00a0  (PII), or personal health information (PHI).\u00a0 Various techniques are \u00a0  used to intercept HTTP/TLS sessions for DLP and other purposes, and \u00a0  are described in \"Summarizing Known Attacks on TLS and DTLS\" \u00a0  [ RFC7457 ]. As far as I know, the MITM techniques used by middleboxes are not described in 7457. You also need to cover the fact that these MITM are a threat to user security because they are often so badly implemented. S 5.4. It's pretty odd to talk about phishing without acknowledging that by far the largest anti-phishing platform (Safe Browsing) operates in the client, not be network interception. \u00a0 \u00a0 The transport header encryption prevents trusted transit proxies.\u00a0 It \u00a0  may be that the benefits of such proxies could be achieved by end to \u00a0   You don't define a \"trusted transit proxy\" so I don't know what this means, and whether they provide any benefit, but this certainly sounds euphemistic. Generally, \"trusted\" is not an adjective we associate with network proxies operated by third parties. \u00a0  In the best case scenario, engineers and other innovators would work \u00a0  to solve the problems at hand in new ways rather than prevent the use \u00a0  of encryption.\u00a0 As stated in [ RFC7258 ], \"an appropriate balance \u00a0  (between network management and PM mitigations) will emerge over time \u00a0  as real instances of this tension are considered.\" Much of the context of this debate is about whether operators not being able to do the things in this document is a problem, and this seems to presume the answer. \u00a0  This optimization at network edges measurably improves real-time \u00a0  transmission over long delay Internet paths or networks with large \u00a0   Do you have a citation for this claim? \u00a0  Web proxies are sometimes used to filter traffic, allowing only \u00a0  access to well-known sites found to be legitimate and free of malware \u00a0  on last check by a proxy service company.\u00a0 This type of restriction \u00a0  is usually not noticeable in a corporate setting as the typical \u00a0  corporate user does not access sites that are not well-known to these \u00a0  tools, but may be noticeable to those in research who are unable to \u00a0  access colleague's individual sites or new web sites that have not \u00a0  yet been screened.\u00a0 In situations where new sites are required for \u00a0  access, they can typically be added after notification by the user or \u00a0  proxy log alerts and review.\u00a0 Home mail account access may be blocked \u00a0  in corporate settings to prevent another vector for malware to enter \u00a0  as well as for intellectual property to leak out of the network. \u00a0  This method remains functional with increased use of encryption and \u00a0  may be more effective at preventing malware from entering the \u00a0  network.\u00a0 Web proxy solutions monitor and potentially restrict access \u00a0  based on the destination URL or the DNS name.\u00a0 A complete URL may be \u00a0  used in cases where access restrictions vary for content on a \u00a0  particular site or for the sites hosted on a particular server. If you are filtering on URL and there is HTTPS involved, then you are a MITM, and this is potentially noticeable to end-users. We encounter this regularly when MITM proxies make mistakes in getting into our trust anchor store. Re: 0-rating. \u00a0  user.\u00a0 This feature is impacted if encryption hides the details of \u00a0  the content domain from the network. \u00a0   Well, maybe. Facebook's zero rating, for instance, is IP-based. https://info.internet.org/en/blog/2015/09/24/enhancing-security-and-privacy-of-free-basics/ S 2.2.2. The presentation here seems biased given that it does not acknowledge that one of the reasons that ISPs do traffic class discrimination is to prioritize favored rather than disfavored traffic, regardless of user preferences. I don't believe that the IETF has taken a position for net neutrality, but I'm also pretty sure we don't have consensus against it.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-02-02 06:30:46-08:00",
    "end_reason": "position_updated",
    "start": "2017-03-14 04:21:22-07:00",
    "text": "Why is section 11 in the appendix only? I would see this as an important part of the document because it seems to me that mobile operators are the ones most impacted by encryption.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Stiemerling",
    "end": "2016-01-05 13:47:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2016-01-05 13:45:35-08:00",
    "text": "I am in favour of publishing this document, but I have two major points that are not addressed in the document by now: 1) It is not clear for anybody what the expected size and sending frequency of such MPLS-PLDM over IP/UDP responses are. This will influence any measures an operator has to take in order to assure that there is no congestion caused by these messages.  2) This leads to my second point: the lack of any reference to  RFC 5405  \"Unicast UDP Usage Guidelines for Application Designers\" and the content out of this RFC that is applicable for this draft. There is no discussion about this at all. Please note well that this is  BCP 145 .  With regard to point 2): I can try to find some help from the transport area, in case you need help.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Stiemerling",
    "end": "2016-04-08 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2016-01-05 13:47:02-08:00",
    "text": "I am in favour of publishing this document, but I have two major points that are not addressed in the document by now: 1) It is not clear for anybody what the expected size and sending frequency of such MPLS-PLDM over IP/UDP responses are. This will influence any measures an operator has to take in order to assure that there is no congestion caused by these messages. I can understand that this cannot be foreseen, but a few words considering this fact are excellent to have in the document.  2) This leads to my second point: the lack of any reference to  RFC 5405  \"Unicast UDP Usage Guidelines for Application Designers\" and the content out of this RFC that is applicable for this draft. There is no discussion about this at all. Please note well that this is  BCP 145 .  With regard to point 2): I can try to find some help from the transport area, in case you need help.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-04-27 07:22:41-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-25 09:17:41-07:00",
    "text": "Thanks for this clean, easy-to-review document.  I do have one point I'd like to flag. I'm making this a DISCUSS to ensure the IESG has a chance to discuss the point raised, and intend to clear after the telechat.  In his review ( https://datatracker.ietf.org/doc/review-ietf-spring-nsh-sr-11-rtgdir-lc-bryant-2022-05-28/ ) Stewart Bryant makes a good point: ``` There is one point that the IESG should ponder. The authors have asked for a IP type assignment. This is a limited registry that needs to last the lifetime of the IP protocol suite. NSH started its life 9 years ago and has been a standard for 4 years and in all this time has not needed such as allocation. Neither SRv6 nor NSH are petite or lightweight protocols. So I wonder if the identification of NSH should happen at the IP layer as proposed, or whether an intermediate multiplexing layer such as UDP should be used? The extra processing for UDP is one test and the extra MTU is 8 octets. The decision for the IESG is whether in their view the extent of deployment and the gain in performance is such that they should authorise the allocation of the IP type. ``` AFAICT the argument against using a UDP encap is \"it's more overhead\" (which is true, but I think Stewart's point is that the UDP overhead is pretty small as a fraction of the SRv6 and NSH overheads). Anyway, it seems like it would be good to at least consider this question.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-11-22 08:57:45-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-19 14:48:33-08:00",
    "text": "I'm having trouble seeing how we got here; this registry architecture is hard to understand, and past actions appear to violate  RFC 3692 . 1.  RFC7153  designated 0x80-0x8f as experimental and then immediately defines 0x80 as the gateway to a further subregistry of FCFS/IETF review codepoints. This does not appear to be \"Reserved for Experimental Use\" in the  RFC 3692  sense, in that it is not meant to be used only by explicit experiments. (It's a standards track document). 2.  RFC8955  compounds it by taking another 2 (of 15 remaining!) experimental codepoints in a standards-track document, for a similar purpose. I agree with this draft's reclassification of the 3 codepoints, as it recognizes reality that they are apparently no longer safe for  RFC 3692  experiments. But I would also like to verify that this behavior will not continue: future standards-track allocations, including those pointing to more subtypes (\"Part 4\", etc), will draw from the FCFS range, not Experimental. Furthermore, experiments (with a draft or not) that use one of these experimental codepoints should be reassigned a FCFS codepoint if they move to Standards track.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2021-11-18 16:22:28-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-18 16:19:14-08:00",
    "text": "Hi, Thank you for your work. Maybe I'm missing something obvious, but why doesn't this document update 8955 just like it updates 7153? I'm asking because your document modifies the allocation policy of the 0x80-0x8F range, as well as the names of 0x80, 0x81, 0x82 (and of sub-types registries) but at the same time it seems to me that 7153 only covers the allocation policy of the 0x80-0x8F range and 0x80 (and its sub-type registry), while it's 7674/8955 which seems to cover 0x81 and 0x82 (and their sub-types registries). Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2021-11-23 06:18:59-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-18 16:22:28-08:00",
    "text": "Hi, Thank you for your work. Maybe I'm missing something obvious, but why doesn't this document update 8955 just like it updates 7153? I'm asking because your document modifies the allocation policy of the 0x80-0x8F range, as well as the names of 0x80, 0x81, 0x82 (and of their sub-types registries), and at the same time it seems to me that 7153 covers the allocation policy of the 0x80-0x8F range but only 0x80 (and its sub-type registry), while it's 8955 which seems to cover 0x81 and 0x82 (and their sub-types registries). Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-09-03 05:59:41-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-06 13:30:33-07:00",
    "text": "Thanks for writing this document. Section 6.1 says: \"Developers MAY develop new protocols or applications that rely on IP \u00a0  fragmentation if the protocol or application is to be run only in \u00a0  environments where IP fragmentation is known to be supported.\" I'm wondering if there should be a bit more nuance here to make the recommendation clearer. Do we think there is a case where an application protocol developed in the IETF will be known to only run in environments where fragmentation is supported? If we don't think developing such a protocol would be in scope for the IETF, then I'm wondering if that case should be called out explicitly with a stronger normative requirement.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-07-02 03:21:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-07-02 03:15:55-07:00",
    "text": "-bis documents require \"changes since\" section. I don't believe IANA Considerations section is correct: it points to a document that gets obsoleted by this one, yet the original document creates new registries. This makes the status of earlier established registries unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-07-02 03:31:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-07-02 03:21:29-07:00",
    "text": "-bis documents require \"changes since\" section. I don't believe IANA Considerations section is correct: it points to a document that gets obsoleted by this one, yet the original document creates new subregistries. This makes the status of earlier established registries unclear. Also, other sections have references to Section 7 (e.g. for registration types) which no longer contain relevant information. I think you should copy the original IANA registration section in its entirety and clearly mark new allocations in it.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-05 07:51:33-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-02 03:31:45-07:00",
    "text": "I don't believe IANA Considerations section is correct: it points to a document that gets obsoleted by this one, yet the original document creates new subregistries. This makes the status of earlier established registries unclear. Also, other sections have references to Section 7 (e.g. for registration types) which no longer contain relevant information. I think you should copy the original IANA registration section in its entirety and clearly mark new allocations in it.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-08-05 05:26:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-05 07:01:36-07:00",
    "text": "3.3 - This fails to distinguish between an invalid certificate (e.g. bad signature, unknown signer) and one that is valid, but is not acceptable for this purpose.\u00a0 I don't get why that is ok for HIP, can you explain?\u00a0 If it is ok, I think you need to say so. If it is not ok (as I'd suspect) then you appear to need to change text or one more new error code.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-10-30 13:43:47-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-25 19:28:07-07:00",
    "text": "I share the concerns of the SecDir reviewer and would like to see more text in the Security Considerations that reflect the inherent trust model and also the lack of integrity protection for the BIER encapsulation.\u00a0 Having these items detailed explicitly is an important consideration for implementers.\u00a0 I do realize that this is the current state with MPLS, but it bears repeating for a new encapsulation. https://mailarchive.ietf.org/arch/msg/secdir/w8qqQtzlEi00uToUGT0N8XVuHkI Thank you.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-26 02:14:33-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-23 08:48:20-07:00",
    "text": "My understanding is that this document specifies a new encapsulation. As such it should also discuss path MTU discovery and fragmentation. Maybe a pointer to section 3 of  rfc3032  is sufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-10-25 11:34:12-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-24 12:26:27-07:00",
    "text": "I believe that there needs to be better guidance of what to do when the TTL expires (and want to thank Al (OpsDir) for noticing this): \"Of course, if the incoming TTL is 1, the packet MUST be treated as \u00a0 \u00a0 \u00a0 a packet whose TTL has been exceeded.\u00a0 The packet MUST NOT be \u00a0 \u00a0 \u00a0 forwarded, but it MAY be passed to other layers for processing \u00a0 \u00a0 \u00a0 (e.g., to cause an ICMP message to be generated, and/or to invoke \u00a0 \u00a0 \u00a0 BIER-specific traceroute procedures, and/or to invoke other OAM \u00a0 \u00a0 \u00a0 procedures.)\" I have read the response to the OpsDir review ( https://www.ietf.org/mail-archive/web/ops-dir/current/msg02897.html ) -- I fully agree that mandating a response to every packet would be bad, but I think that \"it MAY be passed to other layers for processing\" is too weak. I think SHOULD would be fine, or, even better, something about \"SHOULD, with optional implementation specific rate-limiting\" or something. The current text makes it sound like it's perfectly fine to just not bother implementing any sort of reporting / response handing after dropping the packet.  I think that this should be an easy fix and not hold up the document (much or at all)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2023-03-27 06:16:00-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 07:10:53-08:00",
    "text": "This document attempts to do two things: specify \"unsolicited BFD\" and define a YANG model for its management.\u00a0 I am happy to include both in the same document, but the specification of the protocol mechanisms falls short and results in a document that lacks clarity.\u00a0 While YANG is the preferred management mechanism, it should be possible to implement and manage the feature without the model. Most of my concerns are from Section 2 (line numbers from idnits): 154\t\u00a0  Passive unsolicited BFD support MUST be disabled by default, and MUST 155\t\u00a0  require explicit configuration to be enabled.\u00a0 On the passive side, 156\t\u00a0  the desired BFD parameters SHOULD be configurable.\u00a0 The passive side 157\t\u00a0  MAY also choose to use the parameters that the active side uses in 158\t\u00a0  its BFD Control packets.\u00a0 The \"My Discriminator\", however, MUST be 159\t\u00a0  chosen to allow multiple unsolicited BFD sessions. (A) \"the desired BFD parameters SHOULD be configurable\" Which parameters are those?\u00a0 The YANG model uses bfd-types:base-cfg-parms, which only includes a basic set.\u00a0 The point here is that this document's specification part is incomplete because it doesn't specify which parameters \"SHOULD be configurable\". (B) The YANG model offers global and per-interface configuration options.\u00a0 The specification doesn't discuss hierarchical configuration or whether one type should take precedence over the other.\u00a0 [Related to Rob's DISCUSS.] This point was discussed on the mailing list, where it was pointed out that per-interface configuration should override global configuration [1], but that discussion is not reflected in the document. [1]  https://mailarchive.ietf.org/arch/msg/rtg-bfd/GI_eNtxcEeh2_vTl9zfq7K6V1X4 171\t\u00a0  When the passive side receives an incoming BFD Control packet on a 172\t\u00a0  numbered interfaces, the source address of that packet MUST belong to 173\t\u00a0  the subnet of the interface on which the BFD packet is received.\u00a0 The 174\t\u00a0  source address of the BFD Control packet SHOULD be validated against 175\t\u00a0  expected routing protocol peer addresses on that interface. (C) \"SHOULD be validated\"  What does validating the source address \"against expected routing protocol peer addresses on that interface\" entail?\u00a0 Is it just a comparison?\u00a0 Please be explicit on what the normative behavior should be. When is it ok to not validate?\u00a0 Why is this behavior recommended and not required? If the validation is performed, is there an expected action if the source address does not correspond to an \"expected routing protocol peer addresses on that interface\"?\u00a0 Where does this \"expected\" list come from?\u00a0 On a LAN, it seems like any address would be valid since a router doesn't know the list of IGP neighbors beforehand. 177\t\u00a0  The passive side MUST then start sending BFD Control packets and 178\t\u00a0  perform the necessary procedure for bringing up, maintaining and 179\t\u00a0  tearing down the BFD session.\u00a0 If the BFD session fails to get 180\t\u00a0  established within certain specified time, or if an established BFD 181\t\u00a0  session goes down, the passive side SHOULD stop sending BFD Control 182\t\u00a0  packets and MAY delete the BFD session created until BFD Control 183\t\u00a0  packets are initiated by the active side again. (D) \"If the BFD session fails to get established within certain specified time...\" [nit] s/within certain specified time/within a certain specified time Where does a \"certain specified time\" come from?\u00a0 Is it configurable?\u00a0 Does it correspond to any of the state variables in  rfc5880 ? (E) \"SHOULD stop sending BFD Control packets\" When is it ok not to stop sending BFD control packets?\u00a0 Why would the node continue sending packets if the session is not established (or goes down)?\u00a0 Why is this behavior recommended and not required? 185\t\u00a0  When an Unsolicited BFD session goes down, an implementation MAY 186\t\u00a0  retain the session state for a period of time.\u00a0 Retaining this state 187\t\u00a0  can be useful for operational purposes. (F) Not exactly a contradiction, but confusing normative statements (between this paragraph and the one before): \"MAY delete\" vs \"MAY retain\" for the same event (\"BFD session goes down\").",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-04-11 07:04:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 06:27:20-08:00",
    "text": "# GEN AD review of  draft-ietf-bfd-unsolicited-11 CC @larseggert Thanks to Dan Romascanu for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/2NcfuVBkWLD_CcQyTciwKOz2Xac ). ## Discuss ### Section 7.1, paragraph 3 ``` \u00a0 \u00a0  The same security considerations and protection measures as those \u00a0 \u00a0  described in [ RFC5880 ] and [ RFC5881 ] apply to this document.\u00a0 In \u00a0 \u00a0  addition, with \"unsolicited BFD\" there is potential risk for \u00a0 \u00a0  excessive resource usage by BFD from \"unexpected\" remote systems.\u00a0 To \u00a0 \u00a0  mitigate such risks, the following measures are mandatory: \u00a0 \u00a0  *\u00a0 Limit the feature to specific interfaces, and to single-hop BFD \u00a0 \u00a0 \u00a0 \u00a0 with \"TTL=255\" [ RFC5082 ]. \u00a0 \u00a0  *\u00a0 Apply \"policy\" to allow BFD packets only from certain subnets or \u00a0 \u00a0 \u00a0 \u00a0 hosts. \u00a0 \u00a0  *\u00a0 Deploy the feature only in certain \"trustworthy\" environment, \u00a0 \u00a0 \u00a0 \u00a0 e.g., at an IXP, or between a provider and its customers. \u00a0 \u00a0  *\u00a0 Use BFD authentication, see [ RFC5880 ].\u00a0 In some environments, e.g. \u00a0 \u00a0 \u00a0 \u00a0 when using an IXP, BFD authentication can not be used because of \u00a0 \u00a0 \u00a0 \u00a0 the lack of coordination into the operation of the two endpoints \u00a0 \u00a0 \u00a0 \u00a0 of the BFD session.\u00a0 In other environments, e.g. when BFD is used \u00a0 \u00a0 \u00a0 \u00a0 to track the next hop of static routes, it is possible to use BFD \u00a0 \u00a0 \u00a0 \u00a0 authentication: this comes with the extra cost of configuring \u00a0 \u00a0 \u00a0 \u00a0 matching key-chains at the two endpoints.\u00a0 If BFD authentication \u00a0 \u00a0 \u00a0 \u00a0 is used, the Meticulous Keyed SHA1 mechanism SHOULD be used. ``` BFD can be configured to send large volumes of traffic, and it sends it without congestion control. When a past IESG approved BFD for standardization in that form, it was exactly because both endpoints needed to be configured, which significantly reduces the possibility/impact of unilateral misconfiguration. I don't believe the suggestions above provide nearly the same level of protection. Also, if (all of?) these are mandatory, that needs to be made very clear, i.e., using  RFC2119  terms here and elsewhere in the document (where it currently says these mechanisms are recommended...)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-04-18 08:56:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 09:03:13-08:00",
    "text": "Hi, Thanks for this document. Please see my comments below for more details, but I'm balloting discuss on 3 points: (1) The document is somewhat unclear as to whether the configuration is applied hierarchically (I presume that it is, if not then my second discuss point is not valid and can be ignored). (2) As specified, I don't think that the hierarchical configuration will work, because the interface level leaf \"defaults\" will override an explicit value configured globally.\u00a0 I.e., logically, the interface level leaf, if in scope, will always have a value. (3) The document should provide an instance-data example in the appendix to illustrate the use of this configuration. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-26 23:47:56-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 09:00:29-08:00",
    "text": "** Section 7.1 Limit the feature to specific interfaces, and to single-hop BFD \u00a0 \u00a0 \u00a0 with \"TTL=255\" [ RFC5082 ]. Section 2.2 of  RFC5082  says \u201cset the TTL on the protocol packets to 255 (the maximum possible for IP) and then reject any protocol packets that come in from configured peers that do NOT have an inbound TTL of 255\u201d. Guidance on dropping the packets based on TTL in  RFC5082  appears to be missing here.\u00a0  ** Section 7.1.\u00a0 The following considerations are inconsistent:  -- \u201cTo mitigate such risks, the following measures are mandatory: \u2026 Apply \"policy\" to allow BFD packets only from certain subnets or hosts.\u201d Editorially (not discuss but related), why is policy in quotes? Requiring this check conflicts with the less rigorous SHOULD in Section 2: \u201cThe source address of the BFD Control packet SHOULD be validated against expected routing protocol peer addresses on that interface.\u201d -- \u201cTo mitigate such risks, the following measures are mandatory: \u2026 Use BFD authentication, see [ RFC5880 ].\u00a0 In some environments, e.g. when using an IXP, BFD authentication can not be used \u2026 If BFD authentication is used, the Meticulous Keyed SHA1 mechanism SHOULD be used.\u201d The text first says using BFD authentication is mandatory, but then says it is not possible in certain environments.\u00a0 Later is states that \u201cif BFD is used\u201d, but the text already said it was mandatory.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-04-19 01:21:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 11:32:26-08:00",
    "text": "Thanks for working on this specification.  Thanks to Magnus Westerlund for the TSVART review, based on that review and my own read, I am supporting both Lars's and Roman's discuss. On top of that, as this document claims - \"with \"unsolicited BFD\" there is potential risk for excessive resource usage by BFD from \"unexpected\" remote systems\". This translates to me as potential injection of huge amount of traffic which is lacking a self-regulation mechanism in this specification. To large degrees the traffic volume could have random effects on the routing plane and what links are considered up etc. We can hide all these by saying \"Deploy the feature only in certain \"trustworthy\" environment\"\", then I am completely missing the definition of \"trustworthy\" environment\". I would like to discuss that.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-06 15:00:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 13:40:07-07:00",
    "text": "This extension (much like  draft-ietf-manet-dlep-pause-extension ) seems to provide a mechanism to direct a modem to drop traffic in an unauthenticated fashion -- for directly connected networks via the terminate action; and for multi-hop networks via the suppress action. For example, per the mobile scenario in Section 4 of  RFC8175 , a compromised laptop in the switch could use this extension instruct the modem to drop packets without authentication. I saw in Warren\u2019s comment ballet on  draft-ietf-manet-dlep-pause-extension  ( https://datatracker.ietf.org/doc/draft-ietf-manet-dlep-pause-extension/ballot/ ) that  \u201cLou will add: \u00a0 Implementations of the extension defined in this document MUST support \u00a0  configuration of TLS usage, as describe in , \u00a0  in order to protect configurations where injection attacks are \u00a0  possible, i.e., when the link between a modem and router is not \u00a0  otherwise protected.\u201d I believe the same caveat is needed in this draft as they are enabling similar behavior.\u00a0 Please correct me if I\u2019m conflating the capabilities of this extension with the pause extension.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-07-06 07:49:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-07-06 06:12:54-07:00",
    "text": "1. I want to come back to the experimental status. I have seen Alia's reply: \u00a0 \u00a0 In the BIER Charter, work item 9 describes a document based on deployment \u00a0 \u00a0 experience that can justify moving the BIER work from Experimental to Standards \u00a0 \u00a0 Track.\u00a0 When I chartered the WG, it wasn't clear whether it was merely a good idea \u00a0 \u00a0 or a good idea with enough motivations towards deployment that it is worth complicating \u00a0 \u00a0 the architecture at the narrow point of the IP hourglass. From the writeup, it seems that the experiment is successful already: \u00a0 \u00a0 The vendors are being quite tight lipped about current implementations. \u00a0 \u00a0 Operator feedback indicates there are at least two implementations currently, with others in the works. \u00a0 \u00a0 There are currently five vendors collaborating on the work in the IETF.  However, I've not been following the specifications development and implementation to provide a definitive answer. At the minimum, the document needs to describe what the criteria are for a successful experiment. \u00a0 \u00a0 Implementations ( RFC7942 ?)? \u00a0 \u00a0 two interop implementations? \u00a0 \u00a0 hardware implementation? \u00a0 \u00a0 \"deployment experience\" (to cite the charter text)? \u00a0 \u00a0 impact analysis? \u00a0 \u00a0 something else? The ideal BIER document for this explanation is this architecture doc. A reference to the charter Item 9 would be a good start. Examples: https://tools.ietf.org/html/rfc7360#section-1.3 https://tools.ietf.org/html/rfc7499#section-2 2. operations and management section I'm sure there are such considerations: \u00a0 \u00a0 - configuration \u00a0 \u00a0 - sub-domain management \u00a0 \u00a0 - BFR-id management \u00a0 \u00a0 - adding new BFIR/BFER device to the domain \u00a0 \u00a0 - logging \u00a0 \u00a0 - troubleshooting \u00a0 \u00a0 - OAM \u00a0 \u00a0 - etc. There are also two other management documents that should be referenced: chartered item 6 and 7. There are some management sentences, from time to time, in the doc. Ex: avoiding a second copy is an important from an operational point of view \u00a0  It is generally advantageous to assign the BFR-ids of a given sub- \u00a0  domain so that as many BFERs as possible can be represented in a \u00a0  single bit string. \u00a0  ... \u00a0  In order to minimize the number of copies that must be made of a \u00a0  given multicast packet, it is RECOMMENDED that the BFR-ids be \u00a0  assigned \"densely\" (see Section 2) from the numbering space... \u00a0 \u00a0 Btw, I guess you meant: assigned densely per subdomain, right? What this \"operations and management section\" should contain is the points that operators, who will deploy this technology, have to pay attention to. An architecture document is typically the first document people will read.  RFC 5706  appendix A provide typical questions from an OPS point of view. I understand that this is an experiment and you might not have all the answers at this point in time.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-09-13 08:33:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-06 07:49:27-07:00",
    "text": "1. operations and management section I'm sure there are such considerations: \u00a0 \u00a0 - configuration \u00a0 \u00a0 - sub-domain management \u00a0 \u00a0 - BFR-id management \u00a0 \u00a0 - adding new BFIR/BFER device to the domain \u00a0 \u00a0 - logging \u00a0 \u00a0 - troubleshooting \u00a0 \u00a0 - OAM \u00a0 \u00a0 - etc. There are also two other management documents that should be referenced: chartered item 6 and 7. There are some management sentences, from time to time, in the doc. Ex: avoiding a second copy is an important from an operational point of view \u00a0  It is generally advantageous to assign the BFR-ids of a given sub- \u00a0  domain so that as many BFERs as possible can be represented in a \u00a0  single bit string. \u00a0  ... \u00a0  In order to minimize the number of copies that must be made of a \u00a0  given multicast packet, it is RECOMMENDED that the BFR-ids be \u00a0  assigned \"densely\" (see Section 2) from the numbering space... \u00a0 \u00a0 Btw, I guess you meant: assigned densely per subdomain, right? What this \"operations and management section\" should contain is the points that operators, who will deploy this technology, have to pay attention to. An architecture document is typically the first document people will read.  RFC 5706  appendix A provide typical questions from an OPS point of view. I understand that this is an experiment and you might not have all the answers at this point in time.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-07-05 12:22:51-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-05 10:59:20-07:00",
    "text": "I agree with Ben, but feel more strongly than him - why is this Experimental? Where is the experiment / how do you determine if it is successful? The shepherd writeup says: \"(1) Experimental, as per charter. The document title page header indicates experimental. \", but this doesn't really answer the question; the charter says:  \"BIER is initially chartered to do experimental work on this new multicast forwarding mechanism as follows: 1) BIER architecture: The WG will publish an architecture, based upon draft-wijnands-bier-architecture-04....\" I really think that this document should be Informational or PS, or something. I can understand the *work* to be experimental in nature, but the document *itself* seems like it shouldn't be - it doesn't (really) explain how to implement.  I'm making this a DISCUSS, but am more than happy to clear if the chairs / AD says that the've considered this and Experimental really is best.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-02 08:12:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-01 06:15:02-07:00",
    "text": "Thank you for a well written document. It was a pleasure to read. I have a small set of issues that I would like to be fixed before recommending approval of this document. 1) In 3.1: \u00a0  DOTS data channel configuration information as well as state \u00a0  information can be retrieved with the GET method.\u00a0 An HTTP status- \u00a0  line header field is returned for each request to report success or I know this text is copied from  RFC 8040 , but \"status-line header field\" is not correct. It is either \"status-line\" or \"header field\". (A header field always has \":\" in it and HTTP status-line doesn't). I think you meant the former. If I misundestood and this is a part of payload itself, then your document should have an example. \u00a0  failure for RESTCONF operations (Section 5.4 of [ RFC8040 ]).\u00a0 The \u00a0  \"error-tag\" provides more information about encountered errors \u00a0  (Section 7 of [ RFC8040 ]). 2) 5.1.\u00a0 Registering DOTS Clients \u00a0  In order to make use of DOTS data channel, a DOTS client MUST \u00a0  register to its DOTS server(s) by creating a DOTS client ('dots- \u00a0  client') resource.\u00a0 To that aim, DOTS clients SHOULD send a POST \u00a0  request (shown in Figure 11). \u00a0 \u00a0 POST /restconf/data/ietf-dots-data-channel:dots-data HTTP/1.1 \u00a0 \u00a0 Host: {host}:{port} \u00a0 \u00a0 Content-Type: application/yang-data+json \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0 \"ietf-dots-data-channel:dots-client\": [ \u00a0 \u00a0 \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cuid\": \"string\" \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 ] \u00a0 \u00a0 } Your example is syntactically invalid, as you need an empty line after the Content-Type header field (before the payload). The same issue is pretty much in every example in your document. 3) In the same section 5.1: \u00a0  DOTS servers can identify the DOTS client domain using the 'cdid' \u00a0  parameter or using the client's DNS name specified in the Subject \u00a0  Alternative Name extension's dNSName type or SRV-ID in the client \u00a0  certificate. SRV-ID needs a Normative reference to  RFC 6125 . Also, can you give an example of how SRV-ID is going to be used?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-09 09:29:41-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 08:12:45-07:00",
    "text": "Thank you for a well written document. It was a pleasure to read. I have a small set of issues that I would like to be fixed before recommending approval of this document. 1) resolved 2) 5.1.\u00a0 Registering DOTS Clients \u00a0  In order to make use of DOTS data channel, a DOTS client MUST \u00a0  register to its DOTS server(s) by creating a DOTS client ('dots- \u00a0  client') resource.\u00a0 To that aim, DOTS clients SHOULD send a POST \u00a0  request (shown in Figure 11). \u00a0 \u00a0 POST /restconf/data/ietf-dots-data-channel:dots-data HTTP/1.1 \u00a0 \u00a0 Host: {host}:{port} \u00a0 \u00a0 Content-Type: application/yang-data+json \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0 \"ietf-dots-data-channel:dots-client\": [ \u00a0 \u00a0 \u00a0 \u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cuid\": \"string\" \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 ] \u00a0 \u00a0 } Your example is syntactically invalid, as you need an empty line after the Content-Type header field (before the payload). The same issue is pretty much in every example in your document. 3) resolved",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-22 05:10:36-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 04:24:39-07:00",
    "text": "I support Suresh's discuss that the process of how it is indicated if a 1 or 2 byte mask is used is not clear. However, I would additionally like to discuss why this bit mask is needed at all. The TCP flags field in  RFC8519  is already defined as bits. Storing these bits in a signal 8 bit field and applying a matching operation is implementation specific only and doesn't require any changes to the YANG model. I would also quickly like to discuss the use of keep-alives as described in Section 3.1:  \"While the communication to the DOTS server is \u00a0  quiescent, the DOTS client MAY probe the server to ensure it has \u00a0  maintained cryptographic state.\u00a0 Such probes can also keep alive \u00a0  firewall and/or NAT bindings.\u00a0 A TLS heartbeat [ RFC6520 ] verifies \u00a0  that the DOTS server still has TLS state by returning a TLS message.\" I understood that multiple requests can and should be send in the same connection, however, I would expect that those requests are send basically right after each other, such as a look-up and then change of the config. I don't see a need to keep up the connection for a long time otherwise. Especially any action performed are (other than in the signal channel case) not time critical. Therefore I would rather recommend to close and reopen connections and not recommend to use keep-alives at all.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-05-21 20:38:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 13:34:34-07:00",
    "text": "* Section 4.3 The processing requirements for the tcp flags bitmask is not at all clear. Specifically how should an implementation use the values in the flags, operator and the bitmask fields in the tcp subtree to figure out if a given packet matches. An example here could be very helpful. \"Bitmask values can be encoded as a 1- or 2-byte bitmask.\"  How? The bitmask field is a uint16. How would a client indicate a 1 byte bitmask?  [Also note that there are *nine* flags defined for TCP including the experimental NS bit that occurs as bit 7 of Octet 12 and a 1 byte bitmask will not catch them all]",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-19 19:40:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-19 19:39:31-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, Figure 8 --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is inteded to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-19 19:41:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-19 19:40:23-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, and Figure 8. --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is inteded to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-19 19:41:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-19 19:41:18-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, and Figure 8. --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is intended to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-07-06 15:55:20-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-19 19:41:59-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, and Figure 8. --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is intended to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-03-12 14:36:28-07:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 01:22:57-08:00",
    "text": "Thanks to everyone who has contributed to this document over the many years of its development. The document currently appears to contain normative statements that, while not literally contradictory, certainly point implementors in conflicting directions. \u00a75.1.1.1 says: >\u00a0 o\u00a0 Host candidates corresponding to IPv6 link-local addresses MUST >\u00a0 \u00a0  NOT be gathered. Further down, \u00a76.1.2.2 says: >\u00a0 To keep the amount of resulting candidate pairs >\u00a0 reasonable and to avoid candidate pairs that are highly unlikely to >\u00a0 work, IPv6 link-local addresses [ RFC4291 ] MUST NOT be paired with >\u00a0 other than link-local addresses. This second passage is nonsensical if IPv6 link local addresses MUST NOT be gathered. Please remove or amend one of these normative statements. If the first statement is retained, please add rationale. (As an aside, it makes more sense to cite 4291 the first time you mention IPv6 link local address rather than the second)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-03-04 21:27:21-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-20 21:03:20-08:00",
    "text": "* Section 5.2.\u00a0 Lite Implementation Procedures \"For dual-stack hosts, the IPv4 address is RECOMMENDED.\" I am trying to understand the reasoning behind this unequivocal choice (which probably might have made sense in 2010). At least, there is some explanatory text required to justify this.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-07 21:13:34-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-28 16:05:20-08:00",
    "text": "I don't think there's enough clarity on what authentication schemes are supported and how the YANG configuration interacts with MSDP operation. If I'm reading^Wsearching through  RFC 3618  correctly, the only supported authentication mechanism is TCP-MD5 ( RFC 2385 ), and there have been no updates to  RFC 3618  that are indicated in the RFC database.\u00a0 However, RFC 2385  is obsoleted by  RFC 5925  (TCP-AO).\u00a0 Can TCP-AO be used with  MSDP?\u00a0 What protocol elements or operation are controlled by the \"authentication\" container?\u00a0 What algorithms are valid for use with the \"password\" case?\u00a0  RFC 8177  is the sole reference for both the \"key-chain\" leaf and the \"password\" case, but that does not seem a sufficient reference from which to implement.  Also, there are a couple of elements in the \"state-attributes\" container that say they indicate a time when something will/did happen and measure it in seconds.\u00a0 I don't see an indication of what the reference point is for them, though -- \"seconds since when?\".\u00a0 Further context in the  COMMENT to avoid too much quoted text here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-21 17:50:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 09:39:23-08:00",
    "text": "This yang modules makes use of  RFC8177 \u2019s ietf-key-chain module.\u00a0 Please add a reference to this draft inheriting  RFC8177 \u2019s security considerations and associated considerations (see  draft-ietf-ospf-yang  for reusable language).\u00a0  Please also clarify the link between the password and  RFC8177  per the following snippet of the YANG module in the Security Considerations. \u00a0 \u00a0 grouping authentication-container { ... \u00a0 \u00a0 \u00a0 container authentication { \u00a0 \u00a0 \u00a0 \u00a0 if-feature peer-authentication; ... \u00a0 \u00a0 \u00a0 \u00a0 choice authentication-type { ... \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case password {",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-26 21:48:49-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-13 15:33:11-07:00",
    "text": "(1) The statement \"Bytes with no bits set at the end of the byte string are removed.\" in Section 6.7 seems confusing to the point of being potentially harmful, and I'm not sure why it needs to be there.\u00a0 In the context it appears in, it seems to leave the value to be used for the bit string offset in an ambiguous state.\u00a0 If the intent is that such strings should not be generated (and MAY/SHOULD/MUST be rejected by recipients), that's okay, but having them silently ignored is very surprising and may merit discussion. (2) I think we should discuss the relationship between this document and draft-ietf-core-sid , which are before the IESG at the same time.\u00a0 This document says that core-sid is \"one example for\" a specification defining the management of SIDs, but  draft-ietf-core-sid  claims to be the document that \"defines the semantics, the registration, and assignment processes of YANG SIDs\".\u00a0 I'm having a hard time seeing the two statements as compatible with each other, but maybe I'm missing something. (3) The second example of instance-identifier using SID (\u00a76.13.1) seems malformed, with \"key name country\" appearing under both \"list user\" and \"list authorized-key\" and no \"country\" leaf within \"list user\" other than the one under \"list authorized-key\".\u00a0 (The actual identityref example appears to correctly only use \"name\" as the key for \"list user\" and not \"list authorized-key\".) (4) Relatedly, the second example of instance-identifier by name (\u00a76.13.2) does not show a country for \"authorized-key\", and I'm not sure if that's a valid way to represent the given YANG element.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-01-05 09:15:44-08:00",
    "end_reason": "position_updated",
    "start": "2021-07-15 06:35:13-07:00",
    "text": "Thanks for this document, it is good work, and I think that there specification is almost there, but that the text could be tightened up in a few places. 1. The document should be clearer on its use of terminology around schema nodes.\u00a0 Mostly the encoding related to YANG data nodes, not YANG schema nodes.\u00a0 I've provided more information in the comments section. 2. As also raised by Ben, this document should probably cover the YANG data structure extension in  RFC 8791 .\u00a0 This could potentially be done in addition to rc:yang-data, but perhaps better in its place. 3. Did the WG consider supporting encoding YANG metadata ( RFC 7952 )?\u00a0 Presumably this would be expected to be covered as future work? 4. How does the CBOR encoding of SIDs apply to YANG features?\u00a0 This draft references features and the SID draft allows SIDs for them, but I don't understand how they are used in the encoding (since features don't appear in the instance data, they are only at the schema level).  5. I also support Ben's second discuss point.\u00a0 I think that as written, this draft needs a normative reference to the SID draft.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2018-05-10 06:28:12-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-09 09:27:16-07:00",
    "text": "I would like to DISCUSS about the Intended Status of this document -- with the Chairs and AD. I have to confess that I haven't been following the homenet WG as closely as I probably should have.\u00a0 Hopefully that means that the topic below has been discussed and documented already, making this DISCUSS easy to resolve. Back in 2015, the then-Chairs and the AD posted a note titled \"Routing Design Team outcome and next steps\"[1]; in it, they declared \"rough consensus that Babel[*] shall be the \u201cmandatory to implement\u201d routing protocol for Homenet routers, albeit only on an Experimental basis at this time...we solicit Experimental Internet Drafts to document Homenet-specific profiles of any applicable routing solution and to report results of any relevant experimentation and implementation.\u00a0 We expect that this decision will be revisited in a future Standards Track document based on specifications and running code available at that time.\" My interpretation of the above text is that Babel is MTI, but that the work (documents) will be Experimental...and that this decision could change in the future (most likely towards confirming and moving to the Standards Track).\u00a0 This document was originally adopted as Experimental.\u00a0 I didn't find an explicit discussion on the list about changing that original overall direction, nor another declaration by the Chairs/AD.\u00a0 I did find find a thread in which one of the Chairs (Barbara) asked about the status for this document (and this document only)[2]; the initial question was framed around the references being Standards Track documents (HNCP and rfc6126bis) -- just one answer came back (from the author of this document)... I'm treating this point as a DISCUSS because I think that the WG consensus may have not been determined to change the original declaration from the Chairs/AD (from 2015).\u00a0 In my interpretation of that original declaration, moving Babel to the Standards Track means a recognition that it will be *the* protocol going forward (which changes that initial \"only on an Experimental basis at this time\" phrase), is something that should be discussed explicitly, and not just in light of this one document.\u00a0 That is the part that I haven't seen. I note that in the conclusion of the thread about the status of this document [3] Barbara does include reasoning that may result in changing the original declaration (as does the Shepherd writeup), for example: \"there exist multiple, interoperable implementations\" and \"no drafts proposing other homenet routing protocol profiles have been submitted\"...but those points don't seem to have been considered/discussed by the WG (they were not in the original message and I didn't find another thread -- I also looked at the minutes of the last couple of IETF meetings). To be clear, I have no objection with Babel being used in homenet applications, or with it being the Standard protocol.\u00a0 My point here is that it is not clear to me that the WG explicitly reached consensus to change the declaration from the Chairs/AD.\u00a0 I will be happy to clear this DISCUSS when the Chairs/AD point me to the discussion that I missed, or simply tell me that the declaration from 2015 is no longer valid and that the WG knows, or that they believe that the thread discussing this document is enough to call consensus...or something to that effect. [1]  https://mailarchive.ietf.org/arch/msg/homenet/kiI7pIYfpgT2Qrfx1VBAwng7_QY [2]  https://mailarchive.ietf.org/arch/msg/homenet/5L5WYN14gDCamP7qlknJmWkeU5M [3]  https://mailarchive.ietf.org/arch/msg/homenet/35EU8oBr8hunvvSRYUStypZIPVU",
    "type": "Discuss"
  },
  {
    "ad": "Brian Haberman",
    "end": "2016-01-19 09:36:35-08:00",
    "end_reason": "position_updated",
    "start": "2015-09-30 06:09:26-07:00",
    "text": "I support the publication of this document given the need for experimentation in this area. However, there is one point that I would like to discuss... Section 3 contains R-1 which says that this marking \"needs to be visible to all ConEx-capable nodes on the path.\" Additionally, Section 5 says that the choice of using an IPv6 Destination Option precludes non-ConEx-capable devices from having to deal with the extension header. However,  RFC 2460  clearly says that Destination Options are not inspected by intermediate devices. We all know that a variety of intermediate devices ignore the rule in 2460.\u00a0 Given that, I would like this document to explicitly state that it does not abide by the rule in 2460 so that implementations that do follow 2460 but want to support this approach know to update all their extension header processing code.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-01-10 16:26:17-08:00",
    "end_reason": "position_updated",
    "start": "2015-09-30 12:22:49-07:00",
    "text": "I think this should be easy to address, but wanted to discuss options for the text in section 7.\u00a0 Since there is text that says IPsec Authentication should be used when integrity protection and the section goes on to also discuss encryption, shouldn't there be a similar statement that says IPsec encryption should be used when there is a need to protect confidentiality? Also, in reading this, I think because of the selected wording, I was thinking that it wasn't clear enough on the need/recommendation for authentication or encryption with IPsec since there are options for both to be set to NULL/none.\u00a0 You can have a NULL cipher-suite and you can also have authentication set to none to allow for opportunistic security negotiations (fairly new RFC for the latter).\u00a0 There's no need to mention these options explicitly, but rather to make it clear that IPsec can be used to provide authentication and encryption.\u00a0 So I think one additional sentence and some possible rewording in this section would be helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 10:06:52-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 11:27:04-07:00",
    "text": "I support Roman's DISCUSS. Overall I am unclear on the privacy properties of what this document specifies. I think it would help to have a clear statement about the circumstances under which each kind of address generation scheme is recommended. Were  RFC 4941  addresses not considered because addresses generated according to  RFC 8064  have functionally equivalent properties given how often moving vehicle change subnets? For link-local addresses, is it possible to give recommendations for when IIDs should be re-generated?  = Section 5.2 = \"An Interface ID SHOULD be of length specified in other documents.\" Isn't the length specified for each of the two IID generation mechanisms discussed in Section 4.3 and 4.4? = Section 5.3 = \"The demand for privacy protection of vehicles' and drivers' \u00a0  identities, which could be granted by using a pseudonym or alias \u00a0  identity at the same time, may hamper the required confidentiality of \u00a0  messages and trust between participants\" Pseudonymity and confidentiality are not mutually exclusive, so I think this is incorrect.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-11 06:37:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 21:00:58-07:00",
    "text": "A very simple point to fix: I think that IEEE-802.11-2016 should be normative because it is the reference for 802.11-OCB and is the subject of a MUST in Section 4.2.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-26 14:39:24-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-09 09:43:10-07:00",
    "text": "One point on this sentence, which I believe was also commented in the TSV-ART review (Thanks J\u00f6rg!): sec 4.2: \"The mapping to the 802.11 data service MUST use a \u00a0  'priority' value of 1, which specifies the use of QoS with a \u00a0  'Background' user priority.\" I don't think this should be a MUST requirement. I assume the assumption here is that IP traffic is always some \"random\" data that is less important than other V2V communication. However, this is a generic mapping document and should therefore probably not make such an assumption (or at least it would need to be spelled out).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-09 13:03:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-09 13:02:34-07:00",
    "text": "A few items per the text in the Security Considerations (Section 5): (1) Section 5.\u00a0 Per \u201cA previous work at SAVI WG identifies some threats [ RFC6959 ], while SeND presented in [ RFC3971 ] and [ RFC3972 ] is a solution against address theft but it is complex and not deployed.\u201d, a few questions: ** What specific threats from  RFC6959  are of concern?\u00a0 Which mitigations for them are being proposed? ** Why mention SeND if it is \u201ccomplex and not deployed\u201d? (2) Section 5.\u00a0 Per \u201cMore IETF protocols are available in the toolbox of the IP security protocol designer.\u00a0 Some ETSI protocols related to security protocols in ITS are described in [ETSI-sec-archi].\u201d: ** Are there specific protocols to mention here?\u00a0 Would they be different/OCB-specific than what was already noted in the beginning of the section -- \u201cAny security mechanism as the IP layer or above that may be carried out \u2026\u201d? ** What specific ETSI protocols are being recommended from [ETSI-sec-archi]?\u00a0  (3) Section 5.2.\u00a0 Per \u201cAn Interface ID SHOULD be of length specified in other documents\u201d, what other documents? (4) Section 5.3\u00a0 I\u2019m having trouble following this section \u2013 is this a discussion of a threat or mitigation?\u00a0 The references to Section 4.4 and 5.0 didn\u2019t clarity this for me. ** What is meant by the drivers\u2019 identity in this case?\u00a0 What is the pseudonym scheme is being used to protect it or what requirements are being set for it? ** What are the specific challenges of concern around pseudo-anonymization approaches to which an allusion is made? ** Who is the trusted third parted needed?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-09 13:03:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-09 13:03:10-07:00",
    "text": "A few items per the text in the Security Considerations (Section 5): (1) Section 5.\u00a0 Per \u201cA previous work at SAVI WG identifies some threats [ RFC6959 ], while SeND presented in [ RFC3971 ] and [ RFC3972 ] is a solution against address theft but it is complex and not deployed.\u201d, a few questions: ** What specific threats from  RFC6959  are of concern?\u00a0 Which mitigations for them are being proposed? ** Why mention SeND if it is \u201ccomplex and not deployed\u201d? (2) Section 5.\u00a0 Per \u201cMore IETF protocols are available in the toolbox of the IP security protocol designer.\u00a0 Some ETSI protocols related to security protocols in ITS are described in [ETSI-sec-archi].\u201d: ** Are there specific protocols to mention here?\u00a0 Would they be different/OCB-specific than what was already noted in the beginning of the section -- \u201cAny security mechanism as the IP layer or above that may be carried out \u2026\u201d? ** What specific ETSI protocols are being recommended from [ETSI-sec-archi]?\u00a0  (3) Section 5.2.\u00a0 Per \u201cAn Interface ID SHOULD be of length specified in other documents\u201d, what other documents? (4) Section 5.3\u00a0 I\u2019m having trouble following this section \u2013 is this a discussion of a threat or mitigation?\u00a0 The references to Section 4.4 and 5.0 didn\u2019t clarity this for me. ** What is meant by the drivers\u2019 identity in this case?\u00a0 What is the pseudonym scheme is being used to protect it or what requirements are being set for it? ** What are the specific challenges of concern around pseudo-anonymization approaches to which an allusion is made? ** Who is the trusted third parted needed?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-25 15:27:46-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-09 13:03:25-07:00",
    "text": "A few items per the text in the Security Considerations (Section 5): (1) Section 5.\u00a0 Per \u201cA previous work at SAVI WG identifies some threats [ RFC6959 ], while SeND presented in [ RFC3971 ] and [ RFC3972 ] is a solution against address theft but it is complex and not deployed.\u201d, a few questions: ** What specific threats from  RFC6959  are of concern?\u00a0 Which mitigations for them are being proposed? ** Why mention SeND if it is \u201ccomplex and not deployed\u201d? (2) Section 5.\u00a0 Per \u201cMore IETF protocols are available in the toolbox of the IP security protocol designer.\u00a0 Some ETSI protocols related to security protocols in ITS are described in [ETSI-sec-archi].\u201d: ** Are there specific protocols to mention here?\u00a0 Would they be different/OCB-specific than what was already noted in the beginning of the section -- \u201cAny security mechanism as the IP layer or above that may be carried out \u2026\u201d? ** What specific ETSI protocols are being recommended from [ETSI-sec-archi]?\u00a0  (3) Section 5.2.\u00a0 Per \u201cAn Interface ID SHOULD be of length specified in other documents\u201d, what other documents? (4) Section 5.3\u00a0 I\u2019m having trouble following this section \u2013 is this a discussion of a threat or mitigation?\u00a0 The references to Section 4.4 and 5.0 didn\u2019t clarity this for me. ** What is meant by the drivers\u2019 identity in this case?\u00a0 What is the pseudonym scheme is being used to protect it or what requirements are being set for it? ** What are the specific challenges of concern around pseudo-anonymization approaches to which an allusion is made? ** Who is the trusted third parted needed?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-03-17 15:21:31-07:00",
    "end_reason": "position_updated",
    "start": "2018-03-06 12:44:55-08:00",
    "text": "This should hopefully be easy to fix and was pointed out by the Gen-ART reviewer: All of section 4.3 is confusing as to what the length of the TLV really is. Row 3 in the diagram says 2 bytes or 4 bytes, but the number of bits called out in bullets 4 and 5 below it don't seem to add up to those things. Maybe it would be better to draw a diagram with F=0 and a separate diagram with F=1. Please make it clear both in the diagram and in the text what the expected lengths of the fields are -- I find it particularly confusing that the number of bits pictured doesn't align with the number of bits specified in the text per field.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2018-03-18 05:38:57-07:00",
    "end_reason": "position_updated",
    "start": "2018-03-05 13:34:19-08:00",
    "text": "This document feels tightly coupled with  draft-ietf-trill-directory-assisted-encap , even though there are no cross-references.\u00a0 If I understand the mechanisms correctly, a Smart Endnode (discussed in this draft) can then do directory assisted encapsulation (described in  draft-ietf-trill-directory-assisted-encap ).\u00a0 In fact, the encapsulation/decapsulation seems to be the main motivation in defining a Smart Endnode. I think then that this document also falls short in the exploration of potential issues, so I am also balloting DISCUSS.\u00a0 The same cases that I pointed at for  draft-ietf-trill-directory-assisted-encap  [1] are applicable here -- with the added caveat that the Smart Endnode, in general, has other sources of information (learning, etc.), which means that there are potentially more doors to close. The Multi-homing Scenario (Section 6) adds some complexity to the ability to check whether the Ingress RBridge is set correctly in the encapsulation.\u00a0 It would be nice to explore this case a little further and highlight the issues as the topologies get more complex. As I wrote in [1], I don't think that there are easy mitigations for these issues, but at least mentioning them so that operators are aware of the risk would be enough to clear this DISCUSS.\u00a0 Given that the authors partially overlap, it may be a good idea to solve the issue in this document (which is the general case) and then just have the other one point this way. [1]  https://mailarchive.ietf.org/arch/msg/trill/xZvEj_9FtSgHSp4DnKCVxr670gc/?qid=1e5a9496ac80237a3f7cc6aeea09d24d",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-03-19 09:20:17-07:00",
    "end_reason": "position_updated",
    "start": "2018-03-08 05:44:52-08:00",
    "text": "Review in context at:  https://mozphab-ietf.devsvcdev.mozaws.net/D3548 \u00a0  Smart Endnodes would not bring more security and vulnerability issues \u00a0  than the TRILL ES-IS security defined in [ RFC8171 ]. \u00a0   IMPORTANT: I think you need to discuss the security implications of checking and/or not checking the smart endnodes MAC address (a MAY in S 5.2). My understanding is that TRILL is kind of wishy-washy on MAC spoofing in general, but if you *do* have some sort of MAC enforcement in place but you don't enforce here, then this obviously bypasses that. Similar comments apply to the SmartHello filtering, I think. \u00a0  Smart-Hellos can be secured by using Authentication TLVs based on \u00a0  [ RFC5310 ]. \u00a0   I concur with Ben that you should explain the consequences of doing this or not.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-09-27 11:14:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-15 06:05:29-07:00",
    "text": "I am balloting DISCUSS because I believe the specification is not clear enough. (1) The document recommends (5 separate times) that an ID \"SHOULD be identical to the value advertised\" in an existing TLV. If the other TLV is advertised, when is it ok for the values not to be the same?\u00a0 Why is this action recommended and not required? Should the receiver of these TLVs take any action if the values are not identical? (2) \u00a73.1: The requirement for the Router ID to be unique within the flooding scope of the LSP has been removed.\u00a0  Please help me understand why this change is ok.\u00a0 If the Router ID can be used to identify \"the router who generates the inter-AS reachability TLV\", not requiring unique values seems to go counter to that idea.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-21 18:46:53-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-15 05:16:10-07:00",
    "text": "Section 2 notes the use of EDNS0.\u00a0 Please provide guidance in Section 5.1 (Privacy Considerations) given the caution described in Sections 2 and 11.1 of  RFC7871 . This is likely the same feedback provided by Alissa Cooper in her ballot.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-12 05:53:35-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-22 20:27:51-07:00",
    "text": "(A simple editorial fix) Per Section 5.8.2 of [ I-D.ietf-ace-oauth-authz ], the name of the parameter in the C-to-AS communication is \u201cace_profile\u201d (not \u201cprofile\u201d).\u00a0 The \u201cace_profile\u201d parameter is mistakenly referenced as \u201cprofile\u201d in the following place: (a) Section 3.2.\u00a0  \u00a0  The AS can signal that the use of OSCORE is REQUIRED for a specific \u00a0  access token by including the \"profile\" parameter with the value \u00a0  \"coap_oscore\" in the access token response",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-06 18:54:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-18 19:53:19-07:00",
    "text": "Thanks for this document; it will be very nice to have this more-structured mechanism available for future HTTP header (and trailer) fields. (0) There seem to still be a few lingering internal inconsistencies that merit further discussion. Most notably, there is the inherent risk of skew when both prose algorithms and ABNF constructions are provided for the same structures. While Section 1.2 is careful to disclaim that the prose algorithm takes precedence over the ABNF for parsing, to my reading the coverage in the following paragraph of serialization procedures imply that it is the ABNF that is authoritative.\u00a0 In particular, \"[i]mplementations MAY vary from the specified behavior so long as the output still matches the ABNF\" seems to admit deviations from the prose algorithms but require compliance with the ABNF, in effect making the ABNF take precedence over the prose algorithm.\u00a0 Having a different description of the procedure normative for generation vs. consumption invites interoperability-affecting feature skew, such as the handling of empty lists as Julian noted on the list. Similarly, Section 3.1.1's prose says that inner lists are delimited \"by a single space\", but the ABNF uses (1*SP), allowing for more than one space. Additionally, when Section 4.2.3.2 discusses parsing parameter map keys, the handling for duplicate map key names is specified as overwriting the previous value, in contrast to the prose description (Section 3.1.2) that describes these keys as \"unique within the scope [of] the Parameters they occur within\".\u00a0 (While dictionary key names might be expected to have a similar behavior, I did not find conflicting text for that behavior.) Finally, at a prose level we employ needlessly different descriptions in several places for what is effectively the same procedure; while I do not think any of these affect interoperability (and thus the full details are in the COMMENT section), it does seem to be continuing the theme.\u00a0 (These are things like how we describe the algorithm to skip implicit-true for booleans, whether we initialize the output string to the empty string only to immediately add a constant literal character to it vs. initializing the output string to that literal character, etc.) A couple other points that may need further discussion: (1) What aspect(s) of structured field processing are case (in)sensitive? The only mentions I see of case sensitivity are in Section 4.2 discussing header field names and (implicitly) Section 4.2.2 discussing a \"character-for-character\" comparison of dictionary key names, but of course we cite  RFC 5234  for ABNF, which uses case-insensitive matching. On the other hand, base64 encoding requires case sensitivity for successful round-tripping of arbitrary binary data. (2) One of the stated goals of this document is to define intentionally strict processing rules, but there are several places where we could have removed additional optionality but elected to not do so.\u00a0 What is the criterion for \"too far\" towards strictness?\u00a0 For example, Section 4.2.7 gives optionality with respect to base64 padding (see COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-04 02:02:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 09:14:08-07:00",
    "text": "A. Section 3.1: \u00a0  The ABNF for Lists in HTTP fields is: \u00a0  sh-list\u00a0 \u00a0 \u00a0  = list-member *( *SP \",\" *SP list-member ) \u00a0  list-member\u00a0  = sh-item / inner-list \u00a0  Each member is separated by a comma and optional whitespace. To me there is a clarity issue that could lead to interoperability issues. Namely the difference in the meaning of whitespace between  RFC 7230  and this document. Structured headers appear to not allow the HTAB that  RFC7230  allows. And that is fine, but I would expect this to be more clearly discussed. If the intention was to allow for HTAB you need to use WSP rather than SP in above rule.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-05-20 08:25:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-17 15:17:15-07:00",
    "text": "This is probably a simple one, and perhaps I'm missing something obvious: Throughout Section 3, the document specifies minimum data structure sizes (1024 list members, 256 inner list members, 64-character keys, etc.) that the receiver MUST be able to process. What is the desired behavior if any of these data structures exceeds what the receiver can process? Must it skip the entire field, or can it process the first N entries and then ignore the rest? Given the \"Intentionally Strict Processing\" principle, it would be good to spell this out.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-21 05:31:59-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 13:29:32-07:00",
    "text": "(I appreciate that this is pseudo-code which has inherent ambiguity sometimes, so please let me know if I've interpreted it in an unintended way) ** Section 4.2.6.\u00a0 There appears to be an inconsistency here in my reading of the algorithm given the ABNF in Section 3.3.4 -- Let\u2019s assume of token of input_string =\u201c*foo\u201d -- Step 1: pass since input_string[0] = \u201c*\u201d -- Step 2: Set output_string = \u201c\u201d -- Step 3: pass since input_string[0] = \u201c*\u201d, -- Step 3.1: input_string[0] is still \u201c*\u201d and not a tchar, \u201c:\u201d or \u201c/\u201d causing a output_string=\u201d\u201d to be returned  This doesn\u2019t seem correct. ** Section 4.2.7.\u00a0 The parsing guidance doesn\u2019t follow for me given the ABNF in Section 3.3.5. -- Let\u2019s assume input_string = \u201c:cHJldGVuZCB0aGlzIGlzIGJpbmFyeSBjb250ZW50Lg==:\u201d, the example in Section 3.3.5 -- Step 1: pass since input_string[0] = \u201c:\u201d -- Step 2: Set input_string = \u201ccHJldGVuZCB0aGlzIGlzIGJpbmFyeSBjb250ZW50Lg==:\u201d -- Step 3: pass since the last character of input_string is \u201c:\u201d -- Step 4: Set b64_content = \u201ccHJldGVuZCB0aGlzIGlzIGJpbmFyeSBjb250ZW50Lg==\u201d -- Step 5 says \u201cconsume the \u201c:\u201d character at the beginning of the input_string, but there is no such character.\u00a0 It was discarded in Step 2.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-02-28 07:12:56-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-22 03:20:43-08:00",
    "text": "This is generally a well written document, despite certain repetition of text. It was a pleasure to read. I have a couple of issues that I would like to discuss. I believe they would be easy to resolve: 1) In Section 5.8, in the table (I believe this is repeated at least 3 more times elsewhere in the document):  Software Locator: \u00a0  A string containing the Software Locator value. \u00a0  This is expressed as a URI. This field value \u00a0  MUST be normalized to Network Unicode format as \u00a0  described in Section 3.4.4. At minimum this text is misleading (or can be misread) and at maximum it is wrong. I think what you are trying to say is that the location value is first normalized to Network Unicode format as described in Section 3.4.4, then it is converted in UTF-8 and then it is encoded as a URI. (As opposed to doing something else, e.g. convert to URI first and then trying to normalize it). If this is correct, I suggest: \u00a0  A string containing the Software Locator value. \u00a0  This is expressed as a URI [ RFC3986 ]. This field value \u00a0  MUST be first normalized to Network Unicode format as \u00a0  described in Section 3.4.4, then converted to UTF-8 [ RFC3629 ] \u00a0  (if not already in UTF-8), then encoded as a URI. 2) SWID registry is using \"http://invalid.unavailable\" Tag Creator RegID value. invalid.unavailable is not a valid domain name and \"unavailable\" is not registered in the special-use domain registry I am not entirely sure how big of a problem this is, but use of something which can be interpreted as a URI in a non existing non special-use domain seems like a bad idea.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-03-01 19:30:06-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-21 19:08:24-08:00",
    "text": "(This is related to one of Ekr's comments, but I don't think it's quite the same.) In the first paragraph of \u00a77.2, the conclusions seem to be based on the following sentence: \"This is generally not considered to be problematic, as \u00a0  those with access to the endpoint can usually learn of everything \u00a0  disclosed by that endpoint\u2019s records simply by inspecting other parts \u00a0  of the endpoint.\" This doesn\u2019t seem like a reasonable assumption. Multiuser endpoints may well have access controls that prevent a given user from seeing all software packages installed on the system. This leads to the conclusion that the records on the endpoint are not sensitive. I do not think this document should draw that conclusion. Even if this were provably true for all existing systems, such an assumption could be problematic for future systems.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-11-16 00:46:02-08:00",
    "end_reason": "position_updated",
    "start": "2017-08-28 19:36:20-07:00",
    "text": "This is probably just a matter of me being dense, but I'd like to understand what I am missing: Is it legal to mix certificate policies in a given cert path? The last paragraph of section 5 implies that you can, but doesn't say so explicitly. If you _can_ mix policies, what happens if you do? If I read the rules in 4.2.4.4. correctly (and it's likely that I am not), if you run into a cert in the chain that does not follow this profile, it's likely to give a null VRS-IP or VRS-AS value, which would seem to invalidate an certificate further down the chain that _does_ follow this policy? So, I guess it comes down to the following: If mixed policies are allowed, how does that work? If mixed policies are not allowed, there needs to be text that says that. It's quite possible such text exists (here or elsewhere), and I missed it.",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2018-01-21 17:27:05-08:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 20:29:22-07:00",
    "text": "Thank you for considering the stability of the internet's routing system during administrative changes to resources. One thing isn't quite clear to me, so I'm balloting this as a DISCUSS with the plan that a small amount discussion will resolve it. With the definition of the new validation OID (a idea that I like BTW), at any stage of the certificate issuance can the validation OID be switched? That is a TA has a particular OID and down the tree an issued certificate has a different OID? If that can't happen (and please make that clear in the document) is there plan to migrate the set of all issued certificates to the new OID? and deprecate the old OID? Logically speaking a trust anchor cannot be thought of as over-claiming. (eg you trust where the self signed cert came from, and its contents) However the new validation\u00a0 constructs suggest that a TA can over-claim, but it seems like there won't be any warning (as the example in S4.3)\u00a0 to highlight this possible eventuality when (in the model where all RIRs issue a TA) a resource is transferred from one RIR to another for the clients use. Is that interpretation correct? OR does this new model espouse the belief that all RIRs each issue a TA that covers 0/0 and ::/0 in perpetuity? In that construct does this mean that  RFC6491  should be updated or made historic?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-02-12 05:47:11-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-02 19:08:09-07:00",
    "text": "Deterministic ECDSA ( RFC6979 ) gets rid of a significant weakness with ECDSA. IIRC when JOSE was done there was a feeling that adding a MUST or SHOULD for that was tricky due to lack of support in libraries. When we recently re-checked for COSE, the answer was that today, it's ok to have that as a MUST or SHOULD. (If some kind of FIPS-140 stuff precludes a MUST, then a \"SHOULD unless you're sad enough to be stuck having to pay lip lipservice to FIPS-140\" clause might be right. So the DISCUSS point here is: given the real-world demonstrated weakness inherent in the need for an RNG in ECDSA why didn't the WG choose to at least RECOMMEND deterministic ECDSA? (Or better, make it a MUST.) If the answer is: \"we thought about it [ref] and decided to not require deterministic\" then I'll clear. But even if the WG did consider it a couple of years ago, the situation may have changed so a quick re-think might be worthwhile.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-13 15:07:24-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 12:09:35-07:00",
    "text": "I applaud the deliberate consideration being provided for security matters.\u00a0 My concern is about the symmetry between the security claims being made and the level of detail being provided in the mechanisms. ** Definition of a HHIT. Various security claims are made about the HHIT down to specifying cryptographic algorithms and resistance to attacks.\u00a0 However, this document provides inconsistent and vague definitions for a HHIT.\u00a0 Surprisingly, it doesn\u2019t cite draft-ietf-drip-rid.\u00a0 It is difficult to assess these claims given the lack of information on a HHIT.\u00a0 I would have expected this architecture document to make high-level claims and leave the details to a standards-track document.\u00a0 A few places to source the HHTI definitions: -- Section 3 says \u2018\u2026 explains the use of Hierarchical Host Identity Tags (HHITs) [ RFC7401 ] \u2026\u201d,  RFC7401  defines HIT but not HHIT. -- Section 3 also says \u2018Self-asserting in this usage means that, given the Host Identity (HI), the HHIT ORCHID construction and a signature of the registry on the HHIT \u2026\u201d, but as doesn\u2019t explain that connection -- A few places in the text suggest that HHIT, as the name suggest are hierarchical, and this hierarchy is key to ensuring security properties (e.g., Section 3.2. \u201cThe cryptographically-bound addition of the Hierarchy \u2026\u201d; Section 3.4 says \u201cTo provide this, each HHIT embeds plaintext information designating the hierarchy within which it is registered and a cryptographic hash of that information concatenated with the entity's public key, etc. provides examples of computing a HHIT by encoding a HHIT\u201d; and Section 4.2.1. \u201cThe HHIT hierarchy\u00a0 can provide the needed scalability and management structure\u201d).\u00a0 Where is that hierarchy explained in this document?   This is up to the WG, but IMO, the discussion about cryptographic properties would be better suited in the document providing the specifics ( draft-ietf-drip-rid ) and the top-level security properties cited by reference here.\u00a0  ** Verification process of claims/assertions. -- Section 3.2.\u00a0 Each Observer device SHOULD be \u00a0  provisioned either with public keys of the DRIP identifier root \u00a0  registries or certificates for subordinate registries. -- Section 3.2 ... prepopulating small caches on Observer devices with Registry public \u00a0  keys and a chain of Attestations or Certificates (tracing a path \u00a0  through the Registry tree).\u00a0  Where is the behavior ensuring a trust relationship between registries described?\u00a0 These are no chains certificates in the X.509 sense. Where is the link between the \u201cDRIP identifier root registries\u201d and the verification of UA traffic?\u00a0 Is that  draft-ietf-drip-auth ? -- Section 5. \u00a0  Optimization of different DRIP Authentication Messages\u00a0 allows an \u00a0  Observer, without Internet connection (offline) or with (online), to \u00a0  be able to validate a UAS DRIP ID in real-time.\u00a0 First is the sending \u00a0  of Broadcast Attestations (over DRIP Link Authentication Messages) \u00a0  [ I-D.ietf-drip-auth ]\u00a0 containing the relevant registration of the UA's \u00a0  DRIP ID in the claimed Registry.\u00a0 Next is sending DRIP Wrapper \u00a0  Authentication Messages that sign over both static (e.g., above \u00a0  registration) and dynamically changing data (such as UA location \u00a0  data).\u00a0 Combining these two sets of information, an Observer can \u00a0  piece together a chain of trust and real-time evidence to make their \u00a0  determination of the UA's claims. How does the use of specific message work if the Observer is offline? As noted above, this is up to the WG, but IMO there is a level of detail here that distracts from the discussion of the architecture.\u00a0 It would be best covered by reference.  ** Section 9 \u00a0  Broadcast RID messages can contain Personally Identifiable \u00a0  Information (PII).\u00a0 A viable architecture for PII protection would be \u00a0  symmetric encryption of the PII using a session key known to the UAS \u00a0  and its USS ... Per \u201cA viable architecture ...\u201d, I\u2019m not sure how to read all the text after the first sentence given this phrasing.\u00a0 Is the rest of the text the official \u201cDRIP architecture\u201d or an example? I\u2019m assuming the former and believe it would benefit from its own set of security considerations.\u00a0 A few initial questions: -- Are there channel security requirements between the decryption oracle/key escrow or distribution server/USS and the Observer? -- Is there a strong authentication/authorization model to gain services from the USS? -- How does this oracle or key server approach work in the case an offline observer?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-21 17:55:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-18 18:53:16-07:00",
    "text": "The description of the QUOTA response in \u00a74.2.1 only says that the response can occur due to GETQUOTA and GETQUOTAROOT, but it is also described as a possible result of SETQUOTA, in \u00a74.1.3.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-21 07:36:26-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-11 05:58:12-07:00",
    "text": "DOWNREF [ RFC5257 ] from this Proposed Standard to Experimental  RFC5257 , which the IESG needs to approve on the telechat. (No action for the authors.) I'll note that the ballot write-up suggests a status-change for  RFC5257 , in case an ART AD feels inclined to take this on.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-27 23:54:44-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-26 06:57:46-07:00",
    "text": "(1) In 5.9.2, how are pre shared keys (PSK) updated or rotated?\u00a0 Don't you at least need some key id or versioning or old/new thing defined? (Apologies if that \"just works\" via some yang magic of which I'm unaware:-) (2) When someone wants to use IPsec with PSK, wouldn't you also need to specify algorithms etc to get interop?\u00a0 I see there's an \"algorithm\" string in the yang module, but that seems too underspecified to be useful.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-10-27 06:39:59-07:00",
    "end_reason": "position_updated",
    "start": "2016-10-26 10:13:22-07:00",
    "text": "I do have a concern about the definition of the IPv6 address allocation mechanisms. It looks like the service model assumes that one of these mechanisms will be used, while in reality more than one of these mechanisms might be in use at the same time. I just wanted to make sure that this was a considered decision and not an oversight.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-10 19:53:33-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-13 01:11:43-07:00",
    "text": "I agree with Roman that the authorization model seems under-developed. While I recognize that there is need for flexibility across various deployments, I think that we should be providing a default model (and procedures for it) that will apply in many cases, and let deployments specify alternate models if needed.\u00a0 This stuff is hard enough to get right that we should have a secure option that people can use if they don't need to have customized details.\u00a0 (To be clear, I agree with the change of focus from -24 to -25 on the properties that a security policy needs to provide and/or consider, as that is fundamentally the important thing.\u00a0 I just want a fallback/default option that \"does something reasonable in most cases\" in addition. Doing that by reference to some other existing thing would be fine, if such a thing exists.) In particular, the current text seems to rely on the authorization model including: (1) the RD knowing how clients will be using it (and thus what properties the RD needs to enforce), which in the general case cannot be known (though for static networks it could be), yet I don't see any discussion that indicates this as a prerequisite; and (2) the client either knowing out-of-band that an entity is authorized to act as a RD or just blindly trusting any of the unauthenticated (*) advertisement mechanisms.\u00a0 (* Yes, there may be some protection in the network on subscribing to the relevant multicast address, DNS-SD, etc., but the client cannot a priori know that such protections are in place.) Relatedly, the naming model and naming authority should have some clearer discussion.\u00a0 We do mention in Section 7 the possibility for a weak naming model where the RD is responsible for enforcing uniqueness of names but otherwise link attributes are the primary authorization criteria (vs. a traditional scheme with a naming authority and naming hierarchy), but with naming as a fundamental prerequisite of any authentication/authorization scheme, I think clearer discussion of how a naming model is to be selected (and, perhaps more importantly, that it must be fixed as part of a given deployment) for a given network is needed. If I understand correctly, we have some codepoint squatting going on in the examples (e.g., for resource types). We should talk about the security properties of the various RD discovery mechanisms that are defined.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-02-01 03:13:11-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-05 00:31:27-07:00",
    "text": "Thank you for the work put into this document. I am little puzzled by the document shepherd's write-up dated more than one year ago (the responsible AD has even changed and the change is not reflected in the write-up)... while well-written this write-up seems to indicate neither a large consensus nor a deep interest by the CORE WG community. But, I am trusting the past and current responsible ADs on this aspect. Did the authors check with 6MAN WG about the new RDAO option for IPv6 NDP ? I was unable to find any 6MAN email related to this new NDP option and, after checking with the 6MAN WG chairs, they also do not remember any discussion. BTW, I appreciated the use of ASCII art to represent an entity-relationship diagram ! Please find below a couple of non-blocking COMMENTs (and I would appreciate a reply to each of my COMMENTs) and 2 blocking DISCUSS points (but only trivial actions/fixes are required). I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.1 -- It will be trivial to fix, in IPv6 address configuration (SLAAC vs. DHCP) is orthogonal to DHCP 'other-information'. E.g., even if address is configured via SLAAC, DHCPv6 other-information can be used to configure the Recursive DNS Server (or possibly the RD). -- Section 4.1.1 -- Another trivial DISCUSS to fix: in which message is this RDAO sent ? I guess unicast Router Advertisement but this MUST be specified.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-01-29 14:27:36-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 00:05:52-07:00",
    "text": "[[ discuss ]] [ section 4.1.1 ] * Did this get presented to 6man at any point, either via mail to the list or \u00a0 chair or in a presentation slot at an IETF meeting or a 6man interim? \u00a0 I feel confident that there would be no objection to the option as described \u00a0 here, but the working group should have its chance to make an evaluation \u00a0 irrespective of my opinion. \u00a0 --- \u00a0 If this is to be used when link-local methods don't work, another option \u00a0 would have been to add an RD PVD API key and recommend including a PVD \u00a0 option. [ section 4.1.1 & 9.2 ] * Please clarify which ND messages can carry an RDAO.\u00a0 I suspect they should \u00a0 only appear in RAs, but it would be good to state the expectation explicitly. [ Appendix A. ] * Can you explain the ff35:30:2001:db8:1 construction?\u00a0  RFC 3306  section 4 \u00a0 defines some fine-grained structure, and I'm wondering how a group ID of 1 \u00a0 is selected/computed/well known.\u00a0 If there is already a COAP document \u00a0 describing this vis.  RFC 3307  section 4.*, perhaps it's worth dropping a \u00a0 reference in here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-11-15 16:21:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-11 19:57:28-07:00",
    "text": "There appear to be a few areas of straightforward, under-specified elements of the authorization model.\u00a0  -- How does the RD know that a node claiming to be a CT is in fact a CT and is permitted to register on behalf of end-points?\u00a0 It seems like there is a missing, simple statement to make that this is configured out of band with the RD?\u00a0 Or is that carrier somehow in a authentication credentials?\t -- Is there are reason why there is not normative guidance requiring the RD to check whether authentication clients are authorized to register particular resources?\u00a0 Section 7.1 covers the issue, but all of Section 7.* is explicitly noted as informative.\u00a0 Section 8.1. says \u201cEndpoint authentication needs to be checked independently of whether there are configured requirements on the credentials for a given endpoint name (Section 7.1) or whether arbitrary names are accepted (Section 7.1.1)\u201d but this text seems to frame it as authentication issue.\u00a0 Section 8.2 seems to stress only the distinction between the registration and lookup API. -- Section 8.1.\u00a0 Per \u201cIf the server does not check whether the identifier provided in the DTLS handshake matches the identifier used at the CoAP layer then it may be inclined to use the endpoint name for looking up what information to provision to the malicious device.\u201d, this is good advice.\u00a0 If DTLS PSK and RPK are used, what identifiers does the RD have to check to ensure the DTLS and CoAP layers match?\u00a0 Per 9.1.3.1. (for PSK) and 9.1.3.2.1 (for RPK) of  RFC7252  there is the notion of identifiers for DTLS but those don\u2019t manifest in CoAP?\u00a0 Additionally, when DTLS with a certificate is used, is it intended to compare the subjectAltName with the authority in the Registration Base URI (i.e., which exact certificate fields should it compare with the CoAP)?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-08-01 07:21:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 20:24:58-07:00",
    "text": "# Internet AD comments for { draft-ietf-add-dnr-11 } CC @ekline ## Discuss This seem like exceptionally minor points, but are hopefully easily dispatched. ### S4.1, S5.1, S6.1 * The example ADN encoding in S4.1 shows that the trailing null byte is \u00a0 included in the encoding (the label length of the DNS root). \u00a0 This raises the question: why do any of these options need an explicit \u00a0 ADN length?\u00a0 Given: the ADN is a mandatory message element, must be the \u00a0 first element in the message, and there can be no more than one such \u00a0 element, it seems that parsing bounded by the overall option length \u00a0 and validating the \"RFC1035-ness\" :-) of the span preceding the null byte \u00a0 might save a byte or two? \u00a0 (For comparison: the  RFC 8801  PVD ID FQDN did not require a length hint.) ### S4.1, 6.1 * If an ADN length is to be retained in these messages, why is the ADN length \u00a0 2 bytes in the IPv6 variants whereas in the DHCPv4 option a 1 byte length \u00a0 suffices?\u00a0 I know it seems silly to DISCUSS a 1 byte difference, but I \u00a0 figured it would be easy to either explain or fix. * Similarly, why is the Addr Length 2 bytes? \u00a0 My reckoning of a 1-byte addr length would be the ability to list up to \u00a0 15 IPv6 addresses for a single ADN.\u00a0 With 2 bytes a network can advertise \u00a0 ... over 4000 of them (for a single ADN)? My suspicion is that the variable length nature of the ADN component means these options are easily pushed out of 2/4/8 byte alignment, and there may not be much benefit to attempting to adhere to something that only appears like it might align well. (Being parsimonious with bytes may be more of a concern for RAs than DHCP.)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-08-03 10:44:23-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 12:00:30-07:00",
    "text": "After reading this document, I am unclear if it is permitted to omit IP addresses from the Encrypted DNS Option. It doesn't help that there are few normative keywords below: (3.1.6) \"In contexts where putting additional complexity on requesting hosts is acceptable, returning an ADN only can be considered.\" (3.1.8) \"the client makes the following validation checks:... the option includes at least one valid IP address and the \"alpn\" service parameter.\" (3.1.9) \"It is RECOMMENDED that at least the following DNR information... A list of IP addresses to locate the encrypted DNS resolver.\" The option formats seem to allow the possibility of having zero addresses. (\"0\" is a multiple of 4 and 16). I *think* you are saying it is possible to include an ADN, IP address(es), or both, but not neither, with \"both\" being RECOMMENDED. But that isn't really compatible with the client rejecting those as invalid in (3.1.8). If that is accurate, I would recommend: - deleting \"at least one valid IP address and\" from (3.1.8) - Updating (3.1.9) to say that while both are RECOMMENDED, at least one of ADN and IP Address(es) MUST be included.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-07-15 15:00:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-07-13 12:46:33-07:00",
    "text": "# Internet AD comments for { draft-ietf-add-dnr-11 } CC @paulwouters ## Discuss The overarching issue of the ADD WG in general is the concern that using the local network's DNS server (encrypted or not) is a privacy concern. With HTTP dying and HTTPS sealing the last plain-text with Encrypted Client Hello (ECH), DNS is the last resort of getting to know the enduser's intent of where they are trying to connect to. There are many parties interested in seeing the DNS query content, but the enduser is rarely able to determine whether the local network used can be trusted. This is true for coffee shops, hotels, malls but also their home ISP. The only clear case of trust is the enterprise user, who is provisioned (forced) via their enterprise management to use specific DNS resolvers. There are a number of well-known public DNS services such as Google DNS (8.8.8.8), Quad9 (9.9.9.9) and Cloudflare (1.1.1.1). Arguably, these servers have a better reputation of protecting the enduser's privacy than most local networks, as endusers cannot trust most local networks they use. The question all of this raises is, whether the user isn't better of just never trusting or using the local network's DNS server, whether encrypted or not. In that case, all of these ADD documents have little value. For example, we see this already with Firefox and its TRR program https://wiki.mozilla.org/Trusted_Recursive_Resolver  and to some extend with the Android phone \"private DNS\" feature https://www.howtogeek.com/795644/how-to-enable-secure-private-dns-on-android/ On the other hand, we have the argument of, if the enduser is using the local unencrypted DNS, it might as well use the local encrypted DNS. While this is true if this decision is hidden from the enduser, if the enduser believes they are using \"encrypted DNS\", they might not be aware that this encrypted connection still reveals all privacy sensitive data to the local network entity (or its trusted third party). An aware enduser might also make different choices when they think their DNS is \"safely encrypted\", such as visiting the website of an abortion provider. That is, the ADD specifications might lure the enduser in a false sense of security. To me this is one of the biggest issues while reviewing the ADD drafts. Are these drafts potentially harmful to the enduser, or does it only offer improvements to the status quo of the current common (non-encrypted) DNS topologies? While the latter could be true, I do believe based on the development seen at Google/Android and Mozilla/Firefox, I think we are already far into the phase where the enduser only decides _which_ remote trustworthy encrypted DNS service they are going to use and as such only use the local network DNS to kickstart their internet connection (captive portal, paywall) after which they switch to remote encrypted DNS service. And that of course, raises an issue with DNS security providers, who wish to monitor and firewall all their DNS clients' DNS requests to improve enduser security. This includes government mandates to ISPs to filter certain DNS requests for local legal reasons. Which again raises the issues of where such filtering power can be abused by authoritative regimes, restrictive cults (eg scientology netnanny). To summarize, I am really on the fence with respect to all the ADD drafts. While \"encrypted DNS\" is always better than \"unencrypted DNS\", the overarching issue of \"never use or trust the local DNS resolvers\" trumps the DNR /DDR protocols. For those who can dictate how their users MUST use DNS (eg Enterprise usage, parental control, opt-in security software), device provisioning/configuration options are available that require no ADD protocols with the exception of draft-ietf-add-svcb-dns. ### Encrypted DNS servers need a public FQDN because otherwise you cannot get a certificate for all connecting clients that are not provisioned with a private/enterprise CA. How do home users run their own without having a public domain? And how do I authenticate the encrypted DNS on 10.1.1.1 that has no FQDN? (and really, has no verifiable identity at all) ### \u00a0 \u00a0  The DNS client verifies the connection based on PKIX validation No CRLs, OneCRL updates, no OCSP, no Certificate Transparency is available without functional DNS. So full PKIX validation as specified here is not available. ### \u00a0 \u00a0  The DNS client uses Web PKI trust anchors by default unless \u00a0 \u00a0  configured otherwise. CAB/Forum is currently, as far as I know, not taking encrypted DNS into account for their BR's. Also, every OS and even some applications use their own \"webpki\" root store that differs from each other. This can lead to interoperability issues. ### Spoofing attacks are mentioned in the document. Obtain _any_ certificate from Let's Encrypt via ACME, eg using \" something.example.com \", then spoof authentication-domain-name on the wifi. While this attack might be blocked by the AP not allowing wifi clients to send packets to each other, this is not true for all networks, and especially not for home networks where the goal is for local clients to be able to connect to each other. Is there a better way to lock the authentication-domain-name? One possible method might be to bind it to the ESSID. eg if the ESSID is  wifi.nohats.ca . one could only allow authentication-domain-name to be a name within  nohats.ca . Some method of reducing the scope of this attack is needed I believe. ### \u00a0  authentication-domain-name (variable length):\u00a0 A fully qualified \u00a0 \u00a0 \u00a0 domain name of the encrypted DNS resolver.\u00a0 This field is \u00a0 \u00a0 \u00a0 formatted as specified in Section 10 of [ RFC8415 ]. \u00a0 \u00a0 \u00a0 An example of the authentication-domain-name encoding is shown in \u00a0 \u00a0 \u00a0 Figure 2.\u00a0 This example conveys the FQDN \" doh1.example.com .\", and \u00a0 \u00a0 \u00a0 the resulting Option-length field is 18. \u00a0 \u00a0 \u00a0  +------+------+------+------+------+------+------+------+------+ \u00a0 \u00a0 \u00a0  | 0x04 |\u00a0  d\u00a0 |\u00a0  o\u00a0 |\u00a0  h\u00a0 |\u00a0 1\u00a0  | 0x07 |\u00a0  e\u00a0 |\u00a0  x\u00a0 |\u00a0  a\u00a0 | \u00a0 \u00a0 \u00a0  +------+------+------+------+------+------+------+------+------+ \u00a0 \u00a0 \u00a0  |\u00a0  m\u00a0 |\u00a0  p\u00a0 |\u00a0  l\u00a0 |\u00a0  e\u00a0 | 0x03 |\u00a0  c\u00a0 |\u00a0  o\u00a0 |\u00a0  m\u00a0 | 0x00 | \u00a0 \u00a0 \u00a0  +------+------+------+------+------+------+------+------+------+ The draft says \"as specified in Section 10 of [ RFC8415 ]\" but that is just a redirect to Section 3.1 of [ RFC1035 ] which doesn't tell me how to encode the NAME. For example, I do not understand why one \".\" is encoded as 0x07 and another \".\" is 0x03 ? ### \u00a0 \u00a0 \u00a0 Addr Length:\u00a0 Length of enclosed IPv6 addresses in octets.\u00a0 When \u00a0 \u00a0 \u00a0 present, it MUST be a multiple of 16. Why not just a one octet counter then? The number of IPv6 addresses that follow. Then the length of the Addr field becomes counter times 16 octets. That seems more constrained than \"multiple of 16\" ### \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The diagrams lack reference octets. What is the width ? or 4 rows ? or ? I assume this is supposed to be 4 octets wide and 16 octets total? eg I would write: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ (also my pet peeve is people using +-+-+-+ instead of -----) ### \u00a0 \u00a0 \u00a0  A value of zero means that this Authentication Domain Name MUST no \u00a0 \u00a0 \u00a0  longer be used. Why not just omit the entry ? Are clients supposed to keep old entries for their entire lifetime even if when asking a new list, those entries no longer appear? That is not clear from this document. Either that should be made explicit, or the values of 0 should not be allowed. ### \u00a0  By default, Encrypted DNS connections received from outside the local \u00a0  network MUST be discarded by the encrypted DNS forwarder in a CPE. What is an \"encrypted DNS forwarder in a CPE\"? This is not defined in the document and I am confused. I assume the CPE announces some encrypted DNS server as either itself or to some external IP at the ISP network? If itself, how can it get a real FQDN the client can verify with PKIX using CAB/Forum ? If to an external IP, isn't it just acting as a NAT/router forwarding packets and then what does it mean to be an \"encrypted DNS forwarder\" ? ### \u00a0  This recommendation is meant to isolate local network \u00a0  DNS resolver services from the public Internet and prevent external \u00a0  attacks against the local Encrypted DNS resolver. \u00a0  If the DHCP responses or RAs are dropped by the attacker, the client \u00a0  can fallback to use a preconfigured encrypted DNS resolver. This raises the big question of why you think that strategy is a \"fallback strategy\" and not the default behaviour of the client. Wouldn't it be more secure if there is no DHCP/RA drop attacks possible? See my introduction text. ### Multihoming is declared out of scope, but realistically most devices we are talking about here are phones, and those are all multihomed. So I feel pretty strongly that it should not be left out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-08 15:18:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-15 15:00:09-07:00",
    "text": "# Internet AD comments for { draft-ietf-add-dnr-11 } CC @paulwouters ## Discuss ### How and where a user decides to send their DNS queries impacts their privacy. But the document lists no Privacy Considerations section as per  RFC 6973 ### Encrypted DNS servers need a public FQDN because otherwise you cannot get a certificate for all connecting clients that are not provisioned with a private/enterprise CA. How do home users run their own without having a public domain? And how do I authenticate the encrypted DNS on 10.1.1.1 that has no FQDN? (and really, has no verifiable identity at all) ### \u00a0 \u00a0  The DNS client verifies the connection based on PKIX validation No CRLs, OneCRL updates, no OCSP, no Certificate Transparency is available without functional DNS. So full PKIX validation as specified here is not available. ### \u00a0 \u00a0  The DNS client uses Web PKI trust anchors by default unless \u00a0 \u00a0  configured otherwise. CAB/Forum is currently, as far as I know, not taking encrypted DNS into account for their BR's. Also, every OS and even some applications use their own \"webpki\" root store that differs from each other. This can lead to interoperability issues. ### Spoofing attacks are mentioned in the document. Obtain _any_ certificate from Let's Encrypt via ACME, eg using \" something.example.com \", then spoof authentication-domain-name on the wifi. While this attack might be blocked by the AP not allowing wifi clients to send packets to each other, this is not true for all networks, and especially not for home networks where the goal is for local clients to be able to connect to each other. Is there a better way to lock the authentication-domain-name? One possible method might be to bind it to the ESSID. eg if the ESSID is  wifi.nohats.ca . one could only allow authentication-domain-name to be a name within  nohats.ca . Some method of reducing the scope of this attack is needed I believe. ### \u00a0 \u00a0 \u00a0 Addr Length:\u00a0 Length of enclosed IPv6 addresses in octets.\u00a0 When \u00a0 \u00a0 \u00a0 present, it MUST be a multiple of 16. Why not just a one octet counter then? The number of IPv6 addresses that follow. Then the length of the Addr field becomes counter times 16 octets. That seems more constrained than \"multiple of 16\" ### \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The diagrams lack reference octets. What is the width ? or 4 rows ? or ? I assume this is supposed to be 4 octets wide and 16 octets total? eg I would write: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ (also my pet peeve is people using +-+-+-+ instead of -----) ### \u00a0 \u00a0 \u00a0  A value of zero means that this Authentication Domain Name MUST no \u00a0 \u00a0 \u00a0  longer be used. Why not just omit the entry ? Are clients supposed to keep old entries for their entire lifetime even if when asking a new list, those entries no longer appear? That is not clear from this document. Either that should be made explicit, or the values of 0 should not be allowed. ### \u00a0  By default, Encrypted DNS connections received from outside the local \u00a0  network MUST be discarded by the encrypted DNS forwarder in a CPE. What is an \"encrypted DNS forwarder in a CPE\"? This is not defined in the document and I am confused. I assume the CPE announces some encrypted DNS server as either itself or to some external IP at the ISP network? If itself, how can it get a real FQDN the client can verify with PKIX using CAB/Forum ? If to an external IP, isn't it just acting as a NAT/router forwarding packets and then what does it mean to be an \"encrypted DNS forwarder\" ? ### \u00a0  This recommendation is meant to isolate local network \u00a0  DNS resolver services from the public Internet and prevent external \u00a0  attacks against the local Encrypted DNS resolver. \u00a0  If the DHCP responses or RAs are dropped by the attacker, the client \u00a0  can fallback to use a preconfigured encrypted DNS resolver. This raises the big question of why you think that strategy is a \"fallback strategy\" and not the default behaviour of the client. Wouldn't it be more secure if there is no DHCP/RA drop attacks possible? ### Multihoming is declared out of scope, but realistically most devices we are talking about here are phones, and those are all multihomed. So I feel pretty strongly that it should not be left out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-07-18 03:55:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-14 03:59:50-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I think that what is being proposed here is useful. I have one minor discuss comment, where I am really just asking for a bit more clarity over which fields are optional in the protocol extensions: \u00a0  ipv6-address(es) (variable length):\u00a0 Indicates one or more IPv6 \u00a0 \u00a0 \u00a0 addresses to reach the encrypted DNS resolver.\u00a0 An address can be \u00a0 \u00a0 \u00a0 link-local, ULA, or GUA.\u00a0 The format of this field is shown in \u00a0 \u00a0 \u00a0 Figure 3. Should this be 0 or more IPv6 addresses if this field is optional (as per the description in option length)?\u00a0  In general, I found it slightly unclear as to which fields are optional to include and which are always present.\u00a0 Possibly, explicitly indicating which fields are optional would add clarity.\u00a0 A similar comment applies to the DHCPv4 packet format, and IPv6 RAs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-31 16:59:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-11 10:55:23-07:00",
    "text": "I'm concerned that the scheduling function for autonomous cells can cause an infinite loop in the case of hash collision -- Section 3 specifies that AutoTxCell always takes precedence over AutoRxCell, but if those two cells collide, the corresponding cells on the peer in question will also collide.\u00a0 If both peers try to send at the same time and the hashes collide, they will both attempt to transmit indefinitely and never be received. There seems to be some \"passing the buck\" going on with respect to rate-limiting unauthenticated (join) traffic: draft-ietf-6tisch-minimal-security  (Section 6.1.1) says that the SF \"SHOULD NOT allocate additional cells as a result of traffic with code point AF43\"; this document is implementing a SF, and yet we try to avoid the issue, saying that \"[t]he at IPv6 layer SHOULD ensure that this join traffic is rate-limited before it is passed to 6top sublayer where MSF can observe it\".\u00a0 I think we need a clear and consistent story about where this rate-limiting is supposed to happen.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-02 20:37:56-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-31 16:59:42-07:00",
    "text": "I'm concerned that the scheduling function for autonomous cells can cause an infinite loop in the case of hash collision -- Section 3 specifies that AutoTxCell always takes precedence over AutoRxCell, but if those two cells collide, the corresponding cells on the peer in question will also collide.\u00a0 If both peers try to send at the same time and the hashes collide, they will both attempt to transmit indefinitely and never be received. [I have been persuaded that the rate-limiting situation does not present an inconsistency between documents]",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-08 10:18:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-09 17:25:16-07:00",
    "text": "Section 3.\u00a0 Can the normative reference for the SAX algorithm be clarified.\u00a0 The text cites [SAX-DASFAA], but this is an informative reference (and an academic paper with no URL).\u00a0 Appendix B, appears to also describe an algorithm but the introduction describes the text as \u201can example implementation SAX hash function\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-07 07:22:18-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-05 15:36:43-07:00",
    "text": "My understanding is that the intent of this document is to avoid a sharp \"cliff\" wherein several IETF procedures become invalid or unusable around the time of IETF 108, by postponing that cliff until around the time of IETF 111, on the assumption that a longer-term solution will be in place at that time.\u00a0 However, I think I need some help convincing myself that the current text succeeds in doing so, so let's discuss it... In particular, I'm looking at the ability to create a Recall Committee, an event that might well occur after IETF 108 (and thus, after the 2020-2021 NomCom has been seated).\u00a0 Currently in the Introduction and Section 3 we have text such as: \u00a0  This update is an emergency interpretation of the intent of  BCP 10 \u00a0  for this current exceptional situation only, and applies only to \u00a0  [...] any rules that relate to NomCom eligibility or process before \u00a0  IETF 108. My question comes in, then, as to whether a hypothetical formation of a Recall Committee after IETF 108 is or relies on an event or process that is excluded by the clause about \"process before IETF 108\".\u00a0  RFC 8713 does not immediatly bring clarity, discussing that: %\u00a0 The recall committee is created according to the same rules as is the %\u00a0 NomCom with the qualifications that both the person being %\u00a0 investigated and the parties requesting the recall must not be a %\u00a0 member of the recall committee in any capacity. Since the volunteer qualifications that cover both NomCom and Recall Committee members refer to \"the date on which the solicitation for NomCom volunteers was submitted for distribution to the IETF community\", it seems that we use the same date (and thus the same set of IETF meetings for the 3 of 5 criteria) for the attendance requirement of the volunteers, so that is not a problem.\u00a0 But does the act of (say) running the selection process constitute a \"NomCom eligibility or process\"?\u00a0 I'm not sure how to make a clear interpretation here. I think what we are concerned about is the requirement for attendance that has to have applied before IETF 108, but we may not necessarily want to exclude all things that happen after IETF 108.\u00a0 For example, we might arrive at a phrasing that this will apply to \"events that occurred before the scheduled time for IETF 108\".",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-02-20 20:19:29-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 09:45:36-08:00",
    "text": "Thanks for this effort. The draft appears to be in good shape overall; I just have one process point I would like to DISCUSS before approval: Section 12 appears to be an update to  draft-ietf-tsvwg-rtcweb-qos , which is currently in the RFC Editor queue in the MISSREF state. It's not clear to me what the intent of this section is, but if the idea is to formally update a _draft_, then please do not do that. The right way to proceed would be to pull  draft-ietf-tsvwg-rtcweb-qos  from the RFC editor queue and make the changes there. The UPDATES relationship is intended for updating RFCs, which are otherwise immutable. Drafts, even post-IESG approval and in the RFC editor queue can still be changed. Making readers figure out the update between two different RFCs when there is an option to just fix the draft would be a disservice to readers.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-02-20 16:40:19-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 09:15:58-08:00",
    "text": "I believe that this should be trivial DISCUSS to address, but I thought it important enough to warrant it. I'm OK with basically whatever you answer, I just wanted to make sure this had been seen and considered. \"An LE PHB SHOULD NOT be used for a customer\u2019s \"normal Internet\" \u00a0  traffic nor should packets be \"downgraded\" to the LE PHB instead of \u00a0  being dropped, particularly when the packets are unauthorized \u00a0  traffic.\u00a0 \" Great, sounds good to me -- but in the USA at least, there is are many cell phone plans which are \"unlimited\", but after some amount of traffic (e.g 22GB) your connection gets throttled to a lower data rate. Is this traffic still 'a customer's \"normal Internet\" traffic\"? Is it appropriate (whatever that means) to downgrade this traffic to the LE PHB? I understand not wanting to touch this issue with\u00a0 a 10 foot pole (and I don't know what the right answer is!), but you *did* open this can of worms by talking about what classification user traffic should have. Note: I'm happy to clear my DISCUSS no matter what the answer is, I just want to make sure it has been considered / discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-07-18 00:40:44-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-05 14:41:15-07:00",
    "text": "Section 12.5 contains the following normative statement: >\u00a0 Furthermore, because most languages are typically >\u00a0 represented by a single script or a small set of scripts, and >\u00a0 because most scripts are typically contained in one or more >\u00a0 blocks of code points, the software SHOULD warn the user when >\u00a0 presenting a string that mixes code points from more than one >\u00a0 script or block, or that uses code points outside the normal >\u00a0 range of the user's preferred language(s). This guidance seems broadly unimplementable for any users whose native language uses a non-Latin script. Due in large part to the Internet's ASCII heritage, and combined with the somewhat ubiquitous use of Latin characters for other worldwide purposes (e.g., a quick perusal of Russian- and Chinese-language web sites shows numerous examples of Latin representations for things like stock ticker symbols and metric abbreviations), it seems that the normative requirement to warn when \"presenting a string that... uses code points outside the normal range of the user's preferred language(s)\" will *either* warn non-Latin-character users almost constantly (if Latin is considered outside the range), or be broadly useless in preventing spoofing (if it is). I'm not clever enough to come up with a generalized solution for users of all alphabets, so don't have a generic proposal here; but I think that the guidance does at least need to be properly scoped so that it bears only on warning Latin alphabet users of the presence of non-Latin characters, while acknowledging that it is probably rather useless when used in the opposite direction. I imagine that it still makes sense to warn non-Latin users of non-Latin characters outside the codepoints used by their language (e.g., warning Greek speakers of the presence of Cyrillic characters).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-12-15 00:44:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-02 07:46:29-08:00",
    "text": "So there might be something missing here in regards to zero-checksum in UDP when using IPv6. So Section 3.1 in  RFC 7510  discusses this for MPLS over UDP and have some considerations that needs to be done if one are intending to use zero checksum. To me it appears that DETNET flows can not be guaranteed to always fulfill these, and in case you think you can motivate it should probably be stated explicitly and normatively allow it. So if it can't be guaranteed to fulfill these requirements then the next question exists: Do the possibility to use zero-checksum for this flow become something the control plane needs to signal it?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2016-03-15 13:44:10-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-15 12:57:53-07:00",
    "text": "This is DISCUSS because I'm not sure the instructions will be clear to IANA. \u00a0  This document requests that the \"OTN Signal Type\" subregistry of \u00a0  the \"Generalized Multi-Protocol Label Switching (GMPLS) \u00a0  Signaling Parameters\" registry be updated with the following \u00a0  registration policies: \"Standards Action\" and \"Specification \u00a0  Required\" as defined in [ RFC5226 ]. As we've talked about in response to \u00c1lvaro's review, this should say \u00a0  \"Standards Action\" or \"Specification Required\" With \"or\", not \"and\".\u00a0 It also wouldn't be a bad thing to follow \u00c1lvaro's suggestion of adding the conditions, such as: \u00a0  \"Standards Action\" or \"Specification Required\", with the latter used in \u00a0  the case of registration requests that do not come from IETF documents. The existing \"and\" makes it sound like a designated expert will do a review of the specification even when it falls under Standards Action, and that's not what's intended.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-15 23:32:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-01 01:23:19-07:00",
    "text": "Does the 'poll' leaf contain a value measured in seconds as currently stated, or a log2 seconds value (what the \"8-bit signed integer\" of that name in  RFC 5905  holds)?\u00a0 If the former, it should be a wider type than uint8 in order to be able to represent the full set of values. Let's also take another look at the use of nacm:default-deny-all for sensitive authentication-related nodes.\u00a0 My understanding is that typically we only block of the actual secret key material in this way and let the associated metadata (key names, algorithms, etc.) be retrieved.\u00a0 The current module may have default-deny-all in more places than is needed, and we show an example of retrieving key information that ought to have been denied by this ACL. It seems that the current module does not use  RFC 8177  key-chain functionality (despite listing  RFC 8177  as a reference).\u00a0 It seems that best practices for cryptographic configuration would be to use the key-chain functionality, though I may be misunderstanding things.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-02-10 06:08:07-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-28 03:15:08-07:00",
    "text": "Thank you for the work put into this document.  Special thanks for Dieter Sibold as the document shepherd write-up includes text about the WG consensus. Please find below one blocking DISCUSS point (but really trivial and easy to address), some non-blocking COMMENT points (but replies would be appreciated), and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric -- Section 13.1 -- As  RFC 7317  is imported by the YANG module, it must be a normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-10 06:56:34-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-30 09:15:39-07:00",
    "text": "Thank you for the work on this document. I have a simple-to-solve DISCUSS point, and some non blocking comments. Francesca 1. ----- \u00a0 \u00a0 \u00a0 \u00a0 leaf clock-precision { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type int8; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 units \"Hz\"; FP: I believe the units should be seconds here.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-04-28 07:33:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-20 11:19:44-07:00",
    "text": "I agree with Mirja's point #1, and I think it is DISCUSS-worthy. The document seems to be a mix of almost stream-of-conscious reasoning for how the WG arrived at particular design decisions (which probably doesn't need to be in the document at all), requirements on the CDNI FCI, requirements on CDNs (Sec. 5), and then the definition of objects the FCI will use. At a minimum, the last two of these seem like they need to be in a standards-track document if interoperability is to be achieved. Thinking about it another way, when an FCI solution document does get written, won't it need a normative reference to this document because of Section 7? My hunch is that the answer is yes.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-06-26 14:38:18-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-06 13:07:21-07:00",
    "text": "This should be easy to resolve; if other ADs believe that this approach is appropriate, I will clear. But I want to make sure we've thought it through: The draft states a number of normative requirements for how National Libraries manage the namespace. What standing does an IETF informational RFC have to tell the NLs what to do?\u00a0 I think it would be better to state such things as assumptions, or even as non-normative guidance about why the NLs would want to follow these requirements. Please note, however, that simply changing MUSTs to musts would not solve my concern; the normative vs non-normative question is only incidental to my concern.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-06-29 15:05:57-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-07 05:21:01-07:00",
    "text": "I think this document may benefit from an Internationalization Considerations sections, but am not entirely sure how needed it is. So let's discuss it... In particular, the URN:NBN lexical equivalence rules include several case-insensitive comparisons, for the prefix and for the case of the hex digits in any percent-encoded values, but do not specify any operation on the decoded percent-encoded values/characters.\u00a0 In many (perhaps even most?) cases, ignoring such encoded characters for purposes of case-insensitive comparison is the wrong thing to do, but if I understand correctly, it actually is the correct thing to do in this case.\u00a0 Namely, a NBN (or URN:NBN), once assigned, is essentially static data and consumers of it should not attempt to perform modification, Unicode normalization, etc. on it -- that would potentially change what is being identified (or render the identifier invalid).\u00a0 On the other hand, a national library or delegated institution that is assigning NBNs may wish to take into account Unicode normalization rules and other similar considerations while assigning NBNs (in particular, the nbn_string component), as part of their allocation policy.\u00a0 Because these can be subtle, it may be worth explicitly pointing out the potential issues for registration authorities.\u00a0 That, plus the directive to consumers to not normalize, seems like it would be appropriate content for an Internationalization Considerations section. Separately, in Section 4.2.1 where we cover 4-components, I noted that  RFC 8141  rather discourages actually using r-components until their semantics are standardized.\u00a0 The text here seems to be giving free reign for national libraries to assign their own semantics without any coordination with a broader community.\u00a0 Do we really want to advocate for this, as opposed to attempting to get broadly unified semantics for r-components Internet-wide?\u00a0 (Perhaps we already have and I just missed it; if so, a reference here would be appropriate.)",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-04-21 11:10:39-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-20 15:31:08-07:00",
    "text": "This should be a trivial to clear DISCUSS. This text terrifies me: \"It is not considered a fatal error to receive an OPEN message whose (non-extended) Optional Parameters Length value is not 255, and whose first Optional Parameter type code is 255 -- in this case the encoding of this specification MUST be used for decoding the message. A warning MAY be logged.\" It smacks of trying to be too clever, and that the correct response (IMO) when trying to set up a session with something obviously broken is to abort and throw an error. However, I'm sure that there was some discussion, and that the WG decided that this was a good idea; unfortunately I was unable to find anything discussion on this, so all I'm asking for is some reassurance that this was discussed and that this behavior was chosen as a good idea...",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-03-13 18:48:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-13 18:47:16-07:00",
    "text": "I am balloting DISCUSS because the specification is incomplete and not clear enough.\u00a0 This document basically specifies how to construct forwarding entries (\u00a73.1) and packet forwarding (\u00a73.2).\u00a0 I have concerns about both the specification of the first, and about the specification of the tunnel end-points. (1) Forwarding Entries The procedures in \u00a73.1 seem to want to be specified by example, but I think that this approach doesn't serve the document well as it goes into specifics for the protocols used in the example only (even using Normative language), and doesn't provide a general specification.\u00a0 As \u00a73 says, \"the examples in Section 3.1 and Section 3.2 assume that OSPF or ISIS is enabled: in fact, other mechanisms of discovery and advertisement could be used including other routing protocols (such as BGP) or a central controller.\"\u00a0 I would prefer if the text in would talk about the general process first.\u00a0 If the authors think that the examples serve an important function then it's ok to leave them.\u00a0  Others have raised the point about the link state extensions needing to be Normative references.\u00a0 The way the text is written, Normative language is used in some cases to specifically talk about the use of those extensions...so I would agree.\u00a0 Using the extensions just in examples (and not mixing them with specification text) would solve that issue. What would I like to see?\u00a0 For example, the third step talks about \"If A and E are in different IGP areas/levels, then...\"\u00a0 How does the rest of the text help with understanding how BGP, for example, would be used?\u00a0 In this case I believe that the step can be summarized into the need to advertise the SID and encapsulation with enough information so that the receiver \"knows the characteristics of the router that originated the advertisement\", even if not in the same routing/flooding domain (maybe: \"information MUST be advertised across flooding domain boundaries...\" -- I'm sure the authors can come up with better text).\u00a0 Making that (or some text to the effect) the normative statement in this document would be better than using normative language in the example (e.g. \"MUST set the \"router-ID\" field to a valid value\") and hoping/expecting for the reader to be able to translate that into whatever makes sense for BGP, or OSPFv3 or the central controller...\u00a0 After the general specification, you can then use an example (\"for example, if using OSPF, then the router-ID field is set to a valid value...\"). (2) Tunnel Endpoints \u00a72: \"The tunnel selected MUST have its remote end point (destination) address equal to the address of the next SR-MPLS capable node along the path (i.e., the egress of the active node segment).\"\u00a0 I find this statement misleading and confusing. In the general case the statement is wrong: Yes, the tunnel destination should be the next SR-MPLS node, but, that doesn't have to be \"the egress of the active node segment\".\u00a0 For example, in Figure 2 the SID could direct the traffic to the Egress Router (e.g. using it's Node SID) while having individual tunnels from the Ingress Router to the first SR, then to the next SR, etc., as explained in \u00a73.2.1/3.2.2. I realize that the sentence after the statement above is \"This is shown in Figure 1.\"\u00a0 Figure 1 is a degenerate case of the (almost) general case from Figure 2.\u00a0 Even in the single tunnel (Figure 1) case, \"the egress of the active node segment\" doesn't have to be R2, it could be another node inside the SR-MPLS network (as R2, being SR-MPLS aware, should be able to forward the frames). As I hopefully explained above, I have two issues with the statement: 1. It is wrong.\u00a0 I think that what makes it wrong is the clarification that \"the next SR-MPLS capable node along the path\" is \"the egress of the active node segment\".\u00a0 Taken the text is parenthesis out would make me happy. 2. It is a general statement.\u00a0 The placement is somewhat unfortunate because it seems that it may apply only to the Figure 1 case...but it applies in general...and there is no similar statement then describing Figure 2.\u00a0 Instead of adding something similar for Figure 2, perhaps move the sentence to a place that covers all the use cases. A third issue with the statement comes up when considering \u00a73.1/\u00a73.2: there is no specification there that explains how to figure out which should be the tunnel destination address.\u00a0 The example in \u00a73.1 only talks about receiving information from E, including the \"the encapsulation endpoint and the tunnel type of any tunnel used to reach E\"...but says nothing about other potential SR-MPLS capable nodes between A and E, or how A would use a tunnel to one of those transit nodes on the way to E..w.which is what is illustrated in \u00a73.2.1/3.2.2. (3) A very, very late IPR declaration came in after the IETF LC started.\u00a0 I didn't find a thread where the WG was made aware of it. https://datatracker.ietf.org/ipr/3439/",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-03-13 18:58:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-13 18:48:47-07:00",
    "text": "I am balloting DISCUSS because the specification is incomplete and not clear enough.\u00a0 I have concerns about both the construction of forwarding entries, including the setting of the tunnel endpoints. (1) Forwarding Entries The procedures in \u00a73.1 seem to want to be specified by example, but I think that this approach doesn't serve the document well as it goes into specifics for the protocols used in the example only (even using Normative language), and doesn't provide a general specification.\u00a0 As \u00a73 says, \"the examples in Section 3.1 and Section 3.2 assume that OSPF or ISIS is enabled: in fact, other mechanisms of discovery and advertisement could be used including other routing protocols (such as BGP) or a central controller.\"\u00a0 I would prefer if the text in would talk about the general process first.\u00a0 If the authors think that the examples serve an important function then it's ok to leave them.\u00a0  Others have raised the point about the link state extensions needing to be Normative references.\u00a0 The way the text is written, Normative language is used in some cases to specifically talk about the use of those extensions...so I would agree.\u00a0 Using the extensions just in examples (and not mixing them with specification text) would solve that issue. What would I like to see?\u00a0 For example, the third step talks about \"If A and E are in different IGP areas/levels, then...\"\u00a0 How does the rest of the text help with understanding how BGP, for example, would be used?\u00a0 In this case I believe that the step can be summarized into the need to advertise the SID and encapsulation with enough information so that the receiver \"knows the characteristics of the router that originated the advertisement\", even if not in the same routing/flooding domain (maybe: \"information MUST be advertised across flooding domain boundaries...\" -- I'm sure the authors can come up with better text).\u00a0 Making that (or some text to the effect) the normative statement in this document would be better than using normative language in the example (e.g. \"MUST set the \"router-ID\" field to a valid value\") and hoping/expecting for the reader to be able to translate that into whatever makes sense for BGP, or OSPFv3 or the central controller...\u00a0 After the general specification, you can then use an example (\"for example, if using OSPF, then the router-ID field is set to a valid value...\"). (2) Tunnel Endpoints \u00a72: \"The tunnel selected MUST have its remote end point (destination) address equal to the address of the next SR-MPLS capable node along the path (i.e., the egress of the active node segment).\"\u00a0 I find this statement misleading and confusing. In the general case the statement is wrong: Yes, the tunnel destination should be the next SR-MPLS node, but, that doesn't have to be \"the egress of the active node segment\".\u00a0 For example, in Figure 2 the SID could direct the traffic to the Egress Router (e.g. using it's Node SID) while having individual tunnels from the Ingress Router to the first SR, then to the next SR, etc., as explained in \u00a73.2.1/3.2.2. I realize that the sentence after the statement above is \"This is shown in Figure 1.\"\u00a0 Figure 1 is a degenerate case of the (almost) general case from Figure 2.\u00a0 Even in the single tunnel (Figure 1) case, \"the egress of the active node segment\" doesn't have to be R2, it could be another node inside the SR-MPLS network (as R2, being SR-MPLS aware, should be able to forward the frames). As I hopefully explained above, I have two issues with the statement: 1. It is wrong.\u00a0 I think that what makes it wrong is the clarification that \"the next SR-MPLS capable node along the path\" is \"the egress of the active node segment\".\u00a0 Taken the text is parenthesis out would make me happy. 2. It is a general statement.\u00a0 The placement is somewhat unfortunate because it seems that it may apply only to the Figure 1 case...but it applies in general...and there is no similar statement then describing Figure 2.\u00a0 Instead of adding something similar for Figure 2, perhaps move the sentence to a place that covers all the use cases. A third issue with the statement comes up when considering \u00a73.1/\u00a73.2: there is no specification there that explains how to figure out which should be the tunnel destination address.\u00a0 The example in \u00a73.1 only talks about receiving information from E, including the \"the encapsulation endpoint and the tunnel type of any tunnel used to reach E\"...but says nothing about other potential SR-MPLS capable nodes between A and E, or how A would use a tunnel to one of those transit nodes on the way to E..w.which is what is illustrated in \u00a73.2.1/3.2.2. (3) A very, very late IPR declaration came in after the IETF LC started.\u00a0 I didn't find a thread where the WG was made aware of it. https://datatracker.ietf.org/ipr/3439/",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-05-23 08:48:52-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 18:58:07-07:00",
    "text": "I am balloting DISCUSS because the specification is incomplete and not clear enough.\u00a0 I have concerns about both the construction of forwarding entries, including the setting of the tunnel endpoints. (1) Forwarding Entries The procedures in \u00a73.1 seem to want to be specified by example, but I think that this approach doesn't serve the document well as it goes into specifics for the protocols used in the example only (even using Normative language), and doesn't provide a general specification.\u00a0 As \u00a73 says, \"the examples in Section 3.1 and Section 3.2 assume that OSPF or ISIS is enabled: in fact, other mechanisms of discovery and advertisement could be used including other routing protocols (such as BGP) or a central controller.\"\u00a0 I would prefer if the text would talk about the general process first.\u00a0 If the authors think that the examples serve an important function then it's ok to leave them.\u00a0  Others have raised the point about the link state extensions needing to be Normative references.\u00a0 The way the text is written, Normative language is used in some cases to specifically talk about the use of those extensions...so I would agree.\u00a0 Using the extensions just in examples (and not mixing them with specification text) would solve that issue. What would I like to see?\u00a0 For example, the third step talks about \"If A and E are in different IGP areas/levels, then...\"\u00a0 How does the rest of the text help with understanding how BGP, for example, would be used?\u00a0 In this case I believe that the step can be summarized into the need to advertise the SID and encapsulation with enough information so that the receiver \"knows the characteristics of the router that originated the advertisement\", even if not in the same routing/flooding domain (maybe: \"information MUST be advertised across flooding domain boundaries...\" -- I'm sure the authors can come up with better text).\u00a0 Making that (or some text to the effect) the normative statement would be better than using normative language in the example (e.g. \"MUST set the \"router-ID\" field to a valid value\") and hoping/expecting for the reader to be able to translate that into whatever makes sense for BGP, or OSPFv3 or the central controller...\u00a0 After the general specification, you can then use an example (\"for example, if using OSPF, then the router-ID field is set to a valid value...\"). (2) Tunnel Endpoints \u00a72: \"The tunnel selected MUST have its remote end point (destination) address equal to the address of the next SR-MPLS capable node along the path (i.e., the egress of the active node segment).\"\u00a0 I find this statement misleading and confusing. In the general case the statement is wrong: Yes, the tunnel destination should be the next SR-MPLS node, but that isn't always \"the egress of the active node segment\".\u00a0 For example, in Figure 2 the SID could direct the traffic to the Egress Router (e.g. using it's Node SID) while having individual tunnels from the Ingress Router to the first SR, then to the next SR, etc., as explained in \u00a73.2.1/3.2.2. I realize that the sentence after the statement above is \"This is shown in Figure 1.\"\u00a0 Figure 1 is a degenerate case of the (almost) general case from Figure 2.\u00a0 Even in the single tunnel (Figure 1) case, \"the egress of the active node segment\" doesn't have to be R2, it could be another node inside the SR-MPLS network (as R2, being SR-MPLS aware, should be able to forward the frames). As I hopefully explained above, I have two issues with the statement: 1. It is wrong.\u00a0 I think that what makes it wrong is the clarification that \"the next SR-MPLS capable node along the path\" is \"the egress of the active node segment\".\u00a0 Taken the text is parenthesis out would solve this issue. 2. It is a general statement.\u00a0 The placement is somewhat unfortunate because it seems that it may apply only to the Figure 1 case...but it applies in general...and there is no similar statement then describing other cases.\u00a0 Instead of adding something similar for Figure 2, perhaps move the sentence to a place that covers all the use cases. A third issue with the statement comes up when considering \u00a73.1/\u00a73.2: there is no specification there that explains how to figure out which should be the tunnel destination address.\u00a0 The example in \u00a73.1 only talks about receiving information from E, including the \"the encapsulation endpoint and the tunnel type of any tunnel used to reach E\"...but says nothing about other potential SR-MPLS capable nodes between A and E, or how A would use a tunnel to one of those transit nodes on the way to E...which is what is illustrated in \u00a73.2.1/3.2.2. (3) A very, very late IPR declaration came in after the IETF LC started.\u00a0 I didn't find a thread where the WG was made aware of it. https://datatracker.ietf.org/ipr/3439/",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-05-06 05:40:16-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-12 03:52:49-07:00",
    "text": "These points should be easy to resolve: 1) Given section 3.1, the following drafts all seems that they should be normative references: ietf-isis-encapsulation-cap, ietf-ospf-encapsulation-cap, ietf-ospf-segment-routing-extensions, ietf-isis-segment-routing-extensions 2) Sec 3.2.3 on IP Header fields should refer to  RFC6040  for the ECN field and eventually  RFC2983  for DSCP.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-10 18:10:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-10-10 18:10:16-07:00",
    "text": "The final paragraph in Section 2.4 reads: \u00a0  Implementations should convert the local-part and the host-part of \u00a0  internationalized email addresses placed in these extensions to \u00a0  Unicode before display. The mention of converting \"local-part\" to \"Unicode\" has a very strong implication that the local-part of internationalized email addresses can (should be?) ACE-encoded (or otherwise converted to some non-Unicode encoding). Unless my understanding of internationalized email addresses is wildly wrong (and that may be the case), this isn't how they work: the local-part *is* in Unicode, and so conversion to Unicode doesn't make sense. This seems highly likely to lead developers down the path of ACE-encoding the local-part component of email addresses, which would cause incompatibilities.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-18 10:26:40-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-10 18:10:41-07:00",
    "text": "The final paragraph in Section 2.4 reads: \u00a0  Implementations should convert the local-part and the host-part of \u00a0  internationalized email addresses placed in these extensions to \u00a0  Unicode before display. The mention of converting \"local-part\" to \"Unicode\" has a very strong implication that the local-part of internationalized email addresses can be (should be?) ACE-encoded (or otherwise converted to some non-Unicode encoding). Unless my understanding of internationalized email addresses is wildly wrong (and that may be the case), this isn't how they work: the local-part *is* in Unicode, and so conversion to Unicode doesn't make sense. This seems highly likely to lead developers down the path of ACE-encoding the local-part component of email addresses, which would cause incompatibilities.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-04-11 07:37:24-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 18:45:27-07:00",
    "text": "This is a \"discuss discuss\" that I plan to clear once the IESG has considered the topic during tomorrow's telechat. This document has a normative reference to  RFC 8199 , which is informational. This downref was not mentioned in the IETF Last Call announcement , and  RFC 8199  doesn't yet appear in the downref registry . Per  RFC 8067 , this doesn't require running another IETF last call; however, as it wasn't part of the IETF last call discussion, the IESG is required to evaluate whether the downref is appropriate.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-04-11 06:40:58-07:00",
    "end_reason": "new_position",
    "start": "2019-04-11 06:40:16-07:00",
    "text": null,
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-17 11:53:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-11 06:40:58-07:00",
    "text": "This is generally a fine document, but after checking  RFC 7950  syntax for strings I question why you think you need non ASCII tags. There are so many problems that can arise from that. For example, how would IANA be able to enforce uniqueness of Unicode tags written in different Unicode canonicalisation forms?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:39:51-08:00",
    "end_reason": "position_updated",
    "start": "2019-04-11 05:38:14-07:00",
    "text": "This is a minor thing, but people get really confused about it so I'd like to discuss it. This document allows for minting new \"IETF Standard\" tags by publishing documents that are not standards of any kind. That is, because the registry specified in 7.2 has its allocation policy as IETF Review, that means that informational documents can be used to register new \"IETF Standard\" tags. This seems ripe for creating further confusion about what is and is not an IETF \"standard.\" Could these tags simply be called \"IETF tags\"?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-15 08:50:56-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-11 06:49:43-07:00",
    "text": "I think this document does introduce new security considerations, specifically the ability for one user to remove (\"mask\") tags from being visible to other users.\u00a0 A malicious user could interfere with the operations of other users/entities, especially in the case mentioned in an example where multiple semi-independent clients use tags to indicate modules to avoid that may be broken.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-08 06:03:52-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-25 10:14:42-07:00",
    "text": "I have a small discuss that should be easy to address: Sec 4.3: \" The number of retries are implementation and deployment \u00a0  dependent.\" (and also sec 4.4 point 6) Please specify a maximum number of retries and also a minimum retry interval (of e.g. 3 sec best with exponential back-off)!",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-04-14 11:13:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-07 06:14:29-08:00",
    "text": "Thank you for writing this important document. I would like to recommend its approval, but before doing so I had some questions. These relate to issues that I had trouble understanding in the algorithm. And they have been inspired by Paul Kyzivat's Gen-ART review. I'm probably missing something very obvious, but wanted to raise these questions just make sure there are no mistakes. 1. In Section 6, scryptROMix is called with B[i] as the second parameter \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 B[i] = scryptROMix (r, B[i], N) Yet, per scryptROMix is supposed to take a 128*r sequence of octets as its second parameter. What am I missing? Do I understand the notation correctly? I may be confused by the same issue that Paul noted in his review, that same identifiers are used for different purposes. 2. In Section 4, the scryptBlockMix takes an input parameter which is defined as \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 B[0] || B[1] || ... || B[2 * r - 1] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Input octet string (of size 128 * r octets), Yet, B[0] ... B[2*r-1] would seem to be an octet string of size 2*r. What am I missing?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-06-26 08:37:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-06-21 11:27:57-07:00",
    "text": "The SACM charter requires the group to \" whenever reasonable and possible, reuse existing protocols, mechanisms, information and data models. \" If that is reflected anywhere in the requirements, I missed it. (which is possible.) In particular, I think section 2.6 needs to include requirements to favor use of existing \"transfer protocols\".\u00a0 (As written, T-001 seems almost tailored to counter arguments to \"just use HTTP\".)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-08-01 07:54:58-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-26 08:37:15-07:00",
    "text": "(Resending because I forgot to hit the \"send email\" button this first time. No other change.) The SACM charter requires the group to \" whenever reasonable and possible, reuse existing protocols, mechanisms, information and data models. \" If that is reflected anywhere in the requirements, I missed it. (which is possible.) In particular, I think section 2.6 needs to include requirements to favor use of existing \"transfer protocols\".\u00a0 (As written, T-001 seems almost tailored to counter arguments to \"just use HTTP\".)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-11-30 10:52:04-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 12:37:21-08:00",
    "text": "Thank you for this document, it is a useful contribution to RFC series. I enjoyed reading it. I have a small list of issues that is hopefully easy to fix: 1) In 7.4.2: \u00a0  | filter\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | O | T | \"tcpdump\" [pcap] style filter for\u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0  |\u00a0  | input.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | This makes the [pcap] reference Normative. If you don't want to do that, please fully specify syntax in this document. 2) I believe [ I-D.ietf-cbor-cddl ] reference needs to be Normative due to use of CDDL in Appendix A. If you don't think CDDL is normative, you need to state that in Appendix A.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-12-02 16:00:00-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-18 16:28:10-08:00",
    "text": "It is pretty shocking to not see any discussion of the privacy considerations of storing data including client addresses (and ports) alongside DNS transactions, given how central DNS resolution is to user behavior on the web.\u00a0 (Note that there are mentions of potentially anonymized data in Sections 6.2 and 6.2.3 which would presumably forward-reference the privacy considerations.)\u00a0 Data normalization would probably also be mentioned in this section, since (e.g.) the case used for a query/response could be used in fingerprinting an implementation. I'm also concerned about the policy/procedure for allocating/extending the various bitfields and similar potential extension points in the data structures.\u00a0 Section 8 covers the major/minor versioning semantics with respect to new map keys and new maps, but not addition of new bits within existing (uint) bitmaps.\u00a0 Given the usage of the CDDL .bits constraint, it's not really clear that an IANA registry is the right tool to use, but I think some indication of the expected way to allocate new bits is in order, whether it's \"a future standards-track document that updates this document\" or otherwise.\u00a0 (I've noted many, but not all, instances of such bitmaps in my COMMENT section.) There are also a couple of fields whose semantics don't seem to be sufficiently well specified for a proposed-standard document, such as vlan-ids, generator-id, name-rdata, and ae-code.\u00a0 (I understand that some of them are probably only going to have locally relevant semantics, but we should be explicit about when that's the case.) If I'm reading things correctly that the IP address type is inferred from the bytestring length, then I think we need to enforce a restriction on the address prefix length(s) to allow for that inference to be unambiguous (noting that we only have the *byte* length of the address fields at our disposal for disabmgituation, and not the more precise bit-length).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-02-25 08:13:51-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-16 14:04:58-08:00",
    "text": "I am balloting a DISCUSS because I am concerned that this document doesn't actually do what it set out to achieve.\u00a0 I would love it if during the discussion I was pointed to the places where RELOAD already solves the issues, but for now I wasn't able to find them. According to the text, both extensions are intended to collect information \"along the path\", and the Figures clearly depict what is intended to happen.\u00a0 However, I don't think that as specified (or at least as explained) the behavior is guaranteed.\u00a0 Specific points: 1.  RFC6940  says (in Section 6.2. (Symmetric Recursive Routing)) that an \"overlay MAY be configured to use alternative routing algorithms\u2026[or]\u2026MAY be selected on a per-message basis\". How is the symmetry enforced if other routing algorithms are used?\u00a0 Enforcing that the ping/trace messages use symmetric routing when other algorithms are in use won't necessarily help because the paths may be different. 2.  RFC6940  also (in 6.2.2. (Response Origination)) reads: \"the response traverses the same peers as the request traversed, except in reverse order (symmetric routing) and possibly with extra nodes (loose routing).\" In other words, even if symmetric routing is used, there is no guarantee that the same path will be followed by the response, unless the originator builds the Via List with strict details of all the nodes in the path -- maybe this is what is intended, but no explicit mention occurs in the document. 3. In 4.3, what does \"directly or via symmetric routing\" mean? Is it directly connected? If so, then (for the text in 4.3) that would mean that C is adjacent to A, and even though it is the next hop after B, the path taken to reach C with the PathTrack request doesn't include B \u2014 the result is that the diagnostic information received from C may not be relevant relative to destination D.   Are there implementations available?\u00a0 What has been the experience? The Shepherd's write-up didn't mention any, and the TBD codes make me think that maybe Experimental might be a better status for this document.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2016-01-29 12:39:42-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-15 20:18:21-08:00",
    "text": "For Sections 9.1 and 9.2, I would like to see some evidence of discussion that resulted in the decision to make the registry policies Standards Action.\u00a0 Did the working group actually discuss this and make a decision that Standards Action is right?\u00a0 What's the reasoning for not using some softer policy, such as \"IETF Review\" (which might allow for registrations from Experimental documents) or Specification Required (which would allow review by a designated expert of a non-RFC specification)?\u00a0 Why is Standards Action the right thing? Important note on the previous comment: Please don't just change this: talk with me.\u00a0 I'm actually asking a question, and it might well be that Standards Action is right.\u00a0 I want to hear the answer and have a discussion about it.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-03-19 15:27:42-07:00",
    "end_reason": "position_updated",
    "start": "2015-12-16 23:19:11-08:00",
    "text": "Per Alexey's Gen-ART review and my own read, Section 9.1 is inconsistent with Section 5.3. The document says earlier that first and last bits are reserved. This is not shown in the table at all. What's perhaps causing the confusion is that there are special values (all 0s and all 1s) that convey nothing is requested and that everything is requested. This does not appear to be the same as having two reserved bits. You may want one or the other or both, but as it stands 9.1 or 5.3 do not seem to be saying the same thing. Also, Section 5.3 uses \"delimited\" when it probably should have said \"terminated\", unless there's more substructure in the SOFTWARE_VERSION string than is identified by the text.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2015-09-29 10:18:41-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-17 06:23:04-07:00",
    "text": "I am referring to Russ Housley's Gen-ART review. I believe we still has to resolve what to do about the sort order. (Maybe this helps: I\u2019m not actually sure why in a k-element set you order them based\u00a0 mod k because that would seem to produce likely duplicates. Since your backup option in the case of duplicates is proper numeric sort, why just not do that and only that? E.g. \"RBridges are sorted in byte string ascending order by their LAALP IDs, or if they are equal, by their System IDs considered as unsigned integers.\u201d But it could also be that it is too early and I have not yet had enough Diet Coke\u2026) Also, I am not sure I understand this in Section 5.2: \u00a0  Assuming there are \u2026 k member RBridges in an RBv; ... each RBridge is \u00a0  referred to as RBj where 0 <= j < k-1 Wouldn\u2019t that mean that for 2 bridges you have RB0 only, because j=1 does not satisfy 0 <= j < k-1 because 0 <= 1 < 1 is untrue. But again, it is too early here and maybe I\u2019m missing something.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-09-28 14:08:13-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-17 03:34:44-07:00",
    "text": "I have two questions where it's not clear to me if this specification does or does not introduce new vulnerabilities. It could well be that it does not and these are handled elsewhere, but I'm not sure so... (1) How is authorization for being a member of an RBv handled?  (2) If a rogue RB can add itself to an RBv can it arrange things so the rogue RB becomes the DF for the RBv?\u00a0 (If so, that would seem to create new DoS opportunities at least.)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-09-28 05:28:18-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-13 23:57:19-07:00",
    "text": "I have a couple of minor blocking points I would like to discuss, but they should be easy to fix: 1) In 2.1.1 and other sub-sections: should sub-TLV format be defined now, even though you don't specify any sub-TLV? (or is it already specified in another document?) Should recipients ignore unrecognized sub-TLVs or do something else? Please clarify. 2) In 2.1.3: what is \"system priority\"? This is not explained. Please either add an explanation or a reference to a document that defines it.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-27 04:25:54-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-13 16:52:06-07:00",
    "text": "Is this extension to ICCP really compatible with section 10 of  RFC7275 ?\u00a0  RFC7275  says \"It ought not be deployed on or over the public Internet.\u00a0 ICCP is not intended to be applicable when the Redundancy Group spans PEs in different administrative domains\" whereas this draft only refers to the \"well-managed\" stuff and says nothing about multiple domains, and this draft also refers to public contexts such as telephone poles. Can you justify for me how using ICCP here is safe? (It may well be, but I'm entirely unsure, probably mostly due to my ignorance of PON deployments.) The same point was made in the secdir review [1] which did get a response. Sadly, I didn't get how the response answered the question.  \u00a0  [1]  https://www.ietf.org/mail-archive/web/secdir/current/msg06762.html",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-02 17:06:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-07 05:59:33-08:00",
    "text": "I think we need to have a bit more clarity on exactly how/what parts of 4916 are updated (per Section 4.3).\u00a0 Thta is, we have some text that's indented as if it's supposed to be logically inserted into a \"revised 4916\", but no indication of where or whether anything else is removed. Furthermore, that text includes section references to portions of 4916 that are incorrect; normally an Update: would point to such text and say \"this is removed\" or \"this is replaced by \", and the current formulation looks like it's constructing a virtual document that is internally inconsistent.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-01-06 12:32:33-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-22 06:26:45-07:00",
    "text": "WIW, I think that the algorithm/queue empty and WRR issues from Pete Resnick's Gen-ART review need a fix.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-04-08 19:01:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-07 20:24:49-07:00",
    "text": "\u2014 Section 3.1 \u2014 I don\u2019t understand \u201cthe client\u2019s priority decision\u201d: what decision is that?\u00a0 And what\u2019s the point of giving the server a list of algorithms here, given that they all have to be ones that are supported by the server?\u00a0 Won\u2019t the server always have to use the first one in the list?\u00a0 If not, please add some text explaining what the server does. \u2014 Section 3.2 \u2014 \u00a0  If the preview is not available, the server MUST return NIL as the \u00a0  PREVIEW response.\u00a0 A NIL response indicates to the client that \u00a0  preview information MAY become available in a future PREVIEW FETCH \u00a0  request.\u00a0 Note that this is semantically different than returning a \u00a0  zero-length string, which indicates an empty preview. I think the MUST here is hard to follow, because the text doesn\u2019t make a clear enough distinction between \u201cpreview is not available\u201d and \u201can empty preview\u201d.\u00a0 Can you expand the text a bit to explain the distinction more clearly, as this is a protocol requirement?\u00a0 Also, as I noted in response to Meral\u2019s Gen-ART review it would be good to be clear how encrypted messages should be handled in this regard. \u2014 Section 4.1 \u2014 \u00a0  The preview text MUST be treated as text/plain MIME data by the \u00a0  client. I think this requires a normative reference to  RFC 2046 . \u2014 Section 5.1 \u2014 The way you have LAZY working isn\u2019t really consistent with the IMAP protocol model.\u00a0 In that model, the client would not have to ask for the preview twice, one with LAZY and one without.\u00a0 Instead, with LAZY, the server would return FETCH PREVIEW responses when it could \u2014 perhaps some in the first set of FETCH responses, and some, where the PREVIEW part was missing before, in unsolicited FETCH responses when the preview became available.\u00a0 That way, the server has the responsibility of setting off a separate task to generate the previews, and to send them to the client when it has them (at which point it either saves the for future FETCHes or doesn\u2019t). As it\u2019s written here, the client has to open a separate IMAP session with the server and ask a second time for the previews it\u2019s missing \u2014 a separate session to avoid blocking other action on the main session.\u00a0 And if the server has spun off a task to preemptively generate them because the client asked once (a good practice, given the description here) it has to retain them for some indefinite period waiting for the client to ask again. Why was this not done with the first mechanism? \u2014 Section 7 \u2014 As was mentioned in Ben\u2019s review, either the ABNF for \u201ccapability\u201d is in error (it should not include \u201cpreview-mod-ext\u201d) or the description needs to be significantly beefed up.\u00a0 I\u2019m guessing that the intent is that PREVIEW= capabilities include both algorithms and modifiers, that PREVIEW=FUZZY is required, that the presence of any preview algorithm implies PREVIEW=LAZY such that the latter not only need not be specified, but is not permitted to be.\u00a0 So we might have \u201cPREVIEW=FUZZY PREVIEW=FURRY PREVIEW=SLEEPY\u201d, which would mean we support the algorithms FUZZY and FURRY, and the modifiers LAZY and SLEEPY.\u00a0 Is that correct? That seems somewhat obtuse to me, overloading the PREVIEW= capability and inviting confusion. \u2014 Section 8 \u2014 It seems like a bad idea to have to keep the IMAP Capabilities registry in sync with the two new registries: as it stands, when you add a new algorithm you have to add it to the Preview Algorithms registry, and also add a corresponding entry in the Capabilities registry... and similarly for a modifier, if I have that right above. Why not follow the model of AUTH= and RIGHTS=, and just reserve the PREVIEW= capability in the registry, allowing it to apply to entries from the two new registries?\u00a0 That avoids inconsistencies in registrations if we later add algorithms or modifiers.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-09-17 09:12:23-07:00",
    "end_reason": "evaluation_closed",
    "start": "2019-04-08 19:01:09-07:00",
    "text": "\u2014 Section 3.1 \u2014 I don\u2019t understand \u201cthe client\u2019s priority decision\u201d: what decision is that?\u00a0 And what\u2019s the point of giving the server a list of algorithms here, given that they all have to be ones that are supported by the server?\u00a0 Won\u2019t the server always have to use the first one in the list?\u00a0 If not, please add some text explaining what the server does. \u2014 Section 3.2 \u2014 \u00a0  If the preview is not available, the server MUST return NIL as the \u00a0  PREVIEW response.\u00a0 A NIL response indicates to the client that \u00a0  preview information MAY become available in a future PREVIEW FETCH \u00a0  request.\u00a0 Note that this is semantically different than returning a \u00a0  zero-length string, which indicates an empty preview. I think the MUST here is hard to follow, because the text doesn\u2019t make a clear enough distinction between \u201cpreview is not available\u201d and \u201can empty preview\u201d.\u00a0 Can you expand the text a bit to explain the distinction more clearly, as this is a protocol requirement?\u00a0 Also, as I noted in response to Meral\u2019s Gen-ART review it would be good to be clear how encrypted messages should be handled in this regard. \u2014 Section 4.1 \u2014 \u00a0  The preview text MUST be treated as text/plain MIME data by the \u00a0  client. I think this requires a normative reference to  RFC 2046 . \u2014 Section 7 \u2014 As was mentioned in Ben\u2019s review, either the ABNF for \u201ccapability\u201d is in error (it should not include \u201cpreview-mod-ext\u201d) or the description needs to be significantly beefed up.\u00a0 I\u2019m guessing that the intent is that PREVIEW= capabilities include both algorithms and modifiers, that PREVIEW=FUZZY is required, that the presence of any preview algorithm implies PREVIEW=LAZY such that the latter not only need not be specified, but is not permitted to be.\u00a0 So we might have \u201cPREVIEW=FUZZY PREVIEW=FURRY PREVIEW=SLEEPY\u201d, which would mean we support the algorithms FUZZY and FURRY, and the modifiers LAZY and SLEEPY.\u00a0 Is that correct? That seems somewhat obtuse to me, overloading the PREVIEW= capability and inviting confusion. \u2014 Section 8 \u2014 It seems like a bad idea to have to keep the IMAP Capabilities registry in sync with the two new registries: as it stands, when you add a new algorithm you have to add it to the Preview Algorithms registry, and also add a corresponding entry in the Capabilities registry... and similarly for a modifier, if I have that right above. Why not follow the model of AUTH= and RIGHTS=, and just reserve the PREVIEW= capability in the registry, allowing it to apply to entries from the two new registries?\u00a0 That avoids inconsistencies in registrations if we later add algorithms or modifiers.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-10 06:34:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-05 14:05:07-07:00",
    "text": "I wavered a lot about whether this was DISCUSS-worthy, but it seems like we should at least talk about how big a risk for future confusion there is: I'm a little confused by the ABNF for 'capability' in Section 7 -- it seems to allow for (e.g.) PREVIEW=LAZYV2, but the introduction and Section 3.1 talk only about *algorithms* in PREVIEW capability responses (and not modifiers).\u00a0 Is the intent to have capability tags for (non-mandatory) priority modifiers?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-10-05 01:54:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 02:25:24-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I found it easy to read and understand, but have one potential issue that probably warrants a bit of discussion.\u00a0 I don't have any great knowledge of IMAP, so this may already be handled elsewhere, but I had a concern about returning zero-length strings under error conditions. \u00a0  It is possible that the server has determined that no meaningful \u00a0  preview text can be generated for a particular message, and that \u00a0  decision won't change later.\u00a0 Examples of this involve encrypted \u00a0  messages, content types the server does not support previews of, and \u00a0  other situations where the server is not able to extract information \u00a0  for a preview.\u00a0 In such cases, the server MUST return a zero-length \u00a0  string.\u00a0 Clients SHOULD NOT send another FETCH for a preview for such \u00a0  messages.\u00a0 (As discussed previously, preview data is not immutable so \u00a0  there is chance that at some point in the future the server would be \u00a0  able to generate meaningful text.\u00a0 However, this scenario is expected \u00a0  to be rare so a client should not continually send out requests to \u00a0  try to capture this infrequent occurrence.) \u00a0  \u00a0  ... A server MUST NOT return NIL \u00a0  to a FETCH PREVIEW request made without the LAZY modifier. When the LAZY modifier is not being used, then what would be returned if the server was transiently unable to return the preview for any reason?\u00a0 Does it still have to return a zero-length string in this error case?\u00a0 Is there some way that the server can indicate that it cannot satisfy the request now but without indicating that no preview is available?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-30 09:34:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-03 13:22:32-07:00",
    "text": "(1) Retention practices of cached previews Section 1 says \u201cUsing server generated previews allows global generation once per message, and then cached indefinitely\u201d.\u00a0 Why cache indefinitely, especially if the source messages has been expunged?\u00a0 For privacy reasons, couldn\u2019t this caching be consistent with the retention of the email. In Section 9, Security Considerations, there needs to be discussion of this retention too.\u00a0 Perhaps text like:  \u201cImplementations that pre-generate and store previews MUST ensure that the stored preview is also deleted when the corresponding mail message is expunged.\u201d (2) Protection of previews at rest In Section 9, Security Considerations, there needs to be discussion about the potential sensitivity of these previews and the need to protect them.\u00a0 Perhaps text like: \u201cJust as the messages they summarize, previews may contain sensitive information.\u00a0 When stored, these previews MUST be protected with equivalent authorization and confidentiality controls as the source message.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-11-30 12:56:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-29 07:59:06-08:00",
    "text": "Should these not be a rw value?  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro filter-mode\u00a0 \u00a0 \u00a0 enumeration \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro group* [group-address] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro group-address \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro source* [source-address] The example in the appendix shows these values being set (so rw): \u00a0 \u00a0 \u00a0 \u00a0 \"group-address\": \"233.252.0.23\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"filter-mode\": \"include\",",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-12-20 04:09:37-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-01 05:35:54-08:00",
    "text": "Hi, My discuss covers two of comments below that I would like to have some discussion on to resolve (further details are in my comments below): (1) The addition/default of the \"enable\" leaf. (2) Name of the interface_name list key rather than just name. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-11-30 18:33:15-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-30 18:09:14-08:00",
    "text": "Thank you for being responsive to the SECDIR review threat to improve the security considerations text.\u00a0 Specifically,  https://mailarchive.ietf.org/arch/msg/secdir/GUvFWXP7n9IjXW8xlIdMS5ZE5u0/ . Even after these edits, there are a few straightforward ambiguities to clear up. (a) Section 2.\u00a0 \u201cWhen a network's endpoints do not represent individual users (e.g. in industrial, datacenter, and infrastructure contexts), network operations can often benefit from large-scale data collection without breaching user privacy.\u201d Is network telemetry architecture being restricted to such a limited applicability?\u00a0 To quote the original SECDIR thread, is this saying \u201cThe Network Telemetry Framework is not applicable to networks whose endpoints represent individual users, such as general-purpose access networks\u201d?\u00a0 If so, I\u2019d recommend being that explicit. (b) Section 2.1.\u00a0 \u201cTo preserve user privacy, the user packet content should not be collected.\u201d This is a great principle, but extremely nuanced and potentially complicated to implement.\u00a0 Is this saying (using the words of this framework), \u201cTo preserve the privacy of end-users, no user packet content should be collected.\u00a0 Specifically, the data objects generated, exported, and collected by the Network Telemetry Framework should not include any packet payload from traffic associated with end-users systems\u201d?  (c) Section 2.5.\u00a0 Please use stronger and consistent language. OLD Disclaimer: large-scale network data collection is a major threat to\t user privacy [ RFC7258 ].\u00a0 The network telemetry framework presented in\t this document should not be applied to collect and retain individual\t user data or any data that can identify end users without consent.\t Any data collection or retention using the framework must be tightly\t limited to protect user privacy. NEW Large-scale network data collection is a major threat to user privacy and may be indistinguishable from pervasive monitoring [ RFC7258 ].\u00a0 The network telemetry framework presented in this document must not be applied to generating, exporting, collecting, analyzing or retaining individual user data or any data that can identify end users or characterize their behavior without consent. The principles described in (a), (b) and (c) seems sufficiently important they shouldn\u2019t be scattered across the document.\u00a0 Please either make an applicability statement section early in the document or a dedicated privacy consideration section.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-12-02 06:45:16-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-30 18:33:15-08:00",
    "text": "Thank you for being responsive to the SECDIR review thread to improve the security considerations text.\u00a0 Specifically,  https://mailarchive.ietf.org/arch/msg/secdir/GUvFWXP7n9IjXW8xlIdMS5ZE5u0/ . Even after these edits, there are a few straightforward ambiguities to clear up. (a) Section 2.\u00a0 \u201cWhen a network's endpoints do not represent individual users (e.g. in industrial, datacenter, and infrastructure contexts), network operations can often benefit from large-scale data collection without breaching user privacy.\u201d Is network telemetry architecture being restricted to such a limited applicability?\u00a0 To quote the original SECDIR thread, is this saying \u201cThe Network Telemetry Framework is not applicable to networks whose endpoints represent individual users, such as general-purpose access networks\u201d?\u00a0 If so, I\u2019d recommend being that explicit. (b) Section 2.1.\u00a0 \u201cTo preserve user privacy, the user packet content should not be collected.\u201d This is a great principle, but extremely nuanced and potentially complicated to implement.\u00a0 Is this saying (using the words of this framework), \u201cTo preserve the privacy of end-users, no user packet content should be collected.\u00a0 Specifically, the data objects generated, exported, and collected by the Network Telemetry Framework should not include any packet payload from traffic associated with end-users systems\u201d?  (c) Section 2.5.\u00a0 Please use stronger and consistent language. OLD Disclaimer: large-scale network data collection is a major threat to\t user privacy [ RFC7258 ].\u00a0 The network telemetry framework presented in\t this document should not be applied to collect and retain individual\t user data or any data that can identify end users without consent.\t Any data collection or retention using the framework must be tightly\t limited to protect user privacy. NEW Large-scale network data collection is a major threat to user privacy and may be indistinguishable from pervasive monitoring [ RFC7258 ].\u00a0 The network telemetry framework presented in this document must not be applied to generating, exporting, collecting, analyzing or retaining individual user data or any data that can identify end users or characterize their behavior without consent. The principles described in (a), (b) and (c) seems sufficiently important they shouldn\u2019t be scattered across the document.\u00a0 Please either make an applicability statement section early in the document or a dedicated privacy consideration section.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-02-05 15:20:16-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-04 17:18:37-08:00",
    "text": "Thanks to the authors for a well-written and clear document. I have a little bit of confusion about the address resolution scheme mentioned in this document. In section 1.1, The document says: >\u00a0 Frogans is a medium for publishing content and services on the >\u00a0 Internet.\u00a0 From its inception in 1999, the medium was designed as a >\u00a0 generic software layer running on top of the original Internet >\u00a0 infrastructure, i.e. the TCP and IP protocols and the Domain Name >\u00a0 System (DNS) I'm taking particular note of the mention of DNS here. Further down in this section, it then says: >\u00a0 o\u00a0 A registry, called the Frogans Core Registry (FCR), that contains >\u00a0 \u00a0  all Frogans addresses registered by Frogans site publishers.\u00a0 The >\u00a0 \u00a0  registry operator, called the FCR Operator, ensures the resolution >\u00a0 \u00a0  of Frogans addresses when end users enter them in Frogans Player. This implies that conversion from a Frogans address to an IP address is handled by the FCR rather than by DNS, although this isn't spelled out. On the other hand, this is the only part of the system that obviously uses a name-to-address resolution mechanism, so I'm left wondering whether there is any DNS aspect to this resolution. The reason I ask is that the current encoding scheme, which encodes the site-name as (what would in DNS be called) URL-escaped U-labels, is rather out of sync with other URL schemes, which use Punycode for host identifiers. If these URIs aren't used by DNS, that's fine -- but if they are, then I have some follow-up actions to suggest. Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-02-22 08:28:08-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-06 13:43:56-08:00",
    "text": "The text in Section 5 doesn't seem appropriate to me. I think the requirements from  RFC 5378  that are relevant here are the ones in Section 5.8 of that document, not Section 3.4. The rights to reproduce the trademark in the document are already fully described in  RFC 5378  Section 5.3; making a grant of rights here in the text of this document that is both narrower and broader than the language in  RFC 5378  seems problematic. Also, I'm not sure that the IETF IPR policies extend to cover \"rights to use the scheme name in ... Internet protocols\" (if that is read to mean protocols on the wire). I think the appropriate thing to do would be to delete Section 5 and, if the holders of the trademark are willing, to file a disclosure in accordance with  BCP 79 . I've cc'ed the IETF legal counsel on this mail so he can chime in on the discussion if necessary.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-08-04 06:58:18-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-04 02:19:44-07:00",
    "text": "Thanks, I think this is a very useful and well written document. Sorry for my late discuss but I don't think this is anything complicated to address. Based on the TSV review I agree that this document should say more about congestion control. While the TSV reviewer (Thanks Allison!) only proposes to refer  draft-ietf-avtcore-rtp-circuit-breakers-17  and  draft-ietf-rmcat-cc-requirements-09 , I would even prefer to have a normative sentence that says that congestion control MUST be implemented for all traffic flows.  Please also provide the update on DSCP\u00a0 black-holing (in the middle of a flow) as mentioned by David Black.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-08-03 09:00:56-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-03 07:51:08-07:00",
    "text": "I'd like to briefly chat about one aspect of this... Section 3.4: Allowing configuration of STUN/TURN servers from JS makes it easier for a calling server to track a user's call meta-data, if the JS supplied configuration is e.g. always preferred.\u00a0 Shouldn't a browser prefer locally configured servers if those exist and can be used?\u00a0 Or are there other things to be said about which STUN/TURN servers to use when there are multiple choices? (Apologies if this is handled by ICE already, I forget;-)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-02 20:59:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-02 20:58:01-07:00",
    "text": "Thanks for writing this draft. It really helped clarify a lot of things for me. I do have a concern though. In Section 3.3.\u00a0 Usage of temporary IPv6 addresses, the draft states \" The IPv6 default address selection specification [ RFC6724 ] specifies \u00a0  that temporary addresses [ RFC4941 ] are to be preferred over permanent \u00a0  addresses.\" While this is technically true, this is only the seventh rule in an ordered list of eight rules. e.g. A valid permanent address would be preferred over a deprecated temporary address based on Rule 3. If a host had only a valid permanent address and a deprecated temporary address, the mechanism specified in the draft would result in no addresses being made available, whereas the permanent address would have been an acceptable choice using  RFC6724 .  So, it is not entirely clear to me what the draft is trying to accomplish. It says  \"\u00a0  However, this rule is not completely obvious in the ICE scope.\u00a0 This \u00a0  is therefore clarified as follows:\"   What rule is this talking about when it says \"this rule\"? Similarly, it also says \"When a client gathers all IPv6 addresses on a host...\" but it is not clear what \"client\" the draft is referring to.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-02 20:59:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-02 20:59:15-07:00",
    "text": "Thanks for writing this draft. It really helped clarify a lot of things for me. I do have a concern though. In Section 3.3.\u00a0 Usage of temporary IPv6 addresses, the draft states \" The IPv6 default address selection specification [ RFC6724 ] specifies \u00a0  that temporary addresses [ RFC4941 ] are to be preferred over permanent \u00a0  addresses.\" While this is technically true, this is only the seventh rule in an ordered list of eight rules. e.g. A valid permanent address would be preferred over a deprecated temporary address based on Rule 3. If a host had only a valid permanent address and a deprecated temporary address, the mechanism specified in the draft would result in no addresses being made available, whereas the permanent address would have been an acceptable choice using  RFC6724 .  So, it is not entirely clear to me what the draft is trying to accomplish. It says  \"\u00a0  However, this rule is not completely obvious in the ICE scope.\u00a0 This \u00a0  is therefore clarified as follows:\"   What rule is this talking about when it says \"this rule\"? Similarly, it also says \"When a client gathers all IPv6 addresses on a host...\" but it is not clear what \"client\" the draft is referring to.  I think if you can clarify what you want to achieve we can work together on some replacement text.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-04 05:32:56-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-02 20:59:27-07:00",
    "text": "Thanks for writing this draft. It really helped clarify a lot of things for me. I do have a concern though. In Section 3.3.\u00a0 Usage of temporary IPv6 addresses, the draft states \" The IPv6 default address selection specification [ RFC6724 ] specifies \u00a0  that temporary addresses [ RFC4941 ] are to be preferred over permanent \u00a0  addresses.\" While this is technically true, this is only the seventh rule in an ordered list of eight rules. e.g. A valid permanent address would be preferred over a deprecated temporary address based on Rule 3. If a host had only a valid permanent address and a deprecated temporary address, the mechanism specified in the draft would result in no addresses being made available, whereas the permanent address would have been an acceptable choice using  RFC6724 .  So, it is not entirely clear to me what the draft is trying to accomplish. It says  \"\u00a0  However, this rule is not completely obvious in the ICE scope.\u00a0 This \u00a0  is therefore clarified as follows:\"   What rule is this talking about when it says \"this rule\"? Similarly, it also says \"When a client gathers all IPv6 addresses on a host...\" but it is not clear what \"client\" the draft is referring to.  I think if you can clarify what you want to achieve with the address selection we can work together on some replacement text.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-01-04 01:14:33-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 00:12:16-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-opsawg-service-assurance-yang-10 CC @evyncke Thank you for the work put into this document. A very interesting piece of work and a well-written piece of text (even if I am balloting DISCUSS). The examples are also helping. Please find below some DISCUSS points (+ suggestions), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Michael Richardson for the shepherd's detailed write-up including the WG consensus *but* it lacks the justification of the intended status. It would have been nice to list the implementations (even if I know one). Please note that Tommy Pauly is the Internet directorate reviewer (at my request) and you may want to consider this int-dir reviews as well when Tommy will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-opsawg-service-assurance-yang/reviewrequest/16806/ Also, thanks to the WG chairs and the responsible AD to bundle this I-D and its companion to the same IESG telechat: it helps a lot! I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ###  BCP14  template As noted by  https://author-tools.ietf.org/api/idnits?url=https://www.ietf.org/archive/id/draft-ietf-opsawg-service-assurance-yang-10.txt  and Lars, the  BCP14  template is not correct even if it is required for a proposed standard (it mentions  BCP13  ;-) ). As I have further DISCUSS issues below, I am raising the trivial  BCP14  issue to a blocking DISCUSS. ### Section 3.3 To my SQL eyes, it hurts to use a -1 value for health-score when there is no value. There is no \"mandatory true\" statement for this leaf, i.e., it can be absent in the telemetry. Is there a semantic difference between the absence of health-score and the value of -1 ? Is the SAIN collector expected to process those 2 cases differently ? Suggest to either remove the -1 sentinel value, or add \"mandatory true\" attribute, or be specific about the difference (if any). ### Section 4 It is unclear from this section whether it applies to IETF-specified YANG modules only? I.e., may a vendor augment this IETF YANG module in its own namespace ? I guess so, but worth writing it (or restrict this section to future IETF work only).",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-15 07:33:08-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-15 00:22:37-08:00",
    "text": "We can probably sort this out during the IESG telechat, but I want to be sure it's flagged. A number of the shepherd writeup questions were hastily answered and the information we need is largely missing.\u00a0 For instance: -- > What type of RFC publication is being requested on the IETF stream (Best > Current Practice, Proposed Standard, Internet Standard, > Informational, Experimental or Historic)? Why is this the proper type > of RFC? Do all Datatracker state attributes correctly reflect this intent? yes. -- There are three questions here, and only the last of them can be answered \"yes\".\u00a0 The second one is the most interesting one. -- > Several IETF Areas have assembled lists of common issues that their > reviewers encounter. For which areas have such issues been identified > and addressed? For which does this still need to happen in subsequent > reviews? no. -- I don't understand. -- > Have reasonable efforts been made to remind all authors of the intellectual > property rights (IPR) disclosure obligations described in  BCP 79 ? To > the best of your knowledge, have all required disclosures been filed? If > not, explain why. If yes, summarize any relevant discussion, including links > to publicly-available messages when applicable. yes. -- So something's been filed, or reasonable reminders were sent?\u00a0 The datatracker appears to imply this must mean the latter, but it would be great to be clear.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-02-18 07:20:26-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-15 14:41:43-08:00",
    "text": "This document describes a set of guidelines that will be used in an experiment.\u00a0 Why is it not an Experimental document?\u00a0 [I may have missed the discussion in the archive.]",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-03-21 05:30:26-07:00",
    "end_reason": "position_updated",
    "start": "2016-02-18 05:32:43-08:00",
    "text": "Thanks for writing this document, it was much needed and proposes overall the right approach to LISP EID management. And I expect I can move to a Yes position soon. I agree with some of the comments from Peter Yee's Gen-ART review. I\u2019d like to ensure that we work with Luigi to resolve these issues. From my perspective, I think the document is in better shape than the impression one would get just from the listed issues. It is an experimental setup, and some \u201csoft state\u201d approach for instance may be sufficient. However, I do think the following changes should be considered: 1. Add some language to Section 4 to explain if there are things that the registry team should check, and if a failure in those checks is grounds for refusing the request. Even if the check is just to ensure that the request looks reasonable in an expert or the team\u2019s opinion, and that the contact information is valid. 2. Could we be firmer on the expiration and re-registration timeouts? Couldn\u2019t you just say MUST be renewed in 12 months or else after 12+N months the registration will be recycled for other purposes? 3. Section 9 needs to have a more IANA considerations style to it. While you can mostly refer to the rest of the document, I would have expected at least to start with a very basic rule, such as FCFS or Expert Review. Also, start with \u201cThe following new registry should be maintained\u2026\u201d. 4. I think the end of the second paragraph of Section 9 was a bit confusing. What \u201cEID registration service\u201d do you mean? The ability to reserve EIDs as outlined earlier in the document? Or something else, like an automated, programmatic lookup service? Can\u2019t you just say \u201cRIPE needs to maintain a registry of EIDs, including facilities for interested LISP users to request registrations, and for others to see the granted registrations and the associated contact information\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-04-06 10:12:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-02-17 16:04:22-08:00",
    "text": "his is a DISCUSS on behalf of the IANA who are questioning the clarity of text and construction of the EID registry service.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-04 17:11:06-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-04 05:51:15-08:00",
    "text": "I have a few probably quick things I'd like to discuss for this one: (1) 3.1.1: Why MUST a CA ensure that the CA name and Subject name combination is unique? I don't see what'd break in BGPsec if that rule is omitted, but maybe I'm missing something.  (2) 3.1.1: Similarly, I'm not clear why only common name and serial number are allowed in Subject.\u00a0 Why is that needed for interop? (I can see that you want to say that code MUST support those but not why you want to prevent other things.) (3) Where's certificate status checking covered? What's expected for BGPsec router certs? If BGPsec speakers are intended to inherit the CRL checking from 6487 then being explicit about that would probably be worthwhile.\u00a0 And I'd wonder if router cert revocation will be more common than for other resource certs, in which case an OCSP-like system could be needed - did the WG consider that?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-02-25 10:45:08-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-01 16:06:19-08:00",
    "text": "(1) There seems to be some inconsistency in the way the A-bit is described as applied to the min/max delay sub-TLV. Section 4.2 says: \"A-bit.\u00a0 The A-bit represents the Anomalous (A) bit.\u00a0 The A-bit is set \u00a0  when the measured value of this parameter exceeds its configured \u00a0  maximum threshold.\u00a0 The A bit is cleared when the measured value \u00a0  falls below its configured reuse threshold.\u00a0 If the A-bit is clear, \u00a0  the sub-TLV represents steady state link performance.\" Is the A-bit meant to apply only to the min delay? Or only to the max delay? Then Section 5 says: \"For sub-TLVs which include an A-bit (except min/max \u00a0 \u00a0 \u00a0 delay), an additional threshold SHOULD be included \u00a0 \u00a0 \u00a0 corresponding to the threshold for which the performance \u00a0 \u00a0 \u00a0 is considered anomalous (and sub-TLVs with the A-bit are \u00a0 \u00a0 \u00a0 sent).\" Since min/max delay is excepted from this recommendation, I don't understand what the A-bit means in the min/max delay sub-TLV. (2) Section 11 says: \"This document does not introduce security issues beyond those \u00a0  discussed in [ RFC5305 ].\" This seems false. First,  RFC 5305  doesn't seem to discuss any security issues. It points to  RFC 5304 . But even compared to  RFC 5304 , it seems this document does introduce new issues, because it exposes real-time performance information about the network which may be commercially sensitive, and which  RFC 5305  does not expose. So, for example, the claim in  RFC 5304  that \"Because a routing protocol contains information that need not be kept secret, privacy is not a requirement,\" does not seem true. It may be that the same authentication mechanisms can be used, but that doesn't mean the threat model is the same. Happy to defer to others with more routing security clue than I, but it seems like at a minimum the potential value of the information contained in the new sub-TLVs to an attacker needs to be acknowledged.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-05-03 17:42:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-01-24 13:48:17-08:00",
    "text": "I concur with Kathleen's discuss. To put a finer point on it, I think the security considerations section here needs to really clearly state what the security properties of this design are and how they differ from existing NFS. That's not true yes.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-03-14 11:17:37-07:00",
    "end_reason": "position_updated",
    "start": "2018-01-24 08:41:56-08:00",
    "text": "Thanks for your response to the SecDir review.\u00a0 I see the proposed changes have not been integrated yet.\u00a0 This discuss will be resolved when the SecDir review changes have been included. https://mailarchive.ietf.org/arch/msg/secdir/HKdT2KjnWJFmzEPxlGcNH0OnUDg",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-02 07:48:12-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-29 13:36:57-08:00",
    "text": "There are two errata reports against  RFC 7484 , both in status \"reported\" ( https://www.rfc-editor.org/errata_search.php?rfc=7484&rec_status=15 ). Part of the requirements for advancing a document to Internet Standard is to address all errata reports against the original document.\u00a0 On a superficial reading of the diff from  RFC 7484  to this document it does appear that changes are included that would address these two errata reports, but that should probably be acknowledged in the text, and the responsible AD should use the RFC Editor's errata tool to process the reports accordingly.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-01-25 14:29:36-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 02:39:12-08:00",
    "text": "Thank you for the work put into this document. Special congratulations for having THREE implementations including one by the author. Please find below one blocking DISCUSS point (trivial to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). I am also sympathetic to Ben Kaduk's DISCUSS point. Special thanks to Jasdip Singh for the shepherd's write-up including the section about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric -- Section 5.2 -- The end of this section uses \" https://example.net/rdaprir2/ip/2001:0db8:1000::/48 \" (not  RFC 5952  compatible with the leading zero in front of \"db8\") as an example but this example seems to contradict section 3.1.1 of  RFC 9082 .",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-24 19:46:43-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-08 06:05:54-07:00",
    "text": "I support Roman's DISCUSS. I'm also unclear on the over-arching recommendation this document is making for securely deploying this protocol. Given that the protocol itself is insecure, I would have expected some normative requirement for correcting that (e.g., Minimally, Babel deployments MUST be secured using a lower-layer security mechanism, Babel over DTLS, or HMAC-based authentication.) This still would not bring it into line with  BCP 61  Section 7, but perhaps there is some argument for making an exception for this protocol.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-08-07 06:28:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 06:27:33-07:00",
    "text": "I really enjoyed reading this document!\u00a0 Thank you for the work and time that has gone into it. However, I don't think that this specification is ready to be published as a Proposed Standard.\u00a0 In general, I don't think that the document is clear or specific enough to be considered in the Standards Track -- that is the main reason for this DISCUSS. (A) Clear Defaults and Operational Guidance While I appreciate Babel's flexibility in terms of the ability to use different strategies, I believe that both defaults and clear guidance should be provided.\u00a0 Given that \"not all...strategies will give good results\" and that in most cases these are listed as possible choices, I don't think that this document \"has resolved known design choices\" [ BCP9 /rfc7127].\u00a0 The cost/metric computation and route selection specially concern me because I believe that a robust/clear specification is at the heart of any routing protocol. In general what I am looking for to resolve this part of the DISCUSS are two items: (1) Clear defaults.\u00a0 For example, Appendix B talks about constants/default values.\u00a0 I would assume that, given the existing experience, that the values there are probably sensible defaults.\u00a0 Is that not the case?\u00a0  (2) Operational Considerations.\u00a0 Given that Babel can be (and is) used in different environments, I would like to see guidance to operators as they deploy the protocol in their networks.\u00a0 An example of the type of discussion I would like to see expanded is: \"a mobile node that is low on battery may choose to use larger time constants (hello and update intervals, etc.) than a node that has access to wall power\" (\u00a71.1).\u00a0 Consider \u00a72 in  rfc5706  (Operational Considerations - How Will the New Protocol Fit into the Current Environment?). I believe that both items are important, specially in a protocol as flexible as Babel.\u00a0 Some of this guidance could have been included in  draft-ietf-babel-applicability  -- but this information is not there either. (B) Error Handling Many sections of the document describe functionality, or even Normatively mandate it, but there is no discussion about Error Handling. (1) Router-Id Setting \u00a74.5: \u00a0  o\u00a0 the current router-id; this is undefined at the start of the \u00a0 \u00a0 \u00a0 packet, and is updated by each Router-ID TLV (Section 4.6.7) and \u00a0 \u00a0 \u00a0 by each Update TLV with Router-Id flag set. It took me some time to figure out the reason for being able to carry the router-id in two different places inside the same packet, which is my interpretation of the \"and\" above.\u00a0 Let me see if I understood:\u00a0 a packet can carry multiple updates...updates contain routes that were either originated by the local node, OR, learned from other routers...the router-id matches the originator...\u00a0 So...if a packet carries multiple updates, some locally originated and some learned, then it is possible for the packet to first include (for example) a Router-ID TLV (indicating router-id_A), followed by some Update TLVs (without the R-bit set), than then some other Update TLVs (with the R-bit set)...\u00a0  Did I understand correctly?\u00a0 If so, I think there are significant pieces of this operation that are not clearly specified in the document.\u00a0 There is mention of the effect of the Router-ID TLV (or the Update TLV w/R=1) on subsequent Update TLVs...there is an very subtle hint (for my taste) in \u00a74.5 (Parser state) about the state learned for each packet from those TLVs...but there is no explicit text that talks about the need for strict ordering when sending and later when processing...it is all simply implied. What should happen if no Router-Id has been defined?\u00a0 For example, an Update (R = 0) is received but no Router-ID TLV is present...\u00a0 What if the Router-ID TLV is present, but *after* the Update?\u00a0 There are many possible combinations... (2) Default Prefix Similar comments as above...\u00a0 \"P (Prefix) flag...establishes a new default prefix for subsequent Update TLVs with a matching address encoding within the same packet\" (\u00a74.6.9).\u00a0  What if an update with an AE that allows compression is received *before* the one that sets the new default prefix? (3) Next Hop \u00a74.6.9: \u00a0  The next-hop address for this update is taken from the last preceding \u00a0  Next Hop TLV with a matching address family (IPv4 or IPv6) in the \u00a0  same packet even if it was otherwise ignored due to an unknown \u00a0  mandatory sub-TLV; if no such TLV exists, it is taken from the \u00a0  network-layer source address of this packet. What if the Next Hop TLV doesn't exist and the network-layer doesn't correspond to the address family in the Update?\u00a0 For example, let's say IPv6 is used as the network-layer protocol and the Update contains IPv4 prefixes... (4) For the Normative behavior listed here (I may have missed other instances), I have basically the same question: what should a receiver do if it is not the case? - \u00a73.8.1.2: \"A node MUST NOT increase its sequence number by more than 1 in response to a seqno request.\" - \u00a74: \"A Babel packet MUST be sent as the body of a UDP datagram, with network-layer hop count set to 1...\"\u00a0  - \u00a74.6.9: \"If the metric is finite, AE MUST NOT be 0.\u00a0 If the metric is infinite and AE is 0, Plen and Omitted MUST both be 0.\"\u00a0  - \u00a74.6.10: \"...if AE is 0 (in which case Plen MUST be 0 and Prefix is of length 0).\" - \u00a74.6.10/\u00a74.6.11: Is AE 3 a valid value in a request?\u00a0 I assume it isn't.\u00a0 What should a receiver do if AE = 3. (C) Mandatory Bit \u00a74.4: \"The most-significant bit of the sub-TLV, called the mandatory bit...\"\u00a0 The most significant bit of which part of the sub-TLV?\u00a0 As written, that bit would be the first one in the Type, which corresponds to the text in the IANA section.\u00a0 Please be specific. In the IANA considerations section, please include the whole registry in the table to avoid confusion. Note that because of the mandatory bit, the 128-239 range should be Reserved...but it is currently marked as Unassigned.\u00a0 Even worse, value 128 is assigned already [ draft-ietf-babel-source-specific ].\u00a0 The impact may not be too bad because I doubt that Pad1 would need to be mandatory, but it at least causes confusion and inconsistency, and (as currently specified) there would be no way to differentiate between Pad1 and the Source Prefix sub-TLV.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-08-03 07:12:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 06:28:50-07:00",
    "text": "I really enjoyed reading this document!\u00a0 Thank you for the work and time that has gone into it. However, I don't think that this specification is ready to be published as a Proposed Standard.\u00a0 In general, I don't think that the document is clear or specific enough to be considered in the Standards Track -- that is the main reason for this DISCUSS. (A) Clear Defaults and Operational Guidance While I appreciate Babel's flexibility in terms of the ability to use different strategies, I believe that both defaults and clear guidance should be provided.\u00a0 Given that \"not all...strategies will give good results\" and that in most cases these are listed as possible choices, I don't think that this document \"has resolved known design choices\" [ BCP9 /rfc7127].\u00a0 The cost/metric computation and route selection specially concern me because I believe that a robust/clear specification is at the heart of any routing protocol. In general what I am looking for to resolve this part of the DISCUSS are two items: (A1) Clear defaults.\u00a0 For example, Appendix B talks about constants/default values.\u00a0 I would assume that, given the existing experience, that the values there are probably sensible defaults.\u00a0 Is that not the case?\u00a0  (A2) Operational Considerations.\u00a0 Given that Babel can be (and is) used in different environments, I would like to see guidance to operators as they deploy the protocol in their networks.\u00a0 An example of the type of discussion I would like to see expanded is: \"a mobile node that is low on battery may choose to use larger time constants (hello and update intervals, etc.) than a node that has access to wall power\" (\u00a71.1).\u00a0 Consider \u00a72 in  rfc5706  (Operational Considerations - How Will the New Protocol Fit into the Current Environment?). I believe that both items are important, specially in a protocol as flexible as Babel.\u00a0 Some of this guidance could have been included in  draft-ietf-babel-applicability  -- but this information is not there either. (B) Error Handling Many sections of the document describe functionality, or even Normatively mandate it, but there is no discussion about Error Handling. (B1) Router-Id Setting \u00a74.5: \u00a0  o\u00a0 the current router-id; this is undefined at the start of the \u00a0 \u00a0 \u00a0 packet, and is updated by each Router-ID TLV (Section 4.6.7) and \u00a0 \u00a0 \u00a0 by each Update TLV with Router-Id flag set. It took me some time to figure out the reason for being able to carry the router-id in two different places inside the same packet, which is my interpretation of the \"and\" above.\u00a0 Let me see if I understood:\u00a0 a packet can carry multiple updates...updates contain routes that were either originated by the local node, OR, learned from other routers...the router-id matches the originator...\u00a0 So...if a packet carries multiple updates, some locally originated and some learned, then it is possible for the packet to first include (for example) a Router-ID TLV (indicating router-id_A), followed by some Update TLVs (without the R-bit set), than then some other Update TLVs (with the R-bit set)...\u00a0  Did I understand correctly?\u00a0 If so, I think there are significant pieces of this operation that are not clearly specified in the document.\u00a0 There is mention of the effect of the Router-ID TLV (or the Update TLV w/R=1) on subsequent Update TLVs...there is an very subtle hint (for my taste) in \u00a74.5 (Parser state) about the state learned for each packet from those TLVs...but there is no explicit text that talks about the need for strict ordering when sending and later when processing...it is all simply implied. What should happen if no Router-Id has been defined?\u00a0 For example, an Update (R = 0) is received but no Router-ID TLV is present...\u00a0 What if the Router-ID TLV is present, but *after* the Update?\u00a0 There are many possible combinations... (B2) Default Prefix Similar comments as above...\u00a0 \"P (Prefix) flag...establishes a new default prefix for subsequent Update TLVs with a matching address encoding within the same packet\" (\u00a74.6.9).\u00a0  What if an update with an AE that allows compression is received *before* the one that sets the new default prefix? (B3) Next Hop \u00a74.6.9: \u00a0  The next-hop address for this update is taken from the last preceding \u00a0  Next Hop TLV with a matching address family (IPv4 or IPv6) in the \u00a0  same packet even if it was otherwise ignored due to an unknown \u00a0  mandatory sub-TLV; if no such TLV exists, it is taken from the \u00a0  network-layer source address of this packet. What if the Next Hop TLV doesn't exist and the network-layer doesn't correspond to the address family in the Update?\u00a0 For example, let's say IPv6 is used as the network-layer protocol and the Update contains IPv4 prefixes... (B4) For the Normative behavior listed here (I may have missed other instances), I have basically the same question: what should a receiver do if it is not the case? - \u00a73.8.1.2: \"A node MUST NOT increase its sequence number by more than 1 in response to a seqno request.\" - \u00a74: \"A Babel packet MUST be sent as the body of a UDP datagram, with network-layer hop count set to 1...\"\u00a0  - \u00a74.6.9: \"If the metric is finite, AE MUST NOT be 0.\u00a0 If the metric is infinite and AE is 0, Plen and Omitted MUST both be 0.\"\u00a0  - \u00a74.6.10: \"...if AE is 0 (in which case Plen MUST be 0 and Prefix is of length 0).\" - \u00a74.6.10/\u00a74.6.11: Is AE 3 a valid value in a request?\u00a0 I assume it isn't.\u00a0 What should a receiver do if AE = 3. (C) Mandatory Bit \u00a74.4: \"The most-significant bit of the sub-TLV, called the mandatory bit...\"\u00a0 The most significant bit of which part of the sub-TLV?\u00a0 As written, that bit would be the first one in the Type, which corresponds to the text in the IANA section.\u00a0 Please be specific. In the IANA considerations section, please include the whole registry in the table to avoid confusion. Note that because of the mandatory bit, the 128-239 range should be Reserved...but it is currently marked as Unassigned.\u00a0 Even worse, value 128 is assigned already [ draft-ietf-babel-source-specific ].\u00a0 The impact may not be too bad because I doubt that Pad1 would need to be mandatory, but it at least causes confusion and inconsistency, and (as currently specified) there would be no way to differentiate between Pad1 and the Source Prefix sub-TLV.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-22 13:14:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 15:13:10-07:00",
    "text": "I don't think that all of the arithmetic specified in Section 3.2.1 is well defined.\u00a0 Specifcally, the formulations involving bitwise AND assume that the input to the bitwise AND is nonnegative, which does not seem to be implied by the other stated constraints.\u00a0 (For example, an \"integer n\" may well be negative.)\u00a0 Some discussion of the representation of negative integers would then be needed, and then whether the mathematical operation is performed in an abstract infinite-precision machine or in a realizable approximation, etc..\u00a0 It might be simpler to just use the modular arithmetic flavor and avoid any of the issues that can arise when providing two alternative definitions that are intended to be equivalent (since there is always a risk of edge cases). Section 3.5.2 needs to explicitly say that the c and m arguments to M() are the local link cost and the advertised metric, e.g., \"the function M(c, m) used for computing a metric from a locally computed link cost c and the metric m advertised by a neighbor\". Section 3.8.2.1 notes that \"[d]ue to duplicate suppression, only a small number of such requests will actually reach the source.\" (for seqno requests intending to avoid starvation).\u00a0 But Section 3.8.1.2 only has a SHOULD-level requirement to suppress duplicate seqno requests, so I think there is an internal inconsistency. I think we may need to have a discussion about the feasibility of multicast acknowledgment requests with only a 16-bit nonce.\u00a0 With random assignment of nonces the risk of birthday collisions becomes uncomfortably large, and non-random assignments are likely to have worse pathologies.\u00a0 (A pointer to a previous discussion of this topic would, of course, short-circuit a lot of it if not all of it.)\u00a0 Are we willing to make hard assumptions about the maximum size of a multicast domain and the risk of collision we are willing to accept? The discussion in Section 4.6.9 of computing the prefix from an Update message (and parser state) seems a little underspecified when the prefix length is not a multiple of 8 bits.\u00a0 (Additionally, \"Plen\" is not described as measuring bits, explicitly, for any of the PDU descriptions that I remember.)\u00a0 Specifically, the \"Prefix\" description does not mention that any trailing bits must be set to zero, but the subsequent discussion about the prefix is \"computed as follows\" refers to assembling the prefix as a collection of octets, including trailing zero octets, implying that the computed prefix is the full length of the address type. I appreciate that we have some discussion in Section 4.5 about the need for a stateful parser for the babel packet body; this seems like one of the riskiest areas of the protocol from the implementation perspective. However, I think it would be even more helpful to explicitly call out what pieces of state are needed, what protocol elements affect the state, and what ordering requirements (or non-requirements) there are for the interactions between the different protocol elements that affect parser state.\u00a0 Can we have a discussion about whether it's appropriate to add some text along these lines?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-07 04:29:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 04:28:53-07:00",
    "text": "I have a couple of points that needs addressing before this document can move forward. Most of them should the straight forward to address. My main point is about network load. Thanks for discussing network load and correctly adding some warnings at the right places, however, for a PS track document I would like to see more than this. Usually it's good provide default values were suitable (as this often is what people will then pick if there is no good reason to diverge) and more important I really like to see min/max values. Note that  RFC8085  recommend a minimal interval of 3 seconds which probably is also a good hard boundary here.  More concretely I think there are these cases that need more guidance: - Section 3.7.2. (Triggered Updates) advises to send a message multiple times for redundancy in case of loss. 5 and 2 are mentioned as example values. Please provide a normative default value and a normative maximum value here. Moreover the spec should also require to pace out these messages and avoid \"tail loss\" by overloading the local queue.\u00a0 (See also section 3.8.2.1) -Section\u00a0 3.8.1.1.\u00a0 (Route Requests) says: \"Full route dumps MAY be rate-limited, especially \u00a0  if they are sent over multicast.\" I think this should at least be a SHOULD. Please also provide further guidance about to appropriately rate limit and think about other cases where a recommend to implement rate-limiting could make sense. - In section 4.1.1 the update interval needs a lower limit (e.g. 3 seconds) and a recommend default value would be could as well (Note that there are other part in section 3 where the update value is discussed as well). - Section 3.8.2.4. mentions network load when requests are sent to all neighbours after reboot. Please provide more guidance about how to pace out these requests. - Section 3.8.1.2.\u00a0 (Seqno Requests) discusses hop count values but could maybe also give more concrete guidance. I would assume that the hop count value of the current active route is usually know. Maybe that knowledge could be used to pick an appropriate value? Two other smaller discuss points/questions/comments: 1) Sec 4.6.8. (Next Hop): If I interpret this correctly, address compression is allowed for the next hop field and therefore this TLV would actually not be self-terminating. What do I miss? 2) This document needs to specify a registration policy also for each of\u00a0 the already existing registries given this document obsoletes  RFC7557 .",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-07 05:14:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 04:29:27-07:00",
    "text": "I have a couple of points that needs addressing before this document can move forward. Most of them should the straight forward to address. My main point is about network load. Thanks for discussing network load and correctly adding some warnings at the right places, however, for a PS track document I would like to see more than this. Usually it's good provide default values were suitable (as this often is what people will then pick if there is no good reason to diverge) and more important I really like to see min/max values. Note that  RFC8085  recommend a minimal interval of 3 seconds which probably is also a good hard boundary here.  More concretely I think there are these cases that need more guidance: - Section 3.7.2. (Triggered Updates) advises to send a message multiple times for redundancy in case of loss. 5 and 2 are mentioned as example values. Please provide a normative default value and a normative maximum value here. Moreover the spec should also require to pace out these messages and avoid \"tail loss\" by overloading the local queue.\u00a0 (See also section 3.8.2.1) - Section\u00a0 3.8.1.1.\u00a0 (Route Requests) says: \"Full route dumps MAY be rate-limited, especially \u00a0  if they are sent over multicast.\" I think this should at least be a SHOULD. Please also provide further guidance about to appropriately rate limit and think about other cases where a recommend to implement rate-limiting could make sense. - In section 4.1.1 the update interval needs a lower limit (e.g. 3 seconds) and a recommend default value would be could as well (Note that there are other part in section 3 where the update value is discussed as well). - Section 3.8.2.4. mentions network load when requests are sent to all neighbours after reboot. Please provide more guidance about how to pace out these requests. - Section 3.8.1.2.\u00a0 (Seqno Requests) discusses hop count values but could maybe also give more concrete guidance. I would assume that the hop count value of the current active route is usually know. Maybe that knowledge could be used to pick an appropriate value? Two other smaller discuss points/questions/comments: 1) Sec 4.6.8. (Next Hop): If I interpret this correctly, address compression is allowed for the next hop field and therefore this TLV would actually not be self-terminating. What do I miss? 2) This document needs to specify a registration policy also for each of\u00a0 the already existing registries given this document obsoletes  RFC7557 .",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-07 02:03:50-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 05:14:32-07:00",
    "text": "(Sorry I forgot two points about the appendix; see one in the discuss section and one in the comment section) I have a couple of points that needs addressing before this document can move forward. Most of them should the straight forward to address. My main point is about network load. Thanks for discussing network load and correctly adding some warnings at the right places, however, for a PS track document I would like to see more than this. Usually it's good provide default values were suitable (as this often is what people will then pick if there is no good reason to diverge) and more important I really like to see min/max values. Note that  RFC8085  recommend a minimal interval of 3 seconds which probably is also a good hard boundary here.  More concretely I think there are these cases that need more guidance: - Section 3.7.2. (Triggered Updates) advises to send a message multiple times for redundancy in case of loss. 5 and 2 are mentioned as example values. Please provide a normative default value and a normative maximum value here. Moreover the spec should also require to pace out these messages and avoid \"tail loss\" by overloading the local queue.\u00a0 (See also section 3.8.2.1) - Section\u00a0 3.8.1.1.\u00a0 (Route Requests) says: \"Full route dumps MAY be rate-limited, especially \u00a0  if they are sent over multicast.\" I think this should at least be a SHOULD. Please also provide further guidance about to appropriately rate limit and think about other cases where a recommend to implement rate-limiting could make sense. - In section 4.1.1 the update interval needs a lower limit (e.g. 3 seconds) and a recommend default value would be could as well (Note that there are other part in section 3 where the update value is discussed as well). - Section 3.8.2.4. mentions network load when requests are sent to all neighbours after reboot. Please provide more guidance about how to pace out these requests. - Section 3.8.1.2.\u00a0 (Seqno Requests) discusses hop count values but could maybe also give more concrete guidance. I would assume that the hop count value of the current active route is usually know. Maybe that knowledge could be used to pick an appropriate value? Three other smaller discuss points/questions/comments: 1) Sec 4.6.8. (Next Hop): If I interpret this correctly, address compression is allowed for the next hop field and therefore this TLV would actually not be self-terminating. What do I miss? 2) This document needs to specify a registration policy also for each of\u00a0 the already existing registries given this document obsoletes  RFC7557 . 3) Appendix D (Stub Implementations) contain normative language and therefore should probably be moved into the body of the draft.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-11 12:45:40-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 12:19:44-07:00",
    "text": "Security Considerations.\u00a0 While the high level statement of Babel being \u201can insecure protocol\u201d is accurate and clear, precisely enumerating the threats is needed to motivate the selection of the appropriate mitigations.\u00a0  (1) Per \u201cAny attacker can misdirect data traffic by advertising routes with a low metric or a high seqno.\u201d: -- Can the \"any\" of the attacker be scoped any more? -- Explain why this is possible \u2013 because Babel peers are not authenticated and Babel messages aren\u2019t integrity/replay protected -- Discuss the impact of this misdirection: denial of service (dropping the traffic and against a given target), eavesdropping, or allowing for the possibility of traffic modification (depending on upper level security mechanisms) \u2013  RFC4593  covers a number of them -- Note that because Babel messages aren\u2019t encrypted any on-path attacker can gather the routing topology (2) The rest of this paragraph describes the security properties conveyed by link-layer security, IPSec, BABEL-HMAC and BABEL-TLS.\u00a0 They all make sense.\u00a0 Please be explicit that IPSec or BABEL-TLS address all of the above described attacks.\u00a0 BABEL-HMAC addresses only somet. (3) Per \u201cHMAC is simpler and does not depend on DTLS, and therefore its use is RECOMMENDED whenever both mechanisms are applicable\u201d, can you explain this recommendation and the circumstances where \u201cboth mechanisms are applicable\u201d.\u00a0 If one wants to ensure confidentiality, it can\u2019t be realized with HMAC \u2013 they aren\u2019t equal. (4) Per \u201cThe privacy issues that this causes can be mitigated somewhat by using randomly chosen router-ids and randomly chosen IP addresses, and changing them periodically, who\u2019s IP address should be randomly chosen the Babel node or the mobile device? In other sections: (5) Appendix C: Per the last paragraph, \u201cThe packet trailer is intended to carry cryptographic signatures \u2026\u201d, to what security mechanism is that referring?\u00a0 Where is that defined? (6) Appendix D: Is the stub implementation guidance normative?\u00a0 If so, will it satisfy all of the  RFC2119  language in this document? (7) Appendix E.\u00a0 Please explicitly state that the sample implementation is non-normative.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-08-08 05:48:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-08 05:45:32-07:00",
    "text": "Thanks for your work on this well written document. Most of the issues I found have been covered in the ballot positions of my esteemed colleagues. I did have one major concern that I would like to see addressed though. This is in regard to backward compatibility with  RFC6126  implementations. Due to the addition of the mandatory bit and the processing associated with it, I would think that the new implementations will not be able to properly interoperate with the existing  RFC6126  implementations. Is my understanding correct? If so, I would like to see some text explaining what is the expected behavior when deploying into legacy environments.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-08-20 13:57:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-08 05:48:03-07:00",
    "text": "Thanks for your work on this well written document. Most of the issues I found have been covered in the ballot positions of my esteemed colleagues. I did have one major concern that I would like to see addressed though. This is in regard to backward compatibility with  RFC6126  implementations. Due to the addition of the mandatory bit and the processing associated with it, I would think that the new implementations will not be able to properly interoperate with the existing  RFC6126  implementations. Is my understanding correct? If so, I would like to see some text explaining what is the expected behavior when deploying into legacy environments. If not, I would greatly appreciate an explanation and I will clear.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-10-28 09:59:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-28 09:54:50-07:00",
    "text": "\u2014 Section 3.1 \u2014 \u00a0 \u00a0 \u00a0  [ RFC2231 ] encoding of the message Subject header field \u00a0 \u00a0 \u00a0  MUST be supported, but when used, only \"UTF-8\" and \"US-ASCII\" \u00a0 \u00a0 \u00a0  charsets MUST be used (i.e. other charsets MUST NOT be used). NOT DISCUSS: I don\u2019t like the second use of MUST: it\u2019s confusing (for example, it\u2019s not the case that you always MUST use both charsets).\u00a0 I suggest this: NEW \u00a0  [ RFC2231 ] encoding of the message Subject header field \u00a0  MUST be supported, and when used, only the \"UTF-8\" and \"US-ASCII\" \u00a0  charsets are allowed: other charsets MUST NOT be used. END DISCUSS: That said, I don\u2019t understand the need to specifically allow UTF-8 here.\u00a0 If the subject only contains \u201cACME:\u201d, FWS, and a base64 string, it will always be ASCII.\u00a0 Why are we talking about UTF-8 at all? \u00a0 \u00a0 \u00a0  The message MUST also pass \u00a0 \u00a0 \u00a0  DMARC validation [ RFC7489 ], which implies DKIM and SPF validation \u00a0 \u00a0 \u00a0  [ RFC7208 ]. Two things here, which apply to bullet 9 in Section 3.2 also: 1. DMARC does not imply DKIM *and* SPF validation: DMARC uses DKIM *or* SPF to do Identifier Alignment. 2. I have an issue with requiring the use of DMARC at this point, as it\u2019s specified only in an Informational document in the Independent stream.\u00a0 In any case, what\u2019s the point of requiring DMARC?\u00a0 It seems to me that the authentication you need is provided by DKIM or S/MIME; what do you need from DMARC?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-11-18 20:36:06-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-28 09:59:12-07:00",
    "text": "(Sorry; I forgot to include the first item in my initial DISCUSS ballot.) I question why this is Informational, and the shepherd writeup doesn't really explain it.\u00a0 I get that this fills a gap, and that the working group wants to see this adopted.\u00a0 I don't get why, therefore, you aren't proposing a standard here.\u00a0 What is the point of making this Informational, and not Proposed Standard... or Experimental, if you're less sure of whether it will work as expected? \u2014 Section 3.1 \u2014 \u00a0 \u00a0 \u00a0  [ RFC2231 ] encoding of the message Subject header field \u00a0 \u00a0 \u00a0  MUST be supported, but when used, only \"UTF-8\" and \"US-ASCII\" \u00a0 \u00a0 \u00a0  charsets MUST be used (i.e. other charsets MUST NOT be used). NOT DISCUSS: I don\u2019t like the second use of MUST: it\u2019s confusing (for example, it\u2019s not the case that you always MUST use both charsets).\u00a0 I suggest this: NEW \u00a0  [ RFC2231 ] encoding of the message Subject header field \u00a0  MUST be supported, and when used, only the \"UTF-8\" and \"US-ASCII\" \u00a0  charsets are allowed: other charsets MUST NOT be used. END DISCUSS: That said, I don\u2019t understand the need to specifically allow UTF-8 here.\u00a0 If the subject only contains \u201cACME:\u201d, FWS, and a base64 string, it will always be ASCII.\u00a0 Why are we talking about UTF-8 at all? \u00a0 \u00a0 \u00a0  The message MUST also pass \u00a0 \u00a0 \u00a0  DMARC validation [ RFC7489 ], which implies DKIM and SPF validation \u00a0 \u00a0 \u00a0  [ RFC7208 ]. Two things here, which apply to bullet 9 in Section 3.2 also: 1. DMARC does not imply DKIM *and* SPF validation: DMARC uses DKIM *or* SPF to do Identifier Alignment. 2. I have an issue with requiring the use of DMARC at this point, as it\u2019s specified only in an Informational document in the Independent stream.\u00a0 In any case, what\u2019s the point of requiring DMARC?\u00a0 It seems to me that the authentication you need is provided by DKIM or S/MIME; what do you need from DMARC?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-13 15:03:55-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 00:03:13-08:00",
    "text": "I have one point that I am not sure of the significance of and would like to discuss further, and one point that I think has a fairly clear/straightforward resolution. One of the key properties of ACME is that its authenticator provides assurance that both a party controlling the identifier to be certified and the ACME client jointly assent to the certification request of that identifier.\u00a0 I'm trying to explore a bit more the \"jointly assent\" part, and whether it is clear that all steps of the challenge/validation flow are ultimatetly tied to the same order request. In the validation flows for the challenge types from 8555, the full token is returned to the ACME client, which then provides the token to the entity that controls the identifier being certified, in order to set up state to expect a verification attempt using that token.\u00a0 In this email validation flow, though, the token-part1 is *only* present in the challenge email, so there is no thread of continuity that allows the email account holder to tie the validation attempt to the specific request (i.e., token).\u00a0 Any message that comes in claiming to be an ACME challenge would end up being treated as a validation attempt for the pending request, so the ACME server (or a party pretending to be one) does not have to provide any proof of knowledge of the pending validation before the response email is generated.\u00a0 Some key properties here seem to include: there is a portion (token-part2) to the response email that can only be provided by the ACME client, there is a part (token-part1) to the response email that can only be provided by an entity that can receive email at the email address being validated, and that the validation attempt, response email, and ACME order request can be tied together by unique identifiers.\u00a0 It seems that we could achieve all three of these by having the HTTPS response to the ACME client include a token-part0 as well as the token-part2, with token-part0 being used as the subject line of the challenge email and token-part1 being conveyed in some fashion (whether body or headers) of the challenge email.\u00a0 Does such a scheme provide any useful properties that are not provided by the current scheme? The more straightforward point is that the procedure in section 3 indicates that token-part2 is returned to the ACME client over HTTPS, but the stated procedure does not otherwise involve an ACME client in initiating the newOrder request.\u00a0 I think we need to clarify the interaction/relationship between end-user/email client UI/etc and the ACME client in step 1.\u00a0 In particular, I think that \"[t]his document doesn't prescribe how exactly S/MIME certificate issuance is initiated\" seems incompatible with requiring there to be an ACME client involved (and the presumed newOrder ACME request, etc.) unless the \"initiate\" operation is supposed to be the way by which the ACME client is triggered to start the request.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-11-14 21:33:41-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-03 05:07:39-07:00",
    "text": "This is generally a well written document. I have a couple of important comments that I would like to see addressed and several less significant comments. 1) As Mirja pointed out, this spec needs need to register \"Mutual\" HTTP Authentication Schemes with IANA 2) In Section 7: \u00a0  If HTTP is used on a non-encrypted channel (TCP and SCTP, for \u00a0  example), the validation type MUST be \"host\".\u00a0 If HTTP/TLS [ RFC2818 ] \u00a0  (HTTPS) is used with a server certificate, the validation type MUST \u00a0  be \"tls-server-end-point\".\u00a0 If HTTP/TLS is used with an anonymous \u00a0  Diffie-Hellman key exchange, the validation type MUST be \"tls-unique\" \u00a0  (see the note below). \u00a0  Implementations supporting Mutual authentication over HTTPS SHOULD \u00a0  support the \"tls-server-end-point\" validation.\u00a0 Support for \u00a0  \"tls-unique\" validation is OPTIONAL for both servers and clients. I think the two paragraphs are in conflict. For example, the first one says that if TLS with server certificate is used, then \"tls-server-end-point\" MUST be supported. But the second says that it is SHOULD be supported. If the intent of the first paragraph is to say what should appear syntactically, while the second paragraph explains what kind of validation is actually required, I think this still can be made clearer. I suggest you either delete the second of these 2 paragraphs, or you need to reword text in the first (and possibly the second) to specify a non conflicting set of requirements.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 20:53:45-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-18 14:19:46-08:00",
    "text": "In Section 2.3 we refer to the datagram_tag plus layer-2 sender address as being \"a globally unique identifier for the datagram\", but I think this can only hold within some time-bounded window (e.g., the lifetime of the packet), since the tag space is finite and reuse somewhat inevitable.\u00a0 [The simplest way to resolve this is probably to just remove the definition from this document and refer to draft-ietf-6lo-minimal-fragment  for definitions.] I think we should be more clear about whether a \"FULL bitmap\" always has 32 bits set to one, or if \"merely\" having as many bits as the sender sent fragments set to one also counts as \"FULL\".\u00a0 The current text seems to invite different interpretations by implementations.\u00a0 (If FULL does mean all 32 bits, then the semantics of the other case seem unclear to me.) What's the transition/backwards-compatibility story?\u00a0 That is, how does a sender know that all nodes on the path support the RFRAG dispatch types, and what happens if they are sent anyway and get to a node that doesn't implement them? I have grave misgivings about allowing a packet (as identified by sender and tag) to be refragmented by the sender so that a single fragment sequence number is used for fragments of different lengths.\u00a0 We do not seem to provide a mechanism to distinguish which variant of that fragment is being ack'd, which could lead to disagreement between sender and receiver as to whether a full packet is reconstructed. Brainstorming, it might be possible to allow such refragmenting at the sender by using a Fragment_Size of zero to indicate \"this fragment is superseded\" and allocating new sequence number for all its components. (I didn't attempt to do an exhaustive check on whether that proposal is flawed and Fragment_Size of zero already has some existing semantics that would be in conflict.)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-22 11:09:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 05:55:15-08:00",
    "text": "Thanks for this well written document, however, I have a couple points below that need further clarification, all mostly related to congestion control. From an editorial point of view most of this is discussed either in the intro text of section 6, then some part in 7.1, and some in the appendix C. I would really recommend you to instead have a separate section that much clearer states what should be done by default (probably no dynamically window but a small fixed window with maybe size of 1) and what could be don as further optimisation, and also to discuss the parameter/variables there before the algorithms are discussed. And a bit of a provoking question: wouldn't it be easier to just use a reliable transport protocol on top? If this mechanism is intended to be used over a short path with a few hops only (in a local network), I think this should be stated more clearly at the beginning of the document.  In the appendix you state this: \" In addition, deploying such a mechanism requires \u00a0  that the end-to-end transport is aware of the delivery properties of \u00a0  the underlying LLN,...\" But I'm not sure what you mean...? Can you further explain? 1) Sec 6: \"Upon exhaustion of the retries the \u00a0  sender may either abort the transmission of the datagram or retry the \u00a0  datagram from the first fragment with an 'X' flag set in order to \u00a0  reestablish a path and discover which fragments were received over \u00a0  the old path in the acknowledgment bitmap. \" I'm not sure about this \"or\". Why should the first fragment be more successful than any other which requests an ACK? Also if you really want to keep this condition, you need to specify it better. How often do you retry? I guess you need to set the PTO again...? Further the RTO should also implement an exponential back-off. 2) sec 6.3: \"Upon an acknowledgment with a NULL bitmap, the sender endpoint \u00a0  MUST abort the transmission of the fragmented datagram with one \u00a0  exception: In the particular case of the first fragment, it MAY \u00a0  decide to retry via an alternate next hop instead.\" What's mean with \"In the particular case of the first fragment\"? And does this mean it should retry only with the first fragment or the whole transmission. However, if this signal is from the receiving endpoint why should that endpoint change it mind only if a different path is used? If the assumption is that this NULL bitmap is sent by an intermediate node? However, then it would make sense to\u00a0 rather signal this information explicitly (e.g. using a flag). 3) Sec 7.1 (and to some extend sec 6) \"\u00a0  OptWindowSize:\u00a0 The OptWindowSize is the value for the Window_Size \u00a0 \u00a0 \u00a0 that the sender should use to start with.\u00a0 It is greater than or \u00a0 \u00a0 \u00a0 equal to MinWindowSize.\u00a0 It is less than or equal to \u00a0 \u00a0 \u00a0 MaxWindowSize.\u00a0 The Window_Size should be maintained below the \u00a0 \u00a0 \u00a0 number of hops in the path of the fragment to avoid stacking \u00a0 \u00a0 \u00a0 fragments at the bottleneck on the path.\u00a0 If an inter-frame gap is \u00a0 \u00a0 \u00a0 used to avoid interference between fragments then the Window_Size \u00a0 \u00a0 \u00a0 should be at most on the order of the estimation of the trip time \u00a0 \u00a0 \u00a0 divided by the inter-frame gap.\" This needs normative language and more explanation. I recommend to even say that if no congestion control (as discussed in the appendix) is applied, the Window MUST be set to 1. Further, the assumption that the window can or should be set to (at maximum) the number of hop does seem correctly to me. No matter how many hops there are packets are only queued at the bottleneck (the link where the current rate is smaller than the sending rate) and it depends on the sending rate of the bottleneck link how many packets need to be queued. This is completely independent of the number of hops. Further, even if that would be true, as long as this document does not discuss also away to estimate or know the number of hops, this advise would unfortunately be useless... Further I don't think pointing to  rfc6298  for RTT calculation is sufficient (as done in the appendix).  rfc6298  assume frequent ACKs and a reasonably large window, which is both not the case here. All in all, any window adjustments itself are not described at all. What should be done when a congestion marking is received? How does the window need to be adjusted based on an RTO? When should the window be increased again? And how much? 4) Sec 7.1.: Inline with the TSV-ART review (Thanks Collin!), the parameters need more guidance. Especially for he number of retries it should be possible to recommend a default value (e.g. 3) and it would be good to also give an upper limits (MUST NOT be larger than X). Similar for the window size: there should be also at least a default value (see comment above). And further the RTO needs further explanation about how to find a reasonable value. If the RTO is configured (and not estimated dynamically) e.g. it could be set to 3x the maximum expected RTT in the respective network. And it would be even better to provide a minimum default (initial) value. Not that TCP is also designed to work on a large variety of timescales and a minimum initial value of 1s is seen as safe for all Internet scenarios. It's really important to also provide some recommendations like this here. 5) Sec 7.2: \"The management system should monitor the number of retries and of ECN \u00a0  settings that can be observed from the perspective of both the sender \u00a0  and the receiver, and may tune the optimum size of Fragment_Size and \u00a0  of Window_Size, OptFragmentSize, and OptWindowSize, respectively, at \u00a0  the sender.\" This does not see seem correct, as OptFragmentSize and OptWindowSize are the initial values which are configured and therefore should not be changed dynamically. Only Fragment_Size and Window_Size are changes. Further the network should also normatively state somewhere that Fragment_Size and Window_Size MUST not grow above the configured max value. That seems obvious but it's better to be explicit and use normative language respectively. 6) Further sec 7.2 says: \"The inter-frame gap is another tool that can be \u00a0  used to increase the spacing between fragments of the same datagram \u00a0  and reduce the ratio of time when a particular intermediate node \u00a0  holds a fragment of that datagram.\" However, inter-frame gap is a configuration parameter and this is the first time that adapting it dynamically is mentioned here. If you want to adapt it dynamically you need to add more information.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-03-06 12:22:47-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 13:48:58-08:00",
    "text": "[ Be ye not afraid - this should be easy to address.]  \"datagram_size: The size of the datagram in its Compressed Form before it is fragmented. The datagram_size is expressed in a unit that depends on the MAC layer technology, by default a byte.\" and: \"Fragment_Size:\u00a0 10-bit unsigned integer; the size of this fragment in a unit that depends on the MAC layer technology.\u00a0 Unless overridden by a more specific specification, that unit is the octet, which allows fragments up to 1024 bytes.\" I spent quite a while going though the document, looking at the 13 places where you use 'byte' and 3 where you use 'octet', trying to figure out if there is a reason that different terms are used. Normally I'd just say \"meh, these are synonyms\" and ignore it, but in this particular specification (because of the \"by default\" / \"Unless overridden\") I think it is actually important.... Can you standardize on one of the other, or provide more explanatory text if there is a reason?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-12-22 08:15:47-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-17 03:20:20-08:00",
    "text": "The \"crit\" point raised in the gen-art review and maybe elsewhere is I think correct but I don't think section 6 of -08 is a good resolution of this topic. However, I'll clear if this is the WG consensus but it's hard to know that's the case for text just added yesterday. To resolve this discuss we just need to see what the WG list says about the new text.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-10-19 13:50:01-07:00",
    "end_reason": "position_updated",
    "start": "2015-09-30 14:16:16-07:00",
    "text": "The security considerations section seems substantially incomplete. The phrase \"include, but are not limited to\" seems to indicate that people thought there were additional considerations. Please write them down, or explain why there really aren't additional considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-04-30 04:01:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-27 02:52:29-07:00",
    "text": "After reading the discussion between Adam, Kathleen and Alia, I have the following concerns: 1) With the removal of aes-key-wrap from the data model it is now not possible to tell whether a particular key string is a passphrase or whether it contains an encrypted key. 2) I really really think aes-key-wrap should be restored in the document. If there is no facility for doing wrapped keys, implementations will never support them. I would like to at least discuss this.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-05-03 08:51:21-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-30 04:01:12-07:00",
    "text": "After reading the discussion between Adam, Kathleen and Alia, I have the following concerns: 1) With the removal of aes-key-wrap from the data model it is now not possible to tell whether a particular key string is a passphrase or whether it contains an encrypted key.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-04-27 06:15:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-04-26 09:31:48-07:00",
    "text": "Thanks for your work on this draft.\u00a0 There is one outstanding issue from the SecDir review that may require some updated text to resolve.\u00a0 It seems use of the key wrap method in  RFC5649  requires more guidance for implementations to use it with this YANG module.\u00a0 It's good to know that this is in use for other modules, so having a clear reference either to another draft or the text being in this draft for later reference would be helpful. In looking at this text within the draft, I think it would be better to pull the text out of the Security Considerations section and into an earlier section of the draft.\u00a0 It's better to introduce this prior to enumerating security considerations for the draft since this something that would be implemented.\u00a0 Then security considerations should mention the considerations of using this option versus just what's in NACM. You have the text: \u00a0 When configured, the key-strings can be encrypted using the AES Key \u00a0  Wrap algorithm [AES-KEY-WRAP].\u00a0 The AES key-encryption key (KEK) is \u00a0  not included in the YANG model and must be set or derived independent \u00a0  of key-chain configuration.\u00a0 When AES key-encryption is used, the \u00a0  hex-key-string feature is also required since the encrypted keys will \u00a0  contain characters that are not representable in the YANG string \u00a0  built-in type [YANG].\u00a0 AES key-encryption MAY be used for added key \u00a0  security in situations where the NETCONF Access Control Mode is not \u00a0  available. I think it's pretty straightforward after looking at  RFC5649 , but maybe more text would be helpful to clarify for implementers.\u00a0 This might mean more text from 5649 on what gets placed in the YANG data model where you have already allocated for this or including an example.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-05-03 08:28:37-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-27 06:15:35-07:00",
    "text": "Note: My discuss is based on version -20 that contained the AES key wrap.\u00a0 I'd like to see that restored in the draft as it's important for the draft, and the rest of my discuss on that text will make more sense. Thanks for your work on this draft.\u00a0 There is one outstanding issue from the SecDir review that may require some updated text to resolve.\u00a0 It seems use of the key wrap method in  RFC5649  requires more guidance for implementations to use it with this YANG module.\u00a0 It's good to know that this is in use for other modules, so having a clear reference either to another draft or the text being in this draft for later reference would be helpful. In looking at this text within the draft, I think it would be better to pull the text out of the Security Considerations section and into an earlier section of the draft.\u00a0 It's better to introduce this prior to enumerating security considerations for the draft since this something that would be implemented.\u00a0 Then security considerations should mention the considerations of using this option versus just what's in NACM. You have the text: \u00a0 When configured, the key-strings can be encrypted using the AES Key \u00a0  Wrap algorithm [AES-KEY-WRAP].\u00a0 The AES key-encryption key (KEK) is \u00a0  not included in the YANG model and must be set or derived independent \u00a0  of key-chain configuration.\u00a0 When AES key-encryption is used, the \u00a0  hex-key-string feature is also required since the encrypted keys will \u00a0  contain characters that are not representable in the YANG string \u00a0  built-in type [YANG].\u00a0 AES key-encryption MAY be used for added key \u00a0  security in situations where the NETCONF Access Control Mode is not \u00a0  available. I think it's pretty straightforward after looking at  RFC5649 , but maybe more text would be helpful to clarify for implementers.\u00a0 This might mean more text from 5649 on what gets placed in the YANG data model where you have already allocated for this or including an example.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-03-11 11:52:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-11 11:51:34-07:00",
    "text": "This is a process DISCUSS.\u00a0 I don't believe the status of this document as a BCP belonging to  BCP 25  was discussed in the WG or with the IETF community. The Charter for the git WG only explicitly mentions  BCP 9 : \u00a0  The documents produced by this group will not alter the Internet Standards  \u00a0  Process ( BCP 9 ). They will describe how to work within it. Whether working  \u00a0  groups choose to use GitHub or the documented policies to support their work  \u00a0  will remain entirely at their discretion. However, including this document as a part of  BCP 25  (IETF Working Group Guidelines and Procedures) results in the interpretation that it represents consensus on how WGs should proceed -- and not that the decision \"to use GitHub or the documented policies...[is]...entirely at their discretion.\" My reading of the mailing list is that the current RFC Editor note (in which appending the document to  BCP 25  is requested) was added only after the topic was brought up in the Genart LC review. IOW, both (1) the process of reaching the conclusion that this document belongs in  BCP 25 , and (2) the concept that this document would be part of  BCP 25 , are the subject of my DISCUSS.\u00a0 \u00a0 I would like for the IESG to discuss this topic.\u00a0  Not expecting this document to be part of  BCP 25 , or having an explicit discussion with the community about it, would lead me to clear my DISCUSS. ==== [Non blocking comment.\u00a0 I'm including it here because it is related to the status of the document.] This document would be very good Informational document.  I am not a regular GitHub user (and none of the WGs I'm responsible for use it as part of their process), but I have no reason to doubt that the text represents what is believed to be the best way to use GitHub within the IETF process.\u00a0 However, the designation as a BCP can create confusion.\u00a0 [Again, this is a non-blocking comment.]",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-03-20 11:14:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-11 11:52:53-07:00",
    "text": "This is a process DISCUSS.\u00a0 I don't believe the status of this document as a BCP belonging to  BCP 25  was discussed in the WG or with the IETF community. The Charter for the git WG only explicitly mentions  BCP 9 : \u00a0  The documents produced by this group will not alter the Internet Standards  \u00a0  Process ( BCP 9 ). They will describe how to work within it. Whether working  \u00a0  groups choose to use GitHub or the documented policies to support their work  \u00a0  will remain entirely at their discretion. However, including this document as a part of  BCP 25  (IETF Working Group Guidelines and Procedures) results in the interpretation that it represents consensus on how WGs should proceed -- and not that the decision \"to use GitHub or the documented policies...[is]...entirely at their discretion.\" My reading of the mailing list is that the current RFC Editor note (in which appending the document to  BCP 25  is requested) was added only after the topic was brought up in the Genart LC review.\u00a0 [Did I miss the discussion?] IOW, both (1) the process of reaching the conclusion that this document belongs in  BCP 25 , and (2) the concept that this document would be part of  BCP 25 , are the subject of my DISCUSS.\u00a0 \u00a0 I would like for the IESG to discuss this topic.\u00a0  Not expecting this document to be part of  BCP 25 , or having an explicit discussion with the community about it, would lead me to clear my DISCUSS. ==== [Non blocking comment.\u00a0 I'm including it here because it is related to the status of the document.] This document would be very good Informational document.  I am not a regular GitHub user (and none of the WGs I'm responsible for use it as part of their process), but I have no reason to doubt that the text represents what is believed to be the best way to use GitHub within the IETF process.\u00a0 However, the designation as a BCP can create confusion.\u00a0 [Again, this is a non-blocking comment.]",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-03-10 06:05:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-08 23:44:41-07:00",
    "text": "I have a really simple thing to discuss before I move to a \u201cyes\u201d ballot: \u2014 Section 4.1.3 \u2014 \u00a0  Chairs need to assess whether the \u00a0  arguments offered represent new information or not.\u00a0 This can require \u00a0 some discussion to determine accurately.\u00a0 Resolved issues MUST remain \u00a0  closed unless there is consensus to reopen an issue. There seems to be an inconsistency here: WGCs decide whether new information has been given, so it would seem that it\u2019s the WGCs who decide that an issue should be reopened.\u00a0 But then we say there has to be consensus for it.\u00a0 In addition to that appearing inconsistent, I\u2019m not clear how one would determine whether there\u2019s rough consensus to reopen an issue, if doing so were controversial.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-03-11 17:33:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-10 10:45:09-07:00",
    "text": "I originally balloted Abstain, but this is (and has been) bothering me enough that I'm changing it to a discuss. This feels like additional centralization / control / process, without good justification. I happen to use GitHub for my documents (along with discussion / agreement with co-authors), but in personal repos. Our documents include something like: \"[ This document is being collaborated on in Github at  https://github.com/wkumari/ .\u00a0 The most recent\u00a0 version of the document, open issues, and so on should all be available there.\u00a0 The authors gratefully accept pull requests. ]\" This document contains a lot of text about setting up, administering, etc a WG organization / repos -- but there is no good justification (that I could find) on what advantages this has over simply encouraging people use GitHub (because it is easy, and well known), and keeping things in their own repos. If WG documents include a pointer (like above) to the repo, everyone can find it, and we don't need all this. This smacks of scope-creep / chairs having control and process where it a: isn't needed and b: isn't helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-08-02 13:15:41-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 13:50:42-07:00",
    "text": "\u00a77 (\"Results of the Alternate Marking Experiment\") makes several  recommendations about the use of one or two flag bits: \u00a0 \u00a0 \u00a0 One flag: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 3.1, while delay measurement MAY be done according to the \u00a0 \u00a0 \u00a0 single-marking method described in Section 3.2.1.\u00a0 Mean delay \u00a0 \u00a0 \u00a0 (Section 3.2.1.1) is NOT RECOMMENDED since it implies more \u00a0 \u00a0 \u00a0 computational load. \u00a0 \u00a0 \u00a0 Two flags: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 3.1, while delay measurement SHOULD be done according to \u00a0 \u00a0 \u00a0 double-marking method Section 3.2.2.\u00a0 In this case single-marking \u00a0 \u00a0 \u00a0 MAY also be used in combination with double-marking and the two \u00a0 \u00a0 \u00a0 approaches provide slightly different pieces of information that \u00a0 \u00a0 \u00a0 can be combined to have a more robust data set. These recommendations are good, as they are the result of experimentation.\u00a0  However, they don't provide any deployment or operational guidelines of when  is it ok to follow them and when it isn't.\u00a0 For example, for the one flag case,  when it is ok to not measure packet loss as described in \u00a73.1?\u00a0 Why is the use  of that mechanism only recommended and not required? I have the same questions for all the recommendations and optional indications  in the text above.\u00a0 To clear this DISCUSS I expect deployment or operational  recommendations that can be used as implementation/deployment guidance.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-25 23:00:24-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 05:22:19-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-rfc8321bis-02 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Please note that Tim Winters is the Internet directorate reviewer (at my request) and you may want to consider this int-dir review as well when Tim will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-ippm-rfc8321bis/reviewrequest/16061/ Special thanks to Tommy Pauly for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 5 Unsure whether I understand correctly: ``` \u00a0  Color switching is the reference for all the network devices, and the \u00a0  only requirement to be achieved is that all network devices have to \u00a0  recognize the right batch along the path. ``` Why do *all network devices* have to recognize the right batch? Isn't this transparent for them?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-29 02:08:20-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 13:18:20-07:00",
    "text": "# GEN AD review of  draft-ietf-ippm-rfc8321bis-02 CC @larseggert Thanks to Elwyn Davies for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/tX3DO8ZB3yeiaKC_xnI1khVAcss ). ## Discuss ### Section 3.1, paragraph 5 ``` \u00a0 \u00a0  The rest of the document assumes that the blocks are created \u00a0 \u00a0  according to a fixed timer.\u00a0 The switching after a fixed number of \u00a0 \u00a0  packets is an additional possibility but its detailed specification \u00a0 \u00a0  is out of scope. ``` This should more strongly say that the use fixed timers are REQUIRED when implementing the spec. This document should then also be stripped of all text discussing the \"fixed number of packets\" approach, to improve clarity. (You could move it to a non-normative appendix, if there is a desire to keep the text around.) ### Section 3.1, paragraph 16 ``` \u00a0 \u00a0  Two different strategies that can be used when implementing the \u00a0 \u00a0  method: ``` If both of these strategies are part of the standard, concrete guidance needs to be given when to use one or the other. The text below about \"a limited number of traffic flows\") is too unspecific. ### Section 3.2, paragraph 1 ``` \u00a0 \u00a0  The same principle used to measure packet loss can be applied also to \u00a0 \u00a0  one-way delay measurement.\u00a0 There are three alternatives, as \u00a0 \u00a0  described hereinafter. ``` As above, there is a lot of discussion text around these alternatives, but no concrete guidance when one SHOULD be used but not the other two. If that guidance cannot be given, I wonder if we have enough deployment experience to lift this to the Standards Track. ### Section 5, paragraph 1 ``` \u00a0 \u00a0  This document introduces two color-switching methods: one is based on \u00a0 \u00a0  a fixed number of packets, and the other is based on a fixed timer. \u00a0 \u00a0  But the method based on a fixed timer is preferable because it is \u00a0 \u00a0  more deterministic, and it is considered in the document. ``` Section 3.1 says that the fixed-number-based approach is out of scope for this specification. The text above is inconsistent with that. Again, please remove the text that talks about the option that is not actually part of the intended standard (or move it to an appendix.)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-09-08 02:19:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-14 01:09:09-07:00",
    "text": "Sorry, another discuss, but hopefully a trivial one to resolve. I found this text to be a unclear regarding passive vs hybrid: \u00a0  Therefore, the Alternate-Marking Method could be considered Hybrid or \u00a0  Passive, depending on the case.\u00a0 In the case where the marking method \u00a0  is obtained by changing existing field values of the packets the \u00a0  technique is Hybrid.\u00a0 In the case where the marking field is \u00a0  dedicated, reserved, and included in the protocol specification, the \u00a0  Alternate-Marking technique can be considered as Passive. Please can you clarify the third sentence, to clarify that the marking is done at source, or at least outside the controlled domain?\u00a0 I.e., I presume that even if there were some reserved bits in the protocol header for colouring packets, that were then written at the edge of the controlled domain, then this would be a active rather than passive measurement? Thanks, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-05 09:40:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 10:58:52-07:00",
    "text": "Please clarify the expected deployment model of this approach. (a) Section 7.1 \u00a0  For security reasons, the Alternate Marking Method is RECOMMENDED \u00a0  only for controlled domains. (b) Section 10 \u00a0  This document specifies a method to perform measurements in the \u00a0  context of a Service Provider's network and has not been developed to \u00a0  conduct Internet measurements, so it does not directly affect \u00a0  Internet security nor applications that run on the Internet. The text in (a) suggests that deployment can occur on the Internet (although it isn\u2019t recommended).\u00a0 However, (b) and other documents out of IPPM (e.g.,  RFC9197 ) seem to suggest that OAM meta-data must be filtered.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-26 12:28:10-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 17:41:53-07:00",
    "text": "Section 7.1 says: \"The Alternate Marking Method is an example of a solution limited to a controlled domain [ RFC8799 ]. A controlled domain is a managed network that selects, monitors, and controls access by enforcing policies at the domain boundaries, in order to discard undesired external packets entering the domain and check internal packets leaving the domain. [...] It must be possible to control the domain boundaries, and use specific precautions if traffic traverses the Internet.\" \"Controlled domain\" isn't a magic incantation you invoke to make all security issues disappear. Your definition of controlled domain sounds suspiciously like \"the network should magically stop bad packets, and evil people wanting to do bad things!!!!\".  RFC8799  does not define what makes a domain, nor how the boundary is protected. Instead, it \"it shows the need for a precise definition of \"limited domain membership\" and for mechanisms to allow nodes to join a domain securely and to find other members, including boundary nodes.\" and notes that \"the Internet does not have a well-defined concept of limited domains\" and further that \"Domain boundaries that are defined administratively (e.g., by address filtering rules in routers) are prone to leakage caused by human error, especially if the limited domain traffic appears otherwise normal to the boundary routers.\u00a0 In this case, the network operator needs to take active steps to protect the boundary.\" The document states that \"For security reasons, the Alternate Marking Method is RECOMMENDED only for controlled domains.\" - but you have not defined how a network operator is expected to define and enforce the domain boundary; simply saying that the network should select, monitor, and control access by enforcing policies at the domain boundaries, in order to discard undesired external packets doesn't explain how the network should do this. How exactly does the network know what packets are marked? How does the operator filter these? What matching rule can be applied at the boundary to make sure that marked packets do not enter or exit the network?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-08-29 01:57:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 04:58:17-07:00",
    "text": "Thanks for working on this specification. My fellow AD colleagues have already put discusses on the concerns I have. Overall, I found this document easy to ready but lacking some clarity on the assumptions and instructions. For, this I am supporting Roman's and Lars's discuss. Apart from those I have one additional concern. ## Section 7 : says - \u00a0 \u00a0 \u00a0 In the case where the marking method is applied by changing existing \u00a0  fields of the packets, it is RECOMMENDED to use an additional flag or \u00a0  some out-of-band signaling to indicate if the measurement is \u00a0  activated or not in order to inform the measurement points. \u00a0 It is not clear who is changing existing fields of which packets? It needs more specific description for at least which packets are we talking about (IP packets? ) and what additional flag we are referring to here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-20 16:19:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-05 01:45:35-08:00",
    "text": "I agree with Roman, and present a somewhat different take on some of the key aspects of the scoping discussion. I have pretty fundamental concerns about describing this protocol as a \"0-RTT\" service when it both requires strong mutual authentication/authorization of the communicating endpoints and relies on the (local) network to provide those properties.\u00a0 If IP in general provided the kind of mutual authentication assumed here, the internet would be a much more secure place!\u00a0 Unfortunately, it does not and I think this document does its readers a disservice by transparently assuming that it does (in the main body of text; the security considerations do touch on the requisite details).\u00a0 It would be better to discuss the proxy protocol separately from the deployment considerations that allow it to be used without additional set-up in specific deployment scenarios. And that's only when considering the client authenticating the server! Mutual authentication also requires the server to authenticate the client and be able to make authorization decisions based upon that authenticated identity.\u00a0 The deployment model presented here seems to imply a very tight coupling between the Transport Converter operator and the network service provider (in order to determine, based on client IP address, the authenticated client identity and access an authorization database); this seems to make it incompatible with the stated possibility of using a third-party Transport Converter. Additionally, it raises some questions along the lines of draft-arkko-iab-internet-consolidation  and draft-iab-for-the-users. The sketch of a solution for more open network environments in Section 9.2 is insecure (once a Cookie is generated and sent once, it can be freely replayed by an attacker during the Cookie lifetime, which defeats the authorization requirement of the convert protocol).\u00a0 Either fix it or remove it entirely. Please resolve the internal inconsistency in Section 6.2.4 which says that TCP option Kind 0 MUST NOT appear in the list but then goes on to say that the list is padded with zeros to a 32-bit boundary.\u00a0 (There is no listed requirement that the options are listed in any given order, which would be needed to assign a boundary between \"listed options\" and \"padding\".) Why do we need the Cookie TLV at all if the underlying local network supplies all the authentication and authorization that the protocol needs? Section 1.2 says that the Convert Protocol \"is an application-layer protocol which uses a dedicated TCP port number\", but the IANA request in Section 10.1 is for a service name without fixed port number.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-03-06 06:55:23-08:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 06:58:40-08:00",
    "text": "Thank you for the work put into this document. It is indeed useful to be able to deploy easily new TCP features. Nevertheless, please find below two DISCUSSes and some non-blocking COMMENTs (and I would appreciate a response from the authors) and NITS. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 1.2 -- A trivial one: while the title and the abstract of this document appear as quite generic, the document focus is reduced later in section 1.2 to MPTCP:  \u00a0 \"this \u00a0  document specifies how the Convert Protocol applies for Multipath \u00a0  TCP.\u00a0 It is out of scope of this document to provide a comprehensive \u00a0  list of all potential conversion services. \" While I do not mind having a focus on MPTCP only, I would strongly suggest to reflect this focus in the title and in the abstract (the current filename is correct). -- Section 6.2.8 -- I appreciate that this is an experimental document, but, having only 2 occurrences of ICMP in the whole document and no real \"how to process\" TLV \"Destination Unreachable\"... and the payload of this TLV having only the code without the offending packet will probably make Path MTU discovery (and other mechanisms) impossible. While I am not a transport expert, I believe that this aspect needs to be described in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-21 17:43:32-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 20:55:05-08:00",
    "text": "** Deployed without constraints, there would be a number of concerning attacks given this protocol\u2019s design.\u00a0 Christian Huitema\u2019s SecDir review (thank you!) notes some of them.\u00a0 Helpfully, this draft presents various restrictive scoping to mitigate these attacks under certain circumstances: (a) Section 4.1. Transport Converters can be operated by network operators or third parties.\u00a0  Nevertheless, this document focuses on the single administrative deployment case where the entity offering the connectivity service to a client is also the entity which owns and operates the Transport Converter. (b) Section 9.1. Furthermore, ingress filtering policies MUST be enforced at the network boundaries [ RFC2827 ]. (c) Section 9.2. The Convert Protocol is intended to be used in managed networks where end hosts can be identified by their IP address. (d) Section 9.2.\u00a0 Stronger mutual authentication schemes MUST be defined to use the Convert Protocol in more open network environments. Unfortunately, the protocol mechanism to operate outside of these bounds is in scope because (a) and (c) include no normative language.\u00a0 For example, this document doesn\u2019t address converters operated by third parties but it explicitly allows for their possibility with no discussion of the impact. As this is an experimental document where implementation experience likely is needed for refinement, could a compromise be found with an applicability statement that shrinks the threat model and provide better normative guidance.\u00a0 For example (paraphrasing): Applicability statement: Transport Converters MUST only be deployed in a single administrative domain deployment model.\u00a0 The entity offering the connectivity service to a client MUST also be entity which owns and operates the Transport Converter, with no transit over a third-party network. For the Security Considerations: The Convert Protocol is RECOMMENDED to be used in a managed network where end hosts can be identified by their IP address.\u00a0 If such control is not exerted and there is a more open network environment, a strong mutual authentication scheme MUST be defined to use the Convert Protocol. ** Section 9.1.\u00a0 Per \u201cGiven its function and its location in the network, a Transport Converter has access to the payload of all the packets that it processes.\u201d, it\u2019s a per more than that.\u00a0 It is in a position to observe all packets, so that\u2019s payload, meta-data and the ability to profile and conduct traffic analysis.\u00a0 Perhaps something on the order of \u201cGiven its function and location in the network, a Transport Convert is in a position to observe all packets, to include payloads and meta-data; and has the ability to profile and conduct traffic analysis of user behavior\u201d. ** Section 9.1.\u00a0 Per \u201cAs such, it MUST be protected as a core IP router (e.g., [ RFC1812 ])\u201d, no disagreement on the need to protect this router.\u00a0 However, what exact practices are being suggested?\u00a0 Given the  RFC1812 , reference, what specific sections apply?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-11-01 08:17:22-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-16 12:01:57-07:00",
    "text": "(1) I find the absence of any definition of error handling behavior in this document to be a problem. I realize that the attributes specified in this document are meant to be transmitted between components that are all operated by the same administrative entity, but implementors can still make mistakes, and for those cases it seems like error handling should be defined. For example: - What happens if the AAA server sends an IP-Port-Limit-Info attribute with a larger limit than the CGN is able to allocate to that particular user? What is the CGN supposed to do and how is that communicated back to the AAA server? - What happens if the CGN sends an IP-Port-Range attribute that encompasses a larger range than a previously sent IP-Port-Limit-Info? What is the AAA server supposed to do? - What happens if the AAA server sends an IP-Port-Forwarding-Map attribute to map a port that is not within the requesting host's allocated range? Is the CGN expected to change the mapping and send a CoA with a different IP-Port-Forwarding-Map, or communicate some sort of error, or something else? There are surely other error cases. I think it's worth going through the uses of each attribute and specifying all the error handling behavior. This seems especially important since part of the motivation for these attributes is for identification and the consequences of erroneous identification could be severe for the user. Discussion of those consequences is also missing from Section 6. (2) Section 3.1.2 says: \"For port allocation, both IP-Port-Range-Start TLV and IP- \u00a0  Port-Range-End TLV must be included; for port deallocation, the \u00a0  inclusion of these two TLVs is optional and if not included, it \u00a0  implies that all ports that are previously allocated are now \u00a0  deallocated.\" How does an AAA server distinguish between port allocation and deallocation requests if a deallocation request includes a range start and range end? Is the server supposed to assume that whatever range is specified by the most recently received IP-Port-Range attribute represents the only range of allocated ports for the host? What is the meaning of sending an IP-Port-Range request with only a start value or an end value but not both (as seems to be allowable by the above)? (3) The specification of IP-Port-Local-Id seems to allow for unnecessary exposure of potentially sensitive information. There is no explanation given for why the combination of the other identifiers included in IP-Port-Range and IP-Port-Forwarding attributes is insufficient to identify the host in DS-Extra-Lite and Lightweight 4over6 cases. As defined, it sounds like implementations could put basically any user, device, or interface identifier in there. If this TLV is actually necessary to communicate what these attributes are trying to accomplish, the justification for it should be provided and the limitations on when this field may be used and what kind of identifiers can appear here should be stated. (4) The shepherd write-up discusses two different approaches to defining the sub-TLV types and then says: \"Both approaches were considered as valid and the WG has decided to let IANA decide what the approach is preferred when allocating the TLV-Type for the sub-TLVs defined in this document.\" This is not appropriate. The document needs to explicitly define how the types should be allocated and should not leave the decision to IANA. I see that IANA has already noted that Section 7.3 is ambiguous about this; the WG needs to make a choice.   (5) Section 6 seems to be missing a discussion of the consequences of communicating erroneous port range and port mapping information. Since part of the motivation for these attributes is identification of the host, this needs to be discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-11-03 04:54:39-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-15 05:26:00-07:00",
    "text": "I'm late for my review here. If some points in my DISCUSS/COMMENT have been discussed already let me know. I'll flag this as a DISCUSS to follow up on the IPFIX issues. First of, I applause the attempt to reuse/map/combine data models (IPFIX information element and RADIUS attribute). Now, there are a couple of issues. The first set of issues has been sent via the IPFIX experts, copied here for tracking purposes. \u00a0 \u00a0 Dear Authors, \u00a0 \u00a0 The experts for the IPFIX IE registry have returned the following \u00a0 \u00a0 review: \u00a0 \u00a0 In general, the Information Elements in draft-ietf-radext-ip-port- \u00a0 \u00a0 radius-ext are so underspecified as to be unimplementable. They should \u00a0 \u00a0 not be added to the registry in their present form. The authors are \u00a0 \u00a0 advised to read  RFC 7013 , especially Section 4, which provides useful \u00a0 \u00a0 information on defining Information Elements. Specifically: \u00a0 \u00a0 The Information Element transportType is underspecified: (a) I presume \u00a0 \u00a0 this is in reference to sourceTransportPort and \u00a0 \u00a0 destinationTransportPort, but the description must say this if it is \u00a0 \u00a0 the case; (b) It's not clear at all from the description in what \u00a0 \u00a0 context this distinction is useful; (c) What's an ICMP identifier? \u00a0 \u00a0 In addition, the description of transportType appears to create a \u00a0 \u00a0 table which should probably be handled as a subregistry. See See \u00a0 \u00a0  RFC7013  section 4.7. for advice on the creation of tables without \u00a0 \u00a0 subregistries (in short, \"don't\".) \u00a0 \u00a0 The Information Element natTransportLimit has an inappropriate name; \u00a0 \u00a0 it does not describe that which it (presumably) is supposed to \u00a0 \u00a0 represent (see  RFC 7013  section 4.1). In addition, it is \u00a0 \u00a0 underspecified. It is impossible to implement from the description. Is \u00a0 \u00a0 the field IPv4 specific, or is IPv6 supported as well? (If not, why \u00a0 \u00a0 not?) \u00a0 \u00a0 The Information Element localID has an inappropriate name; it is far \u00a0 \u00a0 too general (see  RFC 7013  section 4.1). It uses an inappropriate \u00a0 \u00a0 abstract data type (addresses should never be represented as UTF-8 \u00a0 \u00a0 strings in IPFIX, see  RFC 7013  section 4.2). It is underspecified as \u00a0 \u00a0 well as poorly designed. Without the ability to disambiguate the type \u00a0 \u00a0 of information in the field, this is not a useful Information Element. \u00a0 \u00a0 Without a complete enumeration of possible types (n.b. 'etc.' in the \u00a0 \u00a0 description), it is not a useful Information Element. Its purpose is \u00a0 \u00a0 unclear from its description; further, it appears to violate the \u00a0 \u00a0 following guidance in  RFC 7013  section 4: \"The Information Element \u00a0 \u00a0 must be unique within the registry, and its description must represent \u00a0 \u00a0 a substantially different meaning from that of any existing \u00a0 \u00a0 Information Element. An existing Information Element that can be \u00a0 \u00a0 reused for a given purpose should be reused.\" I have some more issues I would like to discuss: - section 3.2.5, as an example, contains a list of sourceIPv6Address. In IPFIX, we would export those as a list [ RFC 6313 ] Does this RADIUS document want to only reuse the semantic of individual IPFIX information element? And also the semantic of multiple information elements [ RFC 6313 ]? And also the IPFIX encoding? For example, some IPFIX fields are \"right justified\" (sourceTransportPort), while some others are not (localID) The document should be clear.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-10-13 07:22:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-17 07:04:01-07:00",
    "text": "I fully support Alissa's discussion points and have two more to add: 1) IP-Port-Type TLV only covers UDP, TCP and ICMP. This is not very future-proof: there are other transport protocols that have ports or identifiers that may want to be supported in future. Also it is not clear to me from the document why this information is needed at all in the described use cases. Therefore I see two possible ways forward: Either remove the IP-Port-Type TLV or extend it to also cover other cases. Related to this point I would like to mention that  RFC6887  is not restricted to UDP/TCP and therefore the following sentence in section 2 is not correct: \"Note that the definitions of [...] \"internal port\", [...] \"external port\" [...] are the same as defined in Port Control Protocol (PCP) [ RFC6887 ]\" 2) The IE doctors have provide feedback to IANA that the Information Elements in this doc are underspecified (not confirm with rules in  RFC 7013 ) and should therefore be not registered.\u00a0 Addressing this feedback could lead to a mayor rewrite of this doc, especially in the relation to the use and definition of transportType and receptively IP-Port-Type TLV, and should therefore be done before a final IESG decision.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-10-16 23:39:25-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-14 15:56:00-07:00",
    "text": "Sorry for not spotting this in other documents, but do we understand the privacy characteristics of this ICMP identifier? It may well be that the resolution of this discuss requires some other document to exist (in which case I'll get out of the way of this one) but I think we ought be quite cautious in how we introduce\u00a0 new functions for identifiers that may be personally identifying, so I'd like to chat about this a bit. Did the WG discuss the privacy issues associated with this identifier?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-17 18:12:58-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 13:54:02-07:00",
    "text": "I support Roman's Discuss.\u00a0 Isn't there a straightforward translation of the \"div\" procedures to the nested \"div-o\" chain?\u00a0 Why would that not be applicable? I had two other points for discussion: (1) IANA seems unhappy (the expert review identified issues).\u00a0 What's the plan to address them? (2) The following text from the Security Considerations seems inconsistent to me: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 However, \u00a0  including this information about forwarding is at the discretion of \u00a0  the retargeting entity, so if there is a requirement to keep the \u00a0  original called number confidential, no PASSporT should be created \u00a0  for that retargeting - the only consequence will be that downstream \u00a0  entities will be unable to correlate an incoming call with the \u00a0  original PASSporT without access to some prior knowledge of the \u00a0  policies that could have caused the retargeting. I don't understand this -- if the idea is to keep the original called number confidential, wouldn't this necessitate *not giving the original PASSporT to the called entity*, since the original PASSporT includes the original call destination?\u00a0 Without the original PASSporT at all, of course it can't be correlated to an incoming call...\u00a0 (Even in the OOB case, would the post-retargeting called entity even be able to retrieve/decrypt the original PASSporT?)\u00a0 Is this intended to only apply to some non-SIP case?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-23 14:21:52-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 12:35:21-07:00",
    "text": "Section 5.\u00a0 The text notes that procedures for the authentication and verification service for the \u201cdiv-o\u201d claim will be \u201cleft to future work\u201d.\u00a0 Can the rational for this deferral be explained.\u00a0 Creating an interoperable solution without this guidance seem challenging as it would be crucial guidance on processing this newly introduced claim.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-23 15:28:59-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-16 10:21:52-07:00",
    "text": "I think we need to have a discussion about the abstract API for a KEY-DERIVATION instance and how that relates to what we need for a key combination operation.\u00a0 In Section 5 we assume that we can use the HKDF terminology, but that doesn't seem to hold universally for KEY-DERIVATION; for example, while HKDF has IKM, salt, and info, PBKDF2 (from  RFC 3211  that AFAICT introduces keyDerivationalgorithm for CMS) is specified by  RFC 2898  as taking just the input secret (password) and a salt, with no separate 'info' (and of course the different iteration count and PRF parameters needed for its construction).\u00a0 I note (with chagrin, as sponsoring AD) that  RFC 8619  says \"PARAMS ARE absent\" for the HKDF-based KEY-DERIVATION instances but is silent about how one is supposed to know what to pass for salt/info (the IKM we can perhaps assume will be obvious). In short, should we be seeking to define a distinct key combination operation like KRB-FX-CF2 ( RFC6113 ) rather than trying to repurpose key derivation?\u00a0 Some KDFs support this fairly well, but it's not clear to me that it is a universal property.\u00a0 For example, the proof in [H2019] seems to be assuming HKDF but this draft does not (as is clearly seen from the use of the X9.63 KDF in one of the examples).",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2016-03-02 23:18:34-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-29 10:17:30-08:00",
    "text": "This is just something I want to discuss, it's not an objection... At this point we say: \u00a0  Implementations therefore \u00a0  SHOULD avoid using this option if the DNS transport is not encrypted. If you did allow this on unencrypted dns transport this seems like it serves as a utility function for\u00a0 DNS amplification. Wouldn't it be better to say MUST NOT? e.g. this is exclusively for use with TLS / DTLS supporting\u00a0 sessions?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-04-26 21:28:54-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-16 16:22:40-07:00",
    "text": "(1) There is some ambiguity in the document about whether the uCDN passes the IP address of the UA or its prefix to the dCDN. Sec 4.4.1 says that for DNS redirection, the uCDN passes \"IP address or prefix\" of the UA, but then in the definition of resolver-ip specifies it only as the IP address of the UA. Then in Sec 4.5.1 for HTTP redirection the equivalent field is specified as the IP address of the UA and the possibility of sending only a prefix is not mentioned. Then 5.2 has the para that begins \"While it is technically possible to mask some information in the RI Request, such as the last bits of the UA IP address ...\" which makes it seem like prefixes really shouldn't be sent. I think the document needs some consistency and clarity here about whether prefixes are expected to be used for either redirection method. It's also not obvious to me why the document shouldn't recommend to uCDNs that if they are polling multiple candidate dCDNs as described in Sec 5.2, they should use only a prefix for such requests. The arguments given against this seem pretty thin -- isn't preventing correlation of multiple requests to a single UA a good thing, especially when it's being done by a bunch of dCDNs? And I don't understand the CGN example -- isn't the root of the problem here that topologically dispersed UAs are sharing the same public-facing IP address, in which case the dCDN may have the same problem when passed a full IP address as it does a prefix?  (2) Ben noted the weakness of the recommendation in 5.1 regarding TLS. I see that the language here is the same as it is in draft-ietf-cdni-logging-22. But I thought the agreement on that document was MUST use TLS, full stop. So there is ambiguity in both documents I think. \"In an environment where ...\" and \"When TLS is used ...\" seem inconsistent with \"TLS MUST be used ....\" I'm happy to clear on this if I'm missing something from the previous discussion, which I think happened when I was on leave and resulted from one of Stephen's ballots.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-26 04:22:31-07:00",
    "end_reason": "position_updated",
    "start": "2016-03-17 03:10:06-07:00",
    "text": "The basic idea of the uCDN sending everything to the dCDN so that the dCDN can reply with all the details of a request that'll work (i.e. the sc-* stuff) seems broken as it requires that the uCDN expose all security and privacy sensitive data to the dCDN in pretty much all cases. I fail to see why that is an acceptable approach. Can you point me at where the WG disucssed the issues with that approach and considered less security/privacy unfriendly potential alternatives?\u00a0  Some examples: - section 4.1 says \"SHOULD convey as much information as possible\" that is surely wrong - there is no reason to encourage sending cookies and other security/privacy sensitive information and in fact sending such should be discouraged (SHOULD NOT) or even, if possible, prohibited (MUST NOT).\u00a0  - The cs-(cookie) in 4.5.1 is one specific case of sending too much.\u00a0  - 4.4.1 Resolver IP addr is liable to be that of an end user's machine (if they operate a recursive).  But the examples are just that, I'd like to DISCUSS the WG's consideration of the overall design first before we dive into those.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-04-26 11:37:45-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-25 18:42:48-07:00",
    "text": "I have one (hopefully easy) point that I think needs to be fixed before progressing. Section 6, paragraph 6 says : \"... if the TCP Originator stream is missing the stream prefix, or message frames are not parsable as IKE or ESP messages), it MUST close the TCP connection.\" IIUC, the entire point of having the stream prefix is to allow the TCP responder to demux between this protocol, and some other protocol that would normally run on that port. Saying it MUST close the TCP session seems to completely remove that value. I assume people meant to allow the respondent to delegate a stream out to some other protocol handler if the prefix is not present?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-06-14 08:45:08-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-25 05:47:48-07:00",
    "text": "This draft suggests that ports that are assigned to other services can simply be used. This is not okay. If a port is assigned to a certain service, this service and/or the respective RFC defines how this port is used. Simply changing the specified behavior by requiring a check for a magic number cannot be done without updating the RFC that the port assignment belongs to. Also for the use of 4500/tcp  RFC3948  as well as the IANA registry would need to be updated. Further, as also mentioned in the tsv-art review (Thanks Wes!), this draft does not sufficiently handle the case of TCP in TCP encapsulation. Here a copy of the tsv-art review: Reviewer: Wesley Eddy Review result: On the Right Track This document is clear and well-written.\u00a0 It can easily be implemented based on the description. There are a few additional issues that should be considered with advice to implementers in Section 12 on performance considerations: 1) Invisibility of packet loss - Inner protocols that require packet losses as a signal of congestion (e.g. TCP) will have a challenge due to not being able to see any packet losses since the outer TCP will repair them (unless sending into a full outer TCP socket buffer shows up back to the inner TCP as a packet loss?). 2) Nesting of ECN -\u00a0 Inner TCP connections will not be able to use effectively ECN on the portion of the path covered by the outer TCP connection. 3) Impact of congestion response on aggregate - The general \"TCP in TCP\" problem is mentioned, and is mostly appropriate for a single flow.\u00a0 If an aggregate of flows is sharing the same outer TCP connection, there may be additional concerns about how the congestion response behavior impacts an aggregate of flows, since it may cause a shared delay spike even to low-rate flows rather than distributing losses proportional to per-flow throughput. 4) Additional potential for bufferbloat - Since TCP does not bound latency, some applications in the IPsec-protected aggregate could drive latency of the shared connection up and impact the aggregate of flows that may include real-time applications.\u00a0 The socket buffer for the outer TCP connection might need to be limited in size to ensure some bounds? Not addressing these could lead to poor experiences in deployment, if implementations make wrong assumptions or fail to consider them. In the security considerations section, there are several RFCs on mechanisms to increase robustness to RST attacks and SYN floods that could be mentioned if it's worthwhile.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-31 07:45:04-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-09 13:08:29-07:00",
    "text": "A few questions about the Security Considerations: (1) Section 11.\u00a0 I appreciate that this a framework document that is trying to be generic.\u00a0 Section 4 (and others) seem to lay out generic requirements.\u00a0 However, this Security Considerations section is both vague on the protocol choices (understandable) and the security services/properties they would have (the gap).\u00a0  For example, \u201cThe general security measures of the protocols SHOULD be used whenever applicable.\u201d and \u201cThe available security measures of the chosen protocol SHOULD be used to achieve a secured session between the two routers.\u201d\u00a0 Some discussion of what a \u201csecured session\u201d would look like would be helpful. (2) Section 11.\u00a0 What are the elements and enablers of \u201ca certain level of trust \u2026 [being] established between the routers for the protocols to run securely\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:59:29-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 08:12:03-08:00",
    "text": "I support Alvaro's DISCUSS point #2. I'm confused about what the registration policy is for metrics in the new registry. If it is Specification Required, then the places in the document that assume new metrics are defined in an RFC need to be generalized, because Specification Required need not involve any RFC at all. I have an additional concern about this text: \"If the proposed registry entry is defined in an RFC but is not yet \u00a0  widely deployed, there SHOULD be a statement in the RFC that says the \u00a0  proposed registry entry is not ready for registration, and use SHOULD \u00a0  employ a private/experimental ID.\u00a0 It is the responsibility of the \u00a0  document authors to submit the request to IANA when the proposed \u00a0  registry entry is ready for official registration.\" This appears to put a requirement on RFCs to include language that is not timeless and may later become out of date. That is, if this guidance is followed but a metric is later widely deployed, the RFC would have to be updated just to remove the text about the metric not being ready for registration. It seems better to just give guidance about which identifier range registration requests should target, and to give guidance to the designated experts about how to evaluate requests in different ranges.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-12-05 10:00:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 14:37:11-08:00",
    "text": "I have two separate issues that I would like to DISCUSS. (1) Approval of the initial performance metrics entries (in  draft-ietf-ippm-initial-registry ). This document describes the format of the registry, and the initial entries are defined in draft-ietf-ippm-initial-registry.\u00a0 However, the registration policy of Specification Required would not be met if the entries in  draft-ietf-ippm-initial-registry  are approved without expert review. As I mentioned in my ballot for  draft-ietf-ippm-initial-registry , I believe that because both documents are being processed at the same time, and the new entries have been reviewed by the WG, IESG Approval [ rfc8126 ] can be used.\u00a0  I can think of at least three ways to address this DISCUSS point (there may be others): a. Designated Experts for this document can be assigned and the formal review can be done. b. The text in this document can explicitly say that the entries in  draft-ietf-ippm-initial-registry  are to be approved using IESG Approval. c. The Responsible AD can add a Management Item to the Telechat for the IESG to explicitly approve (beyond approval for the publication of  draft-ietf-ippm-initial-registry ) the new entries. I am ok with either choice, but would prefer Option c because it would be faster and cause less churn. (2) \u00a78.1 (Adding new Performance Metrics to the Performance Metrics Registry) defines the following process for entries that are \"not yet widely deployed\": \u00a0  If the proposed registry entry is defined in an RFC but is not yet \u00a0  widely deployed, there SHOULD be a statement in the RFC that says the \u00a0  proposed registry entry is not ready for registration, and use SHOULD \u00a0  employ a private/experimental ID.\u00a0 It is the responsibility of the \u00a0  document authors to submit the request to IANA when the proposed \u00a0  registry entry is ready for official registration. Considering the Specification Required policy and the fact that the RFC has already gone through all the reviews required for publication (including expert review, as mentioned in the same section), how will it work for the \"authors to submit the request to IANA when the proposed registry entry is ready for official registration\"?\u00a0 What specification will be presented to IANA to satisfy the registration requirement?\u00a0  It seems to me that the statement mentioned above would prevent the official registration in the first place, and that same statement (still present in the RFC) should prevent a second review of the same document from resulting in an official registration. This process needs more discussion and clarity for it to work. [Not part of this DISCUSS point, but related.]\u00a0  a. Section 8 talks about instructions about handling of the registry.\u00a0 Perhaps it should be part of the IANA Considerations section. b. \u00a77.1.1 contains additional instructions for IANA, including the reservation of a private/experimental range of Identifiers.\u00a0 This test should also be part of the IANA Considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-07 11:38:54-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 14:26:04-08:00",
    "text": "The ABNF for linkparam (\u00a78.2) incorporates a \"langparam\" production, but that is not defined in any of this document,  RFC 5455 ,  RFC 8288 , or  RFC 7986 .\u00a0 We need to define it somehow, whether by reference or directly. RFC 5545  does define a LANGUAGE parameter (our prose references a \"LANG\" parameter) and languageparam ABNF production, which is perhaps the simplest explanation for what was intended.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-09-01 07:20:44-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-29 12:25:57-07:00",
    "text": "The description of what is added in this draft in the Security Considerations section is good, but aren't there additional security considerations (risks) with this addition? \u00a0 This document extends the LSP Ping and Traceroute mechanisms to \u00a0  discover and exercise ECMP paths when an LSP uses ELI/EL in the label \u00a0  stack.\u00a0 Additional processing is required for responder and initiator \u00a0  nodes.\u00a0 The responder node that pushes ELI/EL will need to compute \u00a0  and return multipath data including associated EL.\u00a0 The initiator \u00a0  node will need to store and handle both IP multipath and label \u00a0  multipath information, and include destination IP addresses and/or \u00a0  ELs in MPLS echo request packets as well as in multipath information \u00a0  sent to downstream nodes.  BTW, the above is a nice description that would have been nice to see sooner in the text. The draft then says:  This document does not itself introduce \u00a0  any new security considerations. Isn't there anything that should be said about risks with the extended capabilities to discover and exercise ECMP paths?\u00a0 Does this help network reconnaissance?\u00a0 Does it help attackers to have this additional information?\u00a0 If it doesn't, please explain why and that will clear up this discuss or adding text would be good.\u00a0 Thanks.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-08-10 07:39:27-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-22 19:11:54-07:00",
    "text": "The following text appears to have been added in -04 \u00a0  A server receiving a ClientHello and a client_version indicating \u00a0  (3,1) \"TLS 1.0\" or (3,2) \"TLS 1.1\" and any of the cipher suites from \u00a0  this document in ClientHello.cipher_suites can safely assume that the \u00a0  client supports TLS 1.2 and is willing to use it.\u00a0 The server MUST \u00a0  NOT negotiate these cipher suites with TLS protocol versions earlier \u00a0  than TLS 1.2.\u00a0 Not requiring clients to indicate their support for \u00a0  TLS 1.2 cipher suites exclusively through ClientHello.client_hello \u00a0  improves the interoperability in the installed base and use of TLS \u00a0  1.2 AEAD cipher suites without upsetting the installed base of \u00a0  version-intolerant TLS servers, results in more TLS handshakes \u00a0  succeeding and obviates fallback mechanisms. This is a major technical change from -03, which, AFAIK, prohibited the server from negotiating these algorithms with TLS 1.1 and below and maintained the usual TLS version 1.2 negotiation rules. This is a very material technical change. I don't consider it wise, but in any case it would absolutely need WG consensus, which I don't believe that it has given the recent introduction. The discussion of dictionary attacks here seems inferior to that in 4279. In particular, you only need to actively attack one connection to capture the data you need for a brute force attack despite the text there referring to trying \"different keys\". Please correct that.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2016-04-21 13:26:22-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-06 17:28:44-08:00",
    "text": "Changing to DISCUSS since I'd like to discuss the IPR situation with the IESG. I had thought re-confirming with the WG that they still wanted to progress the draft would be sufficient given the terms of the disclosure, but if folks think we need to do another IETF LC we should discuss. Also the WG's own discussion about the IPR is ongoing.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-06-02 07:54:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 10:07:27-07:00",
    "text": "As far as I can tell, CMP provides multiple optional levels of encryption and authentication to protect its messages and components of that message. However, I gather that the transport substrate is allowed to be HTTP without TLS. Given that, how does this protocol defend against version downgrade attacks? If an on-path attacker responds to a client message with an error message requiring an older version, do all configurations of CMP detect the intervention?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-10 11:42:31-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-05-31 14:56:50-07:00",
    "text": "As a reviewer, and therefor I suspect also implementors, needing to read current + old and then compare it to new is very confusing. If this is for a few paragraphs I can see the point but throughout the entire long document? It prevented me from doing a full review. The document also \u201cupdates\u201d the IANA Considerations which is not a real process we have. We only have new IANA Considerations and I don\u2019t think we should tell IANA to decode their instructions based on a diff with another rfc.  Please tell me how this document would not be simply better if the diffing and replacing is done for the reader by obsoleting the old documents and creating one new clear readable document? If the WG could not do this, how can we expect an implementer to do this ? This deliverable might have been good for the WG for tracking purposes but I don\u2019t think it works as an RFC for the intended target audience.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-29 14:31:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-10 11:42:31-07:00",
    "text": "As a reviewer, and therefor I suspect also implementors, needing to read current + old and then compare it to new is very confusing. If this is for a few paragraphs I can see the point but throughout the entire long document? It prevented me from doing a full review. The document also \u201cupdates\u201d the IANA Considerations which is not a real process we have. We only have new IANA Considerations and I don\u2019t think we should tell IANA to decode their instructions based on a diff with another rfc.  Please tell me how this document would not be simply better if the diffing and replacing is done for the reader by obsoleting the old documents and creating one new clear readable document? If the WG could not do this, how can we expect an implementer to do this ? This deliverable might have been good for the WG for tracking purposes but I don\u2019t think it works as an RFC for the intended target audience. UPDATE: I've completed my review of -21: #1: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This is a \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  very sensitive service and therefore needs specific \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  authorization.\u00a0 This authorization is with the CA \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  certificate itself.\u00a0 Alternatively, the CA MAY delegate the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  authorization by placing the id-kp-cmKGA extended key usage \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  in the certificate used to authenticate the origin of the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  generated private key or the delegation MAY be determined \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  through local configuration of the end entity. These two MAYs are related, you MUST do one or the other. The text as it can be interpreted to not perform either MAYs. #2 \u00a0  Such validity periods SHOULD \u00a0  NOT be used for protection of CMP messages and key generation. \u00a0  Certificates containing one of the above EKUs SHOULD NOT use \u00a0  indefinite expiration date. This leaves a rather unspecified part on the implementer. What time period is too much? Clearly something between a few seconds and indefinite, but what is it? Can this document make a recommendation ? #3  Throughout the document, Section references for the to-be-patched RFC are turned into links for this RFC, eg in the text \"Replace Section 5.1.3.4 - Multiple Protection\" in Section 2.6 where the section title has a bad link but the section body has the right link. Please verify all of these references and fix where needed. #4 \u00a0 \u00a0 \u00a0 It MAY \u00a0 \u00a0 \u00a0 include the original PKIMessage from the EE in the generalInfo \u00a0 \u00a0 \u00a0 field of PKIHeader of a nested message (to accommodate, for \u00a0 \u00a0 \u00a0 example, cases in which the CA wishes to check POP or other \u00a0 \u00a0 \u00a0 information on the original EE message). If a CA wishes to do so, it would REQUIRE this original PKIMessage. Would it not be better to say \"It MUST include the original PKIMessage\" ? It seems also generally better to send the originals along with the modification so that the next step can (optionally!) authenticate the previous step. Otherwise, there is a lot of implied trust that should be modeled in the Security Considerations.  #5 In Section 2.20, it talks abot updating 4210's Section 7. It suggests removing the first 3 paragraphs with replacement text. However, the text removed describes the behaviour in a version agnostic way that I think is more clear than the replacement text. \u00a0 \u00a0 \u00a0 If the client does not accept EnvelopedData, but EncryptedValue, \u00a0 \u00a0 \u00a0 then it MUST use cmp2000. Why not cmp1999? Because EncryptedValue is valid for cmp1999  RFC2510  as well? Are we assuming cmp1999 is completely dead and no longer deployed? In general I would clarify section 2.20 better. More clearly subdivide client and server, and leave a version of the text in Section 7 before section 7.1 intact. Also, it seems the into in the original Section 7 really covers the protocol behaviour. I am not sure why there are subsections with specific version numbers in 4210 nor do I understand why this has to be patched to an even more elaborate versioning, and mentioning EncryptedValue vs EncryptedEnvelope. It seems the section 7 overview covers all behaviour already. #6 Section 3.4 \"patches\" the IANA Considerations. I'd rather we didn't do this and add a clear new IANA Considerations section with clear complete instructions to IANA as to what changes to make, but I understand perhaps why to do this from a readability point of view. But at the very least leave a note to the RFC Editor to confirm all IANA Actions for this document are summarized in this document's IANA Considerations. \u00a0 \u00a0 < TBD: The temporary registration of cmp URI suffix must be updated \u00a0  from provisional to permanent. > IANA will do this when the document goes from draft to RFC. So this comment can safely be removed. \u00a0  < TBD: A new protocol registry group \"Certificate Management Protocol \u00a0  (CMP)\" (at  https://www.iana.org/assignments/cmp ) and an initial entry \u00a0  'p' must be registered. > Same here. Section 4 IANA Considerations should contain a copy of the \"patch\" instructions as a clear instruction to IANA so they can make the changes without them needing to \"patch\" the old RFC to obtain the instructions. Even if this sounds redundant in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-08-15 17:22:29-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 17:16:20-07:00",
    "text": "iven that you have a static key on the UA, the security considerationsshould discuss point verification, or why it's not needed.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-05-18 05:36:00-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 06:21:16-07:00",
    "text": "I would like to DISCUSS the following point. - From https:/ https://tools.ietf.org/html/draft-ietf-i2rs-pub-sub-requirements-06 , section 2.1 \u00a0 \u00a0 \u00a0  From [i2rs-arch], there are \u00a0 \u00a0 \u00a0  references throughout the document beginning in section 6.2.\u00a0 Some \u00a0 \u00a0 \u00a0  specific examples include: \u00a0 \u00a0 \u00a0  ...  \u00a0 \u00a0 \u00a0  o\u00a0 section 6.3 notes that when local config preempts I2RS, external \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 notification might be necessary What about the local configuration,  https://tools.ietf.org/html/draft-ietf-i2rs-architecture-15#section-6.3  ? Is this logged?  From the client address, it seems that local is not covered. Should it be? \u00a0  Client Address:\u00a0  This is the network address of the Client that \u00a0 \u00a0 \u00a0 connected to the Agent.\u00a0 For example, this may be an IPv4 or IPv6 \u00a0 \u00a0 \u00a0 address.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-05-15 06:39:19-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-04 09:43:26-07:00",
    "text": "Intro: I don't agree that all data retention aspects are out of scope here. They are about as in-scope as log rotation I'd say. I do think it'd be worthwhile noting that if log content contains sensitive data (either security- or privacy-sensitive) then retaining that data for extended durations has a cost, in terms of creating risks if data leaks. While one cannot say here how to evaluate such risks, they do exist and should really be noted. It would also be sensible IMO to say that implementations SHOULD provide a way to purge ancient log content that is no longer needed or useful, but that the definition of when content is no longer needed or useful is out of scope.\u00a0 In saying this I do recognise that much or perhaps even most i2rs log content will not be security or privacy sensitive, but in some cases it can be, e.g. if an operation involved an address that is specific to a user or device carried by a user. In addition, some data retention regimes could impose a requirement to purge log content after a certain duration. I'd say a note about this in the intro or in the security considerations should be a fine way to handle this issue, and to acknowledge that not all data retention issues are out of scope for implementations.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-07 06:35:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-26 20:44:08-07:00",
    "text": "I have grave concerns about the suitability of LISP as a whole, in its present form, for advancement to the Standards-Track.\u00a0 While some of my concerns are not specific to this document, as the core protocol (data-plane) spec, it seems an appropriate place to attach them to. I am told, out of band, that the intended deployment model is no longer to cover the entire Internet (c.f. the MISSREF-state draft-ietf-lisp-introduction 's \"with LISP, the dge of the Internet and the core can be logically separated and interconnected by LISP-capable routers\", etc.), and that full Internet-scale operation is no longer a goal.\u00a0 However, since that does not seem to be reflected in the current batch of documents up for IESG review, I am forced to ballot on them \"as-is\", namely as targetting global Internet deployment.\u00a0 The requirements placed on the mapping system are so stringent so as to be arguably unachievable at Internet-scale, though that arguably has more of an interaction with the control-plane than the data-plane.\u00a0 It's still in scope here, though, as part of the overall description of the protocol flow. There are an almost innumerable number of downgrade attacks possible, and the control-plane and data-plane security mechanisms are not normative dependencies of the current corpus of documents, and as such are not up for consideration as mitigating the security concerns with the core documents. Section 3 defines the EID-to-RLOC Datbaase: \u00a0  EID-to-RLOC Database:\u00a0  The EID-to-RLOC Database is a global \u00a0 \u00a0 \u00a0 distributed database that contains all known EID-Prefix-to-RLOC \u00a0 \u00a0 \u00a0 mappings.\u00a0 Each potential ETR typically contains a small piece of \u00a0 \u00a0 \u00a0 the database: the EID-to-RLOC mappings for the EID-Prefixes \u00a0 \u00a0 \u00a0 \"behind\" the router.\u00a0 These map to one of the router's own \u00a0 \u00a0 \u00a0 globally visible IP addresses.\u00a0 Note that there MAY be transient \u00a0 \u00a0 \u00a0 conditions when the EID-Prefix for the site and Locator-Set for \u00a0 \u00a0 \u00a0 each EID-Prefix may not be the same on all ETRs.\u00a0 This has no \u00a0 \u00a0 \u00a0 negative implications, since a partial set of Locators can be \u00a0 \u00a0 \u00a0 used. No compelling architecture for a trustworthy global distributed database has been presented that I've seen so far, and LISP relies heavily on the mapping system's database for its functionality.\u00a0 I am concerned that so many requirements are placed on the mapping system so as to be in effect unimplementable, in which case it would seem that the architecture as a whole (that is, for a global Internet-scale system) is not fit for purpose. Section 4.1's Step (6) only mentions parsing \"to check for format validity\".\u00a0 I think it is appropriate to mention (and refer to) source authentication checks as well, since bad Map-Reply data can allow all sorts of attacks to occur. There are some fairly subtle ordering requirements between the order of entries in Map-Reply messages and the Locator-Status-Bits in data-plane traffic (so that the semantic meaning of the status bits are meaningful), which is only given a minimal treatment in the control-plane document.\u00a0 The need for synchronization in interpreting these bits should be mentioned more prominently in the data-plane document as well. The usage of the Instance ID does not seem to be adequately covered; from what I've been able to pick up so far it seems that both source and destination participants must agree on the meaning of an Instance ID, and the source and destination EIDs must be in the same Instance.\u00a0 This does not seem like it is compatible with Internet scale, especially if there are only 24 usable bits of Instance ID. There seems to be a lot of intra-site synchronization requirements, notably with respect to Map-Version consistency, the contents and ordering of locator sets for EIDs in the site, etc.; the actual hard requirements for synchronization within a site should be clearly called out, ideally in a single location. The security considerations attempt to defer substantially to the threat-analysis in  RFC 7835 , which does not really seem like a complete threat analysis and does not provide analysis as to what requirements are placed on the boundaries between the different components of LISP (data plane, control plane, mapping system, various extensions, etc.).\u00a0 The secdir reviewer had some good thoughts in this space. The security considerations throughout the LISP documents place a heavy focus on the risk of over-claiming for routing EID-prefixes.\u00a0 This is a real concern, to be clear, but it should not overshadow the risk of an attacker who is able to move traffic around at will, strip security protections, cause denial of service, alter data-plane payloads, etc. Similarly, this document's security considerations call out denial of service as a risk from Map-Cache insertion/spoofing, but the risks from an attacker being able to read and modify the traffic, perhaps even without detection, seems a much greater threat to me. I am not convinced that this protocol meets the current IETF requirements for the security properties of Standards-Track Protocols without at least LISP-SEC as a mandatory-to-implement component, and possibly additional or stronger requirements.\u00a0 (I did not do a full analysis of the system in the presence of those security mechanisms, since that is not what is being presented for review.) Having an EID that is associated to user-correlatable devices has severe privacy considerations, but I could not find this mentioned anywhere in all of the LISP documents I've read so far.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-02 14:39:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-07 06:35:02-08:00",
    "text": "Section 3 still contains text: \u00a0  EID-to-RLOC Database:\u00a0  The EID-to-RLOC Database is a global \u00a0 \u00a0 \u00a0 distributed database that contains all known EID-Prefix-to-RLOC that indicates that the mapping database is a single, global, distributed database; we had previously agreed that the target scope was much more narrow.\u00a0 I could perhaps charitably assume that this instance was missed as an editing error because the phrase \"global distributed database\" spans a line break, but given that this specific instance was called out in my previous discuss position, it is fairly hard to do so. Also in Section 3: \u00a0  Endpoint ID (EID):\u00a0  An EID is a 32-bit (for IPv4) or 128-bit (for \u00a0 \u00a0 \u00a0 IPv6) value used in the source and destination address fields of \u00a0 \u00a0 \u00a0 the first (most inner) LISP header of a packet.\u00a0 [...] 6833bis says (section 5.8) that the inner header can use either RLOC or EID addresses in the header address fields, which contradicts this statement. The various places where we mention \"gleaming\" or similar unauthenticated (un-path-verified?) schemes for learning mapping information should all mention at their description that they are susceptible to spoofing and link to the security considerations. I'm still concerned about the synchronization requirements between map-version changes and LSB usage; with the currently described technology it seems almost inevitable for race conditions around RLOC changes to cause ITRs to make incorrect routing decisions due to misinterpreted status bits. It's unclear whether it's even worth trying to tackle this problem before the map-versioning document is more advanced along in the process, though. (Several comments throughout are relevant, especially those on Section 13.1.) I agree with Warren that clarity on whether traffic is buffered or dropped during the lookup process is needed (e.g., in Section 6). Also in the vein of Warren's comments, in Section 7.1 I was expecting (from our previous discussions) that some text would be added about the determination of L being something that is \"performed once by the administrator of the LISP deployment and treated as a constant across the deployment\". The discussion of Instance IDs remains incomplete, with no discussion of within what scope their values must be unique (as truncated to 24 bits). Similarly (also Section 8), \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Multiple \u00a0  Data-Planes can use the same 32-bit space as long as the low-order 24 \u00a0  bits don't overlap among xTRs. That's a pretty lousy property to have in a PS specification. Section 13 \u00a0  When a Locator record is removed from a Locator-Set, ITRs that have \u00a0  the mapping cached will not use the removed Locator because the xTRs \u00a0  will set the Locator-Status-Bit to 0.\u00a0 So, even if the Locator is in \u00a0  the list, it will not be used.\u00a0 For new mapping requests, the xTRs \u00a0  can set the Locator AFI to 0 (indicating an unspecified address), as \u00a0  well as setting the corresponding Locator-Status-Bit to 0.\u00a0 This I do not remember there being an ordering (or even consistency) requirement on the ITR-RLOC entries in the Map-Request, so it's unclear that just replacing one entry with an AFI-0 entry would convey this information.\u00a0 I suppose that using only a single ITR-RLOC entry, with AFI 0, would provide a usable signal to the ETR, but that does not seem to be what is being described here.\u00a0 (Also, on a rhetorical point, please clarify that the \"as well as\" is for setting the LSB to 0 in data packets; Map-Requests do not include any LSBs.) \u00a0  If many changes occur to a mapping over a long period of time, one \u00a0  will find empty record slots in the middle of the Locator-Set and new \u00a0  records appended to the Locator-Set. At some point, it would be \u00a0  useful to compact the Locator-Set so the Locator-Status-Bit settings \u00a0  can be efficiently packed. This text, implying that compactification must wait for some unspecified later event, seems to be assuming some requirement to preserve order of Locator-Set entries that I cannot find a description of in either 6830bis or 6833bis. Do RFCs 6831 and 8378 need to be normative references for how to do multicast as an optional protocol feature (recalling that https://www.ietf.org/blog/iesg-statement-normative-and-informative-references/ clarifies that references that are relevant only for optional features are still classified as normative)? In Section 16: \u00a0  A complete LISP threat analysis can be found in [ RFC7835 ].\u00a0 In what RFC 7835  remains an incomplete analysis; please stop referring to it as such. \u00a0  of time.\u00a0 The goal is to convince the ITR that the ETR's RLOC is \u00a0  reachable even when it may not be reachable.\u00a0 If the attack is I think Warren is correct that there is also an attack that lies in convincing an ITR that an ETR is not reachable even when it is reachable. The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. Section 4.1's Step (6) only mentions parsing \"to check for format validity\".\u00a0 I think it is appropriate to mention (and refer to) source authentication checks as well, since bad Map-Reply data can allow all sorts of attacks to occur. There are some fairly subtle ordering requirements between the order of entries in Map-Reply messages and the Locator-Status-Bits in data-plane traffic (so that the semantic meaning of the status bits are meaningful), which is only given a minimal treatment in the control-plane document.\u00a0 The need for synchronization in interpreting these bits should be mentioned more prominently in the data-plane document as well. The usage of the Instance ID does not seem to be adequately covered; from what I've been able to pick up so far it seems that both source and destination participants must agree on the meaning of an Instance ID, and the source and destination EIDs must be in the same Instance.\u00a0 This does not seem like it is compatible with Internet scale, especially if there are only 24 usable bits of Instance ID. There seems to be a lot of intra-site synchronization requirements, notably with respect to Map-Version consistency, the contents and ordering of locator sets for EIDs in the site, etc.; the actual hard requirements for synchronization within a site should be clearly called out, ideally in a single location. The security considerations attempt to defer substantially to the threat-analysis in  RFC 7835 , which does not really seem like a complete threat analysis and does not provide analysis as to what requirements are placed on the boundaries between the different components of LISP (data plane, control plane, mapping system, various extensions, etc.).\u00a0 The secdir reviewer had some good thoughts in this space. I am not convinced that this protocol meets the current IETF requirements for the security properties of Standards-Track Protocols without at least LISP-SEC as a mandatory-to-implement component, and possibly additional or stronger requirements.\u00a0 (I did not do a full analysis of the system in the presence of those security mechanisms, since that is not what is being presented for review.) [ed. even though LISP-SEC has been promoted to MTI, it remains difficult to be confident in the results of a full system analysis due to the number of other outstanding issues with the core documents.\u00a0 Consider the risk Ekr noted yesterday in email about tampering with the Map-Request causing apparently-valid repsonses that convey incorrect results with respect to the original query.]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-30 14:21:42-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-02 14:39:29-07:00",
    "text": "Updating for the -27 by removing points that are fully addressed but leaving points that I still want to have further discussion on.\u00a0 It may be most expedient to continue discussion on my -26 ballot thread. Please also note that the COMMENT section was entirely refreshed for the -26 and had a few additions as I read the -27. The various places where we mention \"gleaming\" or similar unauthenticated (un-path-verified?) schemes for learning mapping information should all mention at their description that they are susceptible to spoofing and link to the security considerations. [ed. I have noted offlist to the authors some specific locations] Section 13 \u00a0  When a Locator record is removed from a Locator-Set, ITRs that have \u00a0  the mapping cached will not use the removed Locator because the xTRs \u00a0  will set the Locator-Status-Bit to 0.\u00a0 So, even if the Locator is in \u00a0  the list, it will not be used.\u00a0 For new mapping requests, the xTRs \u00a0  can set the Locator AFI to 0 (indicating an unspecified address), as \u00a0  well as setting the corresponding Locator-Status-Bit to 0.\u00a0 This I do not remember there being an ordering (or even consistency) requirement on the ITR-RLOC entries in the Map-Request, so it's unclear that just replacing one entry with an AFI-0 entry would convey this information.\u00a0 I suppose that using only a single ITR-RLOC entry, with AFI 0, would provide a usable signal to the ETR, but that does not seem to be what is being described here.\u00a0 (Also, on a rhetorical point, please clarify that the \"as well as\" is for setting the LSB to 0 in data packets; Map-Requests do not include any LSBs.) \u00a0  If many changes occur to a mapping over a long period of time, one \u00a0  will find empty record slots in the middle of the Locator-Set and new \u00a0  records appended to the Locator-Set. At some point, it would be \u00a0  useful to compact the Locator-Set so the Locator-Status-Bit settings \u00a0  can be efficiently packed. This text, implying that compactification must wait for some unspecified later event, seems to be assuming some requirement to preserve order of Locator-Set entries that I cannot find a description of in either 6830bis or 6833bis. [ed. these previous two items are rather poorly described; another thread is ongoing to try to clarify both my concerns and how they might be addressed] I think Warren is correct that there is also an attack that lies in convincing an ITR that an ETR is not reachable even when it is reachable. The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. There are some fairly subtle ordering requirements between the order of entries in Map-Reply messages and the Locator-Status-Bits in data-plane traffic (so that the semantic meaning of the status bits are meaningful), which is only given a minimal treatment in the control-plane document.\u00a0 The need for synchronization in interpreting these bits should be mentioned more prominently in the data-plane document as well. The usage of the Instance ID does not seem to be adequately covered; from what I've been able to pick up so far it seems that both source and destination participants must agree on the meaning of an Instance ID, and the source and destination EIDs must be in the same Instance.\u00a0 This does not seem like it is compatible with Internet scale, especially if there are only 24 usable bits of Instance ID. There seems to be a lot of intra-site synchronization requirements, notably with respect to Map-Version consistency, the contents and ordering of locator sets for EIDs in the site, etc.; the actual hard requirements for synchronization within a site should be clearly called out, ideally in a single location. The security considerations attempt to defer substantially to the threat-analysis in  RFC 7835 , which does not really seem like a complete threat analysis and does not provide analysis as to what requirements are placed on the boundaries between the different components of LISP (data plane, control plane, mapping system, various extensions, etc.).\u00a0 The secdir reviewer had some good thoughts in this space. [We're getting closer to something that's possible to properly analyze, but I haven't done that analysis yet]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-12 21:12:13-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-30 14:21:42-08:00",
    "text": "Thank you for all the updates in the -28; we're making great progress! My ballot on the -26 included: % The usage of the Instance ID does not seem to be adequately covered; from % what I've been able to pick up so far it seems that both source and % destination participants must agree on the meaning of an Instance ID, and % the source and destination EIDs must be in the same Instance.\u00a0 This does % not seem like it is compatible with Internet scale, especially if there are % only 24 usable bits of Instance ID. The -28 now says that the whole LISP deployment has to agree on the meaning of Instance ID values (thank you!), but I'm still not entirely sure if the source and destination EIDs need to belong to the same Instance. If they do need to be in the same Instance, I think we should note that (but if not, then the current text should be fine as-is). My apologies if this was already covered and I just forgot. [Someone (me?) still owe some analysis on the security considerations at the boundaries of the various components in the ecosystem.\u00a0 Deborah putting this back on an IESG telechat as a returning item might be the most expedient way to get this to happen, sadly.]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-08 21:19:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-01-12 21:12:13-08:00",
    "text": "[Someone (me?) still owe some analysis on the security considerations at the boundaries of the various components in the ecosystem.\u00a0 Deborah putting this back on an IESG telechat as a returning item might be the most expedient way to get this to happen, sadly.]",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-27 05:17:56-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3126 See my DISCUSS on 6833bis for overall issues. This is just detailed issues on 6830bis as I went through it. DETAIL S 4.1. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 RLOC (outer-header source IP address) in a received LISP packet. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Such a cache entry is termed a \"glean mapping\" and only contains >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 a single RLOC for the EID in question.\u00a0 More complete information >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 about additional RLOCs SHOULD be verified by sending a LISP Map- >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Request for that EID.\u00a0 Both the ITR and the ETR MAY also >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 influence the decision the other makes in selecting an RLOC. This seems like it introduces an immediate overclaiming problem. S 10. >\u00a0 \u00a0 \u00a0 When an ETR decapsulates a packet, it will check for any change in >\u00a0 \u00a0 \u00a0 the 'Locator-Status-Bits' field.\u00a0 When a bit goes from 1 to 0, the >\u00a0 \u00a0 \u00a0 ETR, if acting also as an ITR, will refrain from encapsulating >\u00a0 \u00a0 \u00a0 packets to an RLOC that is indicated as down.\u00a0 It will only resume >\u00a0 \u00a0 \u00a0 using that RLOC if the corresponding Locator-Status-Bit returns to a >\u00a0 \u00a0 \u00a0 value of 1.\u00a0 Locator-Status-Bits are associated with a Locator-Set This seems to enable a pretty obvious denial of service attack in which you send\u00a0 a message with all LSBs set to 0. S 10. >\u00a0 \u00a0 \u00a0 list returned by the last Map-Reply will be set to zero for that >\u00a0 \u00a0 \u00a0 particular EID-Prefix.\u00a0 Refer to Section 16 for security related >\u00a0 \u00a0 \u00a0 issues regarding Locator-Status-Bits. >\u00a0   >\u00a0 \u00a0 \u00a0 When an ETR decapsulates a packet, it knows that it is reachable from >\u00a0 \u00a0 \u00a0 the encapsulating ITR because that is how the packet arrived.\u00a0 In It doesn't even know this. It just knows that that's been claimed by someone who can generate traffic to it. S 10.1. >\u00a0 \u00a0 \u00a0 NOT use the lack of return traffic as an indication that the ETR is >\u00a0 \u00a0 \u00a0 unreachable.\u00a0 Instead, it MUST use an alternate mechanism to >\u00a0 \u00a0 \u00a0 determine reachability. >\u00a0   >\u00a0  10.1.\u00a0 Echo Nonce Algorithm >\u00a0   This mechanism seems sufficient to verify unreachability but is not a secure test of reachability because the nonce is way too short. S 16. >\u00a0 \u00a0 \u00a0 Map-Versioning is a Data-Plane mechanism used to signal a peering xTR >\u00a0 \u00a0 \u00a0 that a local EID-to-RLOC mapping has been updated, so that the >\u00a0 \u00a0 \u00a0 peering xTR uses LISP Control-Plane signaling message to retrieve a >\u00a0 \u00a0 \u00a0 fresh mapping.\u00a0 This can be used by an attacker to forge the map- >\u00a0 \u00a0 \u00a0 versioning field of a LISP encapsulated header and force an excessive >\u00a0 \u00a0 \u00a0 amount of signaling between xTRs that may overload them. Can't I also set a super-high version number, thus gagging updates?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-11-29 16:30:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-08 22:28:46-07:00",
    "text": "[ section 8 ] * I think the currently architecture of IPv6 is such that at a minimum this \u00a0 doc should say that instances SHOULD NOT be used when the inner traffic is \u00a0 IPv6 as overlapping IPv6 prefixes are best and fairly easily avoided and \u00a0 folks should be encouraged to avoid recreating some of the limitations that \u00a0 were unavoidable in IPv4. [ section 12 ] * When the outer header is IPv6, the flow label may also be set a la  RFC 6438 . * When the inner header is IPv6, the flow label may also be a factor in the \u00a0 hashing (6348, if the flow label is non-zero a la 6437). [ section 16 ] * Is it worth adding an extra warning about gleaning mappings for EIDs that \u00a0 the ETR would otherwise have routed internally via the IGP? * In addition to basic uRPF, can an ETR do LISP-specific uRPF, i.e. look up \u00a0 the source EID in the mapping system and check that the source RLOC is within \u00a0 the set returned?\u00a0 If so, the document might mention it.\u00a0 If not, it might \u00a0 be good state explicitly that LISP does not afford this kind of uRPF check.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:03:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:02:50-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. While I fully support xTRs sending and processing ICMP packets, they don't always work in the public internet due to ICMP black holes and the like.  https://datatracker.ietf.org/doc/draft-ietf-tsvwg-datagram-plpmtud/ , which is the RFC Editor queue, would be a more reliable way to determine the Path MTU. Regrettably, the LISP data plane doesn't have a method to pad or otherwise modify the size of its packets besides IP fragmentation, nor to acknowledge those packets beyond the insecure Nonce. It would be best if the ITRs and ETRs had some sort of reliable way to send and acknowledge packets to each other of variable size. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither. - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:04:31-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:03:35-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. While I fully support xTRs sending and processing ICMP packets, they don't always work in the public internet due to ICMP black holes and the like.  https://datatracker.ietf.org/doc/draft-ietf-tsvwg-datagram-plpmtud/ , which is the RFC Editor queue, would be a more reliable way to determine the Path MTU. Regrettably, the LISP data plane doesn't have a method to pad or otherwise modify the size of its packets besides IP fragmentation, nor to acknowledge those packets beyond the insecure Nonce. It would be best if the ITRs and ETRs had some sort of reliable way to send and acknowledge packets to each other of variable size. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither. - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:05:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:04:31-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither. - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:05:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:05:02-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither? - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-12 09:55:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:05:38-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither? - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-09-09 15:02:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 09:55:24-07:00",
    "text": "Thanks for the adding the \u201cpublic internet\u201d explanation and clarifying how multipath routing works. Remaking Discuss issues:  Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither? - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-11 03:29:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-10 09:01:45-07:00",
    "text": "Unfortunately ECN decapsulation is slightly more complicated than described in section 5.3. Please check section 3.2 in  rfc6040  and revise accordingly (maybe also provide a pointer to  rfc6040  instead or in addition to  rfc3168 )! (Also it seems like the text on ECN is simply just twice in sec 5.3; not sure that is helpful). Further, also in sec 5.3: \"The inner-header 'Differentiated Services Code Point' (DSCP) field \u00a0 \u00a0 \u00a0 (or the 'Traffic Class' field, in the case of IPv6) SHOULD be \u00a0 \u00a0 \u00a0 copied from the outer-header DSCP field ('Traffic Class' field, in \u00a0 \u00a0 \u00a0 the case of IPv6) considering the exception listed below.\" However, I didn't find any exception listed. However seeting the DSCP field might also be matter of local policy. E.g. if DSCP is not used for a different purposed in the receiver side lisp network, it could make sense to restore/keep the orginial value in the inner header. Sec 7.1. only takes about ICMPv6 \"Packet Too Big\" packets while \"IPv4-encapsulated packet with the DF bit set to 1\" should be addressed as well. I would like to see another need in section 12 explicitly stating that the source port SHOULD be the same for all packet belong to the same flow.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-11 08:17:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-11 03:29:03-07:00",
    "text": "Unfortunately ECN decapsulation is slightly more complicated than described in section 5.3. Please check section 3.2 in  rfc6040  and revise accordingly (maybe also provide a pointer to  rfc6040  instead or in addition to  rfc3168 )! (Also it seems like the text on ECN is simply just twice in sec 5.3; not sure that is helpful). Further, also in sec 5.3: \"The inner-header 'Differentiated Services Code Point' (DSCP) field \u00a0 \u00a0 \u00a0 (or the 'Traffic Class' field, in the case of IPv6) SHOULD be \u00a0 \u00a0 \u00a0 copied from the outer-header DSCP field ('Traffic Class' field, in \u00a0 \u00a0 \u00a0 the case of IPv6) considering the exception listed below.\" However, I didn't find any exception listed. However seeting the DSCP field might also be matter of local policy. E.g. if DSCP is not used for a different purposed in the receiver side lisp network, it could make sense to restore/keep the orginial value in the inner header. Sec 7.1. only takes about ICMPv6 \"Packet Too Big\" packets while \"IPv4-encapsulated packet with the DF bit set to 1\" should be addressed as well. I would like to see another need in section 12 explicitly stating that the source port SHOULD be the same for all packet belong to the same flow. Sec 5.3 says \"Both N- and V-bits MUST NOT be set in the same packet.\" What happens if both bits are set? The 'Nonce/Map-Version' is just ignored, or maybe the packet should be dropped or something? Please clarify in the doc!",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-11 08:17:28-07:00",
    "text": "I have a couple of smaller discuss points with should be straight-forward to address and one more high-level discussion point that might not have a solution (depending on the deployment status of LISP I guess) but I would like to at least have a discussion. I start with the straight-forward onces: 1) Unfortunately ECN decapsulation is slightly more complicated than described in section 5.3. Please check section 3.2 in  rfc6040  and revise accordingly (maybe also provide a pointer to  rfc6040  instead or in addition to  rfc3168 )! (Also it seems like the text on ECN is simply just twice in sec 5.3; not sure that is helpful). 2) Further, also in sec 5.3: \"The inner-header 'Differentiated Services Code Point' (DSCP) field \u00a0 \u00a0 \u00a0 (or the 'Traffic Class' field, in the case of IPv6) SHOULD be \u00a0 \u00a0 \u00a0 copied from the outer-header DSCP field ('Traffic Class' field, in \u00a0 \u00a0 \u00a0 the case of IPv6) considering the exception listed below.\" However, I didn't find any exceptions listed later in the doc. However, setting the DSCP field might also be matter of local policy. E.g. if DSCP is not used for a different purpose in the receiver side LISP network, it could make sense to restore/keep the original value in the inner header. 3) Sec 7.1. only takes about ICMPv6 \"Packet Too Big\" packets while \"IPv4-encapsulated packet with the DF bit set to 1\" should be addressed as well. 4) I would like to see another sentence in section 12 explicitly stating that the source port SHOULD be the same for all packet belong to the same flow. 5) Sec 5.3 says \"Both N- and V-bits MUST NOT be set in the same packet.\" What happens if both bits are set? The 'Nonce/Map-Version' is just ignored, or maybe the packet should be dropped or something? Please clarify in the doc! 6) And now the more-discussion-needed point: So my underlying concern is the same as brought up by the TSV-ART review that lisp information are not end-to-end integrity protected or authenticated. However, while briefly thinking about how this could be eventually realized, I noticed that there is actually no mechanism to extend the LISP header in any way. There is no version, no option and the LISP header seems to have a fixed, implicitly specified length without an explicit length field. This seems too late to add any kind of extensibility mechanism at this stage of the protocols lifetime, however, I would still like to discuss if there was any discussion about extensibility, what was the reason to chose this approach, and potential if some background about the choice should be given in the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:30:52-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-07 15:03:28-07:00",
    "text": "** Section 1.1. The applicability statement of \u201clarge set of cooperating entities seeking to communicate over the public Internet or other large underlay IP infrastructures\u201d seems inconsistent with many of the protocol mechanics described.\u00a0 Specifically, most of the capabilities in the LISP header (Locator-Status-Bits, Echo-nonce mechanism, Map-Versioning, Instance ID) and the \u201cGleaning mechanism\u201d are explicitly noted as not being suitable for Internet use.\u00a0 This section needs to be explicit that only a subset of the protocol is suitable for the Internet.\u00a0 Likewise, it should be clearer about what is assumed elements of the closed network are trusted for what particular behaviors. ** Section 16. Per \u201cLocator-Status-Bits, echo-nonce and map-versioning SHOULD NOT be used over the public Internet and SHOULD only be used in trusted and closed deployments\u201d -- not disagreement.\u00a0 However, under what circumstances would they be used on the internet to warrant a SHOULD NOT instead of a stronger MUST NOT? ** Section 8.\u00a0 Per \u201cParticipants within a LISP deployment must agree on the meaning of Instance ID values.\u00a0 The source and destination EIDs MUST belong to the same Instance ID.\u201d\u00a0 Could parties agree that the Instance ID is 802.1Q tags and send those across the internet?\u00a0 Recommend stronger cautionary language on using Instance ID.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-11-18 13:24:23-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-18 06:30:52-07:00",
    "text": "** Section 8.\u00a0 Per \u201cParticipants within a LISP deployment must agree on the meaning of Instance ID values.\u00a0 The source and destination EIDs MUST belong to the same Instance ID.\u201d\u00a0 Could parties agree that the Instance ID is 802.1Q tags and send those across the internet?\u00a0 Recommend stronger cautionary language on using Instance ID.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-10-01 19:44:22-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 22:28:02-07:00",
    "text": "* Section 7.1.  This should be an easy fix but I would like to see it fixed before publication. When talking about IPv6 packets being larger than L, the correct behavior should be to send an ICMPv6 message with Type 2 (Packet Too Big) instead of the Destination Unreachable (Type 1) message as specified in the text. The text *is correct* for IPv4 messages with the DF bit set where the Destination Unreachable (Type 3) is the right kind of message to send.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-06-17 16:56:32-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-05 18:21:49-08:00",
    "text": "I read much of this on a plane while overtired, so it is entirely possible / probable that I've completely misunderstood something(s) obvious. Many of the below are probably simple to address, and either I simply need to be educated, or just there needs to be a bit more text / detail provided.  1: \"3.\u00a0 The ITR sends a LISP Map-Request as specified in [ I-D.ietf-lisp-rfc6833bis ].\u00a0 Map-Requests SHOULD be rate-limited.\" What does the ITR do with the packet while waiting for the Map-Request to complete? Must it buffer the packets or can it discard them? If the former, for how long must it buffer? When you say \"SHOULD be rate-limited\", can you provide guidance on rates? 1 request per second? 1 million per second? Is this rate-limit per destination or per device?  Apologies if this is clearly stated in  RFC6833 (bis) - I only skimmed it, and didn't see an answer there.  2: \"6. ... Note that the Map-Cache is an on-demand cache. An ITR will manage its Map-Cache in such a way that optimizes for its resource constraints.\" Presumably I could cause this cache to thrash / overflow by looking at the RLOC database, and choosing EIDs to send traffic to which all require different cache entries, causing the cache to overflow (or, at least, causing maximum cache pressure). This seems like an ideal DoS vector. It seems that there should be more guidance provided on how to size the Map-Cache / the expected order of the cache size, even if it is ultimately an implementation issue (e.g: is a Map-Cache of 100 entries OK for an ITR? or should it be O(1000)? Or roughly size(database)/2? Having multiple devices with small caches, and a bot which does the above seems like a global risk). I'm quite confused by much of the MTU / Fragmentation stuff -- I did read the documents on a plane after not getting much sleep, and so it is entirely possible / probable that I'm just being stupid, but there are bits which don't seem to make sense to me. 3: \"2.\u00a0 Define L to be the size, in octets, of the maximum-sized packet an ITR can send to an ETR without the need for the ITR or any intermediate routers to fragment the packet.\" How do I know what L is? The document \"RECOMMENDS that L be defined as 1500\" -- but 1500 isn't universally true (if it were, we would never have to do Path MTU). What happens when the *actual* MTU on the path is e.g 1476 because there is a tunnel on the path?  The text also mentions \"which is less than the ITR\u2019s estimate of the path MTU between the ITR and its correspondent ETR\" - this implies that the ITR is tracking / estimating the MTU, which a: doesn't align with the rest of the text, or b: sounds like the stateful solution below. I have reread this multiple times, but it still feels like it is avoiding the issue by defining it to not exist. 4: \"Note that reassembly can happen at the ETR if the encapsulated packet was fragmented at or after the ITR.\" - I think that there needs to be more text / description about resource constraints on routers performing reassembly of fragments - in most cases a router doesn't have to / isn't expected to have to reassemble transit packets from arbitrary sources on the Internet (things where routers may reassemble are aimed at the control plane which can be rate-limited, or are from expected source addresses). It seems that spoofing lots of initial fragments without the final one will be a tax on the router.  5: \"Instead of using the Map-Cache or mapping system, RLOC information MAY be gleaned from received tunneled packets or Map-Request messages. A \"gleaned\" Map-Cache entry, one learned from the source RLOC of a received encapsulated packet, is only stored and used for a few seconds, pending verification.\" - it seems that this is ripe for abuse (or I'm missing in the cache expiration). I want to hijack traffic from Site X to well known Service Y, so I look up Service Y and save the TTL from the Map-Reply. I then start spoof packets listing myself as the ETR - eventually Site X will glean from my spoofed packets, and start sending traffic to me - yes, this will only work for a few seconds -- but as soon as I stop getting packets from site X, I know site X has verified the entry and discovered it is wrong... and that the TTL is now being deprecated. I start a timer, and second or two less than the TTL later I start spoofing packets again, knowing that site X will soon expire the cache entry and will once again be willing to accept mine again. A: I get some Site X to Site Y traffic for a few seconds every TTL seconds, and B: the loss of this traffic is a signal that TTL seconds again it will need to be refreshed.   6: \"10.1.\u00a0 Echo Nonce Algorithm\" -- If I spoof lots of packets with the N- and E-bits set, the receiving ETR will need to keep false state, and presumably I can overfill a cache. This will cause the ETR to not be able to include the received nonce on legitimate traffic, and so the ITR on the far side will think this ETR is down. This seems like a fairly easy DoS. I'm guessing that this can be worked around by not setting the E bit in the RLOC-probe Map-Reply message, but this feels like a dangerous foot gun, and should at least be noted. Note that this is different to the \"Note the attacker must guess a valid nonce the ITR is requesting to be echoed within a small window of time.\u00a0 The goal is to convince the ITR that the ETR\u2019s RLOC is\u00a0 reachable even when it may not be reachable.\"\u00a0 attack listed in the document in that a: it doesn't require any guessing, and b: makes an ETR appear down, not up.  The document does mention \"... attack can be mitigated by preventing RLOC spoofing in the network by deploying uRPF  BCP 38  [ RFC2827 ].\" - while that may be true for many of the above,  BCP38  is far from being universally deployed, and this feels similar to solving world hunger by saying everyone must have enough food. :-) Again, apologies if I've completely misunderstood something, clue-bat gladly accepted...",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-08-17 15:53:02-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-16 16:04:48-07:00",
    "text": "Section 5.4 says: \u00a0  NOTE: A new DTLS association can be established based on changes in \u00a0  either an SDP offer or answer.\u00a0 When communicating with legacy \u00a0  endpoints, an offerer can receive an answer that includes the same \u00a0  fingerprint set and setup role.\u00a0 A new DTLS association MUST still be \u00a0  established if such an answer was received as a response to an offer \u00a0  which requested the establishment of a new DTLS association. Unless I've misunderstood something important, this isn't going to work with legacy implementations, unless you also specify that an \"offer which requested the establishment of a new DTLS association\" must also change something else that the legacy answerer will recognize as requiring a new DTLS association. For example, if I send a re-offer with a changed tls-id but the same fingerprint, setup, and transport, the far end will have no reason to think it needs to establish a new DTLS association. So I'll sit there waiting for a new association to be established, and the remote side will never send one. This doesn't seem backwards-compatible. At the very least, more text needs to be added explaining how this is intended to work.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-31 04:00:56-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-14 03:09:50-07:00",
    "text": "This is a fine document, but I have one [hopefully easy to answer] question and a couple of other minor ones: In Section 5.1.\u00a0 General \u00a0  Endpoints MUST support the cipher suites as defined in [ RFC8122 ]. I don't see any ciphers specified in that RFC. Can you clarify what you mean?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-10-27 12:10:50-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 16:06:59-07:00",
    "text": "1. Assuming I understand this document correctly, it conflicts with the guidance in JSEP. Specifically, S 4 says: \u00a0  No default value is defined for the SDP 'tls-id' attribute. \u00a0  Implementations that wish to use the attribute MUST explicitly \u00a0  include it in SDP offers and answers.\u00a0 If an offer or answer does not \u00a0  contain a 'tls-id' attribute (this could happen if the offerer or \u00a0  answerer represents an existing implementation that has not been \u00a0  updated to support the 'tls-id' attribute), unless there is another \u00a0  mechanism to explicitly indicate that a new DTLS association is to be \u00a0  established, a modification of one or more of the following \u00a0  characteristics MUST be treated as an indication that an endpoint \u00a0  wants to establish a new DTLS association: \u00a0  o\u00a0 DTLS setup role; or \u00a0  o\u00a0 fingerprint set; or \u00a0  o\u00a0 local transport parameters; or \u00a0  o\u00a0 ICE ufrag value This seems to say that if there is no tls-id attribute, then an ICE restart (which necessitates a ufrag change) requires a DTLS restart. JSEP isn't incredibly clear on this point, but 5.7.3 seems to say that tls-id neeed not be present: \u00a0 \u00a0 \u00a0 *\u00a0 tls-id value, which MUST be set according to \u00a0 \u00a0 \u00a0 \u00a0  [ I-D.ietf-mmusic-dtls-sdp ], Section 5.\u00a0 If this is a re-offer \u00a0 \u00a0 \u00a0 \u00a0  and the tls-id value is different from that presently in use, \u00a0 \u00a0 \u00a0 \u00a0  the DTLS connection is not being continued and the remote \u00a0 \u00a0 \u00a0 \u00a0  description MUST be part of an ICE restart, together with new \u00a0 \u00a0 \u00a0 \u00a0  ufrag and password values.\u00a0 If this is an answer, the tls-id \u00a0 \u00a0 \u00a0 \u00a0  value, if present, MUST be the same as in the offer. I believe that the first sentence is in error, as we clearly can't have JSEP implementations requiring that tls-id be present. \u00a0  ... \u00a0   \u00a0  o\u00a0 If the remote DTLS fingerprint has been changed or the tls-id has \u00a0 \u00a0 \u00a0 changed, tear down the DTLS connection.\u00a0 This includes the case \u00a0 \u00a0 \u00a0 when the PeerConnection state is \"have-remote-pranswer\".\u00a0 If a \u00a0 \u00a0 \u00a0 DTLS connection needs to be torn down but the answer does not \u00a0 \u00a0 \u00a0 indicate an ICE restart or, in the case of \"have-remote-pranswer\", \u00a0 \u00a0 \u00a0 new ICE credentials, an error MUST be generated.\u00a0 If an ICE \u00a0 \u00a0 \u00a0 restart is performed without a change in tls-id or fingerprint, \u00a0 \u00a0 \u00a0 then the same DTLS connection is continued over the new ICE \u00a0 \u00a0 \u00a0 channel. \u00a0 \u00a0 \u00a0  I think the best interpretation of this is that if tls-id is not present (and hence unchanged) then ICE restart does not cause DTLS restart. This is also my memory of the consensus in RTCWEB. In any case, these two documents clearly must match. 2. S 4 says: \u00a0  The mux category [ I-D.ietf-mmusic-sdp-mux-attributes ] for the 'tls- \u00a0  id' attribute is 'IDENTICAL', which means that the attribute value \u00a0  must be identical across all media descriptions being multiplexed \u00a0  [ I-D.ietf-mmusic-sdp-bundle-negotiation ]. This is not actually what JSEP requires: \u00a0  different categories.\u00a0 To avoid unnecessary duplication when \u00a0  bundling, attributes of category IDENTICAL or TRANSPORT MUST NOT be \u00a0  repeated in bundled m= sections, repeating the guidance from \u00a0  [ I-D.ietf-mmusic-sdp-bundle-negotiation ], Section 8.1.\u00a0 This includes I suspect this is old text. 3. S 7.1 says: \u00a0  If DTLS is transported on top of a connection-oriented transport \u00a0  protocol (e.g., TCP or SCTP), where all IP packets are acknowledged, This is incorrect, because none of these protocols ack all IP packets. \u00a0  all DTLS packets associated with a previous DTLS association MUST be \u00a0  acknowledged (or timed out) before a new DTLS association can be \u00a0  established on the same instance of that transport (5-tuple). More generally, I'm not sure that this is useful, because the required semantic isn't *acknowledged* but rather that the receiver can appropriately demux. So, say you just stop sending DTLS on connection A and start sending on B, what's the delimiter, given that you don't require close_notify here? IIRC, we just decided to punt on this whole thing. Does anyone try to have successive connections over the same transport, even when it's connection oriented? 4. The demux instructions seem to have gotten lost from 6.7.1. At minimum these need a reference to  RFC 7983 .",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-08-15 07:47:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-15 07:37:23-07:00",
    "text": "This is nothing big and should be easy to fix: On section 7.1, of course... \"If DTLS is transported on top of a connection-oriented transport \u00a0  protocol (e.g., TCP or SCTP), where all IP packets are acknowledged, \u00a0  all DTLS packets associated with a previous DTLS association MUST be \u00a0  acknowledged (or timed out) before a new DTLS association can be \u00a0  established on the same instance of that transport (5-tuple).\" I don't think this would be nessecary for QUIC. The point here is, I believe, not the fact that TCP and SCTP are connection-oriented, but that re-transmissions cannot be easily distinguished from the original packets. So the point is rather the use of a reliable protocol that retransmits in a specific way. However, why would you use DTLS with TCP instead of TLS? And I also don't think you want to use DTLS with QUIC because it has it's own crypto. I guess the recommendation should rather be that reliable transports should use TLS, and if DTLS is needed a new DTLS connection can only be established if there is not retransmission ambiguity which is always the case when all outstanding packets are ack'ed or considered lost (timed out).\u00a0 Or am I missing the point?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-05 05:34:59-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 07:47:15-07:00",
    "text": "This is nothing big and should be easy to fix: On section 7.1, of course... \"If DTLS is transported on top of a connection-oriented transport \u00a0  protocol (e.g., TCP or SCTP), where all IP packets are acknowledged, \u00a0  all DTLS packets associated with a previous DTLS association MUST be \u00a0  acknowledged (or timed out) before a new DTLS association can be \u00a0  established on the same instance of that transport (5-tuple).\" I don't think this would be necessary for QUIC. The point here is, I believe, not the fact that TCP and SCTP are connection-oriented, but that re-transmissions cannot be easily distinguished from the original packet. So the point is rather the use of a reliable protocol that retransmits in a specific way. However, why would you use DTLS with TCP instead of TLS? And I also don't think you want to use DTLS with QUIC because it has it's own crypto. I guess the recommendation should rather be that reliable transports should use TLS, and if DTLS is needed a new DTLS connection can only be established if there is not retransmission ambiguity which is always the case when all outstanding packets are ack'ed or considered lost (timed out).\u00a0 Or am I missing the point?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-03-02 07:25:26-08:00",
    "end_reason": "position_updated",
    "start": "2017-03-01 07:11:14-08:00",
    "text": "What is the motivation behind specifying the r-component syntax at this point and then recommending against its use until further standardization is complete? Why not specify the syntax when those future standards get written? The current approach just seems like an invitation for people to start including r-components in URNs without independent implementations understanding their semantics.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-05 07:53:15-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-06 11:31:27-07:00",
    "text": "The IANA considerations section does not seem to stand alone without reading  RFC 5204 . As you are obsoleting  RFC 5204 , readers shouldn't be expected to read it in order to discover original IANA instructions. I think you should copy information from  RFC 5204 .",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-23 15:15:08-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 23:03:58-07:00",
    "text": "Thanks to everyone who has worked on documenting the TACACS+ protocol as it is used today. I understand the desire to publish this document as a status other than Historic, as the protocol remains in use today. However, the shortcomings cited in the \"Security Considerations\" section are quite profound, and really bear highlighting in the document way before we get into what is fundamentally end material. I have serious misgivings about publishing this document as anything other than Historic without some prominent text early in the document (e.g., in the Introduction section) that warns implementors of the several caveats detailed in section 10 and its subsections. They don't need to be explained here, but some language along the lines of the following really needs to be present in order to scope the document: \u00a0  Note that the original TACACS+ implementations did not address all of the \u00a0  baseline security concerns which are considered when designing modern \u00a0  protocols.\u00a0 This document does not change this situation, and implementors \u00a0  should use caution when evaluating the suitability of TACACS+ for any given \u00a0  use.\u00a0 Please see section 10 for additional details. --------------------------------------------------------------------------- \u00a74.6: >\u00a0 To ensure interoperability of current deployments, the TACACS+ client >\u00a0 and server MUST handle user fields and those data fields used for >\u00a0 passwords as 8-bit octet strings.\u00a0 The deployment operator MUST >\u00a0 ensure that consistent character encoding is applied from the end >\u00a0 client to the server.\u00a0 The encoding SHOULD be UTF-8, and other >\u00a0 encodings outside printable US-ASCII SHOULD be deprecated. Without specification of preparation profiles for usernames and passwords, this is an incomplete specification of how to transmit non-ASCII usernames and passwords. While there are other solutions, the easy way to address this is to normatively reference  RFC 7613 , and select one of its username preparation profiles, and indicate its password preparation profile. The most basic problem here is that I might create a username and/or password on a machine that uses one mapping for a non-ASCII character, and later try to log in on a machine that uses a different, but semantically equivalent, mapping for that same character. This is a clear interop issue.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-15 23:20:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-15 11:48:29-07:00",
    "text": "I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) 4.6.\u00a0 Text Encoding \u00a0  All text fields in TACACS+ MUST be printable US-ASCII, excepting Please add a reference to  RFC 20  (for US-ASCII) here. Without out it \"printable\" has no meaning. \u00a0  special consideration given to user field and data fields used for \u00a0  passwords. \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0  client to the server.\u00a0 The encoding SHOULD be UTF-8, and other Please add Normative  RFC 3629  reference here for UTF-8. \u00a0  encodings outside printable US-ASCII SHOULD be deprecated. I am not sure what this mean. You didn't define allowed encoding (really you mean charsets). 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-16 10:26:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-15 23:20:57-07:00",
    "text": "(One small addition to my earlier comments, see new DISCUSS point 6) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) 4.6.\u00a0 Text Encoding \u00a0  All text fields in TACACS+ MUST be printable US-ASCII, excepting Please add a reference to  RFC 20  (for US-ASCII) here. Without out it \"printable\" has no meaning. \u00a0  special consideration given to user field and data fields used for \u00a0  passwords. \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0  client to the server.\u00a0 The encoding SHOULD be UTF-8, and other Please add Normative  RFC 3629  reference here for UTF-8. \u00a0  encodings outside printable US-ASCII SHOULD be deprecated. I am not sure what this mean. You didn't define allowed encoding (really you mean charsets). 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-17 12:10:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-16 10:26:50-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) 4.6.\u00a0 Text Encoding \u00a0  All text fields in TACACS+ MUST be printable US-ASCII, excepting Please add a reference to  RFC 20  (for US-ASCII) here. Without out it \"printable\" has no meaning. \u00a0  special consideration given to user field and data fields used for \u00a0  passwords. \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0  client to the server.\u00a0 The encoding SHOULD be UTF-8, and other Please add Normative  RFC 3629  reference here for UTF-8. \u00a0  encodings outside printable US-ASCII SHOULD be deprecated. I am not sure what this mean. You didn't define allowed encoding (really you mean charsets). 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. 8) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. 9) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-18 03:37:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-17 12:10:33-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) Resolved 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. 8) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. 9) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-18 04:17:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-18 03:37:37-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) Resolved 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Addressed 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. 8) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. 9) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-18 06:28:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-18 04:17:26-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) Resolved 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Addressed 4) Addressed 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) Addressed 8) Addressed 9) Addressed",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-19 08:24:34-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-18 06:28:46-07:00",
    "text": "hank you for addressing most of my DISCUSS/comments. Only one little thing remains:KRB5 and KRB4 need normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-05-16 10:29:18-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 11:55:36-07:00",
    "text": "(1) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. (2) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. (3) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-09-22 10:59:31-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 22:10:21-07:00",
    "text": "I support the DISCUSS ballots by Alexey and Roman, as well as the comments by Deborah and Alissa that more text be in the introduction about the status and limitations here. I also need to add to Alexey\u2019s DISCUSS on 4.6, Text Encoding: \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0 client to the server. This is a mine field.\u00a0 Treating passwords as raw octets without concern for encoding and normalization can cause authentication failures and can be used to attack systems where non-ASCII passwords are in use. Suppose I enter \u201ccr\u00e8me br\u00fbl\u00e9e\u201d as my password. How that\u2019s represented in UTF-8 depends upon my input device, as there are at least two valid representations of each accented vowel.\u00a0 Without normalization/canonicalization, passwords entered on different input devices might not match, blocking my access.\u00a0 And we haven\u2019t touched on bidirectional issues (mixing, say, Hebrew and English characters). The precis framework has detailed explanations of how to deal with usernames and passwords \u2014 see  RFC 8265  (and, for the overall precis framework,  RFC 8264 ). \u00a0  The encoding SHOULD be UTF-8, and other \u00a0  encodings outside printable US-ASCII SHOULD be deprecated.\u201d This doesn\u2019t make sense with respect to how we use \u201cdeprecated\u201d.\u00a0 You need to say \u201care deprecated\u201d, meaning that we recommend against using them.\u00a0 There\u2019s no  BCP 14  \u201cSHOULD\u201d involved here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-15 12:12:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-15 12:10:45-07:00",
    "text": "(1) I appreciate the deliberate and thoughtful attempt in this section to enumerate the possible risks/attacks and mitigations of the protocol as is.\u00a0 In addition to the top-level risks in Section 10.1, I can see the value of maintaining symmetry between Sections 5+10.2; 6+10.3 and 7+10.4.\u00a0 In the spirit of the middle ground this draft is trying to realize (document the as-is, but highlight the issues), I have the following feedback: (a) Section 10.1.\u00a0 I recommend replacing the first three paragraphs of Section 10.1 (\u201cTACACS+ protocol does not \u2026\u201d, \u201cWhile the protocol \u2026\u201d, and \u201cEven though \u2026\u201d) with the following text partially synthesized from Joe Salowey\u2019s review ( https://mailarchive.ietf.org/arch/msg/secdir/rsqrNbVEKph1RdWh836Ard73pHs ) with the current introduction: TACACS+ protocol does not include a security mechanism that would meet modern-day requirements.\u00a0 These security mechanisms would be best referred to as \u201cobfuscation\u201d and not \u201cencryption\u201d since they provide no meaningful integrity, privacy or replay protection.\u00a0 An attacker with access to the data stream should be assumed to be able to read and modify all TACACS+ packets. Without mitigation, a range of risks such as the following are possible: Accounting information may be modified by the man-in-the-middle attacker, making such logs unsuitable and untrustable for auditing purposes. Invalid or misleading values may be inserted by the man-in-the-middle attacker in various fields at known offsets to try and circumvent the authentication or authorization checks even inside the obfuscated body. (b) I recommend finding an alternative home and strengthening the text \u201cFor this reason, deployments SHOULD NOT use connections with TAC_PLUS_UNENCRYPTED_FLAG, as mentioned in the Best Practices section (Section 10.5)\u201d.\u00a0 It seemed odd to mix deployment guidance in a list of risks as currently written.\u00a0 I take Andrej Ota\u2019s point from  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  that there is no harm in requiring the obfuscation, such as it is.\u00a0 Furthermore, why couldn\u2019t this be MUST NOT use? (c) Section 10.5.3.\u00a0 I concur with the SECDIR recommendation and the follow-up discussion with Andrej Ota per  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  which would: s/stronger authentication/less weak/ (2) Section 10.2.\u00a0 I\u2019m confused by the deprecation of TAC_PLUS_AUTHEN_STATUS_FOLLOW but a seemingly weaker \u201cSHOULD NOT be used in modern deployments\u201d.\u00a0 I was expecting a MUST NOT. (3) Section 10.4.\u00a0 Why shouldn\u2019t accounting sessions also use secure transport per 10.5 (like 10.3 and 10.4) given the risks outlined in the text?\u00a0 I was expecting to see this section open with \u201cAccounting Session SHOULD be used via a secure transport (see Best Practices section (Section 10.5))\".",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-24 13:21:34-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:12:12-07:00",
    "text": "(1) I appreciate the deliberate and thoughtful attempt in this section to enumerate the possible risks/attacks and mitigations of the protocol as is.\u00a0 In addition to the top-level risks in Section 10.1, I can see the value of maintaining symmetry between Sections 5+10.2; 6+10.3 and 7+10.4.\u00a0 In the spirit of the middle ground this draft is trying to realize (document the as-is, but highlight the issues), I have the following feedback: (a) Section 10.1.\u00a0 I recommend replacing the first three paragraphs of Section 10.1 (\u201cTACACS+ protocol does not \u2026\u201d, \u201cWhile the protocol \u2026\u201d, and \u201cEven though \u2026\u201d) with the following text synthesized from Joe Salowey\u2019s LC review ( https://mailarchive.ietf.org/arch/msg/secdir/rsqrNbVEKph1RdWh836Ard73pHs ) and the current introduction: TACACS+ protocol does not include a security mechanism that would meet modern-day requirements.\u00a0 These security mechanisms would be best referred to as \u201cobfuscation\u201d and not \u201cencryption\u201d since they provide no meaningful integrity, privacy or replay protection.\u00a0 An attacker with access to the data stream should be assumed to be able to read and modify all TACACS+ packets. Without mitigation, a range of risks such as the following are possible: Accounting information may be modified by the man-in-the-middle attacker, making such logs unsuitable and untrustable for auditing purposes. Invalid or misleading values may be inserted by the man-in-the-middle attacker in various fields at known offsets to try and circumvent the authentication or authorization checks even inside the obfuscated body. (b) I recommend finding an alternative home and strengthening the text \u201cFor this reason, deployments SHOULD NOT use connections with TAC_PLUS_UNENCRYPTED_FLAG, as mentioned in the Best Practices section (Section 10.5)\u201d.\u00a0 It seemed odd to mix deployment guidance in a list of risks as currently written.\u00a0 I take Andrej Ota\u2019s point from  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  that there is no harm in requiring the obfuscation, such as it is.\u00a0 Furthermore, why couldn\u2019t this be MUST NOT use? (c) Section 10.5.3.\u00a0 I concur with the SECDIR recommendation and the follow-up discussion with Andrej Ota per  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  which would: s/stronger authentication/less weak/ (2) Section 10.2.\u00a0 I\u2019m confused by the deprecation of TAC_PLUS_AUTHEN_STATUS_FOLLOW but a seemingly weaker \u201cSHOULD NOT be used in modern deployments\u201d.\u00a0 I was expecting a MUST NOT. (3) Section 10.4.\u00a0 Why shouldn\u2019t accounting sessions also use secure transport per 10.5 (like 10.3 and 10.4) given the risks outlined in the text?\u00a0 I was expecting to see this section open with \u201cAccounting Session SHOULD be used via a secure transport (see Best Practices section (Section 10.5))\".",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-10-19 12:31:25-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-11 15:44:36-07:00",
    "text": "Section 5.3 indicates that \"Advertising Node Identifier\" and \"Receiving Node Identifier\" are \"4 or 6 octets.\" There are two issues that arise with the way this is currently specified, both of which can lead to a lack of interoperability: 1. While implementors might infer that \"Protocol=1\" results in a 4-byte value, and that \"Protocol=2\" results in a 6-byte value, it's a bit unclear what length is to be used here for \"Protocol=0.\" 2. The descriptions for both of these fields include: \"When Protocol is set to 1, then the 32 rightmost bits represent OSPF Router ID.\"\u00a0 This implies that the field is *wider* than 32 bits when Protocol=1, which leaves deep ambiguity about the circumstances under which the field is allowed to be 4 octets. I would strongly recommend that this section add clear language that unambiguously spells out how implementations are expected to select the field width for the four variable-width fields in this Sub-TLV (the two I cite above as well as the interface ID fields).",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-03-21 06:14:07-07:00",
    "end_reason": "position_updated",
    "start": "2016-01-20 06:19:47-08:00",
    "text": "Section 11.3, I like that we're recommending that ECS be disabled by default, but want to check one thing. This says:  \"Due to the high cache pressure introduced by ECS, the feature SHOULD be disabled in all default configurations.\"\u00a0 Does that mean that all servers SHOULD disable this by default or does this only apply to some servers? If the former, it should probably be (re-)stated somewhere early on and more prominently and not only stated far down in the document like this. If the latter, then I think you need to be more precise and I'd like to know why we're not preferring the more privacy friendly option as our default. So I hope your answer is \"yeah, all servers and sure we can state that earlier as well\" :-)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-23 13:45:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-23 12:53:43-07:00",
    "text": "This document changes the registration policy to \"Expert Review\" which, as even quoted in this document, \"has no requirement for a formal document\".\u00a0 Yet the specific guidance to the expert is written as if there will always be a document: consider \"[i]f the document is not adopted by the IDR Working Group\", \"IANA will update [...] a reference to the associated document\", \"[i]n the event that the document is\", ... Is there a requirement for a document or not?\u00a0 (Alternately, what happens if there is a request with no associated document?)",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-03-25 07:42:16-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 12:07:49-07:00",
    "text": "I'm putting in a \"discuss\" DISCUSS that I expect to clear during the call. Several other ADs raised issues that deserve discussion. While they may not fall under the \"discuss criteria\", they also don't fall under the \"discuss non-criteria\" and I want to make sure we spent some time on discussing them.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-03-16 11:50:08-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-16 11:39:09-07:00",
    "text": "I would like to understand the intent of this document a little better. RFC 8126  subtly implies that \"Expert Review\" is a little laxer than \"specification required\". But the guidance to experts in this draft seems to closely match \"IETF Review\" (sec 4.8 of 8126) except that it allows documents to get an allocation at an earlier stage in the process. The shepherd comment that \"RFC Required\" was an alternative proposal also indicates that the intent to become more, not less, strict. Indeed, the main change appears to be eliminating allocations to non-IETF-stream documents. So why not simply change the registry to \"IETF Review\" and allow provisional allocations? It would be much easier to use established mechanisms and standard definitions than rewriting them in this document. Is the SHOULD in Sec 2.1 carrying a lot of weight here?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-29 06:46:11-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-28 11:50:31-07:00",
    "text": "Thank you for your document. It might be just me, but I think your examples in 9.4.1 with trailing \\ don\u2019t seem to match the folding algorithm in section 7, as it doesn\u2019t describe special handling of trailing \\.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-09 15:28:23-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-04 23:07:36-07:00",
    "text": "I think the procedures described herein are incomplete without a footer to terminate the un-folding process.\u00a0 Otherwise, it seems that the described algorithms would leave the two-line header for the second and subsequent instances of folded text in a single document.\u00a0 (If we tried to just blindly remove all instances of the header without seeking boundaries, then we would misreconstruct content when different folding algorithms are used in the same document with the single-backslash algorithm occurring first.) I don't think it's proper to refer to a script that requires bash specifically as a \"POSIX shell script\".\u00a0 I did not attmept to check whether any bash-specific features are used or this requirements stems solely from the shebang line, though. I think the shell script does need to use double-quotes around some variable expansions, especially \"$infile\" and \"$outfile\", to work properly for filenames containing spaces.\u00a0 We do quote \"$infile\" when we're checking that it exists, just not (most of the time) when we actually use it! In addition to the above, I also share Alissa's (and Mirja's) concerns, but feel that Discuss is more appropriate than Abstain, so we can discuss what the best way to get this content published is.\u00a0 For it's fine content, and we should see it published; it's just not immediately clear to me what the right way to do so is.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-20 18:30:29-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-09 15:28:23-08:00",
    "text": "Thank you for the updates in the -10 and -11; the content looks a lot better and I am not uncomfortable about publishing as Informational (vs. BCP)! That said, I think the edits to the script have introduced a regression: \u00a0 \u00a0  # ensure input file doesn't contain the fold-sequence already \u00a0 \u00a0  if [[ -n \"$(\"$SED\" -n '/\\\\$/{N;s/\\\\\\n[ ]*\\\\/&/p}' \"$infile\")\" ]] Unfortunately, I'm not sure this gets all cases, since the 'N' command reads a line and prevents it from being considered as the first half of the wrapped sequence: kaduk$:~/git/openssl$ cat /tmp/a this is a line\\ another line\\ \\that wraps kaduk$:~/git/openssl$ cat /tmp/b this is a line another line\\ \\that wraps kaduk$:~/git/openssl$ sed -n '/\\\\$/{N;s/\\\\\\n[ ]*\\\\/&/p}' < /tmp/a kaduk$:~/git/openssl$ sed -n '/\\\\$/{N;s/\\\\\\n[ ]*\\\\/&/p}' < /tmp/b another line\\ \\that wraps",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-09-05 07:41:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-05 07:40:46-07:00",
    "text": "After some thought I think there are two things about this document that make me uncomfortable enough to ballot Discuss.  a) Due to its home in the netmod WG it is highly likely that people outside the yang community have not paid enough attention to this work. Since this is applicable to code fragments of all kinds, I think the home chosen for this RFC might have inadvertently limited input from the broader community. b) Given a) I think it is better that this document go forward as an Informational document rather than a BCP so that use of this technique becomes optional, without the force of a BCP behind it.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-11-02 15:47:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-05 07:41:00-07:00",
    "text": "After some thought I think there are two things about this document that make me uncomfortable enough to ballot Discuss.  a) Due to its home in the netmod WG it is highly likely that people outside the yang community have not paid enough attention to this work. Since this is applicable to code fragments of all kinds, I think the home chosen for this RFC might have inadvertently limited input from the broader community. b) Given a) I think it is better that this document go forward as an Informational document rather than a BCP so that use of this technique becomes optional, without the force of a BCP behind it.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-16 15:06:28-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-05 05:27:47-08:00",
    "text": "I have two things I'd like to discuss to see if changes are needed or not: (1) Neither this nor  RFC7186  seem to consider battery depletion attacks. Why is that ok? (2) 6.2: HMAC is *not* a digital signature mechanism. While loose terminology may be ok elsewhere, in this case, you shouldn't do that as it can lead to wrong conclusions. Digital signatures do provide origin authentication of sorts, but MACs do not, especially if keys are shared. It is not clear to me that some of the claims in 6.2.x of attacks being mitigated are in fact correct, given shared secrets. (Note: It could be that the claims are correct, I didn't have time to check back on all the vulnerability definitions, sorry. But I'd like to check, given the defective terminology.)",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-23 23:27:58-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-20 04:18:41-07:00",
    "text": "# GEN AD review of  draft-ietf-pce-lsp-extended-flags-07 CC @larseggert Thanks to Roni Even for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/J2jEQIJoyAsZEbtU5IK14E3yROA ). ## Discuss ### 2119 terms This document has some ambiguities that would be clarified by using RFC2119  terms in a few more places: #### Section 3.2, paragraph 2 ``` -\u00a0 \u00a0 Note that PCEP peers MAY encounter varying lengths of the LSP- -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^\u00a0 -------- +\u00a0 \u00a0 Note that PCEP peers MUST handle varying lengths of the LSP- +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^ +++++ ``` #### Section 3.2, paragraph 3 ``` -\u00a0 \u00a0 than it currently supports or understands, it will simply ignore the -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^^^^^^^^ +\u00a0 \u00a0 than it currently supports or understands, it MUST ignore the +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^ ``` #### Section 3.2, paragraph 4 ``` -\u00a0 \u00a0 than the one supported by the implementation, it will consider the -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^^^^ ^^^^^^ ^ +\u00a0 \u00a0 than the one supported by the implementation, it MUST treat the +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^^^^ ^^ ^^ ``` #### Section 5, paragraph 2 ``` -\u00a0 \u00a0 not understood by an implementation would be ignored.\u00a0 It is expected -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^^ +\u00a0 \u00a0 not understood by an implementation MUST be ignored.\u00a0 It is expected +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^ ```",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-09-01 21:08:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 12:00:01-07:00",
    "text": "An easy one, but necessary IMHO: I'm confused by the IANA Considerations section.\u00a0 It looks like a verbatim copy from  RFC 5549  which made the original registration for \"Extended Next Hop Encoding\", but this isn't actually a new registration.\u00a0 Shouldn't this therefore be something like the following? NEW: RFC 5549  added \"Extended Next Hop Encoding\" to the Capability Codes registry, which was created by [ RFC5492 ].\u00a0 IANA is requested to update the definition of that entry to refer instead to this document.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2013-11-21 12:47:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2013-11-19 15:22:09-08:00",
    "text": "I have not finished reviewing yet: I'm just about to start Section 10 as I post this, so I have well over 250 pages yet to read, and I'm sure I'll have many more comments.\u00a0 But I want to get some of this out here now, so the authors aren't entirely blindsided at the last minute.\u00a0 I also might ask that we defer this one telechat, though I'm holding off on that for now. What I have so far follows, in both the DISCUSS and COMMENT sections. ----------------------------------------------------------- 1. This first point is for some discussion with the responsible AD, and I'll clear it after we have that discussion: The grammar, punctuation, and English usage in Section 2 and its subsections is at times very hard to sort through. \u00a0I'm going to call out in the comments some bits that I found particularly troublesome, and will try to suggest alternatives. \u00a0I also suggest that the responsible AD put in an RFC Editor note asking the editors to pay particular attention here and to give it some heavy editing for language clarity. \u00a0This is a complex document, and a good overview in clear English will really help. 2. This point falls into the \"URI/IRI follies\" category: -- Section 3.2 -- \u00a0 \u00a0IRI: \u00a0Internationalized Resource Identifier, is the same as a URI, \u00a0 \u00a0 \u00a0 with the exception that it allows characters from the whole Oh, my; please don't say that it's \"the same as a URI\". \u00a0It'd be reasonable to say \"is similar to a URI, but allows characters [etc].\" -- Section 4.2 -- \u00a0 \u00a0The RTSP URI and IRI are case sensitive, with the exception of those \u00a0 \u00a0parts that [ RFC3986 ] and [ RFC3987 ] define as case-insensitive; for \u00a0 \u00a0example, the scheme and host part. Clumping URIs and IRIs together in such a vague way with respect to case mapping is a dangerous thing.\u00a0 And unless there's a particular reason to say otherwise, it's easy to avoid that by specifically saying that the scheme and host parts are the *only* case-sensitive bits (which is true of generic URIs and IRIs anyway).\u00a0 Is there really a reason not to be clearer, this way?: NEW \u00a0  The \"scheme\" and \"host\" parts of all URIs [ RFC3986 ] and IRIs [ RFC3987 ] \u00a0  are case-insensitive.\u00a0 All other parts of RTSP URIs and IRIs are case- \u00a0  sensitive, and SHOULD NOT be case-mapped. END 3. The paragraph in Section 4.4.2 that explains npt-hhmmss notation and npt-sec notation has some internal inconsistencies that have to be fixed.\u00a0 See my suggestions in the comments section below, which goes beyond the blocking point (the inconsistency) and tries to make the paragraph more readable as well. 4. I'm disturbed by this combination in Section 9.2: it appears that Content-Encoding is optional (the first paragraph doesn't say it MUST be included, and the second paragraph uses lower-case-\"may\" to describe its inclusion), but the second paragraph says that there is no default encoding.\u00a0 So what does it mean to have a message body with no Content-Encoding header?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2013-11-21 13:02:25-08:00",
    "end_reason": "discuss_updated",
    "start": "2013-11-21 12:47:17-08:00",
    "text": "I have not finished reviewing yet: I'm just about to start Section 10 as I post this, so I have well over 250 pages yet to read, and I'm sure I'll have many more comments.\u00a0 But I want to get some of this out here now, so the authors aren't entirely blindsided at the last minute.\u00a0 I also might ask that we defer this one telechat, though I'm holding off on that for now. What I have so far follows, in both the DISCUSS and COMMENT sections. ----------------------------------------------------------- 1. This point falls into the \"URI/IRI follies\" category: -- Section 3.2 -- \u00a0 \u00a0IRI: \u00a0Internationalized Resource Identifier, is the same as a URI, \u00a0 \u00a0 \u00a0 with the exception that it allows characters from the whole Oh, my; please don't say that it's \"the same as a URI\". \u00a0It'd be reasonable to say \"is similar to a URI, but allows characters [etc].\" -- Section 4.2 -- \u00a0 \u00a0The RTSP URI and IRI are case sensitive, with the exception of those \u00a0 \u00a0parts that [ RFC3986 ] and [ RFC3987 ] define as case-insensitive; for \u00a0 \u00a0example, the scheme and host part. Clumping URIs and IRIs together in such a vague way with respect to case mapping is a dangerous thing.\u00a0 And unless there's a particular reason to say otherwise, it's easy to avoid that by specifically saying that the scheme and host parts are the *only* case-sensitive bits (which is true of generic URIs and IRIs anyway).\u00a0 Is there really a reason not to be clearer, this way?: NEW \u00a0  The \"scheme\" and \"host\" parts of all URIs [ RFC3986 ] and IRIs [ RFC3987 ] \u00a0  are case-insensitive.\u00a0 All other parts of RTSP URIs and IRIs are case- \u00a0  sensitive, and SHOULD NOT be case-mapped. END 2. The paragraph in Section 4.4.2 that explains npt-hhmmss notation and npt-sec notation has some internal inconsistencies that have to be fixed.\u00a0 See my suggestions in the comments section below, which goes beyond the blocking point (the inconsistency) and tries to make the paragraph more readable as well. 3. I'm disturbed by this combination in Section 9.2: it appears that Content-Encoding is optional (the first paragraph doesn't say it MUST be included, and the second paragraph uses lower-case-\"may\" to describe its inclusion), but the second paragraph says that there is no default encoding.\u00a0 So what does it mean to have a message body with no Content-Encoding header?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2013-11-30 15:16:47-08:00",
    "end_reason": "discuss_updated",
    "start": "2013-11-21 13:02:25-08:00",
    "text": "I have not finished reviewing yet: I'm just about to start Section 10 as I post this, so I have well over 250 pages yet to read, and I'm sure I'll have many more comments.\u00a0 But I want to get some of this out here now, so the authors aren't entirely blindsided at the last minute.\u00a0 I also might ask that we defer this one telechat, though I'm holding off on that for now. What I have so far follows, in both the DISCUSS and COMMENT sections. ----------------------------------------------------------- 1. This point falls into the \"URI/IRI follies\" category: -- Section 3.2 -- \u00a0 \u00a0IRI: \u00a0Internationalized Resource Identifier, is the same as a URI, \u00a0 \u00a0 \u00a0 with the exception that it allows characters from the whole Oh, my; please don't say that it's \"the same as a URI\". \u00a0It'd be reasonable to say \"is similar to a URI, but allows characters [etc].\" -- Section 4.2 -- \u00a0 \u00a0The RTSP URI and IRI are case sensitive, with the exception of those \u00a0 \u00a0parts that [ RFC3986 ] and [ RFC3987 ] define as case-insensitive; for \u00a0 \u00a0example, the scheme and host part. Clumping URIs and IRIs together in such a vague way with respect to case mapping is a dangerous thing.\u00a0 And unless there's a particular reason to say otherwise, it's easy to avoid that by specifically saying that the scheme and host parts are the *only* case-sensitive bits (which is true of generic URIs and IRIs anyway).\u00a0 Is there really a reason not to be clearer, this way?: NEW \u00a0  The \"scheme\" and \"host\" parts of all URIs [ RFC3986 ] and IRIs [ RFC3987 ] \u00a0  are case-insensitive.\u00a0 All other parts of RTSP URIs and IRIs are case- \u00a0  sensitive, and SHOULD NOT be case-mapped. END 2. The paragraph in Section 4.4.2 that explains npt-hhmmss notation and npt-sec notation has some internal inconsistencies that have to be fixed.\u00a0 See my suggestions in the comments section below, which goes beyond the blocking point (the inconsistency) and tries to make the paragraph more readable as well.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2013-11-30 15:17:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2013-11-30 15:16:47-08:00",
    "text": "I have not finished reviewing yet: I'm just about to start Section 10 as I post this, so I have well over 250 pages yet to read, and I'm sure I'll have many more comments.\u00a0 But I want to get some of this out here now, so the authors aren't entirely blindsided at the last minute.\u00a0 I also might ask that we defer this one telechat, though I'm holding off on that for now. UPDATED: I have finished Section 10, and am starting Section 11.\u00a0 I'm adding the comments from Section 10 here, which include a couple of new DISCUSS points. What I have so far follows, in both the DISCUSS and COMMENT sections. ----------------------------------------------------------- 1. This point falls into the \"URI/IRI follies\" category: -- Section 3.2 -- \u00a0 \u00a0IRI: \u00a0Internationalized Resource Identifier, is the same as a URI, \u00a0 \u00a0 \u00a0 with the exception that it allows characters from the whole Oh, my; please don't say that it's \"the same as a URI\". \u00a0It'd be reasonable to say \"is similar to a URI, but allows characters [etc].\" -- Section 4.2 -- \u00a0 \u00a0The RTSP URI and IRI are case sensitive, with the exception of those \u00a0 \u00a0parts that [ RFC3986 ] and [ RFC3987 ] define as case-insensitive; for \u00a0 \u00a0example, the scheme and host part. Clumping URIs and IRIs together in such a vague way with respect to case mapping is a dangerous thing.\u00a0 And unless there's a particular reason to say otherwise, it's easy to avoid that by specifically saying that the scheme and host parts are the *only* case-sensitive bits (which is true of generic URIs and IRIs anyway).\u00a0 Is there really a reason not to be clearer, this way?: NEW \u00a0  The \"scheme\" and \"host\" parts of all URIs [ RFC3986 ] and IRIs [ RFC3987 ] \u00a0  are case-insensitive.\u00a0 All other parts of RTSP URIs and IRIs are case- \u00a0  sensitive, and SHOULD NOT be case-mapped. END 2. The paragraph in Section 4.4.2 that explains npt-hhmmss notation and npt-sec notation has some internal inconsistencies that have to be fixed.\u00a0 See my suggestions in the comments section below, which goes beyond the blocking point (the inconsistency) and tries to make the paragraph more readable as well. -- Section 10.5 -- \u00a0  The mechanisms for showing liveness of the client is, any RTSP \u00a0  request with a Session header, if RTP & RTCP is used an RTCP message, \u00a0  or through any other used media protocol capable of indicating \u00a0  liveness of the RTSP client. The grammar and punctuation in that sentence is so fractured that I haven't the first idea what it means.\u00a0 It needs to be re-worded, and I can't help. \u00a0  SET_PARAMETER:\u00a0 When using SET_PARAMETER for keep-alive, a body \u00a0 \u00a0 \u00a0 \u00a0  SHOULD NOT be included.\u00a0 This method is the RECOMMENDED RTSP \u00a0 \u00a0 \u00a0 \u00a0  method to use for a request intended only to perform keep- \u00a0 \u00a0 \u00a0 \u00a0  alive. But a short bit above, in Section 10.4, you say this: \u00a0  The keep-alive request will normally \u00a0  be a GET_PARAMETER with a session header to inform the server that \u00a0  this agent cares about this RTSP session. If SET_PARAMETER is what's RECOMMENDED, then why do you say that it \"will normally be\" GET_PARAMETER?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2013-12-01 14:35:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2013-11-30 15:17:55-08:00",
    "text": "I have not finished reviewing yet: I'm just about to start Section 10 as I post this, so I have well over 250 pages yet to read, and I'm sure I'll have many more comments.\u00a0 But I want to get some of this out here now, so the authors aren't entirely blindsided at the last minute.\u00a0 I also might ask that we defer this one telechat, though I'm holding off on that for now. UPDATED: I have finished Section 10, and am starting Section 11.\u00a0 I'm adding the comments from Section 10 here, which include a couple of new DISCUSS points. What I have so far follows, in both the DISCUSS and COMMENT sections. ----------------------------------------------------------- 1. This point falls into the \"URI/IRI follies\" category: -- Section 3.2 -- \u00a0 \u00a0IRI: \u00a0Internationalized Resource Identifier, is the same as a URI, \u00a0 \u00a0 \u00a0 with the exception that it allows characters from the whole Oh, my; please don't say that it's \"the same as a URI\". \u00a0It'd be reasonable to say \"is similar to a URI, but allows characters [etc].\" -- Section 4.2 -- \u00a0 \u00a0The RTSP URI and IRI are case sensitive, with the exception of those \u00a0 \u00a0parts that [ RFC3986 ] and [ RFC3987 ] define as case-insensitive; for \u00a0 \u00a0example, the scheme and host part. Clumping URIs and IRIs together in such a vague way with respect to case mapping is a dangerous thing.\u00a0 And unless there's a particular reason to say otherwise, it's easy to avoid that by specifically saying that the scheme and host parts are the *only* case-sensitive bits (which is true of generic URIs and IRIs anyway).\u00a0 Is there really a reason not to be clearer, this way?: NEW \u00a0  The \"scheme\" and \"host\" parts of all URIs [ RFC3986 ] and IRIs [ RFC3987 ] \u00a0  are case-insensitive.\u00a0 All other parts of RTSP URIs and IRIs are case- \u00a0  sensitive, and SHOULD NOT be case-mapped. END 2. The paragraph in Section 4.4.2 that explains npt-hhmmss notation and npt-sec notation has some internal inconsistencies that have to be fixed.\u00a0 See my suggestions in the comments section below, which goes beyond the blocking point (the inconsistency) and tries to make the paragraph more readable as well. 3. Two bits in Section 10.5: \u00a0  The mechanisms for showing liveness of the client is, any RTSP \u00a0  request with a Session header, if RTP & RTCP is used an RTCP message, \u00a0  or through any other used media protocol capable of indicating \u00a0  liveness of the RTSP client. The grammar and punctuation in that sentence is so fractured that I haven't the first idea what it means.\u00a0 It needs to be re-worded, and I can't help. \u00a0  SET_PARAMETER:\u00a0 When using SET_PARAMETER for keep-alive, a body \u00a0 \u00a0 \u00a0 \u00a0  SHOULD NOT be included.\u00a0 This method is the RECOMMENDED RTSP \u00a0 \u00a0 \u00a0 \u00a0  method to use for a request intended only to perform keep- \u00a0 \u00a0 \u00a0 \u00a0  alive. But a short bit above, in Section 10.4, you say this: \u00a0  The keep-alive request will normally \u00a0  be a GET_PARAMETER with a session header to inform the server that \u00a0  this agent cares about this RTSP session. If SET_PARAMETER is what's RECOMMENDED, then why do you say that it \"will normally be\" GET_PARAMETER?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2014-01-22 03:07:54-08:00",
    "end_reason": "position_updated",
    "start": "2013-12-01 14:35:02-08:00",
    "text": "UPDATED: I have not finished reviewing yet: I'm just about to start Section 14 as I post this. I'm sure I'll have many more comments, but I want to get some of this out here now, so the authors aren't entirely blindsided at the last minute. What I have so far follows, in both the DISCUSS and COMMENT sections. ----------------------------------------------------------- 1. This point falls into the \"URI/IRI follies\" category: -- Section 3.2 -- \u00a0 \u00a0IRI: \u00a0Internationalized Resource Identifier, is the same as a URI, \u00a0 \u00a0 \u00a0 with the exception that it allows characters from the whole Oh, my; please don't say that it's \"the same as a URI\". \u00a0It'd be reasonable to say \"is similar to a URI, but allows characters [etc].\" -- Section 4.2 -- \u00a0 \u00a0The RTSP URI and IRI are case sensitive, with the exception of those \u00a0 \u00a0parts that [ RFC3986 ] and [ RFC3987 ] define as case-insensitive; for \u00a0 \u00a0example, the scheme and host part. Clumping URIs and IRIs together in such a vague way with respect to case mapping is a dangerous thing.\u00a0 And unless there's a particular reason to say otherwise, it's easy to avoid that by specifically saying that the scheme and host parts are the *only* case-sensitive bits (which is true of generic URIs and IRIs anyway).\u00a0 Is there really a reason not to be clearer, this way?: NEW \u00a0  The \"scheme\" and \"host\" parts of all URIs [ RFC3986 ] and IRIs [ RFC3987 ] \u00a0  are case-insensitive.\u00a0 All other parts of RTSP URIs and IRIs are case- \u00a0  sensitive, and SHOULD NOT be case-mapped. END 2. The paragraph in Section 4.4.2 that explains npt-hhmmss notation and npt-sec notation has some internal inconsistencies that have to be fixed.\u00a0 See my suggestions in the comments section below, which goes beyond the blocking point (the inconsistency) and tries to make the paragraph more readable as well. 3. Two bits in Section 10.5: \u00a0  The mechanisms for showing liveness of the client is, any RTSP \u00a0  request with a Session header, if RTP & RTCP is used an RTCP message, \u00a0  or through any other used media protocol capable of indicating \u00a0  liveness of the RTSP client. The grammar and punctuation in that sentence is so fractured that I haven't the first idea what it means.\u00a0 It needs to be re-worded, and I can't help. \u00a0  SET_PARAMETER:\u00a0 When using SET_PARAMETER for keep-alive, a body \u00a0 \u00a0 \u00a0 \u00a0  SHOULD NOT be included.\u00a0 This method is the RECOMMENDED RTSP \u00a0 \u00a0 \u00a0 \u00a0  method to use for a request intended only to perform keep- \u00a0 \u00a0 \u00a0 \u00a0  alive. But a short bit above, in Section 10.4, you say this: \u00a0  The keep-alive request will normally \u00a0  be a GET_PARAMETER with a session header to inform the server that \u00a0  this agent cares about this RTSP session. If SET_PARAMETER is what's RECOMMENDED, then why do you say that it \"will normally be\" GET_PARAMETER? 4. In Section 11.1: \u00a0  Thus following all normative parts in the main sections (the \u00a0  ones with numbers), but omitting the appendices (starting with \u00a0  letters), unless explicitly specified in a main section as being a \u00a0  required appendix. This is not a complete sentence, so I can't figure it out.\u00a0 What do you mean to say here?\u00a0 You appear to be making some statement about the applicability of the document as a whole, yet that statement is buried down in Section 11.1.\u00a0 After turning this into a proper sentence, you might (depending upon what it really is that you're saying) need to promote it to someplace where it's earlier on and more obvious. On the section as a whole, and the meaning of the play.basic feature-tag: Am I to understand that this feature-tag is basically used to say, \"I support the basic spec for RTSP 2.0.\" ?\u00a0 If so, that can (and should) be said a lot more clearly, directly, and succinctly.\u00a0 If that's not right, then this section probably needs to be clearer anyway, because it means I'm not getting it. 5. In Section 13.3: \u00a0  There is also a third possible \u00a0  usage for the SETUP method which is not specified in this memo: \u00a0  adding a media to a session.\u00a0 Using SETUP to add media to an existing \u00a0  session, when the session is in Play state, is unspecified. I don't understand what this is trying to say.\u00a0 If there's a third legitimate use, why does this document mention it, but \"not specify\" it?\u00a0 What does it mean for it to be \"unspecified\"?\u00a0 Is using SETUP to add media to an existing session that's in Ready state specified?\u00a0 Where? There are other places where you say that something \"is unspecified\" (later in 13.3, for example, \"The SETUP of media streams in an aggregate which has not been given an aggregated control URI is unspecified.\"): in general, what does that mean?\u00a0 Does it mean it's not permitted?\u00a0 Does it mean that it *is* permitted, but you don't specify how it works?\u00a0 Or what?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2014-01-28 17:30:08-08:00",
    "end_reason": "position_updated",
    "start": "2013-12-05 03:53:44-08:00",
    "text": "I didn't look back at 2326 since the diff wasn't really useful so feel free to ignore any comment that would equally apply to the earlier RFC.  The security considerations section for the bis draft is very thorough thanks! But I still have a few things I'd like to discuss (sorry;-). Discuss point #1 is the main thing though, if we resolve that, then the others should be easy to clear up. (1) 21.1 - \"transfer of sensitive information\" - I think you need to say here that RTSP *is* less sensitive than HTTP and that's why its ok to have the hop-by-hop scheme. HTTP is more sensitive because users commonly input or read much more sensitive information in HTTP exchanges, e.g.\u00a0 HTTP requests often contain passwords, cookies, cardholder data and responses often contain bank account details, healthcare data, none of which is transported via RTSP. If that is true, then the hop-by-hop scheme is much more reasonable and saying so is important and should help clear my discuss much more easliy. If that is not true (i.e. if really sensitive user information is commonly sent via RTSP) then we need to talk more. (2) 15 - \"This proxy can also limit the client's access to certain types of content.\" That's not a security function but really a censorship function, at least as stated. I suggest deleting the sentence, or changing it to one that's suitable. (3) 18.8 - is this saying that a 2nd request for the same thing won't need to be authenticated even if that was required for the first request? If not, that's not clear to me. (4) 19 - Why is there no equivalent of HTTP CONNECT for TLS?\u00a0 It seems like the choices are to either connect directly over TLS to the origin server or else to have to use a proxy that sees all the plaintext and headers. (5) 19.2 - 2nd last para: Why don't you use SNI here? Just wondering, but it'd fix a problem if it worked. (6) 19.3 - I think you need to say here (or somewhere) that all TLS \"hops\" MUST have commensurate security. (7) 19.3.2 - how is a user supposed to practically \"approve\" a proxy with just e.g. an IP address?\u00a0 That seems meaningless. (8) 21.1 - Location headers and spoofing - I don't get how the \"if\" that preceeds the MUST here can be implemented.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 19:12:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-20 22:01:35-07:00",
    "text": "There seems to be a bit of internal inconsistency in Appendix B.2: \u00a0  Names of PSDs participating in PSD DMARC must be registered this new \u00a0  registry.\u00a0 New entries are assigned only for PSDs that require use of \u00a0  DMARC.\u00a0 [...] These two sentences seem to be in conflict, since a PSD can participate in PSD DMARC without requiring use of DMARC for all its subdomains.\u00a0 The rest of the section is clear that the registry is only intended to be for PSDs that do require the use of DMARC for subdomains, so I expect that a minor tweak to the wording of \"PSDs participating in PSD DMARC\" would be an appropriate fix.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2016-07-13 14:12:23-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-15 12:12:48-07:00",
    "text": "er IANA #912091 Management Item, need approval of Designated Experts for this registry. After Experts approved and Expert Review completed, will remove Discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-01 20:39:28-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 00:31:01-08:00",
    "text": "Thank you for this document (and its predecessor); it's important to get these points clarified, and sooner rather than later.\u00a0 I expect that the following few issues should be quickly resolvable. Section 11.10.1 includes a reference to \"Section 11.7.2.1 of  RFC5661 \", but this document is obsoleting that document.\u00a0 It seems internally inconsistent to both obsolete and depend on the same source -- if we rely on that content, it should be included in this document. This is somewhat awkward since the limited nature of the update results in my not having the full context of the rest of the document; with that limitation in my understanding in mind, I'd like to confirm that we're comfortable with the use of \"network address\" in the context of trunking/migration, specifically the extent to which we do not discuss port numbers.\u00a0 The relevant XDR types do allow for optional port numbers to be included, with a default to be used when not specified, but in this document we do have a new note that different ports may be used for different connection types to the same logical server, and also that different ports \"is not the essence of the distinction between the two endpoints\".\u00a0 I think there might be cases where the port is relevant for a distinction, but the main ones I can think of are of questionable relevance (essentially, roughly equivalent to multiple userspace NFS servers on a single host but in different trust/privilege domains) -- I'd like another opinion or several. In a similar \"discuss discuss\" vein, Section 11.10.8 describes a scenario that does not give much clarity, at a protocol level, into what degree of replication synchronization a client can expect from a given file system that advertises multiple replicas.\u00a0 I recognize that this is de facto just stating the deployed reality, but it's also hard to feel good about having this level of ambiguity in a propsed standard, and the (unchanged) text in Section 11.5.5 seems to impose a stricter consistency requirement, at least on potential migration targets.\u00a0 (A bit more detail in the COMMENT section.) Section 11.13.2 mentions that \"[i]ssues connected with a client impersonating another by presenting another client's id string are discussed in Section 21\", but I failed to find this discussion in Section 21.\u00a0 (The discuss-level issue is just the internal inconsistency; there's a decent argument that this is covered by Appendix C's \"not written in accord with  RFC3552 \".\u00a0 Though if the text was already written for  draft-ietf-nfsv4-mv1-msns-update , not including it here seems a little silly.)",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2016-10-07 15:39:33-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-02 10:52:21-07:00",
    "text": "In section 2.2, the document says: \"The direct implication of Section 2.1 is that, if the network uses a \u00a0  routing protocol, the routing protocols used in multihomed networks \u00a0  SHOULD implement source-prefix based egress routing, for example as \u00a0  described in [ I-D.ietf-rtgwg-dst-src-routing ].\" I understand the desire behind this statement - but find the SHOULD extremely strong given that we don't even have any routing protocol extensions adopted by ISIS, OPSF or even Babel WGs to handle source-prefix based egress routing.\u00a0  I know that we are actively discussing the problems motivating this statement and, I hope, making progress.\u00a0  However, I don't think that the dynamics or scaling or potential looping (for routers that don't support the same source prefixes) have been fully described or resolved. While this problem has been discussed in rtgwg, I do not yet see consensus in the Routing Area that this is the agreed solution.\u00a0 The email sent by v6ops about this problem recommended src-dest-routing as a solution and, indeed, that is being investigated. At a minimum, the language in this section needs to change from SHOULD.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-07-11 12:23:36-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-22 18:18:45-07:00",
    "text": "Thanks for taking the time to document this format for public consumption. I have a handful of blocking concerns (although I'm open to listening to reasons that I might be wrong on this front), and a number of additional comments. --------------------------------------------------------------------------- I have a lot of heartburn around the publication of an in informational document of a protocol called \"Zstandard.\" I know the protocol has been in development for a while, and has non-trivial deployment, so I understand that there would be reluctance to change its name at this point. If we leave the name as-is, I do not think that the normal informational boilerplate is sufficient. I would like to see additional text that explicitly addresses the situation, along the lines of: [Abstract] \u00a0  Zstandard, or \"zstd\" (pronounced \"zee standard\"), is a data \u00a0  compression mechanism.\u00a0 This document describes the mechanism, and \u00a0  registers a media type to be used when transporting zstd-compressed \u00a0  via Multipurpose Internet Mail Extensions (MIME).\u00a0 Despite the use of the \u00a0  word \"standard\" as part of its name, readers are advised that this document \u00a0  is not an Internet Standards Track specification, and is being published \u00a0  for informational purposes only. [Introduction] \u00a0  Zstandard, or \"zstd\" (pronounced \"zee standard\") is a data compression \u00a0  mechanism, akin to gzip [ RFC1952 ]. Despite the use of the word \"standard\" \u00a0  as part of its name, readers are advised that this document is not an \u00a0  Internet Standards Track specification, and is being published for \u00a0  informational purposes only. --------------------------------------------------------------------------- \u00a72.2.1: >\u00a0 For the first block, the starting offset history is populated with >\u00a0 the following values : 1, 4 and 8 (in order). I fear this is ambiguously specified. I can interpret this as either temporal order: Repeated_Offset1 = 8 Repeated_Offset2 = 4 Repeated_Offset3 = 1 Or as sequential order: Repeated_Offset1 = 1 Repeated_Offset2 = 4 Repeated_Offset3 = 8 Please clarify, as this confusion can lead to incompatible implementations. --------------------------------------------------------------------------- The dictionary scheme in here seems problematic, in that the intention is clearly to have public, well-known dictionaries; and the dictionaries are intended to have globally-unique identifiers for that purpose. 31 bits isn't enough space to achieve uniqueness through randomness. While there are other approaches that involve things like dictionary IDs that are hashes of their contents (see, e.g., SigComp), I suspect the notion of expanding the size of this field isn't very appealing. If you keep the format the same (4 bytes), I don't see how the dictionary part of this scheme can be interoperable without a registry of some kind. Even if the intention is to publish further documents on the topic of dictionaries, I believe publication of this document needs to wait on establishment of such a registry. I have no opinion about whether this is resolved by creating the registry in this document, or in holding its publication until the document that does create such a registry is published.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-07-12 08:37:48-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-24 06:41:16-07:00",
    "text": "I support Adam's DISCUSS. Additionally, I think that there are significant privacy  considerations associated with the Skippable Frames described in Section 2.3, that should be documented before this document advances.\u00a0 Specifically, this provides an easy way for a party (not even necessarily the encoder, since these frames can be inserted independently from the actual compression scheme) to insert (e.g.) tracking data into a compressed stream and have it ignored by standard decoders.\u00a0 There are myriad possibilities for how this could be used, such as for watermarking files with information about how they were downloaded/generated/etc., which could be used for tracking leaks from confidential materials or illegal distribution of copyrighted content; there is potential for personally identifying information to be included; the list goes on.\u00a0 I can see that there can also be useful ways to use these frames to introduce additional metadata about the compressed content, but fear that we may want to give guidance for these frames to be stripped/forbidden/etc. absent additional context to indicate that the information in the skippable frame is non-malicious. A more minor note, but still IMO blocking -- in Section 2.1.1.1.2: \u00a0 \u00a0  windowLog = 10 + Exponent; \u00a0 \u00a0  windowBase = 1 << windowLog; \u00a0 \u00a0  windowAdd = (windowBase / 8) * Mantissa; \u00a0 \u00a0  Window_Size = windowBase + windowAdd; I don't think this formula is correct -- windowAdd in this formula is not modified by windowLog at all, which does not match up with the stated maxiumum bound in the body text.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-14 06:35:12-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-02 03:04:18-08:00",
    "text": "I would be happy to ballot Yes on this document, as it is well written and is a useful piece of work. However I have one issue (and a few minor comments) that I would like to DISCUSS before doing so: In Section 5.3 the document says: \u00a0  It is RECOMMENDED that Relying Parties and Publication Servers follow \u00a0  the Best Current Practices outlined in [ RFC7525 ] on the use of HTTP \u00a0  over TLS (HTTPS) [ RFC2818 ]. RFC 7525  is referencing  RFC 6125  for server hostname validation. Unfortunately this is not detailed enough to perform hostname validation, because reference to  RFC 6125  requires specifying answers to every question in section 3 of  RFC 6125 . (And there is no generic RFC that specifies how this is done for protocols using HTTP.) One example of how this might look like is in Section 9.2 of . For your convenience the relevant text is pasted below: \u00a0  Routers MUST also verify the cache's TLS server certificate, using \u00a0  subjectAltName dNSName identities as described in [ RFC6125 ], to avoid \u00a0  man-in-the-middle attacks.\u00a0 The rules and guidelines defined in \u00a0  [ RFC6125 ] apply here, with the following considerations: \u00a0 \u00a0 \u00a0 Support for DNS-ID identifier type (that is, the dNSName identity \u00a0 \u00a0 \u00a0 in the subjectAltName extension) is REQUIRED in rpki-rtr server \u00a0 \u00a0 \u00a0 and client implementations which use TLS.\u00a0 Certification \u00a0 \u00a0 \u00a0 authorities which issue rpki-rtr server certificates MUST support \u00a0 \u00a0 \u00a0 the DNS-ID identifier type, and the DNS-ID identifier type MUST be \u00a0 \u00a0 \u00a0 present in rpki-rtr server certificates. \u00a0 \u00a0 \u00a0 DNS names in rpki-rtr server certificates SHOULD NOT contain the \u00a0 \u00a0 \u00a0 wildcard character \"*\". \u00a0 \u00a0 \u00a0 rpki-rtr implementations which use TLS MUST NOT use CN-ID \u00a0 \u00a0 \u00a0 identifiers; a CN field may be present in the server certificate's \u00a0 \u00a0 \u00a0 subject name, but MUST NOT be used for authentication within the \u00a0 \u00a0 \u00a0 rules described in [ RFC6125 ]. The only thing missing from the above is explicit mentioning that SRV-ID and URI-ID are not used. (I think the same should apply to your document.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-09-24 04:35:19-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-13 13:41:13-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D7386 DETAIL S 6.1. >\u00a0  6.1.\u00a0 \"Log Me\" Authorization >\u00a0   >\u00a0 \u00a0 \u00a0 An end user or network administrator MUST give permission for a >\u00a0 \u00a0 \u00a0 terminal to perform \"log me\" marking.\u00a0 The configuration of a SIP >\u00a0 \u00a0 \u00a0 intermediary to perform \"log me\" marking on behalf of a terminal MUST >\u00a0 \u00a0 \u00a0 be authorized by the network administrator. This seems to contradict S 4.4.2, which describes how you get logging even when the responding UA doesn't support it (and thus presumably doesn't give permission). Perhaps you mean \"at least one end user or administrator...? S 6.4.2. >\u00a0 \u00a0 \u00a0 store all the SIP messages that are exchanged within a given dialog. >\u00a0 \u00a0 \u00a0 SIP messages can contain the personal identifiers listed in >\u00a0 \u00a0 \u00a0 Section 6.4.1 and additionally a user identity, calling party number, >\u00a0 \u00a0 \u00a0 IP address, hostname, and other user and device related items.\u00a0 The >\u00a0 \u00a0 \u00a0 SIP message bodies describe the kind of session being set up by the >\u00a0 \u00a0 \u00a0 identified end user and device. This seems to have extremely negative consequences when security descriptions is used. It seems like you need to prohibit their combination or at least call this out.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-23 09:35:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-01-31 14:22:06-08:00",
    "text": "It looks like we may have a setup where a compliant RP and compliant CA/repository fail to interoperate.\u00a0 This is sufficiently surprising that I want to confirm that it's the intended behavior.\u00a0 In particular, both manifests and CRLs have thisUpdate and nextUpdate fields, and since issuing an update to one requires issuing an update to the other (though the CRL is always actually generated first), it is only natural for us to give guidance that the times in question should match between manifest and corresponding CRL.\u00a0 However, we do this only as RECOMMENDED/SHOULD-level guidance, and accompany it by guidance to RPs that they SHOULD NOT reject a manifest of the fields do not match the CRL.\u00a0 Accordingly, when a CA violates the first SHOULD and issues manifeset+CRL with mismatched thisUpdate/nextUpdate, and an RP violates the second SHOULD (NOT) and rejects such a setup, the RP will be unable to get any RPKI data for that CA.\u00a0 (As a tangent, we also have one place where we give related guidance that the validity period of the single-use EE cert that signs the manifest match the thisUpdate/nextUpdate period, which we might want to keep in mind if we make any changes in this space.) It looks like  RFC 6486  had a conditional MUST-level requirement that *if* a manifest encompasses a CRL, then the \"nextUpdate\" fields MUST match (no guidance on thisUpdate), which we change to a statement of fact that each  manifest does encompass a CRL and guidance that the \"nextUpdate\"s SHOULD match. Additionally,  RFC 6486  had a MUST-level requirement for the validity period of the EE cert to exactly match the thisUpdate/nextUpdate time interval of the manifest, which we currently are relaxing to a SHOULD. Often in this scenario we would strengthen one of the SHOULDs to be a MUST so that interoperability is guaranteed, but I'm not sure that I see a clear argument for which requirement is better to make the MUST.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-16 14:16:13-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-16 07:42:47-07:00",
    "text": "Adding a discussion point: considering that this document contradicts the recommendation in  RFC 9319 , which is a BCP, shouldn't it update  RFC 9319 , and shouldn't it be a BCP? The BCP issue has already been raised, but I don't think the update thing has been mentioned. It seems as though it's the kind thing to do for users of  BCP 185  -- it's the way we have, in our document set, of saying \"oh hi, please don't assume all the information is just in this document here, please go check there too\".",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-05-07 15:11:48-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-13 11:04:46-07:00",
    "text": "From the abstract, it seems this document is strongly urging some best practise. Why is this document Informational and not a BCP ? Unfortunately, the shepherd did not explain that. \u00a0  Any ROA object that includes resources which are a) no longer contained in the new CA certificate, or b) [...] , will be rejected as invalid. Isn't a) the normal expected case? I understand case b) but why is case a) listed here? Or is this saying a ROA with 10 prefixes, of which 1 prefix is no longer in the parent CA, will cause the entire ROA with 10 prefixes to be invalid, and not retain 9 valid prefixes? If so, I think the text should be clarified to say that more clearly. If no so, then I think this case should be omitted from the sentence as it wouldn't be relevant to a \"problem case\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-08-17 17:51:11-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-21 21:26:43-07:00",
    "text": "The example JWK for cryptosuite 1 in \u00a75.1 is not well-formed.\u00a0  RFC 8037 key-exchange uses a crv of \"X25519\" and a kty of \"OKP\". (See COMMENT for more quibbles with \u00a75.1.) I think Appendix E is also using the wrong \"kty\" for X25519 (but is properly using \"X25519\" as the \"crv\"). I'd also like to discuss our treatment of channel binding, as the current mention seems dangerously incomplete.\u00a0 I don't remember if there is generic discussion of channel binding in the core EAP RFCs (if so, a specific reference would help), but otherwise if we're going to mention that protocol elements can be used for channel binding we should give some indication of how to actually do so in a secure manner (e.g., what protocol element needs to be verified against external channel information and what to do if they don't match).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-07-30 12:51:39-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-19 15:37:04-07:00",
    "text": "Thank you for the work on this document. I have a couple of blocking comments related to the IANA section, which should be easy to fix, plus some minor non blocking comments below. Francesca 1. ----- Section 5. FP: IANA is requested to create a sub registry to the EAP registry, but there is no actual \"Nimble out-of-band authentication for EAP Parameters\" registry defined, nor values registered in it. Either this is a new page or (I would suggest) the subregistries are just created directly under the EAP page. 2. ----- Section 5.1 and following FP: This document defines several new registry with policy Specification required, which will need designated experts.  https://tools.ietf.org/html/rfc8126#section-5.3  states that: \u00a0  When a designated expert is used, the documentation should give clear \u00a0  guidance to the designated expert, laying out criteria for performing \u00a0  an evaluation and reasons for rejecting a request.\u00a0 In the case where I believe designated expert guidance should be added to this document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-18 21:02:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-18 15:09:39-07:00",
    "text": "I think this should be pretty easy to resolve, though I'm not sure what the right way to do so it. Section 3 says: \u00a0  [ I-D.ietf-pce-hierarchy-extensions ] defines the H-PCE Capability TLV \u00a0  that is used in the Open message to advertise the H-PCE capability. \u00a0  [ RFC8231 ] defines the Stateful PCE Capability TLV used in the Open \u00a0  message to indicate stateful support.\u00a0 The presence of both TLVs in \u00a0  an Open message indicates the support for stateful H-PCE operations \u00a0  as described in this document. There is no normative reference relationship (in either direction) between draft-ietf-pce-hierarchy-extension and this document; I think that the use of the capability TLV to imply both sets of functionality implies some sort of normative relationship; we wouldn't want version skew between documents to induce breaking changes.\u00a0 In particular, an implementation that already supports  RFC 8231  and is implementing the hierarchy extensions would need to know to look at this document *and implement it*, or would unknowingly be noncompliant with this document and fail to interoperate with a peer that is compliant with this document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-15 15:20:22-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-18 07:15:12-07:00",
    "text": "** Section 4.\u00a0 Per \u201cThe security considerations listed in [ RFC8231 ], [ RFC6805 ] and [ RFC5440 ] apply to this document as well. As per [ RFC6805 ], it is expected that the parent PCE will require all child PCEs to use full security when communicating with the parent.\u201d, the references make sense, thanks for making them.\u00a0 My concern is in the definition of \u201cuse full security\u201d.\u00a0 I can see those words come from  RFC6805 , however, I can't find where that set of practices is defined.\u00a0 Can this please be clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-01-15 14:32:12-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-10 06:39:17-08:00",
    "text": "(1) I think the standard  RFC 8174  boilerplate is needed here. I think it was a mistake to use the 2119 keywords differently in  RFC 7084 , and that mistake need not be repeated. This document uses the normative keywords in the same ways as many other informational documents.  RFC 2119  is not focused on interoperability, but rather on the requirements that the specification using the keywords is laying out. (2) I don't think it is appropriate for this document to defined a new normative keyword, \"DEFAULT,\" in Section 1.1. The right place to do that would be an update to  RFC 2119  or  RFC 8174 . This is especially problematic given that the one place in this document where it is used, it is in a paragraph that also uses other normative keywords. Since it's only used once, I would suggest just explaining what it means in that location (3.2.2) rather than defining it as a keyword.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-14 11:01:45-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-09 20:36:50-08:00",
    "text": "I guess this is related to Suresh's Discuss as well. It's late in the day and I'm reading quickly, so my apologies if I've missed something obvious and this is in fact a non-issue.\u00a0 That said, process-wise, it seems that 464XLAT-6 in Section 3.2.1 is attempting to direct an implementation of  RFC 8115  to violate a MUST-level requirement from that document (\"the conveyed multicast IPv6 prefix MUST belong to the [ASM|SSM] range\") by allowing for all-zero ASM_mPrefix64 and SSM_mPrefix64 fields.\u00a0 (Furthermore, the end of Section 3 of  RFC 8115  appears to suggest that the Well-Known DNS Name heuristic discovery-based method should be used instead, when only unicast services are needed.)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-01-28 10:04:41-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-08 20:42:47-08:00",
    "text": "* Section 3.2.1.  I do not see why the use of  RFC8115  (464XLAT-6) is being mandated for the use of 464XLAT. What is the intent of such a mandate? Especially, since the uPrefix64 is used for address synthesis for SSM for IPv4 *sources* in the IPv6 domain. Given that IPv4 multicast support itself is only conditional in Section 4, I do not see a need at all for this MUST requirement. Can you please clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-26 13:43:17-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-25 07:19:38-07:00",
    "text": "Section 9.2 says: \u00a0  An autonomic network consists of autonomic devices that form a \u00a0  distributed self-managing system.\u00a0 Devices within a domain share a \u00a0  common trust anchor and thus implicitly trust each other.\u00a0 [...] This seems to be a fundamental misstatement of how trust anchors work.\u00a0 Sharing a trust anchor means that you are willing to trust the same entity, the holder of the private key for that trust anchor. It does not imply any relationship between the two entiteis that trust the trust anchor. To be clear,\u00a0 I think that the authors do understand the actual trust and security situation here, and the rest of the subsection makes sense; I just think that this text needs to be changed to make the situation clear to the reader in an accurate way.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-09 07:40:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-05 04:07:18-07:00",
    "text": "This is a fine document and I only found a few minor things that should be easy to fix. In 4.1: \u00a0  The candidate attribute can itself be extended.\u00a0 The grammar allows \u00a0  for new name/value pairs to be added at the end of the attribute. \u00a0  Such extensions MUST be made through IETF Review or IESG Approval \u00a0  [ RFC8126 ] and the assignments MUST contain the specific extension and \u00a0  a reference to the document defining the usage of the extension. This is effectively creating a new registry, but this information is not present in the IANA Considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-14 10:33:21-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-09 07:40:56-07:00",
    "text": "This is a fine document and I only found a few minor things that should be easy to fix. Thank you for addressing my comments. Unfortunately it doesn't look like my DISCUSS point was addressed yet. Also, your IANA change introduced another issue. 1) In 5.1: \u00a0  The candidate attribute can itself be extended.\u00a0 The grammar allows \u00a0  for new name/value pairs to be added at the end of the attribute. \u00a0  Such extensions MUST be made through IETF Review or IESG Approval \u00a0  [ RFC8126 ] and the assignments MUST contain the specific extension and \u00a0  a reference to the document defining the usage of the extension. This is effectively creating a new registry, but this information is not present in the IANA Considerations section. So you need to do one of the following: a) Remove the last sentence b) Reword it to only talk about IETF stream documents for defining extensions (IESG can't really do what you ask, unless you have an IANA registry established for these.) c) Move this text to the IANA considerations and update it to properly define a new IANA registry. 2) In 10.2: You removed the following text: \u00a0  o\u00a0 Name, Email, and Address of a contact person for the registration\t \t\t   \u00a0  o\u00a0 Organization or individuals having the change control I think removing (postal) Address is a good thing. However the rest of this is still needed, as IANA uses this information to decide whether a person/organization is allowed to update an existing registry entry. So please consider adding it back or explain why this information is not needed for a registry where external organizations can add value (without publishing an RFC).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-09 05:56:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-06 08:59:20-07:00",
    "text": "Apologies for multiple ballot emails, wrapped up a bit too soon the first time. I'm confused about Section 7. The mechanisms in  RFC 4091  and  RFC 4092  were deprecated in  RFC 5245 , and this is mentioned in  RFC 8445 . Why does this specification then need to additionally normatively recommend the use of ICE for dual-stack scenarios? This could be interpreted as saying that ANAT is an alternative option for this use case, but it shouldn't be according to  RFC 8445 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-09 11:38:44-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-05 17:14:00-07:00",
    "text": "A fairly minor point, but the example in Section 4.6 is not compliant with the rest of the document.\u00a0 Specifically, any implementation *of this document* must include the \"ice2\" ice-option in addition to any other option being used, per Section 3.2.1.5.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-13 18:25:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-09 11:38:44-07:00",
    "text": "A fairly minor point, but the example in Section 5.6 is not compliant with the ABNF for the ice-options production, which uses SP to separate different ice-option-tag values; the example uses a comma.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-13 18:34:33-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 19:28:32-07:00",
    "text": "(1) Section 8.1. Per \u201cThese require techniques for message integrity and encryption for offers and answers, which are satisfied by the TLS mechanism [ RFC3261 ] when SIP is used\u201d, the guidance is right (use TLS), but this reference is outdated.\u00a0 Section 26.2.1 of  RFC3261  provides rather old guidance on the ciphersuite.\u00a0 Is there a reason why not to use  BCP195  for guidance on versions/ciphersuites? (2) Section 8.2.1, The \u201cvoice hammer attack\u201d appears to be an artifact of SDP.\u00a0 The text explicitly notes that this attack is not \u201cspecific to ICE but that ICE can help provide a remediation\u201d (aside, should \u201cremediation\u201d be \u201cmitigation\u201d).\u00a0 However, the preceding introductory section (8.2) explicitly says \u201cthere are several attacks possible with ICE\u201d.\u00a0 These two statements aren\u2019t consistent. (3) Section 8.2.2.\u00a0 This section reads like an operational consideration.\u00a0 The setup scoped in the parent Section 8.2, \u201cthere are several attacks possible with ICE when the attacker is an authenticated and valid participant in the ICE exchange\u201d, isn\u2019t discussed here (i.e., how is the presence or absence of an ALG germane to an attacker who is a participant in the ICE exchange) (4) Section 8.\u00a0 Is there a reason why the security considerations from  RFC8445  are not noted as also applying (e.g., Section 19.1 - .4.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-06 22:33:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 18:43:58-07:00",
    "text": "(Arguably a \"discuss discuss\".) If we don't have any worked examples of signatures with message recovery, should we include that possibility in the Internet Standard version of the protocol?\u00a0 Some of the description around how the details of this would work remain unclear to me.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-29 05:19:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-18 06:11:02-07:00",
    "text": "Sorry for the late discuss, however rather than deferring the review two weeks we agreed that I would do a later review.  This relates to the registries created in  RFC 8152 . These registries do exist, however the registry rules will not be documented in the replacement standards track document that is in force. And if you look at the IANA page for the COSE regsistries ( https://www.iana.org/assignments/cose/cose.xhtml#algorithms ), they simply reference back to  RFC 8152  which after approval of this document will be an obsoleted RFC.  Thus, I am of the opinion that the rules for expert review and other registration rules for an IETF created registry should exist in an current in force RFC that is referenced by the registry. Thus, I would propose that the registration rule texts from Section 16 in  RFC 8152  is included in Section 12 of this document and also request the IANA to update the registry references to point to the new document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-08 04:20:36-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 19:07:57-07:00",
    "text": "Are the wrong data structures being referenced or did I misunderstand something? ** Section 5.\u00a0 Per \u201cAbbreviated counter signatures use the structure COSE_Countersign1\u201d, this doesn\u2019t seem consistent with the more detailed write-up in Section 5.2 which says that \u201cThe byte string representing the signature value is placed in the CounterSignature0 attribute\u201d.\u00a0 The document makes no other reference to COSE_Countersign1.\u00a0  The shepherd write-up notes that \u2018one item to note is the decision to keep the context string \"COSE_Countersign1\" for abbreviated countersignatures\u2019.\u00a0 However, I found no such reference in Step 1 of Section 4.4 (page 22) which enumerated the possible strings. ** What is the intended name of the structure for the Counter Signature -- is it COSE_Countersignature or COSE_Countersign? -- Table 1, Section 2, Section 4.4 and Section 5.1 (to include the CDDL) reference COSE_Countersignature but -- Section 5. Per \u201cFull counter signatures use the structure COSE_Countersign \u2026\u201d -- Section 5.1.\u00a0 Per \u201cA tagged COSE_Countersign structure \u2026\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-04-24 08:55:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-07 10:46:17-07:00",
    "text": "What's not clear to me from reading this docment is whether anyone actually does IPsec for DHCP relaying. If so, what configurations do they run it in? If not, will they do so as the result of this document?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-04-20 10:50:50-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-08 13:56:39-07:00",
    "text": "This document says that it \"replaces the text in  RFC3315  Section 21.1.\", but it does not have an Updates tag. It is also contains a large blob of  RFC3315 , with clear explanation of what exactly changed. The writeup says \"Even though this I-D introduces changes to  RFC3315 , the WG doesn't want to enforce IPsec encryption on every DHCPv6 server. Therefore it does not update  RFC3315 .\" -- so, if I'm writing a new DHCPv6 implementation, do I need to support this? The document reads like it tries to update 3315, but the writeup says otherwise -- once published, no-one will read the shepherd writeup. I think that the document itself needs to be clearer that this is an optional extension (so if I want to buy an implementation which does this, I ask for  RFC3315  and RFCxxxx). I also do not understand the relationship between this document (which talks about text  RFC3315 ), and  draft-ietf-dhc-rfc3315bis  (which is currently in WGLC) -- if rfc3315bis is almost done, should this reference that instead? Or should rfc3315bis simply incorporate this?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-01-10 11:40:37-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 04:20:01-08:00",
    "text": "What happens when two deployments independently select the same experiment code point with different semantics? Is there some way to detect that, or do they just get confused? This seems like it it's fine in a closed environment, but unless I'm missing something, there's nothing in this text that actually requires that.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-19 15:53:02-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-18 23:56:29-07:00",
    "text": "Section 3.2 notes that \"the presence of [the Restart] TLV indicates that the sender supports the functionality defined in this document\".\u00a0 But, while that was true for  RFC 5306 , I don't see how it can be true for the extended functionality that's new in this document.\u00a0 It seems on first look that the need for a PR to be acknowledged by a PA means that the routers in question will be able to properly determine full feature support at runtime, in which case this is essentially an editorial issue, but I would like to make sure it's received enough thought, so am raising it as a Discuss point to get the needed discussion. (We will still need to change this text to reflect reality, though.) It's also unclear to me if we need to give more description of the behavior when a router planning to restart does not receive (all) the necessary PAs -- does it cancel the planned restart?\u00a0 Fall back to the regular RR usage? It looks like there's an internal inconsistency between Section 3.2 (\"[w]hen transmitting a TLV multiple flags MUST NOT be set.\") and Section 3.3.2 (\"the IIH is retransmitted with both RR and SA bits set\").",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-09-27 12:07:14-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-26 07:48:42-07:00",
    "text": "This should be quick to resolve and may just need some clarifying text in the draft. I see section 5 has DTLS as a SHOULD and this is stated in the security considerations as well, to be used when privacy and security of original traffic is needed.\u00a0 Section 5 says that DTLS is not needed when encryption is addressed at another layer, is that the only case when it is not needed?\u00a0 If so, can that be made more clear in the document?\u00a0 If not, what other situations result in no need for DTLS? Thank you, Kathleen",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-09-27 10:13:47-07:00",
    "end_reason": "position_updated",
    "start": "2016-09-27 06:21:40-07:00",
    "text": "I just wanted to check something relatively new (to me anyway). This week there was an apparently record-breaking (600+Gbps) DDoS attack on a web site in which GRE traffic is said to have been a significant part of the attack. (See [1] for some not very detailed information.) Is the use of GRE traffic as part of DDoS well known in the relevant communities? If so, are tunnels such as those documented here involved or not? If we don't know, should we try find out before approving this? If we do know, are there additional security considerations needed here? \u00a0  [1]  https://noise.getoto.net/tag/gre-ddos/",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-05-10 07:06:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 06:54:32-08:00",
    "text": "= Section 6 = \"DetNet is provides a Quality of Service (QoS), and as such, does not \u00a0  directly raise any new privacy considerations.\" This seems like a false statement given the possibility that DetNet may require novel flow IDs and OAM tags that create additional identification and correlation risk beyond existing fields used to support QoS today.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-03-25 11:38:10-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 07:56:14-08:00",
    "text": "I support Mirja's and Alissa's DISCUSSes...and have a related set of concerns about the coexistence with non-DetNet traffic and privacy: \u00a73.3.1 talks about what I think is a hard to achieve balance between coexisting with non-DetNet traffic and keeping that traffic from disrupting DetNet flows.\u00a0 Because of the constraints, the intent of prioritizing DetNet flows is clear (and that is ok), but that may result in starvation of non-DetNet traffic...even if the text does explicitly say that it \"must be avoided\". I would like to see the potential case of starving non-DetNet traffic called out somewhere.\u00a0 I'm looking for something similar to the first paragraph in \u00a75, but focused on the non-DetNet traffic. Related to the above is the fact that the identification of flows could be used to specifically *not* include some of them as DetNet flows.\u00a0 This is a variation of the concern outlined in \u00a76, but applied to non-DetNet flows, with the potential starvation mentioned above.\u00a0 Again, I would like to at least see some discussion of this risk.   The use case and problem statement documents outline specific applications that may not have non-DetNet traffic, and the Introduction supports that.\u00a0 However, the architecture described in this document may be used in more general networks to provide guarantees to specific traffic...\u00a0 IOW, even if the intention is there, there is no guarantee that DetNet will only be used in the expected use cases.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-25 15:05:21-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-19 19:43:54-08:00",
    "text": "I note that the DETNET WG is explicitly chartered with a work item for the \"overall architecture: This work encompasses ... and security aspects\". It seems incomplete to specify an architecture for a topic such as deterministic networking without specifically considering what threats are and are not in scope to be protected against.\u00a0 Some easy questions should be whether the system is expected to be robust in the face of an attacker that generates non-DetNet traffic?\u00a0 Or an attacker that generates DetNet traffic in excess of reservations?\u00a0 It can even be a fine engineering goal to produce a solution that only protects against media corruption and hardware crashes and leaves active attacks out of scope, but the actual intended scope of the work needs to be clear.\u00a0 At the other end of the spectrum, protecting against as potent an attacker as a malicious traffic policer is probably a lost cause, especially if the policer is authorized to direct remote nodes to take action to terminate \"misbehaving\" flows. The referenced  draft-ietf-detnet-security  is not at a comparable maturity level to this document and also fails to present a clear threat model for the DetNet architecture.\u00a0 (The section entitled \"Threat Model\" reads as more of a taxonomy of threats than a model for what threats are and are not to be addressed.)\u00a0 It also presents the usage of cryptographic mechanisms as mitigation techniques without provisioning for the prerequisties of such mechanisms (e.g., using HMAC for message integrity protection without mention of infrastructure for distributing the keys for keying the HMAC).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-04-15 04:55:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 05:05:34-08:00",
    "text": "Thanks for addressing the tsv-art review comments\u00a0 (and big thanks to Michael and David!) and all the work done so far! I think the document is in good shape and I only have one minor comment that I would like to see addressed/more explicitly spelled out. However, this should be done quickly with potentially 2-3 small changes in the draft. See below.   Given that DetNet traffic is often assumed to be not congestion controlled, it is important that there is also some network function that makes sure the source traffic stays within the requested bandwidth limit in-order to protect non-Detnet traffic. This is to some extended discussed in section 3.3.2 but I think it should be more clearly spelled out that this would require a rate limiting function at each DetNet source/relay (tunnel ingress). Currently sec 3.3.2 says: \"Filters and policers should be used in a DetNet network to \u00a0  detect if DetNet packets are received on the wrong interface, or at \u00a0  the wrong time, or in too great a volume.\" However, maybe this case of limiting non-congestion controlled traffic (in case the source in not keeping to the limits on purpose/in order to cheat, because it couldn't estimate the needed bandwidth requirement an better, or due to timely fluctuations) could be explained more clearing and the respective requirement to implement rate limiting could be state separately and more strongly...? One related comment on this sentence in Sec 3.1:  \"As DetNet provides allocated resources (including provisioned capacity) \u00a0  to DetNet flows the use of transport layer congestion control \u00a0  [ RFC2914 ] by App-flows is explicitly not required.\" I guess congestion control should still be a requirement if the App-flow also passes not-DetNet-aware segments of the path, e.g. maybe the first hop. Usually use of congestion control for application limited flows is also not a problem if sufficient bandwidth is available. Also note that, as I stated above, the important part for not requiring congestion control is actually not only that resources are allocated but also that rate limiting is in place to make sure resources usage cannot be exceeded above the reserved allocation. Maybe this sentence could also be further clarified in the draft...?  And then one more small comment that is also related. Sec 3.2.2.2 says:  \"If packet replication and elimination is used over paths with \u00a0  resource allocation (Section 3.2.1), ...\" My assumption was that all DetNet traffic is send over pre-allocated resources...? If that is not true that has implication on congestion control and needs some additional considerations. Can you please confirm that and maybe clarify in the draft! Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-09 03:33:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-04 05:53:04-08:00",
    "text": "I have a couple of fairly straightforward things I'd like to briefly discuss... (1) 3.2/Figure 7: A fixed 20 byte SKI being a sha-1 hash of the public key is a bad plan, for all the usual reasons. Why is it ok for that to be hardcoded here when it could change if/when new alg choices are made for the RPKI? If it is not too late then I think you should add a length or alg field to that. If it is too late to do that, then are we really ok that you will need to rev the BGPsec version number in order to get rid of all sha-1 code from your implementation? That seems like a bad plan for a new protocol. (2) Figure 8: It seems to me to be an error to omit the signer's ASN from the signed data and only have that included in the signer's certificate. Why is that intimate level of binding to the RPKI desirable? There may well be reasons but I'm not seeing 'em, and I am recalling that it took a chunk of effort to make CMS less dependent on X.509 for similar reasons (meaning identifying signers exclusively via cert issuer and serial in that case).\u00a0 I would expect that there could be demand to have some level of independence between BGPsec and RPKI for at least internal uses such as those noted in the spec already. (3) section 8: Is there a potential exposure here in that a relying party who emits e.g.\u00a0 certificate status checks or cert retrieval queries for an RPKI cert they've not previously seen is exposing something about the set of paths its traffic is likely to follow. (This is similar to why we have OCSP stapling in the web.) IIRC the RPKI specs may cover this but I suspect it'd be worth noting here as well even if so as this represents exposing something about BGP announcement content to off-path parties which I think is new for BGP. Is that a new thing for BGP? (I think the new aspect to the attack is that a bad actor who has already compromised some AS could more easily spot that traffic from the relying party's AS is likely to transit the compromised AS.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-16 15:21:43-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-09 03:33:05-08:00",
    "text": "I have a couple of fairly straightforward things I'd like to briefly discuss... (1) 3.2/Figure 7: A fixed 20 byte SKI being a sha-1 hash of the public key is a bad plan, for all the usual reasons. Why is it ok for that to be hardcoded here when it could change if/when new alg choices are made for the RPKI? If it is not too late then I think you should add a length or alg field to that. If it is too late to do that, then are we really ok that you will need to rev the BGPsec version number in order to get rid of all sha-1 code from your implementation? That seems like a bad plan for a new protocol. (2) Cleared (3) section 8: Is there a potential exposure here in that a relying party who emits e.g.\u00a0 certificate status checks or cert retrieval queries for an RPKI cert they've not previously seen is exposing something about the set of paths its traffic is likely to follow. (This is similar to why we have OCSP stapling in the web.) IIRC the RPKI specs may cover this but I suspect it'd be worth noting here as well even if so as this represents exposing something about BGP announcement content to off-path parties which I think is new for BGP. Is that a new thing for BGP? (I think the new aspect to the attack is that a bad actor who has already compromised some AS could more easily spot that traffic from the relying party's AS is likely to transit the compromised AS.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-04-18 20:23:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-18 20:22:51-07:00",
    "text": "This should be easy to clean up, and it's entirely possible I am misreading something. But Section 3.4, 2nd and 3rd paragraph seem to be inconsistent in SHOULD vs MUST for block size.\u00a0 I _think_ I'm reading the following: 1. If the client requests a specific block size, the server MUST use that size or a smaller one. 2. Any subsequent requests from the client MUST indicate the same size that the server used 3. But paragraph 3 then says all further requests SHOULD indicate the same size. But if they already MUST indicate the same size as in the initial response, then this SHOULD seems non-constraining at best, and at worst in conflict with 1. (ignoring the last-block size issue for the moment.) 4. Then paragraph 3 goes on to say the server SHOULD use the block size indicated in the request or smaller. This seems to conflict with the MUST in 1. 5.\u00a0 Then it again asserts that the client MUST indicate the same size in subsequent requests, conflicting with the SHOULD in 3., but agreeing with the MUST in 1.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-04-18 20:24:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-04-18 20:23:51-07:00",
    "text": "This should be easy to clean up, and it's entirely possible I am misreading something. But Section 3.4, 2nd and 3rd paragraph seem to be inconsistent in SHOULD vs MUST for block size.\u00a0 I _think_ I'm reading the following: 1. If the client requests a specific block size, the server MUST use that size or a smaller one. 2. Any subsequent requests from the client MUST indicate the same size that the server used 3. But paragraph 3 then says all further requests SHOULD indicate the same size. But if they already MUST indicate the same size as in the initial response, then this\u00a0  SHOULD seems non-constraining at best, and at worst in conflict with 1. (ignoring the last-block size issue for the moment.) 4. Then paragraph 3 goes on to say the server SHOULD use the block size indicated in the request or smaller. This seems to conflict with the MUST in 1. 5.\u00a0 Then it again asserts that the client MUST indicate the same size in subsequent requests, conflicting with the SHOULD in 3., but agreeing with the MUST in 1.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-04-21 07:08:52-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-18 20:24:26-07:00",
    "text": "This should be easy to clean up, and it's entirely possible I am misreading something. But Section 3.4, 2nd and 3rd paragraph seem to be inconsistent in SHOULD vs MUST for block size.\u00a0 I _think_ I'm reading the following: 1. If the client requests a specific block size, the server MUST use that size or a smaller one.  2. Any subsequent requests from the client MUST indicate the same size that the server used 3. But paragraph 3 then says all further requests SHOULD indicate the same size. But if they already MUST indicate the same size as in the initial response, then this\u00a0  SHOULD seems non-constraining at best, and at worst in conflict with 1. (ignoring the last-block size issue for the moment.) 4. Then paragraph 3 goes on to say the server SHOULD use the block size indicated in the request or smaller. This seems to conflict with the MUST in 1. 5.\u00a0 Then it again asserts that the client MUST indicate the same size in subsequent requests, conflicting with the SHOULD in 3., but agreeing with the MUST in 1.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-05-14 07:44:54-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-20 04:04:53-07:00",
    "text": "This is only a minor point, requesting to spell out implicit assumptions explicitly. However, I think it's important to address this before publication. It is not clear in the main part of the doc that this extension to does not change the message transmission method as specified in  RFC7252  (Stop-and-wait retransmission). With my initial ready I assumed that this extension would allow the sending of back-to-back messages. Only by looking at the examples, it got clear to me that this is not the case.  Further, this document does not say anything about reliability. Do block message need to be transmitted reliable (as Confirmable)? If not, this extension could still lead to back-to-back sending and then further guidance on congestion control would be needed.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-16 03:42:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-16 01:49:29-08:00",
    "text": "FC 6125 use needs more details. <>",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-04-24 03:16:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-16 03:42:49-08:00",
    "text": "When referencing  RFC 6125  you need to provide more details. In particular, you need to pretty much answer every question in section 3 of  RFC 6125 :  One example of how this might look like is in Section 9.2 of . For your convenience the relevant text is pasted below: \u00a0  Routers MUST also verify the cache's TLS server certificate, using \u00a0  subjectAltName dNSName identities as described in [ RFC6125 ], to avoid \u00a0  man-in-the-middle attacks.\u00a0 The rules and guidelines defined in \u00a0  [ RFC6125 ] apply here, with the following considerations: \u00a0 \u00a0 \u00a0 Support for DNS-ID identifier type (that is, the dNSName identity \u00a0 \u00a0 \u00a0 in the subjectAltName extension) is REQUIRED in rpki-rtr server \u00a0 \u00a0 \u00a0 and client implementations which use TLS.\u00a0 Certification \u00a0 \u00a0 \u00a0 authorities which issue rpki-rtr server certificates MUST support \u00a0 \u00a0 \u00a0 the DNS-ID identifier type, and the DNS-ID identifier type MUST be \u00a0 \u00a0 \u00a0 present in rpki-rtr server certificates. \u00a0 \u00a0 \u00a0 DNS names in rpki-rtr server certificates SHOULD NOT contain the \u00a0 \u00a0 \u00a0 wildcard character \"*\". \u00a0 \u00a0 \u00a0 rpki-rtr implementations which use TLS MUST NOT use CN-ID \u00a0 \u00a0 \u00a0 identifiers; a CN field may be present in the server certificate's \u00a0 \u00a0 \u00a0 subject name, but MUST NOT be used for authentication within the \u00a0 \u00a0 \u00a0 rules described in [ RFC6125 ]. The only thing missing from the above is explicit mentioning that SRV-ID and URI-ID are not used. (I think the same should apply to your document.)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-07-21 04:08:03-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-24 03:16:18-07:00",
    "text": "Thank you for addressing my DISCUSS about use of  RFC 6125 . I have one\u00a0 new small issue from your recent change in In 5.2.3 (that was addressing my comment to include a response example): the example doesn't include Content-Type and (possibly) Transfer-Encoding header fields. Without these it doesn't look syntactically correct.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-03 11:58:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-02 13:20:42-07:00",
    "text": "This is a \"discuss discuss\" -- it's an important question and I'd like to talk about it, but it's not clear that any change to the document will be needed. Once this (and some of the more substantive items in the Comment section) is resolved, I'd be happy to ballot Yes. The introduction notes as an advantage of JWT that: \u00a0  (d)\u00a0 (collection minimization) The request can be signed by a third \u00a0 \u00a0 \u00a0 \u00a0 party attesting that the authorization request is compliant with \u00a0 \u00a0 \u00a0 \u00a0 a certain policy.\u00a0 For example, a request can be pre-examined by \u00a0 \u00a0 \u00a0 \u00a0 a third party that all the personal data requested is strictly \u00a0 \u00a0 \u00a0 \u00a0 necessary to perform the process that the end-user asked for, \u00a0 \u00a0 \u00a0 \u00a0 and statically signed by that third party.\u00a0 The authorization \u00a0 \u00a0 \u00a0 \u00a0 server then examines the signature and shows the conformance \u00a0 \u00a0 \u00a0 \u00a0 status to the end-user, who would have some assurance as to the \u00a0 \u00a0 \u00a0 \u00a0 legitimacy of the request when authorizing it.\u00a0 In some cases, \u00a0 \u00a0 \u00a0 \u00a0 it may even be desirable to skip the authorization dialogue \u00a0 \u00a0 \u00a0 \u00a0 under such circumstances. I'm pretty uncomfortable about suggesting that the authorization dialogue can/should be skipped; do we need to keep this example? Maybe just talking about what an expected use case could be would help alleviate my unease.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-11 08:52:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-03 11:58:53-07:00",
    "text": "My apologies; my previous position was incomplete.\u00a0 Updated to note namespacing issues, and one minor terminology nit about \"DNS-ID\". There seem to be some pretty serious namespacing issues that are not discussed at all in this document.\u00a0 Specifically, using JWT as a container for OAuth 2.0 authorization request parameters (including extension parameters) introduces the usage of many new names (of JSON name/value pairs) into the JWT claims namespace.\u00a0 Furthermore, the addition is not bounded, as any new OAuth extension parameters are implicitly permitted to be used as well!\u00a0 The IANA Considerations make no mention of the collapsed namespace for JWT claims and OAuth 2.0 (authorization request) parameters, leaving substantial potential for collisions in the future. Relatedly, using \"application/jwt\" as the Content-type of the HTTP response from dereferencing the request_uri with no explicit indication of the type/profile of JWT used (whether in the content type or in the JWT claims themselves) gives some risk of misinterpretation of the content.\u00a0 Consider, for example, when that request_uri is dereferenced not by the authorization server in the process of fulfilling an authorization request, but instead by some other service that expects a different type of JWT. This second point is a \"discuss discuss\" -- it's an important question and I'd like to talk about it, but it's not clear that any change to the document will be needed. The introduction notes as an advantage of JWT that: \u00a0  (d)\u00a0 (collection minimization) The request can be signed by a third \u00a0 \u00a0 \u00a0 \u00a0 party attesting that the authorization request is compliant with \u00a0 \u00a0 \u00a0 \u00a0 a certain policy.\u00a0 For example, a request can be pre-examined by \u00a0 \u00a0 \u00a0 \u00a0 a third party that all the personal data requested is strictly \u00a0 \u00a0 \u00a0 \u00a0 necessary to perform the process that the end-user asked for, \u00a0 \u00a0 \u00a0 \u00a0 and statically signed by that third party.\u00a0 The authorization \u00a0 \u00a0 \u00a0 \u00a0 server then examines the signature and shows the conformance \u00a0 \u00a0 \u00a0 \u00a0 status to the end-user, who would have some assurance as to the \u00a0 \u00a0 \u00a0 \u00a0 legitimacy of the request when authorizing it.\u00a0 In some cases, \u00a0 \u00a0 \u00a0 \u00a0 it may even be desirable to skip the authorization dialogue \u00a0 \u00a0 \u00a0 \u00a0 under such circumstances. I'm pretty uncomfortable about suggesting that the authorization dialogue can/should be skipped; do we need to keep this example?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-23 10:20:07-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 17:05:36-07:00",
    "text": "It's not clear to me that we're really specifying the semantics of a single media-type.\u00a0 The introduction discusses how we may want multiple representations to appear in a sequence, potentially representing different content.\u00a0 Or we may have a set of related representations that conceptually are the same content (but are they literally the same resource, or related content?).\u00a0 And there is yet a third option -- one that I'm not sure I fully understand -- wherein the representation is not important, but rather which format is chosen of the several possibilities, to the extent that extreme compression of the representation is possible, with the compression just outputting the format indicator. I don't see that any of these three cases are mutually compatible with each other -- are we not defining three different semantical representations that share a common syntax?\u00a0 How does a receiver know which semantics to apply, if they share a common media-type codepoint?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-02 07:44:00-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 06:05:07-07:00",
    "text": "Are recursive application of the multipart format allowed? I don't find anyting disallowing that. I just want check that it is intentional before No Objection.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-03-16 07:53:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-03-16 07:52:42-07:00",
    "text": "olding a DISCUSS until the new YANG security considerations template including RESTCONF is agreed upon.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-04-21 09:33:58-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-16 07:53:03-07:00",
    "text": "s agreed during the IESG telechat, holding a DISCUSS until the new YANG security considerations template including RESTCONF is agreed upon.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-03-21 01:15:04-07:00",
    "end_reason": "position_updated",
    "start": "2017-03-10 08:47:05-08:00",
    "text": "This draft does not specify a bootstrapping process (see  RFC 7594  5.1.\u00a0 Bootstrapping Process) and says: \"Pre-Configuration Information: This is not modeled explicitly since bootstrapping information is outside the scope of this data model.\" So when and where and how will this be specified?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-06-22 14:04:14-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-16 02:02:19-07:00",
    "text": "This should be quick to clear up, but the IANA Considerations section has a few issues: Section 5.1 declares a new registry with a Specification Required policy.\u00a0  RFC 8126  explains what this means in its Section 4.6, and notes that this will result in a Designated Expert being appointed, and further stipulates that \"clear guidance to the designated expert should be provided when defining the registry\".\u00a0 However, none is evident here.\u00a0 Was this an oversight? Section 5.2 declares a new registry with a First Come First Served policy.\u00a0  RFC 8126 , Section 4.4, covers this, and says in pertinent part, \"... in addition to the contact person field or reference, the registry should contain a field for change controller.\"\u00a0 That's absent here, so please add one. In Section 5.3, the \"Required Parameters\" and \"Optional Parameters\" need to be \"N/A\", not \"None\".\u00a0 See  RFC 6838 , Section 5.6.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-23 19:02:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 15:37:11-07:00",
    "text": "Thanks to Yoav Nir for the secdir review. I agree with Yoav and would like to see his comment addressed: The document defines a CBOR-encoded problem details structure, similar to the JSON- or XML-encoded structure defined in  RFC 7807 . As such, the security considerations for it mostly mirror those of  RFC 7807 , and that is all that the Security Considerations section says.\u00a0 Following this reference, the Security Considerations section of 7807 urges caution when defining new problem types for fear of leaking sensitive information in the relevant fields of new types. There is, however, a difference between 7807 and this document. In 7807 different problems are identified by \"type\". In this document, there is no explicit type. Instead, there are basic details that are defined, plus a registry of standard and custom extra attributes that can be defined. The security considerations section in 7807 is phrased in terms of new types. Security considerations text written specifically for this documentation would not mention new types (which don't exist), but new detail entries. Still, the message would be the same. When defining new detail entries, care should be taken that they do not leak sensitive information.\u00a0 Yet because of the difference, I believe that the text should be written specifically for this document, not just referenced from 7807.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-09-23 09:14:54-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 00:56:41-07:00",
    "text": "1. I agree with Tim Wicinski's OPS DIR point about IANA. \u00a0 \u00a0 The content appears to be fine, but there are some outdated (the biggest one is \u00a0 \u00a0 5226 replaced by 8126), but its the IANA section which appears the most \u00a0 \u00a0 confusing. \u00a0 \u00a0 7.1 OSPF Router Information (RI) Registry -\u00a0 appears fine \u00a0 \u00a0 7.2 OSPF Tunnel Encapsulation Attribute Sub-TLV Registry \u00a0 \u00a0 This one defines the values being defined/allocated from \"This Document\" but in \u00a0 \u00a0 Section 5, each Sub-TLV is defined in other documents, so it's totally \u00a0 \u00a0 confusing. 2. It's not clear which of the following sub-TLVs are required/relevant/interconnected in the Encapsulation Capability TLV \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 Reserved\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 1\u00a0 \u00a0 Encapsulation\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 2\u00a0 \u00a0 Protocol Type\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 3\u00a0 \u00a0 Endpoint\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 4\u00a0 \u00a0 Color\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 5\u00a0 \u00a0 Load-Balancing Block\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 6\u00a0 \u00a0 IP QoS\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 7\u00a0 \u00a0 UDP Destination Port\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document The only hint is: \u00a0 \u00a0 \u00a0 Value (variable): Zero or more Tunnel Encapsulation Attribute Sub- \u00a0 \u00a0 \u00a0 TLVs as defined in Section 5. Zero? really, what's the point? Now, from an operational point of view, which sub-TLVs are required/make sense? Are some sub-TLVs irrelevant without others? Ex: Color without Encapsulation Could we have multiple identical sub-TLVs? Ex: Color",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-09-18 13:25:43-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 19:49:55-07:00",
    "text": "* There seems to be an difference between this document's definition of sub-TLVs (with 2 octet types and lengths) and those of  RFC5512  (with 1 octet types and lengths). So I am surprised to see the document point to the  RFC5512  based TLVs for both syntax and semantics (Sections 5.1, 5.2, 5.3 ...) . Can you please explain how these sub-TLVs are encoded on the wire to be compatible with this draft?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-03-25 09:38:38-07:00",
    "end_reason": "position_updated",
    "start": "2019-01-10 07:24:47-08:00",
    "text": "orry for the late DISCUSS, but we should discuss collecting versa publishing by IANA of postal information.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-12-02 14:42:09-08:00",
    "end_reason": "position_updated",
    "start": "2017-09-09 11:35:25-07:00",
    "text": "It's not clear to me if the prohibition on leaf-to-leaf communications is intended to be a security requirement. If so, it seems like it needs to explicitly state why it is not possible for ACs which are leaf to pretend to be root. If not, then it should say so. Additionally, this solution appears to rely very heavily on filtering, so I believe some text about what happens during periods of filtering inconsistency (and what the impact on the security is).",
    "type": "Discuss"
  },
  {
    "ad": "Jim Guichard",
    "end": "2023-06-30 05:48:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-01 07:19:56-07:00",
    "text": "I am wondering why this is an informational document when it uses reserved bits from both QUIC and TCP headers (?). If those reserved bits are used by the mechanisms described in this document but there is no \"official\" allocation of the bits then future documents that wish to use these bits will be limited and/or clash with an Informational RFC. Adding a DISCUSS as although this is not a technical area of expertise for me, it seems unusual and I would like to better understand the document track selection.  I also do not see a transport area directorate review and in fact the document shepherd highlights that the document could benefit from such a review. Given that the bits introduced in the document are suggested to be carried in the QUIC and TCP headers using their reserved bits, then a review by the area responsible for those transport protocols seems mandatory.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-08-16 01:49:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-24 06:55:13-07:00",
    "text": "Thanks for working on this specification. I hope it will be helpful for the valid network observer who does the flow measurement (given that the end-points actually implements the markings). Thanks to Colin Perkins for the TSVART review ( https://mailarchive.ietf.org/arch/msg/ippm/OMrRG_0CG8uRHVz0o6ivqRD8T6g/  ) and also Lucas Pardue ( https://mailarchive.ietf.org/arch/msg/ippm/RgtxAHmJfANjlfPkn1Jb4Hbbcs8/  ) for his review of the document. Both reviews had led to changes in the document which should improve and clarify the specification even more. As I agree with both the reviewers , even though I have already see some resolutions, I am holding this discuss to make sure agreed resolutions are landed in the document we approve.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-08-23 14:40:48-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-23 14:39:27-07:00",
    "text": "This is a process DISCUSS. The datatracker indicates that the intended status of this document is Internet Standard.\u00a0 However, two process points are not being followed: 1- The replaced document ( rfc7816 ) is an Experimental RFC.\u00a0 According to  rfc6410 , the Standards Track maturity levels first go through a Proposed Standard. 2-  rfc6410  requires a 4-week IETF LC to move to Internet Standard, but the LC for this document lasted only 2. Moving the intended status of this document to Proposed Standard would be one way to address this DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-08-23 15:08:37-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-23 14:40:48-07:00",
    "text": "This is a process DISCUSS (directed at the responsible AD). The datatracker indicates that the intended status of this document is Internet Standard.\u00a0 However, two process points are not being followed: 1- The replaced document ( rfc7816 ) is an Experimental RFC.\u00a0 According to  rfc6410 , the Standards Track maturity levels first go through a Proposed Standard. 2-  rfc6410  requires a 4-week IETF LC to move to Internet Standard, but the LC for this document lasted only 2. Moving the intended status of this document to Proposed Standard would be one way to address this DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-09-01 13:15:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-24 05:23:10-07:00",
    "text": "Thank you for the work put into this document. A simple but efficient technique. Please find below one blocking DISCUSS point (probably easy to address). Please also address Jean-Michel Combes' INTDR review at  https://datatracker.ietf.org/doc/review-ietf-dnsop-rfc7816bis-10-intdir-telechat-combes-2021-08-20/ Special thanks to Tim Wicinski for his shepherd's write-up notably about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2.1 -- I support Erik Kline's COMMENT on this and am raising it to a blocking DISCUSS. A/ in all the discussion in the last \u00a7, a AAAA would have the same benefit when compared to a NS QTYPE. Or what did I miss ? B/ the last two sentences \"Another potential benefit...happy eyeballs query for the A QTYPE.\" are puzzling as using A QTYPE will actually only cache the A answer for the minimized request and more and more Internet users are using IPv6 nowadays (and possibly even more recursive DNS servers). Hence, I would welcome some discussion in the last \u00a7 about the benefit of using A QTYPE rather than AAAA QTYPE and, as suggested by Erik Kline, please remove the last 2 sentences.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-01-09 05:52:27-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-22 04:55:56-08:00",
    "text": "# GEN AD review of  draft-ietf-lpwan-schc-over-sigfox-18 CC @larseggert ## Discuss ### Section 3.6.1.3.1, paragraph 11 ``` \u00a0 \u00a0  When using the Single-byte SCHC Header for Uplink Fragmentation, the \u00a0 \u00a0  Fragmentation Header MUST be of 8 bit size, and it is composed as \u00a0 \u00a0  follows: \u00a0 \u00a0  *\u00a0 RuleID size: 3 bits \u00a0 \u00a0  *\u00a0 DTag size (T): 0 bit \u00a0 \u00a0  *\u00a0 Fragment Compressed Number (FCN) size (N): 5 bits \u00a0 \u00a0  *\u00a0 As per [ RFC8724 ], in the No-ACK mode the W (window) field is not \u00a0 \u00a0 \u00a0 \u00a0 present. \u00a0 \u00a0  *\u00a0 Regular tile size: 11 bytes \u00a0 \u00a0  *\u00a0 All-1 tile size: 0 to 10 bytes \u00a0 \u00a0  *\u00a0 Inactivity Timer: Application-dependent.\u00a0 The default value is 12 \u00a0 \u00a0 \u00a0 \u00a0 hours. \u00a0 \u00a0  *\u00a0 RCS size: 5 bits ``` The fragmentation header fields in this list add up to much more than 8 bit, some are zero, and for the inactivity timer, no encoded length is given at all? Many similar lists in this document have similar issues.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-02-02 13:29:45-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-29 20:48:26-08:00",
    "text": "** Section 3.2.  \u00a0  Messages sent from the Device to the Network are delivered by the \u00a0  Sigfox network (NGW) to the Network SCHC C/D + F/R through a \u00a0  callback/API with the following information: \u00a0  ...  \u00a0  *\u00a0 Device Geolocation (optional) In some circumstances, sending device location information is privacy sensitive.\u00a0 Please provide a pointer or summary text for the relevant security considerations. ** Section 5.\u00a0 The security considerations describe a collection of security services such as authenticity, confidentiality, and replay protection for the Sigfox protocol.\u00a0 However, none of these appear to be described in in this document and no references are provided. -- Per confidentiality: although not cited, Section 5.3 (\u201cApplicative payload encryption\u201d) of  https://storage.googleapis.com/public-assets-xd-sigfox-production-338901379285/6f9a5819-5aa1-4fde-a2b7-eb1ad5193829.pdf  (which is the PDF link describing v1.6 of the SigFoxx protocol from the URL cited at [sigfox-spec]) says: [snip start] Payload encryption is a procedure that encrypts the payload of applicative messages over the air, in both uplink and downlink communication. It uses an AES128 algorithm in mode CTR with an encryption key (Ke), unique per end-point. The procedure is specified in a dedicated Sigfox specification document. [snip end] What is the \u201cdedicated Sigfox specification\u201d? -- Per the \u201cThe radio protocol authenticates and ensures the integrity of each message\u201d is that described in Section 3.8 of [sigfox-spec]? Please describe these security mechanisms or cite them.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-03 06:05:47-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-12-01 10:18:09-08:00",
    "text": "I support Erik's discuss. I see that Roman has already suggested adding normative language regarding the limitation to a single administrative domain (in addition to the \"MUST filter by default for EBGP sessions\"), which I agree with. However, I think there is an additional consideration regarding the limitation of use to a single administrative domain, wherein the domain of use for the tunnel encapsulation attribute may diverge from the domain of use of segment routing, that seems to place this document in conflict with the requirements of  RFC 8402 .\u00a0 In particular, RFC 8402  says, for SR-MPLS and SRv6, that boundary routers \"MUST filter any external traffic\", and additionally for SRv6 that \"explicit routing information MUST NOT be leaked through the boundaries of the administrered domain\".\u00a0 In \u00a73.7 of this document, though, we find that for the Prefix-SID sub-TLV, \"the receiving BGP speaker need not even be in the same Segment Routing Domain as the tunnel's egress endpoint, and there is no implication that the prefix-SID for the advertised prefix is the same in the Segment Routing domains of the BGP speaker that originated the sub-TLV and the BGP speaker that received it\", which seems to suggest violation of the  RFC 8402  requirement.\u00a0 I think we need to have greater clarity on what relationship is actually intended between the SR domain and the tunnel encapsulation usage domain, and if they are to diverge, we need to both somehow rectify this behavior with RFC 8402  and to very clearly document how the 8402-mandated filtering at the SR domain boundary is supposed to happen when the boundary includes tunneled traffic. I also would like to ensure that we have had adequate discussion of the relationship between this document and  RFC 8365 .\u00a0 The IESG has received comments recently (in the context of a different document) that it is irresponsible to effectively obsolete or deprecate existing work without identifying or explicitly updating such work, and without indicating whose responsibility it is to find discrepancies.\u00a0 That seems like it might apply to what's currently in Appendix A, which on first reading suggests \"there might be a problem here, but we aren't saying exactly what or how to fix it, or even who is going to do that work\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-11 14:58:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-03 06:05:47-08:00",
    "text": "[Updated to remove the point about the \"relationship between this document and  RFC 8365 \"; no other changes] I support Erik's discuss. I see that Roman has already suggested adding normative language regarding the limitation to a single administrative domain (in addition to the \"MUST filter by default for EBGP sessions\"), which I agree with. However, I think there is an additional consideration regarding the limitation of use to a single administrative domain, wherein the domain of use for the tunnel encapsulation attribute may diverge from the domain of use of segment routing, that seems to place this document in conflict with the requirements of  RFC 8402 .\u00a0 In particular, RFC 8402  says, for SR-MPLS and SRv6, that boundary routers \"MUST filter any external traffic\", and additionally for SRv6 that \"explicit routing information MUST NOT be leaked through the boundaries of the administrered domain\".\u00a0 In \u00a73.7 of this document, though, we find that for the Prefix-SID sub-TLV, \"the receiving BGP speaker need not even be in the same Segment Routing Domain as the tunnel's egress endpoint, and there is no implication that the prefix-SID for the advertised prefix is the same in the Segment Routing domains of the BGP speaker that originated the sub-TLV and the BGP speaker that received it\", which seems to suggest violation of the  RFC 8402  requirement.\u00a0 I think we need to have greater clarity on what relationship is actually intended between the SR domain and the tunnel encapsulation usage domain, and if they are to diverge, we need to both somehow rectify this behavior with RFC 8402  and to very clearly document how the 8402-mandated filtering at the SR domain boundary is supposed to happen when the boundary includes tunneled traffic.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-01-09 22:55:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-30 21:28:25-08:00",
    "text": "[ section 3.3.1 ] * The text about \"[a]ny one-octet value can be transported\" leaves me \u00a0 wondering about how values that result in ECN bits being set should be \u00a0 treated. \u00a0 I think there needs to be some recognition here that the DSCP part of \u00a0 the octet is only 6 bits (2474 section 3), and that bits 6 & 7 \"MUST/SHOULD \u00a0 be zero on transmission and MUST/SHOULD be ignored by the recipient\". \u00a0 Another way to ask the question here is: if ECN is not to be specified as \u00a0 part of this octet (and IMHO it should not be), which ranges of 6 bit \u00a0 values are permitted: [0..63], with the understanding this will be shifted \u00a0 before setting the octet, or [0,4,8,12,...,252]?\u00a0 Given the text \"It \u00a0 specifies the setting of the one-octet...\", I think it implies the latter, \u00a0 but some clarification would, I think, be helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-15 08:51:54-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-03 02:52:15-08:00",
    "text": "So this is really to start a discussion of how the framework approach of this document may not be explicit enough on what combination is actually viable combination and have existing specification for how to deal with a number of behaviors for tunnels. So my view after having read this one is that the signalling is specified in a two tier fashion, with an outer encapsulation that can be IPvX, IPvX/UDP for example and then a tunnel protocol like GRE, VXLAN, L2TPv3. So I don't believe all combinations of outer encapsulation and tunnel protocol is actually defined. This document does not provide a table with the reference for where the actual data plan specification for combinations are provided. I think it would be good if there actually existed such a table/list.  The next aspect of this discuss is the difficulty in determining if the provided sub-TLVs are sufficient. I will mention a number of potential ones that I wonder if they are necessary to configure these combinations.  To build on Erik Kline's discuss. So are for all these combinations when IP is the outer encapsulation is the egress ECN behavior to correctly mark or drop inner payload well defined. If the egress is not guaranteed to do the correct, then I think a configuration option is required.  When using UDP encapsulation combined with IPv6 there is the question if one can safely use zero-checksum. Per  RFC 6935  and  RFC 6936  some consideration is needed to determine if the inner payload is safe to combine with zero checksum. So this requires the combination of tunnel protocol and inner payload to determine this. So I think some of these tunnel protocols have text on this, but I don't know which combinations have this specified. And also here arise a question if some of these will also need a configuration option as there exist some inner payloads that could not be safe and thus a different tunnel with checksum enabled may be required.  When using UDP encapsulation I am wondering over source port usage. To my knowledge some of these protocols like VXLAN do defines that source ports are picked randomly to ensure header hashing will provide different values for different inner flows. So is there a need in any of this cases to identify a single source port?  So I at least are unable to determine if this specification are containing all necessary attributes when it doesn't have identification of what combinations it expect to work, and what behavior on the above aspects is just working.  So lets start discussing what needs to be addressed here if any.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-07 14:02:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-03 07:02:48-08:00",
    "text": "Per the conversation on my original COMMENT (thanks for the quick response),  https://mailarchive.ietf.org/arch/msg/idr/hV2t6-8mq2dOvmXO-PvLuiON5o4/ , I'm escalating this item to a DISCUSS.\u00a0  Section 11 However, it is intended that the Tunnel Encapsulation  attribute be used only within a well-defined scope, e.g., within a set of Autonomous Systems that belong to a single administrative entity. As this applicability text should be read as a normative SHOULD, please provide a discussion on the risks of open Internet usage in the Security Considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-07 03:46:13-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-03 03:05:21-07:00",
    "text": "I am very glad to see this document and I will be switching to \"Yes\" once we discuss the following issues: 1) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +-+-+\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |PCC|\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |PCE| \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +-+-+\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | StartTLS\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | msg\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |-------\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0  \\\u00a0  StartTLS\u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \\\u00a0 msg\u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0  \\\u00a0 ---------| \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \\/\u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 /\\\u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0  /\u00a0 -------->| \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |<------\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |:::::::::TLS:::::::::| TLS Establishment \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |:::::Establishment:::| Failure \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |<--------------------| Send Error-Type TBA2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 PCErr\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | Error-Value 3/4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 Figure 2: Both PCEP Speaker supports PCEPS (strict), but cannot \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  establish TLS Firstly, I think you also need to demonstrate a case when the server end of TLS is refusing to startTLS before trying TLS negotiation (e.g. if it doesn't have certificate configured). In this case you need to send PCErr in the clear. I think earlier text suggest that this case is possible. Secondly, does the case depicted on this picture mean that TLS was negotiated successfully, but TLS identities were not successfully verified? (I.e. the PCErr is sent over the TLS layer). If TLS failed to negotiate, you don't have a channel to send data on, as the other end will get confused. I think you just have to close connection in such case. So maybe you need 3 figures describing the above 3 cases. 2) In Section 3.4: \u00a0 \u00a0 \u00a0 \u00a0 +\u00a0 Implementations MAY allow the configuration of a set of \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  additional properties of the certificate to check for a \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  peer's authorization to communicate (e.g., a set of allowed \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  values in subjectAltName:URI or a set of allowed X509v3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Certificate Policies) Can you give an example of what you expect to see in the subjectAltName:URI? Your current text doesn't seem sufficient for interoperability.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-08-07 14:40:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 15:49:06-07:00",
    "text": "-3.4, step 2: \"Peer validation always SHOULD include a check on whether \u00a0  the locally configured expected DNS name or IP address of \u00a0  the peer that is contacted matches its presented \u00a0  certificate.\" Why is that not a MUST? As it is, this need to at least discuss the risks involved if you don't check the identity of the peer cert (here or in the security considerations.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-09-04 20:10:52-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-01 09:38:43-07:00",
    "text": "1. This needs a cite to  RFC 6125  to define how to do name validation. 2. You require TLS_RSA_WITH_AES_128_GCM_SHA256, but this is not consistent with modern recommendations, which are for algorithms that provide forward secrecy. You should be recommending TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 with P-256, which is consistent with the recommendations for TLS 1.3 (and UTA, IIRC). 3, It's clear to me how authentication of the PCE works in that the PCC connects to it using a domain name or IP address and therefore can check the PCC's certificate against that, but it's not clear to me what the PCE does when the client connects? Is it supposed to have a list of valid peers? 4. The error reporting mechanism you describe in S 3.2 is unusual: \u00a0  After the exchange of StartTLS messages, if a PCEP speaker cannot \u00a0  establish a TLS connection for some reason (e.g. the required \u00a0  mechanisms for certificate revocation checking are not available), it \u00a0  MUST return a PCErr message (in clear) with Error-Type set to [TBA2 \u00a0  by IANA] (PCEP StartTLS failure) and Error-value set to: I am not aware of any other protocol that does this, and it's a bit problematic because you either need to (a) require that you always send a TLS alert so that the receiver knows that the next byte is a PCE message or (b) specify some mechanism for demuxing PCE and TLS. Even in the former category, many TLS stacks are greedy about their IO, so they will read the alert + the PCE message and then discard the message. Instead you should either: (a) specify that you always send TLS alerts and don't send PCE errors (TLS alerts are pretty rich) (b) send any post-handshake alerts over the TLS connection. Failing that, you need to provide detailed instructions about how to make this work. 5. It seems like it would be a good idea to specify a pinning mechanism so you could say \"always do TLS in future\". Is that something that was discussed? 6.\u00a0 \u00a0 \u00a0 \u00a0 *\u00a0 TLS with X.509 certificates using certificate fingerprints: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Implementations MUST allow the configuration of a list of \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 trusted certificates, identified via fingerprint of the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Distinguished Encoding Rules (DER) encoded certificate octets. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Implementations MUST support SHA-256 as defined by [SHS] as \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the hash algorithm for the fingerprint. What does \"trusted\" mean here? I think it means \"one I would accept as a counterparty\" rather than \"can sign other certs\". In any case, this must be clear. A bunch of other stuff is underspecified (see below).",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-08-09 08:33:58-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-02 15:40:46-07:00",
    "text": "* Section 3.2: This seems to be overly broad and directly contradicts to what is required by  RFC5440 . \u00a0  A PCEP speaker receiving any other message apart from StartTLS, Open, or \u00a0  PCErr as the first message, MUST treat it as an unexpected message \u00a0  and reply with a PCErr message with Error-Type set to [TBA2 by IANA] \u00a0  (PCEP StartTLS failure) and Error-value set to 2 (reception of any \u00a0  other message apart from StartTLS, Open, or PCErr message), and MUST \u00a0  close the TCP connection. According to  RFC5440 , when a non-Open message is received the PCEP speaker is required to send a PCErr message with Error-Type 1 (\"PCEP session establishment failure\") and Error-value 1 (\"reception of an invalid Open message or a non Open message\"). I think this text needs to be reworded to narrow down the scope of this error. * The fallback procedure after receiving the error code 4 needs to be clarified. Is the response 4 remembered for future connections or is it only limited to a single attempt immediately after the TLS connection establishment failure. i.e. After falling back, does the client ever try to establish a secure connection again?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-10-07 07:19:37-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-28 11:34:41-07:00",
    "text": "Holding this point because we should discuss it; this might be a problem to be solved by a different document, in which case I'll lift it. Section 8 of  RFC8126  says that bis documents should update the reference in IANA registries to replace obsolete documents with not-obsolete ones. It appears that 3658 didn't have a \"bis\" document but clearly was replaced by three others. I don't really understand how they fully obsolete 3658 if there are still registries hanging out there. Regardless, perhaps this draft is an opportunity to update the reference to these registries? Or is 3658 not \"really\" obsolete?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-03-02 07:17:00-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-05 13:53:28-08:00",
    "text": "This is a process DISCUSS. This document replaces  draft-randriamasy-alto-cost-calendar , but this information is not reflected in the datatracker.\u00a0 The individual draft has an IPR declaration attached to it [1], but the failure to link the two documents has resulted in the IPR indication not carrying over.\u00a0  The direct effect is that the IETF Last Call [2] explicitly says that \"No IPR declarations have been submitted directly on this I-D.\" The Shepherd writeup says that \"The entire author team has confirmed conformance with  BCP 78 /79 with the shephered.\" -- but that doesn't indicate whether IPR is present or not, just conformance.\u00a0 In looking through the mailing list archive, I couldn't find mention of the IPR at adoption [3] [4] or at WGLC [5]. The declaration was made early in the process [6], and there was no discussion in the WG about it.\u00a0 I can see how it would be easy to overlook. Nonetheless, it is necessary for the WG (and the IETF as a whole) to explicitly consider the declaration before proceeding with the publication of this document. [1]  https://datatracker.ietf.org/ipr/2392/ [2]  https://mailarchive.ietf.org/arch/msg/alto/LI01TfoTCnJRDImEUXA-9x8KsZ4 [3]  https://mailarchive.ietf.org/arch/msg/alto/xFErWArHhpF-0ZVR_1BAhgzRj3k [4]  https://mailarchive.ietf.org/arch/msg/alto/-D7cj6qoD-Q3ye3rpuj8li2xWms [5]  https://mailarchive.ietf.org/arch/msg/alto/67W_XuMfu7JMXQEEZFLkulw_xBI [6]  https://mailarchive.ietf.org/arch/msg/ipr-announce/lnZ65z15_Dn3bylJp7h9rGHxZFk",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-02-28 08:55:09-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-26 00:56:34-08:00",
    "text": "Very easy-to-fix issue with date format specification: \u2014 Section 5 \u2014 \u00a0  Both extensions need to return calendar start time (calendar-start- \u00a0  time, a point in time), which MUST be specified using the HTTP header \u00a0  fields format specified in [ RFC7231 ] where, however, timestamps are \u00a0  still displayed with the acronym \"GMT\" rather than \"UTC\": \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Date: Tue, 15 Nov 2014 08:12:31 GMT The problem with this text is that 7231 specifies three formats and you don\u2019t make it clear which one you want, other than by example.\u00a0 The lack of a section reference doesn\u2019t help (7231 is not small), but that wouldn\u2019t be sufficient anyway.\u00a0 I suggest this: NEW Both extensions return calendar start time (calendar-start-time, a point in time), which MUST be specified as an HTTP \u201cDate\u201d header field using the IMF-fixdate format specified in Section 7.1.1.1 of [ RFC7231 ].\u00a0 Note that the IMF-fixdate format uses \u201cGMT\u201d, not \u201cUTC\u201d, to designate the time zone, as in this example: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Date: Tue, 15 Nov 2014 08:12:31 GMT END \u2014 Section 5.1.2 \u2014 \u00a0  For example: suppose the \"calendar-start-time\" member has value \"Mon, \u00a0  30 Jun 2014 at 00:00:00 GMT\", the \"time-interval-size\" member has That isn\u2019t a valid calendar-start-time value unless you remove \u201c at\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-12-04 20:35:56-08:00",
    "text": "Thanks for the work on this document. I see value, but have a couple of points I think need to be resolved prior to publication: \u00a73.1, definition of \"time-interval-size\": What is the reasoning behind using a string to define the unit? That requires text parsing/comparison to determine the interval. I assume this is intended more for machine use than for human use. Did the working group consider making this a multiple of some primitive time interval? E.g. number of seconds, or perhaps number of minutes? it seems like that would be easier (and therefore less error prone) to interpret. If there is a reason to use a text field, is there an enumeration of legal unit values? Can I use \"12 parsecs\"? \u00a74.1.2, last paragraph: \"The ALTO Client thus may use the same calendar for the next 4 days starting at \"calendar-start-time\" and will only need to request a new one for Friday July 4th at 00:00:00 GMT.\" This implies that if an ALTO server delivers a calendar with a long duration, it cannot make changes to the metrics in that calendar, or if it does make them it cannot expect the client to learn about those changes. Is that the intent? If so, it seems to contradict language in the security considerations (\u00a76) that future events may change and that the client should ensure information updates. (The operational considerations [\u00a77] also say the client does not need to query again during the calendar duration.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-09 17:20:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-03 14:14:36-08:00",
    "text": "hat's the justification for removing the 'constraints' field ofReqEndpointCostMap, compared to RFC 7285?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-06-02 06:27:39-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-02 01:40:04-07:00",
    "text": "Thanks for the effort to produce\u00a0 this\u00a0 YANG model, I always fascinate by the work done in creating the YANG models. I have found inconsistencies in the classification of normative references and informative references, hence, would like to discuss those. Some examples below- - in the terminology section while\u00a0 [ RFC6241 ], [ RFC7950 ], [ RFC8466 ], [ RFC4026 ], and [ RFC8309 ] are normative references, [ RFC8969 ] and [ RFC8340 ] are not. But clearly this document uses terms defined in those documents and I as a reader had to open those RFCs to understand what the terms are and without that I would not be possible to understand this document. - sometimes the this document is correctly referring to other documents as normative, as terms or processes are defines there but sometimes it is not. for example - \u00a0 \u00a0 'signaling-option': Indicates a set of signaling options that are specific to a given VPN network access, e.g., a CE ID ('ce-id' identifying the CE within the VPN) and a remote CE ID as discussed in Section 2.2.2 of [ RFC6624 ]. Now, without understanding what is discussed or defined in  RFC6624  it was hard for me to understand the node/leaf mentioned in this document. Thus, I felt\u00a0 RFCC6624 should be a normative reference but it was not.  - The reference modules from this document cannot be informative reference, can they? For example in section 8.1 it says - \u00a0  This module references [ RFC3032 ], [ RFC4446 ], [ RFC4448 ], [ RFC4553 ], [ RFC4618 ], [ RFC4619 ], [ RFC4717 ], [ RFC4761 ], [ RFC4816 ], [ RFC4842 ], and [ RFC5086 ]. however,  RFC4842  and  RFC5086  is informative reference. I would say, please go through the document and correctly categorise all the references.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-06-27 05:51:10-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-05 05:03:39-07:00",
    "text": "Thank you for a well written document. I have a small list of questions/comments, which I would like to discuss before recommending approval of this document: 1) 3.3.2.\u00a0 Deleting Cells \u00a0  o\u00a0 The CellList in a 6P Request (2-step transaction) or 6P Response \u00a0 \u00a0 \u00a0 (3-step transaction) MUST either be empty, contain exactly \u00a0 \u00a0 \u00a0 NumCells cells, or more than NumCells cells. What is the meaning of \"more than NumCells cells\" in case of DELETE? \u00a0 \u00a0 \u00a0 The case where the \u00a0 \u00a0 \u00a0 CellList is not empty but contains less than NumCells cells is not \u00a0 \u00a0 \u00a0 supported. 2) 3.4.7.\u00a0 Handling Error Responses  How should unrecognized error codes be treated by recipients? For example if one of the nodes is implementing an extension and the other node doesn't support such extension.  I think adding some text to this section would help. 3) 4.2.\u00a0 Requirements for an SF \u00a0  o\u00a0 MAY redefine the format of the CellList field. \u00a0  o\u00a0 MAY redefine the format of the CellOptions field. \u00a0  o\u00a0 MAY redefine the meaning of the CellOptions field. I am a concerned about interoperability problems that might result from these requirements. Can you elaborate on what kind of format changes you are expecting? Wouldn't such changes require some sort of extension (e.g. use of a new extended ADD command)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-07-03 19:45:57-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-02 15:44:55-07:00",
    "text": "Section 3.5 states: \u00a0  [...] When link-layer \u00a0  security is enabled, the 6P messages MUST be secured. but Section 5 (the Security Considerations) says: \u00a0  6P messages are carried inside 802.15.4 Payload Information Elements \u00a0  (IEs).\u00a0 Those Payload IEs are encrypted and authenticated at the link \u00a0  layer through CCM* [CCM-Star]. implying that this message protection is always enabled.\u00a0 So, which is it -- always-on, or (application)-controlled? If use of link-layer security is optional, then the security considerations for the case without link-layer security should be documented. Separately, Section 3.2.2 describes the generic message format, but only for version 0. Some indication should be given as to which aspects of the format are required to be invariant across all versions of 6P (and thus which aspects are potentially specific to version 0). Some readers might assume that only the version nybble is invariant (though there also seems to be a requirement in Section 3.4.1 that the RC_ERR_VERSION response remain invariant to some extent).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-06-09 05:42:07-07:00",
    "end_reason": "position_updated",
    "start": "2017-06-07 14:52:36-07:00",
    "text": "Picking up on the thread that started with the Gen-ART review, I'm not clear on the position of this document when it comes to repeatability. If all of the parameters listed in Section 3.3 (assuming they apply) are configured and documented, is it assumed that the benchmarks will be repeatable and comparable with hardware implementation benchmarks? Or is the position of the document that the benchmarks are not likely to be repeatable/comparable in some (many?) cases, given the increase in complexity? Or that more work needs to be done (outside the specification process) to achieve repeatability? I think this needs to be more clear in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-04-10 11:17:44-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-07 22:44:05-07:00",
    "text": "\u2014 Section 6.4 \u2014 Adding to what Mirja notes about a two-year term for the IESG appointee: the text here clearly assumes it will be the IETF Chair, allows it not to be, but makes that situation awkward.\u00a0 Each IESG should be able to change the appointment if it thinks it appropriate.\u00a0 In particular, we chose the IETF chair this time to maintain continuity with the transition, but we might prefer, once the startup tasks are done, to move to someone else in order to lighten the load on the IETF Chair position.\u00a0 I think such delegation is important. So for a number of reasons, a one-year term makes more sense, perhaps with text encouraging reappointment for two or three years, would be better (along with appropriate changes to term limits in 6.5 to specify years rather than terms).\u00a0 Did the working group specifically discuss and reject this?\u00a0 Or was it just aligned to the IETF Chair\u2019s term without giving consideration to these points?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-04-09 03:24:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-09 03:01:57-07:00",
    "text": "Why isn't IRTF disucssed in this section, or having its own section of similar nature?  4.6.\u00a0 Relationship of the IETF LLC Board to the IETF Leadership \u00a0  The IETF LLC Board is directly accountable to the IETF community for \u00a0  the performance of the IASA 2.0.\u00a0 However, the nature of the Board's \u00a0  work involves treating the IESG and IAB as major internal customers \u00a0  of the administrative support services.\u00a0 The Board and the IETF \u00a0  Executive Director should not consider their work successful unless \u00a0  the IESG and IAB are also satisfied with the administrative support \u00a0  that the IETF is receiving. Can someone please explain why the IETF LLC role for IRTF are almost not at all described? For example is IRTF not a significant internal customer?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-04-11 04:18:43-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-09 03:24:07-07:00",
    "text": "Having not followed this at all I do see some question marks in regards to the IRTF that I would like to have clarification on thus the Discuss position. Why isn't IRTF disucssed in this section, or having its own section of similar nature?  4.6.\u00a0 Relationship of the IETF LLC Board to the IETF Leadership \u00a0  The IETF LLC Board is directly accountable to the IETF community for \u00a0  the performance of the IASA 2.0.\u00a0 However, the nature of the Board's \u00a0  work involves treating the IESG and IAB as major internal customers \u00a0  of the administrative support services.\u00a0 The Board and the IETF \u00a0  Executive Director should not consider their work successful unless \u00a0  the IESG and IAB are also satisfied with the administrative support \u00a0  that the IETF is receiving. Can someone please explain why the IETF LLC role for IRTF are almost not at all described? For example is IRTF not a significant internal customer? Also, what is the relation between the IRTF and IETF community? As the IETF community does not appear to have a definition, it is not possible to determine if IRTF is counted as part of the IETF community or not. In my thinking the IETF and IRTF communities are not the same set, and it is not obvious that IETF community is the super set.  I think some clarification on the IRTFs relation are needed in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-02-17 07:39:42-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 08:39:25-08:00",
    "text": "I'd started balloting this as Abstain, but while writing up the ballot I realized that it's important enough that it deserves to be DISCUSSed. This is clearly clever, but feels to me like it might fall into \"Oo, you are so sharp you\u2019ll cut yourself one of these days\"[0] territory. I'm not saying that the \"v4-via-v6\" is a *bad* idea, but I really don't think that it should be introduced / documented in a Standards Track Babel document - it touches core plumbing, and should be discussed and documented in a V6OPS (or 6MAN) document, and then this document includes it by reference. If this was only ever going to used in Babel environments I'd be much less concerned, but I suspect (hope?) that future solutions will want to do very similar things, and that it needs to be reviewed with an assumption that it might get widely used. It should documented in a \"self contained\" manner so it can be cleanly referenced - at the moment, a reference would need to point at bits of Section 1 and 3, and there is some feeling of \"this is probably safe, the 192.0.0.8 bit might make operations / debugging a bit harder, but... \u00af\\_(\u30c4)_/\u00af\" If this has already received significant discussion in V6OPS / similar, or if it is already clearly documented elsewhere[1], I'll clear my DISCUSS and Abstain or support it. I'm sure that this DISCUSS will be frustrating to the authors/WG - I'm doing so because I'd like to see this technique more able to be used (and make sure that there aren't any sharp pointy bits), not because I think it's a bad idea...  [0]: quote from Terry Pratchett, Thief of Time [1]: I suspect it is already documented somewhere, but the closest I can think is  RFC7600  - \"IPv4 Residual Deployment via IPv6 - A Stateless Solution (4rd)\", an Experimental document which is noticeably different to this. If it *is* already documented somewhere else though, then why is this not just referencing that instead?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-13 19:50:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 12:31:36-07:00",
    "text": "Thanks for this document; it's generally in good shape even though I do want to discuss a few specific points. (1) I'm a bit confused by the indication that we can use linkIds to link to a vCard representation of a participant or location -- if I understand correctly that representation would occupy the \"description\" property of the linked object, but the \"description\" is (at least for locations) supposed to be \"human-readable\", which is perhaps only debatably an apt description of a vCard object. (2) Given the language in Section 1.4.7 about needing to denote on a per-object basis when Ids have semantic meaning outside of the object in which they are defined, I think we need a stronger/clearer statement in Section 4.2.5 that the location Ids have global semantics within a calendar, Section 4.4.5 that participant Ids have global semantics, within a calendar, etc.\u00a0 (My preference would be to reverse the sense of the language in \u00a71.4.7 rather than add language to each instance of Ids with global semantics; see COMMENT.) (3) We may want to discuss the scheduleSequence semantics/usability in the face of a user/\"participant\" that has multiple clients.\u00a0 It seems to me that there is not much preventing the different clients from sending (different) responses that use the same sequence number, and I'm also not sure whether the client is supposed to keep local state on what sequence number to use next or just to increment any value received from the server. (4) I strongly recommend that all the examples not reuse UUIDs for different things (e.g., I see \"2a358cee-6489-4f14-a57f-c104db4dc2f1\" as all of: simple event, location (FRA Airport), location (Math lab room 1), location (Big Auditorium), and virtualLocation (ChatMe).\u00a0 The Section 6.9 example at least rises to Discuss-level (IIUC) as inconsistent with the protocol requirements, since the location id is used for two different locations in sibling events. (5) Additionally, the Section 6.3 example seems malformed, since the \"entries\" array contains as its second element a key/value pair, not a (jstask) object.\u00a0 (Erik noted this as a Comment-level point, it seems, so this is more a note to myself to confirm that it's fixed than informing you of the issue.) (6) Can we briefly discuss the use of the \"/\" character in time zone identifiers in \u00a74.7.2?\u00a0 Specifically, this text: \u00a0  o\u00a0 It MUST start with the \"/\" character (ASCII decimal 47; also see \u00a0 \u00a0 \u00a0 Sections 3.2.19 of [ RFC5545 ] and 3.6. of [ RFC7808 ] for discussion \u00a0 \u00a0 \u00a0 of the forward slash character in time zone identifiers). (a) I see no discussion of the forward slash character in section 3.6 of  RFC 7808 . (b) Also, Section 3.2.19 of  RFC 5545  seems to basically be saying \"there might one day be one (or more!) global registry for time zones, but we don't know of one and can't point you to it\" ... is this really the semantics we want to continue to enshrine?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-29 21:53:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 18:45:05-07:00",
    "text": "I think we need to check the [MAC] reference; following links (and chasing redirects) seems to only find a 1985 publication that talks about DES, with no mention of AES-CBC-MAC.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-11-29 18:26:46-08:00",
    "end_reason": "position_updated",
    "start": "2017-11-29 13:07:50-08:00",
    "text": "(I want to \"discuss\" the following\u00a0 DISCUSS point. If the answer is that this is by design, and the working group thinks that the operational aspects are reasonable, then I will clear.) This extension places normative requirements on any upstream server or relay, which may or may not implement this spec.\u00a0 It further appears that if you try to use this extension without that support, things will break. That seems to require at least an update to the DCHP and DCHPv6 RFCs[1], and some method of discovery or fallback would be helpful. Section 5.4 discusses this a little bit, but I think it needs to talk about what to do when things fail. \"Turn off the feature if you don't get DHCP responses\" doesn't seem satisfying. [1] I see 3.1 and 3.2 make changes to 2131 and 3315, so it seems an \"UPDATES... \" tag is needed one way or another.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2021-03-12 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-01-21 06:52:17-08:00",
    "text": "I realize this was discussed during IETF last call, but the document still seems unclear on whether the contents of security.txt are meant to be consumed by a human or a machine. In some places the syntax of fields is specified in detail, which would imply machine readability is expected. The ABNF is provided, although it is not normative. The registry policy does not require any formal specification of the format of new fields nor a requirement that field formats even be documented. In short, I can't tell whether security.txt files are meant to be machine-consumable. If they are, then the registry entries need to be more tightly specified and the ABNF should probably be normative. If they're not, I'm not sure why the field definitions are constrained to specific formats beyond saying whether they should be URIs or free text.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-03-12 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-01-19 09:58:59-08:00",
    "text": "I have a few issues I\u2019d like to get resolve before I move to \u201cno objection\u201d.\u00a0 I think it will be an easy discussion and quick resolution. \u2014 Section 3.1 \u2014 \u00a0  A \"security.txt\" file that is found in a file system MUST only apply \u00a0  to the folder in which it is located and that folder's subfolders. \u00a0  The file does not apply to any of the folder's parent or sibling \u00a0  folders. You don\u2019t say what happens if there are nested security.txt files.\u00a0 What\u2019s the scope in this situation (which file applies to folder1; which applies to folder1/subfolder)?: /example/security.txt /example/folder1/ /example/folder1/security.txt /example/folder1/subfolder/ I think the document needs to make this clear. \u00a0  # This security.txt file applies to IPv4 address of 192.0.2.0. \u00a0  https://192.0.2.0/.well-known/security.txt I\u2019m uncomfortable with trying to restrict the scope depending upon how the file was retrieved.\u00a0 If  www.example.com  resolves to 192.0.2.0, then it should not matter whether the file is retrieved via\u00a0 or\u00a0 (or via the corresponding v6 address). \u2014 Section 3.6 \u2014 Your examples lack the EXPIRES field that you say MUST be present. \u2014 Section 5 \u2014 \u00a0  The expected file format of the security.txt file is plain text (MIME \u00a0  type \"text/plain\") as defined in section 4.1.3 of [ RFC2046 ] and is \u00a0  encoded using UTF-8 [ RFC3629 ] in Net-Unicode form [ RFC5198 ]. In Section 3 you say that for HTTP: \u00a0  It MUST have a Content-Type of \"text/plain\" with the \u00a0  default charset parameter set to \"utf-8\" (as per section 4.1.3 of \u00a0  [ RFC2046 ]). It would be best to have the format requirement be consistent, however it\u2019s retrieved, so \u201cMUST\u201d (rather than \u201cexpected\u201d) is right, no? The ABNF needs some work.\u00a0 DISCUSS-level issues here, with less important ones below: \u00a0 signed\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 sign-header unsigned sign-footer No, the signed body doesn\u2019t just have a header and footer around the unsigned plain text.\u00a0 A signed body would have an unsigned body, *followed by* a sign-header, a signature, and a sign-footer. \u00a0 unsigned\u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 *line (contact-field eol) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line (expires-field eol) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line [lang-field eol] *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; order of fields within the file is not important I found this confusing, with \u201c*line\u201d repeated all over the place and with \u201ccontact-field\u201d both here and in the \u201cfield\u201d construct, but as I worked it out I see that it\u2019s correct (though defnitely confusing).\u00a0 But while the order of the fields mostly doesn\u2019t matter, the order of the Contact fields, if there are more than one, does matter.\u00a0 So you\u2019ll have to tweak this a bit. Give the above, I suggest this: \u00a0 unsigned\u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (contact-field eol) ; one or more required \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (expires-field eol) ; exactly one required \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [lang-field eol] ; exactly one optional \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; order of fields within the file is not important \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; except that if contact-field appears more than once \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; the order of those indicates priority (Section 3.5.3) \u00a0 field\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 =\u00a0 ; optional fields \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ack-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 can-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 contact-field / ; optional repeated instances \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 encryption-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 hiring-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 policy-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ext-field What do you think?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-24 11:02:56-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-22 02:52:17-07:00",
    "text": "Taking over Alissa's discuss, because I see no changes in -11 related to it: > I realize this was discussed during IETF last call, but the document still > seems unclear on whether the contents of security.txt are meant to be consumed > by a human or a machine. In some places the syntax of fields is specified in > detail, which would imply machine readability is expected. The ABNF is > provided, although it is not normative. The registry policy does not require > any formal specification of the format of new fields nor a requirement that > field formats even be documented. In short, I can't tell whether security.txt > files are meant to be machine-consumable. If they are, then the registry > entries need to be more tightly specified and the ABNF should probably be > normative. If they're not, I'm not sure why the field definitions are > constrained to specific formats beyond saying whether they should be URIs or > free text.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-01-22 21:02:11-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-01-20 21:21:53-08:00",
    "text": "Sorry to pile on, but I'm really not clear on the whole filesystem portion of this. \u00a0  A \"security.txt\" file that is found in a file system MUST only apply \u00a0  to the folder in which it is located and that folder's subfolders. \u00a0  The file does not apply to any of the folder's parent or sibling \u00a0  folders. I take this to mean if I want to report a vulnerability related to the filesystem or something in it (a vulnerable binary, perhaps, or a writable password file, I should look for \"security.txt\" in the directory of interest and use that one; if it's missing, I walk upwards until I find one, and use the first one I found.\u00a0 (If that's not correct, then this needs to be clarified, or given the other DISCUSSes, it may need to be clarified anyway.) What if I want to report something unrelated to the filesystem?\u00a0 Suppose I somehow acquire a root shell on a machine I shouldn't be able to access, and that process has no current working directory.\u00a0 I look around and find \"security.txt\" files in several directories.\u00a0 Which one do I use?\u00a0 Sitting at a shell prompt doesn't automatically map to a place in the filesystem tree where I should start looking.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-03-31 11:51:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-22 21:02:11-08:00",
    "text": "Sorry to pile on, but I'm really not clear on the whole filesystem portion of this. \u00a0  A \"security.txt\" file that is found in a file system MUST only apply \u00a0  to the folder in which it is located and that folder's subfolders. \u00a0  The file does not apply to any of the folder's parent or sibling \u00a0  folders. I take this to mean if I want to report a vulnerability related to the filesystem or something in it (a vulnerable binary, perhaps, or a writable password file), I should look for \"security.txt\" in the directory of interest and use that one; if it's missing, I walk upwards until I find one, and use the first one I found.\u00a0 (If that's not correct, then this needs to be clarified, or given the other DISCUSSes, it may need to be clarified anyway.) What if I want to report something unrelated to the filesystem?\u00a0 Suppose I somehow acquire a root shell on a machine I shouldn't be able to access, and that process has no current working directory.\u00a0 I look around and find \"security.txt\" files in several directories.\u00a0 Which one do I use?\u00a0 Sitting at a shell prompt doesn't automatically map to a place in the filesystem tree where I should start looking.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-04-22 02:13:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-21 02:14:28-08:00",
    "text": "Hi, Thank you for this document.\u00a0 I like that it provides a fairly simple solution to providing vulnerability reporting information, although I also have some sympathy with the observation that if the server is compromised then security.txt could also be compromised. However, I have a concern about the document both being machine readable and also including an expiry date.\u00a0 This would seem to offer an easy mechanism to probe websites for those that have out of date security.txt files and hence may have more lax security practices, or potentially help provide indirect information about what software versions a website might be using.\u00a0 Alternatively, this will end up as Barry has suggested, with lots of old expiry dates. Arguably, the best alternative might be just to not provide a date at all, and rely on the humans to check the provenance of the information, and treat it with suitable caution.\u00a0 An alternative possibility could be just to define a field for when the information was last updated.\u00a0 This doesn't go out of date, but helps provide some clue as to whether the information might be stale or not. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-20 16:45:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-01-20 15:29:00-08:00",
    "text": "** The concept of operations for the file-based approach seems under-specified in a few ways: -- Section 3.1 says: A \"security.txt\" file that is found in a file system MUST only apply to the folder in which it is located and that folder's subfolders. The file does not apply to any of the folder's parent or sibling folders. Unless I missed it, a \u201cuse the most specific directory rule\u201d doesn\u2019t appear to be explicitly stated and there didn\u2019t seem to be a restriction on the number of security.txt files in a filesystem.\u00a0 That is, multiple security.txt seem like they could apply.\u00a0 Assume: (1) /opt/foo/security.txt (2) /opt/foo/bar/security.txt Does security.txt (1) and (2) apply to /opt/foo/bar? How is one intended merge the contents of two files? -- Is the thinking that software publisher going to package a security.txt and put it in some install directory on an end-point (like a SWID)? Or is it more likely to go into a source tar ball or seen only when you \u201cgit clone\u201d a repo (like a  README.md )? -- If it will be in a package, is there an intent to relate any integrity protection of the overall package with the recommend openpgp practices described in this document?\u00a0 If one is signature is invalid does that say anything about the other? -- If it will be in a package, then is the guidance in Section 4.2 appropriate (File systems SHOULD place the \"security.txt\" file under the root directory; e.g., \"/security.txt\", \"C:\\security.txt\") unless we\u2019re assuming some container/chroot-like strategy? -- If an end-point maintainer wants to implement a different policy, is that maintainer supposed to modify/replace the file or put another instance of that file in an alternate directory? ** Section 3.5.2. Per \u201cThe purpose of this field is to allow a digital signature to be applied to the locations of the \"security.txt\" file\u201d, if a security.txt file is retrieved over https via \u201cURL-A\u201d, and the Canonical field does not contain URL-A, should this file be trusted?\u00a0 Same with a file system directory.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-13 07:42:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-01-20 16:45:40-08:00",
    "text": "(Updated)  ** The concept of operations for the file-based approach seems under-specified in a few ways: (After reviewing the other ballot positions of my peers, I believe this first item is the same issue as raise by Barry) -- Section 3.1 says: A \"security.txt\" file that is found in a file system MUST only apply to the folder in which it is located and that folder's subfolders. The file does not apply to any of the folder's parent or sibling folders. Unless I missed it, a \u201cuse the most specific directory rule\u201d doesn\u2019t appear to be explicitly stated and there didn\u2019t seem to be a restriction on the number of security.txt files in a filesystem.\u00a0 That is, multiple security.txt seem like they could apply.\u00a0 Assume: (1) /opt/foo/security.txt (2) /opt/foo/bar/security.txt Does security.txt (1) and (2) apply to /opt/foo/bar? How is one intended merge the contents of two files? -- Is the thinking that software publisher going to package a security.txt and put it in some install directory on an end-point (like a SWID)? Or is it more likely to go into a source tar ball or seen only when you \u201cgit clone\u201d a repo (like a  README.md )? -- If it will be in a package, is there an intent to relate any integrity protection of the overall package with the recommend openpgp practices described in this document?\u00a0 If one is signature is invalid does that say anything about the other? -- If it will be in a package, then is the guidance in Section 4.2 appropriate (File systems SHOULD place the \"security.txt\" file under the root directory; e.g., \"/security.txt\", \"C:\\security.txt\") unless we\u2019re assuming some container/chroot-like strategy? -- If an end-point maintainer wants to implement a different policy, is that maintainer supposed to modify/replace the file or put another instance of that file in an alternate directory? ** Section 3.5.2. Per \u201cThe purpose of this field is to allow a digital signature to be applied to the locations of the \"security.txt\" file\u201d, if a security.txt file is retrieved over https via \u201cURL-A\u201d, and the Canonical field does not contain URL-A, should this file be trusted?\u00a0 Same with a file system directory.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-24 10:54:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-13 07:42:28-07:00",
    "text": "(Updated for -11)  ** Section 3.5.2. Per \u201cThe purpose of this field is to allow a digital signature to be applied to the locations of the \"security.txt\" file\u201d, if a security.txt file is retrieved over https via \u201cURL-A\u201d, and the Canonical field does not contain URL-A, should this file be trusted?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-10 10:40:51-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-01-08 09:51:40-08:00",
    "text": "It's not really clear to me that the question of Updating 7432 has been settled by the responses to the directorate reviews; I've noted a few places in the text that are problematic in this regard, in the COMMENT section. I'm a little worried that we're setting future extensions up for a combinatoric explosion of required analysis, by requiring new capabilities and DF algorithms to determine their applicability/compatibility with all previously defined mechanisms of the other type.\u00a0 But maybe there's some easy math to show that it won't be too bad.\u00a0 Let's have a discussion about  this topic, even if we don't end up needing to make any changes to the  document as a result.\u00a0 (I do note that this explosion would not really happen if we combined the two into a single enumerated codepoint space that combines DF algorithm with the enablement state of all then-defined feature flags.) Wection 3.3 \u00a0  Section 7.6 of [ RFC7432 ] describes how the value of the ES-Import \u00a0  Route Target for ESI types 1, 2, and 3 can be auto-derived by using \u00a0  the high-order six bytes of the nine byte ESI value. The same auto- \u00a0  derivation procedure can be extended to ESI types 0, 4, and 5 as long \u00a0  as it is ensured that the auto-derived values for ES-Import RT among \u00a0  different ES types don't overlap. How do I ensure that the auto-derived values don't overlap? Section 4.2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The ESI value MAY be set to all 0's in the Weight \u00a0  function below if the operator so chooses. I'm not 100% sure I'm interpreting this correctly, but this sounds like a piece of device-specific configuration (i.e., configured by the operator) that must be the same across all devices for correct operation, but is not covered by the advertisement of the DF Election Exctended Community.\u00a0 This would decrease the robustness of the system to basically the \"experimental\" level of DF election algorithm 31, which also relies on universal agreement of manual configuration.\u00a0 Is this actually something we want to include? Section 5 \u00a0  The AC-DF capability MAY be used with any \"DF Alg\" algorithm. It MUST As written, this suggests that it is true for any current or future algorithm, which is in conflict with the text in Section 3.2 that notes that \"for any new DF Alg defined in future, its applicability/compatibility to the existing capabilities must be assessed on a case by case basis.\"\u00a0 It seems more prudent to make the assessment after the relevant technologies are both extant, so I would suggest this be non-normative text, perhaps \"the AC-DF capability is expected to be of general applicability with any future 'DF Alg' algorithm\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-01-24 08:32:40-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-10 10:40:51-08:00",
    "text": "It's not really clear to me that the question of Updating 7432 has been settled by the responses to the directorate reviews; I've noted a few places in the text that are problematic in this regard, in the COMMENT section. [concerns about combinatoric explosion were overblown; removed] Section 3.3 \u00a0  Section 7.6 of [ RFC7432 ] describes how the value of the ES-Import \u00a0  Route Target for ESI types 1, 2, and 3 can be auto-derived by using \u00a0  the high-order six bytes of the nine byte ESI value. The same auto- \u00a0  derivation procedure can be extended to ESI types 0, 4, and 5 as long \u00a0  as it is ensured that the auto-derived values for ES-Import RT among \u00a0  different ES types don't overlap. How do I ensure that the auto-derived values don't overlap? Section 4.2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The ESI value MAY be set to all 0's in the Weight \u00a0  function below if the operator so chooses. I'm not 100% sure I'm interpreting this correctly, but this sounds like a piece of device-specific configuration (i.e., configured by the operator) that must be the same across all devices for correct operation, but is not covered by the advertisement of the DF Election Exctended Community.\u00a0 This would decrease the robustness of the system to basically the \"experimental\" level of DF election algorithm 31, which also relies on universal agreement of manual configuration.\u00a0 Is this actually something we want to include? Section 5 \u00a0  The AC-DF capability MAY be used with any \"DF Alg\" algorithm. It MUST As written, this suggests that it is true for any current or future algorithm, which is in conflict with the text in Section 3.2 that notes that \"for any new DF Alg defined in future, its applicability/compatibility to the existing capabilities must be assessed on a case by case basis.\"\u00a0 It seems more prudent to make the assessment after the relevant technologies are both extant, so I would suggest this be non-normative text, perhaps \"the AC-DF capability is expected to be of general applicability with any future 'DF Alg' algorithm\".",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-12-15 07:17:59-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 06:54:03-08:00",
    "text": "Be ye not afraid -- see  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/  on handling ballots, especially DISCUSS ballots... Can the IETF actually deprecate / make a protocol historic? (as stated in \"Internet Key Exchange version 1 (IKEv1) has been deprecated\" and \"IKEv1 has been moved to Historic status.\") I agree that **making the documents that describe these** be historic is the right thing to do, and also that the IETF can strongly recommend that people don't use/deploy/whatever IKEv1, but I don't really know if we (or anyone) have the power to deprecate a protocol. We are not the protocol police, and we cannot instruct people to e.g deploy protocol foo, so I don't know if we can deprecate a protocol either -- but I suspect that this might be because I don't actually know what \"IKEv1 has been deprecated\" actually *means*. Again, I'm not trying to block what this document is attempting to *do*, but rather make it clear what it is actually doing.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-04-03 17:54:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 00:40:23-07:00",
    "text": "I haven't yet reviewed this document, but it is part of the multi-document problem I flag in my DISCUSS on  draft-ietf-mmusic-trickle-ice-sip , and needs to block on finding a solution to that issue.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-01 15:50:42-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-03 17:54:51-07:00",
    "text": "This document is part of the multi-document problem I flag in my DISCUSS on  draft-ietf-mmusic-trickle-ice-sip , and needs to block on finding a solution to that issue.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-03-26 06:59:47-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 21:39:54-08:00",
    "text": "Thanks for this long-overdue update, and well-written document. I do think that we should discuss a bit the current text in Section 3.1 that allows Experts to change provisional registrations to permanent without consulting the community in the way that they would need to for an initial permanent registration.\u00a0 Is it really expected that the level of community review will be identical for provisional and permanent registrations such that one can suffice for the other?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-07-04 09:33:13-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-03 14:48:47-07:00",
    "text": "I have one discuss point that I hope will be easy to fix. -4.5, 2nd to last paragraph: The first sentence makes ambiguous use of 2119 keywords. Saying that it is RECOMMENDED that something MAY be defined reduces to just MAY, which I don't think is what you want. Also, \"only one\" is ambiguous, in that it can mean \"exactly one\" or \"at most one\". Does the following capture the intent? OLD: \u00a0  It is RECOMMENDED that a TLV Full Type MAY be defined so that there \u00a0  MUST only be one TLV of that Full Type associated with the packet \u00a0  (Packet TLV), message (Message TLV), or any value of any address \u00a0  (Address Block TLV). NEW: \u00a0 If a TLV Full Type is defined, it SHOULD be defined such that at most one  \u00a0 TLV of that Full Type can be associated with a given packet, message, or \u00a0 address block TLV.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-18 17:06:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-09 15:03:55-08:00",
    "text": "Thank you for engaging with the TSVART review. Despite the wordsmithing that has gone on, I am not sure that we have captured the correct text. The proposed change is: > I clarified: > The duration of the trial MUST include least 2 seconds in addition to the time > required to send and receive each burst of frames, to ensure that DUT buffers to > deplete. >  > and I'll add: > The upper search limit for the time to send each burst MUST be configurable as > high as 30 seconds (buffer time results reported at the configured upper limit are > likely invalid, and the test MUST be repeated with a higher search limit). But IIUC it's the additional time that needs to scale up. A layman's reading of the document, IMO, suggests that the burst length has a binary search but the 2 seconds of waiting can be fixed.",
    "type": "Discuss"
  },
  {
    "ad": "Jim Guichard",
    "end": "2023-05-10 12:40:24-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-08 16:14:24-07:00",
    "text": "Section 2 \"Updates to  RFC2328 \" is missing reference to section 10.3. \"The Neighbor state machine\" of  RFC 2328 . Non-inclusive language is used for the \"State(s): Init, Event: 2-WayReceived\" and \"State(s): Exchange or greater, Event: SeqNumberMismatch\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-16 20:29:59-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-14 16:14:57-07:00",
    "text": "lease address the issue raised by the secdir reviewer where AES-CTR iscovered in the text but no codepoint allocated.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-10-16 22:24:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-11 00:01:52-07:00",
    "text": "Thank you for the work put into this document. I am trusting the security AD to check whether it is safe not to have a 'random' IV. I have one trivial-to-fix DISCUSS and a couple of COMMENTs. It is also unclear at first sight whether the 'nonce' built from the sequence number is actually the IIV. Regards, -\u00e9ric == DISCUSS == -- Section 1 -- D.1) Please use the  RFC 8174  template ;)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-11-06 05:03:07-08:00",
    "end_reason": "position_updated",
    "start": "2017-09-27 20:00:56-07:00",
    "text": "I concur with Kathleen's DISCUSS. To state my view of things: 1. The assumption that the datacenter is a secure environment is not a reasonable one. As Kathleen and Adam both observer, datacenter breaches are common and that is why people are moving towards encryption inside the data center. I see that this draft has text claiming that this is only to be deployed in safe environments, but we know that technologies like this get deployed outside the locations for which we claim they are to be deployed, and there's nothing here to stop that. Moreover, the whole trend towards cloud computing pushes us away from designs in which you can safely talk about single secure zones. 2. The text in S 8.1 about how you might want to use some kind of transport security does not seem sufficient. As above, we know that if we don't specify something, people will deploy this technology in insecure settings without any kind of security. I concur with Kathleen's point that this document should provide built-in security mechanisms rather than just punting to the under-layer. Given that as S 1 makes clear, all these SFs are part of the same administrative domain, this seems like a comparatively less challenging setting. If there is some reason why that's infeasible, that needs to be explained.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2017-10-20 13:04:36-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-26 13:42:48-07:00",
    "text": "First, I'd like to thank the authors and WG for your efforts in recent revisions of this draft, it has come a long way.\u00a0 I still want to poke at the lack of a requirement for either integrity protection on the NSH itself or for MUSTs on protections from the transport encapsulation.\u00a0 Attacks inside of a data center or single operator domains happen all too often.\u00a0 The number from 2016 is up 164% as of a statistic I saw earlier today.\u00a0 We can't srug this off anymore. Security Considerations section: First two sentences say: \u00a0  NSH is designed for use within operator environments.\u00a0 As such, it \u00a0  does not include any mandatory security mechanisms.  I think you intended the first sentence to say, \"within a single operator environment\" as what you have now could be multiple networks managed separately with that statement.\u00a0 Then for the second sentence, I know you don't have an integrity mechanism mandated, but I really think one should be.\u00a0 Couldn't the path be altered and not detectable if there is no integrity checking?\u00a0 This could be used to avoid security protections or to route it inappropriately through a multi-tenant environment.\u00a0 Sure, the underlying protocol should provide session encryption on application traffic, but there's no reason why security shouldn't have been baked into this protocol as a requirement. From the architecture document, the security considerations section calls attention to possible issues related to lack of integrity checking.\u00a0 Since no encapsulating transport is specified with required session encryption, and the NSH addition doesn't have integrity protection, how will you meet this architecture requirement from  RFC7665 : \u00a0 Service Overlay:\u00a0 Underneath the service function forwarders, the \u00a0 \u00a0 \u00a0 \u00a0 components that are responsible for performing the transport \u00a0 \u00a0 \u00a0 \u00a0 forwarding consult the outer-transport encapsulation for \u00a0 \u00a0 \u00a0 \u00a0 underlay forwarding.\u00a0 Used transport mechanisms should satisfy \u00a0 \u00a0 \u00a0 \u00a0 the security requirements of the specific SFC deployment.\u00a0 These \u00a0 \u00a0 \u00a0 \u00a0 requirements typically include varying degrees of traffic \u00a0 \u00a0 \u00a0 \u00a0 separation, protection against different attacks (e.g., \u00a0 \u00a0 \u00a0 \u00a0 spoofing, man-in-the-middle, brute-force, or insertion attacks), \u00a0 \u00a0 \u00a0 \u00a0 and can also include authenticity and integrity checking, and/or \u00a0 \u00a0 \u00a0 \u00a0 confidentiality provisions, for both the network overlay \u00a0 \u00a0 \u00a0 \u00a0 transport and traffic it encapsulates. It seems from this text, something should be specified for the transport encapsulation. From the text in the draft under review:  \u00a0  As with many \u00a0  other protocols, without enhancements, the NSH encapsulation could can be \u00a0  spoofed \u00a0  or otherwise modified and is subject to snooping and modification in transit. \u00a0  However, the deployment scope (as defined in [ RFC7665 ]) of the NSH \u00a0  encapsulation is limited to a single network administrative domain as \u00a0  a controlled environment, with trusted devices (e.g., a data center) \u00a0  hence mitigating the risk of unauthorized manipulation of the \u00a0  encapsulation headers or metadata. This is in direct conflict with the Service Overlay requirements in the Security Considerations of  RFC7665 . Section 8.1 I'd like to see some MUSTs to address the concerns listed in  RFC7665  for encapsulation requirements or an addition of integrity protection on NSH itself.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-16 02:37:11-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-27 10:00:40-07:00",
    "text": "I have a couple of comments on the design. I know, as always in IESG review state, it's probably too late to make any changes to the actual header format, therefore most of my comments are actually in the comment section below. I still decided to note them so at least people can consider these points. However, there are a few things that I need clarification for before publication, which I note in this section: 1) Sec 2.2 \"SF/SFF/SFC Proxy/Classifier implementations that do not support SFC \u00a0  OAM procedures SHOULD discard packets with O bit set, but MAY support \u00a0  a configurable parameter to enable forwarding received SFC OAM \u00a0  packets unmodified to the next element in the chain.\u00a0 Forwarding OAM \u00a0  packets unmodified by SFC elements that do not support SFC OAM \u00a0  procedures may be acceptable for a subset of OAM functions, but can \u00a0  result in unexpected outcomes for others; thus, it is recommended to \u00a0  analyze the impact of forwarding an OAM packet for all OAM functions \u00a0  prior to enabling this behavior.\u00a0 The configurable parameter MUST be \u00a0  disabled by default.\" This part is really unclear to me and I believe needs to be further specified. Where should this configurable parameter be? In the Context header? Why don't you just use one of the unassigned bit to indicate if an unknown (OAM) packet should be forwarded or not?  Moreover, I also disagree with this text. If there is a bit/a way to indicate if a not supported OAM packet should be forwarded or not, it should just be defined like this, while any considerations if that bit should be set or not depend on the OAM function itself and do not need to be discussed here. Finally, it is not well explained what an OAM packet is at all. Is that a 'fake' packet that is generated by the operator to actively test the (potentially newly configured) SFP? If so, why does a SF need to know if a packet is an OAM packet or not? Usually it's a bad idea to use different kind of traffic for testing compared to what will be used in operations. Please provide more explanation here! 2) section 2.4 \"An SFC-aware SF MUST receive the data semantics first in order to \u00a0  process the data placed in the mandatory context field.\u00a0 The data \u00a0  semantics include both the allocation schema and the meaning of the \u00a0  included data.\u00a0 How an SFC-aware SF gets the data semantics is \u00a0  outside the scope of this specification.\" This is really confusing to me. I think this is what you need an actually data semantics aka type field for in the base header. Or is there an actual reason to not put this information directly in the base header where it is need but instead assuming some magical way this information may take to reach the node? If the assumption is that the SF is configured to know based of the SFI what the content of the context header has to be, you a) need to say that in the draft, and b) that's really error-prone because it's really hard to tell if the conext header actually holds the information that you need or just random crap (of course depending of the expected data type of this information). In short, I think you really need a type field somewhere here. In any case, you really need to explain this more! Also, the text further says: \"An SF or SFC Proxy that does not know the format or semantics of the \u00a0  Context Header for an NSH with MD Type 1 MUST discard any packet with \u00a0  such an NSH...\" How does the SFC proxy know that it knows the format or not if there is no type field or identifier that indicates what the format should be? Also, a related question from me: why is the context header present in all types of NSH if there is no use for it defined in this document yet? Why is there no fixed length NSH without a context header then? 3) Section 2.5.1: \"If multiple instances of the same metadata are included in an NSH \u00a0  packet, but the definition of that context header does not allow for \u00a0  it, the SFC-aware SF MUST process the first instance and ignore \u00a0  subsequent instances.\" This seems error prone to me. If the same metadata appears multiple where it should not, that seems clearly like an error case for me. Just using the first one and proceed normally might not be the right thing to do. In any case I think such an occasion should at least be logged. If the multiple instances are just a copy of each other and carry the same information, it's probably okay to use that information and proceed. If the different instances carry different information, it maybe a bit dangerous to just use the first one and ignore others silently. In this case I would rather recommend to drop the packet... 4) In line with the second comment from the tsv-art review (thanks Wes!), I don't really understand why this documents says (sec 6) that there can be multiple next hops for the same SFP or SFs can be traversed in a different order. May understanding (from a quick look at  RFC7665 ) would be that, if those things are needed e.g. for load balancing, then one should define different SFPs and the Classifier must have the knowledge that two SFP are equivalent and select them respectively. The reason why I'm really concerned about this is that usually a number of packets below to a flow and all packets belonging to the same flow just ideally take the same route. But usually only the Classifier has a notion of what a flow is and respectively will assign the SFI to the packets belonging to the same flow. If now any SF on the path can more or less randomly decided to forward packet belong to the same flow to one or another next nodes, I would assume that this is not only a problem for the flow, e.g. reordering, but also for SF itself in many cases.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-09-28 01:21:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-09-28 01:20:45-07:00",
    "text": "* Section 5 I think the fragmentation part is underspecified. Take an example where IPv6 is used as the transport encapsulation. If the packet needs to be fragmented, will the NSH header be duplicated into each fragment? If so, this is new behavior for IP that will treat this like any other payload.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-10-03 08:10:10-07:00",
    "end_reason": "position_updated",
    "start": "2017-09-28 01:21:30-07:00",
    "text": "* Section 5 I think the fragmentation part is underspecified. Take an example where IPv6 is used as the transport encapsulation. If the packet needs to be fragmented, will the NSH header be duplicated into each fragment? If so, this is new behavior for IP that will treat this like any other payload. If not how will the subsequent fragments be treated on the service path?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-05-04 21:41:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 22:54:27-07:00",
    "text": "Alvaro and Zahed pointed out concerns about the SHOULDs in Sections 6.1 and 6.2, and since all three of us tripped on the same text, I'd like to discuss them.\u00a0 My own angle is that they're SHOULDs but it's not clear to me why they aren't MUSTs.\u00a0  SHOULD offers the implementer a choice; if we're sure these need to be SHOULDs, then what advice might we provide to implementers that think they have legitimate reasons not to do what they say? For instance, if I'm coding a router that understands HBH but is configured not to honor this option, why might I not ignore the option and forward the packet?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 20:12:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-11 21:36:40-07:00",
    "text": "Thanks for producing this document, which fills a real need and is quite well-written, my comment about its length notwithstanding.\u00a0 Unfortunately, I do have one pretty small point that I think requires a little bit more discussion, to ensure that we produce a specification that is usable as written. Section 7.1 imposes a requirement that \"[i]terative resolvers [...] MUST be configured to behave for these names either: (a) [...], or (b) [...]\".\u00a0 There is no default choice given in the absence of configuration, and it is unclear who this requirement is binding on in any case.\u00a0 Do all iterative resolvers necessarily have a human operator that knows they are responsible for the configuration of the resolver? Is the software author responsible for providing \"default configuration\" to meet this requirement?\u00a0 Let's discuss how this requirement is intended to apply and whether that is achievable in practice.\u00a0 (One of the elided portions from the above quote is \"commplying with this specification\", so perhaps the iterative recursive resolver softwares in question would be implemented to ignore this specification in the absence of such a configuration, as strange as that might seem.)",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-11-07 12:02:15-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-26 15:29:26-07:00",
    "text": "Thank you for writing this document. I will recommend its approval, but before that we have a fix a couple of issues. A Gen-ART review by Elwyn Davies raised a number of valid points. The ones worthy of a Discuss are the following: 1. Section 3.4 protocol definition refers to Appendix A.2 which is depracated/non-normative. I think you have to decide which parts are still in the normative spec, and keep those in the body of the document. 2. Reference to the R flag in 6.2.3 seems wrong, as the flag isn't actually allocated in  RFC 6426  due to an oversight. Maybe either explain the situation and the existing errata, or just define the flag in this RFC and be done with it?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-02-22 13:28:29-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-17 10:00:25-08:00",
    "text": "(1) I agree with Mirja that this document seems to be missing the actual protocol specification, unless Section 6 is meant to provide the normative specification of how the messages are to be exchanged. Is it? If so, I would expect that to be explicit in the document. (2) If there is in fact supposed to be a protocol specified here, I have the same question as I had on  draft-ietf-sidr-publication , which is how do the entities migrate from one version to another and do version negotiation?",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-07-13 10:06:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 05:52:02-07:00",
    "text": "Thanks for the work on this document, Hopefully this discuss will be relatively easy to resolve - and may result from a lack of understanding - but -  \u00a0  Endpoints that receive the grease_quic_bit transport parameter from a \u00a0  peer SHOULD set the QUIC Bit to an unpredictable value unless another \u00a0  extension assigns specific meaning to the value of the bit. Now, this is in reference to a bit - which can only be 0 or 1 - and the document further goes on to clarify certain situations where this bit should be set or unset - so I am not at all sure what this paragraph really means and hoping this can be clarified because I'm not sure how this will be interpreted on implementation.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-07-01 02:05:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 02:15:36-07:00",
    "text": "Hi, Sorry for the late DISCUSS, and hopefully not tricky to resolve, but there are two points that I think it would be helpful to clarify: (1) Ensuring the language is consistent with draft-ietf-quic-manageability. (2) Possibly whether a short Operational Considerations section could/should be added. Details in the comments. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-05-19 07:37:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-08 05:05:41-07:00",
    "text": "Hi, Hopefully not tricky to discuss/resolve, sorry for posting it close to the telechat! I would like to please see some more clarity or guidance about when TAG TBD112 should be used, given that there are two possible encodings of absolute OIDs below \"1.3.6.1.4.1\". Specifically, the questions that I have, that probably need to be clarified are:  - is a CBOR encoder allowed to optimize a TBD110 tag into a TBD112 tag?  - Should CBOR decoder clients always expect to be able to handle both TBD110 and TBD112 tags?  - Or, it the decision over whether to use TBD110 or TBD112 down to the application and the application needs to agree which is use.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-28 21:33:54-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-10 21:28:32-07:00",
    "text": "Thank you for making updates in response to the secdir review; they do help. That said, while I think this is a useful technology to specify and a clear improvement over the existing block-based schemes, this document still has several flaws that need to be fixed before it is ready for publication. Most notably, it is internally inconsistent in several places, about whether bitrate must be fixed or can vary, or whether the encoding/decoding window size ratio is 3/4, or whether the encoding window size only changes during startup as new ADUs are added to reach the max encoding window size, etc.\u00a0 I attempt to note these in my COMMENTs (noting that they were written as I go through the document and I may not have caught all the places where text later in the document clarifies the situation). It's also implied but not entirely clear that the C code is part of the normative algorithm specification, and the C code itself incurs implementation-defined behavior (so as to not be usable as a deterministic protocol standard element), as Ekr notes. The recommendation to bound ls_max_size in section 3.1.1 does not seem strong enough to allow this scheme to meet its stated constraints for maximum latency, since solving very large linear systems can exceed the provisioned timeslot. The SDP encoding for the fssi parmeter should explicitly state that the name value \"E\" is used to convey the E parameter. Multi-byte integer protocol fields need to specify the endianness of encoding (i.e., network byte order).\u00a0 (E.g., for ESI and E values.) The security considerations need to be checked about whether only DoS or data corruption is possible in a few situations. (More details on almost all of these in the COMMENT section.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-10-09 18:05:45-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3423 I do not believe that this specification is sufficiently precise to be interoperably implemented. DETAIL S 3.4. >\u00a0 \u00a0 \u00a0 value, in addition to the maximum FEC-related latency budget >\u00a0 \u00a0 \u00a0 (Section 3.1). >\u00a0   >\u00a0  3.4.\u00a0 Pseudo-Random Number Generator (PRNG) >\u00a0   >\u00a0 \u00a0 \u00a0 The RLC FEC Schemes defined in this document rely on the TinyMT32 What is the normative reference here? We can't really plausibly normatively reference a github link without even a version hash. Is the code in the appendix the normative description of the algorithm. S 3.5. >\u00a0 \u00a0 \u00a0 These considerations apply both the RLC over GF(2) and RLC over >\u00a0 \u00a0 \u00a0 GF(2^^8), the only difference being the value of the m parameter. >\u00a0 \u00a0 \u00a0 With the RLC over GF(2) FEC Scheme (Section 5), m MUST be equal to 1. >\u00a0 \u00a0 \u00a0 With RLC over GF(2^^8) FEC Scheme (Section 4), m MUST be equal to 8. >\u00a0   >\u00a0 \u00a0 \u00a0  Again, is the normative reference here the code? I note that this code contains references to constants which are not defined here and therefore will not compile S 6.2. >\u00a0 \u00a0 \u00a0 ew_size coding coefficients that are computed by the same coefficient >\u00a0 \u00a0 \u00a0 generation function (Section Section 3.5), using the repair key and >\u00a0 \u00a0 \u00a0 encoding window descriptions carried in the Repair FEC Payload ID. >\u00a0 \u00a0 \u00a0 Whenever possible (i.e., when a sub-system covering one or more lost >\u00a0 \u00a0 \u00a0 source symbols is of full rank), decoding is performed in order to >\u00a0 \u00a0 \u00a0 recover lost source symbols.\u00a0 Each time an ADUI can be totally You should provide an algorithm for solving this system or at least a pointer to a description of how to do so S 12.2. >\u00a0 \u00a0 #define TINYMT32_MEXP 127 >\u00a0 \u00a0 #define TINYMT32_SH0 1 >\u00a0 \u00a0 #define TINYMT32_SH1 10 >\u00a0 \u00a0 #define TINYMT32_SH8 8 >\u00a0 \u00a0 #define TINYMT32_MASK UINT32_C(0x7fffffff) >\u00a0 \u00a0 #define TINYMT32_MUL (1.0f / 16777216.0f) ANSI C doesn't specify any particular method of computing floating point arithmetic, so I don't believe that any of this code is portably deterministic. S 12.2. >\u00a0 \u00a0 \u00a0 \u00a0 s->status[0] = s->status[1]; >\u00a0 \u00a0 \u00a0 \u00a0 s->status[1] = s->status[2]; >\u00a0 \u00a0 \u00a0 \u00a0 s->status[2] = x ^ (y << TINYMT32_SH1); >\u00a0 \u00a0 \u00a0 \u00a0 s->status[3] = y; >\u00a0 \u00a0 \u00a0 \u00a0 s->status[1] ^= -((int32_t)(y & 1)) & s->mat1; >\u00a0 \u00a0 \u00a0 \u00a0 s->status[2] ^= -((int32_t)(y & 1)) & s->mat2; You also can't assume that negative numbers have any particular representation (e.g., twos complement) so this XOR is not deterministic.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-05-20 10:53:46-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-10 08:39:55-07:00",
    "text": "I'm really not an expert on legal questions and get easily confused myself but I think just copying in the code including the copyright into the draft appendix leads to conflicting copyright statements, as the all content of the draft has the following copyright: \u00a0  Copyright (c) 2018 IETF Trust and the persons identified as the \u00a0  document authors.\u00a0 All rights reserved. And the code says this: \u00a0 * Copyright (c) 2011, 2013 Mutsuo Saito, Makoto Matsumoto, \u00a0 * Hiroshima University and The University of Tokyo. \u00a0 * All rights reserved.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-18 02:21:48-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 17:50:08-07:00",
    "text": "A few code nits for Section 3.6 so that the code compiles: ** To make the combination of this source code and that in  draft-ietf-tsvwg-tinymt32  compile requires that the directive \u201c#include \u201d be added (for the memset). ** The final return in Section 3.6 is missing a semicolon: s/return 0/return 0;/",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-11-16 23:16:01-08:00",
    "end_reason": "position_updated",
    "start": "2017-11-10 18:03:25-08:00",
    "text": "\u00a0  o\u00a0 TEPs MUST NOT permit the negotiation of any encryption algorithms \u00a0 \u00a0 \u00a0 with significantly less than 128-bit security. IMPORTANT: I don't know what \"significantly means\". I wouldn't be making a point of this, but it's phrased as a normative requirement, so I don't know what conformance means. IMPORTANT: This actually seems to be a bit confusing about how to handle URG. Consider TCP-use-TLS, you would just process URG in the normal way and then generate errors if URG causes reordering at the TLS layer. This seems like a reasonable procedure but is at least arguably prohibited by this text. \u00a0  problems, TEPs MUST compute session IDs using only well-studied and \u00a0  conservative hash functions.\u00a0 That way, even if other parts of a TEP \u00a0  are vulnerable, it is still intractable for an attacker to induce \u00a0   IMPORTANT: this also does not seem to be unambiguous.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-05 00:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-30 06:17:24-07:00",
    "text": "# GEN AD review of  draft-ietf-lsr-ospf-l2bundles-06 CC @larseggert Thanks to Paul Kyzivat for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/IqLhVi63YKAt6GINPOKUQ0sGt3g ). I'm raising Paul's review comment as a DISCUSS: ``` 2) MINOR: Section 2: Normative requirements on future documents While I don't fully understand all the document dependencies, the following normative requirement: \u00a0 ... Specifications that introduce new sub-TLVs of the Extended Link \u00a0 TLV MUST indicate their applicability for the L2 Bundle Member \u00a0 Attributes Sub-TLV.\u00a0 An implementation MUST ignore any sub-TLVs \u00a0 received that are not applicable in the context of the L2 Bundle \u00a0 Member Attribute Sub-TLV. looks to me like it may be imposing requirements on future work that may not itself be aware of or normatively linked to this document. The registry in question is defined only by  RFC7684 . Figure 2 further supports this point by effectively revising the format for the registry, adding an additional column. I suggest it would be appropriate to formally update the registry to reference this document to impose requirements on future registrations, and add a column indicating applicability in the context of the L2 Bundle Member Attribute Sub-TLV. The same logic applies to Figure 3 and the IANA OSPFv3 Extended-LSA Sub-TLVs registry. I suggest the same sort of fix for it. ```",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-11-07 16:57:26-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-24 12:57:07-07:00",
    "text": "I'm not clear how to evaluate the security properties of this protocol given that the IEC specs on which it builds aren't visible to me. (Or at least I didn't find a version I could access.) That's made worse by my relative ignorance of GDOI as well.  So I wonder should the authors or IESG add a note to that effect? Say along the lines of: \"This memo extends  RFC6407  in order to define extensions needed by IEC62351-9. With the current IANA registry rules setup by  RFC6407 , this requires a standards action by the IETF - essentially that means the production of this document. As the relevant IEC specifications are not available to the IETF community, it is not possible for this RFC to fully describe the security considerations applying. Implementers therefore need to depend on the security analysis within the IEC specifications. As two different SDOs are involved here, and since group key management is inherently complex, it is possible some security issues have not been identified, so additional analysis of the security of the combined set of specifications may be advisable.\" I'd be fine with any wording that calls out that the IETF can't really be sure of the overall outcome here. Note that that's not in any way to doubt the authors' own analysis - but given that we know it is quite possible for fewer eyeballs to lead to gaps, and that this really is a complicated beast solving a complicated problem, I'm a bit concerned that we may miss something.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-03-26 07:01:50-07:00",
    "end_reason": "position_updated",
    "start": "2017-12-13 10:41:50-08:00",
    "text": "I ended up reading  draft-ietf-6man-segment-routing-header  in tandem with this document, and I have a question arising out of that. The trust model for SRv6 outlined in this document appears to be one of reliance on the fact that an SRH will only ever be inserted and appear within a single administrative domain. But Section 5.2.2 of  draft-ietf-6man-segment-routing-header  talks about an SRH being inserted by a device outside of the segment routing domain. Which is correct? I think this is an important question because the whole trust model for the SR information seems to rely on out-of-band trust between participating nodes. I also think this is important because there is no discussion in this document of the impact of the inclusion of the SR metadata on the fingerprinting of the device that inserted it. Section 5.1.4 of  draft-ietf-6man-segment-routing-header  sort of alludes to this but seems to equate the capabilities of an active attacker (who can conduct a traceroute) with a passive attacker who could passively collect topology/fingerprinting information simply by observing SRHes flowing by on the network. If the limitation to a single administrative domain is meant to prevent such a passive attack (not sure if that is really true, but perhaps the document assumes it?), that's another reason that the existence of such a limitation needs to be clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-02-12 07:25:56-08:00",
    "end_reason": "position_updated",
    "start": "2017-12-13 19:55:02-08:00",
    "text": "While I understand the assumption that following the capabilities of existing protocols that incorporate similar functionality is okay, I'd like to walk through the security properties left off in the security considerations section to prevent tampering and see what can be done to correct that or minimally to list out the considerations. There's a few places in the security considerations section to call out specifically. Section 8.1: \u00a0  \"The received information is validated using \u00a0  existing control plane protocols providing authentication and \u00a0  security mechanisms.\u00a0 Segment Routing does not define any additional \u00a0  security mechanism in existing control plane protocols.\" For MPLS what \"security mechanisms\" are referred to in this text?\u00a0 It would be helpful to list any properties explicitly or drop this phrase if there are no additional security mechanisms.\u00a0 Since segment routing lists an explicit list of segments (I see that this can be done with MPLS labels and you note it is already exposed), why is there no mention of integrity protection and origin authentication to prevent tampering?\u00a0 I think EKR's comment is already hinting at this with his comments on IPv6, but I'd like to see explicit text to preferably fix this gap in the architecture, but minimally to document it and the associated security threats that result from this gap for MPLS and IPv6. Section 8.2: \u00a0  \"From a network protection standpoint, there is an assumed trust model \u00a0  such that any node adding an SRH to the packet is assumed to be \u00a0  allowed to do so.\u00a0 Therefore, by default, the explicit routing \u00a0  information MUST NOT be leaked through the boundaries of the \u00a0  administered domain.\u00a0 Segment Routing extensions that have been \u00a0  defined in various protocols, leverage the security mechanisms of \u00a0  these protocols such as encryption, authentication, filtering, etc.\" This document focuses on the same threats as the MPLS use cases with no mention of tampering or mitigations.\u00a0 Text should be added to describe how origin authentication and integrity are provided in the source routing header for IPv6 with the associated threats or to describe this gap if a solution does not exist.\u00a0 I have not read the draft referred to at the start of this section, so I don't know if it addresses the concern or not.\u00a0 In any case, this document isn't complete without some text on tampering considerations within your trusted domain. Thank you.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2016-07-25 14:43:19-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-14 14:53:20-07:00",
    "text": "I believe this is more\u00a0 a discussion for the IESG. First, this is way out of my area and I'm not particularly commenting on the details - but  I do agree with Mirja's discuss about \"- The following action does not seem to be appropriate for a specification of an end-to-end protocol: \"And if the splicer wishes to prevent the downstream receivers from detecting splicing, it MUST \u00a0  NOT forward the message.\"\" The full paragraph at the end of Sec 3.2 is: \"When the splicer intercepts the RTCP splicing notification message, \u00a0  it SHOULD NOT forward the message to the down-stream receivers in \u00a0  order to reduce RTCP bandwidth consumption. And if the splicer wishes \u00a0  to prevent the downstream receivers from detecting splicing, it MUST \u00a0  NOT forward the message.\" Even more specifically to me, superficially this seems to me to be a way to change what is in the stream that a receiver has requested or subscribed to without permission or notification.\u00a0  In that light, the idea that the splicer is able to prevent downstream receivers from detecting the splicing does not sound good. Similarly, the end of Sec 3.1 says \"After the splicer intercepts the RTP header extension and derives the \u00a0  Splicing Interval, it will generate its own stream and SHOULD NOT \u00a0  include the RTP header extension in outgoing packets to reduce header \u00a0  overhead.\" This looks like another example of making the choice to hide information from the receiver. I realize that there is probably an technical arms-race going on - of inserting advertisements and building receivers to block undesired advertisements.\u00a0 I am\u00a0 not seeing a balanced solution that considers the receivers as well as the senders. I am startled that there is no consideration of the impact of this extension on the receivers  in the security considerations. The only reference I see in the Security Considerations further assumes that it is appropriate to have an undetectable splicing. \" A malicious endpoint may also break an undetectable splicing. To \u00a0  mitigate this effect, the splicer SHOULD NOT forward the splicing \u00a0  time information RTP header extension defined in Section 4.1 to the \u00a0  receivers. And it MUST NOT forward this header extension when \u00a0  considering an undetectable splicing. \" At a minimum, I feel like there should be a very clear consideration of the pros and cons - including from the viewpoint of a receiver.  If we end up with this biased technology, then it should be clearly stated - not hidden in assumptions.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-06-16 06:20:55-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-13 05:55:21-07:00",
    "text": "I have a few points which I would like to have answers for before moving the doc forward (which may not even results in text changes). I happy to clear my position when answered before the telechat: - The following action does not seem to be appropriate for a specification of an end-to-end protocol: \"And if the splicer wishes to prevent the downstream receivers from detecting splicing, it MUST \u00a0  NOT forward the message.\" I guess if a middlebox decides to drop the message, there is not much we can do. But I definitely would prefer to not see this specified in an RFC. - Why is just having the RTCP message not sufficient? Why are the RTP extensions needed as well? - And is the RTCP message send only once or multiple time? This is not specified. - There is some discussion about the implementation of the slicer in section 5 (where btw. the title \"Failure Cases\" seems inappropriate), while there is one sentence saying: \"If the splicer is implemented following [ RFC6828 ], it will have its \u00a0  own SSRC and will send its own RTCP reports, and will forward \u00a0  translated RTCP reports from the receivers.\" Why are alternatives discussed here, if there is already a recommendation given in  RFC6828 ? And how would proper congestion handling be ensure in the other setups not described in  RFC6828 ?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-09 06:54:39-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-16 04:10:42-07:00",
    "text": "(1) Section 7, 3rd para: Saying that \"splicer works as a trusted entity\" seems wrong - you need to say who trusts whom for what I think. I also don't get what you mean by saying there'll be a security association between the splicer and the receiver, nor how that might ever be possible if the splicer wants to hide what it's doing.\u00a0 I think what you're after is some general statement that splicing breaks all security unless all the parties involved share the same security association. IIRC there is text like that in other RTP documents that might be copied but I forget the detail. (2) Section 7, 4th para: You say there is a case where header extension encryption SHOULD be used - how would that work? If there's a clear way to do it that'd get interop, then why is that not described? If there are ways in which might or might not work, or if some proprietary arrangements might be needed then how is it ok to have a SHOULD there? I suspect that the right thing here may be to not pretend that that can be done but to just stick with saying that splicing is inherently not going to work if you use any real security mechanisms, or something similar. (3) In discussion of  RFC6828  there was some concern about possible creation of loops. I forget the issues though, but wanted to check this in case it also applies here.\u00a0 (See 4.5 of 6828 maybe or the history for that RFC in the tracker.)",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2015-12-17 01:22:36-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-02 12:34:36-08:00",
    "text": "As mentioned by Dave Thaler in his MIB doctor review: I was assigned to do the MIB doctor review of this document, since I previously did an early review of -03.\u00a0 My full comments are in the marked up copy at http://research.microsoft.com/~dthaler/draft-ietf-softwire-dslite-mib-12.pdf Below is a summary of the issues called out therein. Substantive issues: 1)\u00a0 \u00a0 \u00a0  RFC 4001  requires each InetAddress object to explicitly state which other InetAddressType object indicates the type.\u00a0 None of the objects in this document do so.\u00a0  RFC 7659  (the NATv2 MIB) does, and can be used as an example. 2)\u00a0 \u00a0 \u00a0 dsliteNATBindEntry includes dsliteTunnelStartAddPreLen in the INDEX. To confirm this was intended: Can you really have 2 entries that have all other INDEX values the same and differ only in the prefix length? 3)\u00a0 \u00a0 \u00a0 dsliteNATBindTable states that it extends natv2PortMapTable in  RFC 7659 , but rather than reusing the not-accessible objects from that table in its own INDEX clause, it defines its own.\u00a0 That\u2019s fine, but it is then not clear whether each such object in the dsliteNATBindTable INDEX needs to match a corresponding value in the natv2PortMapTable INDEX, or whether there can be additional entries that do not appear in the natv2PortMapTable.\u00a0  This should be clarified. 4)\u00a0 \u00a0 \u00a0 Many objects in that table, such as dsliteNATBindMappingIntRealm, have very terse DESCRIPTIONs, whereas the DESCRIPTION of the corresponding object in the natv2PortMapTable is quite detailed.\u00a0 Hence this draft is far less clear than  RFC 7659 , since this draft has no such language. 5)\u00a0 \u00a0 \u00a0 Objects of type InetAddress incorrectly have a REFERENCE clause pointing to the definition of the InetAddress TC. REFERENCE clauses should be used to point to the spec defining the semantics, rather than the syntax.\u00a0 For example, dsliteNATBindMappingIntAddress is incorrect, whereas the corresponding object in  RFC 7659  (natv2AddressMapInternalAddressType) is correct and points into the DS-Lite RFC ( RFC 6333 ). 6)\u00a0 \u00a0 \u00a0  I didn\u2019t understand DsliteNATBindEntry at all.\u00a0 Its dsliteNATBindMappingMapBehavior object has a value addressAndPortDependent(2) which \u201cmaps to a separate external address and port combination for each different destination address and port combination reached through the same external realm\u201d.\u00a0  However, the external port is in the INDEX clause and the destination address does not appear to be in the table at all.\u00a0 Since the 0 value for the external port already has a different special meaning, it can\u2019t be 0 either.\u00a0  So I don\u2019t understand how this table can work. 7)\u00a0 \u00a0 \u00a0 dsliteAFTRAlarmProtocolType is underspecified.\u00a0 It\u2019s a string, but the description is very confusing as to what the legal string values are, making it sound more like an INTEGER was intended. (\u201cThis object indicate the protocol type of alarm, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0:tcp,1:udp,2:icmp,3:total\u201d) E.g., does that mean the string is \u201c0:tcp\u201d or \u201c0\u201d or \u201ctcp\u201d or what? 8)\u00a0 \u00a0 \u00a0 The dsliteStatisticTransmitted object seems to combine sent + received packets into a single counter with a name that implies only one direction. This is confusing, especially since most other MIB modules separate sent vs received into different counters. 9)\u00a0 \u00a0 \u00a0 dsliteAFTRUserSessionNumAlarm and dsliteAFTRPortUsageOfSpecificIpAlarm both refer to \u201cthe threshold\u201d without stating what threshold that is. There doesn\u2019t seem to be any such threshold object in this MIB module or elsewhere that I could find. 10)\u00a0  dsliteAFTRAlarmScalarGroup is mandatory and requires read-write access. But a lesson learned from the NAT MIB (and many other MIBs) is that many people don\u2019t want write support in their MIB modules.\u00a0 Does the WG really feel that write support is required in all implementations?\u00a0 I\u2019d recommend also having a read-only compliance statement, as is done in many other MIB modules. 11)\u00a0  The security considerations section uses the correct boilerplate for sensitive read-only objects, which includes \u201cThese are the tables and objects and their sensitivity/vulnerability\u201d.\u00a0 However it then only lists the tables/objects and contains no discussion of their sensitivity/vulnerability. This is required in order to comply with MIB review guidelines in  RFC 4181 . 12)\u00a0  Per discussion on MIB Doctors, the root OID should probably not be { transmission xxx }, since that space usually implies that xxx is an ifType (not tunnel type) value. BENOIT: as discussed with the MIB Doctors, it should be under mib-2. 13)\u00a0  A number of undefined terms are used that I could not find in the DS-Lite RFC (6333) either, e.g., connection, session, etc.\u00a0 As such, I couldn\u2019t tell what was meant, and whether there were issues with the meaning.\u00a0 At minimum, REFERENCE clauses should be added to point to a specific section of a document that defines the terms.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-09-27 17:10:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-09-23 01:45:11-07:00",
    "text": "(1) I think there may be some ambiguity we need to resolve, relating to per-AF router IDs and other per-AF lists: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  list router-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  key \"address-family\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id per address family.\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  leaf address-family { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type identityref { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  base vpn-common:address-family; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Indicates the address family for which the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Router-ID applies.\"; What actually gets used as the router-id for a given address family if both \"dual-stack\" and that address family are present in this list? There's some similar potential for amiguity in the \"redistribute-connected\" list for BGP routing, that is also keyed on an address-family identityref. (2) In a similar vein as Roman's Discuss (and perhaps obviated by it?), if we're going to allow raw keys to be specified, as a string type, we should be very clear about whether the string is hex-encoded, base64-encoded, etc., in light of deployed experience with devices that take the string and use it as the raw key (thereby eliminating a good chunk of the key space from potential use). (2.5) For raw keys, should we be using nacm:default-deny-all? (3) the ipsec authentication option for the various routing protocols uses a string to identify an (IKE, unspecified version thereof) SA.\u00a0  RFC 7296  doesn't have the concept of a name for an IKE SA itself, so I think we need to provide more details on what is being named and what the naming authority is.\u00a0 IKE does have identities for the peers, if the goal is to refer to the peer's identity for the SA. (4) I'd also like to have a discussion about the NTP configuration options; in particular, we currently have an enumeration to select between broadcast client and broadcast server, with no option apparent for symmetric or other NTP modes.\u00a0 Given the rigidity of YANG enumerations, I'd like to confirm that no other NTP modes could be appropriate on the network access before we lock in to this model.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-09-28 16:45:58-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-27 17:10:12-07:00",
    "text": "(3) the ipsec authentication option for the various routing protocols uses a string to identify an (IKE, unspecified version thereof) SA.\u00a0  RFC 7296  doesn't have the concept of a name for an IKE SA itself, so I think we need to provide more details on what is being named and what the naming authority is.\u00a0 IKE does have identities for the peers, if the goal is to refer to the peer's identity for the SA. [I'd like to see clarified that these human-readable names are administrator-assigned]",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-09-23 07:20:21-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 13:35:38-07:00",
    "text": "[general] * I'm sure there are plenty things I'm not understanding, and probably \u00a0 these things are easy to address.\u00a0 But in general I feel like there \u00a0 could be some tension between needing to specify/model the L3 \u00a0 attributes that are used to provision both the endpoint and the \u00a0 clients with a possibly somewhat cleaner separation for holding client \u00a0 IP provisioning info.\u00a0 At what point, for example, should there be \u00a0 something like a separate \"client-ip-provisioning-profile\" string \u00a0 that is referenced?\u00a0 I think some of the richness of what can be \u00a0 expressed in IPv6 RAs may be bringing these ideas up, some of which \u00a0 can be expressed in DHCP as well but operationally may be less common. \u00a0 The contents of RIOs in particular seem like a bit of client \u00a0 provisioning information that an endpoint might need to be aware \u00a0 of as well. [S7.6.2] * Provisioning IPv6 clients can be more rich than the DHCPv6/SLAAC \u00a0 model noted here (and much more so than IPv4/DHCPv4). \u00a0 Since you document how local-address/prefix-length becomes a PIO, \u00a0 should there be other related IP connectivity provisioning information \u00a0 in here, like: \u00a0 \u00a0 \u00a0 * more than just one PIO? (is this just repeated \u00a0 \u00a0 \u00a0 \u00a0 ip-connection/ipv6 entries, one for each on-link prefix?) \u00a0 \u00a0 \u00a0 * one or more RIOs that might need to be advertised to clients? \u00a0 \u00a0 \u00a0 * others (PVDIO, ...)? \u00a0 If this is \"out of scope\" for this document, where does it belong \u00a0 in the overall provisioning of an L3VPN service (out of curiosity, \u00a0 given that this document kinda models DHCP IP allocation ranges)? [S8] * Under provider DHCPv6 servers, the server definition has an \u00a0 \"address-assign\" choice of \"number\" with a \u00a0 \"number-of-dynamic-address\" (defaulting to \"1\"), but the description \u00a0 talks about the number of allocated prefixes.\u00a0 Should this value be \u00a0 \"number-of-dynamic-prefixes\" instead?  * Which of these elements describes whether or not DHCPv6 PD \u00a0  (Prefix Delegation) is enabled, and the prefix pools used?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-10-04 05:21:11-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-04 03:51:17-07:00",
    "text": "Thank you for the work on this document, and apologies for the delayed review. I have one DISCUSS point, a couple of comments. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. I have divided comments into \"minor\" (including the questions) and \"nits\". Neither require replies strictly speaking, please feel free to address as you see fit. I will appreciate answers to my questions, to improve my understanding. If any clarification comes out of it, I hope it will help improve the document. Francesca 1. ----- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  leaf holdtime { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type uint32; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  units \"msec\"; FP: This might be me not finding the right reference (or little knowledge of YANG), but I was wondering if \"msec\" was defined somewhere as a unit (note that the description does not mention that the unit is milliseconds either). While doing my due diligence to see if I missed or misunderstood something, I researched the RFCs mentioned in the beginning of the YANG module: \u00a0  This module uses types defined in [ RFC6991 ] and [ RFC8343 ].\u00a0 It also \u00a0  uses groupings defined in [ RFC8519 ], [ RFC8177 ], and [ RFC8294 ]. And found no use of the \"msec\" unit. A quick google search shows that  RFC 8299  uses it, so there is precedence for it, but I couldn't find its definition from that document either. All the other leaves use \"milliseconds\" (which is defined in  RFC 8294 ), so my preference would be to have consistency, if \"msec\" was defined and I just missed it. (Note that a similar remark could be made for \"bps\" used, which does not appear in the description text, and is also used in  RFC 8466 , however there is no issue about consistency there).",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-09-27 10:20:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-19 10:55:15-07:00",
    "text": "(7.6.3) Is there a reason the TCP-AO model in this draft is different from the one in  draft-ietf-idr-bgp-model-11 ? That draft is using a model developed in the TCPM WG ( draft-ietf-tcpm-yang-tcp ) specifically for that purpose. If there is no compelling requirement for something different, or the TCPM modelling work can be stretched to cover this use case as well, it would be far better than rolling a totally separate TCP YANG model here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-09-29 13:16:50-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-19 14:20:00-07:00",
    "text": "**  RFC8177  already defines a container to represent an individual key -- key-string \u2013 as both a string and hex format. Additionally, this representation has built in ACLs to protect it.\u00a0 This model appears to maximize flexibility by supporting both key-chains and an explicit key for protocols like BGP, RIP and ISIS.\u00a0 Is there a reason why this model does not (or perhaps cannot) reuse the key-string representation from  RFC8177  (the same way key-chain is)? And/or to not provide the flexibility for a hex encoded key?  ** Section 9.\u00a0 The text notes that \u2018vpn-service\u2019 is sensitive to write operations.\u00a0 Wouldn\u2019t \u2018vpn-profiles\u2019 be equally sensitive to alterations with similar consequences?\u00a0 For example, altering an encryption-profile-identifier could change the algorithm chosen or the key.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-09-27 04:53:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 01:15:59-07:00",
    "text": "This specification refers to ietf-opsawg-vpn-common for qos related matching, hence I am raising similar discussion as I had for ietf-opsawg-vpn-common (see here  https://datatracker.ietf.org/doc/draft-ietf-opsawg-vpn-common/ ). This specification specifies qos classification based on L4 criteria and describes the procedure for TCP and UDP. It is possible that new L4 protocols (for example QUIC) use UDP as substrate hence can create ambiguity based of the procedure described in the specification. This specification should consider such potential substrate usage of L4 protocols (specially UDP) and hint on the potential augmentations (there might be several ways to do that) or scope it down to not support such cases.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-03 20:08:51-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-03 20:08:10-08:00",
    "text": "One fairly minor point to start: Section 4.3 says that we define a new mode (ICE-HIP-UDP) for the NAT_TRAVERSAL_MODE parameter type, but then goes on to say that \"the presence of the parameter in a HIP base exchange means that the end-host supports NAT traversal extensions defined in this document\".\u00a0 If I undrestand correctly, only the specific presence of the ICE-HIP-UDP mode of the NAT_TRAVERSAL_MODE parameter does so, and so to say that the present of \"the [NAT_TRAVERSAL_MODE] parameter\" indicates support for this document would be backwards incompatible with  RFC 5770 . I'd also like to delve a little further into the potential \"cross-protocol\" attack (same protocol, really, but the same attack) that Ekr raised, between RVS_HMAC and RELAY_HMAC.\u00a0 This is probably a \"discuss discuss\", so let's see where it leads... The semantics for either type of HMAC is that it is an HMAC over the HIP packet excluding itself and subsequent parameters.\u00a0 Pulling up the HIP packet format from  RFC 7401 , that looks like: \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  | Next Header\u00a0  | Header Length |0| Packet Type |Version| RES.|1| \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Checksum\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Controls\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Sender's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Receiver's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HIP Parameters\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The HMAC key is the integrity key for that direction of traffic between HITs, so the \"cross-protocol\" part can only come in by confusing the packet recipient into confusion as to whether it is processing an RVS_HMAC or a RELAY_HMAC (but any other entity will reject the packet by virtue of it using the wrong key).\u00a0 Modern best practices are to go through a key derivation step that incorporates as much information as possible about what the derived key will be used for, which would in this case include the TLV type of the HMAC parameter and presumably the HITs in question as well. In particular, the TLV type of the HMAC parameter is *not* input into the HMAC calculation (at least for RVS_HMAC), so the trivial discriminator is not present.\u00a0 The \"packet type\" in the header in the header is potentially going to differ across usages, so I think that's a good place to focus discussion.\u00a0 Unfortunately, Section 4.2.1 of  RFC 8004  suggests that RVS_HMAC is going to be present a lot of the time, so it's not really clear to me what packet types either RVS_HMAC and/or REPLAY_HMAC are expected to occur in.\u00a0 Could a HIP expert please jump in and help clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-15 18:32:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-03 20:08:51-08:00",
    "text": "One fairly minor point to start: Section 4.3 says that we define a new mode (ICE-HIP-UDP) for the NAT_TRAVERSAL_MODE parameter type, but then goes on to say that \"the presence of the parameter in a HIP base exchange means that the end-host supports NAT traversal extensions defined in this document\".\u00a0 If I undrestand correctly, only the specific presence of the ICE-HIP-UDP mode of the NAT_TRAVERSAL_MODE parameter does so, and so to say that the presence of \"the [NAT_TRAVERSAL_MODE] parameter\" indicates support for this document would be backwards incompatible with  RFC 5770 . I'd also like to delve a little further into the potential \"cross-protocol\" attack (same protocol, really, but the same attack) that Ekr raised, between RVS_HMAC and RELAY_HMAC.\u00a0 This is probably a \"discuss discuss\", so let's see where it leads... The semantics for either type of HMAC is that it is an HMAC over the HIP packet excluding itself and subsequent parameters.\u00a0 Pulling up the HIP packet format from  RFC 7401 , that looks like: \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  | Next Header\u00a0  | Header Length |0| Packet Type |Version| RES.|1| \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Checksum\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Controls\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Sender's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Receiver's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HIP Parameters\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The HMAC key is the integrity key for that direction of traffic between HITs, so the \"cross-protocol\" part can only come in by confusing the packet recipient into confusion as to whether it is processing an RVS_HMAC or a RELAY_HMAC (but any other entity will reject the packet by virtue of it using the wrong key).\u00a0 Modern best practices are to go through a key derivation step that incorporates as much information as possible about what the derived key will be used for, which would in this case include the TLV type of the HMAC parameter and presumably the HITs in question as well. In particular, the TLV type of the HMAC parameter is *not* input into the HMAC calculation (at least for RVS_HMAC), so the trivial discriminator is not present.\u00a0 The \"packet type\" in the header in the header is potentially going to differ across usages, so I think that's a good place to focus discussion.\u00a0 Unfortunately, Section 4.2.1 of  RFC 8004  suggests that RVS_HMAC is going to be present a lot of the time, so it's not really clear to me what packet types either RVS_HMAC and/or REPLAY_HMAC are expected to occur in.\u00a0 Could a HIP expert please jump in and help clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-05-04 12:34:27-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3099 I am very familiar with ICE and yet I found this document extremely hard to follow. The problem is that it cherry-picks pieces of ICE and I'm just not sure that it's a complete specification when put all together. I have noted a number of places where I actually am not sure how to implement something, and fixing those will resolve this DISCUSS, but IMO you really should totally rewrite this document either (a) as a variant of ICE or (b) as an entirely new document not with a pile of new text and then references out to ICE sections. DETAIL S 4.2. >\u00a0 \u00a0 \u00a0 request type SHOULD NOT create any state at the Control Relay Server. >\u00a0   >\u00a0 \u00a0 \u00a0 ICE guidelines [ I-D.ietf-ice-rfc5245bis ] for candidate gathering are >\u00a0 \u00a0 \u00a0 followed here.\u00a0 A number of host candidates (loopback, anycast and >\u00a0 \u00a0 \u00a0 others) should be excluded as described in the ICE specification >\u00a0 \u00a0 \u00a0 [ I-D.ietf-ice-rfc5245bis ].\u00a0 Relayed candidates SHOULD be gathered in If you're going to normatively cherry-pick ICE, you need to note specific sections, I think. S 4.6.2. >\u00a0   >\u00a0 \u00a0 \u00a0 A host may receive a connectivity check before it has received the >\u00a0 \u00a0 \u00a0 candidates from its peer.\u00a0 In such a case, the host MUST immediately >\u00a0 \u00a0 \u00a0 generate a response, and then continue waiting for the candidates.\u00a0 A >\u00a0 \u00a0 \u00a0 host MUST NOT select a candidate pair until it has verified the pair >\u00a0 \u00a0 \u00a0 using a connectivity check as defined in Section 4.6.1. Are you supposed to put this on a TODO check list as with ICE? S 5.8. >\u00a0   >\u00a0  5.8.\u00a0 RELAY_HMAC Parameter >\u00a0   >\u00a0 \u00a0 \u00a0 As specified in Legacy ICE-HIP [ RFC5770 ], the RELAY_HMAC parameter >\u00a0 \u00a0 \u00a0 value has the TLV type 65520.\u00a0 It has the same semantics as RVS_HMAC >\u00a0 \u00a0 \u00a0 [ RFC8004 ]. What key is used for the HMAC?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-04 08:45:11-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 08:23:25-08:00",
    "text": "So this discuss should be relatively easy to address.  So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC 6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-05 02:55:03-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 08:45:11-08:00",
    "text": "So this discuss should be relatively easy to address.  1. So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC 6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information. 2. Secondly, as this solution is different from the  RFC 5770  should this solution have a different service name?  3. So I don't quite understand what the co-existance story are for the relay having an listener on port 10500? Is that port only used for UDP/HIPv1 ( RFC5770 ) and UDP/HIPv2 (This doc). And the listening stack can determine which version is used to determine which of the protocol is run. And the issue with multiplexing is only existing for the ports that one gathers?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-05 03:08:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-05 02:55:03-08:00",
    "text": "So this discuss should be relatively easy to address.  1. So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC  6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information. 2. Secondly, as this solution is different from the  RFC 5770  should this solution have a different service name? The reason I am asking is that it depends on how for example how an initiator determine which of the NAT traversal solution. If there is any intention to use DNS SRV for example different service name would make sense. This is primarily to verify that this has been considered.  3. So I don't quite understand what the co-existance story are for the relay having an listener on port 10500? Is that port only used for UDP/HIPv1 ( RFC5770 ) and UDP/HIPv2 (This doc). And the listening stack can determine which version is used to determine which of the protocol is run. And the issue with multiplexing is only existing for the ports that one gathers? Can you please add a paragraph or two somewhere in the document. I think it should be referenced by the port registration update.  4. MTU impact of NAT traversal.  Section 5.1 states\u00a0   \"It is worth noting that UDP encapsulation of HIP packets reduces the \u00a0  Maximum Transfer Unit (MTU) size of the control plane by 12 bytes.\" There is also a similar text in Section 5.11: \u00a0  It is worth noting that UDP encapsulation of ESP reduces the MTU size \u00a0  of data plane by 8 bytes. I think the document needs a discussion and impact on MTU which this NAT traversal has on the HIP packets being sent.  - First of all there appears to be more packet expansions happening in some cases, for example the RELAY_HMAC option expands packets on one leg. - Secondly, HIP requires IP fragementation support, however IP fragmentation through NAT is commonly not working. Thus an HIP packet being UDP encapsulated that results in packet exceeding MTU will likely end up in an MTU black hole on path.  The addition of the NAT traversal encapsulation actually increases the need for MTU discovery or care in MTU handling by the HIP initiator. I think there need to be discussion of that in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-28 07:44:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-05 03:08:02-08:00",
    "text": "So I think the below are important things that needs to be discussed before proceeding. However, I might have missed things as I didn't have time to read the whole document in detail. Several of the issues are pieces for discussion to ensure that the right thing really is done.  1. So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC  6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information. 2. Secondly, as this solution is different from the  RFC 5770  should this solution have a different service name? The reason I am asking is that it depends on how for example how an initiator determine which of the NAT traversal solution. If there is any intention to use DNS SRV for example different service name would make sense. This is primarily to verify that this has been considered.  3. So I don't quite understand what the co-existance story are for the relay having an listener on port 10500? Is that port only used for UDP/HIPv1 ( RFC5770 ) and UDP/HIPv2 (This doc). And the listening stack can determine which version is used to determine which of the protocol is run. And the issue with multiplexing is only existing for the ports that one gathers? Can you please add a paragraph or two somewhere in the document. I think it should be referenced by the port registration update.  4. MTU impact of NAT traversal.  Section 5.1 states\u00a0   \"It is worth noting that UDP encapsulation of HIP packets reduces the \u00a0  Maximum Transfer Unit (MTU) size of the control plane by 12 bytes.\" There is also a similar text in Section 5.11: \u00a0  It is worth noting that UDP encapsulation of ESP reduces the MTU size \u00a0  of data plane by 8 bytes. I think the document needs a discussion and impact on MTU which this NAT traversal has on the HIP packets being sent.  - First of all there appears to be more packet expansions happening in some cases, for example the RELAY_HMAC option expands packets on one leg. - Secondly, HIP requires IP fragementation support, however IP fragmentation through NAT is commonly not working. Thus an HIP packet being UDP encapsulated that results in packet exceeding MTU will likely end up in an MTU black hole on path.  The addition of the NAT traversal encapsulation actually increases the need for MTU discovery or care in MTU handling by the HIP initiator. I think there need to be discussion of that in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-27 14:21:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-15 23:16:24-07:00",
    "text": "Sec 4.2 and 4.6.2 specify a minimum of RTO of 500ms. There\u2019s no way you would know this,\u00a0 but  draft-ietf-tcpm-rto-consider  is close to IESG approval and specifies a minimum of 1 second without more information about the path. I would prefer that we change these minimums but perhaps there\u2019s a compelling reason for 500ms?   RFC 5770  is a normative downref. I couldn\u2019t find indication the procedures in  RFC 3967  or 4897 were followed to address this. One solution would be to downgrade this document to Experimental.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-30 06:17:14-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-05-10 03:00:05-07:00",
    "text": "1) This document should also update the IANA port registry to add a reference to this RFC-to-be to the existing entry for port 10500 (eventually even with note that this RFC-to-be discusses how to distinguish the services using NAT_TRAVERSAL_MODE). 2) Sec 4.4: \"Hosts SHOULD NOT use values smaller than 5 ms for the minimum Ta,...\" In rfc5245bis this is a MUST. Why is this a SHOULD here? Also in sec 4.6.2.: \"If neither one of the hosts announced a minimum pacing value, a value of 50 ms SHOULD be used.\" This must be a MUST to be inline with sec 4.4. 3) Appendix A: \"Ta value so that only two connectivity check messages are sent on every RTT.\" Why two?  RFC8085  recommends (SHOULD) at may one packet per RTT for non-congestion control transmissions",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-21 04:38:15-08:00",
    "end_reason": "evaluation_closed",
    "start": "2019-07-30 06:17:14-07:00",
    "text": "1) This document should also update the IANA port registry to add a reference to this RFC-to-be to the existing entry for port 10500 (eventually even with note that this RFC-to-be discusses how to distinguish the services using NAT_TRAVERSAL_MODE). 2) Sec 4.4: \"Hosts SHOULD NOT use values smaller than 5 ms for the minimum Ta,...\" In rfc5245bis this is a MUST. Why is this a SHOULD here? Also in sec 4.6.2.: \"If neither one of the hosts announced a minimum pacing value, a value of 50 ms SHOULD be used.\" This must be a MUST to be inline with sec 4.4. 3) Appendix A: \"Ta value so that only two connectivity check messages are sent on every RTT.\" Why two?  RFC8085  recommends (SHOULD) at most one packet per RTT for non-congestion control transmissions",
    "type": "Discuss"
  },
  {
    "ad": "Terry Manderson",
    "end": "2016-06-14 20:38:44-07:00",
    "end_reason": "position_updated",
    "start": "2015-11-17 18:08:45-08:00",
    "text": "I'm not so sure that this will be an easy DISCUSS to work through as I view this in light of future sustainability/deployability of RPKI and any protocol wedded to it (eg BGPSEC). Section 5 \"Additional Requirements\" suggests that both CAs and RPs \"SHOULD\" be capable of supporting a transition and thus able to support multiple RPKI alg. and key profiles. To me this \"SHOULD\" seems like it invites fragility in any such transition. An immediate example would be the root DNSSEC ksk rollover. An rather large amount of work is underway to ascertain the impact. By leaving the SHOULDs in place is this walking the same path?  Let me ask another way. Under what situations is it actually appropriate for a CA or RP to be able to ignore the requirement of being able to support a phased introduction/deprecation of new/different RPKI algorithm and key profiles? And if they ignore such a recommendation does this make the entire RPKI infrastructure a fractured PKI by algorithm?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-02 03:10:47-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 10:49:58-07:00",
    "text": "YANG validator reports the following: yanglint 0.14.80: yanglint --verbose -p {rfclib} -p {draftlib} -p {tmplib} {model} -i: err : The leafref leaf is config but refers to a non-config leaf. (/ietf-subscribed-notifications:subscriptions/subscription/target/stream/stream) err : The leafref leaf is config but refers to a non-config leaf. (/ietf-subscribed-notifications:subscriptions/subscription/target/stream/stream) err : Invalid value \"subscription-policy\" of \"uses\". (/ietf-subscribed-notifications:subscriptions/subscription/subscription-policy) err : Copying data from grouping failed. (/ietf-subscribed-notifications:subscriptions/subscription/subscription-policy) err : Module \"ietf-subscribed-notifications\" parsing failed. I would like to understand whether this is a problem with the document or a problem with the validating tool.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-29 13:20:47-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-29 10:39:30-07:00",
    "text": "[putting this out early in the hopes it can be resolved quickly; I'm just starting to review the document.] This document started life as a rfc5277bis, published in July 2008, before  RFC 5378  ( BCP 78 ) was published in November of 2008.\u00a0 If we are using any text from  RFC 5277  and did not gain the additional rights declaration from the authors of that document, this document needs to use a different boilerplate text (the \"pre-2008\" text).\u00a0 I look at the sibling document draft-ietf-netfonf-yang-push of this document, which does use the pre-2008 boilerplate, and am having a hard time understanding why this document does not also have the pre-2008 boilerplate.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-03 16:57:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-30 14:10:58-07:00",
    "text": "Thanks for this document; I just have a few minor \"housekeeping\" points that should get resolved before publication.\u00a0 (Please also note the substantive comments in the COMMENT section as well, particularly those relating to the transport requirements and security considerations.) I'm not sure that we state clearly enough what is required to have a specification for a transport for notifications.\u00a0 Specifically (see COMMENT), in the module we seem to say that the specification must indicate what the default encoding is to be used if not otherwise specified, but that's not enumerated as a requirement on such a specification anywhere I see.\u00a0 I also think that we could probably require (as opposed to \"highly recommend\" in the current security considerations) that the transport provide message confidentiality and integrity protection. I'm also unsure that I properly understand the use of the \"reset\" RPC -- if it has no effect when transit connectivity already exists, then what entity is going to call \"reset\" in the case of publisher timeout when trying to reach a receiver?\u00a0 Surely not the publisher itself, since that would just be publisher-internal functionality with no need for an external-facing RPC. I'm also a little unclear on the mechanics of the list of subscriptions described in Section 3.3.\u00a0 Does it provide a way for a low-privilege client (that can only access one or a handful of the subscriptions) to enumerate all subscriptions that exist, including subscriptions used by high-privilege clients?\u00a0 If so, we may want to think about some security considerations text to that effect; if not, we may want to say that the access-control will limit which leafs are visible to some clients. Finally, we have a few instances of \"leaf filter-failure-hint\" that's of type \"string\", providing \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Information describing where and/or why a provided filter \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 was unsupportable for a subscription.\"; I don't understand why it's a string as opposed to some form of machine-readable data.\u00a0 Is it supposed to be human-readable?\u00a0 Does that bring in any internationalization considerations?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-06 14:52:05-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-03 16:57:23-07:00",
    "text": "t looks like the description of filter-failure-hint inmodify-subscription-stream-error-info needs the same treatment thatestablish-subscription-stream-error-info\u00a0 received.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-02 05:24:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-02 04:55:34-07:00",
    "text": "My focus when reviewing this document was from a perspective of how to handle overload. I have a hard time understanding how this will actually work, especially in a fashion that preservers goodput and ensure what is considered the most important subscriptions are delivered. Not having good undertanding into netconf and restconf don't hesitate to call out likely missunderstanding by me and provide clarification and pointers.  A) The QoS and priority sending mechanism discussed in 2.3 and furhter defined by the YANG model. I do want to raise the usage of the DSCP code point to a discuss. As the DSCP defines different PHB and relative priorities in the router queues a DSCP value does not provide the publisher any information about priority. I get the feeling from the text that this may be intended. If the only intention is to have the transport perform differential treatment in the network between the publisher and the receiver there are still more considerations are needed. First of all I think these sentence needs a total rewrite: \u00a0  If the publisher supports the \"dscp\" feature, then a subscription \u00a0  with a \"dscp\" leaf MUST result in a corresponding [ RFC2474 ] DSCP \u00a0  marking being placed within the IP header of any resulting \u00a0  notification messages and subscription state change notifications. \u00a0  Where TCP is used, a publisher which supports the \"dscp\" feature \u00a0  SHOULD ensure that a subscription's notification messages are \u00a0  returned within a single TCP transport session where all traffic \u00a0  shares the subscription's \"dscp\" leaf value. I think one need to put a requriement on the transport to use a transport that utilize the DSCP marking on its traffic. Which for the current set of connection oriented transport protocols, TCP, SCTP, and QUIC all currently only support using a single DSCP per connection. Implying multiple transport protocol connections using a particular transport to enable this mapping.  A.2 Queuing model of a publisher.  With the DSCP and the Weight and dependency model I think it is important to clarify the model of the queueing in the publisher. So is the intention that several subscriptions with different weights and possibly dependencies have their individual queues that goes into a scheduler? To avoid complex queue interactions on this level I think there need to be seperate scheduler instances per DSCP. I would also note that Dependency mechanism can't ensure that a dependent stream arrive at receiver after the identified dependency if they are on different DSCP. In fact if one would have HTTP/3 (over QUIC) we may not even guarantee it within a single connection and same DSCP due to packet loss impact. To me this model and what relationship one need to consider here need to be clarified. I think  RFC 7540  Section 5.3.1 is an excellent indication of just the importance of considering what is in the same dependency tree and what it means to have different weighting.  B. The unpredictability of the circuit breaker overload mechanism.  My description of the overload handling in this document is that it is a circuit breaker based mechanism that can blow a fuse on subscriptions that it fails to honor in overload situations. What worries me deply is the total unpredictability of this mechanism.  First, is it the intention to derive what subscriptions are least important from the DSCP, weighting and Dependency parameters? If it is, I think that is a misstake as priority on what subscriptions are most important to retain are not necessarily reflected in their QoS parameters.  Secondly, what are the values when a subscription are considered to be to heavy or not be handled accordingly. Are there any parameter sets that actually describe what SLA the subscriber expect that can be converted into timeout timers or buffer depth thresholds to indicate that publisher side isn't delivering these in time?  Third, I hard time to understand if there are any additional back pressure mechanism between the receiver and the publisher than the transport protocols flow control? So a receiver that is not keeping up processing the data it process will not read out the data out of the flow controlled buffers in the receiver and thus prevent the publisher to write to the transport conncetion, thus causing the publisher to eventually trigger a suspension. Is it correct that this is the only mechanism present?  To my understanding the current mechanism places all subscriptions on the same importance and with the same SLA. Thus likely causing short term overload situations to cause subscription suspensions in random subscriptions. Is the WG fine with this type of randomness occuring and expecting that normally there will be such amount of overprovisioning that being able to indicate priority and SLA are overkill?  C. 2.4.5.\u00a0 Killing a Dynamic Subscription \u00a0  The \"kill-subscription\" operation permits an operator to end a \u00a0  dynamic subscription which is not associated with the transport \u00a0  session used for the RPC.\u00a0 A publisher MUST terminate any dynamic \u00a0  subscription identified by the \"id\" parameter in the RPC request, if \u00a0  such a subscription exists. Can someone please clarify the use case for this functionality. To my understanding it allows another receiver given authority to kill the subscription being delivered to another receiver. Based on the otherwise rather strict that all manipulations of dynamic subscriptions happens from the transport session context that established it I want to better understand the use case it appears out place.  D. The Requirements on a transport supporting Configured Subscriptions Reading through Section 2.5 I arrived at a number of questions. I tried to understand what the requirements are for the",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-10 02:15:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 05:24:33-07:00",
    "text": "My focus when reviewing this document was from a perspective of how to handle overload. I have a hard time understanding how this will actually work, especially in a fashion that preservers goodput and ensure what is considered the most important subscriptions are delivered. Not having good undertanding into netconf and restconf don't hesitate to call out likely missunderstanding by me and provide clarification and pointers.  A) The QoS and priority sending mechanism discussed in 2.3 and furhter defined by the YANG model. I do want to raise the usage of the DSCP code point to a discuss. As the DSCP defines different PHB and relative priorities in the router queues a DSCP value does not provide the publisher any information about priority. I get the feeling from the text that this may be intended. If the only intention is to have the transport perform differential treatment in the network between the publisher and the receiver there are still more considerations are needed. First of all I think these sentence needs a total rewrite: \u00a0  If the publisher supports the \"dscp\" feature, then a subscription \u00a0  with a \"dscp\" leaf MUST result in a corresponding [ RFC2474 ] DSCP \u00a0  marking being placed within the IP header of any resulting \u00a0  notification messages and subscription state change notifications. \u00a0  Where TCP is used, a publisher which supports the \"dscp\" feature \u00a0  SHOULD ensure that a subscription's notification messages are \u00a0  returned within a single TCP transport session where all traffic \u00a0  shares the subscription's \"dscp\" leaf value. I think one need to put a requriement on the transport to use a transport that utilize the DSCP marking on its traffic. Which for the current set of connection oriented transport protocols, TCP, SCTP, and QUIC all currently only support using a single DSCP per connection. Implying multiple transport protocol connections using a particular transport to enable this mapping.  A.2 Queuing model of a publisher.  With the DSCP and the Weight and dependency model I think it is important to clarify the model of the queueing in the publisher. So is the intention that several subscriptions with different weights and possibly dependencies have their individual queues that goes into a scheduler? To avoid complex queue interactions on this level I think there need to be seperate scheduler instances per DSCP. I would also note that Dependency mechanism can't ensure that a dependent stream arrive at receiver after the identified dependency if they are on different DSCP. In fact if one would have HTTP/3 (over QUIC) we may not even guarantee it within a single connection and same DSCP due to packet loss impact. To me this model and what relationship one need to consider here need to be clarified. I think  RFC 7540  Section 5.3.1 is an excellent indication of just the importance of considering what is in the same dependency tree and what it means to have different weighting. To conclude I think this needs a model description and clearer definition and possibly requirements towards the transport. Espceially if you actually need an in-order delivery requirement? B. The unpredictability of the circuit breaker overload mechanism.  My description of the overload handling in this document is that it is a circuit breaker based mechanism that can blow a fuse on subscriptions that it fails to honor in overload situations. What worries me deply is the total unpredictability of this mechanism.  First, is it the intention to derive what subscriptions are least important from the DSCP, weighting and Dependency parameters? If it is, I think that may be a misstake as priority on what subscriptions are most important to retain are not necessarily reflected in their QoS parameters.  Secondly, what are the values when a subscription are considered to be to heavy or not be handled accordingly. Are there any parameter sets that actually describe what SLA the subscriber expect that can be converted into timeout timers or buffer depth thresholds to indicate that publisher side isn't delivering these in time?  Third, I what I understand there are no any additional back pressure mechanism between the receiver and the publisher than the transport protocols flow control? So a receiver that is not keeping up processing the data it process will not read out the data out of the flow controlled buffers in the receiver and thus prevent the publisher to write to the transport conncetion, thus causing the publisher to eventually trigger a suspension due to its queue build up?\u00a0  To my understanding the current mechanism places all subscriptions on the same importance and with the same SLA. Thus likely causing short term overload situations to cause subscription suspensions in random subscriptions. Is the WG fine with this type of randomness occuring and expecting that normally there will be such amount of overprovisioning that being able to indicate priority and SLA are overkill?  At a minimal a change of this sentence in Section 2.5.1 is needed: \u00a0 This could \u00a0  be for reasons of an unexpected but sustained increase in an event \u00a0  stream's event records, degraded CPU capacity, a more complex \u00a0  referenced filter, or other higher priority subscriptions which have \u00a0  usurped resources.  As it states that subscriptions has priorities without reference to a mechanism that provides that priority.  C. 2.4.5.\u00a0 Killing a Dynamic Subscription \u00a0  The \"kill-subscription\" operation permits an operator to end a \u00a0  dynamic subscription which is not associated with the transport \u00a0  session used for the RPC.\u00a0 A publisher MUST terminate any dynamic \u00a0  subscription identified by the \"id\" parameter in the RPC request, if \u00a0  such a subscription exists. Can someone please clarify the use case for this functionality. To my understanding it allows another receiver given authority to kill the subscription being delivered to another receiver. Based on the otherwise rather strict that all manipulations of dynamic subscriptions happens from the transport session context that established it I want to better understand the use case it appears out place.  D. The Requirements on a transport supporting Configured Subscriptions Reading through Section 2.5 I arrived at a number of questions. I tried to understand what the requirements are for the transport that supports Configured Subscriptions. I did note that neither  draft-ietf-netconf-restconf-notif-13  nor  draft-ietf-netconf-netconf-event-notifications-17  supports configured subscriptions. Thus, there appear no template for a solution either, or does there exist another document that is being worked on defining such a transport?  Questions that arose for me related to Configured Susbription Transport where the following: 1. Can Transport Session be initiated in both direction.  RFC 8071  provides a solution for Publisher to Receiver initiation. It is unclear if all parts are in place to have a receiver to publisher initiated transport to be bound to the subscription.  2. What is \"name\" really? It appears to be defined as an empty container. Despite that it appears to have requirements on being both a security identity as well as network address.  3. In Figure 9, which is stated to be for the receiver. What information does the receiver use to determine the transition (d)? And what does it do in this step. Related to Discuss part B).  4.  RFC 8071  appears to lack any considerations for how often and how many times it attempts to connect to the receiver. So applying that mechanism appears to require some usage guidance to avoid causing overload situations or DoS potential by misconfiguring network devices with this soltution to dial out frequently to a target.  As the transport solution requirements are not detail it is actually hard to determine if there are short comings in the description in Section 2.5 and the corresponding YANG model. Is it an reasonable request to document these requirements?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-06 15:08:40-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-30 12:49:28-07:00",
    "text": "Sections 2.4.2.1 and 2.5.6 seems to describe a mechanism (replay) to access historical data that was potentially collected prior to a given subscriber having access to it.\u00a0 This appears to be an explicitly designed feature.\u00a0 No push back on that.\u00a0 However, I believe that explicitly stating this arrangement is warranted.\u00a0 Perhaps something on the order of the following could be added to the Security Considerations -- \u201cThe replay mechanisms described in Sections 2.4.2.1 and 2.5.6 provides access to historical event records.\u00a0 By design, the access control model that protects these records could enable subscribers to view data to which they were not authorized at the time of collection.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-10-14 05:41:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-27 06:27:22-07:00",
    "text": "I have a list of smaller points that should be relatively easy to address. The two main ones: I believe [ I-D.ietf-lisp-sec ] needs to be a Normative Reference for this document. This will address some of the issues raised by Benjamin, but will also make description of various security bits meaningful. Similarly, in Section 5.6: \u00a0  I: This is the xTR-ID bit.\u00a0 When this bit is set, what is appended to \u00a0 \u00a0 \u00a0 the Map-Register is a 128-bit xTR router-ID and then a 64-bit \u00a0 \u00a0 \u00a0 site-ID.\u00a0 See LISP NAT-Traversal procedures in \u00a0 \u00a0 \u00a0 [ I-D.ermagan-lisp-nat-traversal ] for details. This description makes [ I-D.ermagan-lisp-nat-traversal ] a normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-02-07 03:21:29-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-14 05:41:00-07:00",
    "text": "I have a list of smaller points that should be relatively easy to address. The two main ones: I believe [ I-D.ietf-lisp-sec ] needs to be a Normative Reference for this document. This will address some of the issues raised by Benjamin, but will also make description of various security bits meaningful.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-07 05:50:27-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-26 21:51:32-07:00",
    "text": "See my ballot position on rfc6830bis for some more general notes. I did most of my review on the -15, though I attempted to note when the -16 has changed the text. I am concerned about the handling procedures for Map-Requests that are encapsulated with the 'S' bit present.\u00a0 In particular, the ITR is required to discard non-secure responses, which is necessary in order to avoid a downgrade attack (in the current architecture).\u00a0 However, it seems that ETRs are not required to enable security in their registrations, and Map-Servers are supposed to strip the security flag when forwarding Map-Requests to ETRs that do not register as supporting LISP-SEC, and the resulting Map-Reply messages would thus not be secured, and dropped by the initiating ITR.\u00a0 So support for LISP-SEC would need to be mandatory for all ETRs in order for any ITR to be able to enforce the downgrade-protection behavior, which is a pretty bad deployment story.\u00a0 Making LISP-SEC mandatory everywhere would, of course, avoid this issue. I do not understand the procedure for allocation of EIDs.\u00a0 In a global mapping database, there needs to be some authoritative procedure for determining what ETRs and/or Map-Servers are authoritative for a given subset of EID space.\u00a0 All I've seen so far to do this effectively boils down to manual configuration, whether explicitly on a Map-Server or just as a mapping of what keys are authorized to advertise which EIDs. A 64-bit (or in some cases 24-bit) nonce is used, apparently as a request/response correlator, but the actual (cryptographic?) properties required from the nonce in the protocol are not clearly covered.\u00a0 In some cryptographic contexts a 64-bit nonce may be too short; I do not believe that this is the case here, but without a clear picture of what the requirements are it's hard to say for sure.\u00a0 24 bits, on the other hand, is quite small. The layout of the document is somewhat confusing, in a way that could arguably lead to noninteroperable implemnetations.\u00a0 For example, the section on the Map-Register message format includes descriptions of the fields in the records and locators therein, and the section on Map-Notify reuses that portion of the structure, incorporating the field descriptions by reference.\u00a0 But the Map-Register section does not indicate that its descriptions are to apply in both cases, leading to confusing text that talks about values being set or cases that are not possible for a Map-Register (i.e., the section nominally being described).\u00a0 It would be most clear to have a dedicated subsection for the portion of the structure(s) that is being reused, which would allow for the per-field descriptions to clearly indicate in which scope they are defined.\u00a0 But the more minimal change of just indicating that the primary definition will be \"dual use\" would probably suffice as well. The Map-Reply record/locator descriptions are reused similarly; I made a comment on section 5.4 that lists a specific instance, though I believe the phenomenon is more general. Similarly, there are many instances (some noted in my Comment) where a bidirectional interaction between two xTRs is described, yet the peers are identified as \"ITR\" and \"ETR\".\u00a0 This is very confusing when the entity named as \"ITR\" is described as performing ETR functionality, or vice versa; pedagogically, it would be much better to use non-role-based names for the entities while describing these exchanges. While I see that there is an entire document dedicated to Map-Versioning and thus we do not need to fully cover everything here, I think it is critically important to be clear that there are consistency requirements attached to map versions, as relating to the stability of membership of RLOCs in a given record, etc.\u00a0 (I cannot be very clear hear since I am not entirely confident of the details of the consistency requirements yet.) The Map-Register message format field descriptions includes: \u00a0  Nonce:\u00a0 This 8-octet 'Nonce' field is set to 0 in Map-Register \u00a0 \u00a0 \u00a0 messages if no Map-Notify message is expected to acknowledge it. \u00a0 \u00a0 \u00a0 Since the Map-Register message is authenticated, the 'Nonce' field \u00a0 \u00a0 \u00a0 is not currently used for any security function but may be in the \u00a0 \u00a0 \u00a0 future as part of an anti-replay solution. Having the map registrations subject to replay seems like a critical flaw that would allow an attacker to disrupt any sort of mobility situation, even in the presence of LISP-SEC.\u00a0 I cannot see how this protocol could be suitable for Proposed Standard status with such a susceptibility to replay. I think we need more details on the expected Map-Register/Map-Notify and Map-Notify/Map-Notify-Ack message flows.\u00a0 In what cases is the ack not needed, and why? I think we need greater clarity on the 'E' and 'M' bits in the ECM format; more in the Comment section. I am concerned that the extensibility mechanism for ECM encapsulation is insufficiently well specified.\u00a0 Is a registry needed?\u00a0 Will new message types need to Update: this document to indicate the extension?\u00a0 What attributes make a message (un)suitable for encapsulation? Section 8.1 says: \u00a0  o\u00a0 A Negative Map-Reply, with action code of \"Natively-Forward\", from \u00a0 \u00a0 \u00a0 a Map-Server that is authoritative for an EID-Prefix that matches \u00a0 \u00a0 \u00a0 the requested EID but that does not have an actively registered, \u00a0 \u00a0 \u00a0 more-specific ID-prefix. This document provides no mechanism to establish that a Map-Server is authoritative for a given EID-Prefix, so this entire case is non-actionable. Section 8.2 says: \u00a0  An ETR publishes its EID-Prefixes on a Map-Server by sending LISP \u00a0  Map-Register messages.\u00a0 A Map-Register message includes \u00a0  authentication data, so prior to sending a Map-Register message, the \u00a0  ETR and Map-Server SHOULD be configured with a shared secret or other \u00a0  relevant authentication information. This cannot be a SHOULD if things are to work properly; it has to be MUST. Section 8.2 also says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 As developers \u00a0  and operators gain experience with the mapping system, additional, \u00a0  stronger security measures may be added to the registration process. This kind of language for forward-looking guidance indicates that the current security properties are not well-understood by the authors and is inconsistent with Proposed Standard status. Perhaps I am misunderstanding the desired behavior but when Section 8.4 says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  To do this, it forwards the unencapsulated Map-Request, \u00a0  with the original ITR RLOC as the source, to the mapping database \u00a0  system.\u00a0 [...] doesn't this carry substantial risk of running afoul of  BCP 38  filtering? I think the MUST and SHOULD requirements for implementing cryptographic primitives are generally swapped; the more-secure ones (e.g., HMAC-SHA-256-128) should be MUST, and the legacy algorithms needed for compatibility with existing deployments would be SHOULD. Section 9 currently states: \u00a0  [a]s noted in Section 8.2, a Map-Server SHOULD verify that all EID- \u00a0  Prefixes registered by an ETR match the configuration stored on the \u00a0  Map-Server. I think we need a MUST-level requirement for verifying authorization for a given EID-Prefix, with one way of satisfying the requirement being checking configuration, but allowing for other means as well. In the -15, Section 9 also stated: \u00a0  The currently defined authentication mechanism for Map-Register \u00a0  messages does not provide protection against \"replay\" attacks by a \u00a0  \"man-in-the-middle\".\u00a0 Additional work is needed in this area. I don't understand how this sort of statement can be present in a document targetting Proposed Standard status, in effect admitting that there are grave deficiencies in the security posture of the protocol.\u00a0 The -16 has gained some language indicating that LISP-SEC mitigates many attacks in this space, but that is hardly of much use when LISP-SEC is not a mandatory protocol feature. I'm disappointed that there is no Privacy Considerations section, though given that  RFC 7835  seems to attempt to disclaim privacy considerations entirely, perhaps I should not be surprised.\u00a0 Tying devices to persistent Endpoint IDentifiers and using them in mobility situations inherently raises privacy concerns.\u00a0 These are not necessarily fatal to a protocol, but they do need to be discussed and the benefits weighed against the costs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-30 11:53:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-07 05:50:27-08:00",
    "text": "This document has normative dependencies on other WG drafts that are not yet mature (one could perhaps define this as having completed IETF LC).\u00a0 In particular, I believe there is a nontrivial chance that either or both of lisp-sec and 6834bis could require changes to this document in order to be fit for purpose, and thus that this document cannot safely be approved for publication until these normative dependencies are closer to publication. In particular, I have done a fairly full review of lisp-sec and have DISCUSS-worthy points with it (I have not done much review of 6834bis yet). This document includes a mechansism to use HMAC keyed by a pre-shared key to authenticate messages (Map-Register and Map-Notify*); it is directly using the long-term PSK as the HMAC key.\u00a0 This is not really consistent with current IETF best practices (e.g,.  BCP 107 ), which tend to not use the long-term key directly for keying messages, but rather to incorporate some form of key derivation step, to protect the long-term key from cryptanalysis and reduce the need to track long-term per-key data usage limits.\u00a0 It is probably not feasible to directly require all LISP implementations to switch keying strategy, but it seems quite advisable to define new algorithm ID types that include a key derivation step before the HMAC, and to begin efforts to convert the ecosystem to the more sustainable cryptographic usage.\u00a0 I would like to discuss what actions are reasonable to take at this time, on this front. As implied by my previous discuss ballot position, I think Section 5.4 should grow a statement (akin to the one added in Section 5.6) that the \"Record\" format is also used in the \"Map-Reply Record\" field of the Map-Request message, and that the field definitions are reused wholesale for the Map-Register message. In Section 5.6, this text seems internally inconsistent: \u00a0 \u00a0 \u00a0 can continue using an incrementing nonce.\u00a0 If the the ETR cannot \u00a0 \u00a0 \u00a0 support saving the nonce, then when it restarts it MUST use a new \u00a0 \u00a0 \u00a0 authentication key to register to the mapping system.\u00a0 A Map- \u00a0 \u00a0 \u00a0 Server MUST track and save in persistent storage the last nonce \u00a0 \u00a0 \u00a0 received for each ETR xTR-ID that registers to it.\u00a0 If a Map- \u00a0 \u00a0 \u00a0 Register is received with a nonce value that is not greater than \u00a0 \u00a0 \u00a0 the saved nonce, it drops the Map-Register message and logs the \u00a0 \u00a0 \u00a0 fact a replay attack could have occurred. In order for a new key to be useful as stated, the Map-Server must do the nonce tracking per\u00a0 pair and not just per xTR-ID. Also, guidance is needed on what scope of uniqueness is needed for the Key ID to function properly -- unique per Map-Server?\u00a0 Per  pair?\u00a0 Per LISP domain? Also in Section 5.6: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Implementations of this \u00a0 \u00a0 \u00a0 specification MUST include support for either HMAC-SHA-1-96 \u00a0 \u00a0 \u00a0 [ RFC2404 ] and HMAC-SHA-256-128 [ RFC4868 ] where the latter is \u00a0 \u00a0 \u00a0 RECOMMENDED. I don't think this sort of \"mandatory to choose\" is  BCP 201 -compliant. I think there needs to be more description of Site-ID usage and scoping in order to be fully interoperable (more in the COMMENT section). There are multiple places where we talk about message contents being copied from a corresponding request (e.g., from Map-Request to Map-Notify); we need to explicitly state that the authentication data is recomputed to match, e.g., the new message type.\u00a0 I've tried to note these occurrences in the COMMENT section. The condition for Map-Notify-Ack terminating Map-Notify retransmission seems incomplete (more in the COMMENT). In Section 8.2: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  A Map-Register message includes \u00a0  authentication data, so prior to sending a Map-Register message, the \u00a0  ETR and Map-Server SHOULD be configured with a shared secret or other \u00a0  relevant authentication information.\u00a0 [...] We require authentication for Map-Register and do not provide any alternative mechanism for key distribution, so why is this only a SHOULD? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 As developers \u00a0  and operators gain experience with the mapping system, additional, \u00a0  stronger security measures may be added to the registration process. This text does not add confidence to the \"proposed standard\" label. In Section 9: \u00a0  A complete LISP threat analysis can be found in [ RFC7835 ].\u00a0 In what As I have stated previously, the threat analysis in  RFC 7835  is not complete and it should not be referred to as such. \u00a0  3.\u00a0 LISP-SEC [ I-D.ietf-lisp-sec ] MUST be implemented.\u00a0 Network \u00a0 \u00a0 \u00a0  operartors should carefully weight how the LISP-SEC threat model \u00a0 \u00a0 \u00a0  applies to their particular use case or deployment.\u00a0 If they \u00a0 \u00a0 \u00a0  decide to ignore a particular recommendation, they should make \u00a0 \u00a0 \u00a0  sure the risk associated with the corresponding threats is well \u00a0 \u00a0 \u00a0  understood. I'm concerned enough about the risk of having a \"ITR requests lisp-sec but ETR didn't use it\" case that causes complete breakage, that I want to talk about this a bit more.\u00a0 We currently in this document say that lisp-sec is mandatory to implement (which presumably covers at least ITRs, ETRs, Map-Resolvers, and Map-Servers).\u00a0 LISP-SEC itself says that \"and ETR that supports LISP-SEC MUST set the S bit in its Map-Register messages\".\u00a0 Is it possible that an ETR might \"implement\" but then not \"support\" LISP-SEC?\u00a0 If so, then we should consider the possibility that we need an authenticated signal (from the mapping system to the ITR) that downgrading from lisp-sec is allowed.\u00a0 There seem to be several possibilities for how one might construct such a signal; two that came to mind to me would be (1) to define a new ACT value for \"repeat without lisp-sec\" that could be returned as a negative Map-Response directly from the mapping system wherever the mapping system is able to discern that the ETR in question does not support lisp-sec (I don't actually know if this could happen at Map-Resolver or would need to be delayed until the final Map-Server) and (2) to have an optional Map-Request field that the ETR is required to copy unchanged to the Map-Reply; this could then include a message HMAC'd in the ITR-OTK that indicates lisp-sec non-support and binds to the nonce in the request. Whether these are workable ideas seems to depend on aspects of the mapping system to which I cannot speak. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The LISP-SEC \u00a0  protocol defines a mechanism for providing origin authentication, \u00a0  integrity, anti-replay, protection, and prevention of 'man-in-the- \u00a0  middle' and 'prefix overclaiming' attacks on the Map-Request/Map- \u00a0  Reply exchange.\u00a0 [...] Does LISP-SEC actually provide any additional anti-replay protection not present in the base protocol?\u00a0 I do not remember any such additional protection. \u00a0  A complete LISP threat analysis has been published in [ RFC7835 ]. \u00a0  Please refer to it for more detailed security related details. (1) you already said that above, (2) it's still not complete. Section 11 (\"Changes since  RFC 6833 \") is inaccurate (see COMMENT).\u00a0 I did not check whether it is complete, but someone needs to do so before final publication. The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. A 64-bit nonce is used, apparently as a request/response correlator, but the actual (cryptographic?) properties required from the nonce in the protocol are not clearly covered.\u00a0 In some cryptographic contexts a 64-bit nonce may be too short; I do not believe that this is the case here, but without a clear picture of what the requirements are it's hard to say for sure.\u00a0  [ed. there was some previous discussion about 24-bit nonces that has been removed from the text, but the core question of what properties the nonce is required to provide remains unaddressed in the document text.\u00a0 There is also a field called 'Nonce' that is used as a s equence number, the requirements for which are partially described in the new text.] The layout of the document is somewhat confusing, in a way that could arguably lead to noninteroperable implemnetations.\u00a0 For example, the section on the Map-Register message format includes descriptions of the fields in the records and locators therein, and the section on Map-Notify reuses that portion of the structure, incorporating the field descriptions by reference.\u00a0 But the Map-Register section does not indicate that its descriptions are to apply in both cases, leading to confusing text that talks about values being set or cases that are not possible for a Map-Register (i.e., the section nominally being described).\u00a0 It would be most clear to have a dedicated subsection for the portion of the structure(s) that is being reused, which would allow for the per-field descriptions to clearly indicate in which scope they are defined.\u00a0 But the more minimal change of just indicating that the primary definition will be \"dual use\" would probably suffice as well. The Map-Reply record/locator descriptions are reused similarly; I made a comment on section 5.4 that lists a specific instance, though I believe the phenomenon is more general. [ed. this was partially addressed, but the request to examine all data structure reuse (note that \"for example\" was used) was not heeded] Similarly, there are many instances (some noted in my Comment) where a bidirectional interaction between two xTRs is described, yet the peers are identified as \"ITR\" and \"ETR\".\u00a0 This is very confusing when the entity named as \"ITR\" is described as performing ETR functionality, or vice versa; pedagogically, it would be much better to use non-role-based names for the entities while describing these exchanges. [ed. there was some improvement here; I still note some potential sites for confusion in the COMMENT] While I see that there is an entire document dedicated to Map-Versioning and thus we do not need to fully cover everything here, I think it is critically important to be clear that there are consistency requirements attached to map versions, as relating to the stability of membership of RLOCs in a given record, etc.\u00a0 (I cannot be very clear hear since I am not entirely confident of the details of the consistency requirements yet.) I think we need greater clarity on the 'E' and 'M' bits in the ECM format; more in the Comment section. [ed. the reader will need to consult the original ballot's COMMENT section and not the current one] Section 8.1 says: \u00a0  o\u00a0 A Negative Map-Reply, with action code of \"Natively-Forward\", from \u00a0 \u00a0 \u00a0 a Map-Server that is authoritative for an EID-Prefix that matches \u00a0 \u00a0 \u00a0 the requested EID but that does not have an actively registered, \u00a0 \u00a0 \u00a0 more-specific ID-prefix. This document provides no mechanism to establish that a Map-Server is authoritative for a given EID-Prefix, so this entire case is non-actionable. [ed. I think there may have been some previous discussion on this (e.g., that might render it moot) but couldn't find it quickly] Section 8.2 says: \u00a0  An ETR publishes its EID-Prefixes on a Map-Server by sending LISP \u00a0  Map-Register messages.\u00a0 A Map-Register message includes \u00a0  authentication data, so prior to sending a Map-Register message, the \u00a0  ETR and Map-Server SHOULD be configured with a shared secret or other \u00a0  relevant authentication information. This cannot be a SHOULD if things are to work properly; it has to be MUST. Section 8.2 also says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 As developers \u00a0  and operators gain experience with the mapping system, additional, \u00a0  stronger security measures may be added to the registration process. This kind of language for forward-looking guidance indicates that the current security properties are not well-understood by the authors and is inconsistent with Proposed Standard status. I think the MUST and SHOULD requirements for implementing cryptographic primitives are generally swapped; the more-secure ones (e.g., HMAC-SHA-256-128) should be MUST, and the legacy algorithms needed for compatibility with existing deployments would be SHOULD. Section 9 currently states: \u00a0  [a]s noted in Section 8.2, a Map-Server SHOULD verify that all EID- \u00a0  Prefixes registered by an ETR match the configuration stored on the \u00a0  Map-Server. I think we need a MUST-level requirement for verifying authorization for a given EID-Prefix, with one way of satisfying the requirement being checking configuration, but allowing for other means as well.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-30 17:24:33-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-30 11:53:57-07:00",
    "text": "Updating for the -25 by removing points that are fully addressed but leaving points that I still want to have further discussion on.\u00a0 It may be most expedient to continue discussion on my -24 ballot thread.\u00a0 There are a couple of new items to the -25, that I attempt to call out as such (they appear right before the \"the following items were present in my original DISCUSS position\" section). Please also note that the COMMENT section was entirely refreshed for the -24, and I make some additions for the -25. This document has normative dependencies on other WG drafts that are not yet mature (one could perhaps define this as having completed IETF LC).\u00a0 In particular, I believe there is a nontrivial chance that either or both of lisp-sec and 6834bis could require changes to this document in order to be fit for purpose, and thus that this document cannot safely be approved for publication until these normative dependencies are closer to publication. In particular, I have done a fairly full review of lisp-sec and have DISCUSS-worthy points with it (I have not done much review of 6834bis yet). Also in Section 5.6: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Implementations of this \u00a0 \u00a0 \u00a0 specification MUST include support for either HMAC-SHA-1-96 \u00a0 \u00a0 \u00a0 [ RFC2404 ] and HMAC-SHA-256-128 [ RFC4868 ] where the latter is \u00a0 \u00a0 \u00a0 RECOMMENDED. I don't think this sort of \"mandatory to choose\" is  BCP 201 -compliant, since we need to have at least one MTI, strong, algorithm, and this text did not pick one to be MTI.\u00a0 Now (-25) we're at \"SHOULD include support for HMAC-SHA256-128-HKDF-SHA256\", which is also not quite MTI (but is definitely strong).\u00a0 Of course, I personally won't complain if we just go with the new HKDF stuff, but I recognize that it would be a big change for implementations and deployments, and don't think we need to make the spec completely disjoint from reality just to check a box.\u00a0 So we could make HMAC-SHA-256-128 MTI and leave the new one as SHOULD, for example. I think there needs to be more description of Site-ID usage and scoping in order to be fully interoperable (more in the COMMENT section). [ed. Even focusing on the scoping while leaving the detailed usage as deployment-specific would be okay] There are multiple places where we talk about message contents being copied from a corresponding request (e.g., from Map-Request to Map-Notify); we need to explicitly state that the authentication data is recomputed to match, e.g., the new message type.\u00a0 I've tried to note these occurrences in the COMMENT section. [ed. I think just from Map-Notify to Map-Notify-Ack is all that's left] The condition for Map-Notify-Ack terminating Map-Notify retransmission seems incomplete.\u00a0 Specifically, we should only accept the Map-Notify-Ack to stop retransmission if the authentication data validates (and maybe that it uses the same Key-ID as the Map-Notify, though that might be overkill).\u00a0 So just \"a Map-Notify-Ack is received by the  Map-Server with the same nonce\" is not quite enough. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The LISP-SEC \u00a0  protocol defines a mechanism for providing origin authentication, \u00a0  integrity, anti-replay, protection, and prevention of 'man-in-the- \u00a0  middle' and 'prefix overclaiming' attacks on the Map-Request/Map- \u00a0  Reply exchange.\u00a0 [...] Does LISP-SEC actually provide any additional anti-replay protection not present in the base protocol?\u00a0 I do not remember any such additional protection. [ed. specifically, the nonce mechanism already in this document provides a decent level of replay protection, so I am trying to nail down how LISP-SEC does incrementally better than what's already here, for the specific case of an attacker literally recording a Map-Reply and replaying it, bit-for-bit, at a later time. Section 11 (\"Changes since  RFC 6833 \") is inaccurate (see COMMENT).\u00a0 I did not check whether it is complete, but someone needs to do so before final publication. [ed. Waiting to do this until all other changes are in is fine.] New in the -25, there's an internal inconsistency between Section 5.6's description of the Authentication Data procedure, that says implementations \"SHOULD include support for HMAC-SHA256-128+HKDF-SHA256\", and Section 9's \"[a]n implementation MUST support HMAC-SHA256-128+HKDF-SHA256\". Not new in the -25, but IIRC not previously discussed, how does a Map-Server pick a Nonce value for unsolicited Map-Notify messages? The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. I think we need greater clarity on the 'E' and 'M' bits in the ECM format; more in the Comment section [of the ballot on -16], quoted here for clarity: >\u00a0  E:\u00a0 \u00a0 This is the to-ETR bit.\u00a0 When set to 1, the Map-Server's >\u00a0 \u00a0 \u00a0 \u00a0  intention is to forward the ECM to an authoritative ETR. > > I think this needs to say more about which message flows this bit is > defined for.\u00a0 Presumably the ITR will never use it for sending an > encapsulated Map-Request to a Map-Resolver, but there seem to be plenty of > places where ECM wrapping is used. > >\u00a0  M:\u00a0 \u00a0 This is the to-MS bit.\u00a0 When set to 1, a Map-Request is being >\u00a0 \u00a0 \u00a0 \u00a0  sent to a co-located Map-Resolver and Map-Server where the >\u00a0 \u00a0 \u00a0 \u00a0  message can be processed directly by the Map-Server versus the >\u00a0 \u00a0 \u00a0 \u00a0  Map-Resolver using the LISP-DDT procedures in [ RFC8111 ]. > > How does the sender know that its configured Map-Resolver is also a > Map-Server?\u00a0 It's unclear to me why this needs a bit in the message as > opposed to just happening based on the attributes of the receiving > Map-Server.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-08 21:25:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-30 17:24:33-08:00",
    "text": "It looks like an edit or two that was supposed to be in the -26 didn't make it by accident, so sorry for the repeat comments; hopefully the writing work in question will be easy to retrieve. Other than that we're down to just a few remaining points, two of which I believe should be trivial to resolve. In Section 5.6 we say that \"implementations of this spsecification SHOULD include support for HMAC-SHA256-128+HKDF-SHA256 but section 9 says \"implementation MUST support HMAC-SHA256-128+HKDF-SHA256\", which is internally inconsistent; my understanding from a previous discussion with the authors was that HMAC-SHA256-128+HKDF-SHA256 would be a SHOULD and it was HMAC-SHA256-128 that was MUST. The condition for Map-Notify-Ack terminating Map-Notify retransmission seems incomplete.\u00a0 Specifically, we should only accept the Map-Notify-Ack to stop retransmission if the authentication data validates (and maybe that it uses the same Key-ID as the Map-Notify, though that might be overkill).\u00a0 So just \"a Map-Notify-Ack is received by the  Map-Server with the same nonce\" is not quite enough; we'd want to say \"an authenticated Map-Notify-Ack is received by the Map-Server with the same nonce\". In Section 9: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The LISP-SEC \u00a0  protocol defines a mechanism for providing origin authentication, \u00a0  integrity, anti-replay, protection, and prevention of 'man-in-the- \u00a0  middle' and 'prefix overclaiming' attacks on the Map-Request/Map- \u00a0  Reply exchange.\u00a0 [...] I think this document provides anti-replay protection for the Map-Request/Map-Reply exchange (by virtue of the single-use nonce), so we should remove \"anti-replay\" from the list of features LISP-SEC provides for the Map-Request/Map-Reply exchange. I think we need greater clarity on the 'E' and 'M' bits in the ECM format; are we perhaps defining them now in anticipation of future usage by other documents (e.g., ones that define specific mapping system implementations)? in particular (with quotes from my ballot position on the -24 for context): >\u00a0  E:\u00a0 \u00a0 This is the to-ETR bit.\u00a0 When set to 1, the Map-Server's >\u00a0 \u00a0 \u00a0 \u00a0  intention is to forward the ECM to an authoritative ETR. > > I think this needs to say more about which message flows this bit is > defined for.\u00a0 Presumably the ITR will never use it for sending an > encapsulated Map-Request to a Map-Resolver, but there seem to be plenty of > places where ECM wrapping is used. IIUC, the main ECM-wrapped messages we consider in this document are ITR-to-Map-Resolver Map-Requests and Map-Server-to-ETR Map-Requests. Is it an invariant that the ECM 'E' and 'M' bits can never be set at the same time (as they are only defined to have meaning for the different flows I list)? In an off-list discussion I got a clarification that \"The ETR bit is used so the Map-Server knows that the entity registering is an xTR versus a SDN or other type of controller that is registering mappings but doesn\u2019t have a full LISP protocol engine implementation and can\u2019t send Map-Replies\" which sounds like it applies to a Map-Register (\"is registering mappings\") but I didn't think that Map-Register was defined as a possible LCM to be in an ECM.\u00a0 (Maybe I'm just confused about that.) The main thing I still don't understand here is: what entity is going to interpret the E-bit and change behavior depending on its value? > >\u00a0  M:\u00a0 \u00a0 This is the to-MS bit.\u00a0 When set to 1, a Map-Request is being >\u00a0 \u00a0 \u00a0 \u00a0  sent to a co-located Map-Resolver and Map-Server where the >\u00a0 \u00a0 \u00a0 \u00a0  message can be processed directly by the Map-Server versus the >\u00a0 \u00a0 \u00a0 \u00a0  Map-Resolver using the LISP-DDT procedures in [ RFC8111 ]. > > How does the sender know that its configured Map-Resolver is also a > Map-Server?\u00a0 It's unclear to me why this needs a bit in the message as > opposed to just happening based on the attributes of the receiving > Map-Server. It sounds like this is only useful when the ECM contains a Map-Request from ITR to Map-Resolver, but I don't know how an ITR would know to (not) set this bit or what entity is going to change behavior depending on the value of the bit.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-27 18:04:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-08 21:25:47-07:00",
    "text": "(1) The -27 brought back the \"MUST\" for HMAC-SHA256-128 in Section 5.6 per my ballot on the -26, but left unchanged section 9, so we still have a SHOULD vs. MUST inconsistency w.r.t. implementing HMAC-SHA256-128+HKDF-SHA256.\u00a0 (I would of course prefer the same resolution of the inconsistency that Roman does, but have forgotten to what extent we have to defer to the deployed reality.) (2) It looks like the update in Section 5.7 is attempting to address my point about only terminating Map-Notify retransmission when the authentication data of the Map-Notify-Ack validates, but the added text is either misplaced or malformed.\u00a0 Perhaps CURRENT: \u00a0  The Map-Notify-Ack message has the same contents as a Map-Notify \u00a0  message.\u00a0 It is used to acknowledge the receipt of a Map-Notify and \u00a0  for the sender to stop retransmitting a Map-Notify with the same \u00a0  nonce and the authentication data validates.\u00a0 [...] NEW: \u00a0  The Map-Notify-Ack message has the same contents as a Map-Notify \u00a0  message.\u00a0 It is used to acknowledge the receipt of a Map-Notify and, \u00a0  once the the authentication data is validated, allows for the \u00a0  Map-Notify sender to stop retransmitting a Map-Notify with the same \u00a0  nonce. [...] (3) I think that Eric Rescorla's concern about a misbehaving ETR being able to prevent an ITR from learning that the ETR is no longer the appropriate ETR for a given prefix remains unaddressed.\u00a0 I wrote up a longer description at https://mailarchive.ietf.org/arch/msg/lisp/O2ycn4CkWsPhFyqrZuB4ZJBNnl0/ but in short, we only require the ITR to send its Map-Request through the mapping system (vs. directly to the ETR) when SMR is sent from an address not in the current mapping data for that prefix -- if the SMR is sent from an address in the current mapping data, we allow sending Map-Request directly to the ETR, outside the mapping system.\u00a0 I don't see a mechanism that guarantees that such a \"revocation\" event is noticed by the ITR. (4) The specification of the MAC+KDF algorithms doesn't seem detailed enough to be implementable.\u00a0  RFC 4868  is attempted to be used as a reference for both HMAC-SHA256-128 (er, and the one-character-off HMAC-SHA-256-128) and HKDF-SHA2562 (note spurious final '2'), but I think it can only work as a reference for the MAC algorithm.\u00a0 Presumably we need  RFC 5869  or such for the KDF part (5) This is probably my fault, but we're missing a step with how we describe the Map-Notify/Map-Notify-Ack per-message authentication. Specifically, while we do say that the authentication data needs to be recomputed each time, we don't clearly state that this is because the correct per-message key is different, because we are using a different 's' input to the KDF function for the different messages.\u00a0 In line with the \"Map-Register Authentication\" used for Map-Register, this would presumably be \"Map-Notify Authentication\" and \"Map-Notify-Ack Authentication\", but neither of those strings appear in this document. We might be able to localize the change to Section 5.6, akin to OLD: \u00a0 \u00a0 \u00a0 4:\u00a0 The derived per-message key is computed as: per-msg- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 key=KDF(nonce+s+PSK[Key ID]).\u00a0 Where the nonce is the value in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the Nonce field of the Map-Register and 's' is a string equal \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 to \"Map-Register Authentication\".\u00a0 [...] NEW: \u00a0 \u00a0 \u00a0 4:\u00a0 The derived per-message key is computed as: per-msg- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 key=KDF(nonce+s+PSK[Key ID]).\u00a0 Where the nonce is the value in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the Nonce field of the Map-Register and 's' is a string that \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 corresponds to the message type being authenticated.\u00a0 For \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Map-Register messages, it is equal to \"Map-Register \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Authentication\".\u00a0 Similarly, for Map-Notify and Map-Notify-Ack \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 messages, it is \"Map-Notify Authentication\" and \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Map-Notify-Ack Authentication\", respectively. However, I think the rhetoric would be more robust if we also modified Section 5.7 to mention the existence of the different 's' values (or, rather, the different per-message key) when we say that the authentication data is recomputed.\u00a0 Perhaps, s/is recomputed/is recomputed using the corresponding per-message key/ (twice).",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2018-11-30 12:41:00-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-27 06:58:05-07:00",
    "text": "ANA has requested a Temporary Discuss related to issue with port assignments.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-27 05:14:42-07:00",
    "text": "This DISCUSS is somewhat arbitratrily on 6833bis, but many of the same issues apply to 6830bis. I concur with Ben's DISCUSS. I do not believe that these documents have adequate security to advance to Proposed Standard. I thought it might be helpful for me to lay out my starting assumptions and threat model and what I think the appropriate standard is here. That gives us an opportunity to discuss them prior to getting into the specific security issues I raise below. SYSTEM ARCHITECTURE Per offline discussion, I understand that despite some of the introductory material, LISP is not currently intended to be Internet scale but rather to run in what seem to be fairly tightly controlled environments. Thus, I am assuming the following facts about the system: - The Mapping Service itself is secure and trusted.\u00a0 For the purposed \u00a0 of this discussion, I'm modelling all the entities in the services \u00a0 as one trusted element. - The ETRs have a preconfigured relationship with the Mapping Service, \u00a0 which includes some sort of shared key and an ACL on the Mapping \u00a0 Service which tells it which EIDs anm ETR can advertise. How \u00a0 this gets established is out of scope of this discussion. Note that neither of these assumptions would be reasonable in an Internet scale system, but I'm assuming that the text about that in these documents will be removed. Because it's not in the document set before us, nor is it a normative reference, I am disregarding LISP-SEC and only analyzing the system as specified in these documents. THREAT MODEL I'm assuming the usual  RFC 3552  threat model, I.e., - All non-Map Server elements in the system (specifically, endpoints \u00a0 and the xTRs are potentially malicious). \u00a0  - Aside from the links between the Map Server elements, the network \u00a0 is controlled by the attacker. Against this background, my expectation is that the attacker should not be able to affect traffic in any fashion significantly more effective than tampering with the data plane. For instance, it's clearly the case that an on-path attacker between two xTRs can drop all the packets or forward them to some third xTR, but it should not be able to send a small number of packets which would then affect the routing of a large number of packets. I do not expect that the data plane should have better security than native (non-IPsec) traffic. Given the nature of LISP and the existence of a mapping system, it seems like it's kind of a missed opportunity to deploy a credentials system that would support IPsec-style data plane security, but given that this isn't a generally safe assumption for IP traffic, and therefore you need to provide some sort of transport or application security anyway, I don't think it's the right standard to hold LISP to. ATTACKS LISP appears to be vulnerable to a number of routing attacks that I claim above it should not be subject to. For example: 1. An on-path attacker can forge Map Replys to the ITR, \u00a0  thus redirecting traffic. 2. An ETR can perform an \"overclaiming\" attack in which it \u00a0  claims to be responsible for EIDs which it is not actually \u00a0  responsible for. 3. An off-path attacker can temporarily reroute traffic by exploiting \u00a0  the \"gleaning\" feature to cache poison an ITR. In addition, the \u00a0  \"echo noncing\" feature does not appear to have a sufficiently strong \u00a0  nonce to protect against forgery, and thus turning this into a \u00a0  long-term attack 4. An attacker may be able to perform a number of cache invalidation \u00a0  and contamination attacks by exploiting the Map-Version and \u00a0  Locator-Status bits. This may lead to DoS. 5. An attacker who was at time T responsible for an EID block \u00a0  can probably prolong its ability to respond for that block \u00a0  even after it is no longer responsible. \u00a0  6. A number of the components appear to be subject to various replay \u00a0  attacks. I note that many of these attacks are documented in the Security Considerations for these documents. Also, I doubt this list is exhaustive. As noted above, I have spent no time on the data plane protocol. DEFENSES When looking at attacks, it's important to determine whether there are plausible defenses. For most of these, I believe that the answer is \"yes\", at varying levels of cost. As noted above, LISP-SEC appears to be intended to address a number of these issues, so it's possible that requiring LISP-SEC would go a fair ways towards addressing these issues. A cursory look at LISP-SEC turns up some somewhat concerning design choices, so I would have to examine it more closely to give a real opinion. I do not believe that LISP-SEC will address the attacks that do not involve the Mapping Server. For instance, the gleaning contamination/nonce attacks (3) would not appear to be fixed by LISP-SEC. However, it's probably possible to fix them by lengthening the nonce. With that said, I tend to think that the overall authentication architecture here would benefit from a rethink. At a high level, the source of most of these problems is the \"non-transferability\" of the mapping information from the Map Server. If the Map Server instead had an asymmetric key pair which it used to sign mappings, then almost all of these attacks would not work. Specifically: - The map server could send signed Map Replys so forgery wouldn't work - Map Replys from ETRs would be signed, so you couldn't overclaim - Gleaning attacks would sort of work, but because the probe would \u00a0 elicit a Map Reply, you couldn't persist them - Map Versions could be tied to signed objects, so you couldn't do \u00a0 cache invalidation by version. You'd probably need some other \u00a0 approach for Locator Status bits. And so on. Detailed review below, with some duplication.... Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4115 IMPORTANT S 5.2. >\u00a0 \u00a0 \u00a0 s: This is the SMR-invoked bit.\u00a0 This bit is set to 1 when an xTR is >\u00a0 \u00a0 \u00a0 \u00a0  sending a Map-Request in response to a received SMR-based Map- >\u00a0 \u00a0 \u00a0 \u00a0  Request. >\u00a0   >\u00a0 \u00a0 \u00a0 m: This is the LISP mobile-node m-bit.\u00a0 This bit is set by xTRs that >\u00a0 \u00a0 \u00a0 \u00a0  operate as a mobile node as defined in [ I-D.ietf-lisp-mn ]. This would appear to create a normative reference to this document. To avoid that, you need to specify how I behave if I receive it but I don't implement lisp-mn. S 5.2. >\u00a0 \u00a0 \u00a0 m: This is the LISP mobile-node m-bit.\u00a0 This bit is set by xTRs that >\u00a0 \u00a0 \u00a0 \u00a0  operate as a mobile node as defined in [ I-D.ietf-lisp-mn ]. >\u00a0   >\u00a0 \u00a0 \u00a0 I: This is the xTR-ID bit.\u00a0 When this bit is set, what is appended to >\u00a0 \u00a0 \u00a0 \u00a0  the Map-Request is a 128-bit xTR router-ID.\u00a0 See LISP PubSub usage >\u00a0 \u00a0 \u00a0 \u00a0  procedures in [ I-D.ietf-lisp-pubsub ] for details. here too you seem to be creating a normative reference. S 5.5. >\u00a0 \u00a0 \u00a0 \u00a0  is being mapped from a multicast destination EID. >\u00a0   >\u00a0  5.5.\u00a0 EID-to-RLOC UDP Map-Reply Message >\u00a0   >\u00a0 \u00a0 \u00a0 A Map-Reply returns an EID-Prefix with a prefix length that is less >\u00a0 \u00a0 \u00a0 than or equal to the EID being requested.\u00a0 The EID being requested is How do I behave if I receive an EID-Prefix that is less than any of my mappings. So, I might have mappings for 10.1.0.0/16 and 10.2.0.0/16 and someone asks me for 10.0.0.0/8? Also, when you talk about prefix length, I assume you mean the length fo the mask? S 5.6. >\u00a0 \u00a0 \u00a0 Authentication Data:\u00a0 This is the message digest used from the output >\u00a0 \u00a0 \u00a0 \u00a0  of the MAC algorithm.\u00a0 The entire Map-Register payload is >\u00a0 \u00a0 \u00a0 \u00a0  authenticated with this field preset to 0.\u00a0 After the MAC is >\u00a0 \u00a0 \u00a0 \u00a0  computed, it is placed in this field.\u00a0 Implementations of this >\u00a0 \u00a0 \u00a0 \u00a0  specification MUST include support for HMAC-SHA-1-96 [ RFC2404 ], >\u00a0 \u00a0 \u00a0 \u00a0  and support for HMAC-SHA-256-128 [ RFC4868 ] is RECOMMENDED. What prevents replay attacks here? I'm guessing it's the Map-Version- Number, but as I understand it, I can set this to 0. S 6.1. >\u00a0 \u00a0 \u00a0 receives an SMR-based Map-Request and the source is not in the >\u00a0 \u00a0 \u00a0 Locator-Set for the stored Map-Cache entry, then the responding Map- >\u00a0 \u00a0 \u00a0 Request MUST be sent with an EID destination to the mapping database >\u00a0 \u00a0 \u00a0 system.\u00a0 Since the mapping database system is a more secure way to >\u00a0 \u00a0 \u00a0 reach an authoritative ETR, it will deliver the Map-Request to the >\u00a0 \u00a0 \u00a0 authoritative source of the mapping data. If I'm understanding this correctly, this allows an ETR to prevent an ITR from learning that it is no longer the appropriate ETR for a prefix. The way this attack works is that before the topology shift, I send SMRs, thus causing Map-Requests, which, because my entry is cached, refresh the cache on the ITR past the topology shift. I can keep doing this indefinitely. Am I missing something S 8.2. >\u00a0 \u00a0 \u00a0 authentication data, so prior to sending a Map-Register message, the >\u00a0 \u00a0 \u00a0 ETR and Map-Server SHOULD be configured with a shared secret or other >\u00a0 \u00a0 \u00a0 relevant authentication information.\u00a0 A Map-Server's configuration >\u00a0 \u00a0 \u00a0 SHOULD also include a list of the EID-Prefixes for which each ETR is >\u00a0 \u00a0 \u00a0 authoritative.\u00a0 Upon receipt of a Map-Register from an ETR, a Map- >\u00a0 \u00a0 \u00a0 Server accepts only EID-Prefixes that are configured for that ETR. How does it know?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-11-06 13:29:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 01:19:28-07:00",
    "text": "[ __all__ ] * Is there somewhere a broad prohibition for all IPv6 EID addresses and IPv6 \u00a0 EID prefixes that they MUST NOT be IPv6 link-local addresses? \u00a0 Related: are there any use cases for an IPv6 link-local RLOC?\u00a0 Perhaps in \u00a0 some IXP scenarios? [ section 5.5 ] * Are these example prefixes correct?\u00a0 2001:db8::/16 is really just 2001::/16, \u00a0 right? Similarly, I think /24 should be /48 and /32 should be /64, yes? \u00a0 I feel like I must be misunderstanding something important...",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-10-28 09:03:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-06 15:51:22-07:00",
    "text": "Two issues rise to DISCUSS level, IMO: Sec 5.7. Is the intent that the Map-Notifies are only retransmitted if they are unsolicited? If not, repeated Map-Registers could result in a storm of Map-Notifies. Sec 7.1. I very well may have missed something, but it doesn't look like the Map-Request is authenticated. So how can the ETR safely update its Map Cache based on the information in the Map-Reply?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-11-24 15:24:43-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-28 09:03:30-07:00",
    "text": "Two issues rise to DISCUSS level, IMO: Sec 5.7. Is the intent that the Map-Notifies are only retransmitted if they are unsolicited? If not, repeated Map-Registers could result in a storm of Map-Notifies. Thanks for addressing the second DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-11 08:01:43-07:00",
    "text": "1) Versioning and backward compatibility Section 5.2 says: \"Support for requesting multiple EIDs in a single Map-Request \u00a0 \u00a0 \u00a0 message will be specified in a future version of the protocol.\" However, there is no versioning mechanism for this protocol specified. How is versioning supposed to work? Further given there is no new version, I wonder if the changes as outlined in section 10 are all backward-compatible? Especially for the introduction of the Message-Notify-Ack message, I guess there is no problem if a server sends it, however, as the sender of the Message-Notify message might not know if the other end supports sending of the Message-Notify-Ack it can't rely on it. This should be further discussed in the doc! Or is there another strategy to achieve backward compatibility? 2) Size and MTU As outlined in the TSV-ART review (Thanks Colin!) this document does not discuss fragmentation or Path MTU discovery.  RFC8085  recommends to either perform Path MTU discovery or limit the message to 576 bytes for IPv4 or 1280 bytes for IPv6 (minus any static header). As this seems to be an appropriate size for LISP messages, I would recommend this approach. Relying on IP fragmentation (as indicated in the reply to the TSV-ART review) is not recommended by  RFC8085  as this would lead to IP packet without a UDP header, in the case of LISP, which can cause problem and loss when NATs are involved. In any case the chosen approach needs to be further discussed in the doc. 3) Rate-limiting and congestion control Sec 5.3: \"Map-Requests MUST be rate-limited.\u00a0 It is RECOMMENDED that a Map- \u00a0  Request for the same EID-Prefix be sent no more than once per second.\" As already noted by the TSV-ART review (Thanks Colin!),  RFC8085  actually recommends to not send more the one packet per 3 seconds, and that is a restriction for all traffic not on a per-receiver base, or implement congestion control. This limit is meant to not only protect the receiver but also the network from overloading. Why do you use a smaller interval here? Also if (appropriate) rate limiting is used, this should either be a MUST or more explanation when it is okay to use a smaller rate limit should be provided. However, after all, I don't think you those the right approach here for rate limiting. A Map-Request is always expected to be followed by some reply. For these kind of communication pattern,  RFC8085  recommends to limit the number of outstanding requests to 1 (see sec 3.1.1 of  RFC8085  recommending one packet per RTT), also for all traffic and not only per receiver. However, this would also require to implement some simple mechanism to detect a message as lost (see also further below in point 4). Similarly I'm not sure about the intent of this requirement in section 5.5: \"Map-Replies SHOULD be sent for an EID-Prefix no more often than once \u00a0  per second to the same requesting router. \" My understanding is that Replies are only sent when a request is received. Why is this additional rate limit needed? Again if used it should be 3 seconds for all traffic to be inline with  RFC8085 . Also again, why is that not a MUST? Further recommendation are needed here. Further section 6.1 say \"Both the SMR sender and the Map-Request responder MUST rate-limit \u00a0  these messages.\u00a0 Rate-limiting can be implemented as a global rate- \u00a0  limiter or one rate-limiter per SMR destination.\" This seems to be the same rate limit as mention above, or not...? It would probably make sense to rate limit the SMR even further. Please clarify and provide more guidance, e.g. what should the value of a potential additional rate limit for SMR be? Respectively the following sentence in section 6.1 is also unclear: \"The remote ITR MUST rate-limit the Map-Request until it gets a Map-Reply\" Why is the rate-limit as currently proposed depend on the fact if a Map-Reply is received? Is the ITR supposed to retransmit the Map-Request...?  And finally the Map-Register, Map-Notify and Map-Notify-Ack messages does not seem to have any rate-limits. Recommendations inline with  RFC8085  should be provided for the total traffic and not only for a few message types. Again, Map-Notify and Map-Notify-Ack messages should be send only once per RTT as there is a feedback mechanism. For Map-Register sec 8.2 say: \"Map-Register messages are sent periodically from an ETR to a Map- \u00a0  Server with a suggested interval between messages of one minute.\" However, this a rather a low bound than an upper bound. A required (MUST) rate limit is still needed. 4) Loss detection and retransmission As also mention by the TSV-ART review (Once more thanks to Colin!), this spec has an ACK mechanism for Map-Requests and now also for Map-Notify, however, it does not specify what to do if the ACK is not received (loss detection and retransmission scheduling). This makes the spec incomplete and needs to be further specified in the doc (and also has a relation to the point 3 above of course).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:38:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-07 20:04:32-07:00",
    "text": "** The applicability statement in Section 1.1. notes that this will be used on the \u201cpublic Internet\u201d.\u00a0 Therefore, I think we need to consider the use of \u201csecure defaults\u201d.\u00a0 Making lisp-sec and a strong MAC-KDF mandatory to implement is helpful.\u00a0 However, it\u2019s use must also be normatively specified.\u00a0 Specifically, stronger guidance needs to be given when communicating over the public Internet.\u00a0 My thinking would be something like: -- lisp-sec SHOULD (MUST?) be used in for Map-Reply, Map-Notify, Map-Notify-Ack and ECM (i.e. SHOULD/MUST set S=1) -- Map-Register SHOULD (MUST?) use HMAC-SHA256-128+HKDF-SHA256 -- MUST NOT use Algorithm ID = 0 and 1",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-04-16 12:57:36-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-16 10:38:17-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3382 DETAIL >\u00a0 \u00a0 \u00a0 When an offerer generates an offer, in which it wants to add a new >\u00a0 \u00a0 \u00a0 bundled \"m=\" section, the offerer MUST: >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 Assign the offerer BUNDLE address:port (previously selected >\u00a0 \u00a0 \u00a0 \u00a0  [Section 8.3.1] or newly suggested [Section 8.5.1]) to the added >\u00a0 \u00a0 \u00a0 \u00a0  \"m=\" section; or IMPORTANT: This doesn't sound right. You can't use the existing address:port, because if the peer rejects BUNDLE but accepts the m= section then it's broken. >\u00a0 \u00a0 \u00a0 o\u00a0 When the BUNDLE transport has been established, ICE connectivity >\u00a0 \u00a0 \u00a0 \u00a0  checks and keep-alives only need to be performed for the BUNDLE >\u00a0 \u00a0 \u00a0 \u00a0  transport, instead of per individual \"m=\" section within the >\u00a0 \u00a0 \u00a0 \u00a0  BUNDLE group. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 In an offer, if the offer assigns a unique address:port to one or IMPORTANT: This does not define how to interact with trickle ICE.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-05-19 13:18:20-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-16 12:57:36-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3382 DETAIL >\u00a0 \u00a0 \u00a0 When an offerer generates an offer, in which it wants to add a new >\u00a0 \u00a0 \u00a0 bundled \"m=\" section, the offerer MUST: >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 Assign the offerer BUNDLE address:port (previously selected >\u00a0 \u00a0 \u00a0 \u00a0  [Section 8.3.1] or newly suggested [Section 8.5.1]) to the added >\u00a0 \u00a0 \u00a0 \u00a0  \"m=\" section; or IMPORTANT: This doesn't sound right. You can't use the existing address:port, because if the peer rejects BUNDLE but accepts the m= section then it's broken. >\u00a0 \u00a0 \u00a0 o\u00a0 When the BUNDLE transport has been established, ICE connectivity >\u00a0 \u00a0 \u00a0 \u00a0  checks and keep-alives only need to be performed for the BUNDLE >\u00a0 \u00a0 \u00a0 \u00a0  transport, instead of per individual \"m=\" section within the >\u00a0 \u00a0 \u00a0 \u00a0  BUNDLE group. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 In an offer, if the offer assigns a unique address:port to one or IMPORTANT: This does not define how to interact with trickle ICE.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-05 07:55:31-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-06 07:22:08-07:00",
    "text": "This is the same as Ben's DISCUSS point, but I think this is important enough to fix:  Please replicate the appropriate info from the  RFC 5205  IANA considerations. The similar section in this draft does not seem to stand alone. Readers should not need to refer back to the obsoleted RFC to understand this version. RFC 4648  actually has 2 base64 encodings, so you should say which section number you mean (section 4 or section 5). I suspect you meant section 5.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-02-01 23:52:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-01 03:00:09-08:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS points (probably easy to address as I am not a YANG expert), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Please also have a look at Ted Lemon's INT directorate review at . I share Ted's concern about have three independent topics in a single document rather than in 3 documents. Special thanks to Valery Smyslov for the shepherd's write-up including the section about the WG consensus even if I had appreciated a justification for the PS status.  I hope that this helps to improve the document, Regards, -\u00e9ric ## Section 8.1.5 (and others) Please note that I am not a YANG expert, but it seems to me that \"attack-detail* [vendor-id attack-id]\" indicates that vendor-id & attack-id are the keys to attack-detail, i.e., there can only have one attack-detail per pair of vendor-id & attack-id. So, there is no way to have multiple sequential/simultaneous attacks, i.e., should the start-time be also part of the key? As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-03 01:54:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-01 04:30:41-08:00",
    "text": "Thank you for the work on this document, which I found particularly well written and easy to read despite its length. Many thanks to James Gruessing for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/MbTX3xfg6tMeG6mieAsT7hA3gXs/ , and to the authors for addressing James' comments.  I have an easy to fix DISCUSS concerning the examples, and a point about a MUST which should not be there IMO. I also have a number of comments and question that I hope will help improving the document (or my understanding of it). I support Roman's DISCUSS, see  https://trac.ietf.org/trac/art/wiki/TypicalARTAreaIssues#LanguageTags . To answer Ben's note - IMO the text about \"enterprise numbers\" and \"Private Enterprise Numbers\" is clear enough. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0  JSON encoding of YANG-modeled data is used to illustrate the various \u00a0  telemetry operations. FP: There is an inconsistency between this text and the use of \"application/dots+cbor\" in the examples. Either the Content-Format should be changed, or all the examples should be adapted to JSON Content-Format (I am not sure about what Content-Format you should use then, you probably know better). My preference is to keep CBOR and keep the Content-Format. I went through all the examples and reported below the inconsistencies. Section 7.1.2, Figure 4, 5, FP: If in CBOR, the percentiles should be expressed with the tagged item Decimal fraction (represented as a tagged array). 2. ----- Section 7.2.1, Figure 11, 13, 15, 17 FP: Same comment as 1: unit and peak-g should be unsigned in CBOR. 3. ----- Section 7.3.1, Figure 19, 20 FP: Same comment as 1: capacity and unit should be unsigned in CBOR. 4. ----- Section 7.2.1, Figure 11, 13, 15, 17 FP: Same comment as 1: unit and peak-g should be unsigned in CBOR. 5. ----- Section 7.3.1, Figure 19, 20 FP: Same comment as 1: capacity and unit should be unsigned in CBOR. 6. ----- Figure 36, figure 43 FP: Same comment as 1: unit, mid-percentile-g, start-time and attack-severity should be unsigned in CBOR. 7. ----- Figure 45, 47 FP: attack-status, unit, mid-percentile-g, peak-g should be unsigned. I also note that some of the attributes defined in 9132 are used here and on previous examples and have for values the full spelled out meaning for readability, instead of the actual parameter (for example \"status\", that should have value 2 for \"attack-successfully-mitigated\"), and I think that should be at least noted in the text before the example, or if you want to be more precise the \"attack-successfully-mitigated\" could be a comment next to the value 2. 8. ----- Section 7.1.3 \u00a0  client, it MUST respond with a 4.04 (Not Found) error Response Code. FP: I have a preference to remove this MUST here - it is expected behavior that if a resource is not present the server responds with 4.04, so it is not necessary to add the requirement here, actually redefining the response code (although it is the expected one in this case) should be discouraged. I suggest replacing: s/it MUST respond/it responds. (Note that 7.1.4 has the text I would expect, describing the behavior but not adding any already existing requirements).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-03 07:26:06-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 01:54:20-08:00",
    "text": "Thank you for the work on this document, which I found particularly well written and easy to read despite its length. Many thanks to James Gruessing for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/MbTX3xfg6tMeG6mieAsT7hA3gXs/ , and to the authors for addressing James' comments.  To answer Ben's note - IMO the text about \"enterprise numbers\" and \"Private Enterprise Numbers\" is clear enough. I will keep this DISCUSS as a placeholder to discuss my concerns with the responsible AD during the telechat, but expect to remove it afterward, given that the additions in v-21 mostly address 1-7 and 8 has precedent for it in 9132. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-02-03 06:56:39-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 01:58:24-08:00",
    "text": "The protocol uses traffic capacities in various ways (for pipe, baseline and connection capacity, etc.) but doesn't indicate at what layer these capacities are to be interpreted? L2? L3? (L1??) Would the difference in header overhead cause issues when senders and receivers use different interpretations here?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-03 07:06:34-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-31 12:37:57-08:00",
    "text": "** Sections 8.1.5 and 9.1. These sections describe a human readable text field, \u201cattack-description\u201d.\u00a0 Per Section 4.2 of  BCP 18 , \u201c[p]rotocols that transfer text MUST provide for carrying information about the language of that text.\u201d.\u00a0 Practically, can a field to list a language tag field ( RFC 5646  and  https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry ) be added in all places that \u201cattack-description\u201d is defined or at the top level?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-02-02 11:10:37-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-02 08:59:43-08:00",
    "text": "Please note: This really is just a DISCUSSion - I'm happy to be educated / wrong, but I do think that it is important enough that it gets addressed. The 'unit-class' and 'unit' enumerations seems like they add a large amount of complexity for (AFAICT) very little gain.  Do you really need: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Packets per second (pps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Bits per Second (bps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Bytes per second (Bps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Kilo packets per second (kpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Kilobits per second (kbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Kilobytes per second (kBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Mega packets per second (Mpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Megabytes per second (MBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Giga packets per second (Gpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Gigabits per second (Gbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Gigabytes per second (GBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Tera packets per second (Tpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Terabits per second (Tbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Terabytes per second (TBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Peta packets per second (Ppps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Petabits per second (Pbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Petabytes per second (PBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Exa packets per second (Epps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Exabits per second (Ebps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Exabytes per second (EBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Zetta packets per second (Zpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Zettabits per second (Zbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Zettabytes per second (ZBps).\" when just Packets Per Second and Bits Per Second would work? Yes, you might have to have a really large number in BPS, but that seems much much less likely to lead to errors than having parsers have to deal with this. When a user enters a number their glass would presumably allow them to use a more convenient unit, but having it encoded and decoded into this seems needlessly complex. I did look through the document and list to try and find discussions on this point - I'm happy to be pointed at a place where it was discussed and agreed.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-01 07:05:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-30 13:00:58-07:00",
    "text": "Overall the document looks fine, although I wish it had copied less content and depended only on the references cited to avoid accidental errors. I think I checked most of these and they seem fine, but it is possible authors/reviewers up to now have made a mistake. My only DISCUSS item is on recommending PBKDF2. It is kind of showing it age, and we have a much better replacement with argon2 ( RFC 9106 ). Is there a reason why not to recommend some argon2 setting instead of PBKDF2 ?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-09-28 09:52:08-07:00",
    "end_reason": "position_updated",
    "start": "2015-05-27 13:10:13-07:00",
    "text": "I have to raise one of Ben's comments to DISCUSS, after giving it a lot of thought.\u00a0 We talked about it before Ben posted his ballot, and I said that I thought the way the rs-metadata-request subtype is used is abusing media types: media types are meant to label containers for protocol elements, but are not meant to be protocol elements themselves.\u00a0 I said I didn't want to get too wound up with that, though, and I don't... ...except that it allows no room for extensibility.\u00a0 And the moment you need another, different request, we see why this mechanism is abusive.\u00a0 Now, you may say that you don't see any need for extensibility, but we've been proven wrong in those sorts of assumptions many times. So, the discussion is about how you will deal with that.\u00a0 Specifically, an alternative would be to have an rs-request subtype, with a content-type parameter such as \"req=metadata\" (or even use rs-metadata with \"req=snapshot\") and a rule that req= values that are not recognised be ignored.\u00a0 If this should ever need to be extended, other \"req=\" values could be defined.\u00a0 A registry could be created in future, if there turns out to be a need. There are other options, as well, but the main question is why are you sure that no such extensibility is needed? Also, what you're doing with content-disposition isn't in accord with what that field is for: it is for describing how the information in the message part should be presented -- not what it's meant to contain or be used for.\u00a0 This, too, could be better handled with a content-type parameter. The discussion on this point is whether thus was considered, and, if so, why it was rejected.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-07-02 15:17:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-05-26 16:11:03-07:00",
    "text": "I am concerned that this draft allows the recording session to downgrade security from the communication session. It says \"SHOULD NOT\", but then explicitly allows for the downgrade when the SRC and SRS are in the same administrative domain. This seems to create a whole new \"last hop exception\" for media, similar to the one for SIPS that we took so many years to deprecate. (Except it's worse because the potentially insecure hop goes to an endpoint not necessarily expected to be a party to the media.) Section 6.1.2 includes a \"contract in place\" as a form of recording indication. The other mechanisms seem to say that a given call is being recorded. A contract cannot do that, except in the degenerate case of \"all calls are recorded.\" This doesn't seem to fit the spirit of the \"MUST provide recording indication\" language. Section 12, 2nd paragraph says the SRC and SRS \"MUST support SIP with TLS and MAY support SIPS with \u00a0  TLS as per [ RFC5630 ]\". That actually downgrades the requirement for SIPS support from that in 3261/5630. (3261 says you MUST support SIPS if you support TLS.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-07-02 15:17:58-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-07-02 15:17:02-07:00",
    "text": "I am concerned that this draft allows the recording session to downgrade security from the communication session. It says \"SHOULD NOT\", but then explicitly allows for the downgrade when the SRC and SRS are in the same administrative domain. This seems to create a whole new \"last hop exception\" for media, similar to the one for SIPS that we took so many years to deprecate. (Except it's worse because the potentially insecure hop goes to an endpoint not necessarily expected to be a party to the media.)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-07-10 15:28:26-07:00",
    "end_reason": "position_updated",
    "start": "2015-07-02 15:17:58-07:00",
    "text": "I am concerned that this draft allows the recording session to downgrade security from the communication session. It says \"SHOULD NOT\", but then explicitly allows for the downgrade when the SRC and SRS are in the same administrative domain. This seems to create a whole new \"last hop exception\" for media, similar to the one for SIPS that we took so many years to deprecate. (Except it's worse because the potentially insecure hop goes to an endpoint not necessarily expected to be a party to the media.) [2nd and 3rd points cleared]",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-05-28 09:38:19-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-05-26 15:41:05-07:00",
    "text": "(1) 5.3: How does a UA know if it's preference to not be recorded has been ignored?  (2) 12.2: Why is a 2011 ([ I-D.ietf-avt-srtp-ekt ]) expired I-D ok as the method for supporting DTLS-SRTP for the CS, esp when DTLS-SRTP is our currently favoured method for handing WebRTC security? When is that going to be finished? On what basis is that an informative and not normative reference? And is that reference ever likely to be standardised? (Given that it seems to be a form of TLS MitM - is that fair?) Perhaps it'd be better to just admit that re-encryption is needed and get over it? (3) I'll clear once you answer: but wouldn't it be easier all around to just mandate use of mutually authenticated TLS between SRC and SRS in all cases?\u00a0 (Even if some hop-by-hop stuff is needed when there are proxies between SRC and SRS.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-07-13 16:36:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-05-28 09:38:19-07:00",
    "text": "(1) cleared (2) 12.2: Why is a 2011 ([ I-D.ietf-avt-srtp-ekt ]) expired I-D ok as the method for supporting DTLS-SRTP for the CS, esp when DTLS-SRTP is our currently favoured method for handing WebRTC security? When is that going to be finished? On what basis is that an informative and not normative reference? And is that reference ever likely to be standardised? (Given that it seems to be a form of TLS MitM - is that fair?) Perhaps it'd be better to just admit that re-encryption is needed and get over it? (3) I'll clear once you answer: but wouldn't it be easier all around to just mandate use of mutually authenticated TLS between SRC and SRS in all cases?\u00a0 (Even if some hop-by-hop stuff is needed when there are proxies between SRC and SRS.) Also - how is it ok to ever not re-encrypt the media in the RS since if you do not, anyone from the CS who has the right session key can send the SRS bogus packets that it'll accept.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-09-28 14:11:30-07:00",
    "end_reason": "position_updated",
    "start": "2015-07-13 16:36:28-07:00",
    "text": "(1) cleared (2) 12.2: Thanks for fixing up the ekt reference. I still would like to know how, in a case where the recording is for audit/compliance purposes, one can ever allow  the RS to not be re-encrypted since that creates the potential for the CS peers to fake the traffic to the RS. (3) cleared",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-05-16 08:09:47-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-04 11:48:49-07:00",
    "text": "I have a couple of points I would like to discuss. Hopefully they can be resolved easily: Are there really no requirements for privacy or integrity protection? Is there an expectation that this mechanism would ever carry privacy sensitive or otherwise sensitive information? - 4.2.5, 2nd to last paragraph: I am surprised to find that, when the receiver is not the subscriber, that the receiver is expected to opt-out. It seems like some form of opt-in or affirmative consent would be needed here.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2016-05-18 05:43:39-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-03 01:52:29-07:00",
    "text": "Three DISCUSS points, which could be easily resolved IMO. 1. As mentioned on the NETMOD mailing list by Tom Petch, don't redefine the YANG datastore term: > I see that the definition of 'datastores' has cropped up in this AD > Review, as in the e-mail below. > > Meanwhile,  draft-ietf-i2rs-pub-sub-requirements-05.txt  is in IETF Last > Call and redefines, or recreates, the term for us > >\u00a0 \u00a0  A YANG datastore is a conceptual datastore that contains hierarchical >\u00a0 \u00a0  data defined in YANG data models.\u00a0 It is what is referred in existing >\u00a0 \u00a0  RFCs as \"NETCONF datastore\".\u00a0 However, as the same datastore is no >\u00a0 \u00a0  longer tied to NETCONF as a specific transport, the term \"YANG >\u00a0 \u00a0  datastore\" is deemed more appropriate. > > I think that the concept of datastore has been troublesome to those > coming to YANG lately, such as openconfig and I2RS, and that this will > just muddy the waters more, especially as it is tucked away in an > Informational document.\u00a0 If I2RS want to define such terminology, then > it should be in the I2RS Architecture or some such; but IMHO they should > not be defining YANG datastores at all.  2. Maybe I read too much into this (at the time of specifying the operational state in NETMOD) ... \u00a0  A Subscription Service MUST be able support a Subtree Filter so that \u00a0  subscribed updates under a target node might publish only operational \u00a0  data, only configuration data, or both. Proposal: s/Subtree Filter/Filter 3. In the security considerations section \u00a0  Versioning MUST be supported. Versioning of what? Yang push protocol, subscription, transport session, state of of subscription, something else?",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-05-16 06:04:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-05-03 17:23:01-07:00",
    "text": "I have what I hope are two very easily sorted things that I'd like to chat about: (1) 4.2.5, para2: Hang on - this is 2016 isn't it? :-) Why would we ever have a pub/sub service whose subscribers can pretend to be the service? (2) Don't you need a statement somewhere that commensurate security needs to be provided for pushed notifications as was used for the original subscription? That might be a little hard to phrase correctly but I hope we agree that the notifications ought not be significantly less secure than the subscription.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-05-17 12:31:07-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-16 06:04:43-07:00",
    "text": "(Checked this vs. -08 of the draft and we still need to chat about it I think.) I have what I hope are two very easily sorted things that I'd like to chat about: (1) 4.2.5, para2: Hang on - this is 2016 isn't it? :-) Why would we ever have a pub/sub service whose subscribers can pretend to be the service? (2) Don't you need a statement somewhere that commensurate security needs to be provided for pushed notifications as was used for the original subscription? That might be a little hard to phrase correctly but I hope we agree that the notifications ought not be significantly less secure than the subscription.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-01-31 15:30:01-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-31 15:29:36-08:00",
    "text": "I think the security considerations need some elaboration. The draft says \"When operating in secure mode...\", but it doesn't discuss when one might want to run in secure more vs non-secure mode. It would be helpful to discuss the actual threads. You mention TCP DoS attacks, but, for example, can an eavesdropper learn sensitive or private information? Is there a risk of someone impersonating a partner? Tampering with messages on the network? There's a mention of using TLS certs for authentication/authorization, but I think there's more to be said there. Is there any authentication or authorization if you aren't using secure mode? How do you match a TLS certificate to the partner name? The section opens saying that the security considerations from 3315 and 3633 apply, but I doubt either of those contemplated that you would be sending DHCP messages over TCP connections between partner servers.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-02-01 18:28:20-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-31 15:30:01-08:00",
    "text": "I think the security considerations need some elaboration. The draft says \"When operating in secure mode...\", but it doesn't discuss when one might want to run in secure more vs non-secure mode. It would be helpful to discuss actual threats. You mention TCP DoS attacks, but, for example, can an eavesdropper learn sensitive or private information? Is there a risk of someone impersonating a partner? Tampering with messages on the network? There's a mention of using TLS certs for authentication/authorization, but I think there's more to be said there. Is there any authentication or authorization if you aren't using secure mode? How do you match a TLS certificate to the partner name? The section opens saying that the security considerations from 3315 and 3633 apply, but I doubt either of those contemplated that you would be sending DHCP messages over TCP connections between partner servers.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-08-20 06:23:45-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-22 04:07:31-07:00",
    "text": "= Section 5.6.2 = I'm having a little trouble understanding the expected behavior described in Section 5.6.2 so wanted to see if I'm just confused or if there is something to be clarified. The text says: \"In addition to the Redirect-Server AVP or Redirect-Server-Extension \u00a0  AVP, the credit-control server MAY include one or more Restriction- \u00a0  Filter-Rule AVPs, one or more Filter-Rule AVPs, or one or more \u00a0  Filter-Id AVPs in the Credit-Control-Answer message to enable the \u00a0  user to access other services (for example, zero-rated services).\u00a0 In \u00a0  such a case, the access device MUST drop all the packets not matching \u00a0  the IP filters specified in the Restriction-Filter-Rule AVPs, Filter- \u00a0  Rule AVPs or Filter-Id AVPs.\u00a0 If enforcement actions other than \u00a0  allowing the packets (e.g., QoS), are indicated in the Filter-Rule \u00a0  AVPs or Filter-Id AVPs, they SHOULD be performed as well.\u00a0 In \u00a0  addition, if possible, to redirecting the user to the destination \u00a0  specified in the Redirect-Server AVP or Redirect-Server-Extension \u00a0  AVP.\" It seems like if the server sends a Redirect-Server AVP or Redirect-Server-Extension AVP without any of the other AVPs, then all the traffic is supposed to be redirected. But if a Restriction-Filter-Rule AVP, Filter-Rule AVP, or Filter-Id AVP is also included, then the non-matching traffic MUST be dropped, in which case how does the user get redirected? Is the last sentence (which is a sentence fragment, actually) supposed to address this somehow? And in the case of enforcement actions involving QoS, the text seems to say that packets matching the filter MUST be dropped AND have the QoS rules applied to them, so I don't understand how that works. = Section 15.1 = RFC 6733  lists a bunch of sensitive AVPs and then says this about them: \"Diameter messages containing these or any other AVPs considered to be \u00a0  security-sensitive MUST only be sent protected via mutually \u00a0  authenticated TLS or IPsec.\u00a0 In addition, those messages MUST NOT be \u00a0  sent via intermediate nodes unless there is end-to-end security \u00a0  between the originator and recipient or the originator has locally \u00a0  trusted configuration that indicates that end-to-end security is not \u00a0  needed.\" It seems like the list of AVPs in Section 15.1 should have these same requirements applied to them explicitly.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-08-26 09:51:57-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-22 06:48:12-07:00",
    "text": "I support Alissa's Discuss point about sensitive AVPs. I appear to have a different understanding of Section 5.6.2, though, with a different potential issue (but again, it's possible that I'm confused to how things work): With the redirection schemes covered in Section 5.6.2, it sounds like the user can be redirected (at the application protocol level, e.g., HTTP or SIP) to a top-up server to purchase more credits.\u00a0 I don't see a way described how user agents can distinguish between a Diameter-induced redirect and an attacker-induced redirect to a (potentially phishing) site that accepts payment information.\u00a0 To be  clear, the scenario here is that a user is using a credit-controlled  application session to talk to \"arbitrary application servers\",  including potentially attacker-controllled HTTP/SIP/etc. servers;  the attacker could introduce a redirect to a phishing page that asks  for payment information, and the user would be led to believe that  this was the normal flow for \"my prepaid balance has been used up\",  and give their payment information to the phishing site. I think that either user agents need to give some indication that this DIAMETER-level redirect is different than an application-protocol-level redirect (e.g., http) or the Security Considerations need to mention the risk of acclimating users to arbitrary websites redirecting to sites asking for payment credentials, which may or may not be legitimate sites. Separately, in Section 8.68 (for QoS-Final-Unit-Indication): \u00a0  If the Final-Unit-Action AVP is set to REDIRECT at least the \u00a0  Redirect-Server-Extension AVP MUST be present. This MUST seems in conflict with the text in 8.64 (actually, is section 8.64 even internally inconsistent, too?) about \"Redirect-Server AVP, in addition to or instead of the Redirect-Server-Extension AVP\", in particular, the \"instead of\" portion.\u00a0 (The ABNF-based formal language spec in 8.68 does match up with the above MUST, though.)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-08-27 08:01:49-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-23 13:55:17-07:00",
    "text": "Section 8.38. RFC5952  contains significant changes in text representation from  RFC3513  and I am concerned that there might be  RFC4006  compliant implementations that will no longer be legal with a MUST level use of  RFC5952 . e.g. Addresses with upper case hex digits, with leading zeroes in 16 bit fields etc. Has the working group considered this break in compatibility already in its discussions? If it has, this text should still be finessed a bit because  RFC5952  recommendations (even at the MUST level) are a SHOULD for senders with the receivers being required to handle all possible legal formats as per  RFC4291 . So at least the sender rules and receiver rules need to be written differently.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-10-14 14:55:10-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 06:46:27-08:00",
    "text": "The IANA Considerations are a bit confusing, as they appear to ask IANA to do things that were already done long ago.\u00a0 I understand that you want to leave the main text of the IANA Considerations intact, for posterity, and you've put in some \"Editorial note\" things.\u00a0 Maybe the best way to do this is to (1) change \"Editorial note\" to \"IANA note\" or \"Note to IANA\" throughout, (2) change the first IANA note (in the base Section 15) to clearly state that all *changes* that IANA is being asked to make are spelled out in \"IANA note\" items in the appropriate places, and (3) make sure that item 2 is true.\u00a0 And you do need to respond to Pearl Liang's IANA review from 2 March, and answer her questions.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2015-09-23 10:17:43-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 04:01:33-08:00",
    "text": "Thanks for the hard work on this protocol. I have some comments, based on a review by Suresh Krishnan, that I think should be addressed before final approval of the document. First, Section 5.1 should be clear that when used over a reliable transport, not only should the F flag be ignore but that the fragment fields (last four bytes) are not in the packet. Second, Section 6.2.3 should be clear that the header accompanies all fragments. As a result, the current formula for calculating the number of fragments is probably wrong. This too should be updated.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-10-15 06:51:57-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 07:21:58-08:00",
    "text": "Thanks for your work on this draft, it was very well written which is much appreciated. I just have one item I'd like to discuss that should be very easy to resolve.\u00a0  This should be considered with Spencer's question on what happens when the fragments are larger or smaller than the path MTU.\u00a0 It's important to state this to prevent fragmentation overlap attacks (unless you can explain why we don't need to worry about that). In the second sentence on page 42, adding the ending clause may be helpful: \u00a0 The size of each of these N messages MUST be \u00a0  smaller than the path MTU to help prevent fragmentation overlap attacks.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-11-04 18:28:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-03-04 20:38:19-08:00",
    "text": "For the moment, I'm balloting a process Discuss, because I'm not seeing a response to Gorry Fairhurst's TSV-DIR review sent on March 2, at  https://www.ietf.org/mail-archive/web/ietf/current/msg92156.html . Did I miss it? During my review, I did not see a definition of \"transaction failure window\". I can guess what that means, but would love to know for sure. I'm understanding that in  RFC 4582 , the version number (1) was a version number, but in this draft, version 1 means \"reliable transport\" and version 2 means \"unreliable transport\". Is that right? If so, how does an  RFC 4582  TCP-only floor control server receive a message with a version field set to 2, which would have been sent over UDP? I'm also wondering whether overloading the version number field as a transport reliability indicator would cause a problem in the future. If you end up with a mandatory extension that applies to both reliable and unreliable transport, does that mean you'd use two version numbers (possibly 2 for reliable and 3 for unreliable)? Within Gorry's review, these are the points I thought were Discuss-worthy. It's probably best for you to reply to these in his e-mail, rather than try to juggle two sets of overlapping comments. I'm just pointing out what I think matters most. On the others, please do the right thing. - Gorry asked in Section 5: What is the security model when TLS/DTLS is not used? - has the protocol protection from off-path attacks, and how is this provided? I'm especially interested in this question when unreliable transport is used without DTLS. This is probably related to the question about randomizing Conference ID later in Gorry's review. -  Payload Length: - What happens when using a datagram format if the datagram length (e.g. UDP-Length) is less or more than the value specified within the BFCP? - Fragment Length: - What happens if the datagram length (e.g. UDP-Length) is less or more than the value specified within the BFCP?",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-11-04 18:30:50-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-04 18:28:20-08:00",
    "text": "Thanks for working through my Discuss and Comments on -13. I'm mostly good (at the Discuss level), but have one remaining concern, on section 14.\u00a0 Security Considerations \u00a0  BFCP uses TLS/DTLS to provide mutual authentication between clients \u00a0  and servers.\u00a0 TLS/DTLS also provides replay and integrity protection \u00a0  and confidentiality.\u00a0 It is RECOMMENDED that TLS/DTLS with an \u00a0  encryption algorithm according to Section 7 always be used.\u00a0 In cases \u00a0  where signaling/control traffic is properly protected, as described \u00a0  in Section 9 it is REQUIRED to use a mandated encryption algorithm. \u00a0  BFCP entities MAY use other security mechanisms as long as they \u00a0  provide similar security properties. \u00a0   If I'm reading this text correctly (please correct me if I'm misunderstanding), it is still allowed to run BFCP over TCP/UDP without TLS/DTLS.  If you run a protocol over TCP without TLS, you're still vulnerable to on-path attackers, but off-path attackers have to insert attack packets with sequence numbers that are within the current window. That's not impossible, but it's not easy. So, I'm not happy that TLS isn't required when you run BFCP over TCP, but OK, fine. If you run a protocol over UDP without DTLS, off-path attackers don't have this constraint, so inserting attack packets off-path is much easier. That makes BFCP much more vulnerable to attack over UDP than it was over TCP.  Is that really OK? That seems quite odd to me, when said without a clear warning that if you do not use DTLS (or equivalent) security mechanisms the protocol is vulnerable to various attacks. I\u2019d have preferred section 7 to have said \u201cSHOULD use TLS or DTLS\u201d and then have gone on to explain - \u201creasons for not using DLTS include ... but when TLS or DTLS is not used the protocol becomes vulnerable to security attacks (e.g. ...).\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-11-13 13:17:04-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-04 18:30:50-08:00",
    "text": "Thanks for working through my Discuss and Comments on -13. I'm mostly good (at the Discuss level), but have one remaining concern, on section 14.\u00a0 Security Considerations \u00a0  BFCP uses TLS/DTLS to provide mutual authentication between clients \u00a0  and servers.\u00a0 TLS/DTLS also provides replay and integrity protection \u00a0  and confidentiality.\u00a0 It is RECOMMENDED that TLS/DTLS with an \u00a0  encryption algorithm according to Section 7 always be used.\u00a0 In cases \u00a0  where signaling/control traffic is properly protected, as described \u00a0  in Section 9 it is REQUIRED to use a mandated encryption algorithm. \u00a0  BFCP entities MAY use other security mechanisms as long as they \u00a0  provide similar security properties. \u00a0   If I'm reading this text correctly (please correct me if I'm misunderstanding), it is still allowed to run BFCP over TCP/UDP without TLS/DTLS.  If you run a protocol over TCP without TLS, you're still vulnerable to on-path attackers, but off-path attackers have to insert attack packets with sequence numbers that are within the current window. That's not impossible, but it's not easy. So, I'm not happy that TLS isn't required when you run BFCP over TCP, but OK, fine. If you run a protocol over UDP without DTLS, off-path attackers don't have this constraint, so inserting attack packets off-path is much easier. That makes BFCP much more vulnerable to attack over UDP than it was over TCP.  Is that really OK? That seems quite odd to me, when said without a clear warning that if you do not use DTLS (or equivalent) security mechanisms the protocol is vulnerable to various attacks. I\u2019d have preferred section 7 to have said \u201cSHOULD use TLS or DTLS\u201d and then have gone on to explain - \u201creasons for not using DTLS include ... but when TLS or DTLS is not used the protocol becomes vulnerable to security attacks (e.g. ...).\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-05 09:25:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-09 15:31:45-07:00",
    "text": "** Section 5.4.\u00a0  \u00a0  Ads may be inserted either with Client Side Ad Insertion (CSAI) or \u00a0  Server Side Ad Insertion (SSAI).\u00a0 In CSAI, the ABR manifest will \u00a0  generally include links to an external ad server for some segments of \u00a0  the media stream, while in SSAI the server will remain the same \u00a0  during advertisements, but will include media segments that contain \u00a0  the advertising.\u00a0 In SSAI, the media segments may or may not be \u00a0  sourced from an external ad server like with CSAI. \u00a0  \u00a0 \u00a0 \u00a0 \u00a0  \u2026 \u00a0  As a \u00a0  mitigation for concerns driven by those incidents, some SSPs have \u00a0  required the use of players with features like reporting of ad \u00a0  delivery, or providing information that can be used for user \u00a0  tracking.\u00a0 Some of these and other measures have raised privacy \u00a0  concerns for end users. Thanks for starting the discussion about privacy.\u00a0 The framing doesn\u2019t seem completely accurate.\u00a0 Whether there is ad fraud or not, user data of some kind is being sent off to ad exchanges (it\u2019s the basis of the bidding process), and network level tracking is being facilitated through connects to CSAIs.\u00a0 Please provide some editorial construct to suggest that practically any kind of targeted ads are going to entail some trade in privacy, and explain the risks specifically or with a reference.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-30 13:35:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-09 17:45:47-07:00",
    "text": "There seems to be an internal inconsistency about whether, when the API URL is available in a given network via multiple mechanisms, the URLs provided by the different mechanisms must be \"identical\" (Section 3) or merely \"equivalent\" (Section 2).\u00a0 I think we need to be consistent in the requirement, as it is possible for URLs to be equivalent but not identical just by virtue of mundane encoding tricks, even without getting to the question of semantic equivalence of pointed-to resources.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-25 00:57:25-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 06:54:46-07:00",
    "text": "IANA Section: As this document is obsoleting  RFC 7710  is the document that registered the options for DHCPv6 and RA. Why isn't this document updating the registrations to ensure that IANA has the current document as being owner of the codepoints?  In addition when it comes to BOOTP options code 160. What you have in this document appear to potentially lead to another future assignment end up in trouble? Wouldn't reserved be better status for this codepoint?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-03-17 10:42:41-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 09:58:55-08:00",
    "text": "I am balloting DISCUSS because the document underspecifies the use of Endpoint Behaviors. As a result, it is unclear when they should be checked, enforced,  or needed. Details follow. The descriptions of the TLVs in \u00a72 say (twice) that the \"SRv6 Endpoint  behaviors which MAY be encoded, but not limited to, are...etc.\" \u00a0  The text above ends with \"etc.\" which means there are other possible  \u00a0  behaviors. That's not a great use of normative language, even if optional.  \u00a0  My initial instinct was to ask you to be specific, BUT... \u00a0  The description of the SRv6 SID Information Sub-TLV (\u00a73.1) says that \"an \u00a0  unrecognized endpoint behavior MUST NOT be considered invalid\", which seems \u00a0  to mean that any behavior is ok, AND... \u00a0  There's no validation specified, except for the description of the SRv6 SID \u00a0  Structure Sub-Sub-TLV (\u00a73.2.1), where it says that the \"Argument length  \u00a0  MUST be set to 0 for SIDs where the Argument is not applicable\". AND... \u00a0  Several of the service descriptions in \u00a75/\u00a76 say that \"The SRv6 Endpoint \u00a0  behavior of the SRv6 SID is entirely up to the originator of the \u00a0  advertisement. In practice, the SRv6 Endpoint behavior is...\" The result is that any endpoint behavior (even unrecognized) can be used,  while also requiring a specific setting for the argument length in some cases. How can the argument length be validated if the endpoint behavior is unknown? Clearly (from looking at  rfc8986 ), not all endpoint behaviors apply to the services defined in this document. Should a receiver accept any endpoint behavior? What should a receiver do if a known but unrelated behavior (End,  for example) is received? What should the receiver do if the endpoint behavior is known and applicable, but the attribute length is not set correctly? For any specific service (IPv4 VPN Over SRv6 Core, for example, to pick one), should the behaviors used \"in practice\" be enforced? What if different behavior is advertised? Can it safely be ignored? Why is the Endpoint Behavior included in the Sub-TLV if (from the above) it looks like it doesn't matter?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-02-10 14:18:58-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-07 13:46:28-08:00",
    "text": "Thank you for the work put into this document. This protocol is important for scalable and deployable SRv6 services. Please find below some blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Matthew Bocci for the shepherd's write-up including the section about the WG consensus and document history.  Please also expect an INT directorate review before the IESG telechat (I may update this ballot accordingly). I hope that this helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 3.1 \"IANA registry defined in section 9.2 of [ RFC8986 ]\" but there is no section 9.2 in  RFC 8986 . I guess it is section 10.2. Moreover, IANA registries are usually referred to via their name/URL, e.g.,  https://www.iana.org/assignments/segment-routing/segment-routing.xhtml , and not by a section of the RFC that created them. ## Section 3.2.1 Where is \"locator node\" defined ? \"locator block\" is defined in section 3.1 of  RFC 8986  but not the node (I can only guess that this is the \"N\" in the \"B:N\" notation used in  RFC 8986 ). ## Section 6 Section 9 of  draft-ietf-bess-evpn-igmp-mld-proxy-16  indeed defines route types 7 and 8 but it uses non IPv4-only wording. So, s/IGMP join sync route/Multicast Membership Report Synch Route/ + same for type 8.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-03-21 21:20:12-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 22:03:05-08:00",
    "text": "I have little to add to the DISCUSSes held by others beyond my support. However, I would like to discuss having SRv6 control plane information, i.e. SIDs and their behaviours etc., being isolated by associating it with a separate SAFI.\u00a0 Any other protocol element that needs to refer to such information can make reference to it through context-appropriate extensions. {AFI=IPv6, SAFI=unicast} is a valid way to advertise an SRv6 locator prefix, for example, as that's just IPv6 forwarding information.\u00a0 If SRv6-specific information where separately advertised as {AFI=IPv6, SAFI=SRv6} then I suspect it would be simpler to filter out that information, detect leaks, and generally help the SRv6 domain fail closed more easily. But I'm prepared to learn why this wouldn't work or would be somehow worse.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:34:23-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:33:55-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? \u2028\u2028(An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:34:43-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:34:23-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? \u2028\u2028(An obvious way of addressing this particular concern  (would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:34:57-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:34:43-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? \u2028\u2028(An obvious way of addressing this particular concern  (An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:38:37-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:34:57-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? (An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-03-22 16:19:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 13:38:37-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? (An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) It's of course possible for an author to be in the rough as regards consensus, just as any other WG contributor, but it's a little unusual, and this disagreement doesn't even seem to have been previously aired. For this reason, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-17 19:26:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-22 17:32:34-08:00",
    "text": "(3.2.1) \"BGP speakers that do not support this specification may misinterpret, \u00a0  on the reception of an SRv6-based BGP service route update, the part \u00a0  of the SRv6 SID encoded in MPLS label field(s) as MPLS label values \u00a0  for MPLS-based services.\u00a0 Implementations supporting this \u00a0  specification MUST provide a mechanism to control the advertisement \u00a0  of SRv6-based BGP service routes on a per-neighbor and per-service \u00a0  basis.\u00a0 The details of deployment designs and implementation options \u00a0  are outside the scope of this document.\" The idea that BGP hosts are going to be made non-interoperable because you're re-purposing the MPLS label, and so hosts are just going to have to remember who it's OK to exchange this TLV with, sounds unsatisfactory to me. Is there no way to negotiate this? Perhaps the solution John Scudder proposes in his second DISCUSS would solve this problem too: just have a new type for these overloaded MPLS labels.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-02-11 15:03:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-11 14:55:43-08:00",
    "text": "The Security Considerations section says: \"The service flows between PE routers using SRv6 SIDs advertised via BGP are expected to be limited within the trusted SR domain (e.g., within a single AS or between multiple ASes within a single provider network).\u00a0 Precaution should be taken to ensure that the BGP service information (including associated SRv6 SID) advertised via BGP sessions are limited to peers within this trusted SR domain.\" This is related to (from  RFC8402 ): \"Therefore, by default, the explicit routing information MUST NOT be leaked through the boundaries of the administered domain.\" However, we all know that BGP leaks happen -- and when they do, the SID\u2019s contained in the leak will be logged by various systems and hence available to the public into perpetuity. While the document states that border filtering should protect against traffic injection, this does not cover the case of internal compromise. Sure, there is the argument that once there is an internally compromised system, all bets are off -- but with this, an attacker that knows the SIDs in use can perform injection attacks in addition to routing traffic however they like.  So, not only does an operator have to ensure that BGP leaks never occur, they have to then ensure that at no point can there be any filter lapses at any border node, and be able to guarantee the security of every device, server and machine within the domain in order for a secure posture to be maintained.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-03-07 12:54:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-11 15:03:04-08:00",
    "text": "The Security Considerations section says: \"The service flows between PE routers using SRv6 SIDs advertised via BGP are expected to be limited within the trusted SR domain (e.g., within a single AS or between multiple ASes within a single provider network).\u00a0 Precaution should be taken to ensure that the BGP service information (including associated SRv6 SID) advertised via BGP sessions are limited to peers within this trusted SR domain.\" This is related to (from  RFC8402 ): \"Therefore, by default, the explicit routing information MUST NOT be leaked through the boundaries of the administered domain.\" However, we all know that BGP leaks happen -- and when they do, the SID\u2019s contained in the leak will be logged by various systems and hence available to the public into perpetuity. While the document states that border filtering should protect against traffic injection, this does not cover the case of internal compromise. Sure, there is the argument that once there is an internally compromised system, all bets are off -- but with this, an attacker that knows the SIDs in e.g inject traffic into a VPN. This seems to me to significantly expand the attack surface to include the customer's networks too.  Not only does an operator have to ensure that BGP leaks never occur, they have to then ensure that at no point can there be any filter lapses at any border node, and be able to guarantee the security of every device, server and machine within the domain in order for a secure posture to be maintained. Simply saying that precautions should be taken to make sure that route leak don't occur, when the consequences of doing so are a: severe and b: hard to recover from seems to not really cover it. In addition, it seems that the blast radius from a missing ACL seems much larger if it allows injections.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-07-01 13:25:02-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-29 08:42:18-07:00",
    "text": "I have two things I'd like to discuss: (1) Section 10 says: \" This document does not alter [ RFC5812 ] or the ForCES Protocol[ RFC5810 ].\u00a0 As such, it has no impact on these documents security considerations.\u00a0 This document simply defines the operational parameters and capabilities of an LFB that performs LFB class instance extensions across nodes under a single administrative control.\u00a0 This document does not attempt to analyze the presence or possibility of security interactions created by allowing LFB graph extension on packets.\u00a0 Any such issues, if they exist should be resolved by the designers of the particular data path i.e they are not the responsibility of general mechanism outlined in this document; one such option for protecting Ethernet is the use of IEEE 802.1AE Media Access Control Security [ieee8021ae] which provides encryption and authentication. \" I'm not sure I buy that explanation. While you may not be changing the protocol much, you are sending PDUs over a network where they previously were processed within one machine. IIRC, earlier ForCES documents called for IPSec or TLS as mandatory-to-implement (MTI) for anything where ForCES stuff was being sent \"off the box.\" That is clearly being done here, so I don't get how MACsec is now regarded as optional to implement. Can you explain? That may be me recalling incorrectly, or perhaps there is a good reason, but if the above logic were correct there would have been no reason to have said earlier that security was MTI so I'm confused. (2) I'm also unsure that just saying \"use MACsec\" is enough to get interop and security for this. For example, is it likely that separate keys would be setup just for ForCES use here?\u00a0 If so, saying that's needed would be good. If not, I wonder what threats might arise with spoofing ForCES traffic from a box that has the right MACsec keys. Has someone implemented/tested with MACsec and considered those issues?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-05-17 15:42:29-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-16 19:27:04-07:00",
    "text": "Thanks for this work. I plan to ballot \"yes\", but I have a couple of points I think need to be discussed first. \u00a74.2: \" If the signature validation fails, the verification service should infer \u00a0  that the calling party is not authorized for \u2019Resource-Priority\u2019 as \u00a0  indicated in the claim.\u00a0 In such cases, the priority treatment for \u00a0  the associated communication service is handled as per the local \u00a0  policy.\" I suspect there will be deployments where the node making these local policy decisions is downstream from the verifier. How do they know RPH verification failed? Should the verifier strip resource priority header fields for which validation failed? \u00a77.2:  \u00a0  o\u00a0 The verification of the signature MUST include means of verifying \u00a0 \u00a0 \u00a0 that the signer is authoritative for the signed content of the \u00a0 \u00a0 \u00a0 resource priority namespace in the PASSporT.\" I gather the intent is to leave that means to local policy, or to be specified elsewhere. I think that's a problem from an interoperability standpoint. The verifier needs a way to know whether the authorizer is authoritative for the RPH. If we want authorizers and verifiers from different vendors to be able to interoperate, it seems like at least some mechanism needs to be standardized and possibly MTI.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-10 12:57:14-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-09 23:35:38-07:00",
    "text": "A tiny thing, trivial to fix: \u2014 Section 2 \u2014 \u00a0  This document uses the following terms defined in [ RFC8051 ]: Stateful \u00a0  PCE, Active Stateful PCE, Passive Stateful PCE, and Delegation. I think this makes 8051 a normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-20 16:58:21-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 21:04:23-08:00",
    "text": "These should all be trivial to resolve -- just some minor internal inconsistencies that need to be fixed before publication. The discussion of percentile statistical operator in \u00a72.2 is internally inconsistent -- if the percentile number must be an integer, then p99.9 is not valid. Also, the listing of \"cost-source\" values introduced by this document (in \u00a75.1) does not include \"nominal\", but we do also introduce \"nominal\". Similarly, in \u00a73.1.3 we refer to the \"-\" component of a cost metric string, that has been generalized to an arbitrary statistical operator.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-20 13:42:41-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-20 16:58:21-08:00",
    "text": "Thank you for addressing my previous discuss points with the -21 (and my apologies for the spurious one!); I'm glad to see that they were indeed easy to address. However, I have looked over the changes from -20 to -21 and seem to have found a couple more issues that should be addressed: (1) I can't replicate the Content-Length values in the examples (I only looked at Examples 1 and 2).\u00a0 Can you please share the methodology used to generate the values?\u00a0 My testing involved copy/paste from the htmlized version of the draft to a file, manually editing that file to remove the leading three spaces that come from the formatting of the draft, and using Unix wc(1) on the resulting file.\u00a0 It looks like the numbers reported in the -21 are computed as the overall number of characters in the file *minus* the number of lines in the file, but I think it should be the number of characters *plus* the number of lines, to accommodate the HTTP CRLF line endings.\u00a0 (My local temporary files contain standard Unix LF (0x0a) line endings, verified by hexdump(1).) (2) We seem to be inconsistent about what the \"cur\" statistical operator for the \"bw-utilized\" metric indicates -- in \u00a74.4.3 it is \"the current instantaneous sample\", but in \u00a74.4.4 it is somehow repurposed as \"The current (\"cur\") utilized bandwidth of a path is the maximum of the available bandwidth of all links on the path.\"",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-04 02:56:46-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-22 03:32:02-08:00",
    "text": "Thank you for the work put into this document. Please bear with my lack of knowledge about ALTO in general. Please find below one trivial blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Jan Seedorf for the shepherd's write-up about the WG consensus (even if not using the usual template). I have appreciated the \"operational considerations\" section as it addresses many questions that popped up during reading the document; notably, how can the ALTO server measure any metric between the ALTO client and a resource. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.1.3 -- A very trivial DISCUSS to fix: this document relies on  RFC 8312  to specify how TCP throughput is estimated but  RFC 8312  does not appear in the normative reference list (this will probably generate a down ref though).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:37:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 13:57:01-08:00",
    "text": "Thank you for the work on this document. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. I am holding a DISCUSS to make sure the examples are fixed before publication. Additionally, I agree with Christian that the line \"Content-Length: TBA\" in all the examples is not really helpful to the reader, and I suggest to either remove it or replace TBA with the actual content length for each example. Francesca 1. ----- { \u00a0 \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-metric\":\"hopcount\"} \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0  }, \u00a0 \u00a0 \u00a0 \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.89\"\u00a0  : 5, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:198.51.100.34\": 3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 } FP: JSON doesn't validate. There is one \"}\" too many after \"hopcount\". 2. ----- \u00a0  { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\":\"tput\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\"\u00a0  : 256000, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 128000 \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate. I believe there is 2 errors: after the second \"}\" after \"tput\" there is a missing \",\" , and it is also missing a final \"}\" at the end. 3. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\" { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-residual\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\" { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate - there is a bunch of missing \":\" all over. 4. ----- { \u00a0 \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\"}, \u00a0 \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0  \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0  \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\" 5. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\": { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"ipv4:192.0.2.2\"",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-05 10:49:09-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 14:37:30-08:00",
    "text": "Thank you for the work on this document. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. I am holding a DISCUSS to make sure the examples are fixed before publication. Additionally, I agree with Christian that the line \"Content-Length: TBA\" in all the examples is not really helpful to the reader, and I suggest to either remove it or replace TBA with the actual content length for each example. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- { \u00a0 \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-metric\":\"hopcount\"} \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0  }, \u00a0 \u00a0 \u00a0 \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.89\"\u00a0  : 5, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:198.51.100.34\": 3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 } FP: JSON doesn't validate. There is one \"}\" too many after \"hopcount\". 2. ----- \u00a0  { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\":\"tput\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\"\u00a0  : 256000, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 128000 \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate. I believe there is 2 errors: after the second \"}\" after \"tput\" there is a missing \",\" , and it is also missing a final \"}\" at the end. 3. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\" { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-residual\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\" { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate - there is a bunch of missing \":\" all over. 4. ----- { \u00a0 \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\"}, \u00a0 \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0  \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0  \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\" 5. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\": { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"ipv4:192.0.2.2\"",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-04 00:59:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-05 10:49:09-08:00",
    "text": "Thank you for the work on this document, and for addressing my previous DISCUSS points. I noticed two additional JSON issue, easy to fix, reported below. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- Section 4.4.3 \u00a0  { \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-utilized\"}, \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0 \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0 ] \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\". 2. ----- Section 4.3.3. \u00a0  { \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-available\"}, \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0 \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0 ] \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\". (Minor note - is there a reason why the \"srcs\" address has whitespaces while other addresses don't? 3 occurrences in the text).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-04 01:00:03-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-04 00:59:05-08:00",
    "text": "Thank you for the work on this document, and for addressing my previous DISCUSS points. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-03-01 08:06:31-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-29 05:09:48-08:00",
    "text": "This document needs to become much more formal about how it defines the metrics it wishes to use with ALTO. This could either be done either by identifying and normatively referencing existing metrics the IETF has defined, or by defining them here. When normatively referencing existing IETF metrics, it would need to explain why their use with ALTO makes sense. At the moment, the document informatively points to a somewhat arbitrary collection of prior IETF metrics (most of which are from IPPM, residual bandwidth from IS-IS TE, but then reservable bandwidth from OSPF TE?). But it only refers to them as \"examples\", without actually defining how exactly they are to be used with ALTO, or - if not those - which actual metrics are supposed to be used. Defining a mechanism for exposing metric information to clients isn't really useful unless the content of that information is much more clearly specified. Section 4.1.3. , paragraph 2, discuss: >\u00a0 \u00a0 Intended Semantics: To give the throughput of a TCP congestion- >\u00a0 \u00a0 control conforming flow from the specified source to the specified >\u00a0 \u00a0 destination; see [ RFC3649 , Section 5.1 of  RFC8312 ] on how TCP >\u00a0 \u00a0 throughput is estimated.\u00a0 The spatial aggregation level is specified >\u00a0 \u00a0 in the query context (e.g., PID to PID, or endpoint to endpoint). A TCP bandwidth estimate can only be meaningfully be derived for bulk TCP transfers under a set of pretty strict and simplistic assumptions, making this metric a meaningless at best and misleading at worst, given that the source of this information doesn't know what workload, congestion controller and network conditions the user of this information will use or see. Also,  RFC3649  is an Experimental RFC (from 2003!) and  RFC8312  is an Informational RFC. Since this document normatively refers to them, it needs to cite them, and this will cause DOWNREFs for PS document. I would argue that at least  RFC3649  is certainly not an appropriate DOWNREF. Why define this metric at all? The material you point to is the usual model-based throughput calculation based on RTT and loss rates; a client that intended to predict TCP performance could simply query ALTO for this and perform their own computation, which will likely be more accurate, since the client will hopefully know which congestion controller they will use for the given workload, and what the characteristics of that workload are.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-03-17 01:14:41-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-02 03:34:42-08:00",
    "text": "I perhaps understand the intention of extending the ALTO protocol so that the ALTO client and server have defined way of exchanging values for already defined metrics. However, I need to agree with my fellow AD colleagues that this document need to describe why those metrics are needed and describe the relationship with other RFCs those defines those metrics mostly for other contexts. To that end all the RFCs in the Table 1 in section 1 need to be normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-05-03 14:18:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-05 12:42:28-07:00",
    "text": "I am balloting DISCUSS because there are significant clarity issues.  (1) 4.2.\u00a0 Peer Flags \u00a0  In section 4.2 of [ RFC7854 ], the \"locally sourced routes\" comment \u00a0  under the L flag description is removed.\u00a0 If locally sourced routes \u00a0  are communicated using BMP, they MUST be conveyed using the Loc-RIB \u00a0  instance peer type. This change is bigger than simply removing a comment: it is changing the behavior.\u00a0 Note that \u00a78.2/rfc7854 also talks about the L flag.\u00a0 Do the same considerations apply?\u00a0  I would like to see a clearer treatment of the change related to locally sourced routes -- a separate section/sub-section seems appropriate. (2) \u00a74.2/8.2: Peer Flags \u00a74.2 defines a new Flag as follows: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 1 2 3 4 5 6 7 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |F|\u00a0 Reserved\u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+ But it doesn't mention that this field is intended to be specific to the Loc-RIB peer-type.\u00a0 OTOH, \u00a78.2 (IANA Considerations) does:  \u00a0  This document defines a new flag (Section 4.2) and proposes that peer \u00a0  flags are specific to the peer type: The registry [1] shows that the early allocation was made in the \"generic\" (not per-peer-type) Peer Flags field.\u00a0 The flags defined in  rfc7854  and  rfc8671  both assume the same set of Flags for all peer types. [1]  https://www.iana.org/assignments/bmp-parameters/bmp-parameters.xhtml#peer-flags (3) \u00a75.4 (Route Monitoring)\u00a0 The implication in this section is that a BGP UPDATE includes the route information -- but the information in the Loc-RIB may not have come from BGP, so there is no BGP UPDATE to propagate.\u00a0 This clearly is a case where the UPDATE is fabricated.\u00a0 Please provide specific instructions on how this UPDATE is constructed, including any path attributes.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 10:44:14-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-26 12:43:28-07:00",
    "text": "I'd like to discuss the following comments from the Gen-ART reviewer: \"Throughout, but particularly in section 5, this document refers to \"hosts\" doing address selection. To be fair, so does  RFC 6724 , but 6724 is referring to *default* address selection. In reality, *applications* do address selection on a host; the host stack will only do address selection if the application requests a default address. That works well for the scenarios in 6724, but in this document, for example section 5.2.3, I'm not so sure. The idea that a host would receive an ICMP destination unreachable and re-arrange its address selection seems at least an incomplete picture: An application with a (normal, non-multi-path) TCP connection to a remote application is not able to \"try another source address to reach the destination\"; the source address is already set for that TCP connection, so the only choice is to close the connection entirely. If the application chooses to re-establish the connection with a default address, yes, the host stack could then give a new default address back to the application, but this is hardly the dynamic and quickly adjusting process that the document seems to be envisioning. I don't think the above invalidates the core of the document or requires some grand rewrite. But I do think some clarification is in order, saying that the mechanisms described help with the *default* address selection, and some short discussion of the limitations for what applications can (and more importantly cannot) do with these mechanisms would be useful.\"",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-01 08:12:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-26 08:11:42-07:00",
    "text": "I have a question basically on section 5.3, however, maybe I'm misunderstanding something or there is an open aspect here: If I have selected one IP address and then open a TCP connection and during using this TCP connection the connection to the selected ISP fails, my expected behaviour from a multi-homed network would have been that my traffic is simply rerouted to the other ISP. However, all solutions discussed in sec 5.3. assume that the endpoint will switch its IP address. In case of TCP, which is not migration-capable, as indicated by the TSV-ART reviewer (Thanks Michael!), this would mean that I have to open a new TCP connection and start over again. That doesn't see optimal. Should this be considered?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-07-05 07:04:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-07-04 14:14:19-07:00",
    "text": "[Only reviewed the diff from  RFC 5751  so far, but putting a position in the datatracker now in case I don't have time to go back] This is not necessarily a flaw in the document, I just want to ensure that the decision to use the phrase \"for political reasons\" to describe a technical decision made in an IETF-stream RFC is a decision that is consciously approved by the IESG.\u00a0 (I could not find any precedent for such a usage.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-07-19 13:09:11-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-05 07:04:05-07:00",
    "text": "This is not necessarily a flaw in the document, I just want to ensure that the decision to use the phrase \"for political reasons\" to describe a technical decision made in an IETF-stream RFC is a decision that is consciously approved by the IESG.\u00a0 (I could not find any precedent for such a usage.)",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-01-23 18:27:24-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-01-22 18:41:48-08:00",
    "text": "Thanks to everyone who worked on this specification. I think it's well-written, clear, and useful. I fully endorse publication, and intend to ballot \"yes\" once we come to an agreement on the issue I describe below. The problem I'm running into is the URL synthesis rules described in section 3.1 for multi-tenancy engage in exactly the kind of behavior that  RFC 5785  was designed to head off: it creates URLs all over the path space of the authority, rather than coralling all synthesized URLs to live under only one top-level directory. One of the key aspects of the principles of the web architecture is URI opacity , which generally precludes clients from synthesizing URLs.  RFC 5785  was intended as a very limited carve-out to the principle of URI opacity, and was carefully limited to a single top-level path element. This specification oversteps that carve-out by exploding the location that \"Well-Known\" synthesized URLs can appear: it literally increases it from one location (the root) to infinite locations (at the end of any arbitrary path). Fortunately, this defect is trivial to fix. Rather than placing .well-known path components *after* the path identified by an issuer identifier, you place them *before* it, which amends this document's usage to be within the spirit intended by  RFC 5785 . For example, the example in section 3.1: \u00a0 \u00a0  GET /issuer1/.well-known/oauth-authorization-server HTTP/1.1 \u00a0 \u00a0  Host:  example.com Would instead become: \u00a0 \u00a0  GET /.well-known/oauth-authorization-server/issuer1 HTTP/1.1 \u00a0 \u00a0  Host:  example.com",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-03-01 12:32:10-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-23 18:27:24-08:00",
    "text": "Thanks to everyone who worked on this specification. I think it's well-written, clear, and useful. I fully endorse publication, and intend to ballot \"yes\" once we come to an agreement on the issue I describe below. The problem I'm running into is the URL synthesis rules described in section 3.1 for multi-tenancy engage in exactly the kind of behavior that  RFC 5785  was designed to head off: it creates URLs all over the path space of the authority, rather than coralling all synthesized URLs to live under only one top-level directory. One of the key aspects of the principles of the web architecture is URI opacity , which generally precludes clients from synthesizing URLs.  RFC 5785  was intended as a very limited carve-out to the principle of URI opacity, and was carefully limited to a single top-level path element. This specification oversteps that carve-out by exploding the location that \"Well-Known\" synthesized URLs can appear: it literally increases it from one location (the root) to infinite locations (at the end of any arbitrary path). Fortunately, this defect is trivial to fix. Rather than placing .well-known path components *after* the path identified by an issuer identifier, you place them *before* it, which amends this document's usage to be within the spirit intended by  RFC 5785 . For example, the example in section 3.1: \u00a0 \u00a0  GET /issuer1/.well-known/oauth-authorization-server HTTP/1.1 \u00a0 \u00a0  Host:  example.com Would instead become: \u00a0 \u00a0  GET /.well-known/oauth-authorization-server/issuer1 HTTP/1.1 \u00a0 \u00a0  Host:  example.com _______ UPDATE Author's response:  https://www.ietf.org/mail-archive/web/oauth/current/msg17747.html My response:  https://www.ietf.org/mail-archive/web/oauth/current/msg17748.html",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-02-28 06:43:36-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-01-24 00:05:46-08:00",
    "text": "Thank you for the well written IANA Considerations section. I have one comment on it which should be easy to resolve: The document doesn't seem to say anything about allowed characters in Metadata names. When the document talks about \"case-insensitive matching\", it is not clear how to implement the matching, because it is not clear whether or not Metadata names are ASCII only. If they are not, then you need to better define what \"case insensitive\" means.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-03-05 09:17:44-08:00",
    "end_reason": "position_updated",
    "start": "2018-02-28 06:43:36-08:00",
    "text": "Thank you for the well written IANA Considerations section. I have one comment on it which should be easy to resolve: The document doesn't seem to say anything about allowed characters in Metadata names. When the document talks about \"case-insensitive matching\", it is not clear how to implement the matching, because it is not clear whether or not Metadata names are ASCII only. If they are not, then you need to better define what \"case insensitive\" means. You've made a change in section 7.1, which looks good. However there is still the following text in 7.1.1: \u00a0  Metadata Name: \u00a0 \u00a0 \u00a0 The name requested (e.g., \"issuer\").\u00a0 This name is case-sensitive. \u00a0 \u00a0 \u00a0 Names may not match other registered names in a case-insensitive I suggest replacing \"in a case-insensitive manner\" with something like \"if when applying Unicode toLowerCase() to both, they compare equal\". Or maybe keep \"case-insensitive\" and just add a sentence explaining what it is. I think you should use toLowerCase(), as it is already recommended in other IETF specs, like  RFC 8265 . \u00a0 \u00a0 \u00a0 manner unless the Designated Experts state that there is a \u00a0 \u00a0 \u00a0 compelling reason to allow an exception.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-10-11 12:45:45-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-16 20:43:03-07:00",
    "text": "* Section 3.10 It is not clear from this definition how exactly a sender needs to encode this attribute on the wire. e.g. From the spec it looks like an IPv6 prefix such 2001:db8:dead:beef::/64 can legally be encoded using anywhere between 8 octets and 16 octets. What exactly is the preferred encoding? If you intend to allow all of the encodings can you please add an explicit statement to say so.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-08-25 01:05:45-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-24 04:10:56-07:00",
    "text": "he IANA review of this document seems to not have concluded yet; I am holdinga DISCUSS for IANA until it has.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-05 23:31:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-07 21:28:15-07:00",
    "text": "I have a couple points that might require a bit of discussion, but I expect to be pretty easy to resolve: (1) Can we double-check this text in Section 10.1: \u00a0  The Identity Association for Link-Layer Addresses option (IA_LL \u00a0  option) is used to carry one or more IA_LL options, the parameters \u00a0  associated with the IA_LL, and the address blocks associated with the \u00a0  IA_LL. I am pretty sure that the \"is used to carry one or more IA_LL options\" should actually be talking about IA_LLADDR options.\u00a0 But if I'm wrong, and this is saying that IA_LL can carry IA_LL, we should have a lot more discussion about this recursive structure and how to interpret it. (2) I'd also like to have a bit of discussion about the \"direct client mode scenario\" (Section 4.2).\u00a0 The current text implies that a device might use DHCPv6 on a single interface to request addresses for each local interface and then use the returned allocation from the one interface as link-layer addresses on the other interfaces.\u00a0 While we do say that this \"typically means one address per device\", we still talk about the more general case, and I'm not sure I understand when it makes sense.\u00a0 Given that (as Section 11 notes), \"[l]ink-layer addresses are typically specific to a link\", and a multi-interface client may not a priori know that any given set of its interfaces are on the same link, it seems like this scenario is introducing risk that we use an allocated address outside of the scope of authority from which it was allocated, risking collision.\u00a0 (While the security considerations rightly note that coping with collision is something that nodes need to be prepared to do anyway, we don't need to be encouraging it.) Without some discussion of (e.g.) a link aggregation scenario where a client is bonding multiple physical interfaces into a higher-capacity logical interface, I don't think we should mention this multi-interface scenario at all.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-02 07:01:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 04:07:28-07:00",
    "text": "Hi, Thank you for this document.\u00a0 Mostly I found this document to be straight forward to read, but there are a few areas that were unclear to me, that could probably help being clarified. Hopefully none of these are too difficult to address, or they may turn out not to be issues at all ... Client SHOULD, server MUST ignore.\u00a0 In a couple of places in the document (sections 6, 10.1, 10.2), it states that the client SHOULD set 0.\u00a0 To allow the protocol to evolve in future, I believe that it would be better if the SHOULD is changed to a MUST. There doesn't appear to be any specification of how an OPTION_IA_LL should be handled if there are no IA_LL-options, or it contains an IA_LL-option that is not understood by the server.\u00a0 The text does also not specify if IA_LL-options can contain multiple options, and if so how those are encoded (presumably as an array/list of option values), perhaps this is already covered by the DHCPv6 spec?\u00a0 Similar comments also apply to the LLaddr-options field.  9. Releasing Addresses Once a block of addresses have been released, can they immediately be allocated to a different client?\u00a0 Or should they avoid being reused straight away if possible?\u00a0 Perhaps this consideration is already covered by DHCPv6, but it probably makes sense to say something about this, either in section 9, and/or maybe in the security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-06-02 13:43:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-27 13:26:01-07:00",
    "text": "Be ye not afraid -- these should be easy to address. I have some concerns about this document -- much of my unease isn't specifically about the document itself, but rather the impact that deploying this on a wide scale may create. Much of my concerns can probably be addressed by sprinkling on some weasel-words / \"you could shoot yourself in the foot if not careful\" language.  Unless I've horribly misunderstood, in the direct client mode, a device comes up, connects to a switch and then changes its MAC address to the DHCP assigned one. This may interact poorly with: a: switches with small CAM tables (sometimes deployed in DCs) b: devices with configured maximum MACs per port, common in enterprises (e.g:  https://www.cisco.com/c/m/en_us/techdoc/dc/reference/cli/nxos/commands/l2/switchport-port-security-maximum.html  ) c: 802.1X (which is often configured to only allow a single MAC per interface / VLAN) d: switches which do things like DHCP snooping. Again, I do realize that most of these issues are not directly the result of this technique, but implementing / deploying this makes it more likely that devices will come up with a temp address and then pivot to an assigned one, and I'd like to see some operational warnings...",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-21 16:39:24-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-17 21:18:59-08:00",
    "text": "I think we need to be more explicit (whether inline or by reference) about what \"Secure joining and the Link-Layer security that it sets up\" (Section 7) entails in terms of ensuring that access to the LLN is only available to authenticated and authorized entities.\u00a0 It might be worth doing so as explicit assumptions or an applicability statement early in the document (e.g., the Introduction). Also, in Section 2.3 we refer to the datagram_tag plus layer-2 sender address as being \"a globally unique identifier for the datagram\", but I think this can only hold within some time-bounded window (e.g., the lifetime of the packet), since the tag space is finite and reuse somewhat inevitable.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-04-13 05:43:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-12 06:05:19-07:00",
    "text": "Thanks for the work on this document. The DISCUSS comment is easy to fix (missing reference), but I also have a couple of minor comments - for the first one I'd like to see a response but the others are suggestions, please feel free to implement or disregard as you see fit. Francesca 1. ----- Missing Reference: 'RFC8665' is mentioned on line 123, but not defined",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-05-29 12:15:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-18 11:47:03-07:00",
    "text": "[1] This document could instruct IANA to rename \"240-254 Experimental Use\" to \"240-254 Private and Experimental Use\", since that is what this document states: \u00a0  If a BAR value is not specified in a RFC but only privately used for \u00a0  a deployment, it MUST be within the \"240-254 Experimental Use\" range \u00a0  of the registry. Furthermore, the statement implies there are two different allocation types here (\"RFC\" and \"privately used\"), but the IANA Registry shows 3 types: \u00a0  0-127 \tStandards Action \u00a0  128-239 \tSpecification Required \u00a0  240-254 \tExperimental Use The \"Specification Required\" could be a non-RFC specification. If this is done, the Abstract should mention the IANA Registry is updated and the IANA Considerations section should be updated. [2] \u00a0  When a BAR value is defined, the corresponding BA and BC semantics \u00a0  SHOULD be specified.\u00a0 For an IGP Algorithm to be used as a BIER IPA, \u00a0  its RA and RC semantics SHOULD be specified. \u00a0  None of the components of the BAR or IPA can be unknown. [...] Then why are these SHOULDs not MUSTs?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-06-09 09:01:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 10:58:06-07:00",
    "text": "** Section 2. \u00a0  If a BAR value is not specified in a RFC but only privately used for \u00a0  a deployment, it MUST be within the \"240-254 Experimental Use\" range \u00a0  of the registry. If this document is redefining \u201cexperimental use\u201d to be \u201cprivately used for a deployment\u201d please provide the appropriate applicability statement that bounds this \u201cdeployment\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-06-16 07:41:41-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-15 11:42:42-07:00",
    "text": "This is basically pro-forma and should be easy to resolve: as pointed out in the secdir review, \"this is widely used, therefore it must be secure\" does\u00a0 not hold any weight.\u00a0 The security considerations should be adjusted to provide some actual justification of the primitive's security or not make such a claim.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-03 02:17:50-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-02 00:05:40-08:00",
    "text": "This is a fine document and I support its publication. However I have a small set of issues that I would like to discuss first. Are non ASCII names needed? (This is a protocol element, not a human readable string, so non ASCII is not needed). Are ASCII spaces allowed in names? More generally: what do you call printable character?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-03-01 09:24:59-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-03 02:17:50-08:00",
    "text": "This is a fine document and I support its publication. However I have a small set of issues that I would like to discuss first. Are non ASCII names needed? (This is a protocol element, not a human readable string, so non ASCII is not needed).",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2017-02-02 07:11:50-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-01 11:55:29-08:00",
    "text": "Thanks for this useful document. I plan to support its approval shortly, but I think we need to finish the discussion we had with Paul's Gen-ART review. I think I'm starting to agree with Mike, but this is worthwhile to point out to the IESG during our deliberations tomorrow. (The issue is whether as per  RFC 5226  one sends a request to a DE and he or she may send it to mailing list, or if IANA should send the request directly to a mailing list. But I think the language in  draft-leiba-cotton-iana-5226bis  is looser on this respect, as it probably should be.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-02-28 18:20:34-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-01-31 08:26:18-08:00",
    "text": "This specification seems to me to break it's own rules. You state that registrations should include a reference to a specification to improve interop. And yet, for the strings added here (e.g. otp) you don't do that (referring to section 2 will not improve interop) and there are different ways in which many of the methods in section 2 can be done. So I think you need to add a bunch more references.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-13 08:27:08-07:00",
    "end_reason": "position_updated",
    "start": "2017-02-28 18:20:34-08:00",
    "text": "I think we still have the problem that the values  \"defined\" here (e.g. \"fpt\") are under specified to a significant degree.  RFC4949  does not tell anyone how to achieve interop with \"fpt\" (nor any of the other cases where you refer to 4949 I think). There is therefore no utility in \"defining\" \"fpt\" as it will not achieve interop and in fact is more likely to cause confusion than interop. If the solution of actually defining the meaning of things like \"fpt\" is not achievable then perhaps it will be better to only define those for which we can get interop (\"pwd\" and one or two others) and leave the definition of the rest for later. (In saying that I do recall that one of the authors said that there are implementations that use some of these  type-names, but the point of RFCs is not to \"bless\" such things, but to achieve interop.) The version of the same point I made on the  previous revision of this draft is below, but IMO still applies. This specification seems to me to break it's own rules. You state that registrations should include a reference to a specification to improve interop. And yet, for the strings added here (e.g. otp) you don't do that (referring to section 2 will not improve interop) and there are different ways in which many of the methods in section 2 can be done. So I think you need to add a bunch more references.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-03-10 03:30:30-07:00",
    "text": "To be honest I don't fully understand the point of this document. It seem like this document is supposed to be the basis for more discussion, however, I thought that's what we have the wg for. So when and how do we come to a final decision if we want to implement the proposed changes? And what would we do in that case - take this document and republish? Why can't we make the decision first and then publish something? In short, I think it would be important that the document also describes what the next steps are and the triggers to move on!",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2016-01-07 00:33:10-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-14 21:31:00-07:00",
    "text": "You use  RFC 2616  as a reference for HTTP 1.1, but that's obsolete, and the current reference should be  RFC 7230  for the general references and  RFC 7231 , Section 3.1.1.5 for Content-Type (the citation in Section 4 here).\u00a0 The Security Considerations section should cite both 7230 and 7231. -- Section 3.1 -- \u00a0  A JSON object consists of name/value pairs.\u00a0 The JSON names of the \u00a0  pairs are indicated with \"\". I don't find the meaning of the second sentence to understandable at all.\u00a0 What are you trying to say? -- Subsections of 3.2 -- Where are the semantics of the string values, such as \"HIGH\", \"NORMAL\", and \"LOW\", defined? -- Section 4 -- \u00a0  For deployment scenarios where Peer (Client) authentication is \u00a0  desired at the Tracker, HTTP Digest Authentication MUST be supported, \u00a0  with TLS Client Authentication as the preferred mechanism, if \u00a0  available. You need a normative reference to  RFC 7616  for HTTP Digest Authentication, and a citation here. -- Section 4.1.1.1 -- Please re-check your examples carefully, and pass them through a JSON validator.\u00a0 In the first example, for instance, the Content-Length value is wrong and the \"transaction_id\" member is missing its \":\".\u00a0 The third example uses \"TransactionID\" instead of \"transaction_id\" for the member name. Be careful during AUTH48 that you re-check this, including making sure that any Content-Length values are still correct after all the editing.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-10-13 19:08:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2015-10-13 19:07:20-07:00",
    "text": "I think this draft needs privacy considerations. The protocol sensitive information in the form of IP addresses and location. If I understand correctly it may also identify transferred content, which can be highly sensitive under some circumstances. Encryption is optional.\u00a0 It think it needs stronger guidance on privacy implications and the use of HTTPS.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2015-11-13 14:56:22-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-13 19:08:06-07:00",
    "text": "I think this draft needs privacy considerations. The protocol carries sensitive information in the form of IP addresses and location. If I understand correctly it may also identify transferred content, which can be highly sensitive under some circumstances. Encryption is optional.\u00a0 It think it needs stronger guidance on privacy implications and the use of HTTPS.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-12-14 18:29:46-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-13 18:46:47-07:00",
    "text": "Thanks for your work on this draft, I have a few things I'd like to discuss that we should be able to resolve quickly.\u00a0 I'll try where possible to offer suggestions, but please do let me know if there is a good reason why they don't make sense. 1. Section 5.2.7 Please make mention and reference to security provisions for SNMP and Syslog.\u00a0  RFC5424  is just for syslog, so a pointer for SNMP security considerations should be added in this section as well.\u00a0 They use a boilerplate for the text and add considerations specific to a draft.\u00a0  Benoit - do you have a good reference for them to use?\u00a0 A more generic SNMP draft might not be up-to-date with the latest boilerplate text.\u00a0 If that's the case, the recent changes are small and could be stated with a pointer to an RFC with the older boilerplate text. 2. Are there any considerations for the statistics collected, can they be used in a malicious way?\u00a0 I would think so and that this would be an important security consideration.\u00a0 Mentioning possible issues would be helpful to the reader. Section 6 Reference to  RFC2616  isn't enough for the security considerations of HTTP since that's a really old RFC.\u00a0 If you want authentication options, you could point to the HTTPAuth documents, which include updated versions of HTTP basic ( RFC7616 ) and digest ( RFC7617 ).\u00a0 While there are still lots of security issues with these options, the RFCs spell out what the actual considerations are, which are helpful to the reader.\u00a0 This raises the need for TLS 1.2 as well to provide session protection for the session (passive and active attacks) as well as for the authentication used. Section 6.1 Why isn't TLS a must here to protect the session data? If you are relying on OAuth Bearer tokens, they offer no security protection without TLS, so to rely on this, I'd say TLS really should be a MUST.\u00a0 The authentication types to get a bearer token (at least in RFC documentation and in the registry) are all pretty weak and require TLS protection to have any level of security. With the TLS MUST, we are recommending TLS 1.2 as the minimum in drafts.\u00a0 It would be good to see a mention of TLS 1.2 as a minimum recommendation and a reference to the BCP for TLS 1.2 configurations  RFC7525  (it even includes cipher suite recommendations). Privacy I would have expected some discussion on the protection of the 2 ID types and the tracker capabilities and that session encryption (TLS) ought to be used when this is a consideration.\u00a0 Is there a reason this isn't covered?\u00a0 If it's not a concern, I'd like to understand why.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-01-10 14:12:50-08:00",
    "end_reason": "position_updated",
    "start": "2015-10-14 12:26:11-07:00",
    "text": "6.2 - can you explain to me how the overall protection against pollution works? I'm not quite following it and am concerned that it may be lacking. But that may just be me forgetting how this ties together with  rfc7574 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-04-19 09:06:16-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-17 15:38:48-07:00",
    "text": "Thanks for writing this up; it's good to have better clarity about the requirements placed on various actors in pNFS.\u00a0 I will change to Yes once this issue is resolved: Section 4 leaves me confused about what exactly from  RFC 5661  is being updated.\u00a0 That is, the subsections look to be some discussion about how the \"real requirements\" (i.e., this document) apply to the given layout types, and we are told that these sections do not update the specification for those specific layout types.\u00a0 So it's hard to get a clear picture about which specific requirements are being changed/added; this leads me to wonder if the top-level Section 4 should not say \"This section updates Section 12 of [ RFC5661 ]\" and leave the \"discussed here only to illuminate the updates made to Section 12 of [ RFC5661 ]\".",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-07-23 00:14:18-07:00",
    "end_reason": "evaluation_closed",
    "start": "2015-05-27 12:21:43-07:00",
    "text": "Thanks for your work on this draft.\u00a0 I would expect the security consideration to discuss the shift to security at the client as well as to see some text on access controls and access checks, which may just refer to existing sections.\u00a0  The SecDir review had similar comments with some specific suggestions that do not appear to have been addressed, but please do point me to the thread if there has been follow up.\u00a0 Specifically, better organization of the security considerations is requested and I agree with Joe's assessment. https://www.ietf.org/mail-archive/web/secdir/current/msg05662.html",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-12-13 14:17:55-08:00",
    "end_reason": "position_updated",
    "start": "2016-12-13 05:53:53-08:00",
    "text": "Before I ballot yes on this there is one aspect I'd like to briefly discuss... Is this clear enough that it is not replacing temporary addresses, and in saying when one ought use those vs. when one ought use 7217? I'm not sure TBH, but, for me, this text reads a bit too much as \"use 7217 and not temporary addresses\" except for in the place where it says \"For example, this document does not change any existing recommendations concerning the use of temporary addresses as specified in [ RFC4941 ],...\" So my discuss point is: does this document need more clarity as to when to use 7217 and when to use 4941? I suspect it probably does need a more clear statement about that, if we think we can reach consensus on what that ought say;-)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-22 09:54:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 14:44:44-07:00",
    "text": "Are the HMAC keys required to be the hash function's block size or its output size?\u00a0 Section 3.1 says just \"the length of each key is exactly the hash size of the associated HMAC algorithm\", and \"hash size\" conventionally refers to the output length.\u00a0 The referenced Section 2 of RFC 2104  concerns itself with the hash's compression function's block size B, which is generally different. Also in Section 3.1, if we are going to claim that a \"random string of sufficient length\" suffices to initialize a fresh index, we need to provide guidance on what constitutes \"sufficient length\" to achieve the needed property. Blake2s is a keyed MAC, but is not an HMAC construction.\u00a0 If we are to allow its usage for providing integrity protection of babel packets directly, we therefore cannot refer to the preotection scheme as \"HMAC\" generically.\u00a0 Fixing this will, unfortunately, be somewhat invasive to the document, since we mention HMAC all over the place.\u00a0 I believe that \"Keyed Message Authentication Code (Keyed MAC)\" is an appropriate replacement description. The suggestion that the large challenge nonce size admits storage of state in a secure \"cookie\" in the nonce is true, however, implementing this properly presents some subtleties, and it seems like something of an attractive nuisance to suggest that it is possible without giving adequate guidance at how to do it safely.\u00a0 Unfortunately, the best reference I can think of, offhand, is the obsoleted  RFC 5077 . Let's also have a discussion about whether 64 bits of randomness is always sufficient; I left a longer note down in the Comment since I don't expect this to end up being a blocking point.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-07 05:17:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 05:16:36-07:00",
    "text": "I would like to quickly discuss the following approach taken in section 4.3.1.1: \u00a0  \"Since a challenge may be prompted by a packet replayed by an \u00a0  attacker, a node MUST impose a rate limitation to the challenges it \u00a0  sends; the limit SHOULD default to one challenge request every 300ms, \u00a0  and MAY be configurable.\" While it is important to limit challenge message here, there might be a better approach than static rate-limiting given this is a request-response mechanism. Usually the approach is to only allow for one outstanding request (without) reply and apply some kind of loss detect/termination rule. In your case the easiest approach would be when the 30 sec timer is expired, or if the RTT is know or can be estimated than a value of e.g. 3xRTT could be appropriate as well. Please consider this alternative approach. May also see  RFC8085  for further guidance. Further Appendix A (Incremental deployment and key rotation) contains normative language and therefore should probably be moved into the body of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-20 08:51:07-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 05:17:53-07:00",
    "text": "I would like to quickly discuss the following approach taken in section 4.3.1.1: \u00a0  \"Since a challenge may be prompted by a packet replayed by an \u00a0  attacker, a node MUST impose a rate limitation to the challenges it \u00a0  sends; the limit SHOULD default to one challenge request every 300ms, \u00a0  and MAY be configurable.\" While it is important to limit challenge messages here, there might be a better approach than static rate-limiting given this is a request-response mechanism. Usually the approach is to only allow for one outstanding request (without reply) and apply some kind of loss detect/termination rule. In your case the easiest approach would be when the 30 sec timer is expired, or if the RTT is known (or can be estimated) then a value of e.g. 3xRTT could be appropriate as well. Please consider this alternative approach. Maybe also see  RFC8085  for further guidance. Further Appendix A (Incremental deployment and key rotation) contains normative language and therefore should probably be moved into the body of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-07 12:34:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 12:34:11-07:00",
    "text": "A few minor clarifications needed for implementation/precision in the security claims: (1) Section 1.2.\u00a0 Per \u201cany packet accepted as authentic is the exactly copy of a packet originally sent\u201d, this text can be read two ways \u2013 packet as Babel packet or as an IP packet.\u00a0 I think\u00a0 mean the former.\u00a0 Recommend making this clearer as s/any packet/any Babel packet/ (2) Section 2, Per the paragraph, \u201cBy itself, this mechanism is safe against replay \u2026\u201d, please reiterate that for the attack by C to work: A and B must have both lost state; that C is replaying packets with PC previously sent by B (e.g., n+2). (3) Section 4.1.\u00a0 Per \u201cThe node takes the concatenation of the pseudo-header and the packet including the packet header but excluding the packet trailer (from octet 0 inclusive up to (Body Length + 4) exclusive)\u201d, as input for the HMAC.\u00a0 \u201cpacket\u201d is used to sometimes mean IP packet and sometimes a Babel packet carried in an IP packet.\u00a0 As such, the above sentence could be interpretation as: Option #1: HMAC(pseudo-header + the IP header + Babel packet header + Babel packet body \u2013 Babel trailer) Option #2: HMAC(pseudo-header + Babel packet header + Babel packet body) I believe it is option #2.\u00a0 Please be very clear in this text. Other items: (4) Section 2.\u00a0 This section suggests that \u201cone or more HMACs can be appended to the packet\u201d.\u00a0 Under what conditions would it be more than one?\u00a0 What happens if only some of the HMACs are valid?\u00a0 Is use of the same key assumed? (5) Section 4.1.\u00a0 The hash algorithm appears to be negotiated/set out of band (rather than negotiated). The text should explicitly state that somewhere. (6) Section 6.\u00a0 Per \u201cIn particular, reception of a packet with no correct HMAC creates no local state\u00a0 whatsoever\u00a0 (Section 4.3)\u201d, unless this HMAC verification is happening on the NIC, this doesn\u2019t seem sufficiently precise.\u00a0 The \u201cno local state\u201d claim is likely true only as it relates to the tables data structures describes in Section 3.\u00a0 However, the IP and DTLS stack certainly have to account for the packet.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-17 12:09:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 12:34:53-07:00",
    "text": "A few minor clarifications needed for implementation/precision in the security claims: (1) Section 1.2.\u00a0 Per \u201cany packet accepted as authentic is the exactly copy of a packet originally sent\u201d, this text can be read two ways \u2013 packet as Babel packet or as an IP packet.\u00a0 I think\u00a0 mean the former.\u00a0 Recommend making this clearer as s/any packet/any Babel packet/ (2) Section 2, Per the paragraph, \u201cBy itself, this mechanism is safe against replay \u2026\u201d, please reiterate that for the attack by C to work: A and B must have both lost state; that C is replaying packets with PC previously sent by B (e.g., n+2). (3) Section 4.1.\u00a0 Per \u201cThe node takes the concatenation of the pseudo-header and the packet including the packet header but excluding the packet trailer (from octet 0 inclusive up to (Body Length + 4) exclusive)\u201d, as input for the HMAC.\u00a0 \u201cpacket\u201d is used to sometimes mean IP packet and sometimes a Babel packet carried in an IP packet.\u00a0 As such, the above sentence could be interpretation as: Option #1: HMAC(pseudo-header + the IP header + Babel packet header + Babel packet body) Option #2: HMAC(pseudo-header + Babel packet header + Babel packet body) I believe it is option #2.\u00a0 Please be very clear in this text. Other items: (4) Section 2.\u00a0 This section suggests that \u201cone or more HMACs can be appended to the packet\u201d.\u00a0 Under what conditions would it be more than one?\u00a0 What happens if only some of the HMACs are valid?\u00a0 Is use of the same key assumed? (5) Section 4.1.\u00a0 The hash algorithm appears to be negotiated/set out of band (rather than negotiated). The text should explicitly state that somewhere. (6) Section 6.\u00a0 Per \u201cIn particular, reception of a packet with no correct HMAC creates no local state\u00a0 whatsoever\u00a0 (Section 4.3)\u201d, unless this HMAC verification is happening on the NIC, this doesn\u2019t seem sufficiently precise.\u00a0 The \u201cno local state\u201d claim is likely true only as it relates to the tables data structures describes in Section 3.\u00a0 However, the IP and DTLS stack certainly have to account for the packet.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-19 04:13:53-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 05:18:07-07:00",
    "text": "I think the topic should be fairly easily to resolve one way or another. However, even after having read the reply to Marin's comment I don't think this document is published with the right status.  - The document defines new CBOR attributes, that is standard track work as it comes out as consensus document from a IETF WG.  - It does not define or document crypto algorithm just refer to existing ones. - The charter item might have been reasonable as informational if existing attributes could have been used. With the choice to define new attributes I think this has entered standards track. - The status of the document I think will also affect the value that IANA might assign to these COSE Header Parameters.  If there are additional considerations I am happy to learn about them.  Else, I would propose a change of status to proposed standard and redo the IETF last call.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-12-31 13:17:42-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-20 19:57:31-07:00",
    "text": "ection 2.\u00a0 Where is the uri (CCDL) syntax/format/data type (used by x5u and x5u-sender) defined?\u00a0 Is this covered by CBOR tag=32?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:33:47-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 09:36:21-07:00",
    "text": "(1) Related to Alvaro's DISCUSS, given that this document is AD-sponsored and it has an IPR declaration that implies a possible royalty/fee, I think we need to see specific support in the community for advancing this draft in light of the IPR declaration (as would normally be done in a WG for a WG document). I realize there have been expressions of support on the last-call list since the IESG started balloting, but they didn't speak to the IPR question.  (2) If I understand the vision for the IANA registry here, I think it needs to have a specification required policy rather than expert review. It seems like a large part of the value would be having documented specs for other versions (just as for this version), and given that the version space is small I assume we're not expecting a flood of registration requests without documentation.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-02-09 14:53:02-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-11 08:59:50-07:00",
    "text": "Is this an IETF consensus document?\u00a0 [This point is for the IESG to discuss.] rfc8789  (IETF Stream Documents Require IETF Rough Consensus) reads: \"The IETF MUST NOT publish RFCs on the IETF Stream without establishing IETF rough consensus for publication.\" I know that as an AD-sponsored document, it went through IETF LC, but it received no comments at all except for directorate reviews.\u00a0 Does that establish rough consensus?\u00a0 IMO, it just proves that no one objected, but also doesn't support that anyone is in favor. The Shepherd writeup says that the \"document is an Individual Submission that was developed in the Broadband Forum.\"\u00a0 And also adds this opinion: \u00a0  This draft represents a strong-consensus technical solution that has \u00a0  undergone many iterations (and looking at various other alternatives) \u00a0  in Broadband Forum. All the major router vendors and ISPs wanting to \u00a0  do 5G wireline have been involved and are on board... It points to consensus -- but in the BBF. My conclusion is that this is not an IETF consensus document and should not be published in the IETF Stream, according to  rfc8789 .\u00a0 The ISE seems like a better publication path.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-09-07 06:12:00-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 13:28:52-07:00",
    "text": "Similar to Alvaro, I am concerned if the intention is for this document to be published in the IETF stream. I agree with Alvaro's concern on consensus and meeting  RFC8789  guidelines. Even more of a concern for me is that it does not follow the guidelines of  RFC4775  ( BCP125 ) if the intention is in support of BBF's work. RFC4775  recommends when there is a formal liaison in place with another SDO, the liaison channel should be used. On this work, there has been no formal liaison communicating this document meets their needs? The document acknowledges \"This memo is a result of comprehensive discussions by the Broadband Forum's Wireline Wireless Convergence Work Area.\" The Shepherd writeup cites informal verification of support for the document. List discussion indicates the same. But there has been no formal communication confirming these statements. While this document's supporters may be correct in their affirmation of BBF's consensus on this document, RFC4774  was done to ensure IETF and another SDO do communicate directly.  RFC4774  has been valuable in setting the guidelines for other SDOs over these last years. It would be a bad precedent to ignore it here. Considering IETF has a formal liaison relationship with BBF, I don't think it will introduce too much of a delay to obtain confirmation on this solution meeting their needs. I would recommend also sending a note to our IETF-IEEE coordination group.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-11 12:43:15-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-11 09:41:44-07:00",
    "text": "Section 1 states \"The 8 byte  RFC 2516  data packet header...\" Isn't this a 6-byte header?\u00a0 Will this cause problems for devices that are not inspecting the version field assuming the payload follows after 6 bytes?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-12-20 07:41:23-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-19 19:12:51-08:00",
    "text": "How are the measurement interval(s) for these TLVs chosen?\u00a0 I note that  RFC 7810  (and 7810bis), as well as  RFC 7471 , include some text about measurement intervals, in particular, a default value of 30 seconds and in at least one case a requirement for configurability at sub-TLV granularity (thus, TLV granularity for us here).\u00a0 That said, it's not entirely clear to me whether I'm supposed to treat the measurement intervals as also inherited from 7810bis/7471 as part of the \"semantics of the value field\".\u00a0 It may be worth a brief clarifying note in the top-level Section 2.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-02-27 14:32:10-08:00",
    "end_reason": "position_updated",
    "start": "2016-02-15 14:40:27-08:00",
    "text": "This document is clearly requesting the assignment of LISP EID space for an experiment.\u00a0 Why is it not an Experimental document?\u00a0 [I may have missed the discussion in the archive.] Along the same lines, the conditions for the experiment to be successful and the IETF to consider whether to transform the prefix into a permanent assignment (Section 6.\u00a0 3+3 Allocation Plan) are not defined.\u00a0 How should this decision be made?\u00a0 How will the IETF know the experiment is successful?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-06-12 20:13:58-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-06-12 20:12:33-07:00",
    "text": "I am really glad to see this document getting published. It has been a long while in the making. This should be easy to clear but I would like to make sure that the terminology used here to determine TLV lengths is accurate. * In Sections 3.1.3.3., 3.1.4.1., 3.1.4.2., 3.1.5.2, 3.3.3. the TLV-Length is shown to be 4+length of the contents of the TLV-Data (either the ipv6pref or the ipv4pref). I think this should be 2+length of the contents of the TLV-Data instead.  Can you please clarify how you arrived at 4+x instead of 2+x?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-06-13 07:24:11-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-12 20:13:58-07:00",
    "text": "I am really glad to see this document getting published. It has been a long while in the making. This should be easy to clear but I would like to make sure that the calculation used here to determine TLV lengths is accurate. * In Sections 3.1.3.3., 3.1.4.1., 3.1.4.2., 3.1.5.2, 3.3.3. the TLV-Length is shown to be 4+length of the contents of the TLV-Data (either the ipv6pref or the ipv4pref). Maybe I am missing something, but I think this should be 2+length of the contents of the TLV-Data instead.  Can you please clarify how you arrived at 4+x instead of 2+x?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-06-17 09:38:15-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-17 09:56:33-08:00",
    "text": "I support Eric's DISCUSS point about the TTL, but I want to go a step further because this document contradicts  rfc5881 , which is clear about the TTL setting (from \u00a75): \u00a0  If BFD authentication is not in use on a session, all BFD Control \u00a0  packets for the session MUST be sent with a Time to Live (TTL) or Hop \u00a0  Limit value of 255.\u00a0 All received BFD Control packets that are \u00a0  demultiplexed to the session MUST be discarded if the received TTL or \u00a0  Hop Limit is not equal to 255.\u00a0 A discussion of this mechanism can be \u00a0  found in [GTSM]. \u00a0   \u00a0  If BFD authentication is in use on a session, all BFD Control packets \u00a0  MUST be sent with a TTL or Hop Limit value of 255.\u00a0 All received BFD \u00a0  Control packets that are demultiplexed to the session MAY be \u00a0  discarded if the received TTL or Hop Limit is not equal to 255.\u00a0 If \u00a0  the TTL/Hop Limit check is made, it MAY be done before any \u00a0  cryptographic authentication takes place if this will avoid \u00a0  unnecessary calculation that would be detrimental to the receiving \u00a0  system. OTOH, Section 4 of this document specifies:  \u00a0 \u00a0  TTL or Hop Limit: MUST be set to 1 to ensure that the BFD \u00a0 \u00a0  packet is not routed within the Layer 3 underlay network.\u00a0 This \u00a0 \u00a0  addresses the scenario when the inner IP destination address is \u00a0 \u00a0  of VXLAN gateway and there is a router in underlay which \u00a0 \u00a0  removes the VXLAN header, then it is possible to route the \u00a0 \u00a0  packet as VXLAN\u00a0 gateway address is routable address. Not wanting the packet to be routed in the underlay sounds like a reasonable justification -- but I couldn't find the specification in  rfc7348  about \"a router in underlay which removes the VXLAN header\".\u00a0 Maybe I missed it... Independent of VXLAN, the conflict with  rfc5881  remains -- given the text above, it seems to me that it would be ok if the TTL was set to 1 if authentication is is use, but this document doesn't talk about requiring authentication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-29 13:31:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-16 15:43:02-08:00",
    "text": "I have a few points that I think merit IESG discussion. (1) I see that several directorate reviewers expressed unease at the destination (IP and) MAC address assignment procedure for the inner VXLAN headers, and appreciate that there was extensive on-list discussion (more than I could follow).\u00a0 That said, I failed to find a clear statement of why the current text is believed to be safe, and in fact my reading of the current text is that the described procedure is *not* safe.\u00a0 Pointers to key parts of the WG discusison would be more than welcome! To take something of a high-level view of my concerns, if we think of the VXLAN as being a tunnel between VTEPs that carry encapsulated tenant traffic, then what we're trying to do is roughly like BFD between VTEPs, but we want to get fault-detection over as broad a coverage as we can (the \"outermost part of the tunnel\"), so we want to have the option of per-VNI BFD instead of just endpoint-to-endpoint (VTEP-to-VTEP). However, we end up having to do this by trying to insert a thin filter into the tenant's address space (i.e., the inner VXLAN header) and pick out the specific stream of BFD traffic that we're introducing.\u00a0 This is, in some sense, a namespace grab in what is conceptually the tenant's namespace, and we have to be careful that what we do is either guaranteed to not impact the tenant or well-documented and compartmentalized (akin to the \"well-known URIs\"). I've made comments at several places in the document that are more directly tied to specific pieces of text, but in general, if we assume that the tenant can add/remove new addresses at will within their VXLAN abstration, then any attempt to preconfigure by mutual agreement the BFD addresses to use at the VTEPs or to use the VTEP's normal (outer) address as the sentinel value seems subject to the tenant coming in and subsequently trying to use that address, leading to (some of) the tenant's traffic getting silently filtered and interpreted by the VTEP. If we were using domain names as identifiers, we could allocate something under .arpa or similar, but I think our options are more limited when numerical addresses are used. The option suggested by the rtg-dir reviewer of always using the management VNI does not suffer from this namespacing issue, though I recognize that it does reduce the scope over which fault-detection is available, for the cases when different VNIs' traffic are routed or handled differently. (2) Section 6 says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The selection \u00a0  of the VNI number of the Management VNI MUST be controlled through \u00a0  management plane.\u00a0 An implementation MAY use VNI number 1 as the \u00a0  default value for the Management VNI.\u00a0 All VXLAN packets received on \u00a0  the Management VNI MUST be processed locally and MUST NOT be \u00a0  forwarded to a tenant. It seems like the management VNI concept is something that would apply to the entire VXLAN deployment and not just to the BFD-using portions; is this already defined somewhere (in which case we should reference it), or is it new with this document?\u00a0 In the latter case wouldn't it be an update to the core VXLAN spec?\u00a0 (I note that there are some procedural hoops to jump through for an IETF-stream document to update an ISE-stream document...)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-07-14 00:22:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-17 00:51:29-08:00",
    "text": "Thank you for the work put into this document. I fully second Adam's COMMENT that should be fixed before publication (IMHO this is a DISCUSS). Answers to my COMMENTs below will be welcome, even if those COMMENTs are not blocking. As usual, an answer to the DISCUSS is required to clear my DISCUSS though. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == May be I am not familiar enough with BFD, but,  RFC 5881  (the one defining BFD) specifies the use of TTL = Hop Limit = 255.. Why this document uses a value of 1 ? -- Section 3 -- IPv4-mapped IPv6 addresses are only to be used inside a host and should never be transmitted in real packets (including packets inside a tunnel) see section 4.2 of  RFC 4038  (even if informational). As other IESG reviewers, I wonder why ::1/128 is not used? -- Section 8 -- The document specifies no IANA actions while the shepherd write-up talks about a IANA action. -- Section 9 -- This section is only about IPv4 (TTL and  RFC 1812 ). Please address IPv6 as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-07-22 05:28:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-14 00:22:10-07:00",
    "text": "Thank you for the work put into this document and its update. I have cleared one of my DISCUSS point avout TTL = Hop Limit not being 255. All other DISCUSS points remain esp the use of IPv4-mapped IPv6 addresses rather than the IPv6 loopback ::1/128.  I hope that this helps to improve the document, Regards, -\u00e9ric -- Section 3 -- IPv4-mapped IPv6 addresses are only to be used inside a host and should never be transmitted in real packets (including packets inside a tunnel) see section 4.2 of  RFC 4038  (even if informational). As other IESG reviewers, I wonder why ::1/128 is not used? BTW, the right wording is \"IPv4-mapped IPv6 address\" and not \"IPv4-mapped IPv4 address\" as written twice in the document. -- Section 8 -- The document specifies no IANA actions while the shepherd write-up talks about a IANA action. ==> please update the shepherd's report accordingly.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-12-01 07:38:26-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-30 11:54:07-08:00",
    "text": "Don't Panic! As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion... I'm assuming that I'm missing something really obvious here, but this *feels* like a bad idea to me... The document says: \"The use of logotypes will, in many cases, affect the users decision to trust and use a certificate.\" Yes, but that seems like a bad outcome... Random things on the Internet tell me that Microsoft has a well recognized logo. Seems plausible, let's use that as an example. When a user is trying to figure out if a certificate actually belongs to Microsoft they are likely to go \"Oh, yes, it's a square composed of other colored squares, this must really be Microsoft\", even if the CN is for  www.evil-attackers-r-us.net . Even without an attacker intentionally creating visually confusing logos, many are similar - for example,  https://icn.bg/  looks really similar to Microsoft's logo (and many things look very similar to the Pepsi logo -  https://yourmileagemayvary.net/2021/05/23/look-up-in-the-sky-its-a-coke-plane-its-a-pepsi-plane-its/  ). Here is an image with two logos:  https://cdn.mos.cms.futurecdn.net/hD95PaJgx5ZZVCFduTWhtg-1200-80.jpg.webp  One of these is for airbnb, and one is for a Japanese drive-in. Keeping in mind that, as a user, the logotype is likely to affect your decision to trust and use the cert, when entering your credit-card info to book your next vacation rental, do you know which of these you should expect? If you get the drive-in one, would you really recognize that? The document uses VISA and MasterCard as examples, but, without looking in your wallet to actually confirm what their logos look like, are you *sure* that you would be able to unambiguously identify them if placed next to logos made by an attacker?  Ok, so now that I've had my soapbox rant: This document updates  RFC 3709  and  RFC 6170 , which been around since 2004 and 2011 respectively. Apparently the sky hasn't actually fallen yet, and so I must be missing something. I did spend quite a while trying to find examples using  RFC3709 /RFC6170, so I could figure out what I'm missing, but failed. I *did* find a few CA certs with this, but they just had links to  http://logo.verisign.com/vslogo.gif  (which doesn't resolve). The only \"live\" cert was for  https://www.dtihost.cz/ , but it's not valid. Again, I'm probably missing something obvious, and so clue-bat appreciated...",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-11-03 11:03:48-07:00",
    "end_reason": "position_updated",
    "start": "2016-11-02 12:15:07-07:00",
    "text": "Hopefully this is easy to resolve, and is probably just confusion on my part. But I am confused by whether or not the edits in a single patch are expected to be atomic. I assumed no, since the results can speak to multiple edits, but section 5 mentions atomicity as a RESTCONF requirement. Is atomicity not required by yang-patch in general, but required when using RESTCONF? Section 5 goes on to talk about disruption due to partial processing, which further confuses me if RESTCONF requires atomicity.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-12-02 08:04:33-08:00",
    "end_reason": "position_updated",
    "start": "2016-10-31 08:28:37-07:00",
    "text": "This should be easy to resolve through discussion or some text tweaks.\u00a0 In the security considerations section, I see some text that hints at my questions below, but isn't clear enough, so I'd like to discuss it to see if these things are covered, or why they are not, and to see if we can tweak the text a bit. The following text is helpful, is PATCH described in [ I-D.ietf-netconf-restconf ]? \u00a0  This document defines edit processing \u00a0  instructions for a variant of the PATCH method, as used within the \u00a0  RESTCONF protocol. I see section 2.7 discusses error handling and validating the YANG module, but is there a way that the hash (or some other mechanism) of the patch could be validated to ensure the patch was not altered.\u00a0 Is that already described for PATCH? I also see this text in the security considerations section: \u00a0  It is important for RESTCONF server implementations to carefully \u00a0  validate all the edit request parameters in some manner.  Is the source of the patch authenticated?\u00a0 Can the client receiving the patch be authenticated?\u00a0 Is this handled through RESTCONF?\u00a0 Since YANG modules could add in write capabilities, unauthenticated patches could result in opening backdoors or revealing information that was not intended.\u00a0 You are covering it with that statement, but it's not clear if both ends can be authenticated and there are attacks if they are not authenticated.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-02 09:39:27-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-18 17:29:11-08:00",
    "text": "A nontrivial amount of text in this document appears to have been taken from https://access.atis.org/apps/group_public/download.php/32237/ATIS-1000074.pdf which notes that \"No part of this publication may be reproduced in any form, in an electronic retrieval system or otherwise, without the prior written permission of the publisher.\"\u00a0 Do we have prior written permission to duplicate such text?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-09 15:23:54-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-17 15:17:16-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D5207 I would like to discuss the privacy properties of origids. As I read this text, it does not actually require them to be unlinkable or that it not be possible to determine whether two ids represent the same person behind the origid generator, and I believe it should do so. Practically implementing that may require an ID that is longer than a UUID.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-03-31 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2017-03-16 08:08:35-07:00",
    "text": "olding a Discuss so that comments get addressed.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2016-01-07 05:59:28-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-17 06:37:55-08:00",
    "text": "I'm elevating this to a (late) Discuss, because I haven't heard anything back, and didn't want the document approved without having a (short) discussion. I'll be back to Yes after that. In this text, \u00a0  The \"status\" member duplicates the information available in the HTTP \u00a0  status code itself, thereby bringing the possibility of disagreement \u00a0  between the two.\u00a0 Their relative precedence is not clear, since a \u00a0  disagreement might indicate that (for example) an intermediary has \u00a0  modified the HTTP status code in transit.\u00a0 As such, those defining \u00a0  problem types as well as generators and consumers of problems need to \u00a0  be aware that generic software (such as proxies, load balancers, \u00a0  firewalls, virus scanners) are unlikely to know of or respect the \u00a0  status code conveyed in this member. \u00a0   I understand what you're saying about a mismatch being possible, and some of the possible reasons why that might happen, but isn't this saying that anyone who can understand the \"status\" member should prefer its value when there's a mismatch (because it's less likely to have been dorked with by an intermediary - or is that even true)? So, the situation looks to me, like there's a MUST \u00a0  The status member, if present, is only advisory; it conveys the HTTP \u00a0  status code used for the convenience of the consumer.\u00a0 Generators \u00a0  MUST use the same status code in the actual HTTP response, to assure \u00a0  that generic HTTP software that does not understand this format still \u00a0  behaves correctly.\u00a0  that some intermediary can dork with, so the result violates the MUST, and we really can't tell the receiver what you should do at that point. \"Gee, I guess you're gonna have to flip a coin to decide who to believe\" would be sad, but it would be more guidance than the document has now :-)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-14 17:50:09-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-02 11:48:44-08:00",
    "text": "Since the downrefs that were omitted from the IETF Last Call announcement are to documents published on the ISE stream, I would like to ensure that the IESG specifically discusses that fact, as we determine whether or not an additional IETF LC (corrected to indicate the downrefs) is needed. If we knew that the referenced mechanisms already had IETF consensus, I would be much less concerned about having the IESG approve the downrefs without further community consultation. I'd also like to have the authors double-check the Content-Length in the HTTP response in Figure 10 (Section 7.2); my (admittedly hacky) methodology produces a length of 1246 in contrast to the listed length of 1349.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-18 12:18:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 11:52:34-08:00",
    "text": "Exciting to see this work progressing. Section 3.5 (and Section 7): \"Type (8 bits):\u00a0 Type indicating the format of the data contained in \u00a0 \u00a0 \u00a0 this option.\u00a0 Options are primarily designed to encourage future \u00a0 \u00a0 \u00a0 extensibility and innovation and so standardized forms of these \u00a0 \u00a0 \u00a0 options will be defined in a separate document.\" \u00a0 \u00a0  I'm a little confused about what is expected to happen with the option classes and types. Are all future option types in the 0x0000..0x00FF range expected to be specified in a single separate document? If not, that should be clarified. I also think there needs to be a normative requirement that such future specifications define all of the types associated with the option classes. In the registry defined in Section 7, I think the table needs a column for the document to reference for each option class definition. That way when option classes are defined in the 0x0000..0x00FF range, implementers and operators will be able to find the reference and understand the semantics of the types. For the vendor-specific options this can be optional, but still would be nice to list if such documentation exists.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-03-01 08:38:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 19:24:19-08:00",
    "text": "This will be trivial to address: \u2014 Section 1.2 \u2014 \u00a0  The NVO3 framework [ RFC7365 ] defines many of the concepts commonly \u00a0  used in network virtualization. Indeed, and it seems a critical normative reference here.\u00a0 So why is it in the informative section?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-27 17:30:05-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 16:36:32-08:00",
    "text": "This first point is a \"discuss discuss\" for which I'd like to get a sense of what the rest of the IESG feels.\u00a0 I've read the discussion at https://mailarchive.ietf.org/arch/msg/last-call/ywRKREnxWAlunHR7MSaTM4ScsDs but I'm left with a similar sense of uncertainty that Daniel has as to whether the question is fully resolved.\u00a0 Specifically, \"the question\" that I have in mind is to what extent the Geneve architecture includes support for middleboxes that inspect (but do not modify!) the Geneve header and inner payload, to what extent the Geneve architecture is intended to be applicable to scenarios where (end-to-end per-tunnel) underlay confidentiality protection is necessary, and whether those requirements are both strong enough to be deemed an internal inconsistency of requirements/applicability.\u00a0 \"Interposing advanced middleboxes\" and \"service interposition\" are conceived as possible uses for Geneve metadata in Sections 1 and 2.2 as a consideration for why structured tagging is needed on the data plane and not just the control plane, which to me suggests that such usage is considered a first-class use case for Geneve.\u00a0 Section 6.1.1 discusses encryption for traffic traversing untrusted links between geographically separated data centers (though perhaps in this case an encrypted tunnel would be used just for that untrusted transit and leaving the in-datacenter traffic visible to middleboxes), but Section 6.1 discusses cases where the tenant may expect the service provider to provide confidentiality as part of the service.\u00a0 Would this be above or below the Geneve encapsulation? Might some customers insist on one or the other?\u00a0 The consideration from Section 6.1 that the provider of the underlay and the provider of the overlay may not be the same could be taken to imply that the overlay provider itself wants (cryptographic) protection from the underlay provider.\u00a0 I don't have a clear picture of how these considerations interact.\u00a0 (I also note that, since DTLS is mentioned, DTLS 1.3 is going the way of TLS 1.3 and not defining any authentication-only ciphersuites, so if authentication-only service is desired, DTLS may not be the way of the future, leaving IPsec AH as the leading candidate.) Some other section-by-section discuss-level points follow, mostly self-contained/localized issues. Section 3.5.1 \u00a0  o\u00a0 Some options may be defined in such a way that the position in the \u00a0 \u00a0 \u00a0 option list is significant.\u00a0 Options MUST NOT be changed by \u00a0 \u00a0 \u00a0 transit devices. \u00a0  o\u00a0 An option SHOULD NOT be dependent upon any other option in the \u00a0 \u00a0 \u00a0 packet, i.e., options can be processed independently of one \u00a0 \u00a0 \u00a0 another.\u00a0 [...] As was already noted, I don't see how these two requirements are self-consistent. \u00a0  size.\u00a0 A particular option is specified to have either a fixed \u00a0  length, which is constant, or a variable length, which may change \u00a0  over time or for different use cases.\u00a0 This property is part of the \u00a0  definition of the option and conveyed by the 'Type'.\u00a0 For fixed This text is written as if this specification is going to specify further substructure for the \"Type\", with respect to certain types that have fixed length and others that may vary.\u00a0 Otherwise the property would be attached to the option value and not the type value, in my understanding.\u00a0 With the current way the registry is laid out it seems like we need to explicitly say that the entity allocating the option class value needs to specify the interpretation of the 'type' field when used with that option class. Section 4.3.1 \u00a0  2.\u00a0 If Geneve is used with zero UDP checksum over IPv6 then such \u00a0 \u00a0 \u00a0  tunnel endpoint implementation MUST meet all the requirements \u00a0 \u00a0 \u00a0  specified in section 4 of [ RFC6936 ] and requirements 1 as \u00a0 \u00a0 \u00a0  specified in section 5 of [ RFC6936 ]. This seems to implicitly be saying that the other numbered requirements in Section 5 of  RFC 6936  can be ignored, which is updating the behavior of a standards-track document.\u00a0 We need to either be explicit about the update or justify why (the rest of) that applicability statement is not applicable here.\u00a0 If, as the paragraph following the enumerated list says, the requirements specified in  RFC 6936  continue to apply in full, why do we need to call out a MUST-level requirement here? \u00a0  4.\u00a0 The Geneve tunnel endpoint that encapsulates the tunnel MAY use \u00a0 \u00a0 \u00a0  different IPv6 source addresses for each Geneve tunnel that uses \u00a0 \u00a0 \u00a0  Zero UDP checksum mode in order to strengthen the decapsulator's \u00a0 \u00a0 \u00a0  check of the IPv6 source address (i.e the same IPv6 source \u00a0 \u00a0 \u00a0  address is not to be used with more than one IPv6 destination \u00a0 \u00a0 \u00a0  address, irrespective of whether that destination address is a \u00a0 \u00a0 \u00a0  unicast or multicast address).\u00a0 When this is not possible, it is \u00a0 \u00a0 \u00a0  RECOMMENDED to use each source address for as few Geneve tunnels \u00a0 \u00a0 \u00a0  that use zero UDP checksum as is feasible. This functionality is not usable without some mechanism to signal from encapsulator to decapsulator that it is in use. \u00a0  The requirement to check the source IPv6 address in addition to the \u00a0  destination IPv6 address, [...] I do not see this specified as a requirement, only a MAY-level suggestion. Section 4.6 \u00a0  o\u00a0 When performing LSO, a NIC MUST replicate the entire Geneve header \u00a0 \u00a0 \u00a0 and all options, including those unknown to the device, onto each \u00a0 \u00a0 \u00a0 resulting segment.\u00a0 However, a given option definition may \u00a0 \u00a0 \u00a0 override this rule and specify different behavior in supporting \u00a0 \u00a0 \u00a0 devices.\u00a0 [...] This second sentence makes the MUST in the first no longer a MUST.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-02-29 23:27:04-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 10:03:52-08:00",
    "text": "Thank you for the work put into this document. It solves an interesting problem and the document is easy to read. I have one DISCUSS that is **trivial to fix** and some COMMENTs, feel free to ignore my COMMENTs even if\u00a0 I would appreciate your answers to those COMMENTs. Regards, -\u00e9ric == DISCUSS == -- Section 3.3 -- Please use  RFC 8200  the 'new' IPv6 standard rather than  RFC 2460  ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-02 06:52:36-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 06:16:23-08:00",
    "text": "I want to discuss the implications of the source port usage and if that needs a bit more consideration of failure cases and ICMP. So Section 3.3 says: \u00a0  Source port:\u00a0 A source port selected by the originating tunnel \u00a0 \u00a0 \u00a0 endpoint.\u00a0 This source port SHOULD be the same for all packets \u00a0 \u00a0 \u00a0 belonging to a single encapsulated flow to prevent reordering due \u00a0 \u00a0 \u00a0 to the use of different paths.\u00a0 To encourage an even distribution \u00a0 \u00a0 \u00a0 of flows across multiple links, the source port SHOULD be \u00a0 \u00a0 \u00a0 calculated using a hash of the encapsulated packet headers using, \u00a0 \u00a0 \u00a0 for example, a traditional 5-tuple.\u00a0 Since the port represents a \u00a0 \u00a0 \u00a0 flow identifier rather than a true UDP connection, the entire \u00a0 \u00a0 \u00a0 16-bit range MAY be used to maximize entropy. I think using the different source ports to enable flow hashing is a nice idea. However, I am a bit worried over the implications of using the full 16-bit range without caveats. Specifically in cases where a network error or other failure to forward the Geneve encapsulated packet and that result in any form a return traffic towards the tunnel ingress. Such as ICMP Packet Too Big messages or Port / Host unreachable. These messages needs to be consumed by the Geneve tunneling endpoint to affect the right response to them. However, if the source port is corresponding to any port where there exist a listenser or bi-directional server on the tunnel ingress host, such as SSH, Echo etc. the ICMP messages may be consumed by the wrong entity that only filter on source port and not the destination port.  I believe this issue may require at least a explicit consideration in the document. Otherwise thanks for thinking through many transport issues for tunnels.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-04 10:13:34-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-03 11:05:02-08:00",
    "text": "nline with RFC6335 the Assignee and Contact of the port entry should also be updated to IESG\u00a0 and IETF Chair\u00a0 respectively.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-04 01:29:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 10:13:34-08:00",
    "text": "Thanks for the really well written document that addresses all transport related question well (and thanks to David for the early TSV review!). I only have one minor process point that need to be addressed before publication: Inline with  RFC6335  the Assignee and Contact of the port entry should also be updated to IESG\u00a0 and IETF Chair\u00a0 respectively.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-03 06:36:46-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 18:03:42-08:00",
    "text": "(1) The threat model assumed by geneve appears to be expressed in conflicting ways.\u00a0 Section 4.1 notes that  RFC8085 \u2019s definition of \u201ccontrolled environment\u201d applies.\u00a0 However,  - Section 6 notes \u201cWhen crossing an untrusted link, such as the public Internet, \u2026\u201d - Section 6.1 notes \u201cGeneve data traffic between tenant systems across such separated networks should be protected from threats when traversing public networks. Any Geneve overlay data leaving the data center network beyond the operator's security domain SHOULD be secured by encryption mechanisms such as IPsec or other VPN mechanisms to protect the communications between the NVEs when they are geographically separated over untrusted network links.\u201d\u00a0  The advice provided in Section 6.x is sound.\u00a0 Nevertheless, it doesn\u2019t appear to describe a \u201ccontrolled environment\u201d. (2) Section 6.\u00a0 Per \u201cCompromised tunnel endpoints may also spoof identifiers in the tunnel header to gain access to networks owned by other tenants\u201d, couldn\u2019t compromised transit devices do the same? (3) Section 6.1.\u00a0 Similar to what is discussed in Section 6.2 (for integrity), please refer to the impact of a compromised node on confidentiality.\u00a0 For example (not verbatim) \u201cA compromised network node or a transit device within a data center may passively monitor Geneve packet data between NVEs; or route traffic for further inspection.\u201d (4) Section 6.1.\u00a0 Per \u201cDue to the nature of multi-tenancy in such environments, a tenant system may expect data confidentiality to ensure its packet data is not tampered with (active attack) in transit or a target of unauthorized monitoring (passive attack).\u201d, please provide additional precision on the confidentiality. It is only relative to other tenants, but not from the provider (who can engage in tampering and passive monitoring).",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-01 10:28:27-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 05:37:39-08:00",
    "text": "* Section 3.3. This might be an easy DISCUSS to resolve. Since the specification requires the Destination port to be configurable, it is not clear to me how the \"transit\" devices will identify Geneve packets being sent to a non-default port (i.e. not 6081). Can you please clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-24 12:10:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-21 15:58:26-07:00",
    "text": "I think we may have to be more specific about updates to the  RFC 8445  state machine, namely whether we are specifying a new state for a checklist to be in (vs. keeping it somehow in the \"Running\" state and modifying the procedures for that state) and describing what happens in Section 7.2.5.4 when all candidate pairs in the checklist are Failed or Succeeded but the PAC timer has not expired.\u00a0 In other words, the combination of 8445 and this document need to be consistent about what the ICE state machine is. In contrast, Trickle is pretty clear about which conditions in which sections of [rfc5245bis] are updated and how, but we don't seem to provide the same level of detail.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-26 21:26:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 06:53:42-07:00",
    "text": "There are several internal inconsistencies that needs to be resolved before publication, specifically for: (1) the destination address of the IPv6-in-IPv6 tunnel used for flows from the Internet to a ~Raf -- Section 6.2.4 says addressed to the ~Raf, but Figure 7 says \"hop\". (2) the destination address of the IPv6-in-IPv6 tunnel used for flows from a ~Raf to a ~Raf -- Section 6.3.4 says addressed to the ~Raf, but Figure 7 says \"hop\" (3) Table 14 says \"(opt: RPI)\" which, though not defined, I take to mean as indicating that the insertion of the RPI is optional, but the body text in Section 7.1.2 is unconditional that the 6LBR inserts an RPI header (4) Section 7.2.1 does not mention adding v6-in-v6 encapsulation, but Figure 8 has a \"must\" in that column. (5) Section 7.3.1 only has descriptive text that \"[t]he originating node should put the RPI into an IPv6-in-IPv6 header\", but Figure 8 lists this behavior as \"must\" (though there would also be a second v6-in-v6 encapsulationi from root to destination, which is clearly a must). (Note that Section 7.3.2 covers essentially the same flow, but uses \"which must be in an IPv6-in-IPv6 header addressed to the root\".) (6) In Section 5, we say that the DODAG root \"SHOULD force [rank information] to zero\" but then that \"[t]he Internet will therefore not see any SenderRank information\", and a SHOULD-level requirement is not enough to guarantee this statement as fact. Additionally, there are some terminology inconsistencies in Figures 7 and 8 that need to be cleaned up or explained.\u00a0 For example, in Figure 7, what is the difference between \"Yes\" and \"must\" in the \"IPv6-in-IPv6\" column, and in the \"v6-in-v6 dst\" column, what does \"root\" mean? In Figure 8, what does \"Opt\" mean in the \"RPI\" column?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-05-16 23:04:37-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 23:13:09-07:00",
    "text": "The document is interesting and is about an interesting twist of behavior in the light of  RFC 8200  new behavior with respect to Hop-by-hop extension header. But, I am balloting a DISCUSS for two reasons: 1) in section 3.1,\u00a0 I am failing to understand the link between  RFC8200  HbH behavior and why the RPI code needs to be changed to 0x23.\u00a0 => a clear explanation is required on why the option 0x23 is linked to  RFC 8200 : I fail to understand the authors' logic. At first sight, with the new  RFC8200  HbH handling, there is no need to change the RPI code from 0x63 as most routers will ignore HbH anyway. 2) the document deserves a better text as there are too many nits, unexpanded acronyms, ... the reader has hard time to understand the document. Again, the content is useful but need some more work.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-01-25 21:42:20-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 21:46:34-08:00",
    "text": "[ section 12 ] * Ignoring an invalid RH3 header by the end host (I'm assuming this \u00a0 means that segments left > 0) doesn't specify whether the packet \u00a0 should be processed (ignore the RH) or the whole packet should be \u00a0 ignored. \u00a0 I might recommend instead referring to  RFC 6554  S4.2 for how to handle \u00a0 RH3's if the node is also a RPL-aware router and say it MUST drop the \u00a0 packet if segments left is non-zero and it's not a RPL-aware router. \u00a0 Related: I'd also recommend: \u00a0 \"It should just be noted that an incoming RH3 must be fully consumed, or \u00a0  very carefully inspected.\" \u00a0 -> \u00a0 \"It should just be noted that an incoming RH3 MUST be fully consumed.\"",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-30 13:24:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-30 13:24:14-07:00",
    "text": "Per Section 11: \u00a0  [ RFC2473 ] suggests that tunnel entry and exit points can be secured, \u00a0  via the \"Use IPsec\".\u00a0 The suggested solution has all the problems \u00a0  that [ RFC5406 ] goes into.\u00a0 In an LLN such a solution would degenerate \u00a0  into every node having a tunnel with every other node.\u00a0 It would \u00a0  provide a small amount of origin address authentication at a very \u00a0  high cost; doing  BCP38  at every node (linking layer-3 addresses to \u00a0  layer-2 addresses, and to already present layer-2 cryptographic \u00a0  mechanisms) would be cheaper should RPL be run in an environment \u00a0  where hostile nodes are likely to be a part of the LLN. ** I having trouble understanding what recommendation this text was making.\u00a0 The first sentence seems to suggest IPSec, the second sentence seems to discount that advice; and the third seems to suggest  BCP38  as an alternative.\u00a0 Could you please clarify. ** Please be explicit on which challenges in  RFC5406  are being cited (e.g., which sections)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-29 11:58:35-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-30 13:24:34-07:00",
    "text": "Per Section 11: \u00a0  [ RFC2473 ] suggests that tunnel entry and exit points can be secured, \u00a0  via the \"Use IPsec\".\u00a0 The suggested solution has all the problems \u00a0  that [ RFC5406 ] goes into.\u00a0 In an LLN such a solution would degenerate \u00a0  into every node having a tunnel with every other node.\u00a0 It would \u00a0  provide a small amount of origin address authentication at a very \u00a0  high cost; doing  BCP38  at every node (linking layer-3 addresses to \u00a0  layer-2 addresses, and to already present layer-2 cryptographic \u00a0  mechanisms) would be cheaper should RPL be run in an environment \u00a0  where hostile nodes are likely to be a part of the LLN. ** I'm having trouble understanding what recommendation this text was making.\u00a0 The first sentence seems to suggest IPSec, the second sentence seems to discount that advice; and the third seems to suggest  BCP38  as an alternative.\u00a0 Could you please clarify. ** Please be explicit on which challenges in  RFC5406  are being cited (e.g., which sections)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-04-27 08:59:24-07:00",
    "end_reason": "position_updated",
    "start": "2016-04-20 19:20:08-07:00",
    "text": "Section 5.1.1: The following text in the Total Length handling suggests that fragments containing IPsec AH will not get through these translators. Is this intentional? If so, it should be clearly stated. If not, there needs to be an exception defined for AH as well. \"If the Next Header field of the Fragment Header is an extension header (except ESP) then the packet SHOULD be dropped and logged.\" Section 5.3: The following text regarding TTL handling in ICMP messages does not say what to actually do with the TTL value and could lead to ambiguity in implementations. The ICMP error messages\u00a0 containing the packet in error MUST be translated just like a normal IP packet (except the TTL value of the inner IPv4/IPv6 packet) I think the intent (correct me if I am wrong) is to ensure that the the TTL/Hop Limit is not decremented. If so, I would recommend rewording to something like this The ICMP error messages\u00a0 containing the packet in error MUST be translated just like a normal IP packet (except that the TTL/Hop Limit value of the inner IPv4/IPv6 packet are not decremented)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-08-01 03:32:04-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-27 09:43:06-07:00",
    "text": "The tsv-art review has raised a number of substantial issues that need to be addressed before publication (big thanks to Magnus Westerlund!). As far as I can see solution to address these issues have been discussed by email but are not reflected in an updated draft yet. I'm holding this discuss till an update occurs. In other words, please update the draft!",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-07-16 00:33:27-07:00",
    "end_reason": "position_updated",
    "start": "2017-07-05 12:15:41-07:00",
    "text": "1: Instead of answering the questions, the Shepherd Writeup just has links to things - for example: (9) How solid is the WG consensus behind this document? Does it  represent the strong concurrence of a few individuals, with others being silent, or does the WG as a whole understand and agree with it?\u00a0   WG LC:  Passed: https://www.ietf.org/mail-archive/web/trill/current/msg07304.html Discussion:  https://www.ietf.org/mail-archive/web/trill/current/msg07210.html This caused me to go investigate further - it seems that there were only 4 comments received during WGLC (excluding the RtgDir review, a short exchange with Julien Meuric). The comments which *were* received largely just fell into the \"Support\" (with no real discussion) category.  The document was adopted 06 March 2015, and then there were a few automated mentions of it (e.g [0], [1]), but I see no real discussion of the draft *in the WG*.  It is entirely possible that my search fu is weak today, and that there has been sufficient discussion and review of the draft (or that none was needed because it is so obviously right and pure, but I'd like some reassurance of that), especially because a quick review found multiple readability issues / nits.  Note: I'm not holding the discuss on the readability / nits, rather on has the process been followed / is there consensus grounds 2: The document also says that it Updates: 6325, 7177, 7780 - but I don't see clear discussion of the Updates (OLD / NEW). [0]:  https://mailarchive.ietf.org/arch/msg/rtg-dir/c863sUajt86YB_d62uWfF5Hd_X4 [1]:  https://mailarchive.ietf.org/arch/msg/i-d-announce/p5ROVvvoU0B3S1OA2SY3vebX_b4",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 15:40:16-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 18:00:00-08:00",
    "text": "Thanks for discussing the need to secure the various control-plane interactions as part of the Security Considerations.\u00a0 In addition to the integrity and source-authentication properties already mentioned, we need to say that the control-plane functionality will apply authorization checks to any commands or updates that are made by the control-plane protocol. Similarly, I didn't see any discussion of authorization for applying or making changes to the \"rules\" that are mentioned as needing to be applied by a data-plane node (as mentioned in the COMMENT where I ask for clarification on the nature of such rules). Also, we should reference RFCs 8221 and 8247 for the current guidance on IPsec and IKEv2 usage.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-05 04:28:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-05 04:25:09-07:00",
    "text": "ell spotted by Mirja: [RFC8259] should be a Normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-10 02:52:06-08:00",
    "end_reason": "position_updated",
    "start": "2019-09-05 04:28:18-07:00",
    "text": "Well spotted by Mirja/Adam: [ RFC8259 ] should be a Normative reference. Also please change the reference to [ RFC7159 ] to point to [ RFC8259 ].",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-15 10:09:25-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-04 16:08:33-07:00",
    "text": "We use a subset of the JSON \"number\" type to represent integers, which inherits JSON's range limits on numbers.\u00a0 My understanding is that such limits are not present in IODEF XML (e.g., we do not specify a totalDigits value), so this is a new limitation of the JSON format that needs to be documented (and, technically, drops us out of full parity with the XML form). The JSON \"examples\" seem to be using a \"//\" notation for comments, that is not valid JSON nor described by  draft-zyp-json-schema , thus appearing to make the examples malformed (absent some other disclaimer of the commenting convention). How does STRUCTUREDINFO relate to EXTENSION?\u00a0 What makes one vs the other appropriate for a given piece of information?\u00a0 Since the former is only in\u00a0  RFC 7203  and not 7970, we do not have an easy reference for their interplay, given 7970's minimal discussion of the use of 7203. (It sounds like STRUCTUREDINFO is for structures from other published specifications and EXTENSION is for more local/custom things, but I'm not entirely sure if that's exactly the intended split.) Can the shepherd please report on what level of validation has occurred on the CDDL syntax, the mappings between  RFC 7970 's content and this document's content, and the consistency between the formal syntax and the body text (e.g., listings of enum values, member fields of each type, etc.)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-26 12:59:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-15 10:09:25-08:00",
    "text": "We use a subset of the JSON \"number\" type to represent integers, which inherits JSON's range limits on numbers.\u00a0 My understanding is that such limits are not present in IODEF XML (e.g., we do not specify a totalDigits value), so this is a new limitation of the JSON format that needs to be documented (and, technically, drops us out of full parity with the XML form). Can the shepherd please report on what level of validation has occurred on the CDDL syntax, the mappings between  RFC 7970 's content and this document's content, and the consistency between the formal syntax and the body text (e.g., listings of enum values, member fields of each type, etc.)?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-11-18 22:10:08-08:00",
    "end_reason": "position_updated",
    "start": "2019-09-03 12:42:56-07:00",
    "text": "* Section 5 (CDDL) and Appendix B (JSON schema) I am trying to understand how \"ipv6-net-mask\" will be used since there is no such thing, and \"ipv6-net\" already covers the only possible way of denoting prefixes. Can you please clarify why and how you intend to use this? I remember reading and balloting on  RFC7970  and it did not (IMHO rightly) have a category for this.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-16 09:21:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-16 08:43:18-07:00",
    "text": "I would like to get clarification on the following points before recommending approval of this document: 1) How do multiple CAPABILITY TLVs from the same source treated, if they have the same S and D flags, but different subTLV? Are the cumulative? Or this is not allowed? I am sorry if I missed where this was described, let me know if I did. 2) In Section 4, 1st sentence: how can this specification have requirements on implementation that don't support this extension? If this behaviour is already prescribed by another specification, then you should not use  RFC 2118  keyword and you should reference the relevant specification.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-18 03:08:39-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-16 09:21:46-07:00",
    "text": "I would like to get clarification on the following points before recommending approval of this document: 1) How do multiple CAPABILITY TLVs from the same source treated, if they have the same S and D flags, but different subTLV? Are the cumulative? Or this is not allowed? I am sorry if I missed where this was described, let me know if I did.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-18 07:50:09-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-18 03:08:39-07:00",
    "text": "I would like to get clarification on the following points before recommending approval of this document: 1) Section 2 says: \u00a0  The Router CAPABILITY TLV is OPTIONAL.\u00a0 As specified in Section 3, \u00a0  more than one Router CAPABILITY TLV from the same source MAY be \u00a0  present. Section 3 says: \u00a0  Where a receiving system has two copies of a CAPABILITY TLV from the \u00a0  same system that have different settings for a given attribute, the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^^^^^^^^^^^^ \u00a0  procedure used to choose which copy shall be used is undefined. The word \"attribute\" only occurs once in the document, so it would be better if it is replaced for clarity. Does \"a given attribute\" mean \"a single sub-TLV\" or \"all sub-TLVs included in a CAPABILITY TLV instance\"? If \"a given attribute\" means \"a single sub-TLV\", then I have the following followup questions: What happens in real world if there are two CAPABILITY TLVs which contain different attributes? Are they treated as cumulative (i.e. this is a nice trick to overcome CAPABILITY TLV length limit), does the second CAPABILITY\u00a0 TLV value always overrides earlier instances of the CAPABILITY TLV? I think the document should state what happens. If there is no consistent behaviour in this area, the document should says so as well.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-18 07:53:47-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-16 19:33:53-07:00",
    "text": "* Section 4 requires the CAPABILITY TLV to be leaked without any change based on the text below \"If leaking of the CAPABILITY TLV is required, the entire CAPABILITY TLV MUST be leaked into another level without change even though it may contain some sub-TLVs which are unsupported by the Router doing the leaking. \" but Section 2 requires a router leaking the TLV from level-2 to level-1 to set the D bit and this violates the \"without change\" requirement.  I think this inconsistency needs to be resolved somehow.  P.S.: One possible way would be to add some exception text for the D bit into the above text in Section 4. Another would be to remove the restriction against change (I noticed that this restriction did not exist in  RFC4971  - was this check added to fix some issue identified during deployment?).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-05-21 07:13:49-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-09 08:14:07-07:00",
    "text": "There are a lot of places where the actual requirements seem (potentially) ambiguously written or incomplete, or the document is internally inconsistent.\u00a0 I expect that at least some of these are just confusion on my part, so hopefully someone can clue me in on where I'm going astray. Not exactly a DISCUSS, but is there a plan for resolving the normative reference to the expired draft-ietf-bess-evpn-inter-subnet-forwarding ? Does Section 3's \u00a0  [...] In case two or more NVEs are attached to \u00a0  different BDs of the same tenant, they MUST support RT-5 for the \u00a0  proper Inter-Subnet Forwarding operation of the tenant. apply even when there is a SBD between them in the topology, or does something in the SBD also need to support RT-5 in such cases? Section 3.2's \u00a0  o The ESI and GW IP fields may both be zero, however they MUST NOT \u00a0 \u00a0  both be non-zero at the same time. A route containing a non-zero GW \u00a0 \u00a0  IP and a non-zero ESI (at the same time) SHOULD be treat-as- \u00a0 \u00a0  withdraw [ RFC7606 ]. seems to say that ESI and GW IP cannot both be zero at the same time, but there seem to be entires in Table 1 that have that be the case.\u00a0 There are also potential combinations not included in Table 1 -- are we supposed to infer that anything not listed is an error condition (and thus treat-as-withdraw)? Section 4.4.1's \u00a0  Each RT-5 will be sent with a route-target identifying the tenant \u00a0  (IP-VRF) and two BGP extended communities: seems to say that there will always be these two extended communities, but there seems to be other text later implying that the \"Router's MAC\" extended community is not always present.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:41:54-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 13:58:35-07:00",
    "text": "Section 7.6: \" The format type and schema parameters can be specified on this \u00a0 \u00a0 \u00a0 property and are RECOMMENDED for text or inline binary encoded \u00a0 \u00a0 \u00a0 content information.\" Doesn't this need to be REQUIRED rather than RECOMMENDED in order for it to improve rather than potentially worsen interoperability? Section 8.1: \"User agents MUST NOT include this information \u00a0 \u00a0 \u00a0 without informing the participant.\" This seems like it needs to say \"without the participant's express permission.\" (As in  https://www.w3.org/TR/geolocation-API ).",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-05-27 05:15:08-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-16 01:14:11-07:00",
    "text": "Thanks for the work in this document; I think there\u2019s useful stuff here, and I appreciate what it took to put it together.\u00a0 Two things at the DISCUSS level: \u2014 Sections 5.2, 7.1, and 8.1 \u2014 Please see  BCP 178  ( RFC 6648 ), and then remove x-name and x-prop.\u00a0 Thanks. \u2014 Section 10 \u2014 It\u2019s good to refer to  RFC 3986  for URI-related security considerations, and all of them do apply here. Something else that comes to mind that comes along with a set of new URIs is whether they actually point to what they say they do.\u00a0 I don\u2019t see that there\u2019s any way to verify that they do, and I\u2019m very skeptical about the effectiveness of warning an end user about this sort of thing, for many reasons.\u00a0 I can see why allowing URIs is convenient and compelling, but I\u2019m very heavily concerned about tracking and other privacy leaks, malicious and deceptive content, and other such problems, especially considering the prevalence of abusive calendar invitations these days. I\u2019m not sure what the answer is here, but let\u2019s have a discussion about it and see where we can go with it.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-01-04 13:55:29-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-27 05:15:08-07:00",
    "text": "Thanks for the work in this document; I think there\u2019s useful stuff here, and I appreciate what it took to put it together.\u00a0 One thing at the DISCUSS level: \u2014 Section 10 \u2014 It\u2019s good to refer to  RFC 3986  for URI-related security considerations, and all of them do apply here. Something else that comes to mind that comes along with a set of new URIs is whether they actually point to what they say they do.\u00a0 I don\u2019t see that there\u2019s any way to verify that they do, and I\u2019m very skeptical about the effectiveness of warning an end user about this sort of thing, for many reasons.\u00a0 I can see why allowing URIs is convenient and compelling, but I\u2019m very heavily concerned about tracking and other privacy leaks, malicious and deceptive content, and other such problems, especially considering the prevalence of abusive calendar invitations these days. I\u2019m not sure what the answer is here, but let\u2019s have a discussion about it and see where we can go with it. Update: We will discuss this in the calext interim meeting, jointly with CalConnect.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-01-14 06:57:26-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 13:55:29-08:00",
    "text": "Thanks very much for the changes in Section 9.1, and I think we're now at the best place we can reasonable be here.\u00a0 Well done. Thanks also for the changes to clarify the ABNF.\u00a0 They're mostly good, and we should be able to clean these last bits up pretty easily: \u2014 Section 6.6 \u2014 The new ABNF doesn\u2019t correctly specify what the old was trying to say.\u00a0 I think this is correct and concise, but please check it over: NEW sdataprop\u00a0 \u00a0 = \"STRUCTURED-DATA\" sdataparam \":\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  sdataval CRLF \u00a0 \u00a0 \u00a0 sdataparam\u00a0 \u00a0  = ; all parameter elements may appear in any order, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ; and the order is not significant. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (sdataparamtext / sdataparambin / sdataparamuri) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *(\";\" other-param) \u00a0 \u00a0 \u00a0 sdataparamtext = \";VALUE=TEXT\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" fmttypeparam \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" schemaparam \u00a0 \u00a0 \u00a0 sdataparambin\u00a0 = \";VALUE=BINARY\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";ENCODING=BASE64\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" fmttypeparam \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" schemaparam \u00a0 \u00a0 \u00a0 sdataparamuri\u00a0 = \";VALUE=URI\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [\";\" fmttypeparam] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [\";\" schemaparam] \u00a0 \u00a0 \u00a0 sdataval\u00a0 \u00a0 \u00a0  = ( binary / text /uri ) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ; value MUST match value type END \u2014 Section 7.1 \u2014 \u00a0 \u00a0 \u00a0 participantc = \"BEGIN\" \":\" \"PARTICIPANT\" CRLF \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *( partprop / locationc / resourcec ) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"END\" \":\" \"PARTICIPANT\" CRLF This allows multiple instances of partprop (or none), which is not what you mean.\u00a0 The \u201c*\u201d isn\u2019t right.\u00a0 Also, do you really mean to have locationc and resourcec here?\u00a0 Those are blocks that are peers of participantc within eventc, todoc, journalc, and freebusyc\u2026 are they also meant to be nested within participantc?\u00a0 If so, it would be good to have an example or two that shows that.\u00a0 In any case, that bit of ABNF still needs some work. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (calendaraddress) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (created) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (description) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (dtstamp) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (geo) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (last-mod) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (priority) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (seq) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (status) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (summary) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (url) All of these are meant to be optional, so they should be in square brackets, rather than in parentheses.\u00a0 The same is true in Sections 7.2 and 7.3.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-29 10:39:36-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 17:08:42-07:00",
    "text": "I want to talk some about the redefinition of SOURCE.\u00a0 While I agree that the original definition's applicability is more narrow than it needs to be, that doesn't seem to be enough to convince me that there's enough justification to make it so broad as to provide vcard information about a participant or an event link-back, as opposed to just the canonical source of updates for a given object/component.\u00a0 I must apologize for having essentially not done a search of the WG discussion archives for this topic, and pointers into the archive could help to convince me that this redefinition is a stable, interoperable, and backwards-compatible choice. The example in Section 5.4: \u00a0 \u00a0  STRUCTURED-DATA;FMTTYPE=application/ld+json; \u00a0 \u00a0 \u00a0 SCHEMA=\" https://schema.org/FlightReservation \"; \u00a0 \u00a0 \u00a0 ENCODING=BASE64;VALUE=BINARY:Zm9vYmFy contains an inline value that doesn't seem to decode to a valid FlightReservation JSON object. Perhaps I'm misreading, but the ABNF in Section 7.6 does not seem to allow for an explicit VALUE=TEXT parameter to be given, and the description does not list TEXT as the default value type.\u00a0 (I note that the listed example does include VALUE=TEXT, causing this to rise to a Discuss-level internal inconsistency.) Similarly, the examples in Section 8.1 seem incomplete, since they omit the REQUIRED dtstamp and uid properties.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-16 16:22:16-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 12:05:05-07:00",
    "text": "Per the Security Considerations section, [ RFC3986 ] and [W3C.REC-html51-20171003] were helpful. I was hoping to see cautionary text for the potentially danger of handling/parsing arbitrary binaries as allowed by STRUCTURED DATA.\u00a0 I didn\u2019t see it in downstream references. I also tried to find the referenced section suggested by \u201cSecurity considerations relating to the \u2018ATTACH\u2019 property, as described in [ RFC5545 ]\u201d but could not.\u00a0 It\u2019s not the explicit Security Considerations (Section 7 of [ RFC5545 ) or in the definition of Attachment (Section 3.8.1.1 of [ RFC5545 ]).\u00a0 Do you mean Section 3.1.3, Binary Content?\u00a0 Could you please make it clear which section you meant.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-01-10 13:01:34-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-09 19:51:01-08:00",
    "text": "This should be easy to resolve, after which I plan to ballot \"yes\": It seems like this needs to update at least  RFC 5280 . Section 4 creates what I assume to be a new requirement for all email address domains in X.509 certificates to conform to IDNA2008. That seems like a reasonable requirement, but if we want people reading 5280 to know about that requirement, we need the \"updates\" relationship. Also, section explicitly says it updates a section of 5280.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-06 11:17:12-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-15 13:21:56-08:00",
    "text": "Thanks for writing this document; it's an important topic and I look forward to seeing interoperability in this space. However, I don't think this document is quite ready for publication yet, as it has a number of internal inconsistencies (and at least one external inconsistency with IETF procedures) that would get in the way of interoperable implementation. (1) The procedure for substituting an entryPoint from the provider list into the OpenAPI interface description for obtaining configuration data appears to be incompatible with  BCP 190 .\u00a0 Though there's not quite enough detail for me to be able to tell exactly what behavior is intended, the procedure of \"replace localhost in the template with the value from provider discovery\" seems like it implies that the value from provider discovery is just a hostname, and that we are requiring the RUM services to be accessible via HTTP at path /rum/v1 on that machine.\u00a0 The URI path namespace is under control of the owner of the host, and we cannot assert that we will occupy that portion of the namespace.\u00a0 The current version of  BCP 190 ,  RFC 8820 , does allow us to say (effectively) \"delegate a subtree of the path namespace to the protocol\" by letting the owner of the host pick what base path to use for the protocol (even that would not have been allowed by its predecessor,  RFC 7320 ), but we do need to let that host-specific path prefix be indicated somehow, whether by URL template or allowing a base path to be indicated in the provider discovery process. (2) There are a lot of inconsistencies about the parameters and data format of the various API responses as specified in prose, OpenAPI description, and examples.\u00a0 In particular, we also fail to make a clear statement about whether the prose or the OpenAPI description is normative and takes precedence in case of disagreement. I'll list a bunch of things here; I made a fairly careful reading but am not willing to assert that this is a comprehensive listing.\u00a0 (A number of them also get comments in the section-by-section comments; sorry about that duplication.) Sections 9.2.1 and 9.2.2 list configuration data items in the \"configuration data for new user sign up and dial around\" and \"configuration data for the RUE\" configuration retrieval APIs, and per the note at the end of \u00a79.2 they include the REQUIRED data items. However, there are a couple data items that are mentioned elsewhere in the document as if they are always going to be present, but are not present in these lists of required configuration parameters.\u00a0 In particular we talk about the \"provider-domain\" as coming from the configuration, and it appears in examples, but is not mentioned in the prose or OpenAPI format description. The prose (and some examples) refer to an \"outbound-proxies\" RUE configuration element, but \u00a79.2.2 and the OpenAPI description list the singular \"outbound-proxy\" (and with the corresponding difference in format/structure). The prose mentions \"credentials\" from the configuration, but no parameter of that name appears (there is some mention of password under \"carddav\" but that seems insufficiently generic to match all instances; sip-password also exists). \"display-name\" appears in the example in Figure 5 but is not listed in \u00a79.2.2 The prose for the provider configuration resource indicates that the dialAround property is mandatory (it is not marked as \"(OPTIONAL)\"), but the OpenAPI specification does not list this property as required. The prose for the provider configuration's \"signup\" property says that it is an array of JSON objects, but the OpenAPI description says that it is just a single object (not an array).\u00a0 Likewise for \"dialAround\" and \"helpDesk\". The prose for \"phone-number\" specifies E.164 format, but the OpenAPI description does not. \"carddav\" is triply inconsistent: the prose says username, password, and domain name are separated by \"@\" (presumably, in a single string), but the example only shows username and domain name in user@domain form, and the OpenAPI description says it should be an object with separate properties for username/password/domain, as well as an additional \"sendLocationWithRegistration\" property that is probably not supposed to be a child of \"carddav\". (repeating from the previous), the \"sendLocationWithRegistration\" property is listed as belonging to the \"carddav\" object in the OpenAPI description, though the prose and example indicate it should be a property of the toplevel configuration object. The prose and OpenAPI description indicate that \"ice-servers\" is an array of strings, but the example has an array of objects that use the dictionary key to indicate whether each URI is a TURN or STUN server.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-01-24 12:51:42-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-07 10:00:07-08:00",
    "text": "Thanks to Bernard Adoba for the TSVART review. It largely informs my DISCUSS. 1. If I understand correctly, this draft is not at all about interoperating with a WebRTC endpoint, instead borrowing some requirements from that family of specs rather than re-inventing the wheel. That's great, but putting that explicitly in the intro would be helpful. 2. In particular, the statement that RUE is a \"non-browser endpoint\" is confusing if it's not actually meant to interoperate with WebRTC. I *think* you're attempting to distinguish between WebRTC's browser-only requirements and endpoint requirements, but I could be wrong here. 3. In Section 5.5, you require conformance with  RFC8835  with a few vaguely worded exceptions. It would be helpful to actually go through that document enumerate exactly which normative statements in 8835 do not apply. That said, I'm not sure I agree with Bernard that 8835 requires *use* of ICE, rather than support, but maybe we can clarify this in the TSVART thread. 4. As Bernard points out, this ambiguity extends to IPv4 and 6 support. The 8835 requirements are specific to browsers, so they might not apply. If you require support for both, but not necessarily on the same device, it would be good to say so. 5. In Sec. 6, it says \"This specification adopts the media specifications for WebRTC ([ RFC8825 ]).\" Is this a normative statement? Must RUEs comply with the entirety of that document, or is this an informative statement and the real requirements are in the subsections of Sec 6? From the discussion, it sounds like you want to include the requirements for WebRTC \"endpoints\", but not for WebRTC \"browsers\". It would help to clarify all this. It's also possible that my initial understanding is incorrect, in which case the later points don't make any sense and some explanatory text is needed.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-01-20 06:58:34-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-15 04:37:08-08:00",
    "text": "There are a couple of points related to versioning that I would like to see clarified, but I hope that it should be fairly easy to do so. 1. \u00a0  This means an implementation of a \u00a0  specific major version and minor version is backwards compatible with \u00a0  all minor versions of the major version. Is it actually compatible with all other minor versions, or only other minor versions with a greater minor version number.\u00a0 E.g., could an implementation be coded to use/expect a object added in a minor version but that is not present in preceding minor versions? 2. \u00a0  The configuration API also provides the same version mechanism as \u00a0  specified above in Section 9.1.\u00a0 The version of the configuration \u00a0  service MAY be different than the version of the provider list \u00a0  service. It wasn't obvious to me, that for a given provider, how this is communicated.\u00a0 I'm not that familiar with OpenAPI, but looks like the /Versions path is a top level API path, and the data that is contains seems to just be version numbers.\u00a0 Hence, how would a client know which versions apply to provider list service and/or which versions apply to the provide configuration service.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-07 13:13:12-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-15 14:07:32-08:00",
    "text": "** Is there a reason that credential re-use is being suggested as a fall back.\u00a0 It seems risky to reuse the credentials across services.\u00a0 This fall-back also appears to contradict the guidance in Section 5.1. which says \u201cThis username/password combination SHOULD NOT be the same as that used for other purposes, such as retrieving the RUE configuration\u201d.\u00a0 See: -- Section 7.1.\u00a0 Per access to the CardDAV server, \u201c[i]f no matching credentials are configured, the RUE MUST use the SIP credentials from the configuration.\u201d\u00a0  -- Section 9.2.2.\u00a0 sip-password says \u201cIf it was never supplied, the password used to authenticate to the configuration service is used for SIP, STUN and TURN.\u201d -- Section 9.2.2.\u00a0 carddav field says that \u201cIf username or password are not supplied, the main account credentials are used. \u201c ** Is there a reason that a minimum transport requirements of using HTTPS is not defined for accessing the SIP-supporting elements of this architecture. -- Section 7.1.\u00a0 Access to the CardDAV service?\u00a0 Does the guidance in Section 7.2 (The RUE stores/retrieves the contact list (address book) by issuing an HTTPS POST or GET request.) imply that? -- Section 9.\u00a0 Using the overall API? Does the guidance in Section 9.2 (A RUE device may retrieve a provider configuration the using a simple HTTPs web service) imply that? -- Section 9.2.1.\u00a0 For the URI configuration options noted in this section (e.g., the uri in signup)? ** Section 11.\u00a0 There are more than 10 20 normative SIP protocol references in this document.\u00a0 Which of their security considerations apply?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-01-20 01:50:10-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-14 13:43:34-08:00",
    "text": "First of all thanks for working on this technology to make communication available and easy for special human beings. (I have worked with them to converter text to sign language in my bachelor hence had a special feeling while reading this specification).  I understood from the email discussions on the TSVART review ( https://mailarchive.ietf.org/arch/msg/tsv-art/Z_Ne5au4rCHwcig8bospMcLyzTc/ ) that in the system RUI is deployed, we will have gateway(s) with two legs - one with WebRTC (client <--> gateway) and one with RUI client communicating with RUI server (gateway <--> server). With this understanding I have some points which I believe worth discussing.  \u00a0 - WebRTC communication will be congestion and rate controlled. This will use RTCP feedbacks to make the rate control and congestion control happen in the WebRTC peers. On the WebRTC part of the leg, this RTCP feedbacks will be available according to the WebRTC specification. However, this specification does not discuss how those RTCP feedback will be converted from the RUI server to RUI client (i.e the gateway) direction and vice versa. This will require the gateway to have such conversion functions to actually work. what is the thinking here? has this been considered? as I am not sure how is the network looks like between the RUI client and RUI server, there might be the Internet connecting them hence need to have congestion controlled traffic. \u00a0 - Thanks to Bernard Aboba for a comprehensive TSVART review of this draft and I would like to bring some issues, identified in that review, here to make sure they are addressed- \u00a0 \u00a0 * clarification on the use of ICE \u00a0 \u00a0 * clarification on what is a WebRTC client, WebRTC server, gateway, RUI client and RUI server. I believe all four have been conceptually used in the specification without concretely defining their roles. for example - if server is mentioned it need to be distinguishable if it is WebRTC server or RUI server ( I noted that there are servers in this specification which are clearly understandable).",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2016-08-30 03:37:22-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-18 05:37:03-07:00",
    "text": "There was a Gen-ART review from Vijay, with a question about the contents of the Context field. I don't think the document necessarily needs a change or even new text here, but at the very least we need an answer from the authors. I got the same question as Vijay when reading the draft.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-06-22 11:23:27-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-20 18:44:56-07:00",
    "text": "This does seem like an interesting and potentially useful idea -- thanks for doing the work!\u00a0 However, I am not sure that the document as-is is suitable for publication. In Section 4.1.5 we hear that preserving metadata and applying metadata to injected packets is not special and is \"usual\" functionality, but section 4.1.2 calls out that the 4.1.2 approach requires the SFs in the path to be capable of forwarding metadata and attaching metadata to injected packets as if it is a nontrivial requirement.\u00a0 This apparent internal inconsistency needs to be resolved before publication. Why does Section 4.1 offer five different choices with no guidance on how to make a cost/benefit analysis amongst them?\u00a0 Is the full spread of five choices really necessary?\u00a0 Complexity breeds implementation bugs which breed security issues, so I feel that this breadth of choice needs to be justified.\u00a0 This also ties into some confusion I have as to the goal of this document (which currently targets Informational status), akin to what is stated in Alvaro's ballot position: is it just providing information on how to assemble existing pieces in a novel way, or presenting a new protocol specification that is not yet fit for Proposed Standard status, or is it listing out potential solutions to a problem so that they can be implemented and experience gained as to which are useful in practice and which are not?\u00a0 Accordingly, I would be interested to hear about what deployment experience exists already and whether this abstraction proves to be as useful as the use cases seem to promise; if there is little implementation experience, perhaps Experimental status is more appropriate. I further am uncertain as to whether the approach described in Section 4.1.3 even merits consideration at all; the technique it describes seems to have a very leaky abstraction barrier (e.g., w.r.t TTL modifications). This seems especially poignant given the already large size of candidate approaches. The approach described in Section 4.1.5 also seems to be incompletely specified, in that the hSFC Flow ID semantics are not covered at all.\u00a0 On my initial reading I assumed that this field's encoding and semantics were intended to be left as entirely local matters to the lower domain, avoiding a need to specify them in this document.\u00a0 However, I'm not sure that it's actually true, since we generally want multiple vendors to be able to interoperate, and this scheme does not appear to require that the node applying the hSFC Flow ID (and saving state) is the same node that removes it (and restores state).\u00a0 That is, these two nodes could potentially be implemented by different vendors. Even once the above issues are resolved, I will only be able to move to an Abstain position, since this document proposes additional usage of (meta)data in the NSH headers that is not subject to mandatory integrity protection, as was discussed at length for  RFC 8300  and is mandated to be available by  RFC 7665 .",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-10-06 22:52:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-21 06:13:27-08:00",
    "text": "Thank you for the work put into this document. This system could indeed be very useful but I am afraid that this is a very complex system especially for IPv6 NDP.  Minor regret in the shepherd write-up as the WG summary did not include any comment on the WG consensus. Thanks to Jean-Michel Combes for its Internet directorate review at:  https://datatracker.ietf.org/doc/review-ietf-bess-evpn-proxy-arp-nd-11-intdir-telechat-combes-2021-01-20/ as Jean-Michel added some important comments, please review them as well as I support them especially those around DAD that should be a blocking DISCUSS point. I also second Erik Kline's DISCUSS points. Question to the authors and BESS WG chairs: was this document submitted to a 6MAN/V6OPS WGs review ? This is where all IPv6 experts live :-) Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated), and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Would  RFC 8929  be enough to solve the problem ? -- Section 3 -- \"A Proxy-ARP/ND implementation MAY support all those sub-functions or only a subset of them.\", I am afraid that it is mandatory that the reply and duplicate-ip must be coupled: either both of them are active or none of them are active else the system allows for duplicate IP addresses. -- Section 3.1 -- \"A Proxy-ARP/ND implementation SHOULD support static, dynamic and EVPN-learned entries.\" why not a MUST ? Or at least for dynamic & EVPN-learned ? or at least one ? \"Upon receiving traffic from the CE... the PE will activate the IP->MAC and advertise it in EVPN\" it is unspecified how many bindings can be advertised in the case of multiple static MAC for one IP... only one or all ? -- Section 3.2 -- Why not flooding to all other PEs the ARP/NS with unknown options ? It would be safer. -- Section 3.6 -- This function MUST be a mandatory part of the list of functions of section 3. -- Section 5.2 -- An easy to fix: \"Any unknown source MAC->IP entries\" isn't it IP->MAC as in the rest of the document including the terminology section ? -- Section 5.4 -- \"traffic to unknown entries is discarded\" which traffic (section 5.5 is much better to this point suggest to copy the text)? The NDP/ARP or normal data plane traffic ? Where is this behavior specified in the 6 sub-functions of section 3 ?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-07-18 20:17:46-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-20 23:20:47-08:00",
    "text": "[ meta ] * I appreciate the attempt to explicitly discuss handling NS/NA messages with \u00a0 not-previously-seen options.\u00a0 Thank you for that. \u00a0 It seems to me, however, that the proposed approach to proceed with \u00a0 setting the current capabilities in concrete but point to things like \u00a0 \"unicast-forward\" as a relief valve, even though 3.2-f seems to say the \u00a0 multicast packets (i.e. on cache miss) should be discarded (implying the \u00a0 unicast mapping might never be learned in the first place?). [ general ] * When a PE reboots, should it do MLD (e.g. 2710, 3810, ...) of some kind to \u00a0 gather critical state so that it doesn't have to wait for CEs to have \u00a0 problems? [ section 3.1 ] * To my knowledge there is no concept in IPv6 of a link where anycast/O=0 \u00a0 NAs only propagate partway through a broadcast domain.\u00a0 In practice, if I \u00a0 understand the architecture correctly, O=0 NAs will propagate to all CEs \u00a0 \"behind\" a given PE but, if anycast=false, no further. \u00a0 This could lead to a difficult to debug scenario (though I admit this is \u00a0 probably quite rare). \u00a0 Note that 4861-7.2.4 implies that most nodes sending NAs for their own \u00a0 addresses will adhere to \"the Override flag SHOULD be set to one\".\u00a0 This \u00a0 is not a MUST, though.\u00a0 Dropping all O=0 NAs might affect some \u00a0 implementations that don't comply with this SHOULD.\u00a0 I have no idea how \u00a0 many implementations this might affect (in practice, I suspect none?), but... \u00a0 I think it might need to be considered. [ section 3.1.1/3.2 ] * I was not able to understand what the typical disposition of the O bit \u00a0 is supposed to be in these proxied NAs.\u00a0 Is the intent to default to O=0 so \u00a0 that local O=1 can be preferred (vis. 4861-7.2.4 and 4389)?\u00a0 Or will it \u00a0 more typically be set to O=1 (as if just replaying the NA that was learned \u00a0 by another PE)? [ section 3.2 ] * Item (f) as currently written would break Enhanced DAD ( RFC 7527 ), \u00a0 would it not? [ section 3.6 ] * \"Duplicate IP Detection for IPv6 SHOULD be disabled when IPv6 \u00a0  'anycast' is activated in a given EVI.\" \u00a0 This doesn't seem like the right response to me.\u00a0 It should be okay to keep \u00a0 doing DAD for O=1 addresses regardless of the setting of this 'anycast' \u00a0 option, I would have thought. [ section 5.5 ] * I think that recommending Reply Sub-Functions discard NS packets of \u00a0 unexpected for means, in practice, no new NS option or flag can ever really \u00a0 be made to work.\u00a0 The PE(s) serving the CE(s) that make \"new NS\" \u00a0 solicitations will all need to be upgraded, and it's not immediately clear \u00a0 to me that remote PEs wouldn't also need to be upgraded (to support a \u00a0 possible \"new NA\"in response). \u00a0 If this is in fact likely to be the operational reality then I think this \u00a0 limitation probably needs to be noted explicitly.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-12-03 04:31:43-08:00",
    "end_reason": "position_updated",
    "start": "2019-11-30 08:20:53-08:00",
    "text": "Thank you for the work put into this document. The short document is easy to read even if I wonder whether it is useful to spend time on IPv4-only protocol ;-) The deployment issue (section 5) has raised a DISCUSS of mine and I would appreciate a reply on this DISCUSS. Regards, -\u00e9ric == DISCUSS == -- Section 5 -- The risk of having inconsistent view of the topology with H-bit aware and unaware routers seems possible to me (albeit perhaps only transient). Has this feature been tested / simulated in large scale networks?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-03-05 06:21:51-08:00",
    "end_reason": "position_updated",
    "start": "2019-01-23 11:52:31-08:00",
    "text": "s this is a BCP, I don't understand why transport encryption of the private key is not normatively required. Could you explain?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-01-23 20:57:42-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D13996 DETAIL S 2. >\u00a0   >\u00a0 \u00a0 \u00a0 Operators are free to use either the router-driven or operator-driven >\u00a0 \u00a0 \u00a0 method as supported by the platform.\u00a0 Regardless of the method >\u00a0 \u00a0 \u00a0 chosen, operators first establish a protected channel between the >\u00a0 \u00a0 \u00a0 management system and the router.\u00a0 How this protected channel is >\u00a0 \u00a0 \u00a0 established is router-specific and is beyond scope of this document. This seems rather under-specified. Given that we know that people are not careful about this, I think you need to specify some sort of minimum requirements for this channel. That need not be a particular protocol, but it needs to specify the security properties it provides. I see you have some SHOULD-level language later, but I think you need MUST level, and as noted below, I think the guidance is wrong. S 5.2. >\u00a0 \u00a0 \u00a0 the BGP Identifier when it sends the CSR to the CA. >\u00a0   >\u00a0 \u00a0 \u00a0 Even if the operator cannot extract the private key from the router, >\u00a0 \u00a0 \u00a0 this signature still provides a linkage between a private key and a >\u00a0 \u00a0 \u00a0 router.\u00a0 That is, the operator can verify the proof of possession >\u00a0 \u00a0 \u00a0 (POP), as required by [ RFC6484 ]. It's not clear to me what is being claimed in terms of PoP here. As I understand it, the certificate is a binding between the AS number/BGP identifier pair and the public key, but if neither of those is in the PKCS#10 request, then they're not signed over by the private key, and so PoP isn't really operative. The relevant question is whether if I obtain the PKCS#10 request I can obtain a certificate for an identity other than the intended one. S 5.2.1. >\u00a0 \u00a0 \u00a0 ensure the returned private key did in fact come from the operator, >\u00a0 \u00a0 \u00a0 but this requires that the operator also provision via the CLI or >\u00a0 \u00a0 \u00a0 include in the SignedData the RPKI CA certificate and relevant >\u00a0 \u00a0 \u00a0 operator's EE certificate(s).\u00a0 The router should inform the operator >\u00a0 \u00a0 \u00a0 whether or not the signature validates to a trust anchor; this >\u00a0 \u00a0 \u00a0 notification mechanism is out of scope. I don't understand what security this is intended to provide. As I understand it, the way this works is that the operator signs the PKCS#8 package and then sends it to the router, which verifies the signature. This verification is performed based on a key configured by the operator, right? But in that case, if someone obtains operator access to the router, they can just configure their own key, thus bypassing the signature check. Secondarily, I don't understand how this works if the RPKI CA certificate is included in the SignedData, because then how do I validate it against a trust anchor. Finally, how does the router know which of the large number of EEs signed by the RPKI CA it should accept signed PKCS#8 messages from. S 6. >\u00a0 \u00a0 \u00a0 private key it holds corresponds to the returned public key.\u00a0 If the >\u00a0 \u00a0 \u00a0 operator saved the PKCS#10 it can check this correspondence by >\u00a0 \u00a0 \u00a0 comparing the public key in the CSR to the public key in the returned >\u00a0 \u00a0 \u00a0 certificate.\u00a0 If the operator has not saved the PKCS#10, it can check >\u00a0 \u00a0 \u00a0 this correspondence by generating a signature on any data and then >\u00a0 \u00a0 \u00a0 verifying the signature using the returned certificate. It is not clear to me that this is correct. You seem to be assuming that it given a key pair (K_priv, K_pub), it is not possible to generate a new key K_pub' that will validate signatures made with K_priv. This isn't ordinarily an assumption we make of digital signature systems. S 8. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the CA prior to operator initiating the router's CSR.\u00a0 CAs use >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 authentication material to determine whether the router is >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 eligible to receive a certificate. Authentication material at a >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 minimum includes the router's AS number and BGP Identifier as >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 well as the router's key material, but can also include >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 additional information. Authentication material can be Surely it also includes some information that allows the router to prove it is entitled to a key with that AS and BGP identifier, but I'm not seeing this here. S 12.1. >\u00a0 \u00a0 \u00a0 CSR you sent; the certificate will include the subject name, serial >\u00a0 \u00a0 \u00a0 number, public key, and other fields as well as being signed by the >\u00a0 \u00a0 \u00a0 CA.\u00a0 After the CA issues the certificate, the CA returns the >\u00a0 \u00a0 \u00a0 certificate, and posts the certificate to the RPKI repository.\u00a0 Check >\u00a0 \u00a0 \u00a0 that the certificate corresponds to the private key by verifying the >\u00a0 \u00a0 \u00a0 signature on the CSR sent to the CA; this is just a check to make This is not the right check. The CSR contains the public key. If you want to check, make sure it is identical to the one in the cert.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-11-29 18:11:26-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-11-29 18:10:23-08:00",
    "text": "First, I'd like to say thanks for your work on this document. I find this work exciting, and hope to see it widely deployed in the short term. I do have one major concern that I believe rises to the level of a DISCUSS, although I believe it should be trivial to fix. The reason I believe it to be a barrier to publication is that it makes a broad architectural statement that has implications for all application protocols; which, beyond being outside the remit of the working group per its charter, I seriously doubt received the level of cross-area review appropriate for its scope. The statement of concern is in section 5.5.5: \u00a0  As is the case with NAT ALGs, protocol designers are advised to avoid \u00a0  communicating names and addresses in nonstandard locations, because \u00a0  those \"hidden\" names and addresses are at risk of not being \u00a0  translated when necessary, resulting in operational failures. I would expect this statement, if evaluated by the IETF community at large, to be extremely controversial: it implies application-layer protocol designs that provide neither confidentiality nor even integrity protection for protocol parameters. Architecturally, it's important to distinguish between NAT ALGs, which are not a party to the security context of the protocols they carry, and DNS discovery proxies, which are. This makes the guidance in here appropriate in the context of DNS-SD records, while being problematic in the broader NAT ALG case cited. I would find no problem with a narrowly-scoped statement that pertains to DNS usage in particular, although I wonder whether designers of DNS TXT record usage in the future are likely to become aware of such guidance.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-03-22 02:51:51-07:00",
    "end_reason": "position_updated",
    "start": "2017-11-29 18:11:26-08:00",
    "text": "First, I'd like to say thanks for your work on this document. I find this work exciting, and hope to see it widely deployed in the short term. I do have one major concern that I believe rises to the level of a DISCUSS, although I believe it should be trivial to fix. The reason I believe it to be a barrier to publication is that it makes a broad architectural statement that has implications for all application protocols; which, beyond being outside the remit of the working group per its charter, I seriously doubt received the level of cross-area review appropriate for its scope. The statement of concern is in section 5.5.5: \u00a0  As is the case with NAT ALGs, protocol designers are advised to avoid \u00a0  communicating names and addresses in nonstandard locations, because \u00a0  those \"hidden\" names and addresses are at risk of not being \u00a0  translated when necessary, resulting in operational failures. I would expect this statement, if evaluated by the IETF community at large, to be extremely controversial: it implies application-layer protocol designs that provide neither confidentiality nor integrity protection for protocol parameters. Architecturally, it's important to distinguish between NAT ALGs, which are not a party to the security context of the protocols they carry, and DNS discovery proxies, which are. This makes the guidance in here appropriate in the context of DNS-SD records, while being problematic in the broader NAT ALG case cited. I would find no problem with a narrowly-scoped statement that pertains to DNS usage in particular, although I wonder whether designers of DNS TXT record usage in the future are likely to become aware of such guidance.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-11-27 12:47:46-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-11-27 12:46:02-08:00",
    "text": "There are a number of places where the non-LDH names may be configured on a \"normal\" DNS server. An example of this is in Section 5.2.1.\u00a0 Domain Enumeration via Unicast Queries: \"db._dns-sd._udp.example.com.\u00a0  PTR\u00a0  Building  1.example.com .\" Putting this in a zonefile and trying to hand it to e.g BIND makes things sad: dns_rdata_fromtext:  example.com:18 : near ' 1.example.com .': extra input text zone  example.com/IN:  loading from master file  example.com  failed: extra input text zone  example.com/IN:  not loaded due to errors. Another example is in Section 5.3.\u00a0 Delegated Subdomain for LDH Host Names \"For example, a Discovery Proxy could have the two subdomains \"Building  1.example.com \" and \" bldg1.example.com \" delegated to it.\" I think that the document needs to do a better job of explaining that you cannot just include non-LDH in a zonefile without escaping -- Section 5.1. (Format) of  RFC1035  may be a good pointer.\u00a0 It may even be a good idea to repeat this (or at least mention the case) whenever there is an example\u00a0 - readers are likely to just cut and paste without reading the full document, leading to unexpected failures (and then gnashing of teeth on forums)",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2017-11-27 17:48:26-08:00",
    "end_reason": "position_updated",
    "start": "2017-11-27 12:47:46-08:00",
    "text": "This is (IMO) easily addressed -- I like the document, this DISCUSS is simply to improve it and help prevent foot-shooting. I'd be a YES or NoObj once addressed. There are a number of places where the non-LDH names may be configured on a \"normal\" DNS server. An example of this is in Section 5.2.1.\u00a0 Domain Enumeration via Unicast Queries: \"db._dns-sd._udp.example.com.\u00a0  PTR\u00a0  Building  1.example.com .\" Putting this in a zonefile and trying to hand it to e.g BIND makes things sad: dns_rdata_fromtext:  example.com:18 : near ' 1.example.com .': extra input text zone  example.com/IN:  loading from master file  example.com  failed: extra input text zone  example.com/IN:  not loaded due to errors. Another example is in Section 5.3.\u00a0 Delegated Subdomain for LDH Host Names \"For example, a Discovery Proxy could have the two subdomains \"Building  1.example.com \" and \" bldg1.example.com \" delegated to it.\" I think that the document needs to do a better job of explaining that you cannot just include non-LDH in a zonefile without escaping -- Section 5.1. (Format) of  RFC1035  may be a good pointer.\u00a0 It may even be a good idea to repeat this (or at least mention the case) whenever there is an example\u00a0 - readers are likely to just cut and paste without reading the full document, leading to unexpected failures (and then gnashing of teeth on forums)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-21 11:16:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-05 18:58:22-07:00",
    "text": "I have a concern about the MAX_PAYLOADS congestion-control parameter. In Section 7.2 it is stated that both endpoints only SHOULD have the same value.\u00a0 I don't see how this can be anything less than MUST, given that we attribute semantics to whether NUM modulo MAX_PAYLOADS is zero or non-zero in the processing of the Q-Block2 option.\u00a0 If the endpoints disagree on the value of MAX_PAYLOADS they will disagree on the semantics of Q-Block2 -- how can that be interoperable? (Being able to negotiate the value does not seem inherently problematic, but since it is relevant for protocol semantics it seems like the value must be identical on both endpoints.) This seems especially important to have clarity on given that the current specification allows for MAX_PAYLOADS to be decreased at runtime in response to congestion feedback over a 24-hour period, with no synchronization between peers provided (\"Note that the CoAP peer will not know about the MAX_PAYLOADS change until it is reconfigured\".)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-05-19 14:41:55-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-05 17:39:33-07:00",
    "text": "For the most part I found this document relatively easy to follow, considering my complete lack of background in CoAP. However, despite a concerted effort I have not been able to nail down with confidence what the intended semantics of several of your timeouts are, notably NON_RECEIVE_TIMEOUT. Some of the text (for example, \u00a74.4) implies that the timeout is an upper bound on how long an implementation should wait before declaring a block to have been lost (\u201cThe client SHOULD wait for up to NON_RECEIVE_TIMEOUT\u201d). At the very least, this is imprecise because the timeout increases exponentially with repeated timeouts \u2014 but this is a relatively minor matter, discussed further in my comments. Later, in \u00a77.2, you say that expiry of the timeout is not the only trigger for a 4.08 response: \u00a0  It is likely that the client will start transmitting the next set of \u00a0  MAX_PAYLOADS payloads before the server times out on waiting for the \u00a0  last of the previous MAX_PAYLOADS payloads.\u00a0 On receipt of the first \u00a0  payload from the new set of MAX_PAYLOADS payloads, the server SHOULD \u00a0  send a 4.08 (Request Entity Incomplete) Response Code indicating any \u00a0  missing payloads from any previous MAX_PAYLOADS payloads.  It makes sense to me that you use this additional trigger. At this point in my reading of the spec, my understanding of the retransmission algorithm was that a 4.08 should be sent when either a payload is received from a new set of MAX_PAYLOADS, or NON_RECEIVE_TIMEOUT expires. But then I got to the example in 10.2.3, which shows the client waiting for the expiration of NON_RECEIVE_TIMEOUT even though it has received the first of a new set of MAX_PAYLOADS, and I concluded that either I\u2019ve missed something basic, or the document is internally inconsistent. As an aside, I\u2019m also unclear as to why the only trigger you specify for sending a 4.08 is the arrival of the first of a new MAX_PAYLOADS flight. Other possible triggers I noticed include a gap in the sequence, and reception of a payload with More=0. Some of these issues are repeated in my comments, below \u2014 I\u2019ve noted those in the comment. Possibly in addressing this DISCUSS we\u2019ll clear up some of those comments too.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-05-21 09:16:30-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 14:41:55-07:00",
    "text": "I am raising my comment #11 to a DISCUSS. I notice that  RFC 7252  jitters its timers, for example: \u00a0 counter.\u00a0 For a new Confirmable message, the initial timeout is set \u00a0 to a random duration (often not an integral number of seconds) \u00a0 between ACK_TIMEOUT and (ACK_TIMEOUT * ACK_RANDOM_FACTOR) (see \u00a0 Section 4.8) \u2026 \u00a0 ACK_RANDOM_FACTOR MUST NOT be decreased below 1.0, and it SHOULD have \u00a0 a value that is sufficiently different from 1.0 to provide some \u00a0 protection from synchronization effects. MAX_TRANSMIT_SPAN and MAX_TRANSMIT_WAIT are similarly jittered. A number of your introduced parameters  \u00a0 This document introduces new parameters MAX_PAYLOADS, NON_TIMEOUT, \u00a0 NON_RECEIVE_TIMEOUT, NON_MAX_RETRANSMIT, NON_PROBING_WAIT, and \u00a0 NON_PARTIAL_TIMEOUT primarily for use with NON (Table 3). appear at least superficially similar to the timers the authors of  RFC 7252  deemed important to jitter to prevent synchronization effects. Did you specifically consider jittering them, and decide that jitter was unnecessary? If so, can you explain what is different about your specification, compared to the base spec, that eliminates the concern? -- Version 12 resolves the concerns in the DISCUSS point below; I am retaining it for posterity only: For the most part I found this document relatively easy to follow, considering my complete lack of background in CoAP. However, despite a concerted effort I have not been able to nail down with confidence what the intended semantics of several of your timeouts are, notably NON_RECEIVE_TIMEOUT. Some of the text (for example, \u00a74.4) implies that the timeout is an upper bound on how long an implementation should wait before declaring a block to have been lost (\u201cThe client SHOULD wait for up to NON_RECEIVE_TIMEOUT\u201d). At the very least, this is imprecise because the timeout increases exponentially with repeated timeouts \u2014 but this is a relatively minor matter, discussed further in my comments. Later, in \u00a77.2, you say that expiry of the timeout is not the only trigger for a 4.08 response: \u00a0  It is likely that the client will start transmitting the next set of \u00a0  MAX_PAYLOADS payloads before the server times out on waiting for the \u00a0  last of the previous MAX_PAYLOADS payloads.\u00a0 On receipt of the first \u00a0  payload from the new set of MAX_PAYLOADS payloads, the server SHOULD \u00a0  send a 4.08 (Request Entity Incomplete) Response Code indicating any \u00a0  missing payloads from any previous MAX_PAYLOADS payloads.  It makes sense to me that you use this additional trigger. At this point in my reading of the spec, my understanding of the retransmission algorithm was that a 4.08 should be sent when either a payload is received from a new set of MAX_PAYLOADS, or NON_RECEIVE_TIMEOUT expires. But then I got to the example in 10.2.3, which shows the client waiting for the expiration of NON_RECEIVE_TIMEOUT even though it has received the first of a new set of MAX_PAYLOADS, and I concluded that either I\u2019ve missed something basic, or the document is internally inconsistent. As an aside, I\u2019m also unclear as to why the only trigger you specify for sending a 4.08 is the arrival of the first of a new MAX_PAYLOADS flight. Other possible triggers I noticed include a gap in the sequence, and reception of a payload with More=0. Some of these issues are repeated in my comments, below \u2014 I\u2019ve noted those in the comment. Possibly in addressing this DISCUSS we\u2019ll clear up some of those comments too.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-07 05:50:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-05 00:59:46-07:00",
    "text": "The current CORE charter does not seem to cover the topic of this document. I also see no related milestone. Section 1, paragraph 4, discuss: >\u00a0 \u00a0 There is a requirement for these blocks of data to be transmitted at >\u00a0 \u00a0 higher rates under network conditions where there may be asymmetrical >\u00a0 \u00a0 transient packet loss (i.e., responses may get dropped).\u00a0 An example >\u00a0 \u00a0 is when a network is subject to a Distributed Denial of Service >\u00a0 \u00a0 (DDoS) attack and there is a need for DDoS mitigation agents relying >\u00a0 \u00a0 upon CoAP to communicate with each other (e.g., >\u00a0 \u00a0 [ RFC8782 ][ I-D.ietf-dots-telemetry ]).\u00a0 As a reminder, [ RFC7959 ] I understand that COAP was initially chosen to transport DOTS signaling messages due to their small size, support for structured messages and request/response semantics, as well as the ability to function over lossy paths such as found in IoT deployment, which COAP is architected for. DOTS now seems to desire to transport larger messages, and this document extends CORE to enable this functionality. However, this CORE extension seems to solely focus on Internet deployment scenarios, essentially attempting to re-architect COAP into a general Internet transport protocol for transmission over paths with high loss rates. I do not believe that the CORE WG is chartered to do this.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-18 00:49:26-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-07 05:50:25-07:00",
    "text": "[Updating this DISCUSS based on the discussion during the May 6 telechat.] Section 1, paragraph 4, discuss: >\u00a0 \u00a0 There is a requirement for these blocks of data to be transmitted at >\u00a0 \u00a0 higher rates under network conditions where there may be asymmetrical >\u00a0 \u00a0 transient packet loss (i.e., responses may get dropped).\u00a0 An example >\u00a0 \u00a0 is when a network is subject to a Distributed Denial of Service >\u00a0 \u00a0 (DDoS) attack and there is a need for DDoS mitigation agents relying >\u00a0 \u00a0 upon CoAP to communicate with each other (e.g., >\u00a0 \u00a0 [ RFC8782 ][ I-D.ietf-dots-telemetry ]).\u00a0 As a reminder, [ RFC7959 ] I understand that COAP was initially chosen to transport DOTS signaling messages due to their small size, support for structured messages and request/response semantics, as well as the ability to function over lossy paths such as found in IoT deployment, which COAP is architected for. DOTS now seems to desire to transport larger messages, and this document extends CORE to enable this functionality. However, this CORE extension seems to solely focus on Internet deployment scenarios, essentially attempting to re-architect COAP into a general Internet transport protocol for transmission over paths with high loss rates. It's questionable whether \"maintenance of  RFC7959 \" part of the current CORE charter covers this document. The motivation for this new extension is apparently that  RFC7959  doesn't result in sufficient performance for the DOTS use case, i.e., timely delivery of larger amounts of data during periods of high random loss (i.e., under DDoS). This is a fundamentally hard problem, because in order to deliver data in a timely manner in such scenarios, the sender needs to be very aggressive, to send enough packets into the network so that enough arrive at the receiver to make steady progress; and at the same time the feedback channel is also severely degraded due to loss. The IETF TSV area currently has hence no known good solution for such use cases. This specification possibly describes such a solution, but I was not able to find any evaluation results that would show that this proposed mechanism actually delivers the desired performance improvements over  RFC7959  in the scenarios of interest. I was also not able to find any evaluation results of whether the proposed mechanism is safe to use in situations that might be easily confused with DDoS, such as high-load scenarios that are not of malicious origin, or if it even is safe when executing over normal Internet paths. If such evaluation results exists, would you mind pointing me at them? Without evaluation results that demonstrate that the proposed mechanism is effective and safe, I do not believe it should be published on the Standards Track. It could go forward as an Experimental RFC, supporting an experiment to perform such an evaluation.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-05-05 09:00:54-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-29 16:23:32-07:00",
    "text": "I am concerned about the convergence of three different provisions in this spec: - In (4.1), it says \"To reliably get a rejection message, it is therefore \u00a0  REQUIRED that clients use a Confirmable message for determining \u00a0  support for Q-Block1 and Q-Block2 Options.\" IIUC this mandates that at least one request will use CON. - (7.1): all the blocks of a single body over an \u00a0  unreliable transport MUST either all be Confirmable or all be Non- \u00a0  confirmable. - (7.2) However, the other CON congestion \u00a0  control parameters will need to be tuned to cover this change.\u00a0 This \u00a0  tuning is out of scope of this document as it is expected that all \u00a0  requests and responses using Q-Block1 and Q-Block2 will be Non- \u00a0  confirmable (Section 3.2). I can't reconcile (4.1) with the last sentence in (7.2). Moreover, if my reading of (4.1) is correct, it's not sufficient to declare congestion control guidance out of scope when it's a mandated part of the protocol.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-07-26 07:42:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 13:32:03-07:00",
    "text": "# GEN AD review of  draft-ietf-add-ddr-08 CC @larseggert Thanks to Robert Sparks for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/mHeRXL46i0vY3KUKqmxW7l4ZP_k ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS for IANA, so we can determine next steps during the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-08 14:40:56-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 17:49:31-07:00",
    "text": "# SEC AD comments for { draft-ietf-add-ddr-08 } CC @paulwouters ## Discuss See my discuss on  draft-ietf-add-ddr-11  for my generic ADD DNR/DDR concerns ### \u00a0  Clients MUST NOT automatically use a Designated \u00a0  Resolver without some sort of validation Why not? What is the alternative? Using unencrypted DNS to the party that told you how and where to contact these (unvalidated) Designated Resolvers. ### \u00a0  However, if a given Unencrypted Resolver designates a Designated \u00a0  Resolver that does not use a private or local IP address and can be \u00a0  verified using the mechanism described in Section 4.2, it MAY be used \u00a0  on different network connections so long as the subsequent \u00a0  connections over other networks can also be successfully verified \u00a0  using the mechanism described in Section 4.2. This seems to go against a lot of advise in the documents that networks must be treated independently. Also, the network _wants_ you to use their designated resolver, so to say it is okay to use a totally different Designated Resolvers seems to violate the whole DNR/DDR architecture. This will also cause failure if there is split-DNS or internal-only data. Also, using \"public IP\" is not a good trustworthy method to prove that these IPs are truly the same Designated Resolver used by both networks. I can easily use an internal only zone with  dns.nohats.ca . IN A 8.8.8.8 and get a valid ACME'd certificate with SAN= dns.nohats.ca . The user connecting to another network might now be switching from my private DNS on my stolen 8.8.8.8 IP to the real google DNS. ### \u00a0 \u00a0 \u00a0 2.\u00a0 The client MUST verify that the certificate contains the IP \u00a0 \u00a0 \u00a0  address of the designating Unencrypted Resolver in a \u00a0 \u00a0 \u00a0  subjectAltName extension. How feasible is it to get a certificate with SAN=ip from one of the generally accepted root store CA's? Can you give me one example where I can get a certificate for  nssec.nohats.ca  with SAN=193.110.157.123 ?\u00a0 I do not think this is currently possible or easy. If I am right, that means all of Section 4.2 is wishful thinking and not realistic to get rolled out. (I know we can see the cert for 1.1.1.1, so it is possible, but I know of no ACME supported CA that issues these) ### \u00a0  If these checks fail, the client MUST NOT automatically use the \u00a0  discovered Designated Resolver. This creates a strange policy when compared to DNR where if you get a DHCP or RA for the Designated Resolver, which is also not validatable, that you do end up using it? And section 6.5 states DNR trumps DDR. ### \u00a0  If the Designated Resolver and the Unencrypted Resolver share an IP \u00a0  address, clients MAY choose to opportunistically use the Designated \u00a0  Resolver even without this certificate check (Section 4.3). Why only when the IP is the same? Why not for when the IP is different? What's to lose, since the only fallback option is stick to using the unencrypted resolver? ### \u00a0  If resolving the name of a Designated Resolver from an SVCB record \u00a0  yields an IP address that was not presented in the Additional Answers \u00a0  section or ipv4hint or ipv6hint fields of the original SVCB query, \u00a0  the connection made to that IP address MUST pass the same TLS \u00a0  certificate checks before being allowed to replace a previously known \u00a0  and validated IP address for the same Designated Resolver name. How does the appearance of an (unsigned) Additional Answer entry convey any kind of real world trust/authentication? In other words, why should it not ALWAYS pass the same TLS certificate checks ? ### Opportunistic Discovery has the same \"same IP\" issue. As the alternative is to use unencrypted DNS, why not just use it anyway? ### \u00a0  A DNS client that already knows the name of an Encrypted Resolver can \u00a0  use DDR to discover details about all supported encrypted DNS \u00a0  protocols. It's a little odd to mention this as the DNR draft really tries hard to say to only use the network's offered encrypted DNS servers, so this option is in conflict with the DNR draft. ### \u00a0  A DNS forwarder SHOULD NOT forward queries for \" resolver.arpa \" upstream. Unfortunately, all currently deployed software does not know this, so it will be very common that this happens. ## \u00a0  DNS resolvers that support DDR by responding to queries for \u00a0  _dns.resolver.arpa SHOULD treat  resolver.arpa  as a locally served \u00a0  zone per [ RFC6303 ] Why is this not a MUST ? ### \u00a0  To limit the impact of discovery \u00a0  queries being dropped either maliciously or unintentionally, clients \u00a0  can re-send their SVCB queries periodically. I don't see how this would improve security for the client. It also mixes up behaviour of proper DNS clients that have their own retransmit logic for if they get no answer. ### \u00a0  Section 8.2 of [ I-D.ietf-add-svcb-dns ] describes a second downgrade \u00a0  attack where an attacker can block connections to the encrypted DNS \u00a0  server, and recommends that clients prevent it by switching to SVCB- \u00a0  reliant behavior once SVCB resolution does succeed.\u00a0 For DDR, this \u00a0  means that once a client discovers a compatible Designated Resolver, \u00a0  it SHOULD NOT use unencrypted DNS until the SVCB record expires I wonder which attacker can block encrypted DNS connections but not spoof (or block!) an unsigned SVCB record to the local client? And even if that is the case, this would be a denial of service attack if the DNS client cannot fallback to unencrypted DNS. Spoofing an SVCB to a bogus IP with an SVCB TTL of a few hours would be a very cheap 1 packet attack to keep the DNS client down for hours. This seems dangerous to implement. ### \u00a0  DoH resolvers that allow discovery using DNS SVCB answers over \u00a0  unencrypted DNS MUST NOT provide differentiated behavior based on the \u00a0  HTTP path alone, since an attacker could modify the \"dohpath\" \u00a0  parameter.\u00a0 For example, if a DoH resolver provides provides a \u00a0  filtering service for one URI path, and a non-filtered service for \u00a0  another URI path, [...] It seems likely that this advise will get ignored a lot, eg by people who have limited public IPs to use to spin up a DoH server, or who have to pay-per-IP. This advise seems more appropriate for local private IP DoH servers. So I would change this MUST NOT to SHOULD NOT for that reason. ### \u00a0  If the IP address of a Designated Resolver differs from that of an \u00a0  Unencrypted Resolver, clients applying Verified Discovery \u00a0  (Section 4.2) MUST validate that the IP address of the Unencrypted \u00a0  Resolver is covered by the SubjectAlternativeName of the Designated \u00a0  Resolver's TLS certificate. How would one obtain such a certificate via ACME? Since on the IP of the unencrypted resolver, there would be no HTTP server running? Additionally, if the client notices a failed verification of the Designated Resolver's TLS certificate, wouldn't it fallback to the Unencrypted Resolver? But now it may not? So this becomes a denial of service then ? ### \u00a0  Clients using Opportunistic Discovery (Section 4.3) MUST be limited \u00a0  to cases where the Unencrypted Resolver and Designated Resolver have \u00a0  the same IP address. Based on earlier text, this should read \"the same non-public IP address\". ### I kind of miss the mode of where there is no indication of DDR or DNR, and you use \"unilateral probing\" ( draft-ietf-dprive-unilateral-probing ) to just connect to the DoT or DoQ ports of the Unencrypted Resolver and see if you get anything back. It might be unauthenticated TLS but better than port 53? ### \u00a0  This document calls for the addition of \" resolver.arpa \" to the \u00a0  Special-Use Domain Names (SUDN) registry established by [ RFC6761 ]. Why not pick resolver.local? As .local is already handled to not be forwarded by DNS forwarders. It would also not require an addition to SUDN. Even if someone was already using resolver.local, it would not interfere with that usage because that usage would not be using SVCB records. ## Comments ### section 3 \u00a0  To avoid name lookup deadlock, Designated Resolvers SHOULD follow the \u00a0  guidance in Section 10 of [ RFC8484 ] regarding the avoidance of DNS- \u00a0  based references that block the completion of the TLS handshake. I find that reference to list more the issues than solutions that can be followed. The solution to use another DoH server is not really appropriate in most cases The client's other interface likely resides on other networks where its private DoH server cannot resolve the name of another network's private DoH server. It is also not easy to get an IP based certificate (eg SAN=ip) that is accepted by general webpki root stores. And things like OCSP stapling doesn't help if the target is malicious - they just would omit the stapling that proves against its malicious use. The only real advise usable from  RFC8484  is \"use the local unencrypted resolver to resolve the encrypted resolver\". Might as well say that and remove the 8484 reference. ### I would argue that  I-D.ietf-add-dnr  is not an informative but normative reference, as the protocol is mentioned throughout the document as interacting with this protocol. ### \u00a0 \u00a0 \u00a0 Clients that support SVCB will generally send out three queries \u00a0 \u00a0 \u00a0 when accessing web content on a dual-stack network: A, AAAA, and \u00a0 \u00a0 \u00a0 HTTPS queries.\u00a0 Discovering a Designated Resolver as part of one \u00a0 \u00a0 \u00a0 of these queries, without having to add yet another query, \u00a0 \u00a0 \u00a0 minimizes the total number of queries clients send. I don't understand this paragraph. Once clients can send SVCB queries for web content, they already have had to do all the DDR/DNR related queries, so I don't understand the argument of \"saving queries\" ? Also, it is adding queries for a specific target, eg  resolver.arpa , and this cannot be \"saved\" either? What am I misunderstanding here? ### NITS provides provides -> provides",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-07-13 20:07:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-07-13 20:06:02-07:00",
    "text": "[ Apologies, I'm currently participating in the IEEE 802 Plenary meeting, and so was not able to perform as detailed (or timely!) review as normal ] Sec 8.1 - Special Use Domain Name \" resolver.arpa \" \"This document calls for the addition of \" resolver.arpa \" to the Special-Use Domain Names (SUDN) registry established by [ RFC6761 ].\" Unfortunately  RFC6761  Section 4 (Procedure) says: \"The specification MUST state how implementations determine that the special handling is required for any given name.\" and \"The specification also MUST state, in each of the seven \"Domain Name Reservation Considerations\" categories below, what special treatment, if any, is to be applied.\"  And  RFC6761  Section 5 (Domain Name Reservation Considerations) says: \"An IETF \"Standards Action\" or \"IESG Approval\" document specifying some new naming behaviour, which requires a Special-Use Domain Name be reserved to implement this desired new behaviour, needs to contain a subsection of the \"IANA Considerations\" section titled \"Domain Name Reservation Considerations\" giving answers in the seven categories listed below.\" (and lists the categories). I do not see a \"Domain Name Reservation Considerations\" section, nor answers to the 7 questions.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-07-13 21:24:30-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 20:07:07-07:00",
    "text": "[ Apologies, I'm currently participating in the IEEE 802 Plenary meeting, and so was not able to perform as detailed (or timely!) review as normal ] Sec 8.1 - Special Use Domain Name \" resolver.arpa \" \"This document calls for the addition of \" resolver.arpa \" to the Special-Use Domain Names (SUDN) registry established by [ RFC6761 ].\" Unfortunately  RFC6761  Section 4 (Procedure) says: \"The specification MUST state how implementations determine that the special handling is required for any given name.\" and \"The specification also MUST state, in each of the seven \"Domain Name Reservation Considerations\" categories below, what special treatment, if any, is to be applied.\"  And  RFC6761  Section 5 (Domain Name Reservation Considerations) says: \"An IETF \"Standards Action\" or \"IESG Approval\" document specifying some new naming behaviour, which requires a Special-Use Domain Name be reserved to implement this desired new behaviour, needs to contain a subsection of the \"IANA Considerations\" section titled \"Domain Name Reservation Considerations\" giving answers in the seven categories listed below.\" (and lists the categories). I do not see a \"Domain Name Reservation Considerations\" section, nor answers to the 7 questions. [ Apologies again for not being able to do a more in-depth review ]",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-08-11 18:02:19-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-10 16:59:27-07:00",
    "text": "[ section 4.1 ] * I don't quite understand this apparent reliance on IPv6 flows being routed or \u00a0 load-balanced by src/dst and flow label alone.\u00a0 I know of implementations \u00a0 where that is not the case at all, and in fact  RFC 6437  specifically advises \u00a0 that the flow label alone not be relied upon.\u00a0 Quoting section 2: \u00a0 o\u00a0 Forwarding nodes such as routers and load distributors MUST NOT \u00a0 \u00a0  depend only on Flow Label values being uniformly distributed.\u00a0 In \u00a0 \u00a0  any usage such as a hash key for load distribution, the Flow Label \u00a0 \u00a0  bits MUST be combined at least with bits from other sources within \u00a0 \u00a0  the packet, so as to produce a constant hash value for each flow \u00a0 \u00a0  and a suitable distribution of hash values across flows. \u00a0 \u00a0  Typically, the other fields used will be some or all components of \u00a0 \u00a0  the usual 5-tuple.\u00a0 In this way, load distribution will still \u00a0 \u00a0  occur even if the Flow Label values are poorly distributed. \u00a0 Perhaps I'm seriously misunderstanding something though... * In the bulleted list following the final paragraph, the IP identification \u00a0 field is an IPv4-only header field.\u00a0 What is the recommended mechanism for \u00a0 IPv6?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-08-20 07:59:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-11 09:09:58-07:00",
    "text": "I have 2 DISCUSS points. I think that both should be easy to address...  1: \"While most of the routers perform load balancing on flows using Equal Cost Multiple Path (ECMP), a few still divide the workload through packet-based techniques.\u00a0 The former scenario is defined according to [ RFC2991 ], while the latter generates a round-robin scheme to deliver every new outgoing packet.\u00a0 ECMP uses a hashing function to ensure that every packet of a flow is delivered by the same path, and this avoids increasing the packet delay variation and possibly producing overwhelming packet reordering in TCP flows.\" Round-robin / \"per packet\" is a form ECMP, and  RFC2991  doesn't \"define\" just the former, it explains both, and recommends the flow based /\u00a0 hashed approach.  RFC 2991  describes a number of approaches (e.g Modulo-N Hash, Hash-Threshold, Highest Random Weight (HRW)) and makes some good suggestions, but the text as written isn't correct. 2: \"In IPv6, it is sufficient to be routed identically if the IP source and destination addresses and the FlowLabel are constant, see [ RFC6437 ].\" Many routers currently ignore the FlowLabel and use other header info, like port-numbers. The sentence might(?) be true in an idealized network, but in the real world isn't. Some additional text should solve this...",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-18 12:07:41-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 13:17:57-08:00",
    "text": "== Section 2 == \"If this field is not present, \u00a0 \u00a0 \u00a0 then IID is derived from the layer-2 address of the sender as per \u00a0 \u00a0 \u00a0 SLAAC ({? RFC4662 }).\" RFC 8064  recommends that the default IID generation scheme for use with SLAAC is not to use the layer-2 address, but to use the mechanism specified in  RFC 7217 . Is there a reason this specification is making a different recommendation?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-02-25 09:02:29-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 15:12:01-08:00",
    "text": "I am balloting DISCUSS because the relationship between this document and RPL parent selection is not clear.\u00a0 I expect that the issues I point at will be easy to address, either by clarifying the text or my potential confusion. It is not clear to me what is the \"RPL status\" of an enrolled node.\u00a0 IOW, is an enrolled node to be considered one that has joined a DODAG already?\u00a0 This is then causing some confusion on how RPL parent selection and the new structure defined here are related.\u00a0 More details/questions below. (1) rank priority What is the relationship between the rank priority and parent selection as described in  rfc6550 ?\u00a0  The text says that \"it is to help enrolled devices only to compare different connection points\", but no details on the use are provided. The rank priority is described as \"an indication of how willing this 6LR is to serve as an RPL {? RFC6550 } parent\", which points directly at parent selection.\u00a0 The only mention (that I could find) in  rfc6550  of an indication of how \"willing to act as a parent\" a node may be shows up as a guideline when describing the DAO-ACK.\u00a0 The relative values (\"Lower values indicate more willing, and higher values indicate less willing.\") are aligned, but the size of the fields is different.\u00a0 How, if at all, are these values related? (2) What is the PANID?\u00a0 Is there a relationship with the DODAGID or the RPL Instance?\u00a0  (3) The text says that the pan priority \"typically is used by devices which have already enrolled...MAY consider this value when looking for an eligible parent device.\"\u00a0 As with the rank priority, there are no details about how a node may use this value during parent selection.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-28 06:11:18-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-16 09:55:46-08:00",
    "text": "** Section 2.\u00a0 Rank Priority and Pan Priority.\u00a0 Can you please clarify whether a higher or lower number indicated an increased priority: -- Rank priority says \u201cLower values are better\u201d -- What does \u201cbetter\u201d mean?\u00a0 Is a lower number more or less willing this 6LR is to serve as the RPL parent? -- Pan priority doesn\u2019t include guidance on whether a higher or lower number indicate increased priority. ** Section 2.\u00a0 network id.\u00a0 Can you please clarify the computation of the default value using SHA-256. The text initially says that network id is a \u201cvariable length field, up to 16 bytes in size\u201d.\u00a0 Later it says that \u201cthe network ID can be constructed from a SHA256 hash of the prefix (/64) of the network.\u00a0 That is just a suggestion for a default value.\u201d\u00a0 However, a SHA256 hash has a 256 bit output which can\u2019t fit into a 16 byte field size.\u00a0 Is there a truncation?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-02-21 08:34:13-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 14:10:40-08:00",
    "text": "[ Be ye not afraid - this should be easy to answer / address ] The Privacy Considerations says: \"The use of a network ID may reveal information about the network.\"  Good point - but it also goes on to say: \"The use of a SHA256 hash of the DODAGID, rather than using the DODAGID (which is usually derived from the LLN prefix) directly provides some privacy for the the addresses used within the network, as the DODAGID is usually the IPv6 address of the root of the RPL mesh.\" I don't know if this is an issue, but how much entropy is in a DODAGID? From what I could find, the DODAGID is often just an IP address - and subnets are not randomly distributed, nor are L2 addresses (inputs to address generation) - if I know that many of the nodes come from vendor_A, and I know their L2 / MAC range, can I enumerate this, and by extension the DODAGID, and so the hash? I will happily admit that I haven't fully researched this / thought it through, so \"Nah, won't work\" or \"Yes, will work, but we did say 'provides some privacy', not 'absolute privacy'\" or all acceptable answers :-)",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-10-16 06:02:56-07:00",
    "end_reason": "position_updated",
    "start": "2017-10-12 06:53:43-07:00",
    "text": "I've put in a DISCUSS because I think the point I raise below warrants further discussion, unless the WG already discussed it and concluded otherwise. Section 7 says: \"However, when combining both IPv6 privacy extensions and a unique \u00a0  IPv6 Prefix per Host a reduced privacy experience for the subscriber \u00a0  is introduced, because a prefix may be associated with a subscriber, \u00a0  even when the subscriber implemented IPv6 privacy extensions  RFC4941 \u00a0  [ RFC4941 ].\" If an operator assigns the same unique prefix to the same host every time the host connects to the network, the unlinkability benefits of using IPv6 privacy extensions are completely negated. It seems reasonable to me for this document to normatively RECOMMEND that operators assign a different unique prefix to a returning host for the purpose of limiting linkability to the lifetime of the host's connection to the network. I'm sure there are exception cases where this wouldn't make sense, and some examples of those could be given. But by default this seems to me like a reasonable recommendation to mitigate the privacy risk introduced by the unique prefix, while the attacks described in Section 1 would also still be mitigated. Did the WG discuss this?",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-09-13 10:39:40-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-16 15:54:08-07:00",
    "text": "* Section 4 It is not clear what you intend here \"IPv6 Router Advertisement Interval = 300s\" The router advertisement interval is not configured as an absolute value but as minimum and maximum bounds (MinRtrAdvInterval and MaxRtrAdvInterval) which are used to calculate the actual advertisement interval. When the RA is sent from an interface, the actual interval is an uniformly distributed random value between the MinRtrAdvInterval and MaxRtrAdvInterval. At the very minimum you need to clarify if you would like to have this as a lower bound or as an upper bound.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-19 20:52:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-09 18:47:58-07:00",
    "text": "This is a comparatively minor point, but I don't think some of the message layout is quite fully specified.\u00a0 In particular, Section 7.2 discusses some new TLVs (in a confusing way, referring to the class of two TLVs as a single nonexistent TLV) but does not always say which object the TLVs are allowed to appear within.\u00a0 (The first paragraph seems to talk of the TLV appearing in a PCRpt, which is a message and as such would contain only objects and not TLVs directly.)\u00a0 The second paragraph does mention the LSP object, which leads the reader to infer that this TLV is only intended to appear in the LSP object, and only in the PCRpt and PCUpd messages explicitly mentioned, but we probably shouldn't force readers to make that leap.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-12 05:30:58-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-10 07:29:52-07:00",
    "text": "The Security Considerations section has numerous helpful and appropriate references.\u00a0 Thanks for tracking them down.\u00a0 However, explicit, additional text is required to help identify, de-duplicate and deconflict the \u201crelevant guidance\u201d provided by them.\u00a0  (1) Per \u201cit is important that implementations conform to the relevant security requirements of [ RFC5440 ], [ RFC8306 ] and [ RFC8231 ], and [ RFC8281 ]\u201d: ** [ RFC8231 ] says \u201cRECOMMENDED that these PCEP extensions only be activated on authenticated and encrypted sessions across PCEs and PCCs belonging to the same administrative authority, using Transport Layer Security (TLS) [PCEPS], as per the recommendations and best current practices in [ RFC7525 ]\u201d.\u00a0 Good language.\u00a0 This draft again re-states \u201cSecuring the PCEP session using Transport Layer Security (TLS) [ RFC8253 ], as per the recommendations and best current practices in [ RFC7525 ], is RECOMMENDED.\u201d\u00a0 Why say that twice?\u00a0 Is there something new there? ** Per Section 10.4 of  RFC5440  from 2009, IPSec is a MAY and Section 10.2 makes TCP-MD5 a MUST.\u00a0 The more recent (2017)  RFC8306  and  RFC8253  reference TLS and TCP-AO, no IPSec.\u00a0  RFC8306  explicitly says don\u2019t use TCP-MD5.\u00a0 What is the RECOMMENDED approach today? (2) Per \u201c[s]ecuring the PCEP session using Transport Layer Security (TLS) [ RFC8253 ], as per the recommendations and best current practices in [ RFC7525 ], is RECOMMENDED\u201d, how should the guidance on both of these drafts be synthesized?\u00a0 Specifically, this sentence is unclear on whether the the robust TLS 1.2 requirements in Section 3.4 of  RFC8253  are RECOMMENDED, and/or whether the Security Considerations/Section 7 of  RFC8253 , which undermine these robust requirements by saying administrators MAY allow the usage weak ciphersuites, apply.\u00a0 This sentence also cites  RFC7525  which makes statements that weak (NULL) cipher suites MUST NOT be negotiated in contradiction to the  RFC8253  Section 7 guidance. Given the discussion of TLs, some additional treatment of TLS v1.3 is needed, recognizing that  RFC7525  does recommend \u201cv1.2+\u201d Again, there is helpful guidance across all of the references.\u00a0 Please provide more textually narrative about which specific sections apply on the references.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-12 12:37:13-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-25 13:46:16-07:00",
    "text": "draft-ietf-httpbis-semantics  seems to require that in order to merge a trailer field into the header section, the field definition both explicitly permits the merging action \"and defines how trailer field values can be safely merged.\"\u00a0 The discussion in \u00a72 of this document about preserving ordering of trailer values relative to other intermediaries seems to imply that trailer fields will be merged into the header section (otherwise how could there be an order?), but I do not see a specification for how to safely perform the merge operation.\u00a0 Can we have more clarity on the expected behavior in this case?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-09-04 09:47:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-02 02:19:44-07:00",
    "text": "Thank you for the hard work put into this\u00a0 document. Please note that I second Mirja's discuss about the 'copying' text. And, please find below an easy-to-fix DISCUSS and some COMMENTs. Regards, -\u00e9ric == DISCUSS == -- Abstract -- For a standard track document, I find it weird to write 'conventions' rather than specification. Easy to fix.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-09-04 01:38:46-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-28 04:02:23-07:00",
    "text": "Question to the IESG/responsible AD: I found this: \"Appendix A.\u00a0 Copying conditions \u00a0  Regarding this entire document or any portion of it, the authors make \u00a0  no guarantees and are not responsible for any damage resulting from \u00a0  its use.\u00a0 The authors grant irrevocable permission to anyone to use, \u00a0  modify, and distribute it in any way that does not diminish the \u00a0  rights of anyone else to use, modify, and distribute it, provided \u00a0  that redistributed derivative works do not contain misleading author \u00a0  or version information.\u00a0 Derivative works need not be licensed under \u00a0  similar terms.\" Does it make sense to have this in addition to the usual IETF terms? And/or why is this needed here?",
    "type": "Discuss"
  },
  {
    "ad": "Joel Jaeggli",
    "end": "2017-03-31 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2015-01-19 22:29:49-08:00",
    "text": "I'll quote stephen here, since he makes a point that I championed during the discussion. I would like to dicuss this. (3) The proxy injecting this header field means that the user cannot get any signal that this has been done and appendix C even says that the site should not allow the UA to unset the proxy's preference.\u00a0 This also encourages the use of plaintext. Other than saying \"yeah, that's what's done\" I don't believe that this problem was explored at all, never mind addressed. Injection of this value by proxies gets to the very heart of question of consent between two parties the requester and sender and that of the agency of the requestor. Encouraging transparent middle\u00a0 boxes to mess with the contents of flows is imho an irresponsible act on the part of the IETF. I\u00a0 could have definitely held my nose and pass this without comment were it to very strongly discourage that acceptance of such a hint over non-confidential non-tamper resistant\u00a0 channels.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-01-21 11:11:37-08:00",
    "end_reason": "position_updated",
    "start": "2015-01-19 16:50:55-08:00",
    "text": "Before I abstain on this I would like to briefly discuss the evaluation of rough consensus and check if a few points raised were addressed. I'll put those as discuss points, but plan to abstain once those are briefly covered as I think that this is something the IETF should not specify, never mind \"endorse\" as a proposed standard. I think it is something we would regret publishing, much as we would have regretted it had we produced an RFC for the (IMO quite similarly broken and damaging) do-not-track (DNT) flag. (1) While I am definitely in the camp who would prefer that we not specify this at all, and hence am a biased judge, I can't see that there was rough consensus for this, having just re-read the IETF LC mails. The write-up does clearly acknowledge that any consensus was very rough in the view of the sponsoring AD. Note that I'm not at all questioning Barry's intentions here, just his conclusion. In any case, my reading is that there were arguments not addressed (see below) and that it is just not credible that all this LC discussion results in no change at all in the draft, and it is basically not at all clear to me that what seems like a more or less 50:50 set of folks in each camp, (I didn't count though), with both \"camps\" making reasonable arguments for and against, can in this case constitute even a very rough consensus. So I'd like to chat about that with the IESG in case my biased opinion turns out to better map to the mail archive than Barry's AD evaluation of the last call. (2) I also don't believe the point I raised about the scope of this was ever addressed. Does emitting this apply to just the response to that request, or to the origin or to whatever the server thinks is correct or what? Having an undefined semantics and an undefined scope seems broken to me at least but the point was never addressed that I can see. (3) The proxy injecting this header field means that the user cannot get any signal that this has been done and appendix C even says that the site should not allow the UA to unset the proxy's preference.\u00a0 This also encourages the use of plaintext. Other than saying \"yeah, that's what's done\" I don't believe that this problem was explored at all, never mind addressed. (4) The point raised by Joe Hall of CDT that emitting this signals a higher probability that the site is dealing with a minor (and hence perhaps with a user more easily socially exploited) is I think valid and is not reflected in the draft nor much in the discussion.  While the author offered to add text, no change  occurred. (5) I don't see where the point raised by Christian Huitema was dealt with - that the IETF standardising this will likely lead to (in particular) governments who wish to censor content requiring conformance to RFC7xxx. I'm not sure that we have a good BCP telling us to not collude with such, but I don't believe that point was addressed in the LC. (Note: it's quite possible that I missed some things that were dealt with, or that there's scope for disagreement as to whether or not things were or were not addressed.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2015-01-22 09:22:35-08:00",
    "end_reason": "position_updated",
    "start": "2015-01-22 05:21:56-08:00",
    "text": "Sigh. The disposition of this is no longer clear so I  am re-instating my discuss. Before I abstain on this I would like to briefly discuss the evaluation of rough consensus and check if a few points raised were addressed. I'll put those as discuss points, but plan to abstain once those are briefly covered as I think that this is something the IETF should not specify, never mind \"endorse\" as a proposed standard. I think it is something we would regret publishing, much as we would have regretted it had we produced an RFC for the (IMO quite similarly broken and damaging) do-not-track (DNT) flag. (1) While I am definitely in the camp who would prefer that we not specify this at all, and hence am a biased judge, I can't see that there was rough consensus for this, having just re-read the IETF LC mails. The write-up does clearly acknowledge that any consensus was very rough in the view of the sponsoring AD. Note that I'm not at all questioning Barry's intentions here, just his conclusion. In any case, my reading is that there were arguments not addressed (see below) and that it is just not credible that all this LC discussion results in no change at all in the draft, and it is basically not at all clear to me that what seems like a more or less 50:50 set of folks in each camp, (I didn't count though), with both \"camps\" making reasonable arguments for and against, can in this case constitute even a very rough consensus. So I'd like to chat about that with the IESG in case my biased opinion turns out to better map to the mail archive than Barry's AD evaluation of the last call. (2) I also don't believe the point I raised about the scope of this was ever addressed. Does emitting this apply to just the response to that request, or to the origin or to whatever the server thinks is correct or what? Having an undefined semantics and an undefined scope seems broken to me at least but the point was never addressed that I can see. (3) The proxy injecting this header field means that the user cannot get any signal that this has been done and appendix C even says that the site should not allow the UA to unset the proxy's preference.\u00a0 This also encourages the use of plaintext. Other than saying \"yeah, that's what's done\" I don't believe that this problem was explored at all, never mind addressed. (4) The point raised by Joe Hall of CDT that emitting this signals a higher probability that the site is dealing with a minor (and hence perhaps with a user more easily socially exploited) is I think valid and is not reflected in the draft nor much in the discussion.  While the author offered to add text, no change  occurred. (5) I don't see where the point raised by Christian Huitema was dealt with - that the IETF standardising this will likely lead to (in particular) governments who wish to censor content requiring conformance to RFC7xxx. I'm not sure that we have a good BCP telling us to not collude with such, but I don't believe that point was addressed in the LC. (Note: it's quite possible that I missed some things that were dealt with, or that there's scope for disagreement as to whether or not things were or were not addressed.)",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2017-01-25 07:23:04-08:00",
    "end_reason": "position_updated",
    "start": "2016-11-02 18:45:15-07:00",
    "text": "This should be an easy one to fix (or else I'm missing stuff, which is quite possible) but if a fix is needed then it'd impact on interop... In 8.3, I think the ABNF conflicts with the E164Number definition in the certs draft which disallows \"#\" and \"*\" (if I understand the \"FROM\" clause in the ASN.1 module correctly).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2016-08-08 11:21:16-07:00",
    "end_reason": "position_updated",
    "start": "2016-07-06 18:52:44-07:00",
    "text": "Even though the IANA Considerations section was just updated (in version -10), I am putting in this DISCUSS because it is still incomplete/incorrect. 1. Guidance for managing the SubERR namespace should be included.\u00a0 Note that this document only specifies values for ERR 6, but guidance should be given to IANA for the other ERR values as well. 2. Section 6.2.1 (RBridge Channel Error Codes Subregistry) requests the creation of a new registry (\"RBridge Channel Error Codes\u201d), but that registry was already created by  RFC7178 .\u00a0 This document should then split the requests in two parts: assignment of the vales 6-8, and the change to the registration procedure.",
    "type": "Discuss"
  }
]