[
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-05 04:52:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-03 06:57:54-08:00",
    "text": "This is a tiny point, but I think it needs fixing for clarity: 5.2.\u00a0 The AlertMsg-Error Header Field \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 1*3DIGIT The text below makes it clear that the error-code is 3 digits: \u00a0  The ErrorValue contains a 3-digit error code indicating what was \u00a0  wrong with the alert in the request. What you have above allows for 1, 2 or 3 digits. I think you meant: \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 3DIGIT",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-10 04:14:31-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-05 04:52:20-08:00",
    "text": "(Updated, see the extra review comments) I have a few a tiny point, but I think they need fixing for clarity: 1)  5.2.\u00a0 The AlertMsg-Error Header Field \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 1*3DIGIT The text below makes it clear that the error-code is 3 digits: \u00a0  The ErrorValue contains a 3-digit error code indicating what was \u00a0  wrong with the alert in the request. What you have above allows for 1, 2 or 3 digits. I think you meant: \u00a0 \u00a0 \u00a0 error-code\u00a0 \u00a0 \u00a0  = 3DIGIT 2) As per Francesca's review: \"/=\" is illegal in ABNF, it should be \"=/\"",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-02-23 16:48:48-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-23 12:05:30-08:00",
    "text": "Thanks for this document.\u00a0 I have a very small ABNF issue I'd like to discuss, and which should be very easy to sort out one way or another: \u2014 Section 5.2 \u2014 \u00a0 \u00a0 \u00a0 ErrorValue\u00a0 \u00a0 \u00a0  =\u00a0 error-code \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *(SEMI error-params) \u2026 \u00a0  The ErrorValue contains a 3-digit error code indicating what was \u00a0  wrong with the alert in the request.\u00a0 This error code has a \u00a0  corresponding quoted error text string that is human readable.\u00a0 The \u00a0  text string is OPTIONAL, but RECOMMENDED for human readability, \u2026 \u00a0  Similar to how  RFC \u00a0  3261  specifies, there MUST NOT be more than one string per error \u00a0  code. Two things about this: 1. The ABNF makes the text string optional only by allowing zero or more of them (so zero is allowed). 2. The ABNF allows multiple text strings, but the text says that there MUST NOT be more than one. So, shouldn\u2019t the ABNF be this (and if not, why not)?: NEW \u00a0 \u00a0 \u00a0 ErrorValue\u00a0 \u00a0 \u00a0  =\u00a0 error-code [SEMI error-params] END (Also, and not part of the DISCUSS, \u201cSimilar to how  RFC 3261  specifies,\u201d is not good English; maybe, \u201cSimilar to the specification in  RFC 3261 ,\u201d or \u201cAs similarly specified in  RFC 3261 ,\u201d.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-10 10:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 17:16:30-08:00",
    "text": "I support Roman's Discuss (and comment) and will expound on his first point some more. The use of URIs to refer to remote content, potentially hosted on a third party, has numerous security considerations, some better known than others.\u00a0 We need to reference the security considerations of  RFC 3986  to get some coverage of these, such as the \"reliability and consistency\" point. One of the more subtle security considerations of using a URI to a remote resource as part of a request in cases such as this, is that the binding between the identity of the entity referring to the remote URI and the identity of the site providing the corresponding resource (i.e., the authority compoent of the URI) is not always clear.\u00a0 Although  RFC 7852  requires TLS mutual authentication and HTTPS transport for information provided by reference, it makes no statement requiring the TLS server certificate to correspond to the SIP initiator, or any other indication of authorization that the indicated resource makes sense as part of the indicated request. I also have two other Discuss-level points: We discuss the use of timestamps in protocol elements for detecting replay; this requires that all participants have (secure and) accurate time.\u00a0 We need to document this dependency on accurate time, and optionally point out that common internet time protocols such as NTP are not particularly secure at present. I'm also not sure where there's existing treatment of using SIP MESSAGEs as a DoS attack vector; that seems particularly pronounced in the emergency-services case since emergency messages may receive preferential treatment from the network.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-10 11:02:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 13:35:36-08:00",
    "text": "Section 9.\u00a0 Since CAPs can be included by reference (via URI) and the senders may be unknown to the ESRP/PSAP, please include language on the security considerations for untrusted URIs per Section 7 of  RFC3986 Section 9.\u00a0 Per \u201cTo provide protection of the entire SIP message exchange between neighboring SIP entities, the usage of TLS is REQUIRED.\u201d, can you please provide guidance on how to use TLS.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-30 17:05:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 08:01:48-07:00",
    "text": "Probably an easy thing to fix, I see an identity defined as \"rcs-rfc8724\". Using RFC numbers as names can be confusing if such and RFC is obsoleted for another RFC. Couldn't this entry be called \"rcs-crc32\" ?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-10-06 05:52:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 04:44:33-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I would like to discuss whether it is possible/appropriate to add an instance data example (as per my comment 1 below) to this document, or if that is inappropriate or unhelpful for some reason.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-29 14:47:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-24 11:21:07-07:00",
    "text": "** Section 8. An attacker by changing a rule content may block the \u00a0  communication or intercept the traffic.\u00a0  ... The full tree is sensitive, since it represents all the elements that \u00a0  can be managed.\u00a0 This module aims to be encapsulated into a YANG \u00a0  module including access control and identities. Thanks for calling out the entire tree as \u201csensitive.\u201d\u00a0 Please be more specific.\u00a0 There is mention of write sensitivity (i.e., re-writing the rules).\u00a0 Please also discuss any issues with reading the tree. Consider following the template of  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines  to distinguish between write and read access.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-28 06:26:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-29 14:47:29-07:00",
    "text": "** Section 8. An attacker by changing a rule content may block the \u00a0  communication or intercept the traffic.\u00a0  ... The full tree is sensitive, since it represents all the elements that \u00a0  can be managed.\u00a0 This module aims to be encapsulated into a YANG \u00a0  module including access control and identities. [ballot for -15 text] Thanks for calling out the entire tree as \u201csensitive.\u201d\u00a0 Please be more specific.\u00a0 There is mention of write sensitivity (i.e., re-writing the rules).\u00a0 Please also discuss any issues with reading the tree. Consider following the template of  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines  to distinguish between write and read access. [ballot for -17 text] Thanks for the additional words about write sensitivity.\u00a0 What is the impact of an attacker reading the module?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-09-10 06:23:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-08 08:08:49-07:00",
    "text": "I like to thank the TSV-ART reviewer for helping me consider one aspect of the issue I see needing some discussion for this document. This relates to Section 4.2.2.2. and 4.2.2.3.  So both of these section discuss the use of the sequence number for removing packet duplicates and handling reorder. As the text discusses there can be a configured limit for how deep the buffer and state are for performing these operations. We all know that the implementation of this will have a practical limit in both buffer space for reordering as well as state for tracking which sequence numbers that have been forwarded. I think that should be more clearly expressed in the document that these practical limits exists. Thus, the implementations will have tracking and determination of what are new packets (increasing sequence number within a window higher than previous largest seen. And consider sequence number form currently highest seen and a bit backwards as older packets. Thus how this is implemented will impact how this acts in cases of disruptions of the packet flow. Thus, I wonder if there is actually need to be\u00a0 a bit more specific in how classification should be done. Especially if the wrap-around of the sequence number space approaches a small multiple of round trip times for the path which is likely for the 16-bit space.  Then\u00a0 sections fails to discuss how the duplication removal, the reordering buffering and bound latency interacts and affet each other.\u00a0 So if the latency is bounded then the reordering has an hard time limit for the maximum delay. If there is a boundary for reordering then there are no point in de-duplicating packets that will not be forwarded due to the reordering. And even if there are no bounded latency the reordering buffer size will still impact the depth of de-duplication. These practical limits will also be limitations on the guarantees that can be provided.  Thus, from my perspective there is need for more text on the requirements of the implementation of these functions and their interactions of creating limitations.  Another point on 4.2.2.2: When configured, the \u00a0  implementation MUST track the sequence number contained in received \u00a0  d-CWs and MUST ensure that duplicate (replicated) instances of a \u00a0  particular sequence number are discarded. That second MUST I think is possible to meet given that one discard all packets outside of the current window where one have information if a packet sequence number have been forwarded or not. Given that a very late packet beyond the amount of state for the flow likely anyway have little utility that is likely the right choice. However, I think it needs to be made explicit that this is okay.  In Section 4.2.2.3:  When configured, the \u00a0  implementation MUST track the sequence number contained in received \u00a0  d-CWs and MUST ensure that packets are processed in the order \u00a0  indicated in the received d-CW sequence number field, which may not \u00a0  be in the order the packets are received.  I think this part needs to be explicit that packets that are to fare out of order for the implementation to handle will/shall be dropped. \u00a0  Note that an implementation MAY wish to constrain the maximum number \u00a0  of out of order packets that can be processed, on platform-wide or \u00a0  per flow basis.\u00a0 Some implementations MAY support the provisioning of \u00a0  this number on either a platform-wide or per flow basis.\u00a0 The number \u00a0  of out of order packets that can be processed also impacts the \u00a0  latency of a flow. If there exists a latency requirement then that will interact with this when it comes to reordering. In fact a significant issue here is that if the packet flow is not periodic at a steady pace the maximum latency in the reordering buffers based on packet sequence numbers can not be ensured. Instead some form of time limit needs to exist also. If that time limit is only local then there exists a risk that over multiple reordering buffers if multiple independent service labels are used the jitter and latency becomes cumulative. If the goal is to avoid this then the individual packets would need to carry a time stamp to ensure that from ingress of the service label path until the egress a maximum latency is added.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-10-12 01:41:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-10 06:23:38-07:00",
    "text": "I like to thank\u00a0 TSV-ART reviewer Michael T\u00fcxen for helping me consider one aspect of the issue I see needing some discussion for this document. Updated and extended discuss to clarify the issues I see. Please note that D below is new and a consequence in my trying to clarify C. why it matters.  A. The need for latency bounding the POF to enable the MPLS S-Label path to be bounded if reordering protection service is needed. To my understanding in an MPLS network the controller can determine an upper bound of the latency for a path by adding together the path latencies, the packet buffer depths based on the forwarding behavior applied, and the POF buffer depth. However, as currently described it is not made clear that the POF needs to have a configuration for an upper bound of how long a packet may maximum remain in the buffer since arrival. This requirement is somewhat discussed in  So  https://datatracker.ietf.org/doc/draft-ietf-detnet-data-plane-framework/: 3.5.2.2.\u00a0 Path Differential Delay \u00a0  In the preceding example, proper working of duplicate elimination and \u00a0  reordering of packets are dependent on the number of out-of-order \u00a0  packets that can be buffered and the delay difference of arriving \u00a0  packets.\u00a0 DetNet uses flow-specific requirements (e.g., maximum \u00a0  number of out-of-order packets, maximum latency of the flow) for \u00a0  configuration of POF-related buffers.\u00a0 If the differential delay \u00a0  between paths is excessively large or there is excessive mis-ordering \u00a0  of the packets, then packets may be dropped instead of being \u00a0  reordered.\u00a0 Likewise, PEF uses the sequence number to identify \u00a0  duplicate packets, and large differential delays combined with high \u00a0  numbers of packets may exceed the ability of the PEF to work \u00a0  properly. So this configuration needs to be required on the MPLS POF implementation to enable the controller to bound the latency between ingress and egress when POF is used. And it needs to be done in time, per the below paragraph. So given that the buffer is specified in either bytes or simply packets to be buffered will result in that the POF buffering time becomes packet flow dependent and not bounded in time. So if you make the calculation for a DETNET flow thinking it will send 500 packets per second evenly spaced. Then the a buffer of 5 packets would represent an upper limit 1/100th of second. If then the flow sends only 100 packet per second then suddendly the 5-packet buffering would represent 1/20th of a second. Thus defining it in packets or size doesn't work, the upper buffering time needs to be defined in time to provide a bounded latency.  I would note that soley configuring an upper bound between arrival in POF buffer until latest release is more fragile than actually having actual timestamp applied at egress to each packet. But, it can ensure bounded delay as long as the other functions do keep to their boundary.  However, I think the solution here is to clarify the configuration requirement on the POF in Section 4.2.2.3. B. On the relation of the PEF to the POF.  The document does not discuss this, and maybe this is fairly obvious but a relation ship exists. The PEF state needs to be deeper than the POFs when both are used. Otherwise duplicates may be forwarded. If the PEF is at least as deep as the POF, then any duplicate that is more out of order than what the POF allows will be discarded. However, as the POF is not that explicitly specified, even if the information document do define that is what should be done.  I would recommend that the text is made more clear on this relationship and also are explicit about the discard of out of order in the POF.  C. On the implementation details of the PEF and POF in regards to how they accept packets.  So the PEF is likely implemented with a basic data structure which tracks the N latest received packets and keep state if these packets have been seen or not. However, an important implementation detail for this is how this handles when a packet received are significantly higher than previous seen. So does that result in that highest seen are advanced forward to this value? So the 16-bit and 28-bit sequence numbers define a circular space. I assume one tracks the highest sequence number received (H_SN). Based on that one usually consider packets in the range [(H_SN-2^15) MOD 2^16, HSN-1] as older packets not updating the H_SN (for 16-bit sequence numbers) and can consider packets in the range [H_SN+1, H_SN + 2^15-1] as newer. However as N (number of actually tracked packets) are only a sub-set of the fully sequence number the PEF will consider a packet that falls into the range of older packets but outside of the N packets where one have state as to old, and will discard as one lack information about if it is a duplicate or not.  As you may seen this implementation would cause packet loss in the event that packets for this S-Label has passed the ingress and the PRF have put in sequence number and duplicating them and then the packet have been lost due to failure in forwarding the traffic. Then when the network have recovered from this failure there are a significant risk that the packets are outside of the window of validity that would trigger the H_SN to be updated and instead cause all packets to be dropped.  Thus in case of failures there appear to exist a need to be able to reset this state and require the sequence number that is current. And if the details of how these filters are impelementation specific and do not use the ranges I specify the controller would have to potentially cause a reset of the functions for any disturbance as the impact is unknown.  Maybe this is a minor risk in this environment, but the need to reset the POF and PEF state appears necessary for recovery.  D. Denial of service risk with attacker modifying sequence number or performing packet injection between ingress and egrees. Based on what is written in C I would also note that there exist a serious Denial of Service attack on the Detnet flow. If the attacker is capable of either periodically modify the sequence number of an MPLS packet for a particular S-label or inject a MPLS packet into the system that will traverse to the S-Labels PEF or POF at egress with a crafted sequence number. In either of these cases the attacker can advance the acceptance window periodically so that the actual traffic falls into the range that is discarded by the PEF and POF. Thus, cheaply accomplishing a total denial of service. I think this risk due to the PEF and POF should be made explicit in the security considerations. Mitigations needs to be in place to prevent packet modification or injection inside the MPLS network. Some of these appears to be already discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-10 05:56:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-10 03:06:55-07:00",
    "text": "Hi, Thank you for this document. Hopefully a trivial discuss to resolve ... 4.2.1.\u00a0 DetNet Control Word and the DetNet Sequence Number Does this section need to specify the initial value for the sequence number for a new flow? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-12 08:33:54-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-08 11:10:47-07:00",
    "text": "** (Discuss-discuss) Section 6.\u00a0 Per \u201cTo prevent DetNet packets from being delayed by an entity external to a DetNet domain, DetNet technology definition can allow for the mitigation of MiTM attacks, for example through the use of authentication and authorization of devices within the DetNet domain\u201d, can this attack scenario or the appropriate mitigation be clarified.\u00a0 If packets are coming from or going across the DetNet boundary how can any assurances be made?\u00a0 What is architecture element is the \u201cMiTM\u201d (relay? transit? per Figure 2)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-01 20:55:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 19:29:32-07:00",
    "text": "I support Roman's discusses and am happy to see the ongoing discussion thereof. (1) I think there's a conflict between this document and  RFC 8762  with respect to the behavior of pure  RFC 8762  implementations that receive packets longer than the base packet for the given operational mode. RFC 8762  says (Section 4.3): % The Session-Reflector receives the STAMP-Test packet and verifies it. If % the base STAMP-Test packet is validated, the Session-Reflector that % supports this specification prepares and transmits the reflected test % packet symmetric to the packet received from the Session-Sender copying % the content beyond the size of the base STAMP packet (see Section 4.2). But Section 4 of this document says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  A Session-Reflector \u00a0  that does not support STAMP extensions is not expected to compare the \u00a0  value in the Length field of the UDP header and the length of the \u00a0  STAMP base packet.\u00a0 Hence the Session-Reflector will transmit the \u00a0  base STAMP packet.\u00a0 [...] Does \"will transmit the base STAMP packet\" mean something other than \"with the exact length of the base packet [for the given operational mode]\"? (2) As I remarked on (then-)  draft-ietf-ippm-stamp , I think we need to require some level of cryptographic protection whenever control information is included in a Session-Sender's test packet.\u00a0 That is, that a Session-Reflector MUST NOT act on control information received in unauthenticated packets, and specifically, that the HMAC TLV must be used, since the base authenticated STAMP packet's HMAC does not cover the options. (3) The secdir reviewer's question about dealing with 6-to-4 gateways seems to have not gotten a response.\u00a0 Specifically, the requirement that \"[t]he Session-Reflector MUST validate the Length value against the address family of the transport encapsulating the STAMP test packet\" seems to require the protocol to fail when sender and reflector use different address families, or perhaps to require the sender to use trial and error to determine which address family is used by the reflector.\u00a0 Some clarification on the intended operation in such scenarios seems appropriate. (4) The ability for a Session-Sender to (MUST-level!) control the DSCP codepoint used by packets generated by a Session-Reflector feels like it opens up significant risk in site-local (security-relevant) policy.\u00a0 That is, the interpretation of the DSCP codepoints is to large extent site-specific, and allowing a nominally external system to set any/all possible values, without a chance for site policy to be applied and block the use of potentially disruptive DSCP values.\u00a0 So I think we need to modify the \"MUST set\", perhaps requiring that either the requested DSCP value is used or the entire TLV/packet/whatever is rejected. (5) If we're not going to remedy the severability of authenticated options from authenticated base packets (which would be my preferred resolution), we need to document that weakness in the security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-15 17:46:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-01 20:55:05-07:00",
    "text": "Thanks for all the updates; we've made good progress. I think we're still not converged on the DSCP handling, though.\u00a0 I have a bit more exposition in the COMMENT section, but in short, my understanding is that we're setting up a session-reflector to incur unbounded levels of risk with hard protocol requirements.\u00a0 I think we need to provide a way to bound that risk, for example by allowing the Session-Reflector to selectively choose to treat the CoS TLV as unimplemented (set the U flag in its reflected packet) or some other mechanism for local policy to filter what DSCP codepoints are set in reflected packets (ideally, indicating that the policy made a change). Also, there's a bit of fallout from the flags reworking that's left to cleanup in Section 4: we now have the Session-Sender set the U flag to 1, so this text no longer makes sense: % A STAMP system, i.e., either a Session-Sender or a Session-Reflector, % that has received a STAMP test packet with extension TLVs MUST % validate each TLV: % %\u00a0 \u00a0 If the U flag is set, the STAMP system MUST skip the processing of %\u00a0 \u00a0 the TLV. I think it should just apply to the Session-Sender for this case -- the Session-Reflector doesn't need to check the received U flag, since the Session-Sender will not be generating TLVs it does not understand. (Whether or not to keep the behavior for the M and I flags as applying to both Session-Sender and Session-Reflector vs. just Session-Sender does not immediately seem to be of much consequence.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-08-13 17:13:24-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-13 23:25:17-07:00",
    "text": "[ general ] * Please clarify whether the Length is in network byte order or not for all \u00a0 multibyte fields.\u00a0 A single statement, perhaps around 2.0 or something, \u00a0 declaring the convention would suffice (assuming all multibyte integers \u00a0 share the same encoding). * Should there be an IANA registry for the access ID field as well? [ sections 4.2,4.3 ] * I think the L-bit error case guidance may not conform to the guidance \u00a0 in section 4(.0)?\u00a0 Specifically, 4(.0) says if the Length field is funky \u00a0 the copy the rest of the packet into the reponse and set L=1 (yes?). \u00a0 Whereas, 4.2,3 says it MUST zero out the fields (rather than just copy \u00a0 the remainder of the packet).\u00a0 I may have misunderstood something, \u00a0 though.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-08-05 07:09:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-13 10:08:19-07:00",
    "text": "Section 4 says: \"Detected error events MUST be logged.\u00a0 Note that rate of logging MUST be controlled.\" This seems to be incomplete.\u00a0 Why is it a MUST?\u00a0 It doesn't seem to have anything to do with interoperability; if I don't log, nothing breaks.\u00a0 If it's MUST for security reasons, other questions arise: Logged where?\u00a0 What data specifically needs to be logged?\u00a0 How long should they be retained?\u00a0 Do any privacy concerns arise?\u00a0 Do the logs need to be protected at rest? etc.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-08-21 13:50:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-13 10:12:37-07:00",
    "text": "** Section 4.2.\u00a0 The Location TLV is explicitly trying to extract network configuration information that would be elided by the first hop router (MAC) or a NAT (real IP address).\u00a0  RFC8762  helpfully notes that \u201cWhen using STAMP over the Internet \u2026 impact of the STAMP-Test packets MUST be thoroughly analyzed.\u201d\u00a0 Please provide a bit of text describing the privacy implications here (or bound this with an applicability statement). ** Section 4.8.\u00a0 Is the key used for the HMAC TLV the same as the one in the HMAC in the STAMP authenticated packet?\u00a0 Could one use different keys?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:07:14-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-06 11:55:15-08:00",
    "text": "Section 8: Are there plans for the IETF community to develop the guidelines mentioned? I'm wary of publishing an RFC that says the IETF should do something if there are in fact no plans for the IETF to do the thing. RFCs are not necessarily good motivators. Overall this is an interesting document, but it seems to be written in an overly casual way and assumes readers have a lot of context that is not included in the document itself. The Gen-ART review pointed out a number of bits of text that left this impression. It was posted in October and never responded to. I've picked out some bits of the review and added a few more of my own -- collectively addressing these would get the document into publishable shape for a wider audience I think.  General:\u00a0 (1) On first use, please add citations for all the protocols mentioned in the document, as well as a few words to describe what each protocol does. For IETF readers, this will help them understand the implications of various 802 specifications without having to go look them up right away. (2) The IETF meeting network may be interesting as an example to contemplate, but to make this document broadly valuable it would be better to generalize the problem descriptions than to focus on the IETF meeting network. Section 3.1.4 seems a little thin to this non-expert. It is certainly true that \"every station has to be configured to wake up to receive the multicast\", but it seems like only a poorly designed protocol would create the situation where \"the received packet may ultimately be discarded\" on any kind of regular basis. If there are a class of packets that the receiver will ultimately discard, that sounds like they should be on a separate multicast address, or the sender should be determining if the packet will be discarded before sending it. Perhaps what this section is driving at is that multicast protocols are often designed without taking power-saving considerations into account, but then *that's* what this section should probably talk about. As it is, it sounds like the old joke about saying to the doctor, \"My arm hurts when I do this\" and the doctor replying, \"The stop doing that\". In section 3.2.1, the last paragraph is missing a bunch of information: \"It's often the first service that operators drop\": What is \"it\"? \"Multicast snooping\" is not defined. In what scenario are devices \"registering\"? Section 5.1: \"...and sometimes the daemons just seem to stop, requiring a restart of the daemon and causing disruption.\" What a strange thing to say. Does this simply mean \"and the current implementations are buggy\"? Also section 5.1: \"The distribution of users on wireless networks / subnets changes from one IETF meeting to the next\". This document doesn't seem to be about the IETF meeting network. This sentence seems inappropriately specific. The \"NAT\" and \"Stateful firewalls\" sections are also overly specific to the IETF meeting network. Generalizing would help. Section 8: The first paragraph has too little useful comment. There is no reference for 802.1ak, the reference to 802.1Q is inline instead of in the references section, and the content of neither of these standards is explained in this document. The paragraph doesn't really lay out what the topic of discussion is, at least for someone like myself who is not versed in the topic.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-18 18:45:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-01-08 14:19:36-08:00",
    "text": "Section 9 says that \"[ RFC4601 ], for instance, mandates the use of IPsec to ensure authentication of the link-local messages in the Protocol Independent Multicast - Sparse Mode (PIM-SM) routing protocol\" but I could not find where such use of IPsec was mandated.\u00a0 (I do recognize that a similar statement appears almost verbatim in  RFC 5796 , but  RFC 5796  seems focused on extending PIM-SM to support ESP in additon to the AH usage that was the main focus of the  RFC 4601  descriptions, and does not help clarify the  RFC 4601  requirements for me.)\u00a0 The closest I found was in Section 6.3.1 of  RFC 4601 : \"The network administrator defines an SA and SPI that are to be used to authenticate all link-local PIM protocol messages (Hello, Join/Prune, and Assert) on each link in a PIM domain\" but I do not think that applies to all usage of PIM-SM.\u00a0 Am I missing something obvious?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-28 18:50:52-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-18 18:45:30-07:00",
    "text": "Many thanks for all the updates from -11 to -14; the preponderance are good and improve the document. I especially appreciate the change in section 9 to claim only that the use of IPsec is specified, rather than mandated, by the referenced document.\u00a0 Unfortunately, the reference document was changed as well, from  RFC 4601  to  RFC 7761 , but  RFC 7761  calls out as one of the changes from  RFC 4601  that \"authentication using IPsec\" was removed.\u00a0 So the current claim in the -14, that \"[ RFC7761 ] [...] specifies the use of IPsec to ensure authentication of the link-local messages in [PIM-SM]\" is not correct, though for a different reason than what I noted in my ballot position on the -11.\u00a0 It may be most expedient to just restore the reference to the obsolete document, though of course there are other possibilities.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-02-05 11:50:50-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-07 09:54:57-08:00",
    "text": "** Section 9.\u00a0 Section 7 appears to recommend using an ARP sponge per Section 5.1.\u00a0 Please provide some general caution about ARP poisoning/false advertising that could undermine (DoS) this approach (that is being deployed to save battery power).",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-07-24 10:02:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 23:42:39-07:00",
    "text": "Hi, Thanks for the work on this document. While I am supporting the other discusses on this document, I would also like to discuss some of the language in section 8. Specifically:  In order to mitigate the performance-related attacks described above, \u00a0  as described in Section 7 it should be possible for IOAM-enabled \u00a0  devices to selectively apply the mechanisms that use the flags \u00a0  defined in this document to a subset of the traffic, and to limit the \u00a0  performance of synthetically generated packets to a configurable \u00a0  rate.\u00a0 Specifically, IOAM nodes should be able to: Considering the serious security considerations in play here - can we consider making the should here a MUST in both the second and final lines of the above.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-22 00:22:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 22:42:01-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-ioam-flags-09 CC @evyncke Thank you for the work put into this document.  Please find below some blocking DISCUSS points (easy to address as it is about clarifications), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Thanks to Pascal Thubert for his internet directorate review at: https://datatracker.ietf.org/doc/review-ietf-ippm-ioam-flags-09-intdir-telechat-thubert-2022-06-28/  (please consider Pascal's comments as mine). Special thanks to Tommy Pauly for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 4.2 which address `The address of the node performing the copy operation` is confusing in the case of multiple interfaces (typical for a transit device BTW)... Which address should be used ? If the packet was received through an interface with a global address, then this should be the obvious choice or a loopback interface or ??? ### Section 4.2 just truncation ? ``` \u00a0  The copy is also truncated, i.e., any payload that \u00a0  resides after the IOAM option(s) is removed before transmitting the \u00a0  looped back packet back towards the encapsulating node. ``` It is unclear what happens to the IPv6 Next header field... Should the IP header length field be modified ? ### Section 4.2 forwarding ? It is unclear whether the packet is sent back to the source via the received interface or whether the packet is forwarded based on the FIB. ### IANA considerations conflicting text ? In section 4.1: ``` \u00a0  An IOAM trace option that has the Loopback flag set MUST have the \u00a0  value '1' in the most significant bit of IOAM-Trace-Type, and '0' in \u00a0  the rest of the bits of IOAM-Trace-Type.  ``` but in section 6: ``` \u00a0  IANA is requested to allocate the following bits in the \"IOAM Trace \u00a0  Flags Registry\" as follows: \u00a0  Bit 1\u00a0 \"Loopback\" (L-bit) \u00a0  Bit 2\u00a0 \"Active\" (A-bit) \u00a0  Note that bit 0 is the most significant bit in the Flags Registry. ``` Is it bit 0 or bit 1 ?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-18 12:08:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 10:40:25-07:00",
    "text": "Thanks for this document. I have one issue I'd like to be sure we clear up. 1. In \u00a74.1.1, \u00a0  The loopback flag MUST NOT be set if it is not guaranteed that there \u00a0  is a return path from each of the IOAM transit and IOAM decapsulating \u00a0  nodes,  \u00a0   This is heartwarming but I can\u2019t see how you could guarantee this property at all times in any network using dynamic routing or even subject to dynamic conditions (and that would be all networks), and for that matter I\u2019m not sure how to write code to even determine this in any general way. Is it your intention that this MUST NOT is directed to the operator and not to the code implementor? Or perhaps is it for very small values of \u201cguarantee\u201d? That is, is this an aspirational MUST and not a MUST MUST? In general it's a little problematic when we use  RFC 2119  keywords in a protocol document, to express desires about how a protocol's operator should deploy it. They are at their best when used to express requirements for how a coder should implement the protocol. Please consider creating an operational considerations section, and grouping operational requirements and advice there, at least in that case it becomes clear to whom the  RFC 2119  keywords are speaking.  Alternately, please qualify the keywords appropriately in-line, e.g. in the above text you could say something like \u00a0  The domain MUST be configured such that there is expected to be a return \u00a0  path from each of the IOAM transit and IOAM decapsulating nodes; if this \u00a0  expectation does not apply then configuration MUST NOT enable the loopback \u00a0  flag to be set, \u00a0   To me it seems as though it might be less painful to group these into an operational considerations section, but whatever works for you, as long as it's clear. I did a cursory check over the document with this in mind, the other place I identified what looks like operational guidance to me is also in \u00a74.1.1, the paragraph about how you \"SHOULD NOT exceed 1/N of the interface capacity\". At first blush that looks like something that could be computed automatically by inspection of the router's hardware, but by the time we get to the end of the paragraph we see that \"prior knowledge about the network topology or size\" is needed, so it must really be operational guidance. (Possibly this applies to the 1/N paragraphs in \u00a74.2 and \u00a75 also, although it's less clearly the case.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-07-14 20:31:51-07:00",
    "text": "It seems that we accumulated some factual errors by letting this draft sit mostly idle since 2018, as the world evolved around us.\u00a0 Hopefully these are easy to remedy... Section 3.4.1.2 claims to have a list of options that have been specified as Hop-by-Hop options, and Section 3.4.6.2 a list of options that have been specified as Destination Options, each respectively \"at the time of this writing\".\u00a0 IANA has a single registry for both Destination and Hop-by-Hop options, and assessing which ones are defined as Hop-by-Hop vs Destinationmay require following each reference, but it seems that the PDM option from  RFC 8250  has been allocated and is in neither list, and the early allocations for IOAM and Path MTU Record may need to be considered as well.\u00a0 I suppose that we do attempt to go into the individual optiosn in detail in Section 4.3, so perhaps this is not quite so simple to remedy after all. (Note: while it is not the preferred outcome, merely changing the statement from \"time of this writing\" and \"so far been specified\" to \"as of 2018\" ought to be sufficient to resolve the discuss, as would Lars' suggestion of just referring to the IANA registry without incorporating the registry contents.) Section 3.4.8.1 refers to HIP as an \"experimental protocol\", but as of RFC 7401 , HIP is on the standards track. Also, there seems to be some skew between Table 1 and Section 3.4.10.5 regarding the recommended filtering policy for the experimental/testing EH types (drop vs [no recommendation])",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-16 12:26:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-07-13 06:23:29-07:00",
    "text": "Can the principled approach to making these recommendations be more clearly explained and documented?\u00a0 Section 3 primarily establishes a two-option filtering regime (drop vs. permit), but Section 4 seems to provide more nuance with a three-option filtering regime which considers the needs of the network (drop vs. drop if functionality not needed vs. permit).\u00a0 As an aside, a fourth filtering action of removing the options is presented in Section 4.3.9.4.\u00a0 Additionally, see the comment below which has a summary table for recommendations in Section 4 analogous to Table 1 of Section 3 to allow side-by-side comparisons. Was the three-option filtering regime considered for all recommendations?\u00a0 For example, Section 4.3.7.5 , Router Alert (Type=0x05) recommends permitting this option \u201cin environments where support for RSVP, multicast routing, or similar protocols is desired.\u201d (i.e., \u201cdrop if functionality is not needed\u201d).\u00a0 However, Section 3.4.8, HIP (Protocol Number=139) recommend categorically permitted these packets. If an operator knows that HIP is not a technology they have a desire to use in an environment, why shouldn\u2019t they block it (just like was suggested for Router Alerts)? Consideration for conditional discard based on local needs seems appropriate for Shim6, Mobility Header, HIP, ILNP Nonce, Tunnel Encapsulation, and all RPL options if the goal is to minimize traffic which has to go on the slow path. I read in the shepherd\u2019s write-up that trade-offs were made to minimize ossification.\u00a0 However, that rationale is not apparent in the text.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-06-16 14:37:12-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-16 12:26:46-07:00",
    "text": "Can the principled approach to making these recommendations be more clearly explained and documented?\u00a0 Section 3 primarily establishes a two-option filtering regime (drop vs. permit), but Section 4 seems to provide more nuance with a three-option filtering regime which considers the needs of the network (drop vs. drop if functionality not needed vs. permit).\u00a0 As an aside, a fourth filtering action of removing the options is presented in Section 4.3.9.4.\u00a0 Additionally, see the comment below which has a summary table for recommendations in Section 4 analogous to Table 1 of Section 3 to allow side-by-side comparisons. Was the three-option filtering regime considered for all recommendations?\u00a0 For example, Section 4.3.7.5 , Router Alert (Type=0x05) recommends permitting this option \u201cin environments where support for RSVP, multicast routing, or similar protocols is desired.\u201d (i.e., \u201cdrop if functionality is not needed\u201d).\u00a0 However, Section 3.4.8, HIP (Protocol Number=139) recommend categorically permitted these packets. If an operator knows that HIP is not a technology they have a desire to use in an environment, why shouldn\u2019t they block it (just like was suggested for Router Alerts)? Consideration for conditional discard based on local needs seems appropriate for Shim6, Mobility Header, HIP, ILNP Nonce, Tunnel Encapsulation, and all RPL options if the goal is to minimize traffic which has to go on the slow path. I read in the shepherd\u2019s write-up that trade-offs were made to minimize ossification.\u00a0 However, that rationale is not apparent in the text. See also the text from Ben Kaduk's DISCUSSes which I am taking on.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-30 10:29:55-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-29 16:01:17-07:00",
    "text": "Not so much an objection, but a question: What would happen if, in response to a DHCPDISCOVER with the IPv6-only offer, an attacker spoofed a DHCPOFFER with this option and a V6ONLY_WAIT value of UINT32_MAX, when in fact there was no NAT64, or v6 capability, at all? Would the very long timeout amplify existing DoS attacks on DHCP?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-10-26 13:23:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-10-26 13:23:11-07:00",
    "text": "### Clarity about scope of the document As I understand it, this document isn't intended to be an implementable protocol specification on its own; rather, \"specification details for these different echo request/reply protocols are outside the scope of this document\". I'm not crazy about this approach, but if it's to be followed there are some changes needed. Below I provide some suggested text -- please know that I'm just supplying this as a straw man to illustrate my thinking; while you're welcome to use the text I've provided, I don't necessarily expect that. The Abstract says that \"This document describes an extension to the echo request/reply mechanisms\". It does not. Here's an example of how it might be changed to be clearer. OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including Segment Routing with IPv6 data \u00a0  plane (SRv6)), MPLS (including Segment Routing with MPLS data plane \u00a0  (SR-MPLS)), Service Function Chain (SFC) and Bit Index Explicit \u00a0  Replication (BIER) environments, which can be used within the In situ \u00a0  Operations, Administration, and Maintenance (IOAM) domain, allowing \u00a0  the IOAM encapsulating node to discover the enabled IOAM capabilities \u00a0  of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  There is a need to extend echo request/reply mechanisms used in IPv6 \u00a0  (including Segment Routing with IPv6 data plane (SRv6)), MPLS \u00a0  (including Segment Routing with MPLS data plane (SR-MPLS)), Service \u00a0  Function Chain (SFC) and Bit Index Explicit Replication (BIER) \u00a0  environments, for use within the In situ Operations, Administration, \u00a0  and Maintenance (IOAM) domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. \u00a0  Although this document does not itself specify the necessary \u00a0  extensions, it specifies formats and objects that can be used in such \u00a0  specifications, and provides guidelines and requirements for their \u00a0  development. I think the Introduction also needs to be cleaned up. Saying that \"specification details... are outside the scope\" undersells the scope of what's needed. For example, maybe these changes would work in the Introduction: OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including SRv6), MPLS (including SR-MPLS), \u00a0  SFC and BIER environments, which can be used within the IOAM domain, \u00a0  allowing the IOAM encapsulating node to discover the enabled IOAM \u00a0  capabilities of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  This document specifies formats and objects that can be used in the \u00a0  extension of echo request/reply mechanisms used in IPv6 (including \u00a0  SRv6), MPLS (including SR-MPLS), SFC and BIER environments, which can \u00a0  be used within the IOAM domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. OLD: \u00a0  Note that specification details for these different echo request/ \u00a0  reply protocols are outside the scope of this document.\u00a0 It is \u00a0  expected that each such protocol extension would be specified by an \u00a0  RFC and jointly designed by the working group that develops or \u00a0  maintains the echo request/reply protocol and the IETF IP Performance \u00a0  Measurement (IPPM) Working Group. NEW: \u00a0  It is expected that the specification of the instantiation of each of \u00a0  these extensions will be done in the form of an RFC jointly designed \u00a0  by the working group that develops or maintains the echo \u00a0  request/reply protocol and the IETF IP Performance Measurement (IPPM) \u00a0  Working Group. \u00a0   ### Clarity of formats Because this document is specifying things (or trying to) in absence of any concrete instantiation, it's very difficult for me to evaluate if the formats as specified are complete and unambiguous. For now I've left my detailed discussion of this in my COMMENT section, and am optimistic that we can sort it out. However, I'm putting a placeholder here in case that problem turns out to be thornier than hoped.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-10-26 13:25:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-10-26 13:23:56-07:00",
    "text": "### Clarity about scope of the document As I understand it, this document isn't intended to be an implementable protocol specification on its own; rather, \"specification details for these different echo request/reply protocols are outside the scope of this document\". If this approach is to be followed there are some changes needed. Below I provide some suggested text -- please know that I'm just supplying this as a straw man to illustrate my thinking; while you're welcome to use the text I've provided, I don't necessarily expect that. The Abstract says that \"This document describes an extension to the echo request/reply mechanisms\". It does not. Here's an example of how it might be changed to be clearer. OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including Segment Routing with IPv6 data \u00a0  plane (SRv6)), MPLS (including Segment Routing with MPLS data plane \u00a0  (SR-MPLS)), Service Function Chain (SFC) and Bit Index Explicit \u00a0  Replication (BIER) environments, which can be used within the In situ \u00a0  Operations, Administration, and Maintenance (IOAM) domain, allowing \u00a0  the IOAM encapsulating node to discover the enabled IOAM capabilities \u00a0  of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  There is a need to extend echo request/reply mechanisms used in IPv6 \u00a0  (including Segment Routing with IPv6 data plane (SRv6)), MPLS \u00a0  (including Segment Routing with MPLS data plane (SR-MPLS)), Service \u00a0  Function Chain (SFC) and Bit Index Explicit Replication (BIER) \u00a0  environments, for use within the In situ Operations, Administration, \u00a0  and Maintenance (IOAM) domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. \u00a0  Although this document does not itself specify the necessary \u00a0  extensions, it specifies formats and objects that can be used in such \u00a0  specifications, and provides guidelines and requirements for their \u00a0  development. I think the Introduction also needs to be cleaned up. Saying that \"specification details... are outside the scope\" undersells the scope of what's needed. For example, maybe these changes would work in the Introduction: OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including SRv6), MPLS (including SR-MPLS), \u00a0  SFC and BIER environments, which can be used within the IOAM domain, \u00a0  allowing the IOAM encapsulating node to discover the enabled IOAM \u00a0  capabilities of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  This document specifies formats and objects that can be used in the \u00a0  extension of echo request/reply mechanisms used in IPv6 (including \u00a0  SRv6), MPLS (including SR-MPLS), SFC and BIER environments, which can \u00a0  be used within the IOAM domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. OLD: \u00a0  Note that specification details for these different echo request/ \u00a0  reply protocols are outside the scope of this document.\u00a0 It is \u00a0  expected that each such protocol extension would be specified by an \u00a0  RFC and jointly designed by the working group that develops or \u00a0  maintains the echo request/reply protocol and the IETF IP Performance \u00a0  Measurement (IPPM) Working Group. NEW: \u00a0  It is expected that the specification of the instantiation of each of \u00a0  these extensions will be done in the form of an RFC jointly designed \u00a0  by the working group that develops or maintains the echo \u00a0  request/reply protocol and the IETF IP Performance Measurement (IPPM) \u00a0  Working Group. \u00a0   ### Clarity of formats Because this document is specifying things (or trying to) in absence of any concrete instantiation, it's very difficult for me to evaluate if the formats as specified are complete and unambiguous. For now I've left my detailed discussion of this in my COMMENT section, and am optimistic that we can sort it out. However, I'm putting a placeholder here in case that problem turns out to be thornier than hoped.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-21 13:44:06-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 13:25:26-07:00",
    "text": "### Clarity about scope of the document As I understand it, this document isn't intended to be an implementable protocol specification on its own; rather, \"specification details for these different echo request/reply protocols are outside the scope of this document\". If this approach is to be followed there are some changes needed. Below I provide some suggested text -- please know that I'm just supplying this as a straw man to illustrate my thinking; while you're welcome to use the text I've provided, I don't necessarily expect that. The Abstract says that \"This document describes an extension to the echo request/reply mechanisms\". It does not. Here's an example of how it might be changed to be clearer. OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including Segment Routing with IPv6 data \u00a0  plane (SRv6)), MPLS (including Segment Routing with MPLS data plane \u00a0  (SR-MPLS)), Service Function Chain (SFC) and Bit Index Explicit \u00a0  Replication (BIER) environments, which can be used within the In situ \u00a0  Operations, Administration, and Maintenance (IOAM) domain, allowing \u00a0  the IOAM encapsulating node to discover the enabled IOAM capabilities \u00a0  of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  There is a need to extend echo request/reply mechanisms used in IPv6 \u00a0  (including Segment Routing with IPv6 data plane (SRv6)), MPLS \u00a0  (including Segment Routing with MPLS data plane (SR-MPLS)), Service \u00a0  Function Chain (SFC) and Bit Index Explicit Replication (BIER) \u00a0  environments, for use within the In situ Operations, Administration, \u00a0  and Maintenance (IOAM) domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. \u00a0  Although this document does not itself specify the necessary \u00a0  extensions, it specifies formats and objects that can be used in such \u00a0  specifications, and provides guidelines and requirements for their \u00a0  development. I think the Introduction also needs to be cleaned up. Saying that \"specification details... are outside the scope\" undersells the scope of what's needed. For example, maybe these changes would work in the Introduction: OLD: \u00a0  This document describes an extension to the echo request/reply \u00a0  mechanisms used in IPv6 (including SRv6), MPLS (including SR-MPLS), \u00a0  SFC and BIER environments, which can be used within the IOAM domain, \u00a0  allowing the IOAM encapsulating node to discover the enabled IOAM \u00a0  capabilities of each IOAM transit and IOAM decapsulating node. NEW: \u00a0  This document specifies formats and objects that can be used in the \u00a0  extension of echo request/reply mechanisms used in IPv6 (including \u00a0  SRv6), MPLS (including SR-MPLS), SFC and BIER environments, which can \u00a0  be used within the IOAM domain, allowing the IOAM encapsulating node \u00a0  to discover the enabled IOAM capabilities of each IOAM transit and \u00a0  IOAM decapsulating node. OLD: \u00a0  Note that specification details for these different echo request/ \u00a0  reply protocols are outside the scope of this document.\u00a0 It is \u00a0  expected that each such protocol extension would be specified by an \u00a0  RFC and jointly designed by the working group that develops or \u00a0  maintains the echo request/reply protocol and the IETF IP Performance \u00a0  Measurement (IPPM) Working Group. NEW: \u00a0  It is expected that the specification of the instantiation of each of \u00a0  these extensions will be done in the form of an RFC jointly designed \u00a0  by the working group that develops or maintains the echo \u00a0  request/reply protocol and the IETF IP Performance Measurement (IPPM) \u00a0  Working Group. \u00a0   ### Clarity of formats Because this document is specifying things (or trying to) in absence of any concrete instantiation, it's difficult for me to evaluate if the formats as specified are complete and unambiguous. For now I've left my detailed discussion of this in my COMMENT section, and am optimistic that we can sort it out. However, I'm putting a placeholder here in case that problem turns out to be thornier than hoped.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-11-06 23:21:56-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-27 00:22:33-07:00",
    "text": "Hi, I support Roman and Warren's discuss, and again, I have a similar, but slightly separate concern: (1) p 14, sec 6.\u00a0 Security Considerations \u00a0  To protect against unauthorized sources using echo request messages \u00a0  to obtain IOAM Capabilities information, it is RECOMMENDED that \u00a0  implementations provide a means of checking the source addresses of \u00a0  echo request messages against an access list before accepting the \u00a0  message. I'm concerned that performing a source address filtering isn't necessarily that secure, compared with use NETCONF or RESTCONF that can provide AAA access controls.\u00a0 Hence, I think that the security considerations should REQUIRE that IOAM daemons do not respond to these capability requests unless explicitly configured to do so, specifically to avoid implementations potentially leaking information if they are not aware of this functionality (e.g., if it was enabled by default).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-11-07 01:52:59-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-25 19:20:58-07:00",
    "text": "Section 6. \u00a0  A deployment can increase security by using border filtering of \u00a0  incoming and outgoing echo requests/replies. Thanks for calling out the security impact of echo request/replies.\u00a0 Since the cited  RFC9197  reminds the reader that a \u201cnetwork operator is expected to enforce policies that prevent IOAM traffic from leaking outside of the IOAM-Domain\u201d, why is this guidance not mandatory? Would the following text be more appropriate? NEW A deployment MUST ensure that border filtering drops inbound echo requests with a IOAM Capabilities Container Header from outside of the domain, and drops outbound echo request/replies with IOAM Capabilities Headers leaving the domain.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-10-27 06:46:17-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 13:14:55-07:00",
    "text": "Thank you very much for writing this document. Please see:  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ My concerns are closely related to Roman's DISCUSS point: The document says: \"A deployment can increase security by using border filtering of incoming and outgoing echo requests/replies.\" I'm unclear why this is just a \"can increase security\", and not something much much stronger -- but, also, I'm unclear how exactly an operator would be expected to filter these. The Abstract says: \"This document describes an extension to the echo request/reply mechanisms used in [...]\", but from what I can tell, it is more \"here are some containers that you could use in some other protocols\". It seems like, instead of only relying on the network for filtering (which doesn't yet seem to be implemented), the: \"To protect against unauthorized sources using echo request messages to obtain IOAM Capabilities information, it is RECOMMENDED that implementations provide a means of checking the source addresses of echo request messages against an access list before accepting the message.\" should be made stronger. Implementations need to be created to understand IOAM, and so requiring that they have the capability to only accept configured source addresses seems simple.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-03-15 00:39:44-07:00",
    "end_reason": "position_updated",
    "start": "2023-01-31 01:01:47-08:00",
    "text": "# GEN AD review of  draft-ietf-mls-protocol-17 CC @larseggert ## Discuss ### Section 17.1, paragraph 11 ``` \u00a0 \u00a0  *\u00a0 Recommended: Whether support for this ciphersuite is recommended \u00a0 \u00a0 \u00a0 \u00a0 by the IETF MLS WG.\u00a0 Valid values are \"Y\", \"N\", and \"D\", as \u00a0 \u00a0 \u00a0 \u00a0 described below.\u00a0 The default value of the \"Recommended\" column is \u00a0 \u00a0 \u00a0 \u00a0 \"N\".\u00a0 Setting the Recommended item to \"Y\" or \"D\", or changing a \u00a0 \u00a0 \u00a0 \u00a0 item whose current value is \"Y\" or \"D\", requires Standards Action \u00a0 \u00a0 \u00a0 \u00a0 [ RFC8126 ]. ``` The IETF MLS WG may (should) close at some future point. I think the text should talk about the IETF recommending a ciphersuite, not the MLS WG. ### Unclear RFC status Intended RFC status in datatracker is \"Proposed Standard\", but document says \"Informational\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-04 10:14:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-03 18:16:27-08:00",
    "text": "[This is a preliminary Discuss placed before a full document review is complete, to give the authors additional time to consider and respond] The YANG doctor last call review of the -06 notes that these modules are in violation of the expectations of  RFC 8349  (at least w.r.t. defining a new identity for the control-plane protocol and probably also w.r.t. augmenting the \"control-plane-protocol\" under \"/routing\").\u00a0 This document should either be brought into compliance or explain why it diverges. The YANG doctor's comments about the default values for the \"local\" graceful-restart configuration causing the global configuration to never take effect also should be addressed. The YANG doctor also noted that the \"md5-key\" leaf does not specify its semantics, and is presumably sensitive (so that a crypto-type would be more appropriate).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 13:55:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-04 10:14:30-08:00",
    "text": "The YANG doctor last call review of the -06 notes that these modules are in violation of the expectations of  RFC 8349  (at least w.r.t. defining a new identity for the control-plane protocol and possibly more).\u00a0 This document should either be brought into compliance or explain why it diverges. The YANG doctor's comments about default values for \"local\" configuration (e.g., graceful-restart configuration) causing the global configuration to never take effect should also be addressed. Please include some justification for why LDP IPv6 is considered an \"extended feature\" (which is particularly surprising given that Section 2 classifies \"IP\" to refer to both IPv4 and IPv6 together). We need to define the format/semantics of the md5-key string (e.g., is it hex? base64{url,}?) either directly or by reference (as the YANG doctor notes).\u00a0 Using a crypto-type would probably be appropriate, as would adding a note that tcp-md5 is obsoleted by TCP-AO. In the peer-af-policy-container grouping's label-policy/advertise/prefix-list, we need to say if the filter is for inclusion or exclusion of outgoing label advertisements. Similarly for the incoming label advertisements in the 'accept' container (and most of the -list-ref usages?). In the policy-container grouping's label-policy/assign/independent-mode/prefix-list, the description suggests that the contents will provide not just a list of prefixes that act as a filter, but also a map from prefix to label.\u00a0 This is a qualitatively different usage than the previous occurrences of prefix-list-ref, and it seems like a different type may be needed for it.\u00a0 Similarly for ordered-mode. (pro-forma) This document has 6 authors, and per  RFC 7322 , as this is more than five, we are supposed to consider whether that's appropriate. Seeing nothing in the shepherd writeup or similar, I mention it here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 09:14:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-17 13:55:47-07:00",
    "text": "[updating Discuss to reflect points addressed by the -08; COMMENT unchanged from -07] Please include some justification for why LDP IPv6 is considered an \"extended feature\" (which is particularly surprising given that Section 2 classifies \"IP\" to refer to both IPv4 and IPv6 together). We need to define the format/semantics of the md5-key string (e.g., is it hex? base64{url,}?) either directly or by reference (as the YANG doctor notes).\u00a0 Using a crypto-type in the base model as opposed to only as an extension would probably be appropriate, as would adding a note that tcp-md5 is obsoleted by TCP-AO.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-03-23 01:31:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-18 04:02:44-07:00",
    "text": "Thank you for addressing my previous comments (especially around the IPv6 support). But, I am now balloting a DISCUSS because  I-D.ietf-rtgwg-policy-model \u00a0 MUST be a normative reference as it is referenced by the YANG modules of this document. I.e., this document cannot be published _BEFORE_  I-D.ietf-rtgwg-policy-model  ... Else, it will be useless. Regards -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-28 06:16:28-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 05:26:40-08:00",
    "text": "Thank you for using the YANG Security Considerations template.\u00a0 Could you please provide more details on which nodes are sensitive to write and read issues; and the RPC operations of concern.\u00a0 For example, see  draft-ietf-isis-yang-isis-cfg  or draft-ietf-ospf-yang.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-11-09 12:33:47-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-14 10:50:59-07:00",
    "text": "I'm balloting DISCUSS because the specification in \u00a79.1.1 is not clear, and it is not in sync with draft-ietf-idr-tunnel-encaps.\u00a0 [Some of the points below are not DISCUSS-worthy, but I'm including them here because they are related to the larger point.] \u00a79.1.1 talks about using the Encapsulation Extended Community *and* the Router's MAC Extended Community.\u00a0 However, the requirement for these communities to appear together is not explicit anywhere.\u00a0 What are the implications for only one of them being present? The Router's MAC Extended Community \"is only required when Ethernet NVO tunnel type is used\".\u00a0 It seems to me that normatively requiring the extended community is important in this case. What exactly is the \"Ethernet NVO tunnel type\"?\u00a0 \u00a71 (Terminology) says that \"Examples of this type of tunnels are VXLAN or GENEVE.\"\u00a0 A standards track document should be specific about when something is required.\u00a0 For example, I assume that it would also be required when using NVGRE.\u00a0 The tunnel types are a finite number, so please be specific. Where is the GENEVE tunnel type (to be used in the Encapsulation Extended Community) defined?\u00a0 BTW, the [GENEVE] reference is also missing. \u00a74 has this text: \"the tunnel connecting these IP-VRFs can be either IP-only tunnel (in case of MPLS or GENEVE encapsulation) or Ethernet NVO tunnel (in case of VxLAN encapsulation).\"\u00a0 It confuses me because of the apparent contradiction between GENEVE being an example of an Ethernet NVO tunnel type, but also (?) an IP-only tunnel in this case. \u00a74.2/draft-ietf-idr-tunnel-encaps mentions possible conflicts created by the Router's MAC Extended Community and how it may be ignored, but this document doesn't mention using the Encapsulation Sub-TLVs (also from  draft-ietf-idr-tunnel-encaps ) for the same function.\u00a0 Can the same function be achieved with the Encapsulation Sub-TLVs? \"section 4.5 of [TUNNEL-ENCAP]\" is mentioned a couple of times, but there is no \u00a74.5 in  draft-ietf-idr-tunnel-encaps , and there's no reference either.\u00a0 Please remove the specific section number (to avoid becoming out of sync), and instead mention the Encapsulation Extended Community by name.\u00a0 Add a Normative reference to draft-ietf-idr-tunnel-encaps.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-14 14:00:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-13 22:20:07-07:00",
    "text": "ection 7 appears to reference (in a normative fashion) an[IRB-EXT-MOBILITY] document but there is no such reference listed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-29 17:28:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 14:00:01-07:00",
    "text": "(1) Possibly a \"discuss discuss\", but ... if I'm understanding correctly, the symmetric IRB case over an Ethernet NVO tunnel (not MPLS or IP NVO) described in this document is introducing a new scenario where traffic using router (PE) MAC addresses as source and destination is comingled on the same tunnel with traffic using tenant system MAC addresses as source and destination.\u00a0 This places an obligation on the tunnel endpoints to properly isolate and process such \"internal\" tunnel traffic without hampering the ability of tenans systems to communicate.\u00a0 In a world where tenant systems can appear at any time, using previously unknown MAC addresses, this represents a rather challenging problem: how will the PEs be able to pick (and avertise) MAC addresses that they know will not conflict with any present or future customer systems?\u00a0 (A similar dilemma led to quite a delay in the processing of  draft-ietf-bfd-vxlan , which in that case was resolved by limiting the BFD operation to just the \"management VNI\" which is not subject to MAC address conflict with customer systems.)\u00a0 In this docuement's case, we seem to be using a \"well-known\"/reserved MAC address range from  RFC 5798 ; in principle, this should be enough to avoid conflicts, if customer systems are known to not squat on this reserved range.\u00a0 However, this document has some text in Section 4.1 that indicates that there must be external knowledge that auto-derived MAC addresses in the  RFC 5798  ranges \"[do] not collide with any customer MAC address\".\u00a0 So I'm left uncertain whether or not this potential problem is addressed or not.\u00a0 (Also, I don't know if the limit on 255 distinct such MAC addresses presents a scaling issue.) Also, is there any risk that the EVPN IRB setup might also want to use VRRPv3, and thus collide on the MAC addresses in a different manner? (1.1) I'm less sure whether there's a similar collision risk for IP addresses -- we assign IP addresses to NVEs (e.g., for use as BGP Next Hop addresses) and these are used as VTEP addresses when encapsulating packets that are going inter-subnet.\u00a0 I think that at this point in the packet processing we may already know that we're in the the \"IRB tunnel\" scope and that may be enough to de-conflict any potential IP address collision between NVE and customer addresses. (2) Section 7 appears to reference (in a normative fashion) [IRB-EXT-MOBILITY] but there is no such reference. Similarly (as Murray notes), there are a couple apparent references to [TUNNEL-ENCAP] that are also arguably normative, but the target of the reference is not forthcoming (and the IANA registry does not show a \"BGP Encapsulation Extended Community\" that is supposedly defined by [TUNNEL-ENCAP]). There is also not a listed reference for [EVPN-PREFIX], though one could perhaps surmise that it is intended to be [ I-D.ietf-bess-evpn-prefix-advertisement ] (given that the latter does allocate EVPN route type 5 for carrying IP Prefix routes, etx.). However, given that this document has text like \"MUST advertise local subnet routes as RT-5\", this needs to be a normative (not informative) reference.\u00a0 (We may also want to explicitly reference [EVPN-PREFIX] where those normative requirements are made.) (3) I'm not sure whether we are modifying the error-handling semantics for RT-2 from what is specified in  RFC 7432  (and, furthermore, whether the changes are backwards-compatible).\u00a0 If so, it seems like we may need an Updates: relationship.\u00a0 The text in question is in Section 9.1.1 (which itself seems problematic, since this section is advertised as an (example) operational model/scenario): \u00a0  If the receiving NVE receives a RT-2 with only Label-1 and only a \u00a0  single Route Target corresponding to IP-VRF, or if it receives a RT-2 \u00a0  with only a single Route Target corresponding to MAC-VRF but with \u00a0  both Label-1 and Label-2, or if it receives a RT-2 with MAC Address \u00a0  Length of zero, then it MUST treat the route as withdraw [ RFC7606 ] \u00a0  and log an error message. Are all of these treat-as-withdraw behaviors specified in  RFC 7432 ? (4) Let's discuss whether we need more generally a \"backwards compatibility\" section (I mention a couple other places where this might come into play, in the COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-27 16:07:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-29 17:28:45-07:00",
    "text": "I think draft-ietf-bess-evpn-irb-extended mobility needs to be a normative reference, since \"the procedures in [it] must be exercised\" incorporates its procedures by reference.\u00a0 Similarly, draft-ietf-idr-tunnel-encaps  seems like a normative reference since we require the RT-2 route used by this document to be advertised along with the EC that indicates the tunnel type. I still think we need to discuss whether this document Updates: 7432. RFC 7432  specifies the layout and interpretation of the RT-2 (MAC-IP Advertisement Route) EVPN NRLI, but we extend it in several ways (e.g., the Label1 and Label2 (which we spell \"Label-1\" and \"Label-2\", unfortunately) are only MPLS labels in 7432, but we expand that to also allow VNI values in those fields; likewise, 7432 gives no semantics at  all for Label2, but we define some).\u00a0 I understand that 7432 only covers the L2 case but this document adds mixed L2/L3 (IRB), and furthermore  that the IRB case can be inferred based on the contets of the fields in the advertisement, *if you know how to look for them*.\u00a0 But I still can't shake the feeling that this document should either be added as an additional reference for EVPN Route Type 2, or listed as Updating 7432, in order to indicate that we provide more details for the interpretation and contents of the RT-2 NLRI.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-10 11:24:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-02-27 16:07:30-08:00",
    "text": "This document provides semantics for the EVPN RT-2 \"MPLS Label2\" field allocated in but undocumented by  RFC 7432 .\u00a0 I believe that we need to provide some \"trail of breadcrumbs\" from the IANA registry to this document so that the semantics of the protocol field are discoverable.\u00a0 This could take the form of a direct reference from the IANA registry to this document, or by marking this document as Updating  RFC 7432 , or some other mechanism that provides the needed discoverability.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-23 23:11:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-14 23:21:41-07:00",
    "text": "[ general ] * Can you give an example of what happens to non-IPv4/IPv6 Ethernet packets \u00a0 received at the NVE/PE?\u00a0 Do they get bridged, and if so how far?\u00a0 What \u00a0 happens if a host in BT1 ARPs for IPv4 address associated with a TS in \u00a0 a different BT? * Where there are multiple prefixes in an IP-VRF, is there a constraint that \u00a0 any other IP-VRF that contains one of the prefixes must contain all of them? \u00a0 Perhaps that's in 7432...? [ sections 4, 5.4, 5.4, 6.3, 6.4, 9.1.2, 9.2.2 ] * Please document what happens to IPv4 TTL/IPv6 Hop Limit values as they \u00a0 cross various NVEs/PEs. [ section 7 ] * Is there a reference for IRB-EXT-MOBILITY? * The two statements: \u00a0 (1) \"Although the language used in this section is for IPv4 ARP, \u00a0 \u00a0 \u00a0 it equally applies to IPv6 ND.\" \u00a0 (2) \"If there is [a] many-to-one relationship such that there are many host \u00a0 \u00a0 \u00a0 IP addresses correspond[ing] to a single host MAC address ..., then to \u00a0 \u00a0 \u00a0 detect host mobility, the procedures in [IRB-EXT-MOBILITY] must be \u00a0 \u00a0 \u00a0 exercised...\" \u00a0 are in direct conflict.\u00a0 All IPv6 hosts having at least one non-link-local \u00a0 unicast address will have more than one IP address per MAC and this section, \u00a0 or even this document, would not apply?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-07-08 12:34:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-07-08 12:34:13-07:00",
    "text": "I found this document difficult to review. Some of this might be due to the fact that I'm not an expert on EVPN, but I think some of the reason is that the document could be structured better and expressed more clearly. The only reason I'm not opposing the progression of the document on the grounds that it's too unclear to implement is that I've been told, and accept on faith, that implementations *have* been successfully written starting from the spec, which implies it's implementable -- I guess by people who are expert in EVPN already, it wouldn't be implementable by me. In any case, I do have some points I would like to discuss, that are more actionable. 1. I agree with Robert Wilton's comment on -09: ``` One question I have is whether it is possible to have a deployment where some devices support synchronous mode and others support asynchronous mode.\u00a0 Am I right in presuming that this is not supported and if so is this capability signaled in any way? Or is the expectation that this would be controlled via deployment choice of network device, or though configuration management? ``` This issue still exists in -14. I think it should be addressed in the document. Similarly, I agree with Warren Kumari's comment, also on -09: ``` I would strongly recommend that the authors read the OpsDir review at:  https://datatracker.ietf.org/doc/review-ietf-bess-evpn-inter-subnet-forwarding-09-opsdir-lc-jaeggli-2020-07-06/  , especially the: \"it would be helpful if section 4 would be more explicit for non-implementors on when symetric or asymetric modules would be chosen, as it stands the variation basically reads like the enumeration of the features of various implementations.\" comment (which I fully agree with). ``` It seems both of these comments could -- and should! -- be addressed by adding a few paragraphs talking about these topics. This could be done either in \u00a74, as Warren suggests, or in some other section (e.g. you could add an \"operational considerations\" section). 2. Section 7.1 I\u2019m guessing this question isn\u2019t unique to this document, but since this is where I encountered it, I\u2019ll ask: it seems as though the described mobility procedures are vulnerable to a condition where a particular (IP, MAC) appears at two different NVEs at the same time. If this condition exists (either innocently, or maliciously) what prevents the source and target NVEs from continually attempting to claim the (IP, MAC) from one another, flooding the network with updates all the while? (This applies to 7.2 as well.) Since this seems like a potential security issue, I'm including it in my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-07-14 16:21:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-08 12:34:51-07:00",
    "text": "I found this document difficult to review. Some of this might be due to the fact that I'm not an expert on EVPN, but I think some of the reason is that the document could be structured better and expressed more clearly. The only reason I'm not opposing progression of the document on the grounds that it's too unclear to implement is that I've been told, and accept on faith, that implementations *have* been successfully written starting from the spec, which implies it's implementable -- I guess by people who are expert in EVPN already, it wouldn't be implementable by me. In any case, I do have some points I would like to discuss, that are more actionable. 1. I agree with Robert Wilton's comment on -09: ``` One question I have is whether it is possible to have a deployment where some devices support synchronous mode and others support asynchronous mode.\u00a0 Am I right in presuming that this is not supported and if so is this capability signaled in any way? Or is the expectation that this would be controlled via deployment choice of network device, or though configuration management? ``` This issue still exists in -14. I think it should be addressed in the document. Similarly, I agree with Warren Kumari's comment, also on -09: ``` I would strongly recommend that the authors read the OpsDir review at:  https://datatracker.ietf.org/doc/review-ietf-bess-evpn-inter-subnet-forwarding-09-opsdir-lc-jaeggli-2020-07-06/  , especially the: \"it would be helpful if section 4 would be more explicit for non-implementors on when symetric or asymetric modules would be chosen, as it stands the variation basically reads like the enumeration of the features of various implementations.\" comment (which I fully agree with). ``` It seems both of these comments could -- and should! -- be addressed by adding a few paragraphs talking about these topics. This could be done either in \u00a74, as Warren suggests, or in some other section (e.g. you could add an \"operational considerations\" section). 2. Section 7.1 I\u2019m guessing this question isn\u2019t unique to this document, but since this is where I encountered it, I\u2019ll ask: it seems as though the described mobility procedures are vulnerable to a condition where a particular (IP, MAC) appears at two different NVEs at the same time. If this condition exists (either innocently, or maliciously) what prevents the source and target NVEs from continually attempting to claim the (IP, MAC) from one another, flooding the network with updates all the while? (This applies to 7.2 as well.) Since this seems like a potential security issue, I'm including it in my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-07-28 10:25:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-09 06:48:19-07:00",
    "text": "I support Benjamin's DISCUSS and Roman's last DISCUSS point. Regarding Section 11, there are often legal agreements in place that govern all sorts of things about how protocols transfer data between parties, but those are not the main thing to document in an RFC. Section 11 should be documenting the technical considerations for how to protect the data that may be escrowed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-01 17:22:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-08 09:01:06-07:00",
    "text": "Let's have a discussion about the overall plans for providing guidance on mechanisms for (e.g.) cryptographic confidentiality and integrity protection of data both in transit and at-rest, authentication/authorization requirements, etc..\u00a0 In particular, what it's appropriate and necessary to include in this document vs. other documents, and how to provide some specific general baseline guidance that can be used in the absence of conflictinc scenario-specific deployment requirements.\u00a0 Some further details in the COMMENT section, but in general, it seems like there should be some \"off-the-shelf\" mechanism that can be used without a need for every deployment to do a custom thing, for cases where there are not custom requirements.\u00a0 It may not need to be part of this document, but we should have a plan for where it will be. Also, it's not clear to me whether we expect escrow of credentials/verifiers used to authenticate/authorize fourth parties that perform operations (e.g., registrations) at the registry (see comment on Section 3), and that is pretty important for knowing what security requirements to place on the escrow'd data.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-04-29 01:07:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 05:39:36-07:00",
    "text": "Section 8. As this document will be an IETF proposed standard I think the registrant for the RDE and XML schema shall follow the recommendation in  RFC 3688 :  \u00a0  Registrant Contact \u00a0 \u00a0 \u00a0 The individual/organization that is the registration contact for \u00a0 \u00a0 \u00a0 the component being registered.\u00a0 Ideally, this will be the name \u00a0 \u00a0 \u00a0 and pertinent physical and network contact information.\u00a0 In the \u00a0 \u00a0 \u00a0 case of IETF developed standards, the Registrant will be the IESG. So please change that registrant to follow the above. The purpose of this is to prevent any issues over who has change control of the registered entries.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-04-28 13:14:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-08 20:06:44-07:00",
    "text": "I had originally included these just as comments, but since another AD brought up the same point I'd like to discuss them: Section 5.1.3: \"This element SHOULD be present in deposits of type Incremental or Differential.\"\u00a0 This makes it sound like a deposit of those two types not using this element might be non-compliant.\u00a0 I suggest instead \"This element is only used in Incremental and Differential deposits.\"\u00a0 (Or instead of \"used\", maybe \"meaningful\".) Section 5.1.4: \" It SHOULD be present in all type of deposits.\"\u00a0 Same issue.\u00a0 Maybe \"It is valid for use in all types of deposits.\"",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-05-13 08:07:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-08 10:03:46-07:00",
    "text": "Hi, I spotted some issues with the terminology and the description of the algorithm that I would like you to please address. Section 2: Terminology The definitions provided for \"Differential\" vs \"Incremental\" are the opposite to their standard meaning in backups.\u00a0 The term definitions should be reversed to align with the common vernacular.\u00a0 I.e. differential is the diff against the last full backup, incremental is the backup since the backup (of any type) was performed. 5.1.3.\u00a0 Child\u00a0 element \u00a0  The specification for each object to be escrowed MUST declare the \u00a0  identifier to be used to reference the object to be deleted. An identifier is equally important in the add/update case as well to know which object needs to be updated.\u00a0 I would suggest pulling this sentence out of this subsection and adding a new subsection under 5 to briefly describe the requirement on object identifiers and how they are used both in the delete and contents cases. 5.1.4.\u00a0 Child\u00a0 element \u00a0  When applying Incremental or Differential Deposits (when rebuilding \u00a0  the registry from data escrow deposits) the relative order of the \u00a0 \u00a0 elements is important, as is the relative order of the \u00a0 \u00a0 elements.\u00a0 All the\u00a0 elements MUST be applied \u00a0  first, in the order that they appear.\u00a0 All the\u00a0 elements \u00a0  MUST be applied next, in the order that they appear. I think that the text for processing deposits would be better outside of section 5.1.4, since some of the text is referring to section 5.1.3, and isn't specific to the\u00a0 element. Why does the relative order of\u00a0 elements matter?\u00a0 Is this because of potential dependencies between the elements, if so, it would be useful if that was explicitly stated.\u00a0 If not, then I don't understand why the order of deletes would matter. Also, should there be a statement that an object SHOULD NOT exist multiple times (either in the\u00a0 or\u00a0 elements in a single deposit)? \u00a0  If an object is present in the\u00a0 section of several deposits \u00a0  (e.g.\u00a0 Full and Differential) the registry data from the latest \u00a0  deposit (as defined by the Timeline Watermark) SHOULD be used when \u00a0  rebuilding the registry. This doesn't just apply to objects in the\u00a0 section, but equally applies if the object is present in any\u00a0 or\u00a0 section.\u00a0 I.e. the status of whether an object exists and its contents must be taken from the latest deposit.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-13 05:40:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-08 15:35:29-07:00",
    "text": "** Section 6.1.\u00a0 Please provide a normative reference to XML Schema. ** Section 6.1. The schema defines types \u201cclIDType\u201d and \u201crrType\u201d but their use isn\u2019t explained in the text and they don\u2019t appear to be used in the definition of . ** Section 11.\u00a0 Was a requirement to secure the deposit data at rest considered?\u00a0 The text here suggests that such details needed to be worked out individually.\u00a0 However, Section 9 notes that the whole deposit is likely to be confidential.\u00a0 It would seem best practice to store such sensitive information encrypted.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-08-19 14:47:33-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-12 23:36:16-07:00",
    "text": "Thanks to everyone who worked on updating this protocol to reflect experience gathered from the initial CT protocol. I have one blocking comment, and a small number of editorial suggestions. --------------------------------------------------------------------------- \u00a75: >\u00a0 Clients are configured with a base URL for a log and construct URLs >\u00a0 for requests by appending suffixes to this base URL.\u00a0 This structure >\u00a0 places some degree of restriction on how log operators can deploy >\u00a0 these services, as noted in [ RFC7320 ].\u00a0 However, operational >\u00a0 experience with version 1 of this protocol has not indicated that >\u00a0 these restrictions are a problem in practice. The synthesis of URLs by a protocol in this fashion is prohibited by  BCP 190 : \u00a0  Scheme definitions define the presence, format, and semantics of a \u00a0  path component in URIs; all other specifications MUST NOT constrain, \u00a0  or define the structure or the semantics for any path component. Unless the intention of this document is to update  BCP 190  to change this normative requirement, we can't publish it in its current form. Note that doing so would require a change of venue, as updates to  BCP 190  would not be covered by the current TRANS charter. Please see  BCP 190  section 3 for alternate approaches. All three approaches could be made to work for CT, and I would be happy to explain how to do so if clarification is desired.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-03-14 06:09:00-07:00",
    "text": "I think this is an important document and I am looking forward to seeing it as a Proposed Standard in the future. However, it has a good number of editorial issues that make the document hard to read and implement. 5.\u00a0 Log Client Messages \u00a0  type:\u00a0 A URN reference identifying the problem.\u00a0 To facilitate \u00a0 \u00a0 \u00a0 automated response to errors, this document defines a set of \u00a0 \u00a0 \u00a0 standard tokens for use in the \"type\" field, within the URN \u00a0 \u00a0 \u00a0 namespace of: \"urn:ietf:params:trans:error:\". I think you need to register this in  Also, can you clarify whether error need an IANA registry?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-09-27 10:44:07-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 09:34:18-07:00",
    "text": "Glad to see this revision of the protocol. My comments and questions should be easy to address. = Section 10.2, 10.4, 10.5 = A Specification Required registry policy implies expert review. So a registry policy of \"Specification Required and Expert Review\" is duplicative; it should just say \"Specification Required.\" I know this seems trivial but there has been so much confusion about this through the years that it is important to be precise. = Section 10.3 = This section needs to state what the registry policy is for the code points not already registered (presumably Expert Review given 10.3.1, but it needs to be explicit). = Section 10.6.1 = Using the term \"Parameters Required\" as a capitalized term is confusing. FCFS registries by definition can require additional information to be provided in order to get something registered. For avoidance of confusion I think the assignment policy should be listed as First Come First Served and the requirement that parameters be included in the application can use a normative MUST in the last paragraph if there is concern that the parameters won't be supplied. However, I also wonder what will be done with the parameters that are supplied. Is IANA expected to just maintain them privately, or to publish them? What is expected to appear in the 'Log' column in the registry?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-30 19:02:51-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-14 07:09:22-07:00",
    "text": "First off, thanks for this well-written document!\u00a0 I intend to ballot Yes, but there are a few issues that need to be resolved first. Sections 4.11 and 4.12 have arrays of NodeHash to carry consistency and inclusion proofs, respectively, with minimum array size of 1.\u00a0 However, Sections 2.1.4.1 and 2.1.3.1 (respectively) seem to admit the possibility of zero-length proofs in degenerate cases, which the aforementioned protocol description language forbids the conveyance of. (Section 5.3 explicitly requires the use of an empty consistency proof.) Do those minimum array sizes need to be (implicit) zero? (If they do not, it seems that a minimum size of 32 would have the same effect as that of one, since a NodeHash has minimum size 32.) I support Alexey's Discuss regarding the registration of a \"urn:ietf:params:trans:error\" URN namespace. In Section 6: \u00a0  o\u00a0 An Online Certificate Status Protocol (OCSP) [ RFC6960 ] response \u00a0 \u00a0 \u00a0 extension (see Section 7.1.1), where the OCSP response is provided \u00a0 \u00a0 \u00a0 in the \"CertificateStatus\" message, provided that the TLS client \u00a0 \u00a0 \u00a0 included the \"status_request\" extension in the (extended) \u00a0 \u00a0 \u00a0 \"ClientHello\" (Section 8 of [ RFC6066 ]).\u00a0 [...] This is not quite a TLS 1.3-compliant formulation -- TLS 1.3 does not use the \"CertificateStatus message\", but rather uses the encoding of that structure in a status_request extension in the CertificateEntry. I also think we need greater clarity on the (non-)usage of CT for TLS client certificates; see COMMENT I also support Alissa's Discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-25 02:03:16-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-14 06:49:58-07:00",
    "text": "There was a presentation at maprg IETF 103 about the question if CT helps attackers to find new domains. I think this risk should at least be mentioned in the security considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-05-13 10:53:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-05 22:56:23-07:00",
    "text": "reserving Alexey's DISCUSS position...",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-05-14 21:55:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-13 10:53:49-07:00",
    "text": "Thanks for addressing Alexey's DISCUSS position.\u00a0 In -36, a few important IANA-related issues remain, all easy fixes: * Section 10.4 has some messed up markdown around its Specification Required guidance. * Section 10.7 needs to name the sub-registry it's creating.\u00a0 (If it's the title of the section, that should be made clear; the prose doesn't say.) * It should be clear that all of these are sub-registries of \"Transport Layer Security (TLS) Extensions\".\u00a0 Either say that in each section (i.e., refer to the XYZ sub-registry of the \"Transport Layer Security (TLS) Extensions\" registry), or say in Section 10 that everything below is a sub-registry of that one.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-07-26 07:42:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 14:04:08-07:00",
    "text": "# GEN AD review of  draft-ietf-add-svcb-dns-06 CC @larseggert Thanks to Peter E. Yee for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/T4D0gKTp6m_TFw0C26Ib-7PqttY ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS for IANA, so we can determine next steps during the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-12-05 14:54:23-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 15:10:17-07:00",
    "text": "Thanks to everyone who invested their time in this document. I have one blocking comment that I believe should be easy to resolve, and one fairly major comment that should be trivial to fix. \u00a78.1.1: >\u00a0 o\u00a0 The Uri-Path option is set to \"j\". COAP URIs are generally subject to  BCP 190  restrictions, which would require the path to either be provisioned, discovered, or under the \".well-known\" tree. The use of a reserved domain name here may change the rationale; but for the sake of not establishing a precedent for path squatting in CoAP, this document needs to clearly explain the rationale of why  BCP 190  should not apply in this case. Alternately, the implied URI can be changed to something like \"coap:// 6tisch.arpa/.well-known/j \"",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-11-01 15:04:57-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 07:32:08-07:00",
    "text": "I have some issues with the references here, which should be resolvable simply by making some normative. RFC 8505  provides terminology as well as neighbor discovery (in Sections 4.2 and 6), so it seems to me that it should be a normative reference. As  draft-ietf-6tisch-architecture  is used for both necessary terminology and concepts, I can\u2019t see how it isn\u2019t normative.\u00a0 I did find that I had to check it during my review. In Section 5: \u00a0  In an operational 6TiSCH network, all frames MUST use link-layer \u00a0  frame security [ RFC8180 ]. This would seem to be a MUST referring to 8180, making that a normative reference as well.\u00a0 But possibly this might not really be a MUST imposed here, and is instead citing a requirement from elsewhere.\u00a0 In that case, I would simply remove the word \u201cMUST\u201d, so it is stating a fact, rather than a new requirement.\u00a0 You might similarly consider the subsequent sentence.\u00a0 In any case, I do wonder whether\u00a0 7554 and 8180 should be normative.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-09 10:27:48-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 23:24:32-07:00",
    "text": "Thanks for this generally well-written document!\u00a0 It does a great job at making these fairly difficult topics accessible to the reader.\u00a0 I have a few points that should be fairly easy to address, but do need to be addressed before the document should advance. My comment on Section 8.4.4 tries to walk through some scenarios involving a finite lease time on a short address; as a result of that I think it's necessary to direct the 6LN to interpret the time in units of ASN as opposed to wall-clock time. The \"parameter_addinfo\" field in Unsupported_Parameter (Section 8.4.5) feels underspecified to me.\u00a0 The inline text says that only a subset of the link-layer key set from the Configuration could be included here, but how is that formally specified? The string COJP_MAX_JOIN_ATTEMPTS appears only twice in the text, once in Section 8.3.1 and again in the table in Section 8.5.\u00a0 The former text leaves me confused as to what counts as a \"join attempt\" for this purpose, and in particular how it differs from the MAX_RETRANSMIT timer mentioned in the previous sentence. I couldn't find a clear statement that any node sending EBs needs to be prepared to act as a join proxy; Section 4.1 notes that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 During the remainder of the join process, the node \u00a0  that has sent the EB to the pledge acts as the JP. but I couldn't find where that was enforced. I think we may need to say more about how a JP knows that \"secExempt\" is in effect (see comment in Section 5), since that affects a critical piece of the security posture of the network. Finally, can we discuss whether a 32-bit MIC is the most appropriate default for the key usage?\u00a0 I lack the domain background to know how much impact there is in going to an ENC-MIC64 or ENC-MIC128 scheme.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-29 09:43:04-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-29 04:12:49-07:00",
    "text": "1) I hope this point can be resolved quickly as it seems to only need a bit more specifics but I think this part is not sufficient: Sec 6.1: \"The Join Proxy implements a data cap on outgoing \u00a0  join traffic through CoAP's congestion control mechanism.\" I think this needs an normative requirement here. Congestion control is supposed to avoid network overload but also to make use available resources. The congestion control as currently defined\u00a0 for CoAP would probably limit the join traffic appropriately (to something like one packet per RTT likely) but CoAP could in theory use any time a different more aggrieve congestion and therefore just relying on congestion control generically doesn't seem to be sufficient. I recommend to define a hard limit, e.g. 1 packet per RTT or 1 packet per 3 seconds if RTT is unknown (as recommended in  RFC8085 ) and say that this can be achieved by congestion control as specified in the base CoAP spec. 2) Also, not\u00a0 sure if this editorial or a real issue but I'm not sure I fully understand this sentence: Sec 6.1.1: \"A Join Proxy that does not set the DSCP on traffic \u00a0  forwarded should set it to zero so that it is compressed out.\" If the proxy does NOT SET DSCP, why should it SET it to zero? I would think it either sets it to AF43 or it does nothing about it because DSCP is not really used in that network. I guess it's not a big issue and setting to zero seems fine as well but I'm afraid I don't understand the intent here and when exactly the Proxy is supposed to set to AF43 or bleach. 3) This may also be mostly editorial but just to be sure. Section 7.2 provide default value for some of the CoAP transport parameter (where 2 or 3 are the same as defined in  RFC7252 ) but not for all. Why is that? And then finally on reference again: Given that use of  I-D.ietf-core-stateless  is recommend, I believe it should be normative (and wait for publication of that doc).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-30 07:10:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-29 09:43:04-07:00",
    "text": "1) I hope this point can be resolved quickly as it seems to only need a bit more specifics but I think this part is not sufficient: Sec 6.1: \"The Join Proxy implements a data cap on outgoing \u00a0  join traffic through CoAP's congestion control mechanism.\" I think this needs an normative requirement here. Congestion control is supposed to avoid network overload but also to make use available resources. The congestion control as currently defined\u00a0 for CoAP would probably limit the join traffic appropriately (to something like one packet per RTT likely) but CoAP could in theory use any time a different more aggrieve congestion and therefore just relying on congestion control generically doesn't seem to be sufficient. I recommend to define a hard limit, e.g. 1 packet per RTT or 1 packet per 3 seconds if RTT is unknown (as recommended in  RFC8085 ) and say that this can be achieved by congestion control as specified in the base CoAP spec.  Further there seems to be an implicit requirement that the JP MUST implement rate limit using the PROBING_RATE parameter, however that is never explicitly spelled out as a normative requirement. However, if this rate is not provided by the JRC, it doesn't seem that any rate limiting has to enforced. So maybe it would be good to be more strict here. 2) Also, not\u00a0 sure if this editorial or a real issue but I'm not sure I fully understand this sentence: Sec 6.1.1: \"A Join Proxy that does not set the DSCP on traffic \u00a0  forwarded should set it to zero so that it is compressed out.\" If the proxy does NOT SET DSCP, why should it SET it to zero? I would think it either sets it to AF43 or it does nothing about it because DSCP is not really used in that network. I guess it's not a big issue and setting to zero seems fine as well but I'm afraid I don't understand the intent here and when exactly the Proxy is supposed to set to AF43 or bleach. 3) This may also be mostly editorial but just to be sure. Section 7.2 provide default value for some of the CoAP transport parameter (where 2 or 3 are the same as defined in  RFC7252 ) but not for all. Why is that? 4 ) And then finally on references (again): Given that use of  I-D.ietf-core-stateless  is recommend, I believe it should be normative (and wait for publication of that doc).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-05 06:29:59-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-30 07:10:17-07:00",
    "text": "1) I hope this point can be resolved quickly as it seems to only need a bit more specifics but I think this part is not sufficient: Sec 6.1: \"The Join Proxy implements a data cap on outgoing \u00a0  join traffic through CoAP's congestion control mechanism.\" I think this needs an normative requirement here. Congestion control is supposed to avoid network overload but also to make use available resources. The congestion control as currently defined\u00a0 for CoAP would probably limit the join traffic appropriately (to something like one packet per RTT likely) but CoAP could in theory use any time a different more aggrieve congestion and therefore just relying on congestion control generically doesn't seem to be sufficient. I recommend to define a hard limit, e.g. 1 packet per RTT or 1 packet per 3 seconds if RTT is unknown (as recommended in  RFC8085 ) and say that this can be achieved by congestion control as specified in the base CoAP spec.  Further on there seems to be an implicit requirement that the JP MUST implement rate limit using the PROBING_RATE parameter, however, that is never explicitly spelled out as a normative requirement. However, if this rate is not provided by the JRC, it doesn't seem that any rate limiting has to be enforced. So maybe it would be good to be more strict here. 2) Also, not\u00a0 sure if this editorial or a real issue but I'm not sure I fully understand this sentence: Sec 6.1.1: \"A Join Proxy that does not set the DSCP on traffic \u00a0  forwarded should set it to zero so that it is compressed out.\" If the proxy does NOT SET DSCP, why should it SET it to zero? I would think it either sets it to AF43 or it does nothing about it because DSCP is not really used in that network. I guess it's not a big issue and setting to zero seems fine as well but I'm afraid I don't understand the intent here and when exactly the Proxy is supposed to set to AF43 or bleach. 3) This may also be mostly editorial but just to be sure: Section 7.2 provides default values for some of the CoAP transport parameter (where 2 of 3 are the same as defined in  RFC7252 ) but not for all. Why is that? 4 ) And then finally on references (again): Given that use of  I-D.ietf-core-stateless  is recommend, I believe it should be normative (and wait for publication of that doc).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-30 18:57:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-19 14:45:35-08:00",
    "text": "In Section 4.2 we say that \"If an entity is capable of [...] TLS 1.2 or any successors [...], the CAN_TLS flag within its contanct [sic] header SHALL be set to 1.\"\u00a0 I don't understand why we should allow in the spec for an entity to not be capable of TLS 1.2+.\u00a0 Can you give me some examples of situations when you would want to use a TCPCL but cannot use TLS with it?\u00a0 A new major version of TCPCL would be the least-bad time to make a clean break and mandate TLS... There's some good discussion in Section 4.4.2 of the mechanics of TLS X.509 certificate authentication; thanks for that!\u00a0 I do think that there's a fairly critical omission, though, namely that the BP agent needs to provide to the TCPCL Entity the Node ID of the expected next hop from the routing decision (in addition to the hostname/IP address to which to initiate a TCP connection), and this Node ID must also be validated against the TLS certificate and the SESS_INIT from the peer. Otherwise we are in effect falling back to an authorization policy of \"anyone with a cert with a uniformResourceIdentifier SAN of the expected scheme is authorized to do anything\", which is a pretty weak policy. (In some sense, if we require this, then the Node ID in the SESS_INIT becomes redundant, though I think there are some edge cases where it would still be needed in order for both endpoints to agree on the communicating identities.) I also think we need to discuss the TLS X.509 authentication model that will be used, i.e., \"what PKI is being used?\".\u00a0 (To be clear, I don't know that any changes to the text will be required, but do think we should be sure we have a clear picture of what the expected deployment strategies are.) The usage of SNI to pick a cert and the DNS-ID ( RFC 6125 ) to authenticate a hostname might imply that the typical \"Web PKI\" (that deals in hostnames) is intended, but the URIs we need to authenticate Node IDs are not commonly certified by that PKI.\u00a0 Since the server has to present a single certificate even if it is attempting to authenticate as both DNS-ID and the NodeID URI, it seems like it would be challenging to use this scheme in practice against the Web PKI roots. This hybrid of hostname and Node-ID authentication also suffers from an awkward ordering issue when the TLS handshake occurs before the SESS_INIT messages that convey what Node ID is intended to be authenticated -- this requires implementations to use a TLS stack that preserves the peer's certificate and perform name validation after a completed TLS handshake, which is moving more of the complications out of the TLS stack and into the application logic (which introduces risk of security-relevant bugs).\u00a0 It also means that certificate selection must be based solely on SNI hostname and cannot involve the requested Node ID.\u00a0 [There is in theory the selectable name_type field in the TLS server_name extension, but in practice that joint has rusted shut and it seems unlikely that there would be much implementation traction to define a name type for DTN Node ID;  RFC 6066  also fails to give a clear indication of the intended semantics when multiple name types are present.] Please double-check for lingering text that assumes the  RFC 7242 behaviors where all parameters are in the contact header (vs. SESS_INIT) and use of SDNV encoding vs. fixed-lengths.\u00a0 I noted several instances in the COMMENT section, but do not claim to have made an exhaustive review.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-02 22:47:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-30 18:57:11-07:00",
    "text": "[This is essentially a restatement of the comments at https://mailarchive.ietf.org/arch/msg/dtn/jnafmsDt0OXUhYlBwT_U9PuNV5c/ but rephrased to be a standalone review rather than continuation of an existing conversation.] I'm really impressed by the new text about PKIX environments/CA policy, and entity identification; thank you! I suspect that, with one exception, we have similar understandings of what is supposed to happen, but may need to wrangle the actual text on the page a little more to get to the right place. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The one exception relates to the security properties of having the certificate validation procedure be a prioritized list of steps with which steps to use being dependent on the contents of the received certificate.\u00a0 Specifically, if we will end up letting a peer with a DNS-ID cert authenticate as any node ID, then there is no security gain from having the node ID in the cert in the first place, since the attacker will just skip that step.\u00a0 The value of NODE-ID comes into play when we know, before we go into the validation procedure, that the legitimate peer will have the expected NODE-ID in their certificate. Obviously we cannot expect that to always be the case, given that we aim to be compatible with DTN-Ignorant CAs, so we will need to specify some granularity for when we do or do not require the NODE-ID to be present. There are a number of possibilities here and I don't know which is going to be best for the broadest group of deployments.\u00a0 Some simple ideas for consideration include: (a) any given node either always or never requires NODE-ID (b) any given interface either always or never requires NODE-ID (c) push it to the discovery protocol/\"out of band configuration\" (d) a trust-on-first-use-like option of \"once you've seen a NODE-ID for \u00a0 a given node ID, always require NODE-ID in the future for that node \u00a0 ID.\u00a0 (This has pretty significant risks without a way to \"undo the \u00a0 latch\" but if generating a new node ID is cheap they may be \u00a0 tolerable.) (e) define new URI scheme(s) that have similar semantics to the current \u00a0 ones but require NODE-ID for authentication. (f) similar to (e), apply additional granularity based on URI scheme or \u00a0 scheme-specific structure (e.g., certain prefixes/suffixes of names \u00a0 but not others In theory there are similar considerations between DNS-ID and NETWORK-ID (see below for comment about the \"NETWORK-ID\" name), but since they are both expected to be coming from the Web PKI and both have similarly weak models for node authentication it's not clear to me that we should spend much effort on a complicated procedure for there.\u00a0 Something simple like \"if you have a (stable) name for the peer, expect DNS-ID; if you only have an IP address, use NETWORK-ID\" should work quite well (and may even be what you intended anyway). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The main place where I'm still seeing a need for wordsmithing is in the authentication procedures in Section 4.4.3.\u00a0 I see from the previous discussion that the intent of \"SHALL attempt to authenticate [...] If  and security policy disallows an unauthenticated , the entity SHALL terminate the session\" is for security policy to be able to say \"yes, there's no -ID and I'm fine with that (or potentially even \"the -ID that is present failed validation and I'm fine with that\"), which is a surprising wording to me but I guess technically okay.\u00a0 (The current wording strongly implies, to me, that  if validation fails, the session gets terminated; maybe it's something about the double negative in \"disallows an unauthenticated\" that makes the \"security policy\" aspect feel very weak.)\u00a0 What seems significantly problematic to me, though, is the requirement as-written to attempt validation of all three types of ID (NODE-ID, DNS-ID, and NETWORK-ID). In the expected case where a peer's certificate contains only one of the three (or, perhaps, a NODE-ID and one other name type), this means that security policy would have to be some complex matrix with interdependencies between the various types (allow unauthenticated host by DNS-ID if NETWORK-ID present and valid, etc.) that prevents validation of each type of name being performed independently. In particular, this \"must attempt all three types\" logic seems at odds with the first paragraph of the section that says that attempting host name validation is optional. So, I would have expected the text to flow more along the lines of (but written less hastily) \"security policy determines, for a given connection, which identity type(s) is expected, and validation is attempted for those specific type(s).\u00a0 Failed authentication results in session termination.\" It is okay with me for security policy to allow continuing with the connection even when validation is attempted but fails, but I'm not sure that we currently have a fully consistent picture about how/when this happens.\u00a0 In particular, I see a note in Section 8.10.1 that using TLS in a way which does not authenticate both peers is out of scope of this document\" along with a mention of similarities to opportunistic security, yet letting security policy proceed with an unauthenticated peer seems at odds with that \"out of scope\".\u00a0 We should have a clearer picture of whether opportunistic security with no or failed authentication of one or both peers is permitted by this document. I think we can also wordsmith the setting of CAN_TLS a little more; previous discussion indicated a desire to (e.g.) not require TLS when operating over IPsec, but that's a different criterion than \"capable of exchanging messages [with TLS]\".\u00a0 It's also inconsistent with a desire to make TLS support mandatory to implement (but not mandatory to use), since mandatory to implement implies mandatory to be \"capable of exchanging messages with TLS\", thus mandatory to use.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-27 21:03:31-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-02 22:47:59-08:00",
    "text": "[retaining discuss section unchanged from the -21 in order to update the comment section, even though much progress has been made on this front at IETF 109 and via email.\u00a0 IIRC we have a thread open with the PKIX extended key purpose DE for how to modify the TLS certificate validation procedures.] ========================== discuss section from -21 below ==================== [This is essentially a restatement of the comments at https://mailarchive.ietf.org/arch/msg/dtn/jnafmsDt0OXUhYlBwT_U9PuNV5c/ but rephrased to be a standalone review rather than continuation of an existing conversation.] I'm really impressed by the new text about PKIX environments/CA policy, and entity identification; thank you! I suspect that, with one exception, we have similar understandings of what is supposed to happen, but may need to wrangle the actual text on the page a little more to get to the right place. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The one exception relates to the security properties of having the certificate validation procedure be a prioritized list of steps with which steps to use being dependent on the contents of the received certificate.\u00a0 Specifically, if we will end up letting a peer with a DNS-ID cert authenticate as any node ID, then there is no security gain from having the node ID in the cert in the first place, since the attacker will just skip that step.\u00a0 The value of NODE-ID comes into play when we know, before we go into the validation procedure, that the legitimate peer will have the expected NODE-ID in their certificate. Obviously we cannot expect that to always be the case, given that we aim to be compatible with DTN-Ignorant CAs, so we will need to specify some granularity for when we do or do not require the NODE-ID to be present. There are a number of possibilities here and I don't know which is going to be best for the broadest group of deployments.\u00a0 Some simple ideas for consideration include: (a) any given node either always or never requires NODE-ID (b) any given interface either always or never requires NODE-ID (c) push it to the discovery protocol/\"out of band configuration\" (d) a trust-on-first-use-like option of \"once you've seen a NODE-ID for \u00a0 a given node ID, always require NODE-ID in the future for that node \u00a0 ID.\u00a0 (This has pretty significant risks without a way to \"undo the \u00a0 latch\" but if generating a new node ID is cheap they may be \u00a0 tolerable.) (e) define new URI scheme(s) that have similar semantics to the current \u00a0 ones but require NODE-ID for authentication. (f) similar to (e), apply additional granularity based on URI scheme or \u00a0 scheme-specific structure (e.g., certain prefixes/suffixes of names \u00a0 but not others In theory there are similar considerations between DNS-ID and NETWORK-ID (see below for comment about the \"NETWORK-ID\" name), but since they are both expected to be coming from the Web PKI and both have similarly weak models for node authentication it's not clear to me that we should spend much effort on a complicated procedure for there.\u00a0 Something simple like \"if you have a (stable) name for the peer, expect DNS-ID; if you only have an IP address, use NETWORK-ID\" should work quite well (and may even be what you intended anyway). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% The main place where I'm still seeing a need for wordsmithing is in the authentication procedures in Section 4.4.3.\u00a0 I see from the previous discussion that the intent of \"SHALL attempt to authenticate [...] If  and security policy disallows an unauthenticated , the entity SHALL terminate the session\" is for security policy to be able to say \"yes, there's no -ID and I'm fine with that (or potentially even \"the -ID that is present failed validation and I'm fine with that\"), which is a surprising wording to me but I guess technically okay.\u00a0 (The current wording strongly implies, to me, that  if validation fails, the session gets terminated; maybe it's something about the double negative in \"disallows an unauthenticated\" that makes the \"security policy\" aspect feel very weak.)\u00a0 What seems significantly problematic to me, though, is the requirement as-written to attempt validation of all three types of ID (NODE-ID, DNS-ID, and NETWORK-ID). In the expected case where a peer's certificate contains only one of the three (or, perhaps, a NODE-ID and one other name type), this means that security policy would have to be some complex matrix with interdependencies between the various types (allow unauthenticated host by DNS-ID if NETWORK-ID present and valid, etc.) that prevents validation of each type of name being performed independently. In particular, this \"must attempt all three types\" logic seems at odds with the first paragraph of the section that says that attempting host name validation is optional. So, I would have expected the text to flow more along the lines of (but written less hastily) \"security policy determines, for a given connection, which identity type(s) is expected, and validation is attempted for those specific type(s).\u00a0 Failed authentication results in session termination.\" It is okay with me for security policy to allow continuing with the connection even when validation is attempted but fails, but I'm not sure that we currently have a fully consistent picture about how/when this happens.\u00a0 In particular, I see a note in Section 8.10.1 that using TLS in a way which does not authenticate both peers is out of scope of this document\" along with a mention of similarities to opportunistic security, yet letting security policy proceed with an unauthenticated peer seems at odds with that \"out of scope\".\u00a0 We should have a clearer picture of whether opportunistic security with no or failed authentication of one or both peers is permitted by this document. I think we can also wordsmith the setting of CAN_TLS a little more; previous discussion indicated a desire to (e.g.) not require TLS when operating over IPsec, but that's a different criterion than \"capable of exchanging messages [with TLS]\".\u00a0 It's also inconsistent with a desire to make TLS support mandatory to implement (but not mandatory to use), since mandatory to implement implies mandatory to be \"capable of exchanging messages with TLS\", thus mandatory to use.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-02-25 00:38:21-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-20 06:48:15-08:00",
    "text": "eed to confirm that reassigning the TCP Port 4556 is okay with the official assigne Simon Perreault.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-23 01:52:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 06:50:57-08:00",
    "text": "eed to resolve Mirja's discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-23 06:56:13-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-23 01:52:34-07:00",
    "text": "irja's discuss is now resolved except for a single item regarding the aspect of session policies for TCPclv4.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-11-23 10:28:02-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-07 16:41:31-08:00",
    "text": "Sec 6.1. I read this sentence several times and could not figure out what it is saying, and fear there could be interoperability problems. \"When performing an unclean termination, a \u00a0  transmitting node SHALL treat either sending or receiving a SESS_TERM \u00a0  message (i.e., before the final acknowledgment) as a failure of the \u00a0  transfer.\u00a0 Any delay between request to close the TCP connection and \u00a0  actual closing of the connection (a \"half-closed\" state) MAY be \u00a0  ignored by the TCPCL entity.\" First of all, \"failure of the transfer\" is ambiguous because there may be two transfers going on, one in each direction. Second, I would like further clarity on what it means that nodes \"SHALL\" consider it \"a failure of the transfer\". What is actionable if it's a failure? If nothing is actionable, it shouldn't be a SHALL. Does this mean that in subsequent sessions I must resend the whole bundle? Can you list some reasons why an endpoint would choose to close uncleanly? Some motivation might provide helpful context. Moreover the \"sending or receiving\" bit is confusing. - So one option is that I'm a session that has decided to do an unclean termination rather than a clean one. So I send SESS_TERM and then close (FIN? RST?) the TCP connection. So if it's a FIN, I might very well get the last XFER_ACK.\u00a0 If I RST or don't get that ACK, then I do think it's clear that the transfer is a failure, whatever that means. - But as a receiver, how do I know that the termination is unclean? Have I made an independent decision to close uncleanly? Am I to take the receipt of a SESS_TERM without my having sent XFER_ACK as an unclean close? If I sent XFER_ACK, how do I know that the sender sent it? And what does it mean, as a receiver, that the transfer \"failed\" if I have all the data?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-02-20 05:06:19-08:00",
    "text": "Thanks for this well-written document. I have a couple of thing in the comment section below that should be clarified. But there is one point which does not seem correct to me and therefore I'm raising it at thee discuss level: Sec 5.1.1: \"Both sides SHALL send a KEEPALIVE message whenever the negotiated interval \u00a0  has elapsed with no transmission of any message (KEEPALIVE or other). \u00a0  If no message (KEEPALIVE or other) has been received in a session \u00a0  after some implementation-defined time duration, then the node SHALL \u00a0  terminate the session by transmitting a SESS_TERM message (as \u00a0  described in Section 6.1) with reason code \"Idle Timeout\". \" It is not necessary that both endpoints send keepalives when TCP is used underneath as data is transmitted reliably. If one end sends keepalives and transmission fails it will close the TCP connection no matter what. Therefore the case where no keepalive is received, can only happen if no keepalive was send by the application, however, if the own keepalives are send successfully it is also received and the TCP connection is alive. If this is only to test liveness of the TCP connection, why don't you use TCP keepalives instead? Further what happens when a keepalive fails? Should one endpoint try to reconnect, immediately or later when new data is available? And one more small thing: sec 6.1: \"However, an entity MUST always send \u00a0  the contact header to its peer before sending a SESS_TERM message.\" This normative requirement seems contradicting the way version failures are handled earlier on in the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-02-18 19:35:28-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-18 19:34:45-08:00",
    "text": "* Section 4.2: \" TLS 1.2 [ RFC5246 ] or any successors [ RFC8446 ] that are compatible with TLS 1.2\" Hopefully this is easy to resolve but I am not sure what exactly you intended to say with this phrase \"that are compatible with TLS 1.2\". Can you please clarify? (I think going through Appendix D of  RFC8446  may bring up specific things you might be looking for). A similar construct is also used in Section 4.4.1.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-13 11:48:37-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-18 19:35:28-08:00",
    "text": "* Section 4.2: \" TLS 1.2 [ RFC5246 ] or any successors [ RFC8446 ] that are compatible with TLS 1.2\" Hopefully this is easy to resolve but I am not sure what exactly you intended to say with this phrase \"that are compatible with TLS 1.2\". Can you please expand and clarify? (I think going through Appendix D of  RFC8446  may bring up specific things you might be looking for). A similar construct is also used in Section 4.4.1.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-10-12 05:07:27-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 08:45:10-07:00",
    "text": "Hi, Thanks for writing this document.\u00a0 I have a few points that I believe are worthy of discussion. Disclaimer: I'm not familiar with IEEE 802.1CQ, nor am I a DHCPv6 expert ...\u00a0 Some of these questions/comments may have been answered there. My first question relates to process:\u00a0 Have members of the IEEE 802.1WG had an opportunity to review and provide input into this document?\u00a0 If not, then I think that it would be good for them to be given the opportunity to do so.\u00a0 In particular, they might question whether it is appropriate for a client to be able to request MAC addresses to be assigned from the SAI or \"reserved for future use\" address pools.\u00a0 It is worth noting that there is an IETF-IEEE liaison meeting on Mon 15th, that may help.  I'm not sure that I really like how the algorithm is defined in this document (relative to  draft-ietf-dhc-mac-assign ).\u00a0 In  draft-ietf-dhc-mac-assign , the client makes a request, and the server can respond with a completely different smaller MAC address range, i.e. the client is just providing hints/suggestions to the server.\u00a0 I would be much happier if the QUAD option specified in this document behaved similarly.\u00a0 I.e. the QUAD option is used by a client to specify an ordered preference of quads to use, but otherwise the server is allow to offer up an address, or block of addresses, outside the preferred quads, which the client could choose to not accept, or release.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-11 00:36:58-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-17 06:29:20-08:00",
    "text": "Section 7.1: Port request for DOTS signal for home. I think the WG has failed to take the assignment principles in  RFC 6335  to heart: From Section 7:  \u00a0  \"The basic principle of service name and port number registry \u00a0  management is to conserve use of the port space where possible.\" \u00a0  o\u00a0 IANA strives to assign only one assigned port number per service \u00a0 \u00a0 \u00a0 or application. \u00a0 \u00a0 \u00a0 Note: At the time of writing of this document, there is no IETF \u00a0 \u00a0 \u00a0 consensus on when it is appropriate to use a second port for an \u00a0 \u00a0 \u00a0 insecure version of a protocol. \u00a0  o\u00a0 IANA strives to assign only one assigned port number for all \u00a0 \u00a0 \u00a0 variants of a service (e.g., for updated versions of a service). \u00a0  o\u00a0 IANA strives to encourage the deployment of secure protocols. \u00a0  o\u00a0 IANA strives to assign only one assigned port number for all \u00a0 \u00a0 \u00a0 different types of devices using or participating in the same \u00a0 \u00a0 \u00a0 service. \u00a0  o\u00a0 IANA strives to assign port numbers only for the transport \u00a0 \u00a0 \u00a0 protocol(s) explicitly named in an assignment request. \u00a0  o\u00a0 IANA may recover unused port numbers, via the new procedures of \u00a0 \u00a0 \u00a0 de-assignment, revocation, and transfer. After having reviewed Appendix A I think the WG has made the wrong choice and also not considered all the available choices for enabling DOTS signal and call home to be colocated on the same port. Several options exists: \t- URI name space so that it is the same protocol just making requests with different URIs depending on mode \t- Use the already existing settings negotiation to determine the mode of operation. \t- Using ALPN on (D)TLS connection establishment From my perspective the DOTS WG have multiple choices that are quite simple to solve there colocation issue that would not incur significnat cost or overhead. Using an additional port do incur a cost of consuming a resource that is endless and not easily recoverable. I do share the IANA port experts team's verdict that this port assignment should be denied and alternative solution found as the motivation appears very weak.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-07 14:08:27-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 12:00:35-08:00",
    "text": "It seems to me there is a missing operational guidance or undocumented deployment assumptions.\u00a0 Since the motivational use case seems to be home networks (per Section 1.1), I assumed that the call home servers are running primarily consumer grade routers not managed by professional IT expertise.\u00a0 If that assumption is true (and it should be documented if that is the case), then I find many of the operational recommendations not congruent with that environment.\u00a0 Specifically, the degree of interaction and tuning seems outside the realm of expertise of someone without IT training and capabilities of home network ecosystem.\u00a0 In particular: -- Section 1.2  The Call Home DOTS server uses the DDoS attack traffic information to \u00a0  identify the compromised device in its domain that is responsible for \u00a0  launching the DDoS attack, optionally notifies a network \u00a0  administrator, and takes appropriate mitigation action(s).  How would such notification work? -- Section 1.2 and 5.1.\u00a0 Leaves credentials configuration as out of scope.\u00a0 Section 1.2 references [ I-D.ietf-dots-server-discovery ] for provisioning.\u00a0 In turn, Section 1 of [I-D.ietf.server-discovery] also declares this problem out of scope by saying \u201cThis document assumes that security credentials to authenticate DOTS server(s) are pre-provisioned to a DOTS client using a mechanism such as (but not limited to) those discussed in [ RFC8572 ] or [ I-D.ietf-anima-bootstrapping-keyinfra ]\u201d.\u00a0 However,  RFC8572  seems to rely on NETCONF and RESTCONF which seems like a rather uncommon feature of home routers.\u00a0 BRKSI relies on a manufacturer supplied/contracted infrastructure and keystores that also seem uncommon for consumer grade equipment.  -- Section 5.3.1. The Call Home DOTS server domain administrator consent MAY be \u00a0  required to block the traffic from the compromised device to the \u00a0  attack target.\u00a0 An implementation MAY have a configuration knob to \u00a0  block the traffic from the compromised device to the attack target \u00a0  with or without DOTS server domain administrator consent. The suggestion here seems to be that consumers are acquiring devices that can be remotely reconfigured with out a defined trust model?\u00a0 Some policy or operational context seems appropriate here. -- Section 5.3.1 ... notifies the CPE \u00a0  administrator about the compromised device Notify how? -- Section 8.  Appropriate \u00a0  filters (e.g., access control lists) can be installed on the Call \u00a0  Home DOTS server and network between the Call Home DOTS agents so \u00a0  that only communications from a trusted Call Home DOTS client to the \u00a0  Call Home DOTS server are allowed. This seems like a level of sophistication beyond your average home router user and a place where implementations should consider a secure defaults. -- Section 8. Call Home DOTS servers can also seek the consent of DOTS \u00a0  server domain administrator to block the traffic from the potentially \u00a0  compromised device to the target (see Section 5.3.1). What would be the means to gain such consent? -- Section 9. Note that a Call Home DOTS server can seek an administrator's \u00a0  consent, validate the request by inspecting the relevant traffic for \u00a0  attack signatures, or proceed with both courses of action. As above. -- Section 9. \u00a0 \u00a0 The DOTS Call Home is only advisory in nature.\u00a0 Concretely, the DOTS \u00a0  Call Home does not impose any action to be enforced within the \u00a0  network hosting an attack source; it is up to the Call Home DOTS \u00a0  server (and/or network administrator) to decide whether and which \u00a0  actions are required. Such a decisions seems out beyond the ability of your average home router user. -- Section 8\u00a0 \u201c... explicit policy (e.g., the Call Home DOTS client and server are managed by the same administrative entity), Is there an underlying assumption that the ISP is managing the device?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-31 12:08:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-19 15:43:43-07:00",
    "text": "I have a question about the scope of some normative language, which may or may not be problematic but I'm too ignorant of OSPF details to be able to answer myself.\u00a0 In Section 3 we say that: \u00a0  When an OSPF Area Border Router (ABR) distributes information between \u00a0  connected areas it MUST preserve the ELC setting. My undesrtanding is that it's normal operation for an ABR to distribution information about prefixes and such between areas, and in particular that an ABR does not necessarily need to know the semantic details of every bit of information being distributed in that fashion. So, I am imagining a scenario where some routers in both areas advertise/understand the ELC flag but the ABR between them does not implement this spec.\u00a0 What would happen in such a scenario?\u00a0 If the ABR is still expected to distribute the ELC setting without change, isn't that just a core requirement from the respective OSPF specs, as opposed to a new requirement imposed by this spec (which, in this scenario, the ABR is not claiming to adhere to anyway)? There is perhaps a similar question about the ASBR guidance, though when doing cross-protocol signalling there is a more clear need for the ASBR to understand the semantics of the flags it is redistributing (and it's only a \"SHOULD\").",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-18 17:46:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-21 11:23:44-07:00",
    "text": "(1)  RFC 4086  does not state that \"a high-security password must have at least 49 bits of randomness or entropy\" as is claimed in Section 4.1 of this document.\u00a0 It merely says that so much entropy is needed to have a one-in-a-billion chance of success for successfully guessing in the model laid out, and makes no statement about (absolute) \"high\" security. I don't think we need to spend as much time on what  RFC 4086  says as we currently do, and could probably get to the \"use at least 128 bits of entropy\" advice much sooner. (2) There's also some text in Section 5.3 that I'd like to discuss briefly: \u00a0  The registry MUST NOT return any indication of whether the \u00a0  authorization information is set or unset to the non-sponsoring \u00a0  registrar by not returning the authorization information element in \u00a0  the response.\u00a0 The registry MAY return an indication to the \u00a0  sponsoring registrar that the authorization information is set by \u00a0  using an empty authorization information value.\u00a0 The registry MAY \u00a0  return an indication to the sponsoring registrar that the \u00a0  authorization information is unset by not returning the authorization \u00a0  information element. This seems to be assigning semantics to both absent-authinfo and empty-authinfo in the\u00a0 response, but is giving *different* semantics to the response-to-sponsoring-registrar and response-to-non-sponsoring-registrar cases.\u00a0 Is there precedent for changing the semantics of the response based on the identity of the client like this (not just changing the content of the response)?\u00a0 Can we come up with a scheme that provides consistent semantics to all clients, perhaps based on\u00a0 vs empty\u00a0 for unset/set, leaving \"element is absent\" for the deliberately ambiguous case? (3) We may also need to discuss the efficacy of the transition plan, per my comments in Sections 6.1 and 6.3 -- my current understanding is that the proposed plan will break some existing workflows.\u00a0 I am not sure if that is intended, desirable, and/or tolerable, and welcome further insight.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-09-08 06:42:02-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-07 10:27:16-07:00",
    "text": "# GEN AD review of  draft-ietf-cose-countersign-09 CC @larseggert Thanks to Elwyn Davies for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/jrTPQpNSafEhkpyMYn3r250_ghM ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS for IANA, so we can determine next steps during the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-09-20 12:58:25-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-07 19:14:53-07:00",
    "text": "\u00a0 \u00a0 \u00a0 \u00a0 gem install cbor-diag I am concerned about adding install commands for \"programs from the internet\" within an RFC. If the rubygem for some reason becomes malicious, we cannot pull it from the RFC (even if we pull it from the datatracker link, it would still live on in copies of the RFC elsewhere and malicious people could point to copies of those original RFCs to point people to downlod the malicious rubygem. I would be okay with an  iet.org  download location of a ruby gem.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-06-16 07:41:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 23:40:22-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-httpbis-binary-message-05 cc @evyncke Thank you for the work put into this document. And I really mean it even when balloting a blocking DISCUSS because it will be useful. BTW, I sincerely hate to be process-focused and I hope to stand corrected quickly. Please find below one blocking DISCUSS points, which may be resolved during the IESG formal telechat. Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Does it fit HTTPBIS charter ? While I think that this document is useful (even if I have doubts about standards track rather than informational as for the expired PCAP I-D in OPSAWG), I fail to see how this document fits the HTTPBIS charter. The only potential way is at the end of the charter: ``` # Other HTTP-Related Work The Working Group may define extensions and other documents related to HTTP as work items, provided that: * They are generic; i.e., not specific to one application using HTTP. Note that Web browsing by definition is a generic use. * The Working Group Chairs judge that there is consensus to take on the item and believe that it will not interfere with the work described above, and * The Area Director approves the addition and add corresponding milestones. ``` But I do not see any related milestone to this document. Moving this document to AD sponsored is probably the right way. ## Notes This review is in the [\"IETF Comments\" Markdown format][ICMF], You can use the [`ietf-comments` tool][ICT] to automatically convert this review into individual GitHub issues.  [ICMF]:  https://github.com/mnot/ietf-comments/blob/main/format.md [ICT]:  https://github.com/mnot/ietf-comments",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-08 22:05:12-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-04 21:43:57-07:00",
    "text": "My understanding is that this point is essentially overtaken by events, as a similar concern was raised already by Martin D, John, and Roman, and there is a commitment to update the text already made.\u00a0 I'm putting it in at the Discuss level to make sure that I follow-up on the revised text when it appears. But, for concreteness: the text in Sections 8.4, 10.4, and 11 treat cryptographic mTLS, TSIG, and SIG(0) authentication as providing an equivalent level of protection to the (non-cryptographic) IP ACL.\u00a0 My understanding is that IETF consensus is to prefer cryptographic mechanisms for authentication and authorization, when available. Relatedly, the text in Section 8.4 says that TSIG/SIG(0) are \"not sufficient to authenticate the client or server\", which is technically true, but also seems misleading.\u00a0 In XFR scenarios it's not clear that specific identification (authentication) of the counterparty is necessary for secure operation, if authorization to receive/send the zone can be established without specific identification.\u00a0 My undersatnding is that, when combined with a strict TLS profile for server authentication and appropriate trust policy on TLS clients, TSIG and SIG(0) both serve to provide proof of authorization for the exchange even though they only provide authentication in the form of group membership (the relevant key material is typically available to multiple machines).\u00a0 As such, don't they provide strong enough cryptographic protection (and end-to-end, no less!) to be a superior authorization mechanism than an IP ACL?\u00a0 (Any resulting text changes may bleed into Sections 11 and 12 in addition to 8.4, per my COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-06-03 09:56:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-03 11:37:36-07:00",
    "text": "In further discussions it became clear that the authors do not intend for XoT traffic to use an ALPN code at all. I'm afraid this may be a misunderstanding of previous guidance from TLS that XoT did not need its own ALPN code, but could simply use the DoT ALPN since the messages are distinguishable on the wire. To not use an ALPN at all violates best TLS practice. The reasoning given in Appendix A, that this creates difficulty for proxies, doesn't make sense to me. We can talk about it in the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-09 08:54:14-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-02 16:08:33-08:00",
    "text": "Section 2 says that the \"DTLS certificate values\" are required to return no value when read, but this property seems to be intended for private data such as DTLS private key values, not the certificates themselves (which are public). While I appreciate that IPv6 is the current version of the internet protocol, I do see that 6126bis allows for Babel to run over both IPv6 and IPv4, yet this document in multiple places implicitly assumes that Babel runs over IPv6, to the exclusion of IPv4.\u00a0 Such a restriction from the core protocol spec should only be undertaken by an information model with clear reasoning and loud disclaimer. Similarly (as Roman notes), we are putting requirements on the key length for MAC keys (relative to the block size of the underlying hash function) that have were once present in  draft-ietf-babel-hmac  but have been removed as of draft-ietf-babel-hmac-10.\u00a0 I assume that the intent is not to impose additional restrictions compared to the protocol spec, thus we need to catch up to those changes. The description of the babel-mac-key-test and babel-cert-test operations need to be tightened up, as the secdir reviewer noted.\u00a0 (See COMMENT.) We seem to be using terminology from the Network Management Datastore Architecture without reference or otherwise introducing the concepts. This is a Discuss point because the only candidate reference I know of, RFC 8342 , is specific to YANG and data models, so it's applicability for use in an information model may be subject to discussion.\u00a0 (Hopefully this only reflects my ignorance and not a fundamental lack of datastore architecture for information models.)",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2023-01-27 08:53:23-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-18 08:18:05-08:00",
    "text": "I am balloting DISCUSS because I believe that the expected actions resulting from this document are not specific enough: (1) \u00a77 reads: \u00a0  This document formally updates [ RFC3552 ] such that a vulnerability  \u00a0  assessment of transient numeric identifiers is performed when writing  \u00a0  the \"Security Considerations\" section of future RFCs. Is the assessment a requirement or a recommendation (when defining transient numeric identifiers)?\u00a0  The Abstract says that \"this document updates  RFC 3552 , requiring future RFCs to contain a vulnerability assessment of their transient numeric identifiers.\"\u00a0 The update itself doesn't result in a requirement. Please be explicit (SHOULD/MUST ?) in \u00a77. (2) The requirements of the assessment itself (\u00a75) can also be more explicit: [Line numbers from idnits.] 289\t5.\u00a0 Vulnerability Assessment Requirements for Transient Numeric 290\t\u00a0 \u00a0 Identifiers 292\t\u00a0  Protocol specifications that employ transient numeric identifiers 293\t\u00a0  SHOULD: (2a) The points to be covered in the assessment are only recommended and not required.\u00a0 When is it ok to not include any, or all, of the points mentioned?\u00a0 Why is this not a requirement?\u00a0 Are some parts optional? 295\t\u00a0  1.\u00a0 Clearly specify the interoperability requirements for the 296\t\u00a0 \u00a0 \u00a0  aforementioned transient numeric identifiers (e.g., required 297\t\u00a0 \u00a0 \u00a0  properties such as uniqueness, along with the failure severity if 298\t\u00a0 \u00a0 \u00a0  such properties are not met). (2b) \"Clearly specify the interoperability requirements...\"\u00a0 Clarity can be subjective.\u00a0 s/.../Specify the interoperability requirements... 300\t\u00a0  2.\u00a0 Provide a vulnerability assessment of the aforementioned 301\t\u00a0 \u00a0 \u00a0  identifiers. 303\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Note: Section 8 and Section 9 of 304\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ I-D.irtf-pearg-numeric-ids-generation ] provide a general 305\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 vulnerability assessment of transient numeric identifiers, 306\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 along with a vulnerability assessment of common algorithms for 307\t\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 generating transient numeric identifiers. (2c) Going back to (1), is this the only part that is intended to be performed as a result of the update to  rfc3552 ? (2d) What should be included in the vulnerability assessment?\u00a0 Given that this bullet talks about identifiers, are the considerations from \u00a78/I-D.irtf-pearg-numeric-ids-generation (correlation, leakage, fingerprinting, etc.) expected to be included? (2e) The reference to \u00a79 seems not to be needed at this point, or are you also expecting an assessment of the algorithm? 309\t\u00a0  3.\u00a0 Recommend an algorithm for generating the aforementioned 310\t\u00a0 \u00a0 \u00a0  transient numeric identifiers that mitigates the vulnerabilities 311\t\u00a0 \u00a0 \u00a0  identified in the previous step, such as those discussed in 312\t\u00a0 \u00a0 \u00a0  [ I-D.irtf-pearg-numeric-ids-generation ]. (2f) Is the expectation that this recommendation will result in a normative requirement, recommendation, or just an option? 314\t\u00a0  Note: 315\t\u00a0 \u00a0 \u00a0 As discussed in Section 1, use of cryptographic techniques for 316\t\u00a0 \u00a0 \u00a0 confidentiality and authentication might not eliminate all the 317\t\u00a0 \u00a0 \u00a0 issues associated with predictable transient numeric identifiers. 318\t\u00a0 \u00a0 \u00a0 Therefore, the advice from this section SHOULD still be applied 319\t\u00a0 \u00a0 \u00a0 for cases where cryptographic techniques are employed for 320\t\u00a0 \u00a0 \u00a0 confidentiality or authentication of the associated 321\t\u00a0 \u00a0 \u00a0 transientnumeric identifiers. (2g) \"SHOULD still be applied\" Given that \u00a71 doesn't exclude protocols using cryptographic techniques for confidentiality and authentication from the considerations in this document, the \"SHOULD\" above reinforces that and indicates a fact, vs a normative recommendation.\u00a0  s/SHOULD/should [nit] s/transientnumeric/transient numeric",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-01-30 00:48:09-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-16 05:06:25-08:00",
    "text": "# GEN AD review of  draft-gont-numeric-ids-sec-considerations-10 CC @larseggert Thanks to Gyan S. Mishra for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/sQeXJs6ZU4ga80XkFYFCGKo_u0w ). ## Discuss ### Paragraph 0 ``` \u00a0 Network Working Group\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 F. Gont \u00a0 Internet-Draft\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SI6 Networks \u00a0 Updates: 3552 (if approved)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 I. Arce ``` RFC3552  is a BCP on the IAB stream that was approved by the IESG. Can it be updated by a document on the IETF stream without the update also being explicitly approved by the IAB? ### \"Abstract\", paragraph 1 ``` \u00a0 \u00a0  Poor selection of transient numerical identifiers in protocols such \u00a0 \u00a0  as the TCP/IP suite has historically led to a number of attacks on \u00a0 \u00a0  implementations, ranging from Denial of Service (DoS) to data \u00a0 \u00a0  injection and information leakage that can be exploited by pervasive \u00a0 \u00a0  monitoring.\u00a0 To prevent such flaws in future protocols and \u00a0 \u00a0  implementations, this document updates  RFC 3552 , requiring future \u00a0 \u00a0  RFCs to contain a vulnerability assessment of their transient numeric \u00a0 \u00a0  identifiers. ``` Does this document intend to make requirements for all numeric identifiers used by a protocol, or only those that are observable in plaintext? All motivational text is AFAICT based on flaws that arose because such identifiers were transmitted in plaintext, so does the document intend to limit its guidance to those (and not to other identifiers that are for example always transmitted in encrypted form)? If the document does intend to give guidance on identifiers that are transmitted in encrypted form, it would be good to give some examples why that is necessary. In any event, please be more precise about the applicability of the guidance given here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-14 08:35:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 14:29:29-07:00",
    "text": "I support Roman's Discuss point (1) (and basically cover the same as his (2) below). Let's have a discussion about (DTLS) identity. Section 2.1 says that we use mutual authentication and that implementations \"MUST support authenticating peers against a local store of credentials\"; also that \"if a node receives a new DTLS connection from a neighbour to whom it already has a connection, the node MUST NOT discard the older connection until it has completed the handshake of the new one and validated the identity of the peer\".\u00a0 But how does this authentication occur, and what constitutes the identity of the peer.\u00a0 We will frequently have (D)TLS consumers cite  RFC 6125  and say that (e.g.) DNS-ID or SRV-ID must match the name obtained in some fashion.\u00a0 But for Babel, we are authenticating routers -- router identity is usually in the form of just an IP address on a loopback interface!\u00a0 Are we expected to get certificates that certify IP addresses as identity, or use some sort of PSK or password-based TLS authentication?\u00a0 (The last two are not really compatible with the \"MUST send a CertificateRequest\", BTW.)\u00a0 Raw public keys?\u00a0 I think we can give a more clear picture of how to build a secure system. Relatedly, once DTLS authenticates an identity, what level of authorization checks are performed?\u00a0 Are we still in a single authorization domain, where any router that authenticates as being part of a given domain is implictily authorized to be a babel peer and convey any and all routing information? We should also give some guidance on ciphers and algorithms where we discuss the DTLS details ( BCP 195  is probably the safest bet here, even if it's a little in need of an update).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-14 07:54:21-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 05:40:29-07:00",
    "text": "Unfortunately I need to discuss the port request again.  First of all I would like to comment on the shepherd write-up which says: \"The document requires only the allocation of a port number for Babel over DTLS. Having such a second port for the secured version of a protocol is a fairly common practice. This is shown in the IANA Considerations section.\" This is not correct. Having a second port for the secured version of a protocol WAS common practice. However  RFC6335  say now \"The use of separate \u00a0  service name or port number assignments for secure and insecure \u00a0  variants of the same service is to be avoided in order to discourage \u00a0  the deployment of insecure services.\" Anyway, in this case I understand that a different port is desired because unencrypted HELLO messages are still received over the default babel port. However, it is not clear to me why a fixed/default port is needed. The neighbour needs to be discovered in some why, no matter what, before a DTLS connection can be established and this discovery procedure could indicate a dynamic port number that the peer is listening on for babel over DTLS. E.g. the multicast HELLO could have a new TLV with this port information. Please clarify why this option is not suitable! Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-27 10:57:45-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 12:25:53-07:00",
    "text": "(1) Section 1. These are different than the ones listed in Section 6 of  draft-ietf-babel-rfc6126bis  and Section 1 of draft-ietf-babel-dtls.\u00a0 As DTLS and HMAC are mitigations for attacks in  draft-ietf-babel-rfc6126bis , they really should be harmonized. (2) Section 2.1.\u00a0 Per \u201cImplementations MUST support authenticating peers against a local store of credentials\u201d, what does that credentialing look like?\u00a0 Is it certificates, PSK, etc?\u00a0 What validation procedure is being used for this authentication?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-09 15:59:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-07 21:46:51-07:00",
    "text": "This document requires the use of per-delegation-object URLs in the order request object but does not provide a way to obtain such URLs (only a URL for a list of delegations associated to an account is available, not per-delegation URLs). I agree with Francesca and the DE that attaching the \"delegation\" attribute to the identifier makes less sense than attaching it to the order; accordingly, I support Francesca's Discuss. Similarly (and relatedly), there seems to be an object structure mismatch while using a CSR to finalize an order, that may merit some discussion.\u00a0 Each delegation can have its own CSR template, but if a single order is to have the possibility to incorporate multiple identifiers, and each identifier has its own delegation, then there's no reason to expect that a single CSR can be compatible with the templates from the disparate delegations invoked in a single order.\u00a0 We could in principle just require that the CSR templates must be \"consistent\" (and define what that means) in scenarios with multiple identifiers in a single order, but it seems better if we can restructure the object model so things are more naturally aligned.\u00a0 Taken to an extreme, this would entirely divorce CSR template objects from delegation objects, with a URL for the associated CSR template object being an attribute of a delegation.\u00a0 Then we could have something like multiple identifiers and multiple delegations in an order, provided that they all refer to the same CSR template object. I also don't think I understand the need for having \"allow-certificate-get\" in the Order Object (nor its semantics) -- what do we gain from having it in the Object itself that is not achieved by the existing newOrder request payload?\u00a0 As far as I can tell the we only talk about writing to it in the rest of the document, and never have to read or consult its value.\u00a0 If it is necessary, it seems like the document needs to be more clear about why.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-04-07 00:43:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-04-06 10:08:38-07:00",
    "text": "EDIT (06-04-2021): Thank you very much to Carsten Bormann for the CDDL review:  https://mailarchive.ietf.org/arch/msg/cbor/23A-PFhRY-pdkg2-Kgcd4jqySVo/  Authors - please make sure to answer Carsten's comments (and keep me in cc so I can clear my DISCUSS).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-12 14:12:41-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-07 00:43:07-07:00",
    "text": "EDIT (06-04-2021): Thank you very much to Carsten Bormann for the CDDL review:  https://mailarchive.ietf.org/arch/msg/cbor/23A-PFhRY-pdkg2-Kgcd4jqySVo/  Authors - please make sure to answer Carsten's comments (and keep me in cc so I can clear my DISCUSS). EDIT (07-04-2021): Also wanted to point out the IANA Designated Expert review to make sure it is addressed (found in the datatracker, but which I report here for simplicity as well) - thank you to Richard Barnes for it:   1. The \"delegation\" field is currently attached to the \"identifier\" object, which is a bad semantic fit in a few ways. ACME orders can have multiple identifiers, and delegations can describe multiple SAN values, yet this design assumes singularity on both sides. This field should be moved to the order object; in fact, if you wanted to be more radical, you could even use it to replace the \"identifiers\" field in the newOrder request. 2. The \"allow-certificate-get\" field is listed as configurable. It seems like this is a matter of CA policy, so it should either be non-configurable, or if you allow the client to request a value for it, there should be a clear specification that the server is allowed to ignore the client's preference.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-10 12:02:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-06 05:41:09-07:00",
    "text": "Section 5.1, paragraph 4, discuss: >\u00a0 \u00a0 This document requests that IANA create the following new registry >\u00a0 \u00a0 under the Automated Certificate Management Environment (ACME) >\u00a0 \u00a0 Protocol: > >\u00a0 \u00a0 *\u00a0 ACME Identifier Object Fields > >\u00a0 \u00a0 This registry is administered under a Specification Required policy >\u00a0 \u00a0 [ RFC8126 ]. RFC8126  strongly suggests that guidance needs to be given to expert reviewers that are supposed to review and approve requests for \"Expert Review\" and \"Specification Required\" registries. This guidance is missing here. What's also missing are designated contact persons and a change controller. Section 5.6, paragraph 2, discuss: > 5.6.\u00a0 CSR Template Extensions > >\u00a0 \u00a0 IANA is requested to establish a registry \"STAR Delegation CSR >\u00a0 \u00a0 Template Extensions\", with \"Expert Review\" as its registration >\u00a0 \u00a0 procedure. Same as above.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-15 08:00:11-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-15 07:29:27-08:00",
    "text": "I'll keep this as brief as possible: Since this is Informational, I suggest not using  BCP 14 .\u00a0 But it sounds like the WG wanted this to be binding, which means it should be going for BCP status. Let's sort this out.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-03-02 07:48:13-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-25 07:04:46-08:00",
    "text": "Thank you for the work put into this document. I have not had time to review in details though :( but I appreciated the detailed description as well as the useful time diagrams. Please find below one blocking DISCUSS point (which may be my bad understanding), some non-blocking COMMENT points (but replies would be appreciated). I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 7.3.1 -- LINKLOCAL-IPV6-ID-ADDRESS TLV: I fail to understand why there are two addresses in this TLV while others have one one ? Also is 'local' and 'remote' really global addresses ?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-24 17:58:00-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 16:37:43-08:00",
    "text": "[ section 7.3.1 ] * This intended handling of the LINKLOCAL-IPV6-ID-ADDRESS TLV does not seem \u00a0 to be discussed anywhere in this document.\u00a0 Should there be some text \u00a0 about it, or is this TLV left over from previous iterations of the document? * Saying that the LINKLOCAL-IPV6-ID-ADDRESS TLV holds a pair of global IPv6 \u00a0 addresses seems confusing to me. \u00a0 If the pair of global IPv6 addresses is to be considered \"on link\" in the \u00a0 sense that IPv6 ND can be successfully be performed on the link for both \u00a0 of these addresses, then \"ONLINK\" might be better than LINKLOCAL. * Also, why are two interface IDs required?\u00a0 I would have expected that only \u00a0 the outgoing interface name/ID would be of relevance to the recipient of \u00a0 a message with TLV in it?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-09-08 23:06:48-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-12 06:20:53-07:00",
    "text": "his document seems to have unresolved IANA issues, so I am holding a DISCUSSfor IANA until the issues are resolved.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-31 10:16:45-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-05 14:04:28-07:00",
    "text": "This should be quite easy to resolve; I'm just not sure yet which direction the resolution will be. I think we should be a little more clear about whether the client can override the finalRecipient calculation (or just provide a suggestion to do so, or not give any input at all, etc.): the description of the finalRecipient property of an MDN object says that \"if set, it overrides the value that would be calculated by the server from the Identity\", which to me suggests that the client could set something to override the server (if the server sua sponte did something different that would typically be an \"exception\", not an \"override\"), but later on in Section 2.1 we say that \"[w]hen sending the MDN, the server is in charge of generating the \"originalRecipient\", \"finalRecipient\" and \"originalMessageId\" fields according to the [ RFC8098 ] specification.\u00a0 I do not see discussion in  RFC 8098  of client intput into the server's populating of this field, so I'm unsure whether/where the client has input.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-05-22 22:09:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 22:50:38-07:00",
    "text": "## Discuss ### S5.1 *  RFC 6724  source address selection is not sufficient.\u00a0 Many complexities \u00a0 are captured in  RFC 8678 .\u00a0 As  RFC 8475  notes, what's really required to \u00a0 make this work for some nodes is proper next-hop selection in conjunction \u00a0 with source address selection.\u00a0 Either that, or some kind of source-aware \u00a0 routing for forwarding nodes. \u00a0 For originating packets, depending on the topology, the following options \u00a0 can in theory be made to work: \u00a0 \u00a0 * implementing  RFC 6724  rule 5.5, but it's not currently mandatory \u00a0 \u00a0 * implementing  RFC 6724  section 4 recommendation \"that the candidate \u00a0 \u00a0 \u00a0 source addresses be the set of unicast addresses assigned to the \u00a0 \u00a0 \u00a0 interface that will be used to send to the destination (the \"outgoing\" \u00a0 \u00a0 \u00a0 interface)\" -- but this is highly dependent upon interface config \u00a0 \u00a0 * use of PVD Options ( RFC 8801 ) throughout the interior (and, ideally, an \u00a0 \u00a0 \u00a0 IETF-defined PVD End System model) \u00a0 I'm don't think that it's worth going into all this detail in this document, \u00a0 necessarily.\u00a0 You might see if a mix of references to and/or quotations from \u00a0 8678, 8475, and/or mention of the issue of next-hop selection in conjunction \u00a0 with source address selection yields sufficiently concise text to warn the \u00a0 IPv6-multihoming-unfamiliar reader: \"here be dragons (hic sunt dracones)\".",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-04-21 06:22:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 18:23:46-07:00",
    "text": "Thanks for a clear document and thanks to Kathleen for the SecDir review. I have one minor DISCUSS item that can probably be resolved easily by adding a sentence or two. [1] \u00a0  The DOTS client SHOULD use the certificate \u00a0  provided by a provisioning domain to authenticate itself to the DOTS \u00a0  server(s) provided by the same provisioning domain. This sentence suggests there is either another authentication method, or it allows for unauthenticated DOTS clients. If the latter, than I would expect a significant Security Considerations section on how to avoid/reduce malicious clients impact of such a setup. eg I could envision a compromised device from falsely reporting a DDOS attack from a certain network to block the compromised device/network from receiving traffic from certain remote networks.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-22 14:24:58-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-17 15:21:25-08:00",
    "text": "Thanks for this -- it was a good read.\u00a0 I just have a few super-boring poitns of apparent internal inconsistency to fix before publication. There seems to be an internal inconsistency relating to the handling of link-local addresses by a Bridging Proxy: Section 8 descriptively says that such addresses are (always) registered (\"[t]he Bridging Proxy registers any Binding including for a Link-Local address to the 6LBR\"), but Section 9 has this behavior as optional (\"[a] Bridging Proxy MAY register Link Local addresses at the 6BBR and proxy ND for these addresses over the backbone\"). Similarly, I see Section 6 saying that when a 6BBR generates an NA in response to an NS(DAD), it \"MUST have the Override flag set\", but Section 9.2 says \"MUST be answered ... the Override flag not set\" (for the \"different registration\" case, i.e., second bullet) and nothing at all about the Override flag for the \"not as fresh\"/\"Moved\" case (i.e., the third bullet).\u00a0 Am I misreading something? Continuing the theme, Section 10 notes that a \"Registering Node SHOULD register all of its IPv6 Addresses to its 6LR, which is the 6BBR when they are connected at Layer 2\", but Appendix B states the stronger condition that \"[t]he 6BBR assumes that if a node registers at least one IPv6 Address to it, then the node registers all of its Addresses to the 6BBR.\"",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-21 17:58:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 15:32:28-08:00",
    "text": "Section 11.\u00a0 Can assumptions of the about the security properties of the links be clarified.  This specification applies to LLNs and a backbone in which the \u00a0  individual links are protected against rogue access, e.g., by \u00a0  authenticating a node that attaches to the network and encrypting at \u00a0  the MAC layer the transmissions that may be overheard.\u00a0 In \u00a0  particular, the LLN MAC is required to provide secure unicast to/from \u00a0  the Backbone Router and secure Broadcast from the Backbone Router in \u00a0  a way that prevents tampering with or replaying the RA messages. -- what are the specific assumptions about the protections that will be on the link.\u00a0 Is the list of properties in the \u201ce.g.\u201d the full list? -- As the second sentence references the only the LLN MAC, using Figure 1 and 2 as a reference (realizing they are non-normative), what\u2019s expected properties of the links between the router-and-6BBR or IPv6 node-and-6BBR (i.e., the links connecting to the \u201cbackbone side\u201d)?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-19 07:01:16-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-09 09:15:14-07:00",
    "text": "he intended status needs to be changed to Proposed Standard before approval.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 14:57:32-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-09 16:42:55-07:00",
    "text": "I recognize that this document is trying to take the track of \"we recognize that some implementations/deployments violate  RFC 8200 , and while we don't condone that behavior, we want to provide diagnostics to try to mitigate the fallout from them\", but I'm not sure it succeeds in all cases.\u00a0 The discussion in Section 5.1 that is quite clear about \"does not advocate behaviors that might be considered nonconformant\", but there is another usage in Section 2.2 (\"[t]his code SHOULD be sent by an intermediate node that discards a packet because it encounters a Next Header type that is unknown in its examination\") that seems worth revisiting.\u00a0 Perhaps we can reword to be more clear that this is the recommended behavior subject to the predicate that an  RFC 8200  violation has occurred, which is not itself a recommended behavior. In light of the updated usage described in Section 2.2, should we direct IANA to make the \"Reference\" column for the \"unrecognized Next Header type encountered\" parameter problem list both this document and  RFC 4443 ?\u00a0 (It currently does not list any reference, as is the case for many entries on the containing page...) This codepoint is not currently mentioned in the IANA Considerations at all",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-27 02:24:55-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-27 02:15:09-08:00",
    "text": "Thank you for the work done in this document. I have only a single blocking DISCUSS that it trivial to fix: absence of  BCP 14  boilerplate for a standards track document ;-) Suggestion to the authors: add the  BCP14  boilter plate and re-upload a revised version before other IESG members' evaluations. -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-14 16:37:57-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 22:30:06-07:00",
    "text": "(1) and (2) should be easy to fix; (3) may well be \"fixed\" by telling me I'm too naive :) (1) Given that section 1 describes other options, the abstract should not limit to just DHCP and RA as options for provisioning the API URL. (2) Section 4.1 says that: \u00a0  5.\u00a0 The Captive Portal API server indicates to the Enforcement Device \u00a0 \u00a0 \u00a0  that the User Equipment is allowed to access the external \u00a0 \u00a0 \u00a0  network. but I believe this should be the \"Captive Portal Server\" (or, as the previous point has it, the \"web portal\"). (3) Probably a \"discuss discuss\", but ... in Section 1 we have: \u00a0  *\u00a0 Solutions SHOULD NOT require the forging of responses from DNS or \u00a0 \u00a0 \u00a0 HTTP servers, or any other protocol.\u00a0 In particular, solutions \u00a0 \u00a0 \u00a0 SHOULD NOT require man-in-the-middle proxy of TLS traffic. I'd like to understand the motivation for this one a little better. Naively, it seems like we could get away with \"MUST NOT require\" while still allowing it to be done.\u00a0 Am I missing something obvious?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-08 11:58:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-06-08 08:06:12-07:00",
    "text": "Sec 2.3\u00a0 says: At minimum, the API MUST provide: (1) the state of captivity and (2) a URI for the Captive Portal Server. But in section 5 of capport-api, user-portal-url is an optional field. Both a capport-api author and a WG chair agreed that the architecture doc should be fixed, so I'm moving the DISCUSS here.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-08 23:05:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-08 11:58:07-07:00",
    "text": "AFAICT this Discuss still applies to draft-09. Sec 2.3\u00a0 says: At minimum, the API MUST provide: (1) the state of captivity and (2) a URI for the Captive Portal Server. But in section 5 of capport-api, user-portal-url is an optional field. Both a capport-api author and a WG chair agreed that the architecture doc should be fixed, so I'm moving the DISCUSS here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-24 11:28:59-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-25 15:51:00-07:00",
    "text": "(1) This should be pretty easy to resolve, but this text from \u00a74.4 does not seem to match up with the referenced document: \u00a0  The use of TLS places even stronger operational burdens on DNS \u00a0  clients and servers.\u00a0 Cryptographic functions for authentication and \u00a0  encryption requires additional processing.\u00a0 Unoptimized connection \u00a0  setup takes two additional round-trips compared to TCP, but can be \u00a0  reduced with TCP Fast Open, TLS session resumption [ RFC8446 ] and TLS \u00a0  False Start [ RFC7918 ]. Two additional round trips was true of TLS 1.2 and prior versions, but as of TLS 1.3 the application data from the client can be sent after only 1 round trip, accompanying the client Finished (and authentication messages, if in use).\u00a0 Given the nature of the rest of the sentence, we might want to specifically mention TLS 1.3 as an improvement over TLS 1.2, but there are probably a number of ways that we could fix it.\u00a0 Note additionally that for TLS 1.3, session resumption is not a reduction in the number of round trips unless 0-RTT data is used (but AFAIK there is not a published application profile specifying acceptable DNS content for TLS 0-RTT data, so use of TLS 0-RTT data for DNS is forbidden), but is still an efficiency gain due to the reduced number of cryptographic operations (including certificate validation). (2) Trivial to address, but the section heading for Appendix A.8 references  RFC 3326  (The Reason Header Field for the Session Initiation Protocol (SIP)), not  RFC 3226  (DNSSEC and IPv6 A6 aware server/resolver message size requirements)",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-12-17 01:04:46-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-26 04:35:38-07:00",
    "text": "Section 4.2. , paragraph 3, discuss: >\u00a0 \u00a0 Since host memory for TCP state is a finite resource, DNS clients and >\u00a0 \u00a0 servers MUST actively manage their connections.\u00a0 Applications that do >\u00a0 \u00a0 not actively manage their connections can encounter resource >\u00a0 \u00a0 exhaustion leading to denial of service.\u00a0 For DNS, as in other >\u00a0 \u00a0 protocols, there is a tradeoff between keeping connections open for >\u00a0 \u00a0 potential future use and the need to free up resources for new >\u00a0 \u00a0 connections that will arrive. For it to contain a MUST-level requirement, this section needs to give a lot more concrete guidance on what it means to \"actively\" manage connections. Most operating systems by default impose some application limits that usually effectively prevent DOS or other resource exhaustion issues. Is the intent here that DNS implementations need to do more? If so, what?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-05 13:49:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-25 15:01:46-07:00",
    "text": "This document has a dedicated section for DNS over TLS, makes a number of configuration recommendations for DoT, and notes it in the Privacy Considerations.\u00a0 However, there is no mention of DNS over HTTPS (DoH).\u00a0 It seems like DoH should get similar treatment.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-09-23 07:17:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-21 08:21:19-07:00",
    "text": "I would like to discuss the extensibility of the model as described in section 3 regarding 'qos-classification-policy' when UDP is used as substrate. See more in my comments bellow.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-01 12:52:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-01 12:32:07-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required.  When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just vaguely gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-01 12:52:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-01 12:52:11-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required. Furthermore, if triggering Map-Requests is the concern, couldn't the packet still be delivered, without triggering a Map-Request? When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just vaguely gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-01 12:52:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-01 12:52:42-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required. Furthermore, if triggering Map-Requests is the concern, couldn't the packet still be delivered, without triggering a Map-Request? When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-24 14:15:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 12:52:57-07:00",
    "text": "This spec makes liberal use of the approach of dropping any packet received with an unloved Map-Version number, for example (but not limited to) \u00a0  2.\u00a0 The packet arrives with a Dest Map-Version number newer (as \u00a0 \u00a0 \u00a0  defined in Section 6) than the one stored in the EID-to-RLOC \u00a0 \u00a0 \u00a0  Database.\u00a0 Since the ETR is authoritative on the mapping, meaning \u00a0 \u00a0 \u00a0  that the Map-Version number of its mapping is the correct one, \u00a0 \u00a0 \u00a0  this implies that someone is not behaving correctly with respect \u00a0 \u00a0 \u00a0  to the specifications.\u00a0 In this case, the packet carries a \u00a0 \u00a0 \u00a0  version number that is not valid and packet MUST be silently \u00a0 \u00a0 \u00a0  dropped. Isn\u2019t it the case that by definition the packet has arrived at a valid ETR for the mapping (since as the text says, \u201cthe ETR is authoritative\u201d)? Isn\u2019t the map-version more in the nature of a hint than a critical-for-correctness field? What bad behavior is being protected against by silently dropping this traffic, that has arrived at a correct endpoint albeit with an incorrect hint? At various points in the document there's a kind of vague assertion that incorrect map-versions could be an attack. While I don't deny that, the assertion isn't supported or elaborated on anywhere that I saw, which is worrying and also makes it less convincing. Shouldn't the Security Considerations talk about this? I did also go have a look at the Security Considerations in  draft-ietf-lisp-rfc6833bis-31 , which also didn't help me.  RFC 7835  \u00a73.3 does touch on this, suggesting that maybe an attacker could use a spoofed Map-Version to trigger a DoS attack. But this, too, is an unsatisfying rationale, since as you take pains to point out, rate limiting of Map-Requests and such is required. Furthermore, if triggering Map-Requests is the concern, couldn't the packet still be delivered, without triggering a Map-Request? When this was an Experimental protocol this kind of thing was probably less crucial to justify and explain, but I would have expected the experiment to produce results that could be fed into this document. At the moment, the \"drop any packet that doesn't comply with expectations\" design feels arbitrary and potentially brittle. I would appreciate some discussion of this design choice, thanks in advance. (I do acknowledge that security matters can be subtle, and I'm not a SEC AD after all... but all the more reason for the document to be explicit about what the security concerns are instead of just gesturing toward them and leaving the reader to guess.)",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-23 19:11:19-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 08:43:15-07:00",
    "text": "Changed my comments to a DISCUSS, as Donald Eastlake also pointed these out in his secdir review, and I am now convinced we need better text to address this. #1\u00a0 map-version rollover is defined (to skip the 0 version) but I also see: The packet arrives with a Dest Map-Version number greater (i.e., \u00a0 \u00a0 \u00a0  newer) than the one stored in the EID-to-RLOC Database.\u00a0 Since \u00a0 \u00a0 \u00a0  the ETR is authoritative on the mapping, meaning that the Map- \u00a0 \u00a0 \u00a0  Version number of its mapping is the correct one This would imply rollover to a smaller number is not expected to occur ? #2 MUST NOT or SHOULD ? Map-Versioning MUST NOT be used over the public Internet and SHOULD only be used in trusted and closed deployments. This sentence seems to contradict itself. I would turn the SHOULD into a MUST",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-07-13 14:04:50-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 11:54:49-07:00",
    "text": "On the -11 document, I initial wrote the following: The SECDIR review by Donald Eastlake asked about handling roll-over/wrap-around of the Map Version Number.\u00a0 Specifically, can a \u201cMap Version Number advance[e] \u2026 so quickly that an old version number is encountered that appears to be newer than or equal to the current version number. Why can't this happen? Or if it can, why doesn't that hurt?\u201d\u00a0 It would appear that a number of the conclusions of the ITR or ETR on arriving packets in Section 7.1 and 7.2 wouldn\u2019t be correct. I then saw the -12 document published on June 1 which added the following text to Section 7: \u00a0  Map Version Number incrementing \u00a0  and mappings' TTL MUST be managed so that an old version number will \u00a0  not be confused as a new version number. Thank you for adding this text.\u00a0 Practically, this identifies the desired intent, but doesn\u2019t seem describe the mechanics.\u00a0 Can more be said about how this confusion will be mitigated at the ITR/ETRs?\u00a0 I also don't follow how to use the TTLs here. Consider the situation that Donald noted where the Map Version advanced so quickly that it wraps around so that: (a) the new Map Version Number value equals the old Map Version Number.\u00a0 If one followed the guidance in Section 7.1 of: \u00a0  1.\u00a0 The packet arrives with the same Dest Map-Version number stored \u00a0 \u00a0 \u00a0  in the EID-to-RLOC Database.\u00a0 This is the regular case.\u00a0 The ITR \u00a0 \u00a0 \u00a0  sending the packet has in its EID-to-RLOC Map-Cache an up-to-date \u00a0 \u00a0 \u00a0  mapping.\u00a0 No further actions are needed. It would seem that the ITR wouldn\u2019t do a Map-Request and would misroute the packet based on the old mapping. (b) the new Map Version Number is now smaller (but in fact fresher/newer)\u00a0 If one followed the guidance of Section 7.1. of: 3.\u00a0 The packets arrive with a Dest Map-Version number smaller (i.e., \u00a0 \u00a0 \u00a0  older) than the one stored in the EID-to-RLOC Database.\u00a0 This \u00a0 \u00a0 \u00a0  means that the ITR sending the packet has an old mapping in its \u00a0 \u00a0 \u00a0  EID-to-RLOC Map-Cache containing stale information. Per bullet #3, if there was wrap-around would the ITR in fact be sending stale mapping information?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-01 15:48:58-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 00:29:46-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of concerns that need to be cleared up before the document can move forward. --------------------------------------------------------------------------- \u00a74.3.4 discusses the interaction of 3PCC with the trickle ICE mechanism. Unfortunately, the diagrams used in this section do not show a 3PCC signaling flow; they show a two-party call flow with an offerless INVITE. A 3PCC call flow would necessarily involve a 3PCC controller sending an offerless INVITE to one party, receiving an offer from that party (typically in a reliable provisional response or in a 200 OK), and then sending an INVITE to the other party containing that offer. The text in this section matches the diagrams, and consequently does not appear to be an analysis of 3PCC behavior. It is an analysis of two-party offerless INVITE behavior. If this section remains, it needs to be substantially re-worked: the diagrams need to show three parties, with a 3PCC controller performing the controlling role as described in  RFC 3725 . While I haven't stepped through the implications for Trickle ICE when a controller is actually involved and is moving offers and answers around between different message types, I suspect that the analysis in here is substantially different once this starts happening. I would personally be okay if the entire section were removed; however, I have no desire to override working group consensus regarding the value of a section dealing with 3PCC considerations. --------------------------------------------------------------------------- The second issue doesn't necessarily pertain to this document per se as much as it does the interaction among this document,  draft-ietf-ice-trickle  (Trickle ICE),  draft-ietf-mmusic-ice-sip-sdp  (ICE SDP), and  draft-ietf-rtcweb-jsep (JSEP). The problem doesn't lie with any single document, but in the overall result of how they're currently structured. JSEP (in the RFC editor queue) refers to the \"a=end-of-candidates\" SDP attribute as appearing in Trickle ICE, section 9.3, which was true at one point in time. Somewhere along the line, this attribute's definition was moved from there into this document. There are several ways to fix this, each with their own drawbacks: 1. Move the SDP syntax for \"a=end-of-candidates\" back into the Trickle ICE \u00a0  draft. Drawback: Trickle ICE does not currently define any normative SDP \u00a0  behavior; and, in fact, could work in a system that doesn't use SDP at all. 2. Move the SDP syntax into the ICE SDP draft. This is pretty elegant from the \u00a0  perspective that ICE SDP defines SDP syntax for ICE in general (for both \u00a0  SIP and JSEP), and such a move aggregates all of the SDP syntax into a \u00a0  single document that is already necessary to reference from any document \u00a0  that uses SDP for Trickle ICE. Drawback: the document doesn't presently \u00a0  discuss Trickle ICE at all, and this would require a somewhat awkward \u00a0  section that basically says \"If you use [Trickle ICE] with SDP, the syntax \u00a0  for the end-of-candidate marker is...\" 3. Change JSEP to normatively depend on this document for the \u00a0  \"a=end-of-candidates\" syntax. Drawback: This document is extremely \u00a0  SIP-specific, while JSEP is based solely on  RFC 4566  syntax and  RFC 3264 \u00a0  behavior, independent of any SIP semantics.\u00a0 Forcing JSEP to normatively \u00a0  depend on a SIP specific document for a simple attribute syntax definition \u00a0  seems to be letting the tail wag the dog. I believe that #2 is the least inelegant option, but I'm open to #1 and #3. However, The *current* situation -- in which JSEP normatively points to a document from which the text is cites has been removed out from under it -- is clearly wrong.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-22 13:43:11-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-01 15:48:58-07:00",
    "text": "Thanks to everyone who worked on this document. I have a couple of concerns that need to be cleared up before the document can move forward. --------------------------------------------------------------------------- \u00a74.3.4 discusses the interaction of 3PCC with the trickle ICE mechanism. Unfortunately, the diagrams used in this section do not show a 3PCC signaling flow; they show a two-party call flow with an offerless INVITE. A 3PCC call flow would necessarily involve a 3PCC controller sending an offerless INVITE to one party, receiving an offer from that party (typically in a reliable provisional response or in a 200 OK), and then sending an INVITE to the other party containing that offer. The text in this section matches the diagrams, and consequently does not appear to be an analysis of 3PCC behavior. It is an analysis of two-party offerless INVITE behavior. If this section remains, it needs to be substantially re-worked: the diagrams need to show three parties, with a 3PCC controller performing the controlling role as described in  RFC 3725 . While I haven't stepped through the implications for Trickle ICE when a controller is actually involved and is moving offers and answers around between different message types, I suspect that the analysis in here is substantially different once this starts happening. I would personally be okay if the entire section were removed; however, I have no desire to override working group consensus regarding the value of a section dealing with 3PCC considerations. [document reference issue removed -- this document will probably not need to change to address the issue]",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-06-29 14:35:02-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-02 15:54:24-07:00",
    "text": "\u00a0  the Offer (as would be the case when Half Trickle is performed or \u00a0  when new candidates have not been learned since then). IMPORTANT: They must be in order, right? \u00a0  'application/trickle-ice-sdpfrag' bodies do not interfere with the \u00a0  Offer/Answer procedures as specified in [ RFC3264 ]. IMPORTANT: \"pseudo\" m= lines are not defined in 5888 so this is very unclear. \u00a0  sent under the same combination of \"a=ice-pwd:\" and \"a=ice-ufrag:\" in \u00a0  the same order as they were gathered.\u00a0 In other words, the sequence \u00a0  of a previously sent list of candidates MUST NOT change in subsequent IMPORTANT: This appears to conflict with the guidance in Section 6 of the trickle document, which is about reordering candidates from how they were gathered.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-07-02 01:49:55-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-03 07:36:54-07:00",
    "text": "Thanks for the well-written doc and the quick response to the initial tsv review. Also thanks to J\u00f6rg for the thorough and very helpful review! As flagged by the tsv review, there can be an issue with the aggregation of candidates in one INFO message when rate limited and the path MTU/UPD fragmentation. While this is a small point only and I'm sure it can be easily addressed, it important enough that I decided to put a discuss in. I'm sure this can be resolved quickly as well.  Also if the document could give further guidance on an acceptable maximum for the rate of INFO requests that be even better!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-11 15:29:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-03-23 21:43:27-07:00",
    "text": "I think we need some greater clarity on the relationship between IOAM \"layers\" and IOAM-Namespaces.\u00a0 For example, in Section 4 there is a principle of \"Layering\" that seems to indicate that different layers operate entirely independently, such as might occur when traffic from one operator that uses IOAM is conveyed in a tunnel over a different operator's network and both operators use IOAM independently.\u00a0 But in Section 5.3 we seem to see some discussion that IOAM-Namespaces can be used to enforce a separation of layers (\"IOAM-Namespaces provide additional context [...] e.g. if an operator wishes to use different node identifiers for different IOAM layers\"), and that namespace identifiers allow for determination of which IOAM-Option-Types need to be processed \"in case of a layered IOAM deployment\". I think there is also some internal inconsistency relating to the role of IOAM transit nodes.\u00a0 This may be localised in Section 5.2 where we see both that a transit node is one that \"read and/or write or process [the] IOAM data\" and that a transit node \"updates one or more of the IOAM-Data-Fields\" (i.e., always writes), but I did not attempt an exhaustive check for other instances. I don't think the definition of the POSIX epoch is correct -- it seems to be copied (roughly) from the definition of the PTP epoch (i.e., using midnight TAI as the reference) but all the references I consulted indicate that the POSIX epoch started at midnight UTC. As foreshadowed in https://mailarchive.ietf.org/arch/msg/last-call/Ak2NAIKQ7p4Rij9jfv123xeTXQY/ I think we need to have a discussion about the expectations and provisions for cryptographic (e.g., integrity) protection of IOAM data. From my perspective, IOAM is a new (class of) protocols that is seeking publication on the IETF stream as Proposed Standard.\u00a0 While we do make exceptions for modifications to protocols that were developed before we realized how important integrated security mechanisms are, it's generally the case that new protocols are held to the current IETF expectations for what security properties are provided; the default expectation is that a protocol is expected to provide secure operation in the internet threat model of  RFC 3552 .\u00a0 This draft currently only provides a brief note in the security considerations that there exists an individual draft ( draft-brockners-ippm-ioam-data-integrity ) that might provide ways to protect the integrity of IOAM data fields. Shouldn't the security mechanisms be getting developed side-by-side by the protocol mechanisms, to ensure that they are properly integrated and fit for purpose?\u00a0 (This does not necessarily have to be in the same document and could be part of a cluster of related documents, but I don't think that an informative reference to a non-WG draft really qualifies.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-08 14:38:52-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-11 15:29:47-07:00",
    "text": "Thanks for the many updates and email discussion about the relationship between limited (network) domains, IOAM domains, IOAM namespaces, and the like -- I think I do now have a pretty clear picture of how they're expected to interact!\u00a0 However, I think there may still be a couple places in the document that need to get updated in order to match that vision.\u00a0 One point here, and some (more minor) instances in the COMMENT section... Section 5.2 has: \u00a0  The role of an IOAM-encapsulating, IOAM-transit or IOAM-decapsulating \u00a0  node is always performed within a specific IOAM-Namespace.\u00a0 This \u00a0  [...] \u00a0  described above, that is added in a future revision.\u00a0 An IOAM \u00a0  decapsulating node situated at the edge of an IOAM domain MUST remove \u00a0  all IOAM-Option-Types and associated encapsulation headers for all \u00a0  IOAM-Namespaces from the packet. The \"MUST remove [...] for all IOAM-Namespaces\" at the end seems to conflict with the notion of the role of IOAM-decapsulating node being performed within a specific IOAM-Namespace.\u00a0 Indeed, later on in Section 5.3 we see that namespace identifiers \"allow devices which are IOAM capable to determine: [...] o\u00a0 whether IOAM-Option-Type(s) have to be removed from the packet, e.g., at a domain edge or domain boundary.\"\u00a0 If a decapsulating node always had to remove IOAM options from all namespaces, then the namespace identifier is irrelevant to whether option type(s) are removed from the packet. [the following paragraph is retained unchanged from my ballot position on the -12, since the topic seems to still be open.] As foreshadowed in https://mailarchive.ietf.org/arch/msg/last-call/Ak2NAIKQ7p4Rij9jfv123xeTXQY/ I think we need to have a discussion about the expectations and provisions for cryptographic (e.g., integrity) protection of IOAM data. From my perspective, IOAM is a new (class of) protocols that is seeking publication on the IETF stream as Proposed Standard.\u00a0 While we do make exceptions for modifications to protocols that were developed before we realized how important integrated security mechanisms are, it's generally the case that new protocols are held to the current IETF expectations for what security properties are provided; the default expectation is that a protocol is expected to provide secure operation in the internet threat model of  RFC 3552 .\u00a0 This draft currently only provides a brief note in the security considerations that there exists an individual draft ( draft-brockners-ippm-ioam-data-integrity ) that might provide ways to protect the integrity of IOAM data fields. Shouldn't the security mechanisms be getting developed side-by-side by the protocol mechanisms, to ensure that they are properly integrated and fit for purpose?\u00a0 (This does not necessarily have to be in the same document and could be part of a cluster of related documents, but I don't think that an informative reference to a non-WG draft really qualifies.) [new disucssion on this topic as of the -15] The discussion on this topic was over a rather protracted timescale, for which I share much of the blame.\u00a0 I think that the latest message is https://mailarchive.ietf.org/arch/msg/ippm/POycw2NpSl5cIruqSimTa_4WrwI/ where I make a proposal to have some text about how actual use of these data fields in a protocol or encapsulation needs to provide some (possibly optional) mechanism for cryptographic integrity protection, which could be  draft-brockners-ippm-ioam-data-integrity  but could also be native to the encapsulation format.\u00a0 I think that such a construction would allow this document to proceed to RFC without waiting for the other one to be complete.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-03-26 07:28:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-03-24 12:04:41-07:00",
    "text": "Thank you for this document. I think that the discussion on point 5. about referencing normatively IEEE 1588, and 11. about IANA Expert guidelines are worth having, and hope we can get them cleared before the document moves forward. Also, please find some minor comments below.  Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-06-24 11:24:55-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-26 07:28:53-07:00",
    "text": "EDIT(2021-03-26): I removed the question about IEEE1588v2 being normative. I look forward to discussion about 11., i.e. more details about IANA Expert guidelines. ---------- (2021-03-24) Thank you for this document. I think that the discussion on point 5. about referencing normatively IEEE 1588, and 11. about IANA Expert guidelines are worth having, and hope we can get them cleared before the document moves forward. Also, please find some minor comments below.  Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-08-18 23:24:57-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-25 05:29:41-07:00",
    "text": "Section 5.4, paragraph 6, discuss: >\u00a0 \u00a0 A particular implementation of IOAM MAY choose to support only one of >\u00a0 \u00a0 the two trace option types.\u00a0 In the event that both options are Not requiring at least one mandatory-to-implement trace option type is highly problematic, since it creates two incompatible flavors of this standard. Preventing bifurcation seems to trump the desire for allowing (minor?) optimizations.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-03-25 00:47:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-03-25 00:15:03-07:00",
    "text": "I'd also like to discuss what's going on in Section 8. Section 8.1, for instance, says that the registry covers 128 code points.\u00a0 The first seven entries are given, but it's not explicit that a registration comprises a code point and (apparently) a name.\u00a0 It's more typical to include a template that a new registration needs to include.\u00a0 You might require a requested code point number and a name at minimum, but also commonly included in such a template is a reference to the registering RFC.\u00a0 If I were to register a code point here in some later RFC, it would be awfully convenient to have the registry include a reference to that defining document.\u00a0 As it stands, the registry will only ever point to this one.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-08-11 22:07:08-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-25 00:47:57-07:00",
    "text": "I'd also like to discuss what's going on in Section 8. Section 8.1, for instance, says that the registry covers 128 code points.\u00a0 The first seven entries are given, but it's not explicit that a registration comprises a code point and (apparently) a name.\u00a0 It's more typical to include a template that a new registration needs to include.\u00a0 You might require a requested code point number and a name at minimum, but also commonly included in such a template is a reference to the registering RFC.\u00a0 If I were to register a code point here in some later RFC, it would be awfully convenient to have the registry include a reference to that defining document.\u00a0 As it stands, the registry will only ever point to this one. You might want to give  RFC 8126  a once-over, at least Section 2.2.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-10-04 04:56:21-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 08:05:49-07:00",
    "text": "Please clarify what constitutes the edge or boundary of the IOAM domain.\u00a0 Consider: (a) Section 4.\u00a0   IOAM is a \u00a0  network domain focused feature, with \"network domain\" being a set of \u00a0  network devices or entities within a single administration.\u00a0  \u2026 Designers of  \u00a0  protocol encapsulations for IOAM specify mechanisms to ensure that \u00a0  IOAM data stays within an IOAM domain.\u00a0 In addition, the operator of \u00a0  such a domain is expected to put provisions in place to ensure that \u00a0  IOAM data does not leak beyond the edge of an IOAM domain. (b) Section 5.3.\u00a0  Namespace identifiers allow devices which are IOAM capable to \u00a0  determine: \u2026 whether IOAM-Option-Type(s) has to be removed from the packet, \u00a0 \u00a0 \u00a0 e.g. at a domain edge or domain boundary. (a) suggests that the filtering occurs on the basis of the single administrative domain.\u00a0 However, (b) suggests that namespace identifiers are part of the filtering decision; which suggests that sub-domains can be created in a given domain which should be partitioned from each other. The Security Considerations should be clearer on who does the IOAM information filtering, on what criteria and on what boundary.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-07-02 14:21:45-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-20 21:40:52-07:00",
    "text": "Thanks for the work and thought that everyone involved in this document spent. I find the model well described and easy to understand. I agree with Ben's comments about including more information about the privacy and security properties of specific entities in the module. See https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines  for specific guidance. Since this conflicts with normative language in  RFC 6087  \u00a73.4 (and 6087bis \u00a73.7), it is a blocking defect that needs to be remedied prior to publication.",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-06-20 08:50:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-20 08:40:01-07:00",
    "text": "Operational state. Section 2 defines operational aspects of the configured TWAMP mechanisms as being out of scope. How does that relate to the motivation goals in section 1? Having no common machine readable mechanism for retrieving measurement results and verifying the operation of measurement processes does not seem to help in reducing the need for proprietary mechanisms.  If operational aspects are not out of scope, what is the compatibility of this model with NMDA?  Key storage. The document defines its own way of storing keys - while there are multiple existing ways to store keys (routing key-chain model, I2NSF, IPsec model, netconf-keystore). Why yet another key storage mechanism is required?",
    "type": "Discuss"
  },
  {
    "ad": "Ignas Bagdonas",
    "end": "2018-06-26 09:34:06-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-20 08:50:10-07:00",
    "text": "I have three large areas of questions related to this model. They are not related to the contents of the module itself but to the broader scope of where this model can and should fit in the overall context of practical manageability and usability.  1. Operational state. Section 2 defines operational aspects of the configured TWAMP mechanisms as being out of scope. How does that relate to the motivation goals in section 1? Having no common machine readable mechanism for retrieving measurement results and verifying the operation of measurement processes does not seem to help in reducing the need for proprietary mechanisms.  2. What is the compatibility of this model with NMDA?  3. Key storage. The document defines its own way of storing keys - while there are multiple existing ways to store keys (routing key-chain model, I2NSF, IPsec model, netconf-keystore). Why yet another key storage mechanism is required? What could be reused from other existing mechanisms?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-03-11 07:38:26-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-27 10:23:16-07:00",
    "text": "First of all, I am surprised that a document related to IGMP/MLD was not sent to the pim WG for review.\u00a0 I can't find any mention of this draft in the pim WG's archive. \u00a711 says this: \u00a0  This document does not provide any detail about IGMPv1 processing. \u00a0  Multicast working group are in process of deprecating uses of IGMPv1. \u00a0  Implementations MUST only use IGMPv2 and above for IPv4 and MLDv1 and \u00a0  above for IPv6.\u00a0 IGMP V1 routes MUST be considered as invalid and the \u00a0  PE MUST apply the \"treat-as-withdraw\" procedure as per [ RFC7606 ]. \u00a0  Initial version of document did mention use of IGMPv1 and flag had \u00a0  provision to support IGMPv1.\u00a0 There may be an implementation which is \u00a0  deployed as initial version of document, to interop flag has not been \u00a0  changed. Note that the \"Multicast working group\" mentioned above is in fact the pim WG.\u00a0 There's no current WG to deprecate IGMPv1, but  draft-ietf-pim-3376bis  was recently adopted with the intent to progress IGMPv3 to Internet Standard.\u00a0 This text is from  draft-ietf-pim-3376bis  (it is the same text as in  rfc3376 ): \u00a0  IGMPv3 is backward compatible with previous versions of the IGMP \u00a0  protocol.\u00a0 In order to remain backward compatible with older IGMP \u00a0  systems, IGMPv3 multicast routers MUST also implement versions 1 and \u00a0  2 of the protocol (see section Section 7). (Section 7/draft-ietf-pim-3376bis talks about interoperability with older versions.) All this is to say that requiring that IGMPv1 not be used contradicts the IGMPv3 specification, which requires the support.\u00a0 The interoperation between the different versions is already considered in  rfc3376 , so the extra complexity added to this document (tracking the versions in the BGP updates) is not needed from the router side. I am balloting DISCUSS because this document is not in line with other consensus documents (specifically the IGMP specification).\u00a0 To clear, I will want the document reviewed by the pim WG.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-24 18:55:44-08:00",
    "end_reason": "position_updated",
    "start": "2021-10-20 17:48:32-07:00",
    "text": "(1) Apparently each PE is supposed to store version flags for each other PE in the EVI (I guess on a per-route basis?), but this is mentioned just once, in passing, in step 2 of the Leave Group procedures in \u00a74.1.2. Similarly, \u00a76.1 defines, somewhat in passing, some \"local IGMP Membership Request (x,G) state\" that must be maintained in some cases. Let's discuss whether it's appropriate/useful to have a general introductory section that covers what new state PEs are expected to retain as part of supporting IGMP/MLD proxying.\u00a0 Maybe the answer is \"no\", but I would like to have the conversation. (2) I am not sure if the body text is consistent with what is being allocated from IANA.\u00a0 \u00a78 describes PEs that are not using ingress replication as being identifiable as \"\"\"any PE that has advertised an Inclusive Multicast Tag route for the BD without the \"IGMP Proxy Support\" flag\"\"\", but the IANA considerations allocate flags for both IGMP Proxy Support and MLD Proxy Support.\u00a0 Is a PE that advertises MLD Proxy Support but not IGMP Proxy Support to be treated as not using ingress replication, as the literal interpretation of this text would require?\u00a0 Similarly, \u00a79.2.1 and \u00a79.3.1 include restrictions on indication of support for \"IGMP Proxy\" with no mention of \"MLD Proxy\". I do see that there is a generic disclaimer at the end of Section 3 but the way it is written does not actually seem to cover this usage.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-04 03:58:21-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-20 01:28:09-07:00",
    "text": "Thank you for the work put into this document. I have to state that I am neither a EVPN expert not a multicast one. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to St\u00e9phane Litkowski for his shepherd's write-up about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == The text covers in details how to map MLD/IGMP into BGP routes but does not say a word on how to recreate the MLD/IGMP packets. Should there be any such specification ? Are all multicast group address treated as the same ? I would have appreciated some text about link-local multicast as well as global multicast groups addresses. -- Abstract -- While this point is pretty light for a blocking DISCUSS, let's fix it: - the abstract should also mention MLD and not only IGMP - what are 'the above services' ? -- Section 1 -- In the same vein, is it about IGMP only ? Or does it include MLD as well ? It is really unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-04 07:30:25-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-03-04 03:58:21-08:00",
    "text": "As Martin Vigoureux's term is near its end, I took the liberty to re-evaluate the ballot status of this document and clearing parts of my original block DISCUSS points and many of my original non-blocking COMMENT points. See below this line for updated version ---------------------------------------------- Thank you for the work put into this document. I have to state that I am neither a EVPN expert not a multicast one. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to St\u00e9phane Litkowski for his shepherd's write-up about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == The text covers in details how to map MLD/IGMP into BGP routes but does not say a word on how to recreate the MLD/IGMP packets. Should there be any such specification (e.g., in section 4.1) ? -- Section 1 -- In the same vein, is it about IGMP only ? Or does it include MLD as well ? It is really unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-07 23:32:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-04 07:30:25-08:00",
    "text": "As Martin Vigoureux's term is near its end, I took the liberty to re-evaluate the ballot status of this document and clearing parts of my original block DISCUSS points and many of my original non-blocking COMMENT points. See below this line for updated version ---------------------------------------------- Thank you for the work put into this document. I have to state that I am neither a EVPN expert not a multicast one. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to St\u00e9phane Litkowski for his shepherd's write-up about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 1 -- In the same vein, is it about IGMP only ? Or does it include MLD as well ? It is really unclear.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-10-27 23:33:52-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-21 07:22:59-07:00",
    "text": "The IANA Considerations section needs some work: (0) I suggest making each of the actions you want to take (there are four) into their own subsections of this section. (1) \"EVPN Extended Community sub-types registry\" should be \"EVPN Extended Community Sub-Types sub-registry of the BGP Extended Communities registry\", which makes it easier to find. (2) \"Multicast Flags Extended Community\" appears to be a new registry you're creating in the final action here.\u00a0  BCP 26 , for a First Come First Served registry, advises that a change controller column be included.\u00a0 Are you intentionally omitting this here?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-03-22 05:12:25-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-27 23:33:52-07:00",
    "text": "There's an IPR disclosure on this document.\u00a0 In the shepherd writeup, where a summary of the discussion of it is requested, it simply says \"There are 3 IPRs disclosed\".\u00a0 I'd like to hear that summary, or at least confirm the discussion was had and there were no concerns as a result. The IANA Considerations section needs some work: (0) I suggest making each of the actions you want to take (there are four) into their own subsections of this section. (1) \"EVPN Extended Community sub-types registry\" should be \"EVPN Extended Community Sub-Types sub-registry of the BGP Extended Communities registry\", which makes it easier to find. (2) \"Multicast Flags Extended Community\" appears to be a new registry you're creating in the final action here.\u00a0  BCP 26 , for a First Come First Served registry, advises that a change controller column be included.\u00a0 Are you intentionally omitting this here?\u00a0 Or if this is referring to an existing registry, I wasn't able to find it.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-10-24 11:51:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-10-23 20:11:18-07:00",
    "text": "Thanks for the work on this document. I have one item that I want to make sure is discussed prior to publication, thus the DISCUSS position: This document lists all the SDP attributes as having an a Mux Category of \"TBD\".  draft-ietf-mmusic-sdp-mux-attributes  did indeed assign a category of \"TBD\" to all the attributes, save for bfcpver, which didn't exist at the time. But the point of \"TBD\" was to say that  draft-ietf-mmusic-sdp-mux-attributes  did not actually analyze the attributes to determine a \"real\" mux category. It's not intended as free pass to let other attribute definitions skip that analysis.\u00a0  Ideally, I think that this draft should assign a \"real\" mux category for each attribute in it. Failing that, it at least needs to do so for \"bfcpver\". I'm guessing that should be \"caution\" or \"special\". (Perhaps unfortunately,  draft-ietf-mmusic-sdp-mux-attributes  did not define a category of \"nope\" :-) )",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-11-27 14:46:25-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-10-24 11:51:28-07:00",
    "text": "Update: After a bit of discussion and a re-read of  draft-ietf-mmusic-sdp-mux-attributes , I see that, while the use of \"TBD\" does not seem consistent with the definition of TBD, it does seem consistent with the practice in mux-attributes of assigning a category of TBD to attributes associated with non-muxable protocols. I've sent an email to the MMUSIC WG for guidance on the intended use. In the process, I noticed that the category assignments in this draft do not match the existing assignments in mux-attributes, which marks \"floorctrl\" as \"TBD\", and the others as \"NORMAL\". This draft marks all attributes as \"TBD\". I am going to hold the DISCUSS position for now, until discussion of the use of TBD resolves a bit further, and until the assignment mismatch is corrected. Original DISCUSS text: Thanks for the work on this document. I have one item that I want to make sure is discussed prior to publication, thus the DISCUSS position: This document lists all the SDP attributes as having an a Mux Category of \"TBD\".  draft-ietf-mmusic-sdp-mux-attributes  did indeed assign a category of \"TBD\" to all the attributes, save for bfcpver, which didn't exist at the time. But the point of \"TBD\" was to say that  draft-ietf-mmusic-sdp-mux-attributes  did not actually analyze the attributes to determine a \"real\" mux category. It's not intended as free pass to let other attribute definitions skip that analysis.\u00a0  Ideally, I think that this draft should assign a \"real\" mux category for each attribute in it. Failing that, it at least needs to do so for \"bfcpver\". I'm guessing that should be \"caution\" or \"special\". (Perhaps unfortunately,  draft-ietf-mmusic-sdp-mux-attributes  did not define a category of \"nope\" :-) )",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-12-21 12:53:47-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-27 14:46:25-08:00",
    "text": "The category assignments in this draft do not match the existing assignments in mux-attributes, which marks \"floorctrl\" as \"TBD\", and the others as \"NORMAL\". This draft marks all attributes as \"TBD\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-25 04:44:39-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 17:18:36-07:00",
    "text": "I will go ahead and say that we should discuss the \"UDP/TLS/BFCP\" naming. In particular, while I see the previous discussion that there may be existing deployments out there, why can we not give it the same treatment as \"mstrm\", and make the official name \"UDP/DTLS/BFCP\" while documenting that you should accept the old name? We also had a very long discussion about the usage of the term \"initial  offer\" in the context of  draft-ietf-mmusic-sdp-bundle-negotiation ; I do not propose to rehash that discussion, but want to ask whether we should stick to the established precedent with regard to the use of the term (which, IIUC, would involve a change to this document).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-11-21 14:33:29-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-24 12:23:33-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4457 DETAIL S 9. >\u00a0 \u00a0 \u00a0 transport is used for the default candidate, then the 'm' line proto >\u00a0 \u00a0 \u00a0 value MUST be 'UDP/TLS/BFCP'.\u00a0 If TCP transport is used for the >\u00a0 \u00a0 \u00a0 default candidate, the 'm' line proto value MUST be 'TCP/DTLS/BFCP'. >\u00a0   >\u00a0 \u00a0 \u00a0 \u00a0  Note: Usage of ICE with protocols other than UDP/TLS/BFCP and >\u00a0 \u00a0 \u00a0 \u00a0  TCP/DTLS/BFCP is outside of scope for this specification. this is very different from any other use of ICE, and I'm not sure it's interoperable, unless you require that only TCP or only UDP candidates be offered (which you do not seem to). The reason is that with ICE you can flip between different candidates as part of the negotiation. So what happens if I initially get a UDP candidate and then via aggressive nomination settle on TCP (or vice versa). DTLS and TLS aren't really interoperable in that way. It would be far better to do what WebRTC does and when you do ICE, always do DTLS even if it's over TCP.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-04-07 07:26:19-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 07:29:00-07:00",
    "text": "Thank you for the work on this document. I have noticed one easy to fix error in the examples, and I additionally have two comments I'd like to talk about before the document is approved - these are non blocking, but answers are appreciated. Thanks, Francesca 1. ----- \u00a0  In this case, an interface named \"Bundle-Ether1\" of interface type \u00a0  \"ieee8023adLag\" has a desired transmit interval and required receive \u00a0  interval set to 10 ms. FP: But the example actually uses intervals of 100ms: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  100000 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  100000 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-04-07 06:55:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 09:39:46-07:00",
    "text": "Thanks for this specification. I have noticed couple of potentially normative missing references hence the discuss ballot. * iana-bfd-types is imported from  RFC9127 \u00a0 but missing in the normative reference. * ietf-key-chain is imported from  RFC8177 \u00a0 but missing in the normative reference. I hope a revised ID\u00a0 would solve this.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-09 07:24:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 04:44:07-07:00",
    "text": "This is a process discuss.  There apparently have been a failure to coordinate this with IEEE per discussion on the IETF-IEEE mailing list.  Glenn Parsons requested that this was deferred to give IEEE time to review it at their plenary next week. I think this time should be given before approving this document.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-17 09:50:12-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 05:12:36-07:00",
    "text": "I support Magnus's discuss regarding IEEE 802.1Q WG review. I also feel that the YANG model could benefit from another editorial pass:  - In many places the descriptions are very terse, and references are missing.  - The way that auto-neg is defined doesn't really match the 802.3 specification, probably splitting it into two separate leaves (one for whether auto-neg is on/off, and separate one for the duplex setting would be better).  - The use of terminology for VLAN vs QinQ might not be acceptable to IEEE.\u00a0 Finding names that are more closely aligned with the terms in 802.1Q may be helpful (although if I understand it correctly, 802.1Q bridges don't directly expose double VLAN tags).\u00a0 Possibly some of the terminology/description from  draft-ietf-netmod-sub-intf-vlan-model  (which has been reviewed by IEEE 802.1Q WG) may be helpful here.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-08-12 07:02:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-11 06:29:05-07:00",
    "text": "Thank you for the work put into this document. Special thanks to Ole Tr\u00f8an for his shepherd's write-up, which contains a good summary of the WG consensus and the SW (?) implementation status. Thanks as well to Bob Halley for his INT directorate review. Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated). I also agree with DISCUSS points by other ADs: - Lars's one about the size and usefulness of FlowMonID (see my very similar point) - Roman's one about the inconsistencies about limited domain (from my point of view, this should not be limited to a single domain) All in all, I strongly suggest to change the intended status of this document to 'experimental' as this document builds on experimental RFCs. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == This discussion already happened in the 6MAN WG but I still have to be convinced that hop-by-hop is a good idea at all. The fate of packets with HbH is unknown at best and, IMHO, this is a wrong use of HbH because the forwarding/processing of packets is NOT influenced at all by the AltMark option. What is required is a simple 'marking/coloring', which could be at any place in a packet (including destination option). The only benefit of HbH is its location just after the IPv6 header. After all, existing devices can measure and generate IPFIX records in hardware/fastpath by inspecting at the bare minimum the 5-tuple and many devices can also parse extension headers in the fast path (of course not processing HbH in this case). I.e., finding the marking in the Dest Option is probably much easier and doable in current hardware rather than using HbH as HbH forces a software processing. -- Section 2 -- \u00a0 \"In the end, [ I-D.fioccola-v6ops-ipv6-alt-mark ] demonstrated that a \u00a0  new Hop-by-Hop or a new Destination Option was the best approach.\" The above draft has not been published and is even expired for 2 years now... so please remove the 'demonstrated' as there is no proof at all ;-) -- Section 4 -- Please remove \"the destination node removes it\" as there is no reason to remove it. Extension headers are usually not presented / used by upper layers anyway.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-10-07 02:25:24-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-12 07:02:20-07:00",
    "text": "Thank you for the work put into this document. As Brian Carpenter kindly reminded me that an Area Director may not put back a previous argument when the WG consensus was to ignore it, I am updating this ballot by moving the generic DISCUSS as a COMMENT. The other two DISCUSS points remains blocking ones but Giuseppe have already addressed them over email, I am clearing the DISCUSS position as soon as the revised I-D is posted. Special thanks to Ole Tr\u00f8an for his shepherd's write-up, which contains a good summary of the WG consensus and the SW (?) implementation status. Thanks as well to Bob Halley for his INT directorate review. Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated). I also agree with DISCUSS points by other ADs: - Lars's one about the size and usefulness of FlowMonID (see my very similar point) - Roman's one about the inconsistencies about limited domain (from my point of view, this should not be limited to a single domain) All in all, I strongly suggest to change the intended status of this document to 'experimental' as this document builds on experimental RFCs. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2 -- \u00a0 \"In the end, [ I-D.fioccola-v6ops-ipv6-alt-mark ] demonstrated that a \u00a0  new Hop-by-Hop or a new Destination Option was the best approach.\" The above draft has not been published and is even expired for 2 years now... so please remove the 'demonstrated' as there is no proof at all ;-) -- Section 4 -- Please remove \"the destination node removes it\" as there is no reason to remove it. Extension headers are usually not presented / used by upper layers anyway.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-25 11:16:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-25 11:15:47-07:00",
    "text": "There are a few points I'd like to DISCUSS before moving this forward. The first should be easy to address: 1. The number of authors (6) exceeds the maximum recommended by the RFC Editor (5), see  RFC 7322  \u00a74.1.1. Has this exception already been cleared with the AD? I see no mention of it in the shepherd writeup. (Speaking of the shepherd writeup, and this is a comment for the shepherd and not the authors and is only an aside, not something that needs to be addressed in the DISCUSS, the writeup answer to question 1 is incomplete. ) The second is substantive rather than administrative, and may require more discussion: 2. From what I understand of the rules about IPv6 extension header insertion (viz, only end nodes can do it), plus the assumptions stated in \u00a72.1.1 about the extent of the \"controlled domain\", it would seem a natural consequence\u00a0 that ipv6-alt-mark is only applicable to networks where user traffic enters and exits a tunnel at the perimeter of the \"controlled domain\". I don't see this stated plainly anywhere in the document. If I'm correct this seems like an important characteristic to spell out. If I'm incorrect, I'd appreciate a discussion of where I went wrong. I touch on various aspects of this overall point in some of my comments as well. Finally, although I haven't placed any of the further comments in the DISCUSS section, I noted that some of them are fairly fundamental so I would appreciate a thorough reply to the comments as well.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-25 11:16:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-25 11:16:11-07:00",
    "text": "There are a few points I'd like to DISCUSS before moving this forward. The first should be easy to address: 1. The number of authors (6) exceeds the maximum recommended by the RFC Editor (5), see  RFC 7322  \u00a74.1.1. Has this exception already been cleared with the AD? I see no mention of it in the shepherd writeup. (Speaking of the shepherd writeup, and this is a comment for the shepherd and not the authors and is only an aside, not something that needs to be addressed in the DISCUSS, the writeup answer to question 1 is incomplete.) The second is substantive rather than administrative, and may require more discussion: 2. From what I understand of the rules about IPv6 extension header insertion (viz, only end nodes can do it), plus the assumptions stated in \u00a72.1.1 about the extent of the \"controlled domain\", it would seem a natural consequence\u00a0 that ipv6-alt-mark is only applicable to networks where user traffic enters and exits a tunnel at the perimeter of the \"controlled domain\". I don't see this stated plainly anywhere in the document. If I'm correct this seems like an important characteristic to spell out. If I'm incorrect, I'd appreciate a discussion of where I went wrong. I touch on various aspects of this overall point in some of my comments as well. Finally, although I haven't placed any of the further comments in the DISCUSS section, I noted that some of them are fairly fundamental so I would appreciate a thorough reply to the comments as well.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-07-12 13:39:30-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-25 11:16:41-07:00",
    "text": "There are a few points I'd like to DISCUSS before moving this forward. The first should be easy to address: 1. The number of authors (6) exceeds the maximum recommended by the RFC Editor (5), see  RFC 7322  \u00a74.1.1. Has this exception already been cleared with the AD? I see no mention of it in the shepherd writeup. (Speaking of the shepherd writeup, and this is a comment for the shepherd and not the authors and is only an aside, not something that needs to be addressed in the DISCUSS, the writeup answer to question 1 is incomplete.) The second is substantive rather than administrative, and may require more discussion: 2. From what I understand of the rules about IPv6 extension header insertion (viz, only end nodes can do it), plus the assumptions stated in \u00a72.1.1 about the extent of the \"controlled domain\", it would seem a natural consequence\u00a0 that ipv6-alt-mark is only applicable to networks where user traffic enters and exits a tunnel at the perimeter of the \"controlled domain\". I don't see this stated plainly anywhere in the document. If I'm correct this seems like an important characteristic to spell out. If I'm incorrect, I'd appreciate a discussion of where I went wrong. I touch on various aspects of this overall point in some of my comments as well. Finally, although I haven't placed any of the further comments in the DISCUSS section, I note that some of them are fairly fundamental so I would appreciate a thorough reply to the comments as well.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-26 07:05:24-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-06 02:36:00-07:00",
    "text": "Section 2.1. , paragraph 4, discuss: >\u00a0 \u00a0 Therefore, the IPv6 application of the Alternate Marking Method MUST >\u00a0 \u00a0 NOT be deployed outside a controlled domain. That's not what Section 6 says, which allows use outside a controlled domain (across the Internet) if protection is applied? Section 2.1. , paragraph 4, discuss: >\u00a0 \u00a0 Some scenarios may imply that the Alternate Marking Method is applied >\u00a0 \u00a0 outside a controlled domain, either intentionally or unintentionally, >\u00a0 \u00a0 but in these cases, IPsec authentication and encryption MUST be used. How can one require use of IPsec for an unintentional use outside of a controlled domain? If the header leaks by accident, surely it's unreasonable to expect that IPsec had been set up to catch any and all such possible leakage? Also (as a comment), if IPsec is required by this document, it needs to be normatively cited. Section 5.3.1. , paragraph 2, discuss: >\u00a0 \u00a0 It is important to note that if the 20 bit FlowMonID is set >\u00a0 \u00a0 independently and pseudo randomly there is a chance of collision. >\u00a0 \u00a0 Indeed, by using the well-known birthday problem in probability >\u00a0 \u00a0 theory, if the 20 bit FlowMonID is set independently and pseudo >\u00a0 \u00a0 randomly without any additional input entropy, there is a 50% chance >\u00a0 \u00a0 of collision for 1206 flows.\u00a0 So, for more entropy, FlowMonID can >\u00a0 \u00a0 either be combined with other identifying flow information in a >\u00a0 \u00a0 packet (e.g. it is possible to consider the hashed 3-tuple Flow >\u00a0 \u00a0 Label, Source and Destination addresses) or the FlowMonID size could >\u00a0 \u00a0 be increased. It seems odd to define a dedicated FlowMonID, but make it so short that it is basically not usable in many realistic scenarios. If other parts of the packet headers need to be inspected to disambiguate FlowMonID collisions, this (1) should at least be more carefully specified in this document (since every node will need to do it in the same way) but (2) probably argues for a much longer FlowMonID - why not make it 64 bits or longer? The IANA review of this document seems to not have concluded yet; I am holding a DISCUSS for IANA until it has.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-08-10 17:01:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-09 17:11:16-07:00",
    "text": "I have some concerns about this approach, plus some points of confusion that hopefully will clear up quickly. I support Lars's first two DISCUSS points. (1) I am unclear about the relationship between limited domains and the prohibition against modifying either option before the destination. Is the intent that (a) this is only used for traffic that begins and ends in the domain; (b) user traffic is encapsulated with an outer IPv6 header that is removed prior to domain exit; or (c) the \"destination\" actually means the egress point from the domain? (2) Relatedly, if the source nodes are\u00a0 user-generated packets, how is this in practice a limited domain? Source nodes have enormous power to degrade the measurement by sending packets that fill the entire FlowMon space with only 1M packets, which not only consumes router resources but also pollutes every single measurement in the domain.   (3) The draft informatively references the (Experimental) RFCs 8321 and 8889 and covers some of the same ground, but as a Proposed Standard. Is part of the purpose here to update these RFCs? For other measurement techniques, we've had a generic measurement draft in IPPM and encapsulations in the appropriate protocol-specific groups like 6man. Why was that approach not taken here? Will future encapsulations of alternate marking refer to this one normatively on how to conduct the measurement? (4) Are there any restrictions on FlowMon IDs? Need these be pseudorandom, or can they encode information in the clear? (5) I don't understand the basic motivation for using HBH options if these can result in the packet being diverted to the slow path on intermediate nodes. This seems like a major drawback for a delay measurement! (6) Sec 5.1: When using timer-based batches, I gather you use times well in excess of potential reordering. If using a counter-based method, how does the measurement account for potential reordering? There could easily be a very large instantaneous burst followed by a path change that lowered the latency.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-31 08:45:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-10 17:01:25-07:00",
    "text": "I have some concerns about this approach, plus some points of confusion that hopefully will clear up quickly. I support Lars's first two DISCUSS points. (edited) (1) The precise use case is unclear to me. An end-user (not in the controlled domain)\u00a0 generates an IPv6 packet, and I gather some sort of middlebox then inserts the header if it meets some criteria (perhaps that the destination IP is also within the domain). If this is correct, I would like to check with the experts if a non-endpoint inserting a header is compliant with  RFC8200 . Also, this should be written down somewhere. If not correct, I have many more questions. (2) The draft informatively references the (Experimental) RFCs 8321 and 8889 and covers some of the same ground, but as a Proposed Standard. Is part of the purpose here to update or obsolete these RFCs?  (3) Are there any restrictions on FlowMon IDs? Need these be pseudorandom, or can they encode information in the clear? (4) Sec 5.1: When using timer-based batches, I gather you use times well in excess of potential reordering. If using a counter-based method, how does the measurement account for potential reordering? There could easily be a very large instantaneous burst followed by a path change that lowered the latency.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-04-28 09:09:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-31 08:45:23-07:00",
    "text": "Thanks for addressing most of my DISCUSS points. I would like an unambiguous statement in Section 3.1 that the FlowMonID MUST appear to be random. There is still language that suggests it might not be: (e.g., \"The disambiguation issue is more visible when the FlowMonID is pseudorandomly generated...\". If it is anything less than a MUST, there needs to be additional Security Considerations to reflect the impact of not doing so.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-08-12 07:28:07-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-11 23:17:36-07:00",
    "text": "A procedural question about the IPR disclosures, which I expect we can clear up during the telechat in a few hours: Though there have been two IPR disclosures on this document, the shepherd writeup conspicuously claims there has been no discussion about either.\u00a0 For at least one of them the licensing terms indicate a fee may apply.\u00a0 As this is seeking Proposed Standard status, I'd like to inquire about this.\u00a0 In particular, Section 4 of  BCP 79  says: \u00a0 \u00a0 \u00a0 A working group may take into \u00a0 \u00a0 \u00a0 consideration the results of this procedure in evaluating the \u00a0 \u00a0 \u00a0 technology, and the IESG may defer approval when a delay may \u00a0 \u00a0 \u00a0 facilitate obtaining such assurances. I note the \"may\", but still it feels like an important step was missed here.\u00a0 So: Was there an implicit conclusion that the IPR claims don't hinder the technology?\u00a0 Or did nobody check it out?\u00a0 Or did the WG decide consciously not to worry about it?\u00a0 Or is it actually fine to just ignore them?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-10 13:03:25-08:00",
    "end_reason": "position_updated",
    "start": "2021-08-09 13:48:45-07:00",
    "text": "Please provide consistent guidance on where this methodology can be used.\u00a0 Consider: (a) Section 2.1. \u201cTherefore, the IPv6 application of the Alternate Marking Method MUST NOT be deployed outside a controlled domain.\u201d (b) Section 2.1.\u00a0 \u201cSome scenarios may imply that the Alternate Marking Method is applied outside a controlled domain, either intentionally or unintentionally, but in these cases, IPsec authentication and encryption MUST be used.\u201d (c) Section 6. \u201cThis document aims to apply a method to perform measurements that does not directly affect Internet security nor applications that run on the Internet.\u201d (d) Section 6. \u201cAs stated above, the precondition for the application of the Alternate Marking is that it MUST be applied in specific controlled domains, thus confining the potential attack vectors within the network domain.\u00a0  (e) Section 6. \u201cIn this case, the user, aware of the kind of risks, may still want to use Alternate Marking for telemetry and test purposes but the inter-domain links need to be secured (e.g., by IPsec) in order to avoid external threats.\u00a0 For these specific scenarios the application of the Alternate Marking Method outside a controlled domain is possible but IPsec through AH\u00a0 \u00a0 (Authentication Header) or ESP (Encapsulating Security Payload) MUST be used.\u201d (a) and (d) seem to very clear that this approach MUST only be used in a controlled domain.\u00a0 However (b) and (d) seem to suggest that this prohibition is at best a \u201cSHOULD\u201d.\u00a0 If (b) and (d) are true, than (c) not affecting applications on the internet might not be true. ** Section 6.\u00a0 Thanks for mentioning \u201cAt the management plane, attacks can be set up by misconfiguring or by maliciously configuring AltMark Option.\u201d\u00a0 Please be clearer on what these attacks could look like.\u00a0 Would these include: -- using the FlowMonId as a tracking identifier? -- (Likely possible at both the data and management plane would be a) covert channel between the sender and an on-path observer?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-05-17 16:01:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-11 14:21:36-07:00",
    "text": "I must be missing something fairly fundamental here. \"As stated above, the precondition for the application of the \u00a0  Alternate Marking is that it MUST be applied in specific controlled \u00a0  domains, thus confining the potential attack vectors within the \u00a0  network domain.\u00a0 [ RFC8799 ] analyzes and discusses the trend towards \u00a0  network behaviors that can be applied only within a limited domain. \u00a0  This is due to the specific set of requirements especially related to \u00a0  security, network management, policies and options supported which \u00a0  may vary between such limited domains.\u00a0 A limited administrative \u00a0  domain provides the network administrator with the means to select, \u00a0  monitor and control the access to the network, making it a trusted \u00a0  domain.\u00a0 In this regard it is expected to enforce policies at the \u00a0  domain boundaries to filter both external packets with AltMark Option \u00a0  entering the domain and internal packets with AltMark Option leaving \u00a0  the domain.\u00a0 Therefore the trusted domain is unlikely subject to \u00a0  hijacking of packets since packets with AltMark Option are processed \u00a0  and used only within the controlled domain.\" The above says that this must only be done in a limited/controlled domain, and that operators are: \"expected to enforce policies at the domain boundaries to filter both external packets with AltMark Option entering the domain and internal packets with AltMark Option leaving the domain.\". The \"only do this in in limited domain\" seems to simply punt on the security concerns / considerations. What is an operator supposed to do if their device doesn't understand this option? Are you really suggesting that everyone needs to do though and update edge firewall filters everywhere to block this? What happens when a filter is unintentionally missed? Or when the device cannot filter N headers deep?  [edit firewall family inet6 filter altmark term demo] wkumari@rtr2.pa o# set from extension-header ? Possible completions: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Range of values \u00a0 [\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Open a set of values \u00a0 ah\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Authentication header \u00a0 any\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Any extension header \u00a0 dstopts\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Destination options \u00a0 esp\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Encapsulating security payload \u00a0 fragment\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Fragment \u00a0 hop-by-hop\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Hop by hop options \u00a0 mobility\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Mobility \u00a0 routing\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Routing Yes, many networks use automation to apply filters, but it is still unreasonable to force operators to have to keep updating and deploying new filters when new protocols are created.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:39:21-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-29 13:21:17-08:00",
    "text": "Thank you for the work on this document. Many thanks to Julian Reschke for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/XfLbtK1eLb7s0Z6e_AqGgkoWny0/ . I have one DISCUSS point that has to do with IANA considerations, and is hopefully easy to resolve. Francesca 1. ----- FP: I am sure the Designated Expert will bring this up, but \"iss\" is already defined as a OAuth Parameter, for authorization requests. I don't think it's a good idea to use the same parameter name, although in a different message of the exchange, for something different, as the registration defined in Section 5.2 seems to imply. I strongly recommend to change the name in this document. Or, if we can agree that the meaning is similar enough to the original \"iss\", merge the two IANA registrations (this would not be my preferred choice).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-02 04:34:45-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:39:21-08:00",
    "text": "Thank you for the work on this document. Many thanks to Julian Reschke for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/XfLbtK1eLb7s0Z6e_AqGgkoWny0/ . I have one DISCUSS point that has to do with IANA considerations, and is hopefully easy to resolve. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- FP: I am sure the Designated Expert will bring this up, but \"iss\" is already defined as a OAuth Parameter, for authorization requests. I don't think it's a good idea to use the same parameter name, although in a different message of the exchange, for something different, as the registration defined in Section 5.2 seems to imply. I strongly recommend to change the name in this document. Or, if we can agree that the meaning is similar enough to the original \"iss\", merge the two IANA registrations (this would not be my preferred choice).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-08-02 13:17:09-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 14:19:06-07:00",
    "text": "\u00a79 (\"Results of the Multipoint Alternate Marking Experiment\") makes several  recommendations about the use of one or two flag bits: \u00a0 \u00a0  One flag: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 6 by applying the network clustering partition described \u00a0 \u00a0 \u00a0 in Section 5.\u00a0 While delay measurement MAY be done according to \u00a0 \u00a0 \u00a0 the Mean delay calculation representative of the multipoint path, \u00a0 \u00a0 \u00a0 as described in Section 7.1.1.\u00a0 Single-marking method based on the \u00a0 \u00a0 \u00a0 first/last packet of the interval cannot be applied, as mentioned \u00a0 \u00a0 \u00a0 in Section 7.2.1. \u00a0 \u00a0 \u00a0 Two flags: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 6 by applying the network clustering partition described \u00a0 \u00a0 \u00a0 in Section 5.\u00a0 While delay measurement SHOULD be done on a single \u00a0 \u00a0 \u00a0 packet basis according to double-marking method Section 7.2.1.\u00a0 In \u00a0 \u00a0 \u00a0 this case the Mean delay calculation (Section 7.1.1) MAY also be \u00a0 \u00a0 \u00a0 used as a representative value of a multipoint path. \u00a0 \u00a0 \u00a0 One flag and hash-based selection: packet loss measurement SHOULD \u00a0 \u00a0 \u00a0 be done as described in Section 6 by applying the network \u00a0 \u00a0 \u00a0 clustering partition described in Section 5.\u00a0 Hash-based selection \u00a0 \u00a0 \u00a0 methodologies, introduced in Section 7.2.2, MAY be used for delay \u00a0 \u00a0 \u00a0 measurement. These recommendations are good, as they are the result of experimentation.\u00a0  However, they don't provide any deployment or operational guidelines of when  it is ok to follow them and when it isn't.\u00a0 For example, for the one flag case,  when it is ok to not measure packet loss as described in \u00a76?\u00a0 Why is the use  of that mechanism only recommended and not required? I have the same questions for all the recommendations and optional indications  in the text above.\u00a0 To clear this DISCUSS I expect deployment or operational  recommendations that can be used as implementation/deployment guidance.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-07-12 08:29:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-07-12 08:28:33-07:00",
    "text": "Thanks for this document. As you may have noticed I had considerable difficulty with the definition of \"cluster\". Once I completed an end-to-end read-through, this was resolved (good!) but because RFCs are often consumed piecemeal (e.g. someone may just dip into a portion of a document rather than settling down with a nice cup of tea to read it end-to-end), I think it's important to fix this problem, on the assumption I'm not the only person who might be thrown off. I'll leave the details in the COMMENT, but I will repeat one observation from my comment #3, which is that I count at least four separate (re-)definitions of \"cluster\" in the document. With so many, it's no wonder that they're inconsistent, and quite likely the cleanest solution would involve cutting the number of definitions down to as close to 1 as possible.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-18 12:27:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 08:29:30-07:00",
    "text": "Thanks for this document. As you may have noticed I had considerable difficulty with the definition of \"cluster\". Once I completed an end-to-end read-through, this was resolved (good!) but because RFCs are often consumed piecemeal (e.g. someone may just dip into a portion of a document rather than settling down with a nice cup of tea to read it end-to-end), I think it's important to fix this problem, on the assumption I'm not the only person who might be thrown off. I'll leave the details in the COMMENT, but I will repeat one observation from my comment #3, which is that I count at least four separate (re-)definitions of \"cluster\" in the document. With so many, it's no wonder that they're inconsistent, and quite possibly the simplest solution would involve cutting the number of definitions down to as close to 1 as possible.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-29 02:11:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 11:37:16-07:00",
    "text": "# GEN AD review of  draft-ietf-ippm-rfc8889bis-02 CC @larseggert Thanks to Russ Housley for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/OTAnYgNGwDIRaQu_9IDo1QN1KHM ). ## Discuss ### Section 1, paragraph 11 ``` \u00a0 \u00a0  Note that the fragmented packets case can be managed with the \u00a0 \u00a0  Alternate-Marking methodology.\u00a0 The same considerations of \u00a0 \u00a0  [ I-D.ietf-ippm-rfc8321bis ] apply also in the case of Multipoint \u00a0 \u00a0  Alternate Marking.\u00a0 As defined in [ I-D.ietf-ippm-rfc8321bis ] the \u00a0 \u00a0  marking node MUST mark all the fragments except in the case of \u00a0 \u00a0  fragmentation within the network domain, in that event it is \u00a0 \u00a0  suggested to mark only the first fragment. ``` \"MUST mark ... except\" is not clear enough. In the case where there is fragmentation, what is the defined behavior? \"Suggest to mark\" leaves a lot open to interpretation. In general, the use of  RFC2119  language in this document should be checked. See comments below.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-05 09:38:54-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 11:19:54-07:00",
    "text": "Please clarify the expected deployment model of this approach. (a) Section 9. \u00a0  The Multipoint Alternate Marking Method is RECOMMENDED only for \u00a0  controlled domains, as per [ I-D.ietf-ippm-rfc8321bis ]. (b) Section 10 \u00a0  This document specifies a method of performing measurements that does \u00a0  not directly affect Internet security or applications that run on the \u00a0  Internet. The text in (a) suggests that deployment can occur on the Internet (although it isn\u2019t recommended).\u00a0 However, (b) suggests that OAM meta-data would not be used on the Internet.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-04-06 14:03:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-04-06 14:02:43-07:00",
    "text": "Although the document is largely clear and well-written (thanks for that), I was left with one burning question: what are these sub-TLVs *for*? There\u2019s no specification for what the router is supposed to do with them, only how to originate them. The only clue I get is buried down in Section 5: \u00a0  The identification of the node that is originating a specific prefix \u00a0  in the network may aid in debugging of issues related to prefix \u00a0  reachability within an OSPF network. If their purpose is to act as debugging aids, I think the least you should at least say so briefly in the abstract and introduction. If they have some purpose beyond that, it\u2019s missing from the doc.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-04-07 17:37:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-06 14:03:32-07:00",
    "text": "Although the document is largely clear and well-written (thanks for that), I was left with one burning question: what are these sub-TLVs *for*? There\u2019s no specification for what the router is supposed to do with them, only how to originate them. The only clue I get is buried down in Section 5: \u00a0  The identification of the node that is originating a specific prefix \u00a0  in the network may aid in debugging of issues related to prefix \u00a0  reachability within an OSPF network. If their purpose is to act as debugging aids, I think you should at least say so briefly in the abstract and introduction. If they have some purpose beyond that, it\u2019s missing from the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-05 07:09:38-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 06:44:04-08:00",
    "text": "The shepherd writeup (which has a note that it is still in progress and not ready for submission) indicates that the \"IPR questions are pending\". Please confirm that they were affirmatively resolved.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-11 22:32:07-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 12:32:51-08:00",
    "text": "Quite minor points, really, but they do need to be resolved before publication.\u00a0 (Slightly more details/locations in the COMMENT section.) We don't actually provide a definition (whether directly or by reference) for the \"classic calculation for standard deviation of a population\". We don't actually provide a definition (whether directly or by reference) for what the \"time_offset\" calibration value records.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-12-03 10:37:26-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 05:55:49-08:00",
    "text": "Thank you for the work put into this document.  I have a couple of easy and trivial to fix DISCUSS. And a couple of COMMENTs, feel free to ignore the COMMENTs but I would appreciate it if you replied to them. Regards, -\u00e9ric == DISCUSS == -- Section 4.2.2 -- Easy to fix: there is no 'protocol' field in the IPv6 header but a 'next header' one that has the same semantic. -- Section 9.2.2. -- Also easy to fix, 'next header' for ICMPv6 is not 01 but 58 (decimal) and 'ICMPv6 echo request' is 128 (decimal).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-12-12 00:36:25-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 02:10:30-08:00",
    "text": "I think these entries shows well how the registry is intended to extended and the benefit in being clear on what information is needed. I do have a question that I think needs an answer: Regarding Section 4.2.2: \u00a0  o\u00a0 IPv6 header values: \u00a0 \u00a0 \u00a0 *\u00a0 DSCP: set to 0 \u00a0 \u00a0 \u00a0 *\u00a0 Hop Count: set to 255 \u00a0 \u00a0 \u00a0 *\u00a0 Protocol: Set to 17 (UDP) Does anything about the IPv6 flow ID need to be stated here? As this is a path delay measurement, the value of the flow ID field has the potential to change the result. If one would use a new random value for each individual measurement in a sequence one may see different results than from using the same ID for all the measurements. Or is this specified in any of the references? In most case I would expect one use a single value, but likely randomly selected. However, it does depend on what purpose of ones measurement one have, thus I think this do matter.  I think this question applies to all measurements that are multi-packet ones so section 5, 7, 8 and 9 most definitely.  I also wonder if IPv6 Flow ID is an output parameter that needs to be kept?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-09 21:51:44-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 17:46:44-08:00",
    "text": "I have a 0-RTT-related topic that I'd like to discuss, as the current situation isn't entirely clear to me.\u00a0 In particular, TLS 1.3 provides (and QUIC inherits) a mechanism for a server to advertise that it just does not support 0-RTT at all, via the (absence of the) \"early_data\" extension.\u00a0 This meshes nicely with the guidance in  RFC 8446  that 0-RTT is to only be used cautiously, and only with specific request from the application.\u00a0 However, this specificiation diverges from that requirement for application opt-in (per \u00a79.1), and so when I read the directive in \u00a75.5 that \"servers MUST adopt one of the following behaviors\", I am forced to wonder if the absence of a \"abort the connection, because you do not enable early data at all\" option is intended to forbid a server from taking that approach and thus require servers to implement and enable 0-RTT at runtime. I hope that the intent was just for the \u00a75.5 listing to be predicated on the server using 0-RTT at all, but it's hard to reach that conclusion from the existing text, so I have to seek clarification.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-02-08 19:17:51-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 15:40:52-08:00",
    "text": "I plan to ballot \"yes\" for this document, but I have some concerns about the security properties that I think need to be resolved first. I have followed the discussion resulting from Robert's Gen-ART review (and will have comments about that in the \"COMMENTS section\", but I think I see an additional issue that hasn't been covered in that discussion. draft-ietf-bfcpbis-rfc4582bis  (currently in the RFC Editors queue) defines some situations where TLS and client authentication are normatively required. Specifically, section 9 of that draft says that, if the signaling channel is authenticated and has confidentiality and integrity protection, the BFCP client MUST be authenticated. Section 14 additionally says that under those circumstances, BFCP is REQUIRED to use the mandated cryptographic algorithm. But bfcp-websocket only says that WSS and client authentication are RECOMMENDED. I think this could be fixed by requiring WSS, and the web-based client authentication techniques described in this draft whenever the signaling protocol is secured. The simplest way to describe that might be to say that BFCP-websocket must use at least as strong protections as the signaling channel.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-10-06 07:46:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-06 07:46:18-07:00",
    "text": "The text contains contradictions on how to handle implementation-time use case that might use the YANG file format. (a) Section 2. \u201cThe file MUST be available already at implementation time, retrievable in a way that does not depend on a live network node.\u00a0 E.g., download from product website.\u201d (b) Section 2. \u201cThe YANG modules specified in this document define a schema for data that is designed to be accessed via network management protocols such as NETCONF [ RFC6241 ] or RESTCONF [ RFC8040 ].\u00a0 \u2026 The Network Configuration Access Control Model (NACM) [ RFC8341 ] provides the means to restrict access for particular NETCONF or RESTCONF users\u201d (c) Section 2.\u00a0 \u201cWhen that data is in file format, data should be protected against modification or unauthorized access using normal file handling mechanisms.\u201d (a) \u2013 (c) cannot all be satisfied at the same time.\u00a0 (b) seems to only apply to the run-time use cases.\u00a0 (a) and (b) seem to apply to the implementation time use cases.\u00a0 Please make this clearer.\u00a0  Per (c), it might be clearer to keep this text, but also noting that using the YANG file format inherits all of the security considerations of  draft-ietf-netmod-yang-instance-file-format  which has additional considerations about read protections; and distinguishing between data at rest and in motion.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-10-14 15:05:51-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 07:46:32-07:00",
    "text": "The text contains contradictions on how to handle implementation-time use case that might use the YANG file format. (a) Section 2. \u201cThe file MUST be available already at implementation time, retrievable in a way that does not depend on a live network node.\u00a0 E.g., download from product website.\u201d (b) Section 2. \u201cThe YANG modules specified in this document define a schema for data that is designed to be accessed via network management protocols such as NETCONF [ RFC6241 ] or RESTCONF [ RFC8040 ].\u00a0 \u2026 The Network Configuration Access Control Model (NACM) [ RFC8341 ] provides the means to restrict access for particular NETCONF or RESTCONF users\u201d (c) Section 2.\u00a0 \u201cWhen that data is in file format, data should be protected against modification or unauthorized access using normal file handling mechanisms.\u201d (a) \u2013 (c) cannot all be satisfied at the same time.\u00a0 (b) seems to only apply to the run-time use cases.\u00a0 (a) and (b) seem to apply to the implementation time use cases.\u00a0 Please make this clearer.\u00a0  Per (c), it might be clearer to keep this text, but also noting that using the YANG file format inherits all of the security considerations of  draft-ietf-netmod-yang-instance-file-format  which has additional considerations about read protections; and distinguishes between data at rest and in motion.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-09-22 20:33:55-07:00",
    "text": "Many thanks for taking on the task of producing a roll-up update for the core TCP specification!\u00a0 I am sure it was a lot of work, but I am happy to see it done. That said, I do have a few points that I would like to have a bit more discussion on before the document is published; I'm happy to see that Warren already linked to https://www.ietf.org/blog/handling-iesg-ballot-positions/  on the topic of what a DISCUSS position can (and cannot) mean. (1) We incorporate some long-standing enhancements that improve the security and robustness of TCP (in particular, random ISN and protection against off-path in-window attacks come to mind), but only at SHOULD or MAY requirements level. For example, we currently say: \u00a0  A TCP implementation MUST use the above type of \"clock\" for clock- \u00a0  driven selection of initial sequence numbers (MUST-8), and SHOULD \u00a0  generate its Initial Sequence Numbers with the expression: \u00a0  ISN = M + F(localip, localport, remoteip, remoteport, secretkey) and: \u00a0 \u00a0 \u00a0 \u00a0  +\u00a0  RFC 5961  [37] section 5 describes a potential blind data \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 injection attack, and mitigation that implementations MAY \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 choose to include (MAY-12).\u00a0 TCP stacks that implement \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  RFC 5961  MUST add an input check that the ACK value is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [...] What prevents us from making a MUST-level requirement for randomized ISNs?\u00a0 Is it just the fact that it was only a SHOULD in  RFC 6528  and a perception that promoting to a MUST would be incompatible with retaining Internet Standard status? Likewise, what prevents using stronger normative language (e.g., MUST) for the  RFC 5961  protections? It seems to me that these mechanisms are of general applicability and provide significant value for use of TCP on the internet, even though they are not fully robust and do not use cryptographic mechanisms.\u00a0 If there are scenarios where their use is harmful or even just not applicable, that seems like an exceptional case that should get documented so as to strengthen the general recommendation for the non-exception cases. (2) I think this is just a process question to ensure that the IESG knows what we are approving at Internet Standard maturity, though it is certainly possible that I misunderstand the situation. In Section 3.7.3 we see the normative statement (SHLD-6) that \"when the when the effective MTU of an interface varies packet-to- packet, TCP implementations SHOULD use the smallest effective MTU of the interface to calculate the value to advertise in the MSS option\".\u00a0 This seems to originate in  RFC 6691  (being obsoleted by this document), but  RFC 6691 is only an Informational document and has not had an opportunity to \"accumulate experience at Proposed Standard before progressing\", to paraphrase  RFC 6410 . Similarly, Section 3.9.2 has (SHLD-23) \"Generally, an application SHOULD NOT change the DiffServ field value during the course of a connection (SHLD-23).\"\u00a0 This is a bit harder to track down, as the DiffServ field was not always known by that name.\u00a0 I actually failed to find a directly analogous previous statement of this guidance (presumably my error), and thus don't know if it had any experience at the PS level or not. RFC 6410  seems pretty clear that some revisions are okay in Internet Standards without such \"bake time\" at PS, but it does seem like something that should be done consciously rather than by accident. (3) This is also a process point for explicit consideration by the IESG. Appendix A.2 appears to discuss a few (rare) scenarios in which the technical mechanisms of this document fail catastrophically (e.g., getting stuck in a SYN|ACK loop and failing to complete the handshake). Does this meet the \"resolved known design choices\" and \"no known technical omission\" bar required by  RFC 2026  even for *proposed* standard? (Note that  RFC 2026  explicitly says that the IESG may waive this requirement, at least for PS.) (AFAICT one such scenario is reported at https://www.rfc-editor.org/errata_search.php?eid=3305  , which the change log for this document calls out as \"not applicable due to other changes\"; I am not sure which \"other changes\" are intended, for this case.) (4) Another point mostly just to get explicit IESG acknowledgment (elevating one of Lars' comments to DISCUSS level, essentially). As the changelog (and gen-art reviewer!) notes: \u00a0  Early in the process of updating  RFC 793 , Scott Brim mentioned that \u00a0  this should include a PERPASS/privacy review.\u00a0 This may be something \u00a0  for the chairs or AD to request during WGLC or IETF LC. I don't see any evidence to suggest that such a review actually occurred.\u00a0 Do we want to seek out such a targeted review before progressing?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-11 02:46:18-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-20 07:18:33-07:00",
    "text": "The IESG needs to approve the following DOWNREFs during the telechat: \u00a0 DOWNREF [10] from this Internet Standard to Proposed Standard  RFC6298 . \u00a0 DOWNREF [2] from this Internet Standard to Draft Standard  RFC1191 . \u00a0 DOWNREF [7] from this Internet Standard to Proposed Standard  RFC3168 . \u00a0 DOWNREF [11] from this Internet Standard to Proposed Standard  RFC6633 . \u00a0 DOWNREF [9] from this Internet Standard to Draft Standard  RFC5681 . \u00a0 DOWNREF [5] from this Internet Standard to Proposed Standard  RFC2675 . \u00a0 DOWNREF [4] from this Internet Standard to Proposed Standard  RFC2474 .",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-09-22 15:52:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-09-22 15:51:13-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-12-16 10:32:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 15:52:37-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS, because I think that it is important enough that it needs addressing: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-02-17 06:37:48-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 13:45:17-07:00",
    "text": "* I found at least one reference that should be normative reference but they are not. Section 3.8.5 : describes -- \u00a0   \u00a0 \u00a0 TCP implementations MUST still include support for the urgent mechanism (MUST-30). Details can be found in  RFC 6093  [38] \u00a0  \u00a0 This to ne makes  RFC6093  a must to read and understand to deploy this specification. Hence it should in the normative references. * (This perhaps more process thing than technical), me and Benjamin Kaduk discussed another issue regarding urgent pointer. This specification specifies - \u00a0 \u00a0 \u00a0  Pointer indicates first non-urgent octet\u00a0 \u00a0 \u00a0  | MUST-62|  \u00a0  \u00a0  RFC1011  rectifies  RFC973  to - \u00a0 \u00a0 \u00a0 The urgent pointer points to the \u00a0 \u00a0 \u00a0 \u00a0  last octet of urgent data (not to the first octet of non-urgent \u00a0 \u00a0 \u00a0 \u00a0  data). \u00a0 So what does happen to  RFC1011  rectification then when 793bis is not bis anymore? Is this a known fact and there is conscious decision not to do anything about it? or was this a unknown fact and that part of  RFC1011  need to be obsoleted (how?)?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-28 15:50:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 16:33:46-07:00",
    "text": "I think we lack sufficient precision (forgive the pun) in how we talk about \"accuracy\" and \"precision\".\u00a0 Are the leafs that claim to specify \"accuracy\" specifying a precision?\u00a0 If so, the precision of a specific measurement, the precision of the measurements that led to the creation of the coordinate frame, or something else?\u00a0 Are they doing so in relative terms (e.g., percentage) or absolute terms (e.g., degrees and meters)?\u00a0 (There are \"units\" directives only for \"height-accuracy\" and not the others.)\u00a0 How can we we say that we'll have 16 fraction-digits of precision for lat/long when the maximum accuracy we can say that a geodetic-system has only gives us 6 fraction-digits for coord-accuracy? When we say that the \"precision of this measurement is indicated by the reference-frame\" is that the same thing as the relevant \"-accuracy\" nodes, or something else?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-06-17 15:09:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 05:13:23-07:00",
    "text": "Thank you for the work on this document, and thank you to the shepherd for a very well-written shepherd write up. I have a couple of DISCUSS points related to the IANA section, and some non blocking question. Francesca 1. ----- \u00a0  The allocation policy for this registry is First Come, First Served, \u00a0  [ RFC8126 ] as the intent is simply to avoid duplicate values. FP:  RFC 8126  specifies: \u00a0  When creating a new registry with First Come First Served as the \u00a0  registration policy, in addition to the contact person field or \u00a0  reference, the registry should contain a field for change controller. \u00a0  Having a change controller for each entry for these types of \u00a0  registrations makes authorization of future modifications more clear. \u00a0  See Section 2.3. The current registry dos not contain contact person, nor reference, nor change controller fields. 2. ----- \u00a0  It should be noted that [ RFC5870 ] also creates a registry for \u00a0  Geodetic Systems (it calls CRS); however, this registry has a very \u00a0  strict modification policy.\u00a0 The authors of [ RFC5870 ] have the stated \u00a0  goal of making CRS registration hard to avoid proliferation of CRS \u00a0  values.\u00a0 As our module defines alternate systems and has a broader \u00a0  (beyond Earth) scope, the registry defined below is meant to be more \u00a0  easily modified. FP: Thanks for bringing this up - I want to confirm that we need this registry, and that we are not creating a way to bypass the CRS registration policies by providing a different registry with a more lenient policy.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-06-22 04:02:09-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-17 02:32:38-07:00",
    "text": "Section 8, paragraph 2, discuss: >\u00a0 \u00a0 [EGM08]\u00a0 \u00a0 Pavlis, N.K., Holmes, S.A., Kenyon, S.C., and J.K. Factor, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"An Earth Gravitational Model to Degree 2160: EGM08.\", >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Presented at the 2008 General Assembly of the European >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Geosciences Union, Vienna, Arpil13-18, 2008, 2008, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 egm08_wgs84.html>. > >\u00a0 \u00a0 [EGM96]\u00a0 \u00a0 Lemoine, F.G., Kenyon, S.C., Factor, J.K., Trimmer, R.G., >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Pavlis, N.K., Chinn, D.S., Cox, C.M., Klosko, S.M., >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Luthcke, S.B., Torrence, M.H., Wang, Y.M., Williamson, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  R.G., Pavlis, E.C., Rapp, R.H., and T.R. Olson, \"The >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Development of the Joint NASA GSFC and the National >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Imagery and Mapping Agency (NIMA) Geopotential Model >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  EGM96.\", Technical Report NASA/TP-1998-206861, NASA, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Greenbelt., 1998, >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . I question whether these two can be normatively referenced without an explicit DOWNREF check. First, the URLs of both are broken. Second, the cached versions on  archive.org  seem to be web pages that link to a lot of other material, with no indication that anything on these pages is standards material. Are better references available here?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-07-15 08:35:21-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 15:09:26-07:00",
    "text": "** Section 3.\u00a0 leaf astronomical-body.\u00a0 The content of this field appears to be \"An astronomical body as named by the International Astronomical Union (IAU) or according to the alternate\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 system if specified.\"\u00a0 What\u2019s the normative reference to the IAU\u2019s list of astronomical bodies.\u00a0 Listed here is \u201c https://www.iau.org \u201d which is an unstable reference to a website with changing content.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-04 08:21:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-24 23:17:14-08:00",
    "text": "I support \u00c9ric's and Erik's and Roman's Discusses. We've had similar issues with embedding client IP addresses in security tokens all over the place, e.g., in Kerberos tickets, where it provided negligible security benefit and frequently caused (hard to diagnose!) breakage. I further note based on some of the responses so far that (as I understand it) the issues of multiple client IPs is quite realistic just for making requests to the CSP vs the uCDN, and no amount of time-locality can save us. I expect that the IESG will have some in-person discussion of this topic and what we are willing to put in an IETF-stream RFC.\u00a0 (My own personal opinion is that we have a fair amount of leeway to document \"some people are doing this thing\" accompanied by explanations of the flaws in that practice, but that we have very limited scope to recommend bad practices.) I think we should also discuss the proposed technique of redistributing shared secrets used to generate MACs for signed JWTs.\u00a0 I see a minimal acknowledgment that there is potential cause concern in the penultimate paragraph of the security considerations that \"it is important to know the implications of a compromised shared key\", but in my mind the text there does not really call out the severity of those implications.\u00a0 I would have expected something like \"redistributing the shared key in this manner allows the dCDNs to impersonate the CSP to the uCDN and produce arbitrary signed URLs that are accepted by the uCDN as authentic\".\u00a0 Well, what I *actually* would have expected was to just not define this mechanism at all, as it is too risky to use a group-shared symmetric key in a group where participants are at different trust levels.\u00a0 But perhaps the WG can produce some explanation of why this is acceptable... I also have concerns about our guidance to leave the JWT \"jti\" unchanged when re-signing with different contents, e.g., changing Issuer and/or Audience, etc..\u00a0 We don't seem to mention one way or another whether \"jti\" needs to be preserved while performing Signed Token Renewal, but changing the \"exp\" while preserving \"jti\" seems like it would be problematic as well.\u00a0 The guidance in  RFC 7519  is somewhat vague (basically, that it needs to change if it identifies a \"different data object\"), so we may want to consult the broader OAuth WG (not necessarily just the IANA DE) for further interpretation.\u00a0 I can also add based on the responses so far that the \"jti\" is not solely to be used to prevent replay, and so I am skeptical of reasoning based on such an argument. The combined defaults for the CDNI Metadata Interface for URI Signing seem to be an unsafe combination.\u00a0 Specifically, the default behavior for the \"issuers\" property is to allow any Issuer, and the default for the \"jwt-header\" property is to take the header from the JWT in band. As far as I can tell, this means that the dCDN will just blindly accept anything that is formatted as a JWT and signed by any key nown to the dCDN.\u00a0 The authentication and authorization properties of such behavior are so poor so as to effectively be useless, absent some level of care surrounding key management to isolate keys to given URIs.\u00a0 In fact, the lack of substantive discussion of key management and requirements thereof seems Discuss-worthy in its own right.\u00a0 We need to say something about obtaining a key along with a trust path to what it's authorized to be used for, even if the specific protocol mechanism for doing so is left out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-20 13:28:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-04 08:21:49-08:00",
    "text": "Thanks for the updates in the -22 through -24.\u00a0 I think a couple of my discuss points remain at the discuss level, which I'll expound on a bit more below. I am happy to see the pervasive disclaimers that use of a symmetric shared key is supported but NOT RECOMMENDED, and the note that redistribution of the symmetric shared key to dCDNs (including cascaded CDNs) is included for legacy feature parity and highly discouraged in new implementations. However, I think this does not fully address my original discuss point.\u00a0 As I said then, [[I see a minimal acknowledgment that there is potential cause concern in the penultimate paragraph of the security considerations that \"it is important to know the implications of a compromised shared key\", but in my mind the text there does not really call out the severity of those implications.\u00a0 I would have expected something like \"redistributing the shared key in this manner allows the dCDNs to impersonate the CSP to the uCDN and produce arbitrary signed URLs that are accepted by the uCDN as authentic\".]]\u00a0 In particular, I think it is important to emphasize in some manner that the cryptographc properties of the symmetric shared key are fully symmetric across all participants, even though the administrative and organizational structure here is hierarchical with explicitly more- and less-trusted entities, making the symmetric cryptographic mechanism a mismatch for the desired trust boundaries and inviting abuse.\u00a0 Only contractual controls prevent misuse in this scenario, whereas we have well-understood technologies that allow technical measures to prevent misuse that are preferred. It's also still unclear to me that there's sufficient need to document the symmetric key *redistribution* case in this document at all, if the only use case is for \"legacy feature parity\".\u00a0 Given that it's a fairly simple idea, what is to stop us from leaving it undocumented in this Proposed Standard and letting any implementors that need it do so on their own, or with a separate Informational document mentioning its existence?\u00a0 I am not aware of any preexisting IETF work that we need to retain compatibility with, and the data presented so far does not make a compelling (to me) case that we must include this functionality in order for the IETF offering to be competitive. (To be clear, I do not object to describing the use of symmetric keys for a single-hop scenario, as the risks there are much smaller.) I'd also like to have some additional discussion on this point from my previous Discuss position, reproduced with typo fixed: === The combined defaults for the CDNI Metadata Interface for URI Signing seem to be an unsafe combination.\u00a0 Specifically, the default behavior for the \"issuers\" property is to allow any Issuer, and the default for the \"jwt-header\" property is to take the header from the JWT in band.\u00a0 As far as I can tell, this means that the dCDN will just blindly accept anything that is formatted as a JWT and signed by any key known to the dCDN.\u00a0 The authentication and authorization properties of such behavior are so poor so as to effectively be useless, absent some level of care surrounding key management to isolate keys to given URIs.\u00a0 In fact, the lack of substantive discussion of key management and requirements thereof seems Discuss-worthy in its own right.\u00a0 We need to say something about obtaining a key along with a trust path to what it's authorized to be used for, even if the specific protocol mechanism for doing so is left out of scope. === I do see that \u00a71.3 gained a mention of \"obtain the key in a manner that allows trust to be placed in the assertions made using that key\", apparently per my suggestion in my original COMMENT section.\u00a0 However, I don't think this is sufficient.\u00a0 I strongly encourage a dedicated section on the requirements for key management and how updates (both additions and removals) of the list of trusted Issuer/key pairs are managed.\u00a0 Failing that, at a minimum the default for the \"issuers\" property in the CDNI Metadata Interface needs to be changed to say that an empty list means that any Issuer in the dCDN's trusted key store of issuers is acceptable for signing JWTs for URI signing.\u00a0 This is to be contrasted with \"any Issuer at all\", which does not impose an obligation on the dCDN to maintain a list of Issuer/key pairs trusted for signing JWTs used in signed URIs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 12:59:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-20 13:28:53-07:00",
    "text": "I see that the -25 has demoted discussion of symmetric key redistribution from (paraphrasing) \"a normal thing mentioned in passing\" to a SHOULD NOT action.\u00a0 This is a step in the right direction, but I am not sure that it's far enough.\u00a0 Is there some additional background on why this functionality (of key redistribution from uCDN to dCDN in particular, or group sharing of a single symmetric key from CSP to both uCDN and dCDN) is required to retain that I am failing to find?\u00a0 The latest discussion I see in the WG email archives is https://mailarchive.ietf.org/arch/msg/cdni/iFP6w3z22yQ1s0IJisrsIJN1ikU/ which seemed to suggest that the mechanism would be removed entirely. The security properties of this group key sharing are sufficiently poor that (if we do need to keep it) I think there would need to be explicit discussion in the document about what the use case is and why that use case allows for the weakening of security properties.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-11-15 04:56:10-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-23 05:50:03-08:00",
    "text": "Thank you for the work put into this document. Special thanks for the doc shepherd write-up , which was really useful about the WG history. Please find below one blocking DISCUSS points (which should be solved easily), one non-blocking COMMENT point (but replies would be appreciated), and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2.1.10 -- About \"Client IP (cdniip) claim\", I really wonder whether this could be used in real life as some IPv4 Carrier-Grade NAT (CGN) have a large pool of \"public\" IPv4 addresses that could select different public IPv4 addresses if badly designed. How will it work with dual-stack UAs where some connections could be over IPv4 and some over IPv6 ? Now to mention a dual-home (Wi-Fi & mobile data) UA ? Or what if the dCDN is between the UA and the CGN (assuming that the uCDN or CSP are upstream of the CGN) ? Also, \"If the received signed JWT contains a Client IP claim\" uses singular rather than \"one or several\"  I also noted that Section 7 (security considerations) puts some restrictions on the usefulness of cdniip. I would welcome some applicability statements on the use of cdniip.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-01-03 04:50:17-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-15 04:56:10-08:00",
    "text": "Thank you for the work put into this document. Thank you for fixing all my previous COMMENTs in the -22 revision. I am afraid that I need to keep my DISCUSS about the cdniip even with the addition of a paragraph at the end of section 2.1.10... This paragraph ressembles to an application statement but it it really light. Why did the authors select not to use  RFC 8174  normative language \u201cNOT RECOMMENDED\u201d ? The section 7 (security considerations) is still very light on the IP address sharing. -\u00e9ric == DISCUSS == -- Section 2.1.10 -- About \"Client IP (cdniip) claim\", I really wonder whether this could be used in real life as some IPv4 Carrier-Grade NAT (CGN) have a large pool of \"public\" IPv4 addresses that could select different public IPv4 addresses if badly designed. How will it work with dual-stack UAs where some connections could be over IPv4 and some over IPv6 ? Now to mention a dual-home (Wi-Fi & mobile data) UA ? Or what if the dCDN is between the UA and the CGN (assuming that the uCDN or CSP are upstream of the CGN) ? Also, \"If the received signed JWT contains a Client IP claim\" uses singular rather than \"one or several\"  I also noted that Section 7 (security considerations) puts some restrictions on the usefulness of cdniip. I would welcome some applicability statements on the use of cdniip.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-12-29 21:34:23-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 17:46:53-08:00",
    "text": "Apologies for piling on, but I want to second Eric Vyncke's Discuss.\u00a0 The use of Client IP addresses is more problematic than one might suspect from a reading of this document. RFC 8305  Happy Eyeballs means for a dualstack client and a dualstack CSP or CDN there are no guarantees that the address family will be the same. Furthermore, a client using  RFC 8981  (4941bis) IPv6 temporary addresses might change source address (even with every request) so an exact match would not be recommended. To make matters even more complicated, a mobile client might make the CSP request on Wi-Fi, walk out of range, and complete a subsequent CDN request via its mobile provider network (or vice versa).\u00a0 So, even using a fairly short CIDR length for truncation may not work since the origin network can be completely different between requests. The latter behaviour can also be trigger by connection migration transports, like MPTCP and (soon) QUIC. I think one solution might include relaxing all the MUSTs in section 2.1.10. Instead, perhaps some text that clarifies the presence of reliability issues with Client IPs and recommends that CDNs be develop a more sophisticated policy (or avoid using this altogether and prefer to use other claims). Including the Client IP for logging purposes might be helpful, but being too strict about verifying it can lead to client-visible failures. Alternatively, UAs need to be augmented to know that when a cdniip is part of the claim that it must try to keep the source IP address the same for subsequent requests, recognizing, as section 7 does, that NAT can make this impossible.\u00a0 I'm not sure this is a workable option, though.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-04 08:05:44-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 18:01:03-08:00",
    "text": "** Section 1.3.\u00a0 Per \u201cNote that the signed Redirection URI MUST maintain the same (or higher) level of security as the original Signed URI.\u201d: -- How is this equivalence assessed? -- Can one create an architecture to that cascades a mix of uCDNs whose path will mix both asymmetric and symmetric keys?\u00a0 Assuming that\u2019s possible what\u2019s \u201csame or higher\u201d here? ** Section 2.1.7.\u00a0 The specified use of the jti claim in the URI signing workflow appears to conflict with the underlying definition of this claim in  RFC7519 . (a) Section 1.3. says \u201c\u2026 the CSP needs to allow the uCDN to redistribute shared keys to a subset of their dCDNs.\u201d (b) Section 2.1.7 says \u201cIf the received signed JWT contains a Nonce claim, then any JWT subsequently generated for CDNI redirection MUST also contain a Nonce claim, and the Nonce value MUST be the same as in the received signed JWT.\u201d (c.1) Section 4.1.7 of  RFC7519  says \u201cThe identifier value MUST be assigned in a manner that ensures that there is a negligible probability that the same value will be accidentally assigned to a different data object \u2026 (c.2) Section 4.1.7 of  RFC7519  also says \u201c\u2026 if the application uses multiple issuers, collisions MUST be prevented among values produced by different issuers as well.\u201d The constraints in (b) suggests that the Nonce claim value needs to be the same across every logical hop in the cascading CDN path.\u00a0 My understanding of the architecture is that some of the claims in the JWTs such as the cdniuc or cdnistd claims might changes when there are cascading CDNs.\u00a0 If they change, this seems like that would constitute a different \u201cdata object\u201d who have the same unique (jti claim) identifier which would violate (c.1).\u00a0 One could argue that perhaps the CDNs are at arm-length so they aren\u2019t really an \u201capplication us[ing] multiple issuers\u201d, however, the architectural construct of shared keys suggested by (a) seems to imply otherwise which would suggest that this violated (c.2).\u00a0 If I\u2019ve misunderstood the architecture let me know. The notion of keeping the nonce the same seems like the right design, its just the reuse of this particular claim seems mismatched.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-14 19:16:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-14 19:08:25-07:00",
    "text": "I generally found this a well-written and pleasant to read document. I do have some additional comments on it and tomorrow I'll update the comments section of my ballot to reflect them, but wanted to post the DISCUSS portion tonight. I would like to understand the motivation behind what seems to me to be a curious inconsistency. I was surprised, when I reached \u00a76.9, to find out that an ITR MUST discard a Map-Reply whose HMAC ID or KDF ID don't match what the ITR sent. As I understand it, this is used as a form of algorithm negotiation. That much I get (although it's surprising there's no text telling the ITR to remember the negotiated algorithm for future reference). What I don't get, is why \u00a76.7 and \u00a76.7.1 tell the Map-Server to go to the trouble of creating a full, properly-formed Map-Reply (quite possibly involving the ETR too in the process) in the case where it doesn't support the HMAC or KDF recommended by the ITR. In such a case the Map-Server *knows* the ITR will discard the Map-Reply. So why waste cycles and bandwidth sending anything other than a bare-bones, \"I don't support your algorithm, here's the one I like\" message?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-15 10:08:05-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-14 19:16:28-07:00",
    "text": "I generally found this a well-written and pleasant to read document. I do have some additional comments on it and tomorrow I'll update the comments section of my ballot to reflect them, but wanted to post the DISCUSS portion tonight. I would like to understand the motivation behind what seems to me to be a curious inconsistency.  On the one hand, \u00a76.7 and \u00a76.7.1 mention that  \u00a0  While processing the Map-Request, the Map-Server can overwrite the \u00a0  KDF ID field if it does not support the KDF ID recommended by the \u00a0  ITR. and similar for the HMAC ID. They then go on to detail all the other work the Map-Server does to create a well-formed Map-Reply (if replying directly) or Map-Request (if sending the message to an ETR to take action). This seemed fine, until I got to \u00a76.9, which told me that after the Map-Server (and often, ETR) went to all that work to create those messages... \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If the KDF ID in the Map-Reply does not match the \u00a0  KDF ID requested in the Map-Request, the ITR MUST discard the Map- \u00a0  Reply and similar for the HMAC ID.  Why did you tell the Map-Server to spend cycles and bandwidth doing the work to produce a fully-formed Map-Reply in this case where you know the ITR is just going to discard the result? Why doesn't the Map-Server simply send a bare-bones \"I don't support your algorithm, here's the one I do like\" message?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-07-01 10:35:19-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 00:29:41-07:00",
    "text": "Sections 8.1 through 8.5 all create registries with \"Specification Required\" rules.\u00a0  RFC 8126  says this about \"Specification Required\": \u00a0  As with Expert Review (Section 4.5), clear guidance to the designated \u00a0  expert should be provided when defining the registry, and thorough \u00a0  understanding of Section 5 is important. Only Section 8.5 includes any such guidance.\u00a0 Is none needed for the other four?\u00a0 Also, I'm having trouble understanding the advice that Section 8.5 does give.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-07-08 05:51:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 06:25:12-07:00",
    "text": "Note I support the DISCUSSes and COMMENTS of Roman and Murray, and John's comments, and I won't repeat those issues in this review. #1 The document keeps talking about generating OTK's which are One Time Key's, and then \"securely transports\" these. If we have such a secure transport, why can't this same mechanism be used by the Map-Server for the Map-Request and Map-Reply message security instead of OTKs? Possibly I am not understanding the full architecture? An ascii art diagram would be useful at the beginning of the document. This all kind of tastes like Kerberos/GSSAPI. Couldn't that be used instead? Why not just use mTLS between all parties and get rid of all the custom crypto with OTK's ? #2 \u00a0  LISP-SEC deployments SHOULD use AUTH-HMAC-SHA- \u00a0  256-128 HMAC function, unless older implementations using AUTH-HMAC- \u00a0  SHA-1-96 are present in the same deployment It makes be sad that 1 older device downgrades the usable algorithm for all nodes. Would it be possible to change the protocol slightly so those with sha2 support could use this and only the sha1-only node uses the old algorithm? #3 \u00a0  or by enabling DTLS [ RFC9147 ] between the ITR and the Map-Resolver. Should this clarify that the DTLS connection should be mutually authenticated? eg both peers must identify themselves to the other, unlike the more common (D)TLS connections where only the client authenticates the server. This applies to multiple locations where it says DTLS can be used. #4 The Registry \"LISP-SEC Authentication Data HMAC ID\" seems to really be conveying a _preference_. Should this be reflected in the name of the registry? Additionally, can we leave value 0 as Reserved, and make NOPREF the value 1, etc. The \"Key Wrap Functions\" registry specifies 0 as Reserved, but then associated a KEY WRAP and KDF with this value. That is, it combines a \"Reserved\" with a \"NULL wrap\" entry. These two should be clearly split - eg reserve 0\u00a0 with Key wrap and KDf set to \"N/A\", and if needed create a \"null-wrap-null if an entry is needed with key wrap and kdf set to \"none\". The \"Key Derivation Functions\" also mixes up NOPREF and Reserved.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-07-13 13:58:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 18:47:40-07:00",
    "text": "** Since originally scheduled for the telechat in version -26, thank you for adding the following text about preferring HMAC-SHA256 for new deployments in -27: \u00a0  The HMAC \u00a0  function AUTH-HMAC-SHA-256-128 [ RFC6234 ] MUST be supported in LISP- \u00a0  SEC implementations.\u00a0 LISP-SEC deployments SHOULD use AUTH-HMAC-SHA- \u00a0  256-128 HMAC function, unless older implementations using AUTH-HMAC- \u00a0  SHA-1-96 are present in the same deployment [ RFC2104 ]. Could this same approach be applied for the algorithms set by KDF ID.\u00a0 Specifically: -- Section 6.9 says: \u00a0  The key derivation function \u00a0  HKDF-SHA1-128 [ RFC5869 ] MUST be supported. ... \u00a0 However, since HKDF-SHA1-128 is mandatory to implement, the process \u00a0  will eventually converge. Could it say something to the effect of: The key derivation function HKDF-SHA256 MUST be supported in LISP-SEC implementations.\u00a0 LISP-SEC deployments SHOULD use the HKDF-SHA256 HKDF function, unless older implementations using HKDF-SHA1-128 are present in the same deployment. However, since HKDF-SHA1-128 and HKDF-SHA256 are supported, the process will eventually converge. -- Section 8.5.\u00a0 Add HKDF-SHA256 to the \"LISP-SEC Authentication Data Key \u00a0  Derivation Function ID\" registry",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-02-16 07:42:14-08:00",
    "end_reason": "position_updated",
    "start": "2017-02-16 03:20:29-08:00",
    "text": "hy is this using TCP/DTLS/SCTP instead of TCP/TLS/SCTP?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-08-10 06:06:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-08-08 18:33:38-07:00",
    "text": "Issue #1 \u00a0 \u00a0 \u00a0 \u00a0 The discovery of such a Relevant RRSet MUST be performed using the \u00a0 \u00a0 \u00a0 \u00a0 algorithm specified in section 3 of [ RFC8659 ]. The input domain to the \u00a0 \u00a0 \u00a0 \u00a0 discovery algorithm SHALL be the domain \"part\" ([ RFC5322 ]) of the email \u00a0 \u00a0 \u00a0 \u00a0 address that is being certified. And  RFC 8659  states: \u00a0 \u00a0 \u00a0 \u00a0 The search for a CAA RRset climbs the DNS name tree from the \u00a0 \u00a0 \u00a0 \u00a0 specified label up to, but not including, the DNS root \".\" until \u00a0 \u00a0 \u00a0 \u00a0 a CAA RRset is found. While this algorithm makes sense for a CAA to restrict issuing, I'm not sure it makes sense for email addresses where the permission might be granted by a parent. eg ig there is a CAA record saying \"no email certs\" at  nohats.ca , and there is a CAA record saying \"sure, issue stuff\" at  toronto.nohats.ca , is it the desired behaviour that  toronto.nohats.ca  can override the  nohats.ca policy and issues certs for  paul@toronto.nohats.ca ?\u00a0 This also brings into question whether Public Suffix List (PSL) type restrains matter. It might very well be the intent, but then perhaps it should be made a little more explicit ? (and then I have to rethink about what I think about subdomains overriding their parents) Issue #2: Section 5.4 contains an example of conflicting records, and the text then describes a process of \"failing open\". From a security point of view, I would argue this should \"fail close\" and not allow issuance. Was this discussed in the WG? What is the rationale behind this \"more vulnerable to mistakes\" interpretation?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 10:23:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-11 10:13:21-07:00",
    "text": "Further details in the COMMENT, but can we briefly discuss the apparent requirement for the PANID/NID to have a couple bits set to zero (the ones that would be U/L and Individual/Group in the resulting IID)?\u00a0 It seems like (but is not entirely clear to me) this is a new requirement on the layer-2 behavior that is being imposed by the IPv6 adaptation layer, and in particular that this is setting up a scenario where certain existing layer-2 deployments would be unable to utilize the IPv6 adaptation layer, which would be a very surprising behavior for an IETF Proposed Standard.\u00a0 What alternatives were explored and rejected before settling on this approach that introduces new limitations on the underlying PLC deployments? I mention in a few places in the COMMENT scenarios where we pull in part of the functionality from  RFC 6282  and  RFC 4944 , e.g., the IP header compression scheme and the fragmentation format.\u00a0 It seems to me that the intent is that our payload always use the  RFC 4944  \"dispatch\" scheme and that we only use a subset of (and only sometimes?) the particular functionality that  RFC 4944 /6282 can dispatch to.\u00a0 But the current text doesn't mention the dispatch behavior at all, so it's hard for me to be certain that my understanding is correct.\u00a0 It seems that some more explicit treatment in the document of how what we are specifying interacts with/uses the  RFC 4944  dispatch layer would be important in order for someone to be able to implement from this document. I support Roman and \u00c9ric's Discusses.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-01-10 23:04:07-08:00",
    "end_reason": "position_updated",
    "start": "2021-08-09 22:44:25-07:00",
    "text": "Thank you for the work put into this document. Special thanks to Carles Gomez for his shepherd's write-up, which contains a good summary of the WG consensus *BUT* it does not mention that the IEEE normative references are not free. Strange that Carles' email address,  carlesgo@entel.upc.edu , is not in the datatracker status page. Please find below some blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated), and some nits. Please also address Dave Thaler's INT-DIR review at: https://datatracker.ietf.org/doc/review-ietf-6lo-plc-06-intdir-telechat-thaler-2021-08-06/  (some of my DISCUSS points are coming from Dave's review) I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Is there any reason why the IETF Last Call  https://mailarchive.ietf.org/arch/msg/6lo/f59y8rMg-p_aCKYSSEtBzoJK4qQ/  did not mention that the two IEEE normative references were behind a paywall ? It prevented some more detailed reviews and is an important fact. How can a PLC node distinguish between an IPv6 PDU and a non-IPv6 PDU ? I.e., is there the equivalent of a EtherType in a layer-2 PLC PDU ? Then, this should be mentioned in this document else some text explaining why it is not required would be welcome. Especially when the normative IEEE references are not freely available. -- Section 4.1 -- I am repeating here Dave Thaler's point 1) as it is completely unclear to me how the shared secret/version number are shared and provisioned, this could prevent interoperation hence my DISCUSS. While I appreciate that the nodes are constrained, some warnings about having a *single global IPv6 address* should be written or if the spec supports more than one global IPv6 address per node, then the current text must be changed.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-07 14:19:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-09 15:21:14-07:00",
    "text": "** Section 8. A few additional threats should be mentioned.\u00a0 Note that a robust treatment is not needed here (and likely not possible due to the generality of this document).\u00a0 However, they should be acknowledged. -- This section mentions both availability (DoS) and confidentiality (eavesdropping) concerns.\u00a0 Thank you. Wouldn\u2019t there also be the possibility of significant integrity risks given that possible actuators or sensors being controlled?\u00a0  Note if the referenced link layer security mechanisms would be useful. -- Figures 5 \u2013 7 seems to present architectures which connects operational technology to the Internet via the PANC.\u00a0 However, this section doesn\u2019t acknowledgement of that risk outright or by citation. ** Section 8.\u00a0 Per \u201cThus link layer security mechanisms are designed in the PLC technologies mentioned in this document\u201d, which specific mechanisms were being cited is not clear.\u00a0 Is their use required or are they use case dependent?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-22 05:59:15-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-07 14:19:05-08:00",
    "text": "[updated for -09] ** Section 8. A few additional threats should be mentioned.\u00a0 Note that a robust treatment is not needed here (and likely not possible due to the generality of this document).\u00a0 However, they should be acknowledged. -- This section mentions both availability (DoS) and confidentiality (eavesdropping) concerns.\u00a0 Thank you. Wouldn\u2019t there also be the possibility of significant integrity risks given that possible actuators or sensors being controlled?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 19:55:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-20 00:47:41-07:00",
    "text": "Roman and Russ did the heavy lifting already, but I think I have a bit more fiddling to do regarding the validation procedures (just getting them internally consistent, I think)... (1) Here: \u00a0  As the signer specifies the covered RPKI resources relevant to the \u00a0  signature, the RPKI certificate covering the inetnum: object's \u00a0  address range is included in the [ RFC5652 ] CMS SignedData \u00a0  certificates field. we say that the signing certificate is included in the SignedData certificates field.\u00a0 That makes sense, as SignedData is a SEQUENCE including \"certificates [0] IMPLICIT CertificateSet OPTIONAL\", and CertificateSet, as a SET OF CertificateChoices, allows for the literal \"Certificate\" branch of CertificateChoices. But later on, we say that: \u00a0  1.\u00a0 Obtain the signer's certificate from an RPKI Repository.\u00a0 The \u00a0 \u00a0 \u00a0  certificate SubjectKeyIdentifier extension [ RFC5280 ] MUST match \u00a0 \u00a0 \u00a0  the SubjectKeyIdentifier in the CMS SignerInfo SignerIdentifier \u00a0 \u00a0 \u00a0  [ RFC5286 ].\u00a0 If the key identifiers do not match, then validation \u00a0 \u00a0 \u00a0  MUST fail. which entails fetching the certificate from a directory, based on the SubjectKeyIdentifier. Why do we need to obtain the certificate twice in two different ways? (2) We are careful to note that: \u00a0  The bracketing \"# RPKI Signature:\" and \"# End Signature:\" MUST be \u00a0  present exactly as shown. How do we construct the bits (CIDR block?) that come after the quoted strings?\u00a0 Do they only matter for matching start/end, or are we supposed to check them in the validation procedure?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 21:15:33-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-25 19:55:35-07:00",
    "text": "Roman and Russ did the heavy lifting already, but I think I have a bit more fiddling to do regarding the validation procedures (just getting them internally consistent, I think)... (2) We are careful to note that: \u00a0  The bracketing \"# RPKI Signature:\" and \"# End Signature:\" MUST be \u00a0  present exactly as shown. How do we construct the bits (address range?) that come after the quoted strings?\u00a0 Do they only matter for matching start/end, or are we supposed to check them in the validation procedure?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-20 13:08:48-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 14:17:04-07:00",
    "text": "Thank you for the work on this document, and thank you to the shepherd for a very well-written and in-depth shepherd write up: it was very informative and very appreciated. I have one DISCUSS point (that should be easy to fix) and a question. Francesca 1. ----- \u00a0  then BASE64 encoded and line wrapped to 72 or fewer characters. FP: Please add a (normative) reference to  RFC 4648  and specify if Section 4 (\"base64\") or Section 5 (\"base64url\") is to be used.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-05-21 16:00:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-20 00:36:43-07:00",
    "text": "I may have missed something, but why does Section 5 advocate for use of HTTPS to fetch geofeed files in the second paragraph, and then FTP in the seventh?\u00a0 Which is right?\u00a0 Or perhaps both are right, but there's some context being assumed here that I don't have.\u00a0 In any case, please clarify.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-20 06:52:37-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 14:06:33-07:00",
    "text": "The validation process for the signature computed in Section 4 seems underspecified.\u00a0  For example, let\u2019s consider the example in Appendix A.\u00a0 Through a whois query for 192.0.2.0 one finds a \u201cremarks:\u00a0 \u00a0 \u00a0 \u00a0 Geofeed \u201d field which leads to a geofeed file which had the detached CMS signature blob \u201c# RPKI Signature: 192.0.2.0/24\u201d depicted at the end of Appendix A.\u00a0 What reference or text guides how to validate that signature in the RPKI (akin to the level of detail in Section 3.3 of  RFC7909  or  RFC6125 )? I\u2019m inferring that the steps would roughly be: ** Download the end-entity certificate identified by the subjectKeyIdentifier field via the pointer/URI in the \u201csubjectInfoAccess\u201d\u00a0 field extracted from the CMS signature blob ** Download the intermediate certificate identified by the authorityKeyIdentifier field via the pointer/URI in the \u201ccaIssuer\u201d field extracted from the CMS signature blob ** Based on the RIR identified in the whois query, download the RPKI trust anchor of the RIR ** Validate the certificate chain from the RPKI trust anchor down to the end-entity certificate.\u00a0 Check that all of the basicConstraints, certificatePolicies, etc. are accurate.\u00a0 Check the CRL. ** Verify that the end-entity certificate contains the IP address of interest (192.0.2.0) in the sbgp-ipAddrBlock field ** Validate the signature using the algorithm identified in the CMS signature blog using the end-entity certificate Is that the process?\u00a0 Is that stated somewhere in the document or available via reference?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-03 10:09:59-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-01-31 15:19:02-08:00",
    "text": "The CIPO description specifies that a 5-bit Reserved1 field and a 13-bit Public Key Length field are combined to fit into a 16 (not 18)-bit space. (The Figure shows the Public Key Length field as 11 bits.) Why do we need to allow ambiguity/flexibility as to the point representation within a given Crypto-Type value (as opposed to fixing the representation as a parameter of the Crypto-Type)?\u00a0 Alternately, what does \"(un)compressed\" mean, as it's not really clarified directly?\u00a0 Furthermore, Table 2 lists an \"(un)compressed\" representation for type 0 (over P-256), but  RFC 7518  notes that the compressed representation is not supported for P-256 (Section 6.2.1.1).\u00a0 I also am not finding the needed codepoints registered in the JOSE registries to use ECDSA25519 (crypto-type 2) -- do we need to register anything there? Per my comment on Section 4.4, there may be some implicit expectation/requirement of 128+-bit ROVRs for AP-ND, but I didn't find where such a requirement was stated.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-06 16:05:38-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-03 10:09:59-08:00",
    "text": "Why do we need to allow ambiguity/flexibility as to the point representation within a given Crypto-Type value (as opposed to fixing the representation as a parameter of the Crypto-Type)?\u00a0 Alternately, what does \"(un)compressed\" mean, as it's not really clarified directly?\u00a0 Furthermore, Table 2 lists an \"(un)compressed\" representation for type 0 (over P-256), but  RFC 7518  notes that the compressed representation is not supported for P-256 (Section 6.2.1.1).\u00a0 I also am not finding the needed codepoints registered in the JOSE registries to use ECDSA25519 (crypto-type 2) -- do we need to register anything there?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 14:54:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-06 16:05:38-08:00",
    "text": "We need to indicate somehow that the needed codepoints will be registered in the JOSE registries to use ECDSA25519 (crypto-type 2), whether by doing it ourself or by depending on another doc that does so.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-02-01 00:40:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-29 06:18:38-08:00",
    "text": "Thank you for the work put into this document. I found the document easy to read. Please find below a trivial-to-fix DISCUSS (and I am requesting a reply and/or action on this one) plus some non-blocking COMMENTs and NITs. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.4 -- The length of the reserved field is not specified. Or am I missing something obvious ?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-10-22 00:07:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-22 00:06:40-07:00",
    "text": "Thank you for the work put into this document. It is an important topic and the document is both easy to ready and detailed. Please find below one trivial DISCUSS point and a couple of non-blocking COMMENT points but please also check: - Ines Robles IoT directorate review:   https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-iotdir-telechat-robles-2020-10-20/ - Bernie Volz Internet directorate review:    https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-intdir-telechat-volz-2020-10-20/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Please replace all  RFC 4260  reference to  RFC 8200 . Trivial to fix ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-10-30 02:05:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 00:07:30-07:00",
    "text": "Thank you for the work put into this document. It is an important topic and the document is both easy to ready and detailed. Please find below one trivial DISCUSS point and a couple of non-blocking COMMENT points but please also check: - Ines Robles IoT directorate review:   https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-iotdir-telechat-robles-2020-10-20/ - Bernie Volz Internet directorate review:    https://datatracker.ietf.org/doc/review-ietf-lwig-tcp-constrained-node-networks-11-intdir-telechat-volz-2020-10-20/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Please replace all  RFC 2460  references to  RFC 8200 . Trivial to fix ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-10-30 16:13:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-19 14:51:57-07:00",
    "text": "In Sec 4.1.1: \u00a0  An IPv6 datagram size exceeding 1280 bytes can be avoided by setting \u00a0  the TCP MSS not larger than 1220 bytes.\u00a0 This assumes that the remote \u00a0  sender will use no TCP options, aside from possibly the MSS option, \u00a0  which is only used in the initial TCP SYN packet. \u00a0  In order to accommodate unrequested TCP options that may be used by \u00a0  some TCP implementations, a constrained device may advertise an MSS \u00a0  smaller than 1220 bytes (e.g. not larger than 1200 bytes).\u00a0 Note that \u00a0  it is advised for TCP implementations to consume payload space \u00a0  instead of increasing datagram size when including IP or TCP options \u00a0  in an IP packet to be sent [ RFC6691 ].\u00a0 Therefore, the suggestion of \u00a0  advertising an MSS smaller than 1220 bytes is likely to be \u00a0  overcautious and its suitability should be considered carefully. I would delete everything after the first sentence in this excerpt. While RFC6691  is informational, it clarifies  RFC1122 , which is a standard, and Sec 4.2.2.6 is quite clear that senders MUST consider TCP and IP option length when sizing TCP payloads. Absent any evidence that there are TCP endpoints or middleboxes that are violating  RFC1122 , further reducing the MSS because someone might be violating it is excessive.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2023-01-15 15:09:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-15 00:41:30-08:00",
    "text": "# Internet AD comments for  draft-ietf-ippm-ioam-deployment-02 CC @ekline ## Discuss ### S7.3 * \"A deployment can choose to configure and support one or both of the \u00a0  IOAM Trace-Option-Types.\" \u00a0 I don't think this paragraph is quite correct as written, since it's \u00a0 theoretically tied to the limitations of the protocols in use in a \u00a0 deployment.\u00a0 Perhaps adding something along the lines: \u00a0 \"Which options can be supported is not only a function of the \u00a0  operator-defined configuration, but may also be limited by protocol \u00a0  constraints unique to a given encapsulation layer.\"",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-01-10 11:27:16-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 14:39:26-08:00",
    "text": "Thanks for working on this specification. I have a easy to fix discuss point. It is a bit confusing to see where these IOAM namespace, IOAM laying at section 7 come from. Is this something this document is suggesting to use to easy implementation and deployment? or is this something described in other documents and merely described here. As Section 7 is the main meat of this specification, I would like to discuss if this could be clarified better.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-06-05 14:35:48-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-22 09:08:36-07:00",
    "text": "I have a small list of issues that I would like to discuss before recommending approval of this document: 1) The first reference to UTF-8 needs a Normative reference to  RFC 3629 . 2) In Section 3.10.1, you say: \u00a0  The names of generic objectives MUST NOT include a colon (\":\") and \u00a0  MUST be registered with IANA (Section 7). In Section 7 you only say: \u00a0  GRASP Objective Names Table.\u00a0 The values in this table are UTF-8 \u00a0  strings.\u00a0 Future values MUST be assigned using the Specification \u00a0  Required policy defined by [ RFC5226 ]. IANA is not going to review section 3.10.1 and there is no back reference in Section 7. IANA needs to know that values with \":\" are not to be registered.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-07-05 17:05:53-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-24 19:32:54-07:00",
    "text": "ISSUE 1 The security situation here is pretty unspecified here, in at least two respects: 1. In terms of communication security, you seem to have two modes: \u00a0  (a) Punt it to ACP \u00a0  (b) Use TLS as specified in S 3.5.2.1 I'm not reviewing ACP here (though I have some comments on that too) but S 3.5.2.1 doesn't (for) instance explain how to do certificate validation, which it clearly needs to do. Finally, I don't understand the security story for the multicast packets. This is especially relevant for Rapid mode, where you are attaching real work to these multicast packets. 2. I didn't find the security model very clear. As I understand things, basically anyone on the network who has ACP credentials is trusted to engage in negotiation with you, so, for instance, if you want to get parameter X, then you basically just trust whoever on the network offers you X. is that correct? That seems like it needs to be very explicitly called out. And if that's not true, then I don't understand the spec. ISSUE 2 This document seems like it provides incomplete guidance on how to actually implement it. For instance: \u00a0  discovery messages to a reasonable value, in order to mitigate \u00a0  possible denial of service attacks.\u00a0 It MUST cache the Session ID \u00a0  value and initiator address of each relayed Discovery message until What's \"reasonable\"? ISSUE 3. I don't think I understand how the transition from UDP multicast to TCP/TLS unicast works. Maybe I'm just misreading the spec, so could you point me to the section that describes this. Finally, I don't see a spec for how you map CBOR onto the wire. Do you just shove them on? Something else? I see that Martin Thomson raised a number of these issues in his review in more detail.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-05-23 08:19:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-05-23 06:51:11-07:00",
    "text": "1) Use of transport protocols is not sufficiently defined Especially the following text in section 3.5.3 seems not to reflect later assumptions correctly; it seems to be assumed that TCP is used for all messages other than the discovery and therefore reliable transport is provided for these message (see sections 3.5.5 and 3.8.5): \"All other GRASP messages are unicast and could in principle run over \u00a0  any transport protocol.\u00a0 An implementation MUST support use of TCP. \u00a0  It MAY support use of another transport protocol but the details are \u00a0  out of scope for this specification.\u00a0 However, GRASP itself does not \u00a0  provide for error detection or retransmission.\u00a0 Use of an unreliable \u00a0  transport protocol is therefore NOT RECOMMENDED.\" section 3.8.4.: \" It then listens for unicast TCP responses on a given port...\" 2) Time-out handling section 3.5.4.4: \"Since the relay device is unaware of the timeout set by the original \u00a0  initiator it SHOULD set a timeout at least equal to GRASP_DEF_TIMEOUT \u00a0  milliseconds.\" Should a relay really maintain an own time-out? Wouldn't it be suffiecent to just relay again if another discovery message is received. Otherwise this can lead to an amplification, when the own time-out expires and another relay message is sent when another discovery message is received due to the time-out of the orginating peer. Further in relation to the point about, this should be more specific: section 3.5.4.4: \"Also, it MUST limit the total rate at which it relays \u00a0  discovery messages to a reasonable value, in order to mitigate \u00a0  possible denial of service attacks. \" 3) Version and extensibitity: section 3.5.4.5: \"A possible future extension \u00a0  is to allow multiple objectives in rapid mode for greater efficiency.\" How can this extension be defined if there is no version mechanism?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-07-07 04:30:32-07:00",
    "end_reason": "position_updated",
    "start": "2017-05-23 08:19:11-07:00",
    "text": "1) Use of transport protocols is not sufficiently defined Especially the following text in section 3.5.3 seems not to reflect later assumptions correctly; it seems to be assumed that TCP is used for all messages other than the discovery and therefore reliable transport is provided for these message (see sections 3.5.5, 3.8.4 and 3.8.5): \"All other GRASP messages are unicast and could in principle run over \u00a0  any transport protocol.\u00a0 An implementation MUST support use of TCP. \u00a0  It MAY support use of another transport protocol but the details are \u00a0  out of scope for this specification.\u00a0 However, GRASP itself does not \u00a0  provide for error detection or retransmission.\u00a0 Use of an unreliable \u00a0  transport protocol is therefore NOT RECOMMENDED.\" In general the usage of the transport protocols is not well enough specified, see also Spencer's comments and this part of Martin's tsv-art review (Thanks!): \"* Usage of UDP: This document is not discussing any of the aspects in  RFC 8085 . Every usage of UDP is required by IETF consensus to review  RFC 8085  and to address at least the applicable subset of issues listed in  RFC 8085  (or the predecessor  RFC 5405 ). * Starting with UDP and switching to TCP for the data transfer looks like the right do. However, UDP should be really only used to discover other devices, but not piggy back further protocol mechanics. However, this document is not really specific on how to make use of TCP, for instance, how long are TCP connections kept open or closed down after a protocol exchange (persistent vs temporary connections). What happens if a TCP connection is shutdown by one end or is forcefully closed, e.g., by a reset?\" I would recommend, as assumed in the rest of the document, to update section 3.5.3 to only use UDP for the initial recovery message and open a TCP connection for the discovery response and require that all other messages to be sent over TCP (also removing any option to use any other reliable transport because TCP seems to be the right choice here.) Further, additional guidance is needed when to open and close a TCP connection (or keep it alive for later use) and what to do if the connection is interrupted. 2) Time-out handling section 3.5.4.4: \"Since the relay device is unaware of the timeout set by the original \u00a0  initiator it SHOULD set a timeout at least equal to GRASP_DEF_TIMEOUT \u00a0  milliseconds.\" Should a relay really maintain an own time-out? Wouldn't it be sufficient to just relay again if another discovery message is received. Otherwise this can lead to an amplification, when the own time-out expires and another relay message is sent when another discovery message is received due to the time-out of the originating peer. Further in relation to the point about, this should be more specific: section 3.5.4.4: \"Also, it MUST limit the total rate at which it relays \u00a0  discovery messages to a reasonable value, in order to mitigate \u00a0  possible denial of service attacks. \" 3) Version and extensibility: section 3.5.4.5: \"A possible future extension \u00a0  is to allow multiple objectives in rapid mode for greater efficiency.\" How can this extension be defined if there is no version mechanism?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-02-02 16:15:46-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-19 21:32:34-08:00",
    "text": "Thanks, Mike, for the excellent editing work on a very clear and well written document. In Section 4.1.1 I\u2019m confused by the combination of the following two paragraphs, and would like to discuss what I\u2019m missing: \u00a0  Like HTTP/2, HTTP/3 does not use the Connection header field to \u00a0  indicate connection-specific fields; in this protocol, connection- \u00a0  specific metadata is conveyed by other means.\u00a0 An endpoint MUST NOT \u00a0  generate an HTTP/3 field section containing connection-specific \u00a0  fields; any message containing connection-specific fields MUST be \u00a0  treated as malformed (Section 4.1.3). ... \u00a0  This means that an intermediary transforming an HTTP/1.x message to \u00a0  HTTP/3 will need to remove any fields nominated by the Connection \u00a0  field, along with the Connection field itself.\u00a0 Such intermediaries \u00a0  SHOULD also remove other connection-specific fields, such as Keep- \u00a0  Alive, Proxy-Connection, Transfer-Encoding, and Upgrade, even if they \u00a0  are not nominated by the Connection field. Given the MUST in the first, how can the second only be SHOULD?\u00a0 Wouldn\u2019t such an intermediary, acting as the HTTP/3 client, be producing a malformed message if it did not \u201cremove other connection-specific fields\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-02 16:28:49-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-20 10:29:16-08:00",
    "text": "[note to Lucas/chairs: a few (three, I think) of these discusses/comments have preexisting github issues created by the editors over the past couple days due to some out of band discussions; if we can easily reuse them instead of creating new ones that would be preferred] (discuss point 1) Mike already filed  https://github.com/quicwg/base-drafts/issues/4761 and I think we can keep the discussion there. But to reiterate, we reference [SEMANTICS] for certificate validation and use in determining authority for the \"https\" scheme, yet the additional prose discussion we offer (with CN-ID and DNS-ID as the certificate fields to validate against, though not by that name) does not match what's currently present in [SEMANTICS].\u00a0 Discussion so far on the linked issue against [SEMANTICS] suggests that [SEMANTICS] will change, but we should not go forward with this document until we've resolved the disparity.\u00a0 (One might also wonder whether we need to duplicate the content ourselves or should just reference the other document(s).) There is a related topic in that our current formulation in this document treats CN-ID and DNS-ID as equivalently recommended, but current recommendations (including in  RFC 6125 ) are to prefer SAN-based names over the (legacy) CN-ID.\u00a0 I believe there are even some efforts underway in the Web ecosystem to move to fully deprecating the use of CN-ID; at present I believe that some entities require that any name present in the CN-ID be replicated as a DNS-ID as well.\u00a0 If we are to proceed with giving equal preference to CN-ID and DNS-ID, I think that we need to justify or at least call out the divergence from current IETF guidance. [Martin filed  https://github.com/quicwg/base-drafts/issues/4769  for the topic regarding whether CN-ID is mandatory or even recommended.] (discuss point 2) I also think that the procedure, as written, for coalescing HTTP requests against different URI authority components onto a single HTTP/3 connection is under-specified and seems inconsistent both with earlier WG conclusions and with previous IETF-mandated practices for certificate validation. [begin historical tracethrough] There appears to be quite a long history in this space (and I probably missed some of it, even).\u00a0 The idea of coalescing has been around back from the days when we only allowed Alt-Svc as discovery for using QUIC (no direct access), with https://github.com/quicwg/base-drafts/issues/940  being an early issue leading to  https://github.com/quicwg/base-drafts/pull/1024/files , with text that requires both Alt-Svc and valid certificate in order to be authoritative.\u00a0 Then we had https://github.com/quicwg/base-drafts/issues/2223  that notes that this Alt-Svc requirement is more restrictive than  RFC 7540 , which allegedly only requires the certificate to match a given name.\u00a0 (One might argue that 7540's \"additionally depends on having a certificate that is valid\" implies the \"depends on the host having resolved to the same IP address\" still applies, though of course ORIGIN weakens that if it was ever present and this is not terribly relevant to the current question.) Comments on #2223 seem to confirm that the intent is to largely parallel what HTTP/2 does; I'll come back to that in a bit.\u00a0 The corresponding text changes here are https://github.com/quicwg/base-drafts/pull/3558/files  that brings in the concept that \"a server is considered authoritative for all URIs with the 'https' scheme for which the hostname in the URI is present in the authenticated certificate provided by the server, either as [...]\". This text got moved a bit and reworded slightly in response to the secdir review ( https://github.com/quicwg/base-drafts/pull/4419/files ), but the intent is largely still present as \"If a server presents a valid certificate and proof that it controls the corresponding private key, then a client will accept a secured TLS session with that server as being authoritative for all origins with the \"https\" scheme and a host identified in the certificate.\" [end historical tracethrough] So now we have text that says: \u00a0  If a server presents a valid certificate and proof that it controls \u00a0  the corresponding private key, then a client will accept a secured \u00a0  TLS session with that server as being authoritative for all origins \u00a0  with the \"https\" scheme and a host identified in the certificate. This seems problematic to me, and divergent from HTTP/2, in that it focuses on the contents of a certificate *all* being valid/authoritative, as opposed to a certificate being valid for a given host/name.\u00a0 To quote \u00a79.1.1 of  RFC 7540 : \u00a0  For \"https\" resources, connection reuse additionally depends on \u00a0  having a certificate that is valid for the host in the URI.\u00a0 The \u00a0  certificate presented by the server MUST satisfy any checks that the \u00a0  client would perform when forming a new TLS connection for the host \u00a0  in the URI. A representative discussion of these checks is included in  RFC 6125 , and the general procedure for (server) certificate validation takes as input a candidate name of a service or entity that the client is attempting to contact, a certificate (chain) and signature presented by the server, and the application context in which the decision is being made [0].\u00a0 In short, the question is always \"do I (as the client) trust the peer entity to act as this specific name?\", and the answer may differ across names present in a single certificate!\u00a0 So I think we need to refresh this text once more, to bring back the sense that for each name that we might want to allow the server to act as an authority for, we have to do the normal validation checks.\u00a0 Saying that we validate a certificate once along with proof of possession of its private key and then the holder of the key is a valid authority for all names in the certificate invites violation of the client's security policy.\u00a0 For example, the client's trust database might not allow the CA(s) in the presented chain to certify some of the names contained in the certificate, among other reasons. (discuss point 2.1) There is probably some extra excitement surrounding revocation, in that the \"normal certificate validation procedures\" typically involve some form of attempt at a revocation check.\u00a0 What should happen if this check determines that the certificate has been revoked is not entirely clear. Presumably the attempt to use a new name from the certificate would fail, but does it also imply that the entire connection should be torn down, since it was built using the now-revoked certificate? (discuss point 2.2) In practice, the procedure of \"check the name in question against the certificate chain\" seems to mean that a client that is willing to coalesce connections needs to retain the certificate and chain presented by the peer, so that it is available as input to the certificate validation engine (typically accessed via the TLS stack, I suppose) at the time when an authentication decision needs to be made for a given name.\u00a0 This operational practice, as well as the actual mechanics of running a fresh certificate validation procedure, should probably be mentioned down in Section 3.3 where we discuss the actual connection reuse procedures.\u00a0 In particular, I think it would be very benficial to indicate what protocol interactions trigger an attempt by the client to validate a new name from the certificate for use as the authority for HTTP responses, as well as to note clearly that the certificate+chain have to be retained in order to run these checks. (discuss point 2.3) I think we should also look at the procedures for server push as they relate to coalescing; my understanding is that pushed responses are allowed to be for requests to a different authority, and thus that a client will need to discard or reject pushes that are from an authority that the client does not accept the peer as being authoritative for.\u00a0 I guess this is in some sense a check that the client always has to do for all pushed responses, but I'm not entirely sure whether or where that is currently described. [0] This context includes things like the set of trust anchors, as well as potentially information about restrictions on trust anchors, revocation checks, pinning or other restrictive information that reduces the set of CAs that might be allowed to certify a given name, etc.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-10-07 09:10:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 13:56:38-07:00",
    "text": "I am balloting DISCUSS because I find the document unclear and lacking proper technical details around significant functionality, as reflected in my first 3 points.\u00a0 The fourth point is related to the registration policy (which doesn't match the definition in  rfc8126 ), and my last point is for the IESG to consider. (1) Pseudocode and normative behavior The use of pseudocode was chosen as the mechanism to specify behavior, as explained in \u00a74: \u00a0  An implementation of the pseudocode is compliant as long as the externally \u00a0  observable wire protocol is as described by the pseudocode. Clarity in the pseudocode is essential because it is used to determine compliance.\u00a0 Several places need improvement: (1a) In \u00a74.1/\u00a74.13/\u00a74.15, the pseudocode is missing an ELSE after S04, to include the error conditions if SL != 0.\u00a0 A check for an error condition when SL is decremented is also needed.\u00a0 As written, the pseudocode could process the packet (SL == 0) *and* send an ICMP time exceeded message... :-( I'm using as a reference the pseudocode in \u00a74.3.1.1/rfc8754, which includes the same initial statement. (1b) It would be nice if the behavior in \u00a74.1.1 were also specified using pseudocode.\u00a0 As written, I am not sure if the intent is to process any upper-layer header or only specific ones.\u00a0 Is the objective for this operation to be similar to the one in \u00a74.3.1.2/rfc8754?\u00a0 Please be specific on what is meant by \"allowed by local configuration\". [Note: this point by itself is not DISCUSS-worthy, but \u00a74.1.1 is used, for different reasons, in some of the other items I point to below.\u00a0 That is why I include it here.] (1c) \u00a74.4/\u00a74.6: S01 of the second piece of pseudocode is an instruction for processing a non-IPv6 upper header.\u00a0 However, earlier in that section, it is specified that the SID \"is associated with one or more L3 IPv6 adjacencies/an IPv6 FIB table\".\u00a0 How can the upper header not be IPv6 if the specification explicitly says it has to be? (1d) \u00a74.5/\u00a74.7 have the same issue but related to IPv4. (1e) \u00a74.9 also has the same issue when it specifies that \"End.DX2 SID...is associated with one outgoing interface I\", but allows for the processing of non-ethernet payloads which could then be forwarded through a different outgoing interface. (1f) \u00a74.11/\u00a74.12 allows the processing of non-ethernet payloads, which will not be \"associated with an L2 Table T\" as described. (2) \u00a74.12 describes the only behavior that can carry an ARG.\u00a0 I don't understand how it works: \u00a0 \u00a0 \u00a0 Arg.FE2 is encoded in the SID as an (k*x)-bit value.\u00a0 These bits \u00a0 \u00a0 \u00a0 represent a list of up to k OIFs, each identified with an x-bit \u00a0 \u00a0 \u00a0 value.\u00a0 Values k and x are defined on a per End.DT2M SID basis.\u00a0 The \u00a0 \u00a0 \u00a0 interface identifier 0 indicates an empty entry in the interface \u00a0 \u00a0 \u00a0 list. Let's assume a router has 10 possible OIFs, and the operator uses 4-bit values to identify them; then, the ARG would take 40 bits of the SID.\u00a0 Is that how the math works? Assuming my interpretation is correct, for 20 OIFs and 5-bit values we would need 100 bits.\u00a0 Considering the examples in \u00a73.2, where a /64 is allocated to a router, this behavior wouldn't have enough bits!\u00a0 I realize that maybe a better encoding would be to use a 20-bit field, each representing an interface.\u00a0 However, there would still be a limit of < 64 OIFs.\u00a0 Am I missing something? I'm trying to ultimately get to the fact that there are limits to this behavior, but they are not described in the document.\u00a0 Please clearly explain any limitations and any possible workaround. (3) The description of the flavors in \u00a74.16 is also unclear. The section starts with this introduction: \u00a0  The PSP, USP and USD flavors are variants of the End, End.X and End.T \u00a0  behaviors.\u00a0 For each of these behaviors these flavors MAY be \u00a0  supported for a SID either individually or in combinations. By being \"variants\", I interpret that the behavior is different than what is specified in \u00a74.1.\u00a0  (3a) Some of the behaviors, as listed in Table 4, include an indication of the flavors.\u00a0 How are the values interpreted?\u00a0 For example, the Table lists 8 different behaviors related to End: | 1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0001 |\u00a0  End (no PSP, no USP)\u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0002 |\u00a0 \u00a0 \u00a0  End with PSP\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 3\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0003 |\u00a0 \u00a0 \u00a0  End with USP\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | 0x0004 |\u00a0 \u00a0  End with PSP&USP\u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | ... | 28\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001C |\u00a0 \u00a0 \u00a0  End with USD\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 29\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001D |\u00a0 \u00a0  End with PSP&USD\u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 30\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001E |\u00a0 \u00a0  End with USP&USD\u00a0 \u00a0 |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | | 31\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | 0x001F | End with PSP, USP & USD |\u00a0 \u00a0 [ This.ID ]\u00a0 \u00a0  | Is value 1 what is specified in \u00a74.1?\u00a0 Or does it include USD, which is not explicitly excluded)? (3b) If a behavior with more than one flavor is signaled, how should the receiving node determine which one to apply?\u00a0 I guess that the application of behaviors 4 or 29 depends on the number of SLs -- the expected behavior should be clearly specified. (3c) Is it assumed that all nodes support all behaviors?\u00a0 Are there mandatory to implement behaviors?\u00a0 Should the behavior be advertised before it is used? (3d) \u00a74.16.1.2:  \u00a0  When a SID of PSP-flavor is processed at a non-penultimate SR Segment \u00a0  Endpoint Node, the PSP behavior is not performed as described in the \u00a0  pseudocode below since Segments Left would not be zero. For example, for the End behavior, I'm assuming that behavior 1 is performed instead of 2 (or 4, or 29, or 31) if SL != 0.\u00a0 Should this be done even if the node did not advertise the non-PSP flavor?\u00a0 If the node is not known to support the PSP flavor, should it be an error to receive a packet requesting that behavior? If only the PSP flavor is advertised, can the Source assume that the node also supports the non-PSP flavor? \u00a0 [BTW, I'm asking about advertisement because \u00a74.16.1.1 makes the statement \u00a0 that the nodes \"advertise the SIDs instantiated on them via control plane \u00a0 protocols as described in Section 9\".\u00a0 Even though \u00a79 talks about control \u00a0 plane protocols are \"not necessary for an SDN control plane\" because \"one \u00a0 expects the controller to explicitly provision the SIDs\".] (3e) \u00a74.16.2 describes the USP flavor, which is one where the endpoint consumes the packet by processing the next header.\u00a0 I don't understand how the outcome due to the extended process is different from the original one in \u00a74.1.\u00a0 Can you please explain?\u00a0 It seems to me that the externally observable result is the same. I have the same question about the USD flavor and the externally observable behavior related to \u00a74.1. In general, the observable behavior of \u00a74.1, USP, and USD seem the same to me.\u00a0 The next two points are related. (3f) \u00a74.16.3 describes the USD flavor, which assumes that the decapsulation results in a packet that can be forwarded.\u00a0 Can the FIB lookup result in a local destination? (3g) Does the USD flavor mean that, for the End behavior (as described in \u00a74.1), the action of \"process the next header in the packet\" cannot result in a forwarded packet?\u00a0 Same question for the USP behavior? (3h) The last paragraph in \u00a74.16.3: \u00a0  An implementation that supports the USD flavor in conjunction with \u00a0  the USP flavor MAY optimize the packet processing by first looking \u00a0  whether the conditions for the USD flavor are met, in which case it \u00a0  can proceed with USD processing else do USP processing. What are the \"conditions for the USD flavor\"?\u00a0 As far as I can tell from the document, the only condition is for the specific behavior to be signaled.\u00a0 What else? Going back to the questions above...\u00a0 When is the option to optimize possible?\u00a0 Does a specific behavior have to be used?\u00a0 Behavior 30 (End with USP&USD)?\u00a0 Or can it also optimize if behavior 3 (End with USP) is signaled? (4) \u00a710.2 creates a new registry with an \"FCFS\" registration procedure.\u00a0 I am assuming that this is the same as the \"First Come First Served\" (no abbreviation!) policy from  rfc8126 ; please add a reference if that is the case.\u00a0 The description used is not the same as what  rfc8126  specifies: - \"Requests for allocation...must include a...preferably also a brief \u00a0 description of how the value will be used.\"\u00a0  Using \"preferably\" indicates \u00a0 that a description is optional.\u00a0 However, it is not optional in  rfc8126 . - \"...brief description...may be provided with a reference to an Internet \u00a0 Draft or an RFC or in some other documentation that is permanently and \u00a0 readily available.\"\u00a0 There is no such requirement in  rfc8126 .\u00a0 For example, \u00a0 the \"Specification Required\" policy requires \"a permanent and readily \u00a0 available public specification\".\u00a0 Is that what you want\u00a0 instead? (5) This point is for the IESG to discuss. \u00a74.16.1.2: \u00a0 \u00a0 \u00a0 The End, End.X and End.T behaviors with PSP do not contravene \u00a0 \u00a0 \u00a0 Section 4 of [ RFC8200 ] because the destination address of the \u00a0 \u00a0 \u00a0 incoming packet is the address of the node executing the behavior. The spring WG's interpretation of  rfc8200  was a central point in the appeal presented against the WG consensus on this document.\u00a0 The text above, I believe, reflects that consensus.\u00a0  However, given that the document relies on the spring WG's interpretation of  rfc8200 , I think it would be better if the text is explicit.\u00a0  Suggestion: to add at the end of the paragraph>   \u00a0  This conclusion represents the consensus interpretation of the spring WG.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-24 00:52:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-24 00:43:29-07:00",
    "text": "The current requirement that IANA-assigned SRv6 Endpoint Behavior codepoints are used, with no range reserved for local assignment, seems to be inviting codepoint squatting from the nominally reserved range. Why is there an absolute requirement for registration (even FCFS) without ranges for local or experimental use?\u00a0 (What are the various reserved ranges reserved for?) The (normative) pseudocode does not seem to handle the case when the SRH is omitted for the degenerate case where there is only a single segment, or for the PSP flavor. The pseudocode for the PSP and USP procedures seem incorrect -- Hdr Ext Len is measured in units of 8 octets, and does not include the first 8 octets of the extension header, but Payload Length is measured in octets.\u00a0 Literally decreasing the Payload Length by the Hdr Ext Len value will produce a malformed IPv6 packet. If \"PSP operation is deterministically controlled by the SR Source Node\", why do we need to define behavior codepoints that (for example) use both PSP and USP?\u00a0 I don't see how there is full determinism in this case while being different from the \"PSP only\" flavor. There are numerous factual errors and un/under-specified protocol behavior (see COMMENT), including: how to set the outer Hop Limit (multiple instances), the order of segments in the SRH, specification of headend behavior by reference to informal example, L2 frame en/decapsulation procedures, and the \"Opaque\" note for endpoint behavior 65535. A discussion topic, which may or may not entail changes to this document:  RFC 8200  notes that specifications of new extension headers need to indicate their ordering constraints with respect to the other extension headers, but  RFC 8754  makes no such indications.\u00a0 Are there in practice ordering constraints that we should attempt to document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-09 09:04:52-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-24 00:52:05-07:00",
    "text": "[edited to remove nonsensical point that had crept in about the SRH being a new extension header; it's \"just\" a routing header] The current requirement that IANA-assigned SRv6 Endpoint Behavior codepoints are used, with no range reserved for local assignment, seems to be inviting codepoint squatting from the nominally reserved range. Why is there an absolute requirement for registration (even FCFS) without ranges for local or experimental use?\u00a0 (What are the various reserved ranges reserved for?) The (normative) pseudocode does not seem to handle the case when the SRH is omitted for the degenerate case where there is only a single segment, or for the PSP flavor. The pseudocode for the PSP and USP procedures seem incorrect -- Hdr Ext Len is measured in units of 8 octets, and does not include the first 8 octets of the extension header, but Payload Length is measured in octets.\u00a0 Literally decreasing the Payload Length by the Hdr Ext Len value will produce a malformed IPv6 packet. If \"PSP operation is deterministically controlled by the SR Source Node\", why do we need to define behavior codepoints that (for example) use both PSP and USP?\u00a0 I don't see how there is full determinism in this case while being different from the \"PSP only\" flavor. There are numerous factual errors and un/under-specified protocol behavior (see COMMENT), including: how to set the outer Hop Limit (multiple instances), the order of segments in the SRH, specification of headend behavior by reference to informal example, L2 frame en/decapsulation procedures, and the \"Opaque\" note for endpoint behavior 65535.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-28 15:19:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-09 09:04:52-08:00",
    "text": "Thanks for the updates through to the -26; they help a lot. However, I do think there is one final Discuss-level point that needs to be resolved: it's mostly a process point, to make sure that what we say in this document complies to the requirements that were laid out in  RFC 8754  for the procedure we're trying to follow.\u00a0 Specifically, in the process of trying to finalize my review comments, I ended up doing a lot of background reading, in which I noticed that  RFC 8754  says: \u00a0  New SIDs defined in the future MUST specify the mutability properties \u00a0  of the Flags, Tag, and Segment List and indicate how the Hashed \u00a0  Message Authentication Code (HMAC) TLV (Section 2.1.2) verification \u00a0  works.\u00a0 Note that, in effect, these fields are mutable. This is a bit confusing to me, in that the SIDs themselves appear as entries in the Segment List, and it's not quite clear when or how a per-SID behavior relating to fields in the containing SRH might come into play.\u00a0 However, given that we allocate a behavior codepoint for \"the SID defined in  RFC 8754 \", I am forced to conclude that the behaviors specified in this document meet the definition of \"new SIDs\" that are being defined \"in the future\" (from the reference point of  RFC 8754 ), and therefore that they must specify the indicated properties. I'm told out of band that the intent is to do the same thing that  RFC 8754  does for the SID it defines, and so this should be trivial to resolve just by adding a brief note that (e.g.) \"the SIDs specified in this document have the same HMAC TLV handling and mutability properties of the Flags, Tag, and Segment List field as the SID specified in  RFC 8754 \".\u00a0 However, I believe that such an explicit statement is required, and that we would introduce an internal inconsistency between this document and  RFC 8754  if we say nothing on this topic.\u00a0 In particular, I think that we would not inherit that behavior as some kind of default behavior if we make no statement at all. I am sorry that I did not notice this earlier, but I feel that it is important to remain consistent with the requirements of  RFC 8754  and thus that this is appropriate to raise as a Discuss-level point, even if I have previously reviewed the text in question.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-10-29 22:29:51-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 23:40:28-07:00",
    "text": "I support Alvaro's and others' discuss points.\u00a0 I have only a few points that I think are easily cleared. [ section 3.2 ] * I'm a bit concerned about this first example, as it might give the mistaken \u00a0 impression that fc00::/7 is free for anyone to carve up as they wish \u00a0 (I say this regardless of what this operator may or may not have done). \u00a0 Per 4193, operators are supposed to generate random /48s from fd00::/8. \u00a0 I think this is easily corrected though, and I'd suggest: \u00a0 OLD: \u00a0 .....\u00a0 The provider historically deployed IPv6 and assigned \u00a0 infrastructure addresses from a portion of the fc00::/7 prefix.\u00a0 They \u00a0 further subdivided the prefix into three /48 prefixes (Country X, \u00a0 Country Y, Country Z) to support their SRv6 infrastructure.\u00a0 From \u00a0 those /48 prefixes each router is assigned a /64 prefix from which \u00a0 all SIDs of that router are allocated. \u00a0 NEW: \u00a0 .....\u00a0 The provider historically deployed IPv6 and assigned \u00a0 infrastructure addresses from ULA space [ RFC 4193 ].\u00a0 They specifically \u00a0 allocated three /48 prefixes (Country X, Country Y, Country Z) to \u00a0 support their SRv6 infrastructure.\u00a0 From those /48 prefixes each router \u00a0 was assigned a /64 prefix from which all SIDs of that router are allocated. [ section 4.16.2 ] * I'm not sure I understand what the value of specifying USP is.\u00a0 This looks \u00a0 to me like an implementation detail and seems unnecessary.\u00a0 In all cases \u00a0 where the S03 code block is entered it's the processing of the remainder of \u00a0 the inner packet that's important, I would think. \u00a0 I guess, what's the value of specifying the way in which an implementation \u00a0 can begin to process the next header?\u00a0 Is this for chained SRHs and thus \u00a0 resubmitting the inner SRH to the same SID processing (8200 says that the \u00a0 RH 'should appear at most once', but that's as strong as the text gets)? [ section 4.16.3 ] * This too seems like an implementation detail, and it's not clear what it's \u00a0 adding to the document.\u00a0 But I must be misunderstanding something. [ section 7 ] * What flow label is included in hashing where End.DX4 is concerned?\u00a0 If \u00a0 it's the flow label of the outermost IPv6 header, then the same question \u00a0 comes to mind for End.X and End.DX6; I'd assumed it would be the inner \u00a0 packet's flow label (and src/dst addresses) that would factor into the \u00a0 flow hashing. [ section 8 ] * Of what value to the ingress node is knowledge of USP or USD behaviour \u00a0 at the terminus?\u00a0 That still seems like exposing an implementation detail.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-28 09:21:21-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-21 11:23:16-07:00",
    "text": "Section 3.1.\u00a0 (In case I missed it, please provide the obvious reference) Per \u201cIn such a case, the semantics and format of the ARG bits are defined as part of the SRv6 endpoint behavior specification\u201d, is \u201cendpoint behavior specification\u201d Section 4 or another document?\u00a0 If the former, I don\u2019t see any references to argument bits in the pseudo-code of the Section 4.* subsections.\u00a0 If the latter, what document?\u00a0 Can the behaviors be polymorphic (i.e., same network behavior accepting different arguments)?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-03-30 15:52:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 21:15:01-07:00",
    "text": "[ general ] * ND in IPv6 is more than just its analogous ARP function (as immediately \u00a0 evidenced by the need to support passing the NA flags).\u00a0 I'm concerned that \u00a0 this approach isn't actually satisfactory for IPv6, and could end up \u00a0 constraining existing and future ND extensions and uses. \u00a0 [1] New flags \u00a0 As new flags are defined in the NA message, they will not be deployable \u00a0 in these environments until this standard (and possibly others) is updated. \u00a0 A more forward-compatible option might be to just include the whole NA \u00a0 \"flags plus reserved\" word (there is room for it in the format in \u00a0 section 2). \u00a0 [2] Current and new NA ND Options \u00a0 This approach doesn't support sending additional ND Options in the NA, and \u00a0 therefore things like Secure Neighbor Discovery (SeND,  RFC 3971 ) cannot \u00a0 be supported (nor can any future NA option). \u00a0 Arguably, ND proxying might best be disabled when a node is attempting to \u00a0 use SeND and/or whenever a Nonce Option is present an NA.\u00a0 Nevertheless, \u00a0 new ND options might be specified that can be carried in NS/NA messages. \u00a0  RFC 4861  sections 4.2 and 4.3 say that \"[f]uture versions of this protocol \u00a0 may define new option types\", and while it also says that \"[r]eceivers \u00a0 MUST silently ignore any options they do not recognize and continue \u00a0 processing the message\", in this case it would be the infrastructure that \u00a0 would prevent two nodes from attempting to use a newer ND option on either \u00a0 side of this PE/CE proxying boundary and not necessarily a limitation of the \u00a0 nodes themselves. \u00a0 There is no space for these options in the current section 2 format. \u00a0 Can it be extended to optionally carry the ND options that a PE has \u00a0 observed to be sent by the node? \u00a0 Alternatively, I think we'll need some text that ND proxying MUST be \u00a0 disabled if NSes contain any options other things like TLLAO or if NAs are \u00a0 observed to have anything other than SLLAO. \u00a0 Basically, I think we should take care to not impede the deployment of any \u00a0 extensions to ND.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-12-01 03:24:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 13:44:00-07:00",
    "text": "Hi, Hopefully a relatively easy discuss to resolve and this might just be my ignorance here: Section 2 states that I flag is used for an immutable ARP/ND Binding which is for a configured ARP/ND entry. Section 3.2 Reception of the EVPN ARP/ND Extended Community, has the following text: \u00a0 \u00a0 \u00a0 *\u00a0 Receiving multiple EVPN MAC/IP Advertisement routes with I=1 \u00a0 \u00a0 \u00a0 \u00a0  for the same IP but different MAC is considered a \u00a0 \u00a0 \u00a0 \u00a0  misconfiguration. But wouldn't this scenario occur if the configured ARP/ND entry was changed to point to a new MAC address? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-10-12 07:37:38-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 09:16:59-07:00",
    "text": "Be ye not afraid! This DISCUSS should be fairly trivial to address... This allows for more information to be carried with MAC/IP Advertisements. It seems to me that this gives a DoS-style attacker more opportunities to exhaust state on routers - I could sit on a wire and create lots of ARP/ND states (make up new IP and MAC combinations), causing this to be propagated and burning memory / state / etc. This is somewhat discussed in  RFC 7432 , but the technique in this document seems like it makes this issue somewhat worse - a single sentence in the Security Considerations noting it would satisfy me (as would an explanation that I'm mistaken :-)). I also support EK & Rob's DISCUSSes",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-15 07:50:37-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 23:17:01-08:00",
    "text": "We can probably sort this out during the IESG telechat, but I want to be sure it's flagged. A number of the shepherd writeup questions were hastily answered and the information we need is largely missing.\u00a0 For instance: -- > What type of RFC publication is being requested on the IETF stream (Best > Current Practice, Proposed Standard, Internet Standard, > Informational, Experimental or Historic)? Why is this the proper type > of RFC? Do all Datatracker state attributes correctly reflect this intent? yes. -- There are three questions here, and only the last of them can be answered \"yes\".\u00a0 The second one is the most interesting one. -- > Several IETF Areas have assembled lists of common issues that their > reviewers encounter. For which areas have such issues been identified > and addressed? For which does this still need to happen in subsequent > reviews? no. -- I don't understand. -- > Have reasonable efforts been made to remind all authors of the intellectual > property rights (IPR) disclosure obligations described in  BCP 79 ? To > the best of your knowledge, have all required disclosures been filed? If > not, explain why. If yes, summarize any relevant discussion, including links > to publicly-available messages when applicable. yes. -- So something's been filed, or reasonable reminders were sent?\u00a0 If the former, where's the discussion or what was its result?\u00a0 According to the Last Call text, there was one filing.\u00a0 Was it discussed?\u00a0 Is it a source of concern?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-01-03 11:36:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 06:27:36-08:00",
    "text": " ** Section 2. health score.\u00a0 The definition of a health score defined here (0 to 100) is inconsistent with Section 3.2 and the YANG definition in  draft-ietf-opsawg-service-assurance-yang  which uses -1 to 100.\u00a0 Given the shepherd\u2019s write-up for the -yang document says that this (changing from 0..100 to -1..100) was a last-minute addition, it seems that perhaps this document hasn\u2019t caught up. ** Section 4. However, the SAIN agents must be \u00a0  secured: a compromised SAIN agent may be sending wrong root causes or \u00a0  symptoms to the management systems.\u00a0 This can be partially achieved \u00a0  by correctly setting permissions of each node in the YANG model as \u00a0  described in the companion document \u00a0  [ I-D.ietf-opsawg-service-assurance-yang ] -- Can a more specific section reference be provided into the  draft-ietf-opsawg-service-assurance-yang  on this configuration? -- what does it mean to \u201csecure\u201d the SAIN agent and how is this related to a YANG configuration.\u00a0 Isn\u2019t the agent either a running process on the device or a system/process on another system harvesting information (metrics)?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-10-07 03:47:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-05 17:51:33-07:00",
    "text": "I am balloting DISCUSS because I believe that the behavior specified in this document is not clear enough.\u00a0 I think these points should be easy to address. (1) The main behavior in this document (using the reverse metric) is covered in the following sentences: \u00a76: \u00a0  A router receiving a Hello packet from its neighbor that contains the \u00a0  Reverse Metric TLV on a link SHOULD use the RM value to derive the \u00a0  metric for the link to the advertising router in its Router-LSA... \u00a0  ... \u00a0  The neighbor SHOULD use the reverse TE metric value... \u00a77: \u00a0  Implementations SHOULD NOT accept the RM from its neighbors by default  \u00a0  and SHOULD provide a configuration option to enable the acceptance of  \u00a0  the RM from neighbors on specific links. For all cases, why is this behavior recommended and not required?\u00a0 When is it ok to not use the RM, or to accept it by default? (2) \u00a76: \u00a0  A router stops including the Reverse Metric TLV in its Hello packets \u00a0  when it needs its neighbors to go back to using their own provisioned \u00a0  metric values.\u00a0 When this happens, a router that had modified its \u00a0  metric in response to receiving a Reverse Metric TLV from its \u00a0  neighbor should revert to using its provisioned metric value. No normative language is used here -- should there be a SHOULD/MUST there? Even if \"should revert\" is used, the behavior is unclear and could be interpreted as not required.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-10-06 16:52:41-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-10-05 17:26:45-07:00",
    "text": "I hope this is a quick one. A naive reading of Sec 2.2 implies that a router could generate reverse-metric TLVs quite rapidly, triggering a storm of TLVs from a potentially large number of neighbors. Each reverse metric advertisement generates N LSAs, increasing the amplification of any sort of misconfiguration or misbehavior far more than a traditional LSAs that is updated too often. At the very least, this ought to come up in security considerations, but I wonder if applying some sort of rate limit (beyond which neighbors are free to ignore) would be a firmer way of limiting the problem. I'm flexible on the best way forward.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-10-06 16:53:25-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-06 16:52:41-07:00",
    "text": "hanks for handling my DISCUSS.I believe you are still working out the details with Alvaro, but I am satisfied.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-10-10 06:53:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-06 03:50:41-07:00",
    "text": "Thanks for this document. I support Alvaro's discuss.\u00a0 Having read Alvaro's discuss after writing my ballot comments it seems to be some what closely related, but I am also balloting discuss because I find the operational guidelines to be unclear. (1) p 8, sec 7.\u00a0 Operational Guidelines\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  Implementations MUST NOT signal reverse metric to neighbors by\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0  default and MUST provide a configuration option to enable the\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  signaling of reverse metric on specific links.\u00a0 Implementations\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  SHOULD NOT accept the RM from its neighbors by default and SHOULD\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  provide a configuration option to enable the acceptance of the RM\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  from neighbors on specific links.\u00a0 This is to safeguard against\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   \u00a0  inadvertent use of RM.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   I'm not really sure that I properly understand how this feature works from a manageability perspective.\u00a0 Particularly for your first use case, when considering that the proposal is for per link configuration for the acceptance of RM from neighbours.\u00a0 This would seem to suggest that before you can make use of reverse-metric you have to already have determined the links on the affected devices to then configure them to accept the reverse-metrics, at which point, doesn't this partially defeat the use case?\u00a0 Or is the main goal to simplify the coordination of changing the metric at both ends of the link at the same time?\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   Or is the intention that during the maintenance window the operators would enable the \"allow receipt of reverse-metrics\" on all links within, say, an area?\u00a0 If so, would hierarchical device and area specific configuration be more appropriate?\u00a0 E.g., allow it to be enabled/disbaled on individual links, but also allow more coarse grained configuration. Not as an update for this document, but I am assuming that the LSR working group with eventually update or augment the OSPF YANG module with standard configuration to support this feature. (2) p 8, sec 7.\u00a0 Operational Guidelines \u00a0  For the use case in Section 2.1, it is RECOMMENDED that the network \u00a0  operator limits the period of enablement of the reverse metric \u00a0  mechanism to be only the duration of a network maintenance window. Presumably this isn't feasible when the CE is not managed by the provider?\u00a0 In this scenario, is the expectation that the configuration to accept reverse-metrics would just be left always enabled on the CE device?\u00a0 Is this a security concern? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-09-22 20:33:55-07:00",
    "text": "Many thanks for taking on the task of producing a roll-up update for the core TCP specification!\u00a0 I am sure it was a lot of work, but I am happy to see it done. That said, I do have a few points that I would like to have a bit more discussion on before the document is published; I'm happy to see that Warren already linked to https://www.ietf.org/blog/handling-iesg-ballot-positions/  on the topic of what a DISCUSS position can (and cannot) mean. (1) We incorporate some long-standing enhancements that improve the security and robustness of TCP (in particular, random ISN and protection against off-path in-window attacks come to mind), but only at SHOULD or MAY requirements level. For example, we currently say: \u00a0  A TCP implementation MUST use the above type of \"clock\" for clock- \u00a0  driven selection of initial sequence numbers (MUST-8), and SHOULD \u00a0  generate its Initial Sequence Numbers with the expression: \u00a0  ISN = M + F(localip, localport, remoteip, remoteport, secretkey) and: \u00a0 \u00a0 \u00a0 \u00a0  +\u00a0  RFC 5961  [37] section 5 describes a potential blind data \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 injection attack, and mitigation that implementations MAY \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 choose to include (MAY-12).\u00a0 TCP stacks that implement \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  RFC 5961  MUST add an input check that the ACK value is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [...] What prevents us from making a MUST-level requirement for randomized ISNs?\u00a0 Is it just the fact that it was only a SHOULD in  RFC 6528  and a perception that promoting to a MUST would be incompatible with retaining Internet Standard status? Likewise, what prevents using stronger normative language (e.g., MUST) for the  RFC 5961  protections? It seems to me that these mechanisms are of general applicability and provide significant value for use of TCP on the internet, even though they are not fully robust and do not use cryptographic mechanisms.\u00a0 If there are scenarios where their use is harmful or even just not applicable, that seems like an exceptional case that should get documented so as to strengthen the general recommendation for the non-exception cases. (2) I think this is just a process question to ensure that the IESG knows what we are approving at Internet Standard maturity, though it is certainly possible that I misunderstand the situation. In Section 3.7.3 we see the normative statement (SHLD-6) that \"when the when the effective MTU of an interface varies packet-to- packet, TCP implementations SHOULD use the smallest effective MTU of the interface to calculate the value to advertise in the MSS option\".\u00a0 This seems to originate in  RFC 6691  (being obsoleted by this document), but  RFC 6691 is only an Informational document and has not had an opportunity to \"accumulate experience at Proposed Standard before progressing\", to paraphrase  RFC 6410 . Similarly, Section 3.9.2 has (SHLD-23) \"Generally, an application SHOULD NOT change the DiffServ field value during the course of a connection (SHLD-23).\"\u00a0 This is a bit harder to track down, as the DiffServ field was not always known by that name.\u00a0 I actually failed to find a directly analogous previous statement of this guidance (presumably my error), and thus don't know if it had any experience at the PS level or not. RFC 6410  seems pretty clear that some revisions are okay in Internet Standards without such \"bake time\" at PS, but it does seem like something that should be done consciously rather than by accident. (3) This is also a process point for explicit consideration by the IESG. Appendix A.2 appears to discuss a few (rare) scenarios in which the technical mechanisms of this document fail catastrophically (e.g., getting stuck in a SYN|ACK loop and failing to complete the handshake). Does this meet the \"resolved known design choices\" and \"no known technical omission\" bar required by  RFC 2026  even for *proposed* standard? (Note that  RFC 2026  explicitly says that the IESG may waive this requirement, at least for PS.) (AFAICT one such scenario is reported at https://www.rfc-editor.org/errata_search.php?eid=3305  , which the change log for this document calls out as \"not applicable due to other changes\"; I am not sure which \"other changes\" are intended, for this case.) (4) Another point mostly just to get explicit IESG acknowledgment (elevating one of Lars' comments to DISCUSS level, essentially). As the changelog (and gen-art reviewer!) notes: \u00a0  Early in the process of updating  RFC 793 , Scott Brim mentioned that \u00a0  this should include a PERPASS/privacy review.\u00a0 This may be something \u00a0  for the chairs or AD to request during WGLC or IETF LC. I don't see any evidence to suggest that such a review actually occurred.\u00a0 Do we want to seek out such a targeted review before progressing?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-11 02:46:18-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-20 07:18:33-07:00",
    "text": "The IESG needs to approve the following DOWNREFs during the telechat: \u00a0 DOWNREF [10] from this Internet Standard to Proposed Standard  RFC6298 . \u00a0 DOWNREF [2] from this Internet Standard to Draft Standard  RFC1191 . \u00a0 DOWNREF [7] from this Internet Standard to Proposed Standard  RFC3168 . \u00a0 DOWNREF [11] from this Internet Standard to Proposed Standard  RFC6633 . \u00a0 DOWNREF [9] from this Internet Standard to Draft Standard  RFC5681 . \u00a0 DOWNREF [5] from this Internet Standard to Proposed Standard  RFC2675 . \u00a0 DOWNREF [4] from this Internet Standard to Proposed Standard  RFC2474 .",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-09-22 15:52:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-09-22 15:51:13-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-12-16 10:32:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 15:52:37-07:00",
    "text": "[ \"Then I said unto you, Dread not, neither be afraid of of this DISCUSS, for it be easy to address\" ] I'm raising one of Erik's comments to a DISCUSS, because I think that it is important enough that it needs addressing: ---- [S3.9.2.1] * I feel like there should be some additional caveat about security \u00a0 implications of support for source routing.\u00a0  RFC 6274 , for example, says \u00a0 packets with LSRR (6274s3.13.2.3) and SSRR (6274s3.13.2.4) options should \u00a0 be dropped, citing various security concerns. \u00a0 I'm not sure there needs to be a lot of text; perhaps just an observation \u00a0 that some end systems may not support the source route semantics described \u00a0 here for security (or policy) reasons? ---- I realize that this document isn't intended to be a summary of all RFCs which mention anything related to TCP, but this particular point seems like it could do with an extra bit of reinforcement. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-02-17 06:37:48-08:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 13:45:17-07:00",
    "text": "* I found at least one reference that should be normative reference but they are not. Section 3.8.5 : describes -- \u00a0   \u00a0 \u00a0 TCP implementations MUST still include support for the urgent mechanism (MUST-30). Details can be found in  RFC 6093  [38] \u00a0  \u00a0 This to ne makes  RFC6093  a must to read and understand to deploy this specification. Hence it should in the normative references. * (This perhaps more process thing than technical), me and Benjamin Kaduk discussed another issue regarding urgent pointer. This specification specifies - \u00a0 \u00a0 \u00a0  Pointer indicates first non-urgent octet\u00a0 \u00a0 \u00a0  | MUST-62|  \u00a0  \u00a0  RFC1011  rectifies  RFC973  to - \u00a0 \u00a0 \u00a0 The urgent pointer points to the \u00a0 \u00a0 \u00a0 \u00a0  last octet of urgent data (not to the first octet of non-urgent \u00a0 \u00a0 \u00a0 \u00a0  data). \u00a0 So what does happen to  RFC1011  rectification then when 793bis is not bis anymore? Is this a known fact and there is conscious decision not to do anything about it? or was this a unknown fact and that part of  RFC1011  need to be obsoleted (how?)?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-26 09:11:21-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-07 06:58:03-08:00",
    "text": "As per IANA: The IANA Considerations section needs to mention the registration procedure for the new registry. I also agree (at least) with comments raised by Adam, they are similar to what I raised in my own review. Some of them need fixes (e.g. to text or examples).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-29 09:28:23-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-26 09:11:21-07:00",
    "text": "Thank you for addressing earlier comments, including comments from Adam. The media type registration: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"application/x-x509-ca-cert\"\t  \t\u00a0  \"application/x-x509-ca-ra-cert\"\t  \t\u00a0  \"application/x-x509-next-ca-cert\"\t  \t\u00a0  \"application/x-pki-message\" These still need registration templates, even if they are grandfathered.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-08 13:00:37-08:00",
    "end_reason": "position_updated",
    "start": "2019-02-06 21:05:08-08:00",
    "text": "Thanks for this easy-to-read document! I have a fairly silly point, where the behavior seems to still be underspecified: Section 4.4 says that an error-handling path should \"ignore this request\"; does that mean that it should terminate the underlying connection over which HTTP is running?\u00a0 Return an HTTP error?\u00a0 Keep the connection open until the peer times out?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-02-07 06:34:16-08:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3890 I have not had time to give this as thorough a read as I would like, and would feel necessary were we advancing it at PS, so I am not confident in its security properties. I have nevertheless noted a number of issues that I think merit a DISCUSS. DETAIL S 2.3. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 then a locally generated self-signed certificate MUST be used. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 The keyUsage extension in the certificate MUST indicate that it >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 is valid for digitalSignature and keyEncipherment (if available). >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 The self-signed certificate SHOULD use the same subject name as >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 in the PKCS #10 request.\u00a0 In this case the messageType is PKCSReq >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (see Section 3.2.1.2). Should it use the same *key* as the PKCS#10 request? S 2.3. >\u00a0   >\u00a0 \u00a0 \u00a0 Note that although the above text describes several different types >\u00a0 \u00a0 \u00a0 of operations, in practice most implementations always apply the >\u00a0 \u00a0 \u00a0 first one even if an existing certificate already exists.\u00a0 For this >\u00a0 \u00a0 \u00a0 reason support for the first case is mandatory while support for the >\u00a0 \u00a0 \u00a0 latter ones are optional (see Section 2.9). we probably shouldn't have a SHOULD for something we know people don't do, especially in an Info document. S 2.5. >\u00a0 \u00a0 \u00a0 using CMS (Section 3). >\u00a0   >\u00a0 \u00a0 \u00a0 If the CA supports certificate renewal and if the CA policy permits >\u00a0 \u00a0 \u00a0 then a new certificate with new validity dates can be issued even >\u00a0 \u00a0 \u00a0 though the old one is still valid.\u00a0 The CA MAY automatically revoke >\u00a0 \u00a0 \u00a0 the old client certificate.\u00a0 To renew an existing certificate, the Is this sentence about automatically revoking related to the previous one? I.e., can I revoke the old certificate if the new one is not yet valid? That would seem unwise. S 3. >\u00a0 \u00a0 \u00a0 confidentiality use two layers of CMS, as shown in Figure 2.\u00a0 By >\u00a0 \u00a0 \u00a0 applying both enveloping and signing transformations, the SCEP >\u00a0 \u00a0 \u00a0 message is protected both for the integrity of its end-to-end >\u00a0 \u00a0 \u00a0 transaction information and the confidentiality of its information >\u00a0 \u00a0 \u00a0 portion.\u00a0 Some messages do not require enveloping, in which case the >\u00a0 \u00a0 \u00a0 EnvelopedData in Figure 2 is omitted. I want to make sure I understand which messages *do* require enveloping. I would assume PKSReq, at least if it includes the challenge password, right? Maybe I'm missing it, but i don't see a clear statement anywhere. S 3.1. >\u00a0 \u00a0 \u00a0 the recipient's public key.\u00a0 If the key is encryption-capable (for >\u00a0 \u00a0 \u00a0 example RSA) then the messageData is encrypted using the recipient's >\u00a0 \u00a0 \u00a0 public key with the CMS KeyTransRecipientInfo mechanism.\u00a0 If the key >\u00a0 \u00a0 \u00a0 is not encryption-capable (for example DSA or ECDSA) then the >\u00a0 \u00a0 \u00a0 messageData is encrypted using the challengePassword with the CMS >\u00a0 \u00a0 \u00a0 PasswordRecipientInfo mechanism. This requires a very strong ChallengePassword, which I don't see you saying anywhere. S 3.1. >\u00a0 \u00a0 \u00a0 Note that some earlier implementations of this specification dealt >\u00a0 \u00a0 \u00a0 with non-encryption-capable keys by omitting the encryption stage, >\u00a0 \u00a0 \u00a0 based on the text in Section 3 that indicated that \"the EnvelopedData >\u00a0 \u00a0 \u00a0 is omitted\".\u00a0 This alternative processing mechanism SHOULD NOT be >\u00a0 \u00a0 \u00a0 used since it exposes the challengePassword used to authorise the >\u00a0 \u00a0 \u00a0 certificate issue. Why is this not a MUST? S 8.3. >\u00a0   >\u00a0 \u00a0 \u00a0 The challengePassword sent in the PKCS #10 enrolment request is >\u00a0 \u00a0 \u00a0 signed and encrypted by way of being encapsulated in a pkiMessage. >\u00a0 \u00a0 \u00a0 When saved by the CA, care should be taken to protect this password, >\u00a0 \u00a0 \u00a0 for example by storing a salted iterated hash of the password rather >\u00a0 \u00a0 \u00a0 than the password itself. this won't work if you are using it for encryption. S 8.7. >\u00a0 \u00a0 \u00a0 is public and thus encrypting the requests is of questionable value. >\u00a0 \u00a0 \u00a0 In addition CRLs and certificates sent in responses are already >\u00a0 \u00a0 \u00a0 signed by the CA and can be verified by the recipient without >\u00a0 \u00a0 \u00a0 requiring additional signing and encryption.\u00a0 More lightweight means >\u00a0 \u00a0 \u00a0 of retrieving certificates and CRLs such as HTTP certificate-store >\u00a0 \u00a0 \u00a0 access [13] and LDAP are recommended for this reason. This statement appears to directly cut against  RFC 7258 , which establishes the IETF consensus that we should be considering disclosure of metadata and its impact on pervasive monitoring. A protocol which claims to have IETF consensus should not take the opposite position. In addition to this, the claim that certificates are inherently public is in fact not universally true, as discussions about redaction in CT demonstrate. Moreover, the fact that a given endpoint has given certificate is not public. S 8.8. >\u00a0 \u00a0 \u00a0 default to SHA-1, with many supporting only that hash algorithm with >\u00a0 \u00a0 \u00a0 no ability to upgrade to a newer one.\u00a0 SHA-1 is no longer regarded as >\u00a0 \u00a0 \u00a0 secure in all situations, but as used in SCEP it's still safe.\u00a0 There >\u00a0 \u00a0 \u00a0 are three reasons for this.\u00a0 The first is that attacking SCEP would >\u00a0 \u00a0 \u00a0 require creating a SHA-1 collision in close to real time, which won't >\u00a0 \u00a0 \u00a0 be feasible for a very long time. I don't believe that this statement reflects the consensus of the cryptographic community and it's also not clear to me that the requirement for real-time is correct without quite a bit more analysis.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-08 05:16:32-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-06 05:36:16-08:00",
    "text": "Given the purpose of this document is to describe a deployed protocol that however is not recommended by the IETF community for new deployments anymore, the IESG should discuss if this document should be published as Historic.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-02-23 05:53:10-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-15 16:48:04-08:00",
    "text": "** In following the robust discussion in the TSVART thread ( https://mailarchive.ietf.org/arch/msg/tsv-art/vcJRc6oXRRiCl5-bouLTyRVbTc8/ ), it appears that design assumption of this document is to build on  RFC9301  and  RFC9303 .\u00a0 Section 3 helpfully outlines unique deployment assumptions for PubSub relative to  RFC301 .\u00a0 Missing is an explicit summary of what Alberto stated in  https://mailarchive.ietf.org/arch/msg/tsv-art/80yDl25rP3Ev4H_x_rOstue_J7M/ .\u00a0 There appears to be a stronger requirements to use LISP-SEC or associated pre-shared secret to secure this new mechanism which is not the same as the baseline  RFC9301  (per Section 1.1).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-03-30 16:44:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-01-02 04:08:23-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-extra-sieve-action-registry-05 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (trivial to address), some non-blocking COMMENT points, and some nits. Special thanks to Bron Gondwana for the shepherd's detailed write-up including the WG consensus and the justification of the intended status (but see my DISCUSS below).  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Intended status The I-D text says \"Informational\" while the meta-data and the shepherd's review say \"proposed standard\".",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-03 06:29:15-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-04 11:17:54-08:00",
    "text": "A registry is surely very useful. Currently, all entries are based on RFCs. Is it the intention of this RFC to change that practice by setting the registry policy to Expert Review? It seems more appropriate to set the policy to RFC Required.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-31 12:06:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-19 15:44:36-07:00",
    "text": "As for other reviewers, many of my comments duplicate those for the OSPF document; I expect that the analogous responses apply and am fine if they only appear for one document's review. Here, the question I have about normative language applies to the text in Section 3: \u00a0  When a router propagates a prefix between ISIS levels ([ RFC5302 ], it \u00a0  MUST preserve the ELC signaling for this prefix. The scenario in question is analogous to the OSPF cross-area case: is the router propagating the prefix between ISIS levels required to implement this document; is preservation of the flag value a new requirement from this document vs. a preexisting property; and is this document trying to make normative requirements of devices that don't implement this document? Likewise, the ASBR case for cross-protocol redistribution seems to rather inherently require understanding the semantics of the flags being translated.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-27 22:27:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-07 15:06:50-07:00",
    "text": "Thanks for this document; it's generally well-written and the changes since 7049 are helpful.\u00a0 I do have a few points that may need discussion before publication, though. Let's discuss whether the framing of tag number 35 for \"regular expressions that are roughly in [PCRE] form or a version of the JavaScript regular expression syntax\" meets the interoperability expectations for Internet Standard status (bearing in mind that we are defining a data format and not a protocol).\u00a0 I note that it is okay to leave the codepoint allocated with the current meaning and the previous document as its reference, but decline to discuss it in the document going for STD (we are in the process of doing that with COSE countersignatures at the moment). The example in Section 5 of \"the item is a map that has byte strings for keys and contains at least one pair whose key is 0xab01\" seems to be in violation of the definition of a valid map, since applications are not allowed to rely on invalid behavior.\u00a0 (That is, the implied \"more than one pair whose key is 0xab01\" would be invalid.) I think that the new deterministic encoding rules for sorting map keys should be clear about whether \"no content\" sorts before or after \"content present\" -- that is, how 0x10 and 0x1020 are ordered when the 0x10 byte is identical and we have to compare\u00a0 with 0x20. The discussion in Appendix C suggests that C (programming language) implementations all use two's-complement representation of signed integers; this requirement is present in POSIX but not C itself (I verified this for C99 and C11). Additionally, the encode_sint() function (also Appendix C) relies on C implementation-defined behavior while right-shifting a signed integer. The C decode_half() function in Appendix D assumes that 'int' is wider than 16 bits (since assigning a value to an int16_t variable when the value is not representable in int16_t incurs implementation-defined behavior).\u00a0 Given that this spec is specifically targetting constrained devices, it's not clear that such an assumption is justified.\u00a0 (It also right shifts a signed integer, incurring the same implementation-defined behavior mentioned above.\u00a0 (The bitwise AND against 0x8000 is also problematic for an int16_t.))",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-01 19:18:09-08:00",
    "text": "I'd like to have a (hopefully brief!) discussion about our description of the \"strict transport security\" functionality the HTTPS RRtype provides, with respect to its accuracty/completeness and how explicit vs implicit we should be about the corresponding divergence from \"pure\" HTTP behavior. It's pretty clear that at a pure HTTP protocol level (which as far as I can tell is the scope of applicability that we claim) that resources accessed with \"http\" scheme and resources accessed with \"https\" scheme have no intrinsic relationship -- \u00a74.2.2 of draft-ietf-httpbis-semantics-19  says: \u00a0  Resources made available via the \"https\" scheme have no shared \u00a0  identity with the \"http\" scheme.\u00a0 They are distinct origins with \u00a0  separate namespaces.\u00a0 [...] But the procedures in this document (e.g., \u00a79.5, \u00a79) seem pretty clear that, when an HTTPS record is published, accesses for \"http\" scheme resources should be converted to \"https\" scheme accesses, with implication that the client should expect to get the same resource back from the modified query compared to the unmodified \"http\"-scheme one. While there is a caution in \u00a79.5 that: \u00a0  If this redirection would result in a loss of functionality (e.g. \u00a0  important resources that are only available on the \"http\" origin), \u00a0  the operator MUST NOT publish an HTTPS RR. but in my reading it leaves some important details as only implicit! We need to care not only about resources only available on one vs the other origin, but also about whether the translation would change the semantics of the client's request/response exchange.\u00a0 That is, whether the resources accessible by the different schemes are actually analogous (which, per the above, is not required by HTTP and is subject to the site administrator's control or in some cases other application protocols on top of HTTP used by that origin). This (mostly implicit) requirement is a potential barrier for adoption of the HTTPS RRtype, and while the precondition is very often going to be satisfied, I wanted to get a sense for whether we should make the requirement more explicit, and possibly more prominent in the document (e.g., mention it in the Introduction).\u00a0 I don't know what the right answer is, but it seems important enough to ensure that the topic receives deliberate consideration.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-05-09 15:27:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-03 00:43:35-08:00",
    "text": "[Appendix D.2] * Sorry to be super nitpicky/petty about this. \u00a0 With respect to Figure 7: IPv4-mapped IPv6 addresses have a complicated \u00a0 history (see  RFC 4942  S2.2 for an amuse-bouche, as well as itojun's \u00a0  draft-itojun-v6ops-v4mapped-harmful ). \u00a0 Unless there is something very useful to be gained by the inclusion of this \u00a0 example (what?) I would strongly suggest removing it.\u00a0 I fear it will only \u00a0 cause confusion.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-05-23 05:01:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-03-02 14:13:10-08:00",
    "text": "Thank you for the work on this document Many thanks to Cullen Jennings for his ART ART review: https://mailarchive.ietf.org/arch/msg/art/CfAGYlDfw5kPjlhbujmikX43J6Q/ .  I am concerned by the use of SHOULD in this document. In several places (see 1. below for what I identified as problematic SHOULDs) the document lacks text about why these are SHOULD and not MUST or MAY. I agree with John Klensin, who formulated it very clearly: If SHOULD is used, then it must be accompanied by at least one of: (1) A general description of the character of the exceptions and/or in what areas exceptions are likely to arise.\u00a0 Examples are fine but, except in plausible and rare cases, not enumerated lists. (2) A statement about what should be done, or what the considerations are, if the \"SHOULD\" requirement is not met. (3) A statement about why it is not a MUST. I also have a number of non blocking comments and questions. I will appreciate answers to my questions, to improve my understanding. If any clarification comes out of it, I hope it will help improve the document. Francesca 1. ----- FP: SHOULD lacking additional context: \u00a0  Within a SVCB RRSet, all RRs SHOULD have the same Mode.\u00a0 If an RRSet \u00a0  is used to impose an ordering on SVCB RRs.\u00a0 SVCB RRs with a smaller \u00a0  SvcPriority value SHOULD be given preference over RRs with a larger \u00a0  SvcPriority value. \u00a0  In AliasMode, the SVCB record aliases a service to a TargetName. \u00a0  SVCB RRSets SHOULD only have a single resource record in AliasMode. \u00a0  If multiple are present, clients or recursive resolvers SHOULD pick \u00a0  one at random. \u00a0  In AliasMode, records SHOULD NOT include any SvcParams, and \u00a0  recipients MUST ignore any SvcParams that are present. \u00a0  Zone-file implementations \u00a0  SHOULD enforce self-consistency.  \u00a0  If the client is SVCB-optional, and connecting using this list of \u00a0  endpoints has failed, the client SHOULD attempt non-SVCB connection \u00a0  modes. \u00a0  If the client enforces DNSSEC validation on A/AAAA responses, it \u00a0  SHOULD apply the same validation policy to SVCB. \u00a0  If the client is unable to complete SVCB resolution due to its chain \u00a0  length limit, the client SHOULD fall back to the authority endpoint, \u00a0  as if the origin's SVCB record did not exist. \u00a0  For compatibility with clients that require default transports, zone \u00a0  operators SHOULD ensure that at least one RR in each RRSet supports \u00a0  the default transports. \u00a0  Global Scoped Entry Registry [Attrleaf].\u00a0 The scheme SHOULD have an \u00a0  entry in the IANA URI Schemes Registry [ RFC7595 ].\u00a0 The scheme SHOULD \u00a0  have a defined specification for use with SVCB.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-05-24 11:44:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-23 05:01:45-07:00",
    "text": "Thank you for the work on this document. Many thanks to Cullen Jennings for his ART ART review: https://mailarchive.ietf.org/arch/msg/art/CfAGYlDfw5kPjlhbujmikX43J6Q/ .  Thank you for addressing my previous DISCUSS and COMMENTs. I have reviewed v-09 and I noticed 4 points were not addressed (or I missed them). Do let me know if you think no further clarifications were necessary - just making sure these were not missed, as I have not seen any answers to them. Re: the use of SHOULD - thank you for adding context to most of them. I did not see any added context to these following two SHOULDs: > Zone-file implementations SHOULD enforce self-consistency.  and > If the client enforces DNSSEC validation on A/AAAA responses, it SHOULD apply the same validation policy to SVCB. If SHOULD is used, then it must be accompanied by at least one of: (1) A general description of the character of the exceptions and/or in what areas exceptions are likely to arise.\u00a0 Examples are fine but, except in plausible and rare cases, not enumerated lists. (2) A statement about what should be done, or what the considerations are, if the \"SHOULD\" requirement is not met. (3) A statement about why it is not a MUST. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-03-22 09:07:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-02 23:39:57-08:00",
    "text": "Section 15.3.1 creates a new IANA registry with a First Come First Served registration policy.\u00a0  RFC 8126  says this of that policy: \u00a0  It is also important to understand that First Come First Served \u00a0  really has no filtering.\u00a0 Essentially, any well-formed request is \u00a0  accepted. Yet this document stipulates: \u00a0  [...]\u00a0 The Format Reference \u00a0  MUST specify how to convert the SvcParamValue's presentation format \u00a0  to wire format and MAY detail its intended meaning and use.\u00a0 An entry \u00a0  MAY specify a Format Reference of the form \"Same as (other key Name)\" \u00a0  if it uses the same presentation and wire formats as an existing key. These seem to me to be in conflict.\u00a0 We're asking IANA to do more than what the BCP says is valid here.\u00a0 Should this instead be Expert Review?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-05-09 15:29:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-22 09:09:16-07:00",
    "text": "Section 15.3.1 creates a new IANA registry with a First Come First Served registration policy.\u00a0  RFC 8126  says this of that policy: \u00a0  It is also important to understand that First Come First Served \u00a0  really has no filtering.\u00a0 Essentially, any well-formed request is \u00a0  accepted. Yet this document stipulates: \u00a0  [...]\u00a0 The Format Reference \u00a0  MUST specify how to convert the SvcParamValue's presentation format \u00a0  to wire format and MAY detail its intended meaning and use.\u00a0 An entry \u00a0  MAY specify a Format Reference of the form \"Same as (other key Name)\" \u00a0  if it uses the same presentation and wire formats as an existing key. These seem to me to be in conflict.\u00a0 We're asking IANA to do more than what the BCP says is valid here.\u00a0 Should this instead be Expert Review?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-23 12:27:10-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 20:59:03-07:00",
    "text": "Section 4.3.4 asserts: \u00a0  [...]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 We'll note that the Join \u00a0  Priority is now specified between 0 and 0x3F leaving 2 bits in the \u00a0  octet unused in the IEEE Std. 802.15.4e specification.\u00a0 After \u00a0  consultation with IEEE authors, it was asserted that 6TiSCH can make \u00a0  a full use of the octet to carry an integer value up to 0xFF. I'm extremely reluctant to publish this text in the IETF stream without a citation. I also think there are more topics that need to be covered in the security considerations (see Comment, and not just the Section-6 portions), especially with respect to the reliance on the link-layer security mechanism and its network-wide shared key.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-10-25 08:20:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 08:47:54-07:00",
    "text": "I only had a quick read of this document, however, it seems to me that there are strong dependencies on a whole bunch of drafts, that are only listed as informational. I don't have a deep enough understanding to make a final judgement of which draft would need to be listed as normative references, however, I wanted to raise this point on the discuss level in order to ensure that this is considered before publication. To give an example: Section 4.6.3 goes quite seep into details of what's described in [ I-D.ietf-6lo-fragment-recovery ]. However as long as [ I-D.ietf-6lo-fragment-recovery ] is not published yet, the 6tisch arch should probably not rely on the content of this draft that strongly. Putting [ I-D.ietf-6lo-fragment-recovery ] as a normative reference ensures that this draft will not be published before [ I-D.ietf-6lo-fragment-recovery ].",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-08-11 07:25:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-11 04:52:37-07:00",
    "text": "Thanks for the solid work on this document, for the most part, I found it clear and easy to parse. In Section 1, I see the following:  Each ROA contains a set of IP prefixes, and an AS number of \u00a0  an AS authorized to originate all the IP prefixes in the set \u00a0  [ RFC6482 ]. While I have some idea of what this means - it's confusing and I believe will cause confusion on the part of other readers.\u00a0 It's confusing to the point where I'm not even sure exactly what the wording should be, but reading that, an AS number of an AS doesn't seem right at all. Let's discuss and see if we can find a way to come to text on this section that is less confusing. Thanks Andrew",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-01-21 12:48:36-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 15:08:19-08:00",
    "text": "(1) This document describes several methods to determine the status of a  tunnel (in \u00a73), none of which \"provide a \"fast failover\" solution when used  alone, but can be used together with the mechanism described in Section 4\"  (\u00a71).\u00a0 \u00a73 also says this: \u00a0  An implementation may support any combination of the methods \u00a0  described in this section and provide a network operator with control \u00a0  to choose which one to use in the particular deployment. While \u00a73.1 is clear in the fact that it is not a requirement for all  downstream PEs to use the same mechanism, there are no guidelines to aid the  operator to chose which mechanism to use.\u00a0 Some cases may be obvious (e.g.  \u00a73.1.3 applies to tunnels of a specific type), but others are not.\u00a0 I would  like to see deployment considerations related to the advantages/disadvantages  that each method may have in specific situations (including their possible  combination). (2) The BFD Discriminator Attribute has a very narrow application in this document when compared to the potential other uses given the extensibility possibilities related to bootstrapping BFD.\u00a0 I have serious concerns about  the attribute being defined in this document, amongst a series of other  mechanisms. (2a) The tunnel can be monitored without the new BGP Attribute (assuming  proper configuration of course).\u00a0 Why is that option is not even mentioned in  the document?\u00a0   In fact, the document recommends deleting the BFD session if the Attribute is not present.\u00a0 Why is that recommendation in place, and what are the cases when it can not be followed? (2b) The fact that BFD monitoring can be achieved without the new attribute makes me think that the bootstrapping of BFD using BGP would be better served  in a document produced by the BFD WG.\u00a0 One of the editors has expressed the  same opinion [1] [2].\u00a0 Has a discussion taken place in the BFD WG (or at least  with the Chairs) about this work?\u00a0 Why was it not taken up there? [1]  https://mailarchive.ietf.org/arch/msg/rtg-bfd/T1jVpgyXuPatTpuD_wA0JC3CT1c/ [2]  https://tools.ietf.org/wg/bess/minutes?item=minutes-96-bess.html",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-23 16:52:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-14 16:51:00-08:00",
    "text": "Let's talk about what the requirements are for consistency across PEs in the algorithm for selecting the Primary Upstream PE.\u00a0 Section 4 notes that \"all the PEs of that MVPN [are required] to follow the same UMH selection procedure\", but leaves the option of non-revertive behavior as something that \"MAY also be supported by an implementation\", without requirement for consistency across all PEs.\u00a0 It seems to me that if some PEs use non-revertive behavior and others do not, then they will disagree as to which PE is the Primary (or active) PE in some cases, which seems to conflict with the initial guidance that all PEs needed to pick the same one.\u00a0 Is it perhaps that the PEs need to agree on which PE is to be advertised as Primary but not necessarily to actually be using that one for traffic?\u00a0 Or am I missing something?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-12-13 08:27:39-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 23:52:17-07:00",
    "text": "Thanks for the work done on defining this mechanism! I think it's quite useful, and I plan to ballot \"Yes\" as soon as the minor but important issue below is fixed. \u00a76.1: >\u00a0 Status:\u00a0 standard My reading of  RFC 3864  does not allow Experimental RFCs to register HTTP header fields as \"Status: Standard.\"",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-11-10 13:33:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 09:30:15-07:00",
    "text": "This should be a trivial discuss to resolve, but affects interoperability so is still balloted as such.\u00a0 In Section 3.1: \u00a0  o\u00a0 \"validated-certificate-chain\": the value is the certificate chain \u00a0 \u00a0 \u00a0 as constructed by the UA during certificate chain verification. \u00a0 \u00a0 \u00a0 (This may differ from the value of the \"served-certificate-chain\" \u00a0 \u00a0 \u00a0 key.)\u00a0 The value is provided as an array of strings, which MUST \u00a0 \u00a0 \u00a0 appear in the order matching the chain that the UA validated; each \u00a0 \u00a0 \u00a0 string in the array is the Privacy-Enhanced Mail (PEM) \u00a0 \u00a0 \u00a0 representation of each X.509 certificate as described in \u00a0 \u00a0 \u00a0 [ RFC7468 ]. This needs to say whether the end-entity certificate appears first or last (that is, without assuming what order the UA's chain-validation code uses). I believe we usually say something like \"the first certificate in the chain represents the end-entity certificate being verified\".",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-12-20 12:53:53-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 16:12:07-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4579 This generally seems like a sound mechanism, but I believe there are some points here that are sufficiently unclear they might create interop problems,s o I am balloting DISCUSS. Most importantly, this document just says you support CT, but that creates a potential interop problem if say 6962-tris had a different way of delivering CT information or a different syntax. I'm not saying you need a version here, but you need to indicate that it's not forward-looking. Also, see below. DETAIL S 2.4. >\u00a0 \u00a0 \u00a0 beginning an HTTP conversation over the TLS channel. >\u00a0   >\u00a0 \u00a0 \u00a0 If a connection to a Known Expect-CT Host violates the UA's CT policy >\u00a0 \u00a0 \u00a0 (i.e., the connection is not CT-qualified), and if the Known Expect- >\u00a0 \u00a0 \u00a0 CT Host's Expect-CT metadata indicates an \"enforce\" configuration, >\u00a0 \u00a0 \u00a0 the UA MUST treat the CT compliance failure as an error. Is this supposed to be a hard failure, as with HSTS. If not, how does it interact with HSTS's hard failure reqs. S 3.1. >\u00a0 \u00a0 \u00a0 \u00a0  (This may differ from the value of the \"served-certificate-chain\" >\u00a0 \u00a0 \u00a0 \u00a0  key.)\u00a0 The value is provided as an array of strings, which MUST >\u00a0 \u00a0 \u00a0 \u00a0  appear in the order matching the chain that the UA validated; each >\u00a0 \u00a0 \u00a0 \u00a0  string in the array is the Privacy-Enhanced Mail (PEM) >\u00a0 \u00a0 \u00a0 \u00a0  representation of each X.509 certificate as described in >\u00a0 \u00a0 \u00a0 \u00a0  [ RFC7468 ]. What happens if you try to construct multiple paths? S 3.1. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 does not have or does not trust the public key of the log from >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 which the SCT was issued), \"valid\" (indicating that the UA >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 successfully validated the SCT as described in Section 5.2 of >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [ RFC6962 ] or Section 8.2.3 of [ I-D.ietf-trans-rfc6962-bis ]), or >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"invalid\" (indicating that the SCT validation failed because >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 of, e.g., a bad signature). Is \"invalid\" anything other than the specific cases listed above?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-22 01:30:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 06:38:35-07:00",
    "text": "Section 4.1: \u00a0  The API server endpoint MUST be accessed using HTTP over TLS (HTTPS) \u00a0  and SHOULD be served on port 443 [ RFC2818 ]. I have another reason than Roman to discuss this particular sentence. First of all what is the intention of which HTTP version should be supported here?  And which protocol are the port 443 you are recommending, TCP, UDP or SCTP? This also relates to HTTP/3 as it is getting close to being published, we can expect that in the future maybe people would like to upgrade to HTTP/3. Already now I am wondering if the written allow for HTTP/2 over TLS/TCP? Note, that I am mostly commenting from the perspective if you want to be specific that it is HTTP/1.1. over TLS/TCP that is the goal. Then this document should make certain changes in the formulation. If you want to be unspecific and don't think that will hurt interoperability, then another formulation that the current is also needed. Likely also a discussion about how a client will figure out what versions are supported. And maybe one of the ART ADs can help untangle if  RFC 2818  really is the right normative reference here? Or if it should be  RFC 7230  and possibly additional references for HTTP/2?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-06-08 08:08:36-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-06 14:48:48-07:00",
    "text": "Unless I am misinterpreting the language here, there is a disconnect between this document and the architecture document. Sec 2.3 of -architecture says: At minimum, the API MUST provide: (1) the state of captivity and (2) a URI for the Captive Portal Server. But in section 5 user-portal-url is an optional field. Is -architecture actually levying a requirement on the api spec, or the api server? I am also confused by this sentence at the end of section 4.1 about failed authentication: \u201cIt may still be possible for the user to access the network by being redirected to a web portal.\u201d Who is doing the redirecting here? If authentication has failed, how is this redirect authenticated and secure against theft of credentials?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-06-19 05:42:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-09 19:51:18-07:00",
    "text": "\u201cDiscuss discuss\u201d.\u00a0 Section 4 says \u201cThe API server endpoint MUST be accessed using HTTP over TLS (HTTPS) and SHOULD be served on port 443 [ RFC2818 ].\u201d\u00a0 There is also various guidance on verifying the API server identity and access to revocation and time resources.\u00a0 However, the way I read the definition of the \u201cCaptive Portal API Server\u201d per Section 2 and per Figure 1 of  draft-ietf-capport-architecture , the API server is logically different than the service at the user-portal-url URL (i.e., Web Portal Server in the architecture).\u00a0  Section 7.1 helpfully points out \u201cInformation passed between a client and a Captive Portal system may include a user's personal information, such as a full name and credit card details.\u00a0 Therefore, it is important that Captive Portal API Servers do not allow access to the Captive Portal API over unencrypted sessions.\u201d\u00a0 The first sentence is makes sense, but the second, while true, doesn\u2019t follow the first for me.\u00a0 PII and credit card information would be the kind of input you would provide to the _Web Portal Server_ not the Captive Portal API (of course both are part of the overall Captive Portal system).\u00a0 I feel there is missing guidance roughly on the order of the user-portal-url \u201cprovides the URL of a web portal _that MUST be accessed over TLS_ with which a user can interact.\u201d (and the venue-info-url SHOULD use TLS too).\u00a0  Both this draft and  draft-ietf-capport-rfc7710bis-07  are fundamentally providing pointers to other resources.\u00a0 Would it be out of scope for this document to place restrictions on what the API is capable of pointing to?\u00a0 If not here, then where?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 17:14:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 19:53:14-07:00",
    "text": "I'm not sure I understand how the examples are consistent with the main specification, so let's please discuss it to either un-confuse me or fix the document. Section 3.9 seems to say that the oldest (source or redundant) text at the mixer takes priority when there is text from more than one source waiting to be sent, but the examples in Section 3.21 seem to show (e.g.) text received from A at time 20400 that is to be sent as redundancy, being sent after text from B received at time 20500 (sent as primary). Is the intent that if there is any primary text, the oldest primary text is sent first, and only if there is no outstanding primary text do we consider the redundant text? In a related vein, Section 3.10 says that a packet is sent when (among other things) \"330 ms has passed since already transmitted text was queued for transmission as redundant text\".\u00a0 But that doesn't say anything about the timer being reset by subsequent transmission or queuing of redundant text, so I'm not sure how in the Section 3.21 example, we say that transmitting B1 and B2 as redundancy was planned as 330 ms after packet 105 -- the original B2 was sent in packet 104, so shouldn't the 330ms start from packet 104's transmission?\u00a0 (The stated time for this seems to match 330ms after 104, so maybe the \"105\" is just a typo?) I also left a note in the comment that there's a remark about \"lower security level\" in Section 3.19 that's not really accurate; we should resolve that in some manner before the document proceeds.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-06-17 07:36:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-17 07:36:24-07:00",
    "text": "This memo is defining a RTP payload for JPEG XS that is not publicly available. This hampers the review of the memo, specially when it is defining terminologies which ask me to look a the specifications. This concerns has also been raised by other ADs. was this document made available during the work in the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-06-17 07:37:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-17 07:36:43-07:00",
    "text": "This memo is defining a RTP payload for JPEG XS that is not publicly available. This hampers the review of the memo, specially when it is defining terminologies which ask me to look a the specifications. This concerns has also been raised by other ADs. Was this document made available during the work in the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-07-20 08:26:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-17 07:37:10-07:00",
    "text": "This memo is defining a RTP payload for JPEG XS that is not publicly available. This hampers the review of the memo, specially when it is defining terminologies which ask me to look at the specifications. This concerns has also been raised by other ADs. Was this document made available during the work in the working group?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-09-08 08:33:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-08 00:44:27-07:00",
    "text": "Let's chat about IANA Considerations, which I think needs some work.\u00a0 Fortunately, I think these all have straightforward fixes. First, the easy stuff: \"Required parameters\" and \"Optional parameters\" should probably not be \"None\"; see  RFC 6838  Section 5.6. The \"Security Considerations\" field simply states what the payload is.\u00a0 I think, at a minimum, this should specifically refer to the Security Considerations in the referenced document.\u00a0 Moreover, note this from  RFC 6838 : \u00a0  o\u00a0 Any security analysis MUST state whether or not they employ such \u00a0 \u00a0 \u00a0 \"active content\"; if they do, they MUST state what steps have been \u00a0 \u00a0 \u00a0 taken, or MUST be taken by applications of the media type, to \u00a0 \u00a0 \u00a0 protect users of the media type from harm. This required content is absent.\u00a0 In the referenced document I don't see any evidence that there's active content (i.e., the payload is not directly executable as far as I can tell), but it would be a good idea to say so, at least because the BCP requires it. Finally, as this is a standards action with IETF consensus, the change controller is supposed to be the IETF. Separately, the double \"SHOULD\" in bullet #1 of Section 6 leaves the possibility that an implementation does neither of those things.\u00a0 Is that what you intended to allow?\u00a0 If not, some revised guidance here is probably in order.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-12-03 05:55:45-08:00",
    "end_reason": "position_updated",
    "start": "2015-12-02 21:48:24-08:00",
    "text": "I'm lost on something here, so I'd like to discuss it briefly so that I understand what I'm looking at. I'm not expecting this to be hard to resolve. In this text \u00a0  However, the three \u00a0  SSRCs comprising each participant will almost certainly see identical \u00a0  reception quality, since they are co-located. \u00a0   it sounds like you're describing a heuristic (\"will almost certainly see\", so if you use a reporting group, the results will be close enough).  In other places in the document, like \u00a0  Since they are co-located, every \u00a0  SSRC in the RTCP reporting group will have an identical view of the \u00a0  network conditions, and see the same lost packets, jitter, etc.\u00a0  \u00a0   it sounds like you're saying they'll always have an identical view (\"will see\", with no qualification).  Which is it? As a comment, but on exactly the second text so I'll include it here, is \"see the same lost packets\" telling me that more than one SSRC is sending \"the same lost packets\"? If this was \"see (roughly) the same loss rate\", I wouldn't be surprised, but I'm confused here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-08 14:55:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-07 23:56:41-07:00",
    "text": "I support Roman's Discuss points. Sorry to provide so many new substantive points here -- I was only able to follow the email discussions in the WG (and not completely, even) but not to actually read the document earlier.\u00a0 It hopefully goes without saying, but the goal is to make sure we get it right, since it's going to be an important pillar for the future of things; I'm happy to see that this is advancing. (1) I don't think that the claim in Section 4.2 that \"[b]oth RPC and TLS have peer and user authentication\" is correct, at least given my understanding of those terms.\u00a0 Using this document's definition of RPC \"peer authentication\" as analogous to TLS server authentication, the functionality that TLS calls \"mutual authentication\" is more analogous to RPC client authentication, though it is sometimes repurposed for use for user authentication, with concommittant bad user experience.\u00a0 This analogy does not seem critical to the mechanisms of this document, so I believe we should remove or modify it. (2) The mention of using RPCSEC_GSS with GSS channel bindings to TLS is quite underspecified.\u00a0 Unfortunately, this is largely the fault of other specifications, but we have to deal with the fallout.\u00a0 On first glance (but subject to further clarification/change), it seems like we should: - Say what channel binding type (from the registry that  RFC 5929  registered \u00a0 stuff in) is to be used -- just citing 5929 doesn't help, since it \u00a0 mentions three different ones (none of which are really right for TLS 1.3, \u00a0 see below) - provide a mechanism for the peers to determine whether GSS channel binding \u00a0 to TLS is to be used.\u00a0 (As discussed in \u00a0  draft-ietf-kitten-channel-bound-flag , the current state of things GSS is \u00a0 that if one party supplies channel bindings but the other doesn't, the \u00a0 security context negotiation fails, which is usually not the best for \u00a0 usability.)\u00a0 Since this is a greenfield GSS-API application, the simplest \u00a0 thing by far is to just say \"always provide the channel bindings when \u00a0 using RPCSEC_GSS over TLS\".\u00a0 It's even the more secure option, too :) - give more detail about what value to provide as the 'chan_binding' input \u00a0 to the GSS security context negotiation.\u00a0 We currently reference  RFC 5929 , \u00a0 that defines three different channel-binding values, but none of them are \u00a0 really usable for TLS 1.3 (as discussed in \u00a0  draft-ietf-kitten-tls-channel-bindings-for-tls13 ).\u00a0 Most likely this will \u00a0 mean using the tls-exporter value from that document. (3) Please check this reference in Section 5.1.1: \u00a0  Reverse-direction operation occurs only on connected transports such \u00a0  as TCP (see Section 2 of [ RFC8166 ]).\u00a0 [...] It seems likely that  RFC 8167  was intended... (4) I don't think it's particularly safe to suggest that non-protected RPCs should be exchanged on the same 5-tuple that just terminated a DTLS association, since neither DTLS nor UDP provide in-order delivery, so there is ambiguity as to whether a datagram should be interpreted as DTLS protected or not.\u00a0 This is particularly problematic in the face of the three different DTLS record headers (DTLSPlaintext, DTLSCiphertext(full), and DTLSCiphertext(minimal)) with something like 10 or 11 different possible values for the first byte that might be in flight, with limited \"magic number\" verification fields available.\u00a0 I think I need some input from the TSV ADs about what the options are, though -- while a cooling-off period might be fine if an ephemeral port is in use, it seems problematic for cases where fixed port numbers are used for both source and destination. (5) Section 5.2.1 requires that: \u00a0  *\u00a0 Implementations SHOULD indicate their trusted Certification \u00a0 \u00a0 \u00a0 Authorities (CAs). Indicate to whom? (6) The usage of  RFC 6125  procedures in Section 5.2.1 seems counter to its intent.\u00a0 Specifically, we seem to be saying \"the peer gave me a cert, let me look through it to see if it has something I like\", but  RFC 6125 's intended procedure is \"I know a list of names that I expect to see at least one of in the cert; these rules tell me whether the cert is valid for any such name\". It's not entirely clear that it's appropriate for this document to specify how the client has to order its list of names by type (per Section 6.1 of RFC 6125 's \"The client constructs a list of acceptable reference identifiers\"), which the bit about \"The following precedence applies\" seems to be doing.\u00a0 To the extent that we give a recommendation to use DNS-ID instead of CN-ID, and ipAddress SAN instead of CN-ID, that's already covered by  RFC 6125 ; it would be okay for us to say \"use DNS-ID or iPAddress SAN\", though.\u00a0 (Roman's comment about \"why not a normative MUST\" for putting IP addresses in the iPAddress SAN is related, and if we don't have a compelling reason to allow the flexibility, we should limit to the specific DNS-ID/iPAddress options without allowing CN-ID.) (6.1) Note additionally that if wildcard certificates are to be used,  RFC 6125  requires the application protocol specification to give details on how they are to be used. (6.2)  RFC 6125 's procedures are (facially, at least) only valid for TLS server authentication.\u00a0 We also want to authenticate TLS clients, so we should say whether we expect the same procedures to be used, or what procedures should be used (even just as how it differs from the  RFC 6125 ones).\u00a0 Of particular note is that, since the server is not initiating the network connection, it is unlikely to have a preconceived notion of what client identity to expect, and is likely limited to attempting to extract something from the certificate.\u00a0 In this scenario a precedence list (as I complained about being inconsistent with  RFC 6125  above) would be appropriate. (7) Section 5.2.1 uses the phrase \"renegotiate the TLS session\". Renegotiation is not defined or allowed for TLS 1.3; generally one would need to either remember the presented certificate and re-run the validation process on it or shutdown the TLS connection and make a new one, though in theory one could try to define a mechanism using post-handshake authentication.\u00a0 (I don't recommend the latter, though; it's not widely implemented/used.) (8) Can we clarify the status of DNSSEC (or DANE) requirements?\u00a0 Section 1 assumes that support for DNSSEC is already available in an RPC implementation, but Section 7.1.1 says that \"Clients [sic] implementors can choose from\" a list of things including DANE TLSA records.\u00a0 Why would we require DNSSEC support but not using the records if they're present? (9) I agree with Roman('s comment) that Sections 5.2.2 and 5.2.4 should give a minimum amount of information to be exposed to the administrator for implementing the trust mode.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-02 17:30:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-08 14:55:42-07:00",
    "text": "Thank you for the updates in the -09; they address all my previous Discuss points (from the -08).\u00a0 Unfortunately, there is one more issue that was introduced in the update and will need to be resolved: While I appreciate the efforts to find appropriate external specifications to reference, I do not believe that an id-kp-rpcTLSServer certificate is a Resource Certificate per  RFC 6487  -- that specification deals with the RPKI (Resource PKI) used to authenticate IP address assignment, but the RPKI is an entirely separate PKI than the Internet PKI (\"PKIX\").\u00a0 I think we should drop that sentence entirely.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-10-20 07:04:31-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-25 13:55:18-07:00",
    "text": "This presumably a trivial fix but I think it's important enough to be a DISCUSS: I think the document needs some discussion of the security properties of TLS1.3 early data over TCP, if only to refer to Section 8 of  RFC 8446  (replay) and mention that it is not forward-secure, unlike the rest of the payload.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:00:15-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-06 20:24:10-07:00",
    "text": "** Despite Section 5.0 stating that only TLS v1.3+ can be used, there are two references to TLS v1.2 mechanisms: -- Section 5.0. Per \u201cImplementations MUST support certificate-based mutual authentication.\u00a0 Support for TLS-PSK mutual authentication [ RFC4279 ] is OPTIONAL\u201d.\u00a0 Shouldn\u2019t Section 2.2.2 or 4.2.11 of  RFC8446  be used instead?  -- Section 5.2.4.\u00a0 The token binding mechanism suggested here,  RFC8471 , only applies to TLS v1.2.\u00a0 The expired  draft-ietf-tokbind-tls13  provides the TLS v1.3 mechanism. ** Section 7.4.\u00a0 Per \u201cWhen using AUTH_NULL or AUTH_SYS, both peers are required to have DNS TLSA records and certificate material \u2026\u201d, what is \u201ccertificate materials\u201d?\u00a0 Can this guidance please be clarified (and perhaps related to the options specified in Section 5.2).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-18 22:25:55-07:00",
    "text": "My assessment of the IETF consensus is that this document should not have an Updates: relationship with  RFC 8446 , and accordingly it cannot be approved until that (and the corresponding prose) is removed.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-02-23 11:49:01-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-23 11:41:33-08:00",
    "text": " simple thing: the document header should state that it updates RFC 8446.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-07 10:39:25-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-23 11:49:01-08:00",
    "text": "pdate: if the consensus is that the document does not update RFC8446, then the Abstract and Introduction ought not to say otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-02-16 15:58:24-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 12:49:15-08:00",
    "text": "This should be easy: What's the \"Subject\" field in Section 5.1?\u00a0 It doesn't appear to be a column in the current registry ( https://www.iana.org/assignments/channel-binding-types/channel-binding-types.xhtml ).",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-05-04 06:56:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-26 13:53:24-07:00",
    "text": "I am pulling in Ben's DISCUSS here: \u00a0 \u00a0 My assessment of the IETF consensus is that this document should not have an Updates: relationship with  RFC 8446 , and accordingly it cannot be approved until that (and the corresponding prose) is removed. Additionally, I also believe that this change does not really warrant an Updates: clause, as  RFC 8446  simple states that an extension offering channel binding is currently (at the time of writing) not available. In other words, the core TLS 1.3 specification is not updated. One does not require to implement this document to implement a properly up to date TLS 1.3 core specification.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-05 06:18:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-28 13:43:48-08:00",
    "text": "** On the issue of what behavior is MTI, Section 5.2 of Section  RFC5801  and Section of  RFC5802  say: (a)\u00a0  'tls-unique' is the default channel binding type for any application \u00a0  that doesn't specify one. (b)\u00a0  Servers MUST implement the \"tls-unique\" [ RFC5929 ] channel binding \u00a0  type, if they implement any channel binding. Section 3 of this document says: (c) As \"tls-unique\" is not defined for TLS 1.3 (and greater), this \u00a0  document updates [ RFC5801 ], [ RFC5802 ], and [ RFC7677 ] to use \"tls- \u00a0  exporter\" as the default channel binding over TLS 1.3 (and greater). \u00a0  Note that this document does not change the default channel binding \u00a0  for SCRAM mechanisms over TLS 1.2 [ RFC5246 ], which is still \"tls- \u00a0  unique\". No problem with the guidance in (c).\u00a0 Without specific citations being made, I\u2019m inferring that (c) is intended to \u201cupdate\u201d/clarify (a) in a TLS 1.3 context.\u00a0  To the issue of MTI, (c) is silent on the guidance in (b).\u00a0 Since \u201ctls-unique\u201d is not defined for TLS 1.3, how would an implementer comply in the case of a server that is TLS 1.3 only?\u00a0 Should this document make a statement to the effect of \u201ctls-exporter\u201d is MTI for any servers implementing TLS 1.3?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-07-05 17:37:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-07 06:29:00-07:00",
    "text": "Table 3 has \"None\" in all the cells corresponding to SF and SFC OAM functions. But then Sections 6.4.1 through 6.4.4 discuss several tools that can be used to provide some of these functions. I understand that the text about the table says \"Table 3 below is not exhaustive,\" but still it seems misleading to say \"None\" in the table when there are, in fact, tools available that are discussed just a few paragraphs later.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-07 11:07:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-05 22:31:51-07:00",
    "text": "I think this is pretty well done.\u00a0 I had little trouble following it and this is my first foray into the realm of SFC. One item I'd like to discuss though.\u00a0 From Section 3.1.1: \u201cOn one end of the spectrum, one might argue that an SF is sufficiently available if the service node (physical or virtual) hosting the SF is available and is functional.\u00a0 On the other end of the spectrum, one might argue that the SF's availability can only be concluded if the packet, after passing through the SF, was examined and it was verified that the packet did indeed get the expected service.\u201d I found this a bit surprising, especially given the critical nature of many SF functions.\u00a0 Why would it ever be the case that, say, \u201cwell, the hypervisor says the VM is up, so the SF is up\u201d is a safe conclusion?\u00a0 For such a critical component, I would expect only some more complete test is necessary to conclude availability of the SF.\u00a0 Shouldn't we at least be pushing implementers toward the latter end of that spectrum?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-03 10:50:22-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-28 15:25:34-07:00",
    "text": "Let's discuss whether we should have content in this document discussing the relationship between this new certificate extension and the extension defined by  RFC 8226 .\u00a0 In paticular, whether it is permitted/expected for both extensions to appear in the same certificate, and whether any specific processing is required in that case.\u00a0 (If no such processing is specified, we could end up with interesting edge cases where a given PASSporT is handled differently depending on which extension(s) are supported by the recipient.)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-07-11 06:48:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 09:02:10-07:00",
    "text": "1. In \u00a73.2, \u00a0  The following HHIT Suite IDs are defined: \u00a0 \u00a0 \u00a0 \u00a0 HHIT Suite\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Value \u00a0 \u00a0 \u00a0 \u00a0 RESERVED\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 \u00a0 \u00a0 \u00a0 \u00a0 RSA,DSA/SHA-256\u00a0 \u00a0  1\u00a0 \u00a0 [ RFC7401 ] \u00a0 \u00a0 \u00a0 \u00a0 ECDSA/SHA-384\u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 [ RFC7401 ] \u00a0 \u00a0 \u00a0 \u00a0 ECDSA_LOW/SHA-1\u00a0 \u00a0  3\u00a0 \u00a0 [ RFC7401 ] \u00a0 \u00a0 \u00a0 \u00a0 EdDSA/cSHAKE128\u00a0 \u00a0  TBD3 (suggested value 5)\u00a0  (RECOMMENDED) What, exactly, does the notation \"RECOMMENDED\" on the last quoted line mean? AFAICT there's no unambiguous way to parse this. My guess is that it's meant to mean \"this is the suite we think you should use\". Whatever the intended meaning, please elaborate to make the meaning clear. I suggest removing the notation from the table, and providing prose in some appropriate section instead, with \"RECOMMENDED\" if you think the  RFC 2119  keyword is needed. If desired, you could xref that section from the table, although I don't think that's really necessary. This comment also applies to the similar lines in \u00a73.4.1, \u00a73.4.1.1, and \u00a73.4.2. The use in \u00a73.4.1.1 is especially confounding, since the prose right before the table tells us that (all of) \"the following EdDSA curves are required\" (but evidently not REQUIRED)... but only some of the required curves are RECOMMENDED? I definitely have no clue, then, what \"RECOMMENDED\" means in this section.  RFC 2119  basically defines RECOMMENDED as a weaker form of REQUIRED, but that doesn't seem to be how you're using it. Similarly, I have no clue what \"RECOMMENDED\" is meant to mean in its several uses in \u00a78.2 and \u00a78.4. I suggest simply removing it from those sections entirely. (Taken together, this comment covers every use of RECCOMMENDED in the document.)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-07-13 12:06:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 11:29:55-07:00",
    "text": "John raised this in a comment, and I agree with it: Please provide proper guidance for your new registry's designated experts, or let's discuss why you think what's there is sufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-18 18:21:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 19:07:44-07:00",
    "text": "#1 \u00a0  Note that if the zone  hhit.arpa  is ultimately used, some registrar \u00a0  will need to manage this for all HHIT applications. Regardless of what zone is used, someone needs to keep it operational. It might be an attractive target to attack, eg to try and avoid drones being shut down. I would feel much better if this zone was optional, not mandatory. (but if optional, one could also argue maybe not have it at all?) \u00a0  If the HHITs cannot be \u00a0  looked up with services provided by the registrar identified via the \u00a0  embedded hierarchical information or its registration validated by \u00a0  registration attestations messages [drip-authentication], then the \u00a0  HHIT is either fraudulent or revoked/expired. That's quite catastrophic if there is a Registrar/Registry outage. Would all the drones get shot down or would they all be ignored (so they can fly to their terrorism target) #2 As DISCUSS'ED by others,  https://www.iana.org/assignments/hip-parameters/hip-parameters.xhtml#hi-algorithm  does not seem to have a third field for \"status\" to denotate RECOMMENDED, REQUIRED, etc, even though  RFC 7401  creates the registry, uses the terms too but doesn't populate a status field. Perhaps this or another short RFC could do so. Also, 3.4.1 calls this \"Algorithm profiles\" and \"Values\" but the IANA registry calls it \"Algorithm Profile\" (singular) and \"Value\" (singular) #3 Section 3.4.1.1. has a NULL field of variable length ? Or perhaps the slash and pipe symbols on those first and second lines got swapped by accident? #4 \u00a0  The new EdDSA HI uses [ RFC8080 ] for the IPSECKEY RR encoding: \u00a0 \u00a0 \u00a0 Value\u00a0 Description \u00a0 \u00a0 \u00a0 TBD2 (suggested value 4) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  An EdDSA key is present, in the format defined in [ RFC8080 ] I have asked the Expert of this Registry whether they are okay with this entry to the ipseckey-rr-parameters registry. It might be confusing for IKE.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-13 13:02:05-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 12:02:22-07:00",
    "text": "** With updates tag for  RFC7343 , I read the text in Section 3.5.* as providing a generic description of a new ORCHID computation techniques.\u00a0 Other parts of the text describe how to use it for HIT and HHIT.\u00a0 If that interpretation is correct: -- Section 3.5.1.\u00a0  \u00a0  With a 28-bit IPv6 prefix, the \u00a0  remaining 100 bits can be divided in any manner between the \u00a0  additional information (\"Info\"), OGA ID, and the hash output. Since this section is describing a generic ORCHID technique, does this mean one could potentially choose a 0 or 1 bit hash output size?\u00a0 All the provided security analysis is predicated on a 64-bit HIT.\u00a0 What is associated analysis and security considerations for smaller HITs? -- Section 3.5.1. \u00a0  The header content consists \u00a0  of the Prefix, the Additional Information (\"Info\"), and OGA ID (HIT \u00a0  Suite ID).\u00a0  Secondly, the length of the resulting hash is set by sum \u00a0  of the length of the ORCHID header fields.\u00a0  The second sentence is true only if ORCHID setup is according to the DRIP spec: p=28, info=28, OGA-ID=8 to make 64 bits.\u00a0 However, this is a generic update to define an ORCHID.\u00a0 The previous text said that an OGA-ID could be 4 bits \u2013 28+28+4 = 60, so if the \u201cresulting hash should be set by the length of the ORCHID header field\u201d, it would be off by 4 bits. ** Section 4.2 \u00a0  A mapping service (e.g., DNS) MUST provide a trusted (e.g., via \u00a0  DNSSEC [ RFC4034 ]) conversion of the 4-character Manufacturer Code to \u00a0  high-order 58 bits (Prefix | HID) of the HHIT. Can this \u201ctrust\u201d be described in more detail?\u00a0 Section 4.4 makes it a point to say \u201ccryptographically bind all content in the ORCHID through the hashing function.\u00a0 A recipient of a DET that has the underlying HI can directly trust and act on all content in the HHIT\u201d.\u00a0 Here this information is being split.\u00a0 Is the out-of-scope mechanism expected to provide a similar guarantee? ** Section 4.6 \u00a0  The EdDSA25519 HI (Section 3.4) underlying the DET can be used in an \u00a0  84-byte self-proof attestation (timestamp, HHIT, and signature of \u00a0  these) to provide proof of Remote ID ownership (GEN-1 in [ RFC9153 ]). \u00a0  In practice, the Wrapper and Manifest authentication formats \u00a0  (Sections 6.3.3 and 6.3.4 of [drip-authentication]) implicitly \u00a0  provide this self-attestation.\u00a0 A lookup service like DNS can provide \u00a0  the HI and registration proof (GEN-3 in [ RFC9153 ]). \u00a0  Similarly, for Observers without Internet access, a 200-byte offline \u00a0  self-attestation could provide the same Remote ID ownership proof. \u00a0  This attestation would contain the HDA's signing of the UA's HHIT, \u00a0  itself signed by the UA's HI.\u00a0 Only a small cache that contains the \u00a0  HDA's HI/HHIT and HDA meta-data is needed by the Observer.\u00a0 However, \u00a0  such an object would just fit in the ASTM Authentication Message \u00a0  (Section 2.2 of [ RFC9153 ]) with no room for growth.\u00a0 In practice, \u00a0  [drip-authentication] provides this offline self-attestation in two \u00a0  authentication messages: the HDA's certification of the UA's HHIT \u00a0  registration in a Link authentication message whose hash is sent in a \u00a0  Manifest authentication message. I\u2019m having trouble following along on where the guidance for offline verification is described \u2013 who exactly signs what with what key and in what format is this stored.\u00a0 Is this considered in-scope for this document?\u00a0 Given the asserted security properties,  -- I\u2019ll note that  draft-ietf-drip-auth  is an informative reference. -- What exactly needs to be in the offline Observer\u2019s cache?\u00a0 I couldn\u2019t find that in draft-ietf-drip-auth. -- Why is the first sentence in the first paragraph present?\u00a0 It is describing a hypothetical situation that isn\u2019t used in DRIP.\u00a0 Likewise, the first sentence of the second paragraph also seems like a hypothetical using verbs like \u201ccould provide\u201d -- The text reference a lookup service, how does that service an offline Observer?   ** Section 9.\u00a0  \u00a0  Therefore, the HHIT registration and HHIT/HI registration validation \u00a0  is strongly recommended. If validation isn\u2019t done, who are the promised security guarantees of global non-collision possible?\u00a0 Practically, why isn\u2019t this a MUST? ** Section 9.5. \u00a0  The UAS/USS registration \u00a0  process should include registering the DET and MUST reject a \u00a0  collision, forcing the UAS to generate a new HI and thus HHIT and \u00a0  reapplying to the DET registration process. How does a UAS \u201cgenerate a new HI\u201d in the case of a CTA2063A or manufacturer hard-coding the HHIT per Section 3.2 of  draft-ietf-drip-arch-24 ?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-07-14 11:38:10-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 09:01:06-07:00",
    "text": "Apologies for the terse / rushed tone of this ballot - I'm currently traveling and really short on time.  1: \"A mapping service (e.g., DNS) MUST provide a trusted (e.g., via DNSSEC [ RFC4034 ]) conversion of the 4-character Manufacturer Code to high-order 58 bits (Prefix | HID) of the HHIT.\u00a0 Definition of this mapping service is currently out of scope of this document.\" -- this feels really underspecified, especially because it is a MUST. DNSSEC provides channel security, but by itself doesn't provide \"trusted\" data, nor provide a \"conversion\", etc.  Where is the \"trust\" here? (Sec 9 doesn't really answer this) Who is supposed to run this? Even more so, why is this a \"just stick it in the DNS\" type solution (see comment #2).  2: \"Now it should be noted that the 2^64 attempts is for stealing a specific HHIT.\u00a0 Consider a scenario of a street photography company with 1,024 UAs (each with its own HHIT); you'd be happy stealing any one of them.\" This is only true if I want to steal one for this specific street photography company - surely I'd be perfectly happy \"stealing\" any HHIT that works? Doesn't that make it more on the order of (number of units), not 1024? Also, the \"Therefore, the HHIT registration and HHIT/HI registration validation is strongly recommended.\" bit seems underspecified.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-05 07:18:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 10:55:51-08:00",
    "text": "Thank you for the work put into this document. It is easy to read. Please find below a couple of blocking DISCUSS points and some non-blocking COMMENT points and some nits. In addition to my own points, please consider Zhen Caos' INT directorate review at: https://datatracker.ietf.org/doc/review-ietf-dots-server-discovery-11-intdir-lc-cao-2020-10-12/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4 -- Trivial to fix: there is no \"DHCP lease\" for stateless DHCPv6... You should probably rather refer to the information-request refresh time option (section 21.23 of  RFC 8415 ). -- Section 5.1.2 -- I fully second Zhen Cao's review: how will the IPv4-mapped IPv6 address(es) be used? They MUST not appear on the wire and there is a DHCPv4 option to convey the DOTS information. Is it when DHCPv6 is available, no DHCPv4, and only IPv4 connectivity to the DOTS server ? If so, then please clarify the text.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-22 20:26:58-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-18 15:15:16-08:00",
    "text": "These should be quite straightforward to resolve, but do need to be addressed before publication: (1) Section 2.6.4 lists some KEM identifiers and says that \"these algorithms ... are key encapsulation mechanisms using elliptic curve encryption\".\u00a0 But RSAES-KEM is in the list, which is based on RSA encryption, not elliptic-curve encryption.\u00a0 (I note that the example in \u00a72.6.4 has an\u00a0 element, which seems to make it not a terribly useful example for RSAEA-KEM usage.) (2) Section 2.3 also makes this interesting statement: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  That is to say, the verification \u00a0  key is different from and not feasibly derivable from the signing \u00a0  key. This is demonstrably false; e.g., for the Edwards-Curve methods, where \u00a75.1.5 of  RFC 8032  provides a step-by-step procedure for determining the verification key from the signing key.\u00a0 If the statement was reversed (\"signing key is not feasibly derivable from the verification key\"), it would seem unobjectionable.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 11:56:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-22 20:26:58-08:00",
    "text": "Thanks for the updates in the -23 through -25, they include many good fixes.\u00a0 Unfortunately, the changes introduced a new issue, and in reviewing around that I noticed another thing that seems problematic. The XMSS and XMSSMT identifiers listed don't match up with the prose and are hard to match up to FIPS 202, the stated reference for the SHAKE XOF(s).\u00a0 Specifically, FIPS 202 defines *two* XOFs, SHAKE128 and SHAKE256, not the (one) \"SHAKE extensible output function\" mentioned in the prose. The tabulated identifiers include in the second token of the URI anchor both \"shake\" and \"shake256\", which one might presume to indicate SHAKE128 and SHAKE256, respectively, but we should really be more explicit about what the \"shake\" token means (or just switch to \"shake128\"). We definitely need to correct the prose to indicate that there are two XOFs, though. I'm also a bit confused by the options given for 192-bit output sizes. The prose indicates that there should be a \"SHA2 output size\" of 192 bits, but the listed reference for SHA2 ( RFC 6234 ) does not offer a native 192-bit hash function, and if a truncated version of a SHA2 family hash function is desired, we would need to indicate which member of the SHA2 family is to be used prior to truncation.\u00a0 My apologies for not having noticed this previously. (The SHAKE functions, as XOFs, of course have no difficulty producing a 192-bit output, though the security strength of such an offering is low enough that it's unclear whether we actually want to provide that option.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-08-05 09:02:27-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 04:36:13-07:00",
    "text": "Julius, Thank you for the work put into this document. I have one DISCUSS and a couple of COMMENTs. One generic comment: is there a need to describe (even in a short format) Babel again? Regards, -\u00e9ric == DISCUSS == -- Section 2.2 -- The 'bug resistance' property of Babel was perhaps learned during the implementation, but, I wonder whether the document may simply state 'robust with respect to bugs', this is quite a strong statement that needs to be backed by facts or proof.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-09 12:28:12-07:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 16:55:47-08:00",
    "text": "I may well just be confused about this, but let's discuss and find out. Section 3.3.2 says \"[a]s per  RFC 8505 , a 6LN MUST NOT register its link-local address.\"\u00a0 Which part of  RFC 8505  says this?\u00a0 Section 5.6 thereof seems to enumerate some cases where link-local addresses MUST (not MUST NOT) be registered, and there's not much other discussion of link-local addresses that I saw.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-04-22 11:37:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 15:55:38-08:00",
    "text": "I found this paragraph in Section 3.1 to be hand-wavy: \"Note that this specification allows using different MTUs in different \u00a0  links.\u00a0 If an implementation requires use of the same MTU on every \u00a0  one of its links, and a new node with a smaller MTU is added to the \u00a0  network, a renegotiation of one or more links can occur.\u00a0 In the \u00a0  worst case, the renegotiations could cascade network-wide.\u00a0 In that \u00a0  case, implementers need to assess the impact of such phenomenon.\" What are the consequences of link \"renegotiation\"? If every MTU downgrade results in a storm of messages, that's a bad property. Is the use case where the MTU must be the same on all links an important one? If not, simply requiring hosts to handle this case seems way cleaner.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-06-16 04:14:45-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-16 04:09:46-07:00",
    "text": "This document seems to have unresolved IANA issues. Holding a DISCUSS until we can confirm on the telechat that a resolution is in progress.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-29 02:12:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-16 04:14:45-07:00",
    "text": "# GEN AD review of  draft-ietf-avtcore-cryptex-06 CC @larseggert Thanks to Linda Dunbar for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/OSDyO_tiu5StDZyyJjwRP-Nvj-M ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS until we can confirm on the telechat that a resolution is in progress.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-19 09:33:18-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 04:28:16-07:00",
    "text": "Thanks for this document. It is clear, and I appreciate reading the rationale of the proposed solution. Just one discuss item: \u00a0  Peers MAY negotiate both Cryptex and the header extension mechanism \u00a0  defined in [ RFC6904 ] via signaling, and if both mechanisms are \u00a0  supported, either one can be used for any given packet.\u00a0 However, if \u00a0  a packet is encrypted with Cryptex, it MUST NOT also use [ RFC6904 ] \u00a0  header extension encryption, and vice versa. Why this complexity? Based on the Section 1, Cryptex is much more preferred. Why allow \"either one can be used for any given packet\" instead of saying if both are negotiated, Cryptex SHOULD be used? Or why not stronger, if both peers support Cryptex,  RFC6904  SHOULD NOT (MUST NOT?) be used?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-07-25 08:02:18-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-14 14:50:53-07:00",
    "text": "I\u2019m having trouble understanding the relationship between this work and SRTP without making assumptions.\u00a0 Section 1.3 notes that there is a design goal to build on top of SRTP and to have simple SRTP interactions.\u00a0 Section 3 also says the design goal is to \u201creuse the existing SRTP framework.\u201d\u00a0 Finally, Section 6.2 and 6.3 says \u201d[t]he encryption (or decryption) procedure is identical to that of [ RFC3711 ] except for the Encrypted Portion of the SRTP packet.\u201d I believe the correct read is that \u201cdo everything from SRTP unless noted as different here\u201d.\u00a0 However, saying \u201cencryption and description procedures\" per Sections 6.2/6.3 doesn\u2019t capture that for me.\u00a0 This leaves open questions about key management, establish and maintaining state for cryptographic contexts, MTI algorithms, etc. The text would benefit from being explicit on what behavior \u201ca=cryptex\u201d behavior reuses from SRTP.\u00a0 I don\u2019t believe that changes any of the expected core mechanics.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-02-06 09:39:32-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-05 10:48:03-08:00",
    "text": "(1) Picking up on a Gen-ART review comment: Section 5.1.7 seems to be aimed at entities other than the operators of DNS privacy services. That is, the \"impact\" seems like it is on third-party entities, but then the \"optimization\" talks about DNS privacy service operators using \"alternative means for traffic monitoring.\" I guess what I don't understand is why the DNS privacy service operators need alternative means, since they still have access to the cleartext. (2) I think Section 6 needs to clarify that it is providing suggestions only on matters relating to the technical operation of DNS privacy services that may be described in DROP policies, and not on any other matters. There are numerous other matters that are typically addressed in privacy statements (e.g., what form of legal process the operator requires to supply data to law enforcement, how the operator handles data about children, etc.). This document should not give the impression that the listed items in the subsections are an exhaustive list, nor should it attempt to offer an exhaustive list. (3) I do not think item #5 in Section 6.1.2 belongs in this document. I don't see how it is within scope for the IETF to be specifying these sorts of best practices.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-06-28 11:44:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-06 09:39:32-08:00",
    "text": "I have added more detail to point #3 below as requested on today's telechat. (1) Picking up on a Gen-ART review comment: Section 5.1.7 seems to be aimed at entities other than the operators of DNS privacy services. That is, the \"impact\" seems like it is on third-party entities, but then the \"optimization\" talks about DNS privacy service operators using \"alternative means for traffic monitoring.\" I guess what I don't understand is why the DNS privacy service operators need alternative means, since they still have access to the cleartext. (2) I think Section 6 needs to clarify that it is providing suggestions only on matters relating to the technical operation of DNS privacy services that may be described in DROP policies, and not on any other matters. There are numerous other matters that are typically addressed in privacy statements (e.g., what form of legal process the operator requires to supply data to law enforcement, how the operator handles data about children, etc.). This document should not give the impression that the listed items in the subsections are an exhaustive list, nor should it attempt to offer an exhaustive list. (3) I do not think item #5 in Section 6.1.2 belongs in this document. I don't see how it is within scope for the IETF to be specifying these sorts of best practices, which are not technical or operational in nature but focus on legal matters and likely require the involvement of lots of lawyers in order to get the provisions written. This section implies that the DROP documents would become legal/compliance documents by nature, which may or may not be a good choice but is not within the remit of the IETF to specify. Also, I think what this section asks for is not the norm today and therefore it seems odd for the IETF to specify a best practice that operators may not have any chance of being able to comply with (e.g., listing specific law enforcement agencies, privacy laws, or countries where data centers will reside and the data will never move from them).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-07-02 06:16:22-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-28 11:44:02-07:00",
    "text": "Trimmed to the one outstanding point from my original DISCUSS: I do not think item #5 in Section 6.1.2 belongs in this document. I don't see how it is within scope for the IETF to be specifying these sorts of best practices, which are not technical or operational in nature but focus on legal matters and likely require the involvement of lots of lawyers in order to get the provisions written. This section implies that the DROP documents would become legal/compliance documents by nature, which may or may not be a good choice but is not within the remit of the IETF to specify. Also, I think what this section asks for is not the norm today and therefore it seems odd for the IETF to specify a best practice that operators may not have any chance of being able to comply with (e.g., listing specific law enforcement agencies, privacy laws, or countries where data centers will reside and the data will never move from them).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-03 15:20:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-03 15:19:55-08:00",
    "text": "This document is trying to make normative references to sections of draft-ietf-dprive-rfc7626-bis  that have not existed since the -01 of that document, with the content having been removed for being too controversial. Do we need to delay processing this document until 7626bis has settled down and it is clear what content we can refer to in that vs. needing to incorporate into this document?\u00a0 (It's unclear that such content would be less controversial in this document than in that one.) Specifically, Section 5.1.2 of this document refers to Section 2.5.3 of that document (\"Rogue Servers\").",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-05 19:30:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-03 15:20:17-08:00",
    "text": "This document is trying to make normative references to sections of draft-ietf-dprive-rfc7626-bis  that have not existed since the -00 of that document, with the content having been removed for being too controversial. Do we need to delay processing this document until 7626bis has settled down and it is clear what content we can refer to in that vs. needing to incorporate into this document?\u00a0 (It's unclear that such content would be less controversial in this document than in that one.) Specifically, Section 5.1.2 of this document refers to Section 2.5.3 of that document (\"Rogue Servers\").",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-27 16:05:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 19:30:17-08:00",
    "text": "[updated to add one discuss point and a comment section] This document is trying to make normative references to sections of draft-ietf-dprive-rfc7626-bis  that have not existed since the -00 of that document, with the content having been removed for being too controversial. Do we need to delay processing this document until 7626bis has settled down and it is clear what content we can refer to in that vs. needing to incorporate into this document?\u00a0 (It's unclear that such content would be less controversial in this document than in that one.) Specifically, Section 5.1.2 of this document refers to Section 2.5.3 of that document (\"Rogue Servers\"). [new discuss point] This is perhaps more a flaw in  RFC 8310  than in this document, but I'd still like to discuss it: in Section 5.1.2 we read that: \u00a0  When using DNS-over-TLS clients that select a 'Strict Privacy' usage \u00a0  profile [ RFC8310 ] (to mitigate the threat of active attack on the \u00a0  client) require the ability to authenticate the DNS server.\u00a0 To \u00a0  enable this, DNS privacy services that offer DNS-over-TLS should \u00a0  provide credentials in the form of either X.509 certificates \u00a0  [ RFC5280 ] or Subject Public Key Info (SPKI) pin sets [ RFC8310 ]. Authenticating the DoT server via X.509 certificate as described here and in RFC 8310  seesm to involve looking for an ADN in the certificate; however, I could not find any discussion of how to know what CA(s) or trust anchors to trust to certify the ADN in a certificate.\u00a0 It's possible that  RFC 8310 's use of \"PKIX Certificate\" is supposed to imply that Web PKI trust anchors are used, but that's not immediately clear.\u00a0 It may be the case that we need to mention provisioning a trust anchor as well as the X.509 certificate information, here.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-04-27 02:19:43-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-07 04:43:02-07:00",
    "text": "Thanks for this document, and sorry for the late discuss, which should hopefully be trivial to fix. \u00a0  Notification (N): 1 bit \u00a0 \u00a0 \u00a0 When set to 1, this bit indicates that the control plane message \u00a0 \u00a0 \u00a0 exchange is only used for notification during protection \u00a0 \u00a0 \u00a0 switching.\u00a0 When set to 0 (default), it indicates that the control \u00a0 \u00a0 \u00a0 plane message exchanges are used for protection-switching \u00a0 \u00a0 \u00a0 purposes.\u00a0 The N bit is only applicable when the LSP Protection \u00a0 \u00a0 \u00a0 Type Flag is set to 0x04 (1:N Protection with Extra- Traffic), \u00a0 \u00a0 \u00a0 0x08 (1+1 Unidirectional Protection), 0x10 (1+1 Bidirectional \u00a0 \u00a0 \u00a0 Protection), or 0x20 (Shared Mesh Protection).\u00a0 If 0x20 (SMP), the \u00a0 \u00a0 \u00a0 N bit MUST be set to 1.\u00a0 The N bit MUST be set to 0 in any other \u00a0 \u00a0 \u00a0 case. I think that the way that this  RFC4872  text has been updated makes this text unclear/ambiguous. Specifically, I think that somebody could reasonably interpret this as saying that the N bit is set to 1 for SMP, and otherwise it must always be set to 0, but I don't think that is the intention.\u00a0 So please can this be clarified. One fix could be to swap the order of the last 2 sentences.\u00a0 E.g., \u00a0 \u00a0 \u00a0 or 0x20 (Shared Mesh Protection).\u00a0 The N bit MUST \u00a0 \u00a0 \u00a0 be set to 0 in any other case. If 0x20 (SMP), the \u00a0 \u00a0 \u00a0 N bit MUST be set to 1. Alternatively, I think that you could possibly just remove the \"If 0x20 (SMP), the N bit MUST be set to 1.\" and instead rely on the text in 5.2/5.3, (perhaps strengthening with  RFC 2119  language if required). Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-04-21 12:59:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-20 22:49:38-07:00",
    "text": "Thanks for this document.\u00a0 Enabling Open-ID and OAUTH with SIP is quite useful. This document specifically calls out single sign-on as a reason to use this mechanism, and SSO has a host of serious security and privacy issues.\u00a0 As those issues are not discussed in the referenced documents, I think they need to be raised here.\u00a0 Recommended usage/configuration to avoid or mitigate the issues would be ideal, but at the very least I think they need to be documented, as it\u2019s clear that implementors are not aware of them or don\u2019t think they\u2019re important enough to worry about.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-05 11:46:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-23 12:25:03-07:00",
    "text": "I support Roman's Discuss. The \"Bearer\" authentication challenge includes the address (or name?) of an authorization server to contact to obtain tokens, as mentioned in multiple places in the document (noted in the COMMENT section).\u00a0 Our experience in the OAuth world has shown that several classes of vulnerabilities are possible when the client blindly attempt to use any provided AS, and that a whitelist of \"allowed\" or \"trusted\" ASes is needed for secure operation.\u00a0 I believe that the same is true for the SIP usage, and we should mention this requirement explicitly. Section 1.2 tries to apply the OAuth confidential/public client distinction to SIP UACs, but it does so in a non-analogous fashion: the OAuth distinction is for the client's ability to protect credentials that identify the client itself; the usage in this document refers to protecting *user* credentials and obtained tokens.\u00a0 I don't think that it's appropriate to invoke the OAuth terminology when using it for a different meaning. Both Public and Confidential OAuth clients are capable of providing the necessary protections for *user* credentials (though they are of course not guaranteed to do so), which leaves me unclear on what the intended requirements actually are. Section 2.3 states that: \u00a0  When a proxy wishes to authenticate a received request, it MUST \u00a0  search the request for Proxy-Authorization header fields with 'realm' \u00a0  parameters that match its realm.\u00a0 It then MUST successfully validate https://tools.ietf.org/html/rfc7235#section-4.4  suggests that it is not expected to have a sequence or list of Proxy-Authorization header fields present in a single request that are intended to be interpreted by different proxies.\u00a0 Is this text compatible with that part of  RFC 7235 ?\u00a0 Furthermore, I didn't find much guidance in 7235 or 3261 about when to include the \"realm\" parameter in Proxy-Authorization; do we want to give any guidance here?\u00a0 (That is to say, I almost didn't find where it was even defined as possible to do so...) I'm also not sure if we're attempting to profile  RFC 6749  and always require a refresh token to be issued, or just have some editorial tweaks to make to avoid suggesting that we do have such a requirement (noted in the COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-05-05 15:12:45-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-05 11:46:23-07:00",
    "text": "Thanks for the updates in the -14 (and -15); they cover most of my points. Unfortunately, the new security considerations text seems to introduce a problematic recommendation: \u00a0  Because of that, it is critical to make sure that extra security \u00a0  measures be taken to safeguard credentials used for Single Sign-On. \u00a0  Examples of such measures include long passphrase instead of a \u00a0  password, enabling multi-factor factor authentication, and the use of \u00a0  embedded browser when possible, as defined in [ RFC8252 ]. Looking at  RFC 8252  (Section 8.12), it seems to be rather strongly recommending to *not* use an embedded browser, which is the opposite of the apparent recommendation here.\u00a0 Are we missing a word \"avoiding\" or similar? Also, I am not 100% sure my note about refresh tokens was fully addressed; in Section 2.1.1 we see: \u00a0  The refresh token is only used between the UAC and the AS.\u00a0 If the AS \u00a0  provides a refresh token to the UAC, the UAC uses it to request a new \u00a0  access token and refresh token from the AS before the currently used \u00a0  access token expires ([ RFC6749 ], Section 1.5).\u00a0 If the AS does not Is it accurate to say that the refresh token is used \"to request a new access token and refresh token\" (specifically the \"and refresh token\" part)?\u00a0 I know that it is not always returned, but am less sure about whether the semantics always include an (implicit) request for a new one.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-04-28 02:00:54-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-23 06:31:42-07:00",
    "text": "I think these resolution for this is rather straight forward, however the implications of one is going to break deployed implementations.  1. Section 4: This is rather straight forward to resolve but you do have a SIP syntax violation in these rules.  \u00a0 \u00a0 \u00a0  challenge\u00a0 =/\u00a0 (\"Bearer\" LWS bearer-cln *(COMMA bearer-cln)) \u00a0 \u00a0 \u00a0  bearer-cln = realm / scope / authz-server / error / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 auth-param \u00a0 \u00a0 \u00a0  authz-server = \"authz_server\" EQUAL authz-server-value \u00a0 \u00a0 \u00a0  authz-server-value = https-URI \u00a0 \u00a0 \u00a0  realm =  \u00a0 \u00a0 \u00a0  auth-param =  \u00a0 \u00a0 \u00a0  scope =  \u00a0 \u00a0 \u00a0  error =  \u00a0 \u00a0 \u00a0  https-URI =  So  RFC 3261  defines the Challenge construct as:  challenge\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 (\"Digest\" LWS digest-cln *(COMMA digest-cln)) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / other-challenge Where this extension needs to match the syntax of the other-challenge: other-challenge\u00a0 \u00a0  =\u00a0 auth-scheme LWS auth-param \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *(COMMA auth-param) Where we need to look at: auth-param\u00a0 \u00a0 \u00a0 \u00a0 =\u00a0 auth-param-name EQUAL \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ( token / quoted-string ) Please note what is included in the \"token\" rule.  \u00a0 \u00a0 \u00a0 token\u00a0 \u00a0 \u00a0  =\u00a0 1*(alphanum / \"-\" / \".\" / \"!\" / \"%\" / \"*\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \"_\" / \"+\" / \"`\" / \"'\" / \"~\" ) the allowed syntax for https-URI in  RFC 7230  is: \u00a0 \u00a0 https-URI = \"https:\" \"//\" authority path-abempty [ \"?\" query ] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [ \"#\" fragment ] Which include both \"/\", \"?\" and \"#\" that are not allowed in token. Thus, the URI included in the authz-server-value\u00a0 MUST be converted into a quoted-string matching syntax rule.  2. In addition should not the \"authz_server\" be registered in the  https://www.iana.org/assignments/sip-parameters/sip-parameters.xhtml#sip-parameters-12  registry?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-05 06:11:48-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 08:01:38-07:00",
    "text": "The use of the OpenID ID token appears to be underspecified.\u00a0 Section 1.3 notes the possibility of using it as one of the three possible tokens.\u00a0 However, the SIP procedures in Section 2 makes no note of it, only covering the use of the \u201caccess token\u201d and the \u201crefresh token\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-11-27 14:40:39-08:00",
    "text": "(1) Let's talk briefly about how JWT issuers are identified.\u00a0 Section 4 has some text: \u00a0  For this ACME Authority Token usage of JWT, the payload of the JWT \u00a0  OPTIONALLY contain an \"iss\" indicating the Token Authority that \u00a0  generated the token, if the \"x5u\" element in the header does not \u00a0  already convey that information; typically, this will be the same \u00a0  location that appeared in the \"token-authority\" field of the ACME \u00a0  challenge.\u00a0 [...] While \"iss\" is the default way to identify a JWT issuer, the JWT BCP ( RFC 8725 ,  BCP 225 ) does not make a strong recommendation that it is the preferred way to do so, with the implication that other ways to identify the issuer are reasonable.\u00a0 However, the text here only mentions the \"x5u\" element as an alternative to \"iss\" for identifying the issuer, which does not seem to be a comprehensive depiction of the JWT ecosystem.\u00a0 Issuers could be identified by other X.509 related protected headers such as \"x5c\", or in some situations just by the key used for signing (when that key is accompanied by other configured metadata), among other things.\u00a0 So, I don't understand why we call out \"x5u\" specifically here and apparently don't allow other ways of identifying the issuer. (2) We seem to describe the contents of the \"atc\" JWT claim as an array in \u00a74, but the examples show its payload as a JSON map.\u00a0 Which is correct? (3) I'd also like to have a (hopefully brief) discussion about the properties that we do and do not provide as relates to binding an authority token to an ACME client. In particular, in the REST API to the Token Authority, we have the client provide the fingerprint of its ACME key/identity, but the Token Authority does not do any validation on that value and is expected to just include it directly in the issued token.\u00a0 This means that some other entity X who is not the legitimate client but knows their key (fingerprint), and is also authorized to use a given identifier by the Token Authority, could cause a token to be issued that references the legitimate client's key.\u00a0 (Note that X could learn the fingerprint of the client by, e.g., being a semi-trusted CDN in front of the ACME server as considered by  RFC 8555 \u00a710.1.)\u00a0 That token would then only be useful by the legitimate client, and so there would need to be some other vulnerability that lets X trick the client into using that token, but it still seems that we have broken the chain of custody that would let us claim that the authority token was generated \"based on a request from the client\" (\u00a73.3).\u00a0 In particular, it seems that (with these preconditions) we might have a scenario where a client gets issued a certificate for numbers that it is not actually authorized for! This weakness does not immediately lead to an obvious vulnerability, as it requires two additional factors to be exploited -- the attacker must themselves be authorized at the Token Authority, and there needs to be some as-yet-unknown mechanism for the attacker to cause the client to use this new/different token -- but I think we at a minimum need to document the properties that we don't provide. We could choose to make the mechanism more complicated and close off this loophole by requiring proof of possession in the request to the token authority.\u00a0 The obvious way to do this robustly would require another round trip, though, to let the token authority provide a nonce that the proof of possession is provided over.\u00a0 Sometimes we can use a TLS Exporter value to save on that round-trip, but I haven't thought through very carefully what that would look like here.\u00a0 The request to the token authority would probably need to convey the entire public key, not just the fingerprint, so that the signature could be verified. There's another risk relating to thumbprints that is probably worth documenting -- we in effect are hardcoding a dependence on SHA256 for the fingerprints.\u00a0 (I'm happy to see that the wire-format of the thumbprint does identify the hash function used, so a transition mechansims should be pretty straightforward.)\u00a0 In light of the  BCP 201 guidance for building in algorithm agility, I think we should say that we are hardcoding SHA256 and SHA256 is believed to still be quite strong (the SHA-3 contest helped solidify that position), but if a second preimage attack for SHA256 is found, an issued authority token could be used with a different ACME account key.\u00a0 We can also go on to say that in that event, implementations can migrate to using a different hash function for the fingerprints due to the in-band hash function identification in the fingerprint field.\u00a0 Such a transition would require a new RFC to actually specify the details of the new behavior, but would not be very invasive to implementations. (4) We mention almost in passing that the tkauth-01 challenge type has a new \"token-authority\" field that designates a location where a token can be acquired.\u00a0 I think we need to have some more explicit discussion of the semantics of this field and how it's populated, especially in light of how this document implies that typical usage will include \"token-authority\" but the companion document implies that \"token-authority\" will not be in common usage.\u00a0 We definitely need some discussion of the security considerations of having party X tell the client to go authenticate to party Y and do some thing; this type of flow is very prone to enabling phishing attacks where the client gives party Y credentials that party Y is not supposed to have.\u00a0 In many cases it ends up being a de facto requirement that the client is configured with a specific list of allowed values for \"party Y\" and must reject anything not known to be trusted.\u00a0 (So, in this case, that would have the client reject any token authority URLs that are not in this preconfigured allow-list.)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-07-13 12:09:04-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 21:18:43-08:00",
    "text": "The examples in Section 4 make use of a function called \"base64url\" which is defined in  RFC 4648 .\u00a0 Do we not need a normative reference to that document? There was some chatter from the ARTART reviewer (review still pending) that suggested some confusion around validating the examples, and this was part of it.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-06-24 14:50:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-30 14:37:34-07:00",
    "text": "I'd like to DISCUSS some questions I have about the content of Section 4's IS-IS rules. I don't expect it will be difficult to resolve these, I just want to be sure we have the conversation. 1. In \u00a74 (2.C), \u00a0 \u00a0 \u00a0  C.\u00a0 The SRLGs advertised in IS-IS SRLG ASLA TLVs and the other \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  link attributes advertised in IS-IS ASLA sub-TLVs are \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  REQUIRED to be collated, on a per-application basis, for all \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  applications that have their bit set in the SABM/UDABM in at \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  least one of the aforementioned TLV types. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0   Is there some reason that there's no need to consider the case where both of the TLV types in question have zero-length application bit masks? 2. Later in the same paragraph, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  When performing \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  this collation, only the TLVs with the application's bit set \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  in SABM/UDABM MUST be used when such TLVs are available from \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  either TLV types. I suspect you aren't saying what you mean, and the \"only... MUST\" construct is hard to puzzle out. Do you perhaps mean TLVs that don\u2019t have the application's bit set MUST NOT be used? Because as you've written it,  - All TLVs with the bit set MUST be collated, - Any TLVs without the bit set MAY be collated (by implication). Which doesn't seem very sensible AFAICT. A possible rewrite, if I've understood your intention correctly, might be \"When performing this collation, every TLV with the application's bit set in SABM/UDABM MUST be included, when such TLVs are available from either TLV type.\" (Note also a minor fix for agreement in number, s/types/type/ in the last word.) 3. And still later in the same paragraph, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If the bit for an application is set in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the SABM/UDABM of only one of the TLV types, then the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  attributes from the other TLV type with zero-length \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application bit mask MUST be also collated for that \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application, if such TLV is available. I'm confused by the reference to a zero-length application bit mask. Can't the other TLV type have a nonzero-length application bit mask, but still have the application bit in question not set within the bit mask? I guess probably what you mean is, if the other TLV type is present and has a zero-length application bit mask, since a zero-length SABM/UDABM basically is a wildcard, the equivalent of all bits being set (as I read  RFC 8920 ).  If that's right, then a change seems in order, along the lines of \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If the bit for an application is set in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the SABM/UDABM of only one of the TLV types, and if the  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  other TLV type has a zero-length application bit mask, then the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  attributes from the other TLV type with zero-length \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application bit mask MUST be also collated for that \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  application, if such TLV is available. I just interpolated the \"and\" clause. It's a bit wordy and could probably be further condensed, but I think it clarifies sufficiently. On the other hand, if I'm not right about this (very possible) then I'd appreciate further discussion on what I got wrong, so we can figure out if the text needs clarification or if I just need a clue bat.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-06-26 12:49:35-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-23 08:41:03-07:00",
    "text": "Several sections mandate actions to be taken where the specific mechanisms are not clearly defined.\u00a0 This lack of specifics leaves me at a loss about what is being mandated. Specifically: (1) \u00a74.3.2 (Quality of Service): \"Quality of Service...MUST be provided  \u00a0 \u00a0 locally by the DetNet-aware hosts and routers supporting DetNet flows.\u00a0  \u00a0 \u00a0 The traffic control mechanisms used to deliver QoS...are expected to be  \u00a0 \u00a0 defined in a future document.\" (2) \u00a75.2 (Forwarding Procedures): \"Specifically...SHALL use management and  \u00a0 \u00a0 control information to select the one or more outgoing interfaces and  \u00a0 \u00a0 next hops...\"\u00a0 This sentence sounds very generic to me: using management  \u00a0 \u00a0 and control information is what every forwarder does -- regardless of  \u00a0 \u00a0 DetNet.\u00a0 Not only is it a generic statement, but the management and  \u00a0 \u00a0 control functions are not defined... (3) \u00a75.3 (DetNet IP Traffic Treatment Procedures): \"MUST ensure that a  \u00a0 \u00a0 DetNet flow receives the traffic treatment that is provisioned for  \u00a0 \u00a0 it...Typical mechanisms used to provide different treatment to different  \u00a0 \u00a0 flows includes the allocation of system resources...and provisioning or related parameters...Other mechanisms than the ones used in the TSN case are outside the scope of this document.\"  It is ok to define the mechanisms in a different document -- but there are no specific references.\u00a0 What exactly is this document requiring (MUST)?\u00a0 If there are no specifics on the mechanisms (or where they are defined), how can an implementation comply with this document?\u00a0 What are the interoperability consequences if not all nodes comply with the same set of (undefined) mechanisms? I am balloting DISCUSS because I believe that this omission makes the specification incomplete.\u00a0  Adding details will satisfy my concern.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-10 04:22:47-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-22 11:51:02-07:00",
    "text": "A few easy clarifications: ** Section 7.\u00a0 Per \u201cFrom a data plane perspective this document does not add or modify any header information\u201d, this statement, which is also found in Section 9.1 of  draft-ietf-detnet-security-10  does not seem consistent with Section 3 which states \u201c\u2026 however modification of these fields is allowed, for example changing the DSCP value, when required by the DetNet service\u201d. ** Section 7.\u00a0  RFC8655  reminds us that \u201cSecurity considerations for DetNet are constrained (compared to, for example, the open Internet) because DetNet is defined to operate only within a single administrative domain\u201d.\u00a0 However, the only IP-specific guidance on preventing escape from the DetNet domain is in Section 4.2 (\u201cNote that not mixing DetNet and non-DetNet traffic within a single 5-tuple,\u00a0 as described above, enables simpler 5-tuple filters to be used (or re-used) at the edges of a DetNet network to prevent non-congestion-responsive DetNet traffic from escaping the DetNet domain.\u201d).\u00a0 Please provide more prescriptive guidance in this section. ** Section 7.\u00a0 The guidance from  RFC8655  and  draft-ietf-detnet-security  needs to be deconflicted relative to confidentiality.\u00a0 The following assertions are stated in a single paragraph: (a) The primary considerations for the data plane is to maintain \u00a0  integrity of data and delivery of the associated DetNet service \u00a0  traversing the DetNet network.\u00a0   (b) Application flows can be protected \u00a0  through whatever means is provided by the underlying technology.\u00a0 For \u00a0  example, encryption may be used, such as that provided by IPSec \u00a0  [ RFC4301 ] for IP flows and/or by an underlying sub-net using MACSec \u00a0  [IEEE802.1AE-2018] for IP over Ethernet (Layer-2) flows. (a) appears to be a cut-and-paste (or maybe vice versa) from Section 9 of  draft-ietf-detnet-security-10 (b) appears to be a cut-and-paste from Section 5 of  RFC8655 . The concatenation of (a) + (b) appears to be unique to this document. When  RFC8655  states (b), it prefaced with \u201c[t]o maintain confidentiality of data traversing the DetNet, application flows can be protected through whatever means is provided by the underlying technology.\u201d\u00a0 (a) makes no references to confidentiality.\u00a0 It seems like it should.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-17 01:39:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-21 09:29:05-07:00",
    "text": "Thank you for the work on this document. This is a discuss DISCUSS - while reading this document and considering the normative downref to  RFC 8907  TACACS+, which is informational, I agree with Elliot [1] that to me this document would make more sense as informational. I have followed the mail thread and saw the authors' responses, which quoted  RFC 3967  : \u00a0  o\u00a0 A standards document may need to refer to a proprietary protocol, \u00a0 \u00a0 \u00a0 and the IETF normally documents proprietary protocols using \u00a0 \u00a0 \u00a0 informational RFCs. I am not convinced that this is one of the cases that this bullet was supposed to cover. Additionally, I could not find in meeting minutes that this was ever discussed in the wg, as was suggested in the mail thread [2]. I'd like to know if the resp AD is aware of any related discussion after this point was raised. Another point the authors made in favor of keeping this std track was that they haven't seen any YANG data model published as informational. Again, I am not convinced that this is reason enough to progress this as std track. I note that this was reported in the shepherd write up [3] and in the last call [4], so won't block progress after a discussion, but I do think it is worth talking about. Please let me know if I missed anything. Thanks, Francesca [1]  https://mailarchive.ietf.org/arch/msg/opsawg/2mRkaXy5M9XCPp4_wXNpQd9GLdk/   [2]  https://mailarchive.ietf.org/arch/msg/opsawg/MOnCfYBS3j4wBnZWDjl_YQHfvzg/ [3]  https://datatracker.ietf.org/doc/draft-ietf-opsawg-tacacs-yang/shepherdwriteup/ [4]  https://mailarchive.ietf.org/arch/msg/opsawg/FJmtUtB0x8tV0MUdO9Uhvc2e1p0/",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-13 12:17:25-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-19 15:08:09-07:00",
    "text": "**  RFC8907  was published with informational status and it contained substantial caution in its security considerations that the protocol was fundamentally insecure and would not \u201cmeet modern-day requirements.\u201d\u00a0 This measured approach was taken to provide a stable description of a widely deployed protocol and to serve as the basis for future improvements. The context for this follow-on, seemingly related work does not track the situation around  RFC8907  (as I remember it).\u00a0 Specifically: -- this functionality is new, and is not documenting the \u201cas is\u201d deployed state -- this functionality is advocating for supporting an insecure approach with proposed standard (rather than informational) status ** Is this document intentionally breaking backward compatibility on the \u201cshared-secret\u201d size specified in  RFC8907 ? (a) Section 4. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case shared-secret { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 leaf shared-secret { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type string { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 length \"16..max\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } (b) Section 10.5.1 of  RFC8907  says \u201cTACACS+ server administrators SHOULD configure secret keys of a minimum of 16 characters in length.\u201d As (b) is not a MUST (a \u201csecret key\u201d shorter than 16 is possible), it would appear that (a) breaks compatibility.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-03-25 07:54:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-25 02:23:44-07:00",
    "text": "\"Appendix C\", paragraph 1, discuss: > Appendix C: Automating the Initial Window in TCP over Long Timescales The content of this appendix seems to be unrelated to TCB sharing and reads like a separate document - why is it included in this document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-17 00:31:35-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-19 19:45:44-07:00",
    "text": "(1) I am not entirely sure what we mean by saying that temporary addresses must have a lifetime that is \"statistically different\" across different addresses, and accordingly I am not sure that the procedures in Section 3.4+3.5 for rereshing a temporary address achieve that property.\u00a0 (The text about \"statistically different\" does not appear in  RFC 4941 , and the relevant parts of Section 3.4/3.5 are unchanged from  RFC 4941 , so this may be the result of an incomplete update.) Specifically, when Section 3.5 says to \"[repeat] the actions described in Section 3.4, starting at step 4\" that seems to (for long-lived PIOs) result in, e.g., the new temporary address having lifetime TEMP_VALID_LIFETIME starting at exactly the time when the previous one expired; wouldn't an observer be able to trivially correlate \"new address showed up with TEMP_VALID_LIFETIME\" with \"address that expired at that time\"?\u00a0 Note that the attacker does not need to know the value of TEMP_VALID_LIFETIME in order to perform a DFT on the distribution of \"new address\" events.\u00a0 (Furthermore, we apparently qualify the \"repeating the actions\" with some caveats, which doesn't exactly qualify as \"repeating the actions\" anymore.\u00a0 That said, the caveats currently listed in Section 3.5 don't seem to be enough to provide the \"statistically different property\" in what I believe to be the intended interpretation.) (2) Please fix the reference for DupAddrDetectTransmits in Section 3.8 -- it is defined in 4862, while RetransTimer is in 4861. (3)  RFC 4941  cannot be a *normative* reference of this document if we are going to Obsolete it.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-12-01 10:55:29-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 01:47:45-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-v6ops-ipv6-deployment-08 CC @evyncke Thank you for the work put into this document even if I had hoped for a cleaner document. I also regret that security is not mentioned as an incentive to deploy IPv6 security policies as most end-points have IPv6 enabled by default. I am also concerned that this document did not get enough reviews (thanks Robert for your  https://mailarchive.ietf.org/arch/msg/v6ops/Trz62uglkVKOuXY3gXV_lNpyBEc/  and 3 reviews -- if not mistaken -- during V6OPS WGLC). Please find below several blocking DISCUSS points (should the document be sent back to the V6OPS WG ?) and some non-blocking COMMENT points. Special thanks to Fred Baker for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this review helps to improve the document because it is important Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 1.1 ``` \u00a0 \u00a0 \u00a0 IPv4 as a Service (IPv4aaS): It means that IPv4 service support is \u00a0 \u00a0 \u00a0 provided by means of transition mechanism, therefore there is a \u00a0 \u00a0 \u00a0 combination of encapsulation/translation + IPv6-only overlay + \u00a0 \u00a0 \u00a0 decapsulation/translation.\u00a0 For an IPv6-only network, connectivity \u00a0 \u00a0 \u00a0 to legacy IPv4 is either non-existent or provided by IPv4aaS \u00a0 \u00a0 \u00a0 mechanisms. ``` It must be \"IPv6-only underlay\", see other use of \"underlay/overlay\" in other IETF published RFC: 7364, 7365, 9272, ... ### Section 4.2 overlay Again the title and the introduction are incorrect. It should be \"IPv4 as a Service and IPv6-only ***Underlay***\". ``` \u00a0  Both are IPv4aaS solutions by leveraging IPv6-only overlay.\u00a0 IPv4aaS \u00a0  offers Dual-Stack service to users and allows an ISP to run IPv6-only \u00a0  in the network (typically, the access network). ``` The above text repeats the same mistake. ### Section 4.2 464XLT and MAP-T While I really like 464XLT, it should not appear in a section with \"underlay\" as it is *not* an encapsulation mechanism. The same reasoning applies for MAP-T. The section should be about IPv4aaS then 464XLAT and MAP-T could be included. ### Section 5.2 ``` \u00a0  IPv6 addresses can be assigned to an interface \u00a0  through different means, such as Stateless Auto-Configuration (SLAAC) \u00a0  [ RFC4862 ], stateful and stateless Dynamic Host Control Protocol \u00a0  (DHCP) [ RFC8415 ].\u00a0  ``` Stateless DHCPv6 *does not* assign IPv6 addresses/prefixes. ### Section 5.4.2 As it is linked to security, I am raising this to a DISCUSS level. Fragmentation can be used to bypass all layer-4 filters not only in NDP as mentioned in the draft, but in any protocol. Please add text about  RFC 8200  section 5: ``` \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Extension headers, if any, and the Upper-Layer header.\u00a0 These \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  headers must be in the first fragment. ```",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-24 19:40:54-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-05 09:43:44-08:00",
    "text": "I see that the list of \"changes since  RFC 7540 \" in Appendix B lists: \u00a0  *\u00a0 The ranges of codepoints for settings and frame types that were \u00a0 \u00a0 \u00a0 reserved for \"Experimental Use\" are now available for general use. But this doesn't seem to be reflected in either \u00a711 (IANA Considerations) or the live registry. Should it be?\u00a0 (Some backchannel discussion suggests that it's rather this entry in the appendix is erroneous.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-17 09:27:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-09 23:21:21-07:00",
    "text": "(Very much a \"discuss discuss\" -- I just want to make sure the conversation happens, regardless of the outcome.) I do see the response to Alvaro's ballot position but I'm still not sure that I understand what specifically requires this document to be on the standards-track. Yes, there are differences between IP-over-MPLS and IP-over-DetNet-MPLS, but (e.g.) how much of the DetNet-specific handling is just \"when you send the traffic onwards you need to ensure the quality of service\" which in this scenario means translating the DetNet IP needs into the DetNet MPLS configuration?\u00a0 In other words, a lot of this seems to be just giving information about how to fulfill the existing requirements from (e.g.)  draft-ietf-detnet-ip , so I am not sure that I understand what the truly new protocol pieces and/or requirements are.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-24 08:48:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-18 20:53:13-08:00",
    "text": "I think the following text from Section 4.1 of  RFC8314  needs to be updated as well. Is there any reason this is left out? \u00a0  Transition of users from SSL or TLS 1.0 to later versions of TLS MAY \u00a0  be accomplished by a means similar to that described above.\u00a0 There \u00a0  are multiple ways to accomplish this.\u00a0 One way is for the server to \u00a0  refuse a ClientHello message from any client sending a \u00a0  ClientHello.version field corresponding to any version of SSL or \u00a0  TLS 1.0.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-24 08:48:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-24 08:48:16-07:00",
    "text": "hanks for addressing my DISCUSS point about legacy ClientHello handling in -05.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-02 17:36:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-20 16:40:01-07:00",
    "text": "In Section 2.3 we make a claim about item 'e)' of section 5.5.3 of  RFC 4862 , in particular that it says that 'an RA may never reduce the  RemainingLifetime\" to less than two hours', but the relevant text from  RFC 4862  seems to be: \u00a0 \u00a0 \u00a0 2.\u00a0 If RemainingLifetime is less than or equal to 2 hours, ignore \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the Prefix Information option with regards to the valid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 lifetime, unless the Router Advertisement from which this \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 option was obtained has been authenticated (e.g., via Secure \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Neighbor Discovery [ RFC3971 ]).\u00a0 If the Router Advertisement \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 was authenticated, the valid lifetime of the corresponding \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 address should be set to the Valid Lifetime in the received \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 option. which clearly allows an *authenticated* RA to reduce the \"RemainingLifetime\" to smaller values.\u00a0 (Text with a similar not-quite-accurate statement appears in Section 2.4 of this document as well.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-14 22:01:53-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 20:53:14-08:00",
    "text": "(1) Rather a \"discuss-discuss\", but we seem to be requiring some changes to TLS 1.3 that are arguably out of charter.\u00a0 In particular, in Section 8.3 we see that clients are forbidden from sending EndOfEarlyData and it (accordingly) does not appear in the handshake transcript.\u00a0 The reasoning for this is fairly sound; we explicitly index our application data streams and any truncation will be filled in as a normal part of the recovery process, so the attack that EndOfEarlyData exists to prevent instrinsically cannot happen.\u00a0 However, the only reason we'd be required to send it in the first place is if the server sends the \"early_data\" extension in EncryptedExtensions ... and we already have a bit of unpleasantness relating to the \"early_data\" extension, in that we have to use a sentinel value for max_early_data_size in NewSessionTicket to indicate that the ticket is good for 0-RTT, with the actual maximum amount of data allowed indicated elsewhere.\u00a0 TLS extensions are cheap, so a new \"quic_early_data\" flag extension valid in CH, EE, and NST would keep us from conflating TLS and QUIC 0-RTT semantics, thus solving both problems at the same time.\u00a0 On the other hand, that would be requiring implementations to churn just for process cleanliness, so we might also consider other alternatives, such as finessing the language and/or document metadata for how this specification uses TLS 1.3. (There are a couple other places in the COMMENT where we might suffer from scope creep regarding TLS behavior as well, but I did not mark them as DISCUSS since they are not changing existing specified behavior.) (2) Let's check whether the quic_transport_parameters TLS extension should be marked as Recommended or not.\u00a0 The document currently says \"Yes\", and the live registry say 'N'.\u00a0 That said, the earliest mention I can see of using 'N' in the archives is in https://mailarchive.ietf.org/arch/msg/tls-reg-review/z8MOW0bYNP2KIj4XcCXBe2IOKfI/ which seems to just be stating what IANA did when they changed what codepoint (since there were issues with the initially selected value '46') and not a reasoned decision. The perhaps haphazard nature of that change notwithstanding, in my opinion the 'N' actually is correct, since the extension is not appropriate for general use *of TLS* (indeed, we require that TLS implementations that support this document abort the connection if it is used for non-QUIC connections).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-13 21:21:17-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 22:47:08-08:00",
    "text": "s the genart reviewer noted, the sentence being deleted isin Section 2.1 of RFC 2026, not Section 2.6 (as currently claimed).",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-03-10 08:57:11-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 06:48:23-08:00",
    "text": "Thanks for the effort here. I am putting a discuss as I agree with TSVART review by Bernard Aboba\u00a0 about normative ref to iab-rfcefdp-rfced-model. That will be downref as well.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-06-15 12:17:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 09:53:46-07:00",
    "text": "# ART AD Review of  draft-ietf-avtcore-rtp-vvc-16 cc @fpalombini Thank you for the work on this document. I have two DISCUSS points - hopefully easy to resolve - and a few non blocking comments, but answers will be appreciated. Francesca ## Discuss ### DONL and NALU size in figures 5 and 6 Section 4.3.2: ``` \u00a0  The first aggregation unit in an AP consists of a conditional 16-bit \u00a0  DONL field (in network byte order) followed by a 16-bit unsigned size \u00a0  information (in network byte order) that indicates the size of the ``` Which indicates DONL to be a 16-bit field, but in the figure 5 DONL appears to be 24 bits. ``` \u00a0  An aggregation unit that is not the first aggregation unit in an AP \u00a0  will be followed immediately by a 16-bit unsigned size information \u00a0  (in network byte order) that indicates the size of the NAL unit in ``` Same for the NALU size: 16 bits in the paragraph above, but 24 bits in figure 6. ### IANA Media type review request missing As specified by  RFC6838 , it is strongly encouraged to post the media type registration to the media-types mailing list for review (see  https://mailarchive.ietf.org/arch/msg/media-types/3_DukpPWrpkTXO-zynjJlShtC1w/  for an example of a\u00a0 registration review). Is there any reason this was not done here? If not, please post to the media-types mailing list, and I will remove the discuss with no objections raised in a week or so.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-06-20 03:01:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 12:17:25-07:00",
    "text": "# ART AD Review of  draft-ietf-avtcore-rtp-vvc-16 cc @fpalombini Thank you for the work on this document. I have two (EDIT: one) DISCUSS points - hopefully easy to resolve - and a few non blocking comments, but answers will be appreciated. Francesca ## Discuss ### IANA Media type review request missing As specified by  RFC6838 , it is strongly encouraged to post the media type registration to the media-types mailing list for review (see  https://mailarchive.ietf.org/arch/msg/media-types/3_DukpPWrpkTXO-zynjJlShtC1w/  for an example of a\u00a0 registration review). Is there any reason this was not done here? If not, please post to the media-types mailing list, and I will remove the discuss with no objections raised in a week or so.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-15 06:47:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 06:47:28-07:00",
    "text": "lease be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. Is something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can optiin or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-15 06:48:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 06:47:59-07:00",
    "text": "Please be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. Is something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can optiin or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-15 06:51:55-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-06-15 06:48:29-07:00",
    "text": "Please be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. If something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can optiin or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-07-08 06:54:46-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 06:51:55-07:00",
    "text": "Please be aware that this document is far outside my area of expertise, and my comments might make no sense. Please do not be nervous to tell me I am wrong - likely I am.... #1 \u00a0  [VVC] is particularly vulnerable to such \u00a0  attacks, as it is extremely simple to generate datagrams containing \u00a0  NAL units that affect the decoding process of many future NAL units. \u00a0  Therefore, the usage of data origin authentication and data integrity \u00a0  protection of at least the RTP packet is RECOMMENDED, for example, \u00a0  with SRTP [ RFC3711 ]. If something is \"particularly vulnerable\", why is its security counter measures only RECOMMENDED instead of REQUIRED ? Is there a real world use case where this vulnerable protocol should continue despite the threat without these counter measures? #2 Media-Aware Network Element (MANE) are briefly mentioned in the Security Considerations, but it is unclear to me how a user can opt-in or opt-out of using these or how it could even evaluate a MANE for trustworthiness. Does a user even know if there is a MANE ? And especially combining the two issues, if a MANE can rewrite the SEI, would it not mean that it could attack a user with malicious data that appear trusted? #3 In the IANA Considerations, it points to another section. It is customary to just make this section stand on its own with clear and explicit instructions for IANA so they do not need to read or understand large parts of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-08-18 01:43:12-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-16 05:59:37-07:00",
    "text": "I would like discuss if this specification should be making stronger statement to enforce the reinterpretation the SDP Offer/Answer model for parameters sprop-max-don-diff and sprop-depack-buf-bytes. In section 7.3.2.3, it says sprop-max-don-diff and sprop-depack-buf-bytes parameter should be interpreted differently than usual interpretation of the parameters according to  RFC 3264 . This is a significant change and kind of easy to miss. This section does not use any normative text to enforce the change either.\u00a0  I am also supporting Francesca's discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-20 10:44:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 21:22:10-08:00",
    "text": "I have a very boring Discuss point and a somewhat boring point, and expect to change my ballot to Yes once they're resolved. In Section 3.2 we say that pacing mechanisms \"MAY\" be used to avoid bursts when the CMD is fanning out PBUs, but in Section 6 we say that pacing \"SHOULD\" be used; please resolve the inconsistency (preferrably with \"MUST\" as Mirja requests). Please also include some discussion of privacy considerations (I give some suggestions in the COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-03-08 14:31:21-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 12:54:31-08:00",
    "text": "Thank you for the work put into this document. And congratulations for the many advanced ASCII art ! Except for section 3.6, the text is really easy to read. I have a block DISCUSS below but it should be trivial to fix. Please also address the points raised by Carlos during the INT directorate review. Thank you again Carlos ! https://datatracker.ietf.org/doc/review-ietf-dmm-pmipv6-dlif-05-intdir-telechat-pignataro-2020-02-28/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.3 & 4.4 & 4.5 -- Probably trivial to fix but is \"Prefix Length\" expressed in bits (/64) or in bytes (8 bytes). If the latter, then how can we have a prefix of /57 ? The definition of the \"Prefix length\" field should be specific about the unit (bits/bytes) and be aligned with the definition of \"Anchored prefix\" (as this one seems to assert that the prefix length must be a multiple of 8).",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-28 09:06:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-28 09:05:48-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message send by the P/S-MAAR in other modes.  Finally on in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-28 09:06:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-28 09:06:06-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message send by the P/S-MAAR in other modes.  Finally in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-02 02:11:12-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-28 09:06:20-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message sent by the P/S-MAAR in other modes.  Finally in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-19 02:47:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 02:11:12-08:00",
    "text": "Sec 3.2: \"The INITIAL_BINDACK_TIMEOUT [ RFC6275 ] SHOULD \u00a0  be used for configuring the retransmission timer.\" Use of this timeout from  RFC6275  is fine. However, you should also indicate that the rest of the specified retransmission mechanism should be used as well. That means exponential backoff as well as a max number of retries. Further I think it would also be important to overall rate-limit the traffic e.g. as specified in  RFC6275 : \"The mobile node MUST NOT send Mobility Header messages \u00a0  of a particular type to a particular correspondent node more than \u00a0  MAX_UPDATE_RATE times within a second.\" In addition the same mechanisms should probably be also required for any (new) message sent by the P/S-MAAR in other modes.  Finally in the security consideration section I see this: \"The CMD SHOULD use a pacing approach to limit \u00a0  this amplification risk.\" Which is good! But why is that a SHOULD and not a MUST? Update: This discuss is inline with the comments provided by the TSV-ART review (thanks J\u00f6rg!) which lead to an update that don't seem fully addressed. So please review that feedback as well and continue discussion with the TSV-ART reviewer if needed.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-09-10 11:32:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-03 20:55:54-07:00",
    "text": "This should be a very easy discussion to have and to resolve: \u2014 Section 2.1 \u2014 \u00a0  The OCSP \u00a0  clients SHOULD use a length of 32 octets for the Nonce extension. \u00a0  The minimum nonce length of 1 octet is defined to provide the \u00a0  backward compatibility with older clients following [ RFC6960 ] \u00a0  however, the newer OCSP clients MUST use a length of at least 16 \u00a0  octets for Nonce extension. I\u2019m puzzled by this, so please explain: as long as we\u2019re talking about new clients, developed with this document in place, why shouldn\u2019t it be a MUST to use 32 octets?\u00a0 Why would a new client use 16 bits, rather than 32, and what are the considerations that the coder would need to understand in making that decision?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-11 00:52:39-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-30 05:27:11-07:00",
    "text": "# GEN AD review of  draft-ietf-lsr-pce-discovery-security-support-11 CC @larseggert ## Discuss ### Section 4, paragraph 3 ``` \u00a0 \u00a0  Section 4 of [ RFC5088 ] states that no new sub-TLVs will be added to \u00a0 \u00a0  the PCED TLV, and no new PCE information will be carried in the \u00a0 \u00a0  Router Information LSA.\u00a0 This document updates [ RFC5088 ] by allowing \u00a0 \u00a0  the two sub-TLVs defined in this document to be carried in the PCED \u00a0 \u00a0  TLV advertised in the Router Information LSA. \u00a0 \u00a0  Section 4 of [ RFC5089 ] states that no new sub-TLVs will be added to \u00a0 \u00a0  the PCED TLV, and no new PCE information will be carried in the \u00a0 \u00a0  Router CAPABLITY TLV.\u00a0 This document updates [ RFC5089 ] by allowing \u00a0 \u00a0  the two sub-TLVs defined in this document to be carried in the PCED \u00a0 \u00a0  TLV advertised in the Router CAPABILITY TLV. \u00a0 \u00a0  This introduction of additional sub-TLVs should be viewed as an \u00a0 \u00a0  exception to the [ RFC5088 ][ RFC5089 ] policy, justified by the \u00a0 \u00a0  requirement to discover the PCEP security support prior to \u00a0 \u00a0  establishing a PCEP session.\u00a0 The restrictions defined in \u00a0 \u00a0  [ RFC5089 ][ RFC5089 ] should still be considered to be in place. ``` (This is mostly for discussion on the telechat, and I expect to clear during the call.) Why were 5088/89 so strict on not allowing new sub-TLVs? This seems quite unusual for IETF specs. I'm not arguing that this document can't update those earlier RFCs to allow these new sub-TLVs, but it seems odd to do so and in the same sentence say \"the restrictions should still be considered in place.\" ### Section 8.2, paragraph 1 ``` \u00a0 \u00a0  The PCED sub-TLVs were defined in [ RFC5088 ] and [ RFC5089 ], but they \u00a0 \u00a0  did not create a registry for it.\u00a0 This document requests IANA to \u00a0 \u00a0  create a new registry called \"PCED sub-TLV type indicators\" under the \u00a0 \u00a0  \"Interior Gateway Protocol (IGP) Parameters\" grouping.\u00a0 The \u00a0 \u00a0  registration policy for this registry is \"IETF Review\" [ RFC8126 ]. \u00a0 \u00a0  Values in this registry come from the range 0-65535. ``` Should the registration policy not be stricter (e.g., Standards Action?) given that 5088/89 didn't even allow any new values?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-10-10 12:19:03-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-10 09:26:00-07:00",
    "text": "This should be simple to resolve, but it has to be clarified: The shepherd writeup says there were IPR claims made about the document.\u00a0 The question also asks for a summary of the resulting discussion, but the shepherd writeup doesn't provide one.\u00a0 Can we confirm that the discussion was had, or some other answer to the question can be provided?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-10-13 03:47:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-04 09:47:50-07:00",
    "text": "Hi, Sorry for the discuss, but I find a couple of specification aspects of this draft to be unclear enough that I think that they probably warrant a discuss, hopefully easy to explain or resolve: In section 3.2, it wasn't clear to me exactly where I find what the Key-Id is.\u00a0 I suspect that this is probably referring to \"KeyId\" in  rfc5925 .\u00a0 If so, I think that would be emphasizing. In section 3.3, it wasn't clear to me what the Key chain name is, or what exactly it refers to.\u00a0 Is this referring to a local key-chain name installed in a YANG Keystore (given that there is a reference to  RFC8177 ) or something else.\u00a0 Either way, I think that expanding on the description here would probably be very beneficial.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-10-07 14:32:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 13:11:18-07:00",
    "text": "\u00a78.7: \"it is possible that Flow Specifications will be distributed by BGP as well as by PCEP as described in this document...implementations MAY provide a configuration control to allow one protocol to take precedence over the other as this may be particularly useful if the Flow Specification make identical matches on traffic but have different actions.\" I understand the need to allow one protocol to take precedence over the other. The concern I have is that in BGP's distribution model FlowSpecs are forwarded to other BGP speakers...which may not also be PCCs.\u00a0 If PCEP takes precedence, and the actions are different, then there might be nodes that take the BGP-defined action when not intended to...potentially resulting in unexpected forwarding or rate-limiting of the traffic. Clearly, this issue is related to the different distribution models for the information.\u00a0 If the operator took care of using BGP to distribute FlowSpecs to only the PCCs, then this issue wouldn't exist.\u00a0 I would like to see some text that provides guidance when using both distribution mechanisms.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-29 17:57:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-25 13:31:02-07:00",
    "text": "As with the others, I also found this document to be quite easy to read and well-structured; thank you!\u00a0 I just have a couple points I'd like to discuss, but I am not pressing for a specific resolution and expect to change to No Objection once the discussion has occurred (whatever the conclusion is). This is a Discuss because I want to have a discussion, not because I'm confident in the correctness of my position.\u00a0 But it seems like the ambiguity about when multiple flow specifications in single FLOWSPEC object are treated as logical AND to narrow a single flow specification versus treated as separate flow specifications per Section 8.4 could lead to confusion, and it would be simpler and have less risk to stick to the \"one flow specification per FLOWSPEC object\" model as discussed in the rest of the document.\u00a0 If the ability to define multiple flows within a single FLOWSPEC object is retained, I think we need more specific procedures for identifying when that is the case, quite possibly with a specific enumeration of cases. I also mention in the per-section comments several places where (IIUC) there seems to be a need to match the Speaker Entity Identifier TLV as well as the FS-ID value.\u00a0 It might even be an exhaustive list, but please do a pass to check.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-05 14:41:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 14:34:23-08:00",
    "text": "Thank you for the work on this document. Many thanks to Thomas Fossati for his in-depth review:  https://mailarchive.ietf.org/arch/msg/art/MKG2Cdin96WLcksnA6nAu6pvThM/  , and thanks to the authors for addressing it. I have two comments that need to be addressed before publication. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0 \u00a0  data:\u00a0  }, \u00a0 \u00a0  data:\u00a0  { \"op\": \"add\", \u00a0 \u00a0  data:\u00a0 \u00a0  \"/cdni-advertisement/capabilities-with-footprints \u00a0 \u00a0  /0/footprints/0/footprint-value/-\", \u00a0 \u00a0  data:\u00a0 \u00a0  \"value\": \"192.0.2.0/24\" \u00a0 \u00a0  data:\u00a0  } \u00a0 \u00a0  data: ] FP: JSON doesn't validate. The key \"path\": is missing. 2. ----- Media type registration FP: I haven't seen the media type registrations being reviewed by the media-type mailing list, as requested by  RFC 6838 . Before progressing the document, I would really appreciate the authors to post the registrations to the media-type mailing list for review. Note that people there might also weigh in to the point Thomas made about the media type name, and if it's worth specifying a more detailed media type name, or not in this case.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-17 07:09:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-05 14:41:40-08:00",
    "text": "Thank you for the work on this document, and for partly addressing my previous DISCUSS. Many thanks to Thomas Fossati for his in-depth review:  https://mailarchive.ietf.org/arch/msg/art/MKG2Cdin96WLcksnA6nAu6pvThM/  , and thanks Alexey Melnikov for his media-types review. I will keep this DISCUSS while waiting for the update making the changes discussed with Alexey:  https://mailarchive.ietf.org/arch/msg/media-types/GhN8V1BqwcC4fEThhSRpCcn48gI/ Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-25 05:19:59-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-17 07:09:40-08:00",
    "text": "Thank you for the work on this document, and for partly addressing my previous DISCUSS. Many thanks to Thomas Fossati for his in-depth review:  https://mailarchive.ietf.org/arch/msg/art/MKG2Cdin96WLcksnA6nAu6pvThM/  , and to Alexey Melnikov for his media-types review:  https://mailarchive.ietf.org/arch/msg/media-types/uGakYYYPVjBEwei9isTaluPwhDE/ . Only 2 small changes noted by Alexey are still missing - quoting the relevant text in his mail  https://mailarchive.ietf.org/arch/msg/media-types/LU4gHAY4fQZ6vK7rh8pdSfDwTO0/: 1. >>\u00a0 \u00a0  Also when you split the registration template into 2 it would be \u00a0  >>\u00a0 \u00a0  good to have a sentence here explaining how the two formats differ. > > > Thanks for the suggestion. Could you kindly give us some further  > examples about what should be explained? Do we need to explain the  > different cases where the two subtypes should be used, or just explain  > the difference between the two registration forms? The former. If I as an implementor read the registration, I need to  decide whether or not I should implement processing of this particular  media type. 2. I've just realized that you are also missing \"Fragment identifier  considerations:\" field after this one. (See  RFC 6838 ) Having it as \"N/A\"  is fine. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-05 13:30:45-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:42:11-08:00",
    "text": "The security consideration is silent on how to handle client (uCDN) authentication for this specific CDN use case.\u00a0 Hence, the default guidance from Section 15.13.2 of  RFC7285  seems to apply -- that HTTP Digest Authentication or TLS client authentication could be used. If I understand the use case right, it seems like the uCDNs and dCDNs should know about each other, and there wouldn\u2019t be an unreasonably large number of them to prevent credentials existing for peers.\u00a0 Is there a reason why there isn\u2019t a normative guidance requiring some kind of peer authentication given this narrow use case?\u00a0 If not, why is ok given the significance of this ALTO data in FCI model.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-06-05 03:42:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-01 00:46:50-07:00",
    "text": "This is generally a well written document, but I have a couple of very small points that need to be fixed: Abstract: I have no CLUE what you are talking about. Abstracts should be self contained, i.e. being understandable on its own. The Introduction section has more relevant text which you might want to copy here. In 11.13: you need to have a Normative Reference to the language tag document here ( RFC 5646 ) when you describe the \"lang\" attribute.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-06-05 03:52:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-06-05 03:42:37-07:00",
    "text": "Thank you for updating the document. However one of the changes looks incorrect to me: You incorrectly using  RFC 2119  as a reference for language tags instead of  RFC 5646 . In 11.13: you need to have a Normative Reference to the language tag document here ( RFC 5646 ) when you describe the \"lang\" attribute.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2016-08-15 08:25:53-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-05 03:52:32-07:00",
    "text": "Thank you for updating the document. However one of the changes looks incorrect to me: You incorrectly using  RFC 2119  as a reference for language tags instead of  RFC 5646 . The following changes will address my concern: In 11.3 replace: OLD: \u00a0 Such an attribute is compliant with [ RFC2119 ]. NEW: \u00a0 Such an attribute is compliant with the Language-Tag ABNF production from [ RFC5646 ]. In 11.5 replace: OLD: \u00a0 Each such element has to be compliant with [ RFC2119 ]. NEW: \u00a0 Each such element has to be compliant with the Language-Tag ABNF production from [ RFC5646 ].",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2016-06-01 10:40:04-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-01 07:22:24-07:00",
    "text": "- 11.2: I would like to discuss whether it's a good idea to allow arbitrary values for mediaType, beyond those types registered in IANA. The text seem to encourage proprietary values. Did the working group consider requiring IANA registration of some sort for new values?",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2016-06-08 08:31:24-07:00",
    "end_reason": "position_updated",
    "start": "2016-05-31 14:37:56-07:00",
    "text": "The document looks good, I just have a couple of items on the security considerations to discuss as they are not mentioned and I'm not sure if they have a good reason to be excluded. 1. Session encryption to prevent active (tampering) or passive (information gathering for example) attacks.\u00a0 Integrity protection and authentication are mentioned, but without looking through a few documents, I don't know if that means encryption or some hash value comparisons or something else.  2. Schema drafts tend to cover the need for well-formed schemas as part of the security considerations.\u00a0 Can you add something in about that (not much is required, but it's good for implementers to know this is important)?\u00a0 You can see two recent examples for guidance: YANG -  https://datatracker.ietf.org/doc/draft-ietf-netmod-rfc6020bis/ IODEF -  https://datatracker.ietf.org/doc/draft-ietf-mile-rfc5070-bis/",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-06-01 14:34:16-07:00",
    "end_reason": "position_updated",
    "start": "2016-06-01 12:32:19-07:00",
    "text": "There may be no change needed here, but I want to check. This draft defines no security mechanisms and doens't say how to interoperably use any security mechanisms. For example, I don't understand how one might (interoperably) do RBAC or other \"advanced\" security mechanisms that are promised in other CLUE documents. [1] Even worse, I don't get how one could e.g. use XMLENC to encrypt parts of the schema here, as that'd (I think) almost certainty have to have been considered in the design of this schema, but there's no evidence of that. That seems to end up meaning that the only security mechanisms that one can use with CLUE and for which one can currently achieve interop are transport security mechanisms. That all seems to conflict with text in the security consideration of the CLUE protocol draft. So my question to discuss is: other than transport security, what interoperable security mechanisms are expected to be defined in CLUE, and where might I find descriptions of those?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-04-14 06:56:57-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-11 04:28:48-07:00",
    "text": "Thank you for the work put into this document. I *really* find the idea and the protocol interesting and useful. The text is also easy to read and to understand (albeit underspecified in some cases -- hence my DISCUSS). Please find below some blocking DISCUSS points (easy to address by adding some text), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Chris Wood for the shepherd's detailed write-up including the WG consensus *but* it lacks the justification of the intended status.  Other thanks to Tim Winters, the Internet directorate reviewer (at my request): https://datatracker.ietf.org/doc/review-ietf-masque-connect-ip-09-intdir-telechat-winters-2023-04-07/  (and I have read the email exchange, thanks to all) I hope that this review helps to improve the document, Regards, -\u00e9ric # DISCUSS (blocking) As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 8 Several parts of this section are unspecified, see below. `Note that ICMP messages can originate from a source address different from that of the IP proxying peer.` is of course obvious, but I think that this case (ICMP originating from the global Internet to the proxy client) deserves a section on its own. Notably whether this source must be within the target ? The source address to be used by the proxy when originating an ICMP should also be specified, even if just a reference to  RFC 6724  for IPv6. ## Section 9.2 In the example where the IP proxy has an IP address in the same prefix as the legacy client (there is no on-link / off-link state for IPv4 as opposed to IPv6), the encapsulation behavior of section 7 requires the TTL to be decremented before entering the tunnel, which is really wrong as it this case it is not formally a routing to a different prefix and some protocols may expect TTL=255, which won't be the case. Request to add some text about this \"issue\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 14:22:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-10 17:22:08-07:00",
    "text": "Thank you for this document; it has been a long time coming and is much awaited.\u00a0 That said, I have a few points I'd like to discuss before I can comfortably ballot Yes: I'm happy to see prominent references to RFCs 7525 and 6125. Unfortunately, merely citing  RFC 6125  does not provide a usable specification for an application to implement; we need to additionally state what type of name (e.g., SRV-ID or DNS-ID) is used as input to the validation process and how the application obtains that name.\u00a0 Given that we are defining a service name (and port number) for ntske, SRV-ID might be appropriate (DNS-ID is the most common form I see consumers of  RFC 6125  using). In a related vein, if ALPN is necessary for confirming ntske operation, it's not entirely clear to me that a dedicated port (in addition to service name) is required, and  RFC 6335  discourages fixed port numbera llocations.\u00a0 Perhaps it's not intended that DNS-SD is used to discover NTS-KE servers, though -- there's no reference to  RFC 6763  in this document, or other discussion of server discovery that I can see. We seem to be internally inconsistent about whether the Cookie extension can be encrypted -- Section 5.7 says \"MUST NOT be encrypted\", but Section 5.2 implies that it could be encrypted: \u00a0  Always included among the authenticated or authenticated-and- \u00a0  encrypted extension fields are a cookie extension field and a unique \u00a0  identifier extension field.\u00a0 [...] Section 7.6 says that applications for new record types need to specify the contents of the \"Set Critical Bit\" field, but this field is not included in the table of initial entries.\u00a0 Additionally, there doesn't seem to be a clear description of what the semantics of the \"Set Critical Bit\" field should be.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-22 16:01:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-19 14:22:59-07:00",
    "text": "[updated for -25] Thank you for this document; it has been a long time coming and is much awaited.\u00a0 That said, I have a few points I'd like to discuss before I can comfortably ballot Yes: I'm happy to see prominent references to RFCs 7525 and 6125. Unfortunately, merely citing  RFC 6125  does not provide a usable specification for an application to implement; we need to additionally state what type of name (e.g., SRV-ID or DNS-ID) is used as input to the validation process and how the application obtains that name.\u00a0 Given that we are defining a service name (and port number) for ntske, SRV-ID might be appropriate (DNS-ID is the most common form I see consumers of  RFC 6125  using).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-20 03:28:34-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-18 07:24:58-07:00",
    "text": "Two issues I would like to discucss: 4.1.7.\u00a0 NTPv4 Server Negotiation The \u00a0  contents of the string SHALL be either an IPv4 address, an IPv6 \u00a0  address, or a fully qualified domain name (FQDN). The client MUST NOT send more than one \u00a0  record of this type. I get there are assumptions about which address family to use for this record. Is it assumed that one the KE server will chose what address family the clien'ts request is coming in over? Do there need to be more discussion of this assumption in the document? For example an client indication of an IPv4 address can the server respond with an IPv6? And maybe even more relevant, what if the client has included an IPv6 address in the field in the request, even if the connection to the KE is over IPv4. I would appreciate some clarification or recommendation on how to select what family to use so that the protocol achieve the least amount of surprise here.  Secondly, I struggle to full understand the implementation requirements of the replay protection.  5.7:  \u00a0 \u00a0 \u00a0 Exactly one Unique Identifier extension field which MUST be \u00a0 \u00a0 \u00a0 authenticated, MUST NOT be encrypted, and whose contents MUST NOT \u00a0 \u00a0 \u00a0 duplicate those of any previous request. Is the last \"MUST NOT\" really a MUST NOT in the most strict sense? It could require a client to keep a history of all used Unique Identifiers since it started. I think that would be a significant state management task for the client. I would expect that a client could work well with a window of N packets, where N is in the range hundreds to thousands and using a RNG for the Unique Id field. By tracking requests sent, their timestamp and Unique Id the client wouldn't the client be able to protect against replays? Discard any unknown unique IDs, discard any second reception of Unique IDs. This also depends on that replay packets outside of the window can be detected even if the RNG generated a duplicate ID. I assume so is possible based on that the NTP timestamps that are authenticated will be outside of the window of what is acceptable and not match the request.  To summarize can we get some more clarity on how the client process of replay protection.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-24 11:17:18-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-19 06:10:07-07:00",
    "text": "Two rather small and hopefully quick-to-address points that I think must be clarified before publication of this spec: 1) Sec 5.7: \"In that \u00a0  case, it MUST be able to detect and stop looping between the NTS-KE \u00a0  and NTP servers by rate limiting the retries using e.g. exponential \u00a0  retry intervals.\" Yes, rate limiting and exponential back-off is good here. However, you anyway need to define a maximum number of retries (to actually make it stop at some point) and further given some recommendation for an appropriate rate limit (e.g. initial retry after 3 seconds...?). 2) Sec 4.1.3: \"\u00a0 \u00a0 \u00a0 Error code 2 means \"Internal Server Error\".\u00a0 The server MUST \u00a0 \u00a0 \u00a0 respond with this error if it is unable to respond properly due to \u00a0 \u00a0 \u00a0 an internal condition.\" At least for this error, I think you need to specify what the client should do on reception. Retry? Immediately? How often? Or wait for a while?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-25 16:00:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-21 22:45:38-07:00",
    "text": "(1) Can we check whether it's okay to use the yang \"string\" type for raw cryptographic keys (e.g., ospfv2-key, ospfv3-key)?\u00a0 My understanding was that yang strings were limited to human-readable, but that the crypto keys could be raw binary values. (2) Do we need to say anything about how to indicate when there are discontinuities for the various \"counter\" types?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-26 08:07:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-25 16:00:09-07:00",
    "text": "[\"string\" type for raw keys is intentional, and incentive to move to the more modern key-chain model] (2) Do we need to say anything about how to indicate when there are discontinuities for the various \"counter\" types?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-26 13:03:38-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-20 10:58:39-07:00",
    "text": "A \u201cdiscuss to discuss\u201d.\u00a0 Per the convention outlined in  https://trac.ietf.org/trac/ops/wiki/yang-security-guidelines , thank you for clearly noting the implication of not securing these nodes properly.\u00a0  Furthermore, following the convention, I would have expected Section 4 to have enumerated the sensitive writeable/creatable/deletable data nodes; and the sensitive readable nodes individually.\u00a0 For a model this large, I can imagine that individual enumeration would be a long list.\u00a0  In the case of read operations, the text opens with saying that \u201csome of the readable data nodes ...\u201d and later says \u201cThe exposure of the ... LSDB will expose the detailed topology ...\u201d.\u00a0 Can you help me understand which part of ietf-ospf.yang is the LSDB and which parts refer to \u201csome of the readable nodes\u201d?\u00a0 Is there are a difference, or is this text asserting that all parts of the modules are sensitive and need access control?\u00a0  A related line of questioning for the write operation.\u00a0 The text opens with saying that \u201cThere are a number of data nodes defined in ietf-ospf.yang ... [and that] [w]rite operations ... to these nodes without proper protection can have a negative effect on the network operations ... [and] ... the ability to modify OSPF configuration ...\u201d is problematic.\u00a0 Can you help me understand which parts of the text is the \u201cOSPF configuration\u201d vs. \u201cthere are number of data nodes ...\u201d?\u00a0 If there isn\u2019t a different, is the text asserting that all parts of the modules are sensitive and need access control?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-05-10 11:49:20-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 07:48:59-07:00",
    "text": "Thank you for this document. I think this is an important document which should move forward, but I would like to discuss some points before it does so. These might result in simple clarifications, or might require more discussion, but I do hope they help improve the document. General comments: I found confusing to understand how optional or mandatory is the use of CBOR for profiles of this specification compared to the transport used. I understand the need for flexibility, but maybe it should be clarified the implication of using CoAP (is CBOR mandatory then?) vs HTTP (is CBOR always permitted? How is the encoding in that case? Is the same media type application/ace+cbor used in that case?). Note also that while requests include the content type to use, both in case HTTP or CoAP+CBOR are used, the response don't seem to include this information.  I would like it to be clarified what requirements (or even just recommendations) are there to use CoAP vs HTTP for different legs of the exchange - not necessarily remove the flexibility but to clarify for implementers what can be done and what would be the reasoning to do that: for example if both endpoints support HTTP with the AS, most likely you can have HTTP between C and RS, so does it really make sense to run this instead of OAuth 2.0? Right now all is permitted, but does it all make sense? I feel like this type of considerations are missing. As a note - I am not sure what allowing a different encoding than CBOR for any leg of the exchange adds to the specification - it makes things more confusing, and if needed it could be specified in another document. While going through and thinking about encodings (assuming we keep the doc as is with regards to allowing more than just CBOR), I wondered if it would be better to define a new media type to use when the ACE framework is used with HTTP, to differentiate from OAuth 2.0, since some of the endpoints used are the same (/token and /introspect at the AS). I am interested to hear more from my co-AD as well if this would be an OK use of a new media type - I am thinking of the case where AS is supporting both OAuth 2.0 and the Ace framework - or if it is unnecessary, since the encodings are the same, and the parameters are registered in OAuth 2.0 registry.  More detailed comments below. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-11 00:20:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-05-11 00:17:29-07:00",
    "text": "This one should be easy: Section 6.1: * Why is an Experimental status RFC registering a new header field with \"standard\" status?\u00a0 (See  RFC3864 , Section 4.2.1.)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-05-18 08:26:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-11 00:20:32-07:00",
    "text": "This one should be easy, then I plan to ballot \"Yes\": Section 6.1: * Why is an Experimental status RFC registering a new header field with \"standard\" status?\u00a0 (See  RFC3864 , Section 4.2.1.)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-15 03:36:37-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-20 05:25:30-08:00",
    "text": "The document is generally quite readable, which is great. But I have a few small issues I would like to get clarification on before recommending approval of this document: In 4.1: \u00a0  Message Type: The last byte is used to indicate the type of the \u00a0  EKTField.\u00a0 This MUST be 2 for the FullEKTField format and 0 in \u00a0  ShortEKTField format.\u00a0 Values less than 64 are mandatory to \u00a0  understand while other values are optional to understand. I thought I knew what this meant when I read it, and then I saw this: \u00a0  A receiver \u00a0  SHOULD discard the whole EKTField if it contains any message type \u00a0  value that is less than 64 and that is not understood. \"SHOULD discard ... EKTField\" makes this field NOT mandatory. (If you said \"SHOULD discard the whole packet\", that would have been different.) Also, how \"discard\" different from the following sentence suggesting \"ignore\"? I think you have some inconsistencies/terminology problem here! \u00a0  Message type \u00a0  values that are 64 or greater but not implemented or understood can \u00a0  simply be ignored.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-16 02:20:38-08:00",
    "end_reason": "position_updated",
    "start": "2019-07-15 03:44:36-07:00",
    "text": "ecent ABNF changes (from \"*\" to \"\\*\") made the ABNF invalid.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-02-21 09:17:21-08:00",
    "text": "I'm adding a process discuss to hold things until we get clarity around the IANA expert reviews.  I know Benjamin mentioned this in his DISCUSS; I am duplicating it here in case we clear up the rest of Benjamin's discuss points prior to the IANA questions.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-20 08:33:44-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-19 09:39:57-08:00",
    "text": "[this is a placeholder Discuss\u00a0 to indicate a couple of broad issues early; a full review and ballot position is forthcoming] I think\u00a0 we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection. (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper? I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field.\u00a0 Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-17 13:12:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-20 08:33:44-08:00",
    "text": "I think we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection.\u00a0 (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper? I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field. Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType? I'll also hold a discuss for the IANA NOT OK (I noticed the need for more columns for TLS extension type, at least, and there seems to be more in their review). Please state clearly what the scope of an SPI value (and its binding to EKTKey and\u00a0 other parameters) is; e.g., that it is only defined within a given communications session. Section 4.2.1 \u00a0  Outbound packets SHOULD continue to use the old SRTP Master Key for \u00a0  250 ms after sending any new key.\u00a0 This gives all the receivers in \u00a0  the system time to get the new key before they start receiving media \u00a0  encrypted with the new key. What channel is the \"sending any new key\" to occur on?\u00a0 The most straightforward reading would be in the FullEKTField, but that does not seem to make much sense.\u00a0 (Also, is the \"any new key\" an SRTP master key or an EKTKey?) Section 5's one-paragraph intro doesn't really paint a clear picture for me of why/which DTLS connections are \"secure\" in a way that the central media distribution is not.\u00a0 From reading the whole doc, my perception is that basically this scheme is useful in cases when you have a central hub for DTLS negotiation that's trusted to have access to media plaintext, plus a mesh of SRTP streams (whether centrally mediated or directly connected), and that it's not appropriate when the\u00a0 central hub is not trusted with media access or when there is not a single DTLS party that can distribute the EKT to all (other) participants).\u00a0 Could we get some clear explanation of where this technique is and is not expected to be utilized? Section 5.5.2 has: \u00a0  Note: To be clear, EKT can be used with versions of DTLS prior to \u00a0  1.3.\u00a0 The only difference is that in a pre-1.3 TLS stacks will not \u00a0  have built-in support for generating and processing Ack messages. You need to be more clear about the Ack being needed even when pre-1.3 is in use (which would seem to make DLTS 1.3 a normative reference). (See also the COMMENT about citing both DTLS 1.2 and 1.3.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-09-05 16:57:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-17 13:12:07-07:00",
    "text": "Thanks for the updates in the -10; we're\u00a0 making progress.\u00a0 I think there are still some issues left to resolve, though. My previous position had: \"\"\"I think we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection.\u00a0 (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper?\"\"\" I think I remember having such a discussion, but cannot find any record of it.\u00a0 Does anyone have a pointer handy (or a corrective to my memory)? Similarly, I don't remember any discussion on: \"\"\"I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field. Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType?\"\"\" We are also still waiting on IANA, if I understand correctly.\u00a0 I do not see  any indication that the needed expert review for TLS ExtensionType allocation has been requested (the authors should initiate this, per  RFC 8447 ), and there may have been other matters that needed clarification.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-11-19 17:25:22-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-05 16:57:26-07:00",
    "text": "Thanks for the updates in the -10; we're\u00a0 making progress.\u00a0 I think there are still some issues left to resolve, though. My previous position had: \"\"\"I think we need to discuss whether the mechanism described in Section 4.1 contains an EKT-specific extension mechanism or is in fact a more general mechanism for including extensions in SRTP packets outside the SRTP cryptographic protection.\u00a0 (If so, we would probably need to Update 3711 to indicate as much, and perhaps allow for multiple extension types to be present adjacently.)\u00a0 In particular, how would this EKT extension interact with any other future mechanism that needs to add data to SRTP\u00a0 packets outside the SRTP cryptographic wrapper?\"\"\" I think I remember having such a discussion, but cannot find any record of it.\u00a0 Does anyone have a pointer handy (or a corrective to my memory)? Similarly, I don't remember any discussion on: \"\"\"I also think we need to discuss whether it is appropriate to set a precedent that any standards-track protocol can get a dedicated TLS HandshakeType (noting that this is a potentially scarce one-octet field. Would it be more appropriate to define a generic \"key transport\" container that can be generally applicable to many protocols, and have an internal extension point that allows for an SRTP+EKT-specific usage within the TLS HandshakeType?\"\"\" [IANA says they're okay now]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-15 11:32:27-08:00",
    "end_reason": "position_updated",
    "start": "2019-11-19 17:25:22-08:00",
    "text": "The -10 introduced text implying that the DTLS 1.3 retransmission rules are normative, that is in conflict with the existing text indicating that DTLS 1.2 retransmission rules are normative (see COMMENT). The DTLS 1.3 Ack message is a dedicated content-type, not a handshake-type. I support Alexey's Discuss about the ABNF breakage. Note that there is a similar issue in the names of the TLS extensions in the IANA considerations -- the names now include \"\\_\" instead of just \"_\".",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-22 01:42:20-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 07:18:15-08:00",
    "text": "I think there are an important discrpency between the figure and the ABNF for the full EKT message in section 4.1: Figure 1:  \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  : \u00a0 \u00a0  :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 EKT Ciphertext\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  : \u00a0 \u00a0  :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  : \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |\u00a0  Security Parameter Index\u00a0 \u00a0 | Length\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |0 0 0 0 0 0 1 0| \u00a0 \u00a0  +-+-+-+-+-+-+-+-+ The ABNF parts that appears relevant:  \u00a0 \u00a0 EKTCiphertext = 1*256BYTE ; EKTEncrypt(EKTKey, EKTPlaintext) \u00a0 \u00a0 Epoch = 2BYTE \u00a0 \u00a0 SPI = 2BYTE \u00a0 \u00a0 FullEKTField = EKTCiphertext SPI Epoch EKTMsgLength EKTMsgTypeFull Note that the above ABNF states that the SPI is followed by a 16-bit Epoch field prior to the length field.  Can you please ensure that this discrepancy is clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-06-16 03:11:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 09:47:14-07:00",
    "text": "This is I think simply a oversight but I am putting a discuss so that this certainly gets addressed before the document proceeds to the next stage. Section 3.2 does not say what happens when the requirements are not met. There must be guidance on what to do in that case like there are in section 3.3, 3.4 an 3.5.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-04-19 05:36:14-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 04:30:50-07:00",
    "text": "Thank you for the work put into this document. This document describes a nice addition to CBOR. Please find below one blocking DISCUSS points (mainly to generate discussion -- I will clear my DISCUSS most probably after discussion), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Christian Ams\u00fcss for the shepherd's write-up even if the justification for the intended status is somehow weak (but at least present).  I hope that this helps to improve the document, Regards, -\u00e9ric As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: Just a normal DISCUSS based on the absence of  BCP14  and any normative language in a standard track document. Explanations from the authors/WG/AD will be more than welcome as I am not convinced by the shepherd's explanation (basically \"let's avoid down ref\").",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-05-06 04:30:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 19:03:00-07:00",
    "text": "Section 2.1. (a) \"In both enveloping methods, CBOR Protocol designers need to obtain a CBOR tag for each kind of object that they might store on disk.\u00a0 ... The IANA policy for 4-byte CBOR Tags is First Come First Served, ...\" (b) \"This tag needs to be allocated by the author of the CBOR Protocol.\" Both of these statements are made in this section and they appear to conflict.\u00a0 (a) appears to be saying that CBOR tags will be allocated from the FCFS IANA registry to the protocol designer.\u00a0 However, later in the section (b) says that the author is allocating the tags.\u00a0 If the author performing the allocation/assignment, it would seem to be coming from the registry per (a).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-06-25 00:25:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-05 23:29:57-07:00",
    "text": "Thank you for the work put into this document. I found the use cases part of section 3.1 very interesting to read even if some of them seem very far fetched ;-) Please find below some blocking DISCUSS points (easy to address though), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to - Carlos Bernardos for the shepherd's write-up even if a justification for the informational status would have been welcome but the WG consensus description is appreciated.  - Pascal Thubert for his IETF last call INT directorate review at:  https://datatracker.ietf.org/doc/review-ietf-ipwave-vehicular-networking-20-intdir-lc-thubert-2021-06-18/  and for his IESG telechat INT directorate review  https://datatracker.ietf.org/doc/review-ietf-ipwave-vehicular-networking-27-intdir-telechat-thubert-2022-02-28/  Pascal's Last Call & telechat reviews were (at least partially) acted upon by Paul ;-) I hope that this helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Abstract & Section 1 \"then enumerates requirements for the extensions of those IPv6 protocols\" does not match any IPWAVE WG work item, i.e., it is outside the scope of the charter of IPWAVE WG. As the document does not explicitly specify requirements, I strongly suggest to use the word \"gaps\" rather than \"requirements\" in the abstract and section 1. ## Section 4.1 Using an IPv6 address out of a ULA prefix still requires DAD. So the text below should be updated to be corrected: \u00a0 \"their own IPv6 Unique Local Addresses \u00a0  (ULAs) [ RFC4193 ] over the wireless network, which does not require \u00a0  the messaging (e.g., Duplicate Address Detection (DAD)) of IPv6 \u00a0  Stateless Address Autoconfiguration (SLAAC) [ RFC4862 ].\" ## Section 4.2 Very similar comment as above (i.e., DAD & MLD must be done for all IPv6 addresses of an interface and not only for the global one): \u00a0 \"... When global IPv6 \u00a0  addresses are used, wireless interface configuration and control \u00a0  overhead for DAD\" ## Section 5.2 \u00a0 \"... If DHCPv6 is used to assign \u00a0  a unique IPv6 address to each vehicle in this shared link, DAD is not \u00a0  required. \" This is incorrect and must be changed (see section 18.2.10.1. of  RFC 8415 )",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-23 09:04:49-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-04-05 20:17:31-07:00",
    "text": "I had difficulty in understanding the bounds for the scope of the use cases and proposed architecture.\u00a0 At times I had trouble understanding what was an example of related work, and what was narrative formally describing the gaps in IPv6 for vehicular networking.\u00a0 In that spirit: ** The Privacy Considerations are under-specified: -- Section 6.3 suggests the needs for logging, \u201cTo deal with this kind of security issue, for monitoring suspicious behaviors, vehicles' communication activities can be recorded in either a central way through a logging server (e.g., TCC) in the vehicular cloud or a distributed way (e.g., blockchain [Bitcoin]) along with other vehicles or infrastructure.\u00a0 To solve the issue ultimately, we need a solution where, without\u00a0 \u00a0 privacy breakage, \u2026\u201d.\u00a0 Some discussion on the \u201cprivacy breakage\u201d is needed.\u00a0 What exactly would be the trade offs between a centralized vs. distributed log?\u00a0 Who would get to see this information?\u00a0 What is sensitive about this information? -- Section 5.1.2 and 6.3 highlights the use of MAC address pseudonyms.\u00a0 This is helpful.\u00a0 More discussion is needed about the associate privacy threat being mitigated.\u00a0 Section 6.3 mentions an \u201cadversary from tracking a vehicle\u201d which I think means a passive observer of the path.\u00a0 However, there are other entities in which ecosystem \u2013 what is the privacy exposure to the TCC, V2I, etc?\u00a0 The opening in Section 6 notes that \u201cvehicles and infrastructure must be authenticated\u201d and those credentials (perhaps bound to even MAC pseudonyms) would also facilitate tracking even given MAC pseudonyms.\u00a0 Section 6.1 explicit comments on using VINs in certificates.\u00a0 Who are the assumed trusted actors? -- Section 3.3 notes a V2P use case where the pedestrian\u2019s smart-phone is sharing unspecified information.\u00a0 Does that include location information?\u00a0 Who gets it?\u00a0 What kind of identifiers are shared? ** Section 4.2 \u00a0  Note that it is dangerous if the \u00a0  internal network of a vehicle is controlled by a malicious party.\u00a0 To \u00a0  minimize this kind of risk, an reinforced identification and \u00a0  verification protocol shall be implemented.  -- What are these dangers? -- What is a \u2018reinforced identification\u2019? -- Who are the parties in this verification protocol?\u00a0 What security properties is this verification providing? ** Section 6. \u00a0  Vehicles and infrastructure must be authenticated in order to \u00a0  participate in vehicular networking.\u00a0  Authenticated with respect to whom? Vehicles to infrastructure and vice-versa?\u00a0 Or to someone else? ** Section 6 makes references to \u201csecure communication\u201d \u2013 what is the expected key management approach and is that in scope? ** The need for safety properties (very helpful) is asserted multiple times but not further discussed in the Security Considerations: -- Section 3:\u00a0  \u00a0 \u00a0 \u00a0  In addition, IPv6 \u00a0 \u00a0 \u00a0 security needs to be extended to support those V2V use cases in a \u00a0 \u00a0 \u00a0 safe, secure, privacy-preserving way. -- Section 3.1:  \u00a0 \u00a0 \u00a0 To support applications of these V2V use cases, the required \u00a0 \u00a0  functions of IPv6 include IPv6-based packet exchange and secure,\u00a0 \u00a0  \u00a0 \u00a0  safe communication between two vehicles.\u00a0  -- Section 3.3: \u00a0  To support applications of these V2X use cases, the required \u00a0  functions of IPv6 include IPv6-based packet exchange, transport-layer \u00a0  session continuity, and secure, safe communication between a vehicle \u00a0  and a pedestrian either directly or indirectly via an IP-RSU.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-11-02 15:42:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-23 09:04:49-07:00",
    "text": "Thanks for all of the changes in -29 to address the DISCUSS points noted for -28.\u00a0 To help us talk these through the remaining issues, I have updated my ballot to remove issues that have already been resolved.\u00a0 I have also provided feedback on the new text in -29 intended to resolve the original DISCUSS points. (1) The Privacy Considerations are under-specified: (1.a) [per -28] Section 6.3 suggests the needs for logging, \u201cTo deal with this kind of security issue, for monitoring suspicious behaviors, vehicles' communication activities can be recorded in either a central way through a logging server (e.g., TCC) in the vehicular cloud or a distributed way (e.g., blockchain [Bitcoin]) along with other vehicles or infrastructure.\u00a0 To solve the issue ultimately, we need a solution where, without\u00a0 \u00a0 privacy breakage, \u2026\u201d.\u00a0 Some discussion on the \u201cprivacy breakage\u201d is needed.\u00a0 What exactly would be the trade offs between a centralized vs. distributed log?\u00a0 Who would get to see this information?\u00a0 What is sensitive about this information? From -29: \u00a0  Alternatively, for \u00a0  completely secure vehicular networks, we shall embrace the concept of \u00a0  \"zero-trust\" for vehicles in which no vehicle is trustable and \u00a0  verifying every message (such as IPv6 control messages including ND, \u00a0  DAD, NUD, and application layer messages) is necessary.\u00a0 In this way, \u00a0  a failure to prevent a cyberattack shall never happen on a vehicular \u00a0  network.\u00a0 Thus, we need to have an efficient zero-trust framework or \u00a0  mechanism for vehicular networks. I\u2019m speculating that the second from last sentence, \u201c[i]n this way, a failure to prevent a cyberattack shall never happen on a vehicular network\u201d was added to partially respond to the above feedback.\u00a0 Saying that an attack will \u201cnever\u201d success due to a zero-trust framework is not plausible.\u00a0 Could this please rephrased. (1.b) [per -28] Section 3.3 notes a V2P use case where the pedestrian\u2019s smart-phone is sharing unspecified information.\u00a0 Does that include location information?\u00a0 Who gets it?\u00a0 What kind of identifiers are shared? Thanks for adding the following text -29: \u00a0  The location information of a VRU from a smart device is multicasted \u00a0  only to the nearby vehicles.\u00a0 The true identifiers of a VRU's \u00a0  smartphone shall be protected, and only the type of the VRU, such as \u00a0  pedestrian, cyclist, and scooter, is disclosed to the nearby \u00a0  vehicles. To clarify, this \u201cmulticasted\u201d in the IPv6 sense?\u00a0 The VRU\u2019s smartphone is using some kind of \u201cfake identifier\u201d (source address?) to announce its presence so as not to reveal its \u201ctrue identifier\u201d?\u00a0 Is there a security consideration (attack) that these \u201cfake identifiers\u201d multicasting to nearby vehicles could convince that vehicle that they are surrounded by pedestrians (e.g., roughly  https://www.abc.net.au/news/2020-02-04/man-creates-fake-traffic-jam-on-google-maps-by-carting-99-phones/11929136)? \u00a0  Can we state the security properties or provide a reference to handle this issue.\u00a0 I see the following text later in the section: \u00a0  To support applications of these V2X use cases, the required \u00a0  functions of IPv6 include IPv6-based packet exchange, transport-layer \u00a0  session continuity, and secure, safe communication between a vehicle \u00a0  and a pedestrian either directly or indirectly via an IP-RSU. I don\u2019t recognize the desired properties of protecting identifiers as being congruent with the above text. (2) Section 4.2 \u00a0  Note that it is dangerous if the \u00a0  internal network of a vehicle is controlled by a malicious party.\u00a0 To \u00a0  minimize this kind of risk, an reinforced identification and \u00a0  verification protocol shall be implemented.  -- [per -28] Who are the parties in this verification protocol?\u00a0 What security properties is this verification providing? [new per -29] Thanks for adding this new text in -29 in response: \u00a0  To minimize this kind of risk, \u00a0  an augmented identification and verification protocol with extra \u00a0  means shall be implemented.\u00a0 These extra means can be certificate- \u00a0  based, biometric, credit-based, and one-time passcode (OTP) \u00a0  approaches in addition to a used approach [ RFC8002 ].\u00a0 The \u00a0  verification shall provide security properties such as \u00a0  confidentiality, integrity, authentication, authorization, and \u00a0  accounting [ RFC7427 ]. I\u2019m having trouble understanding this guidance.\u00a0 The architecture is suggesting \u201caugmented identification and verification with extra means.\u201d\u00a0 I don\u2019t follow what \u201caugmented means\u201d or \u201cextra\u201d -- augmented or extra from what baseline?\u00a0 The security properties this provides is \u201cconfidentiality, integrity, authentication, authorization and accounting\u201d don\u2019t seem to match authentication and identity topics.\u00a0  To the specific examples, how does \u201ccredit-based\u201d provide the stated security properties?\u00a0  I have the same question for the others.  ** [per -28 and same for -29] The need for safety properties (very helpful) is asserted multiple times but not further discussed in the Security Considerations: -- Section 3:\u00a0  \u00a0 \u00a0 \u00a0  In addition, IPv6 \u00a0 \u00a0 \u00a0 security needs to be extended to support those V2V use cases in a \u00a0 \u00a0 \u00a0 safe, secure, privacy-preserving way. -- Section 3.1:  \u00a0 \u00a0 \u00a0 To support applications of these V2V use cases, the required \u00a0 \u00a0  functions of IPv6 include IPv6-based packet exchange and secure,\u00a0 \u00a0  \u00a0 \u00a0  safe communication between two vehicles.\u00a0  -- Section 3.3: \u00a0  To support applications of these V2X use cases, the required \u00a0  functions of IPv6 include IPv6-based packet exchange, transport-layer \u00a0  session continuity, and secure, safe communication between a vehicle \u00a0  and a pedestrian either directly or indirectly via an IP-RSU. The explanation from the authors noted that the following text was added to Section 4.2 -29: \u201cA malicious party can be a group of hackers, a criminal group, and a competitor for industrial espionage or sabotage.\u201d \u201cThe verification shall provide security properties such as confidentiality, integrity, authentication, authorization, and accounting [ RFC7427 ].\u201d I\u2019m having trouble understanding how this text addresses the safety properties.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-16 04:01:58-08:00",
    "end_reason": "position_updated",
    "start": "2020-04-20 14:06:32-07:00",
    "text": "Let's discuss whether the various and sundry conditional SHOULDs in Section 3.1 are better written as conditional MUSTs (i.e., with the listed exclusions being the only allowed exclusion). Also, Appendix A.2 seems to show \"Len (extended)\" as just 0-2 bytes when IIUC it is 0-4 bytes.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-11-05 07:30:09-08:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 22:13:49-07:00",
    "text": "[[ discuss ]] [ section 2.2.2 ] * I agree with Ben's point about MTU.\u00a0 Some text about the implications seems \u00a0 warranted.\u00a0 Even just a link to 7252#4.6 might be fine (and maybe a \u00a0 skull-and-crossbones emoji [\u2620\ufe0f] if they can be included now ;-) * 60 minutes for address changes?\u00a0 Out of curiosity, upon what was this based? \u00a0 I lack a good deal of context, but this kind of feels like the kind of \u00a0 constant that will get baked into code and come to govern some behaviour \u00a0 that later might need updating.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-08-24 06:37:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-22 14:12:24-07:00",
    "text": "(1) [I'm raising this point to be a discussion -- it may not end with changes to the document.] This document recommends that route refresh not be used when inbound policies change at a relatively high rate.\u00a0 ROV validation is \"only\" an example. As Jeff Haas wrote on the idr list [1]: \u00a0  This isn't any different than any other over-aggressive  \u00a0  provisioning tool's impact.\u00a0  Was there any consideration given to making a general recommendation and not just limiting it to ROV?\u00a0 I can see the direct impact on  rfc6811 /rfc8481, and how general BGP advice is out of scope for sidrops.\u00a0 However, I am primarily curious whether there is anything particular to ROV to focus the recommendation this way.\u00a0 I couldn't find a related discussion (beyond Jeff's message) in the archive, but I may have missed it. [1]  https://mailarchive.ietf.org/arch/msg/idr/F3w0RDyv9dK4w15fzuDZx3P4Jw0 (2) I have a couple of issues with this paragraph from \u00a74.\u00a0 Addressing them should be relatively easy: \u00a0  When RPKI data cause one or more paths to be dropped due to ROV, \u00a0  those paths MUST NOT be evaluated for best path, but MUST be saved \u00a0  (either separately or marked) so they may be reevaluated with respect \u00a0  to new RPKI data. (2a) \"paths to be dropped due to ROV, those paths MUST NOT be evaluated for best path\" Neither  rfc6811  nor  rfc8481  require that routes be \"dropped due to ROV\".\u00a0  rfc8481  requires that \"Absent specific operator configuration, policy MUST NOT be applied.\" Please clarify that the trigger above (\"dropped due to ROV\") is defined by the operator and is not just a result of ROV. (b) \"MUST be saved (either separately or marked)\" For a required action, the description is not clear.\u00a0 For starters, \"marked\" how?\u00a0 Separately where? From \u00a71.1/rfc4271: \u00a0  The Adj-RIBs-In contains unprocessed routing information that has \u00a0  been advertised to the local BGP speaker by its peers. The RIB structures in  rfc4271  are conceptual -- but since this document requires keeping information (presumably in the Adj-RIB-In), please be more specific about where and marked how. (3) The following requirement from \u00a75 is outside the scope of this document: \u00a0  If the BGP speaker has insufficient resources to support either of \u00a0  the two proposed options, it MUST NOT be used for Route Origin \u00a0  Validation.\u00a0 I.e. the knob in Section 4 should only be used in very \u00a0  well known and controlled circumstances. Requiring a node not to be used for ROV is a powerful statement.\u00a0 It basically invalidates the base operation specified on  rfc6811 /rfc8481 by always requiring the mechanism in this document.\u00a0 While I understand the potential resource demands, selecting a node to perform a specific operation in a particular operator's network is outside the scope of this document. Instead, I would like to see guidance to the operator to consider not using the specific piece of equipment to perform a particular function.\u00a0 This can be as easy as: \u00a0 \u00a0 If the BGP speaker has insufficient resources to support either  \u00a0 \u00a0 of the two proposed options, the operator is strongly encouraged  \u00a0 \u00a0 to consider an alternate piece of equipment to perform Route Origin  \u00a0 \u00a0 Validation. The second part of the sentence (\"I.e. ...\") sounds like a better recommendation -- and, clearly, not the same as \"MUST NOT be used\".",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-09-08 03:35:58-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 06:22:15-07:00",
    "text": "Hi Authors, Thanks for the document, for the most part I find it clear and easy to understand. I however would like to discuss the following:  If the BGP speaker's equipment has insufficient resources to support \u00a0  either of the two proposed options, it MUST NOT be used for Route \u00a0  Origin Validation.\u00a0 The equipment should either be replaced with \u00a0  capable equipment or ROV not used.\u00a0 I.e. the knob in Section 4 should \u00a0  only be used in very well known and controlled circumstances. My concerns with this are two fold - firstly - it's entirely unclear what is meant by \"well known and controlled circumstances\". More importantly, I'm concerned that this paragraph as written could lead to a situation that where people read this as \"if you can't support this behavior - forget BGP security\" - and that I would think would be a more dangerous situation than the route refresh behavior. I'd be happier if we could  a.) Either say that operators should plan for upgrades - but turn off RPKI in the meantime or b.) Change the wording such that it says something along the lines of \"it MUST not be used for ROV without the informed consent of the peers\" - meaning that peer that takes the brunt of the refreshes has to consent explicitly. Either option prevents the position where operators running smaller older hardware are handed an excuse to forgo RPKI entirely - or to turn it off - because in my experience once someone turns something off, getting them to turn it back on again, can be a tricky proposition. Let's discuss! Thanks Andrew",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-24 13:46:54-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-24 13:45:40-07:00",
    "text": "I'm strongly in favor of this work and glad to see it here.\u00a0 I do want to DISCUSS Section 4, though.\u00a0 I apologize for not having reviewed and commented on this section before now. My concern can be summed up as, some of the language of Section 4 while well-intentioned, can mislead the reader into thinking it's fine to continue sending Route Refreshes after all.\u00a0 If you could see your way clear to taking a swing at reorganizing it to  mitigate that, it would be great.\u00a0 The most notable example of a place where the reader could be misled is the third paragraph, which has the clause \"... MUST issue a route refresh\".\u00a0 I think  you are probably meaning to say that such a route refresh would be a natural consequence of not following this spec (and not saving the ineligible routes) -- but by using the 2119 keyword you  create a different expectation. Please let me know if you want to talk this through in more detail.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-08-24 14:07:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 13:46:54-07:00",
    "text": "I'm strongly in favor of this work and glad to see it here.\u00a0 I do want to DISCUSS Section 4, though.\u00a0 I apologize for not having reviewed and commented on this section before now. My concern can be summed up as, some of the language of Section 4 while well-intentioned, can mislead the reader into thinking it's fine to continue sending Route Refreshes after all.\u00a0 If you could take a swing at reorganizing it to mitigate that, it would be great. The most notable example of a place where the reader could be misled is the third paragraph, which has the clause \"... MUST issue a route refresh\".\u00a0 I think you are probably meaning to say that such a route refresh would be a natural consequence of not following this spec (and not saving the ineligible routes) -- but by using the 2119 keyword you create a different expectation. Please let me know if you want to talk this through in more detail.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-24 07:02:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 03:31:26-07:00",
    "text": "# GEN AD review of  draft-ietf-sidrops-rov-no-rr-03 CC @larseggert Thanks to Paul Kyzivat for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/Qhb_8-Kc5e5QEE47En6NhULHnjI ). ## Discuss ### Unclear RFC status ``` \u00a0 Intended status: Standards Track\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Arrcus, Inc. ``` The datatracker metadata for this document indicated a intended status of \"Internet Standard\". I assume this is incorrect and needs to be changed (probably to \"Proposed Standard\".)",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-08-25 07:48:43-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 23:30:21-07:00",
    "text": "This should be easy to resolve, but it's a necessary process check:\u00a0 The shepherd writeup says this is going for Internet Standard status, but the other metadata and the document itself seems to be set for Proposed Standard.\u00a0 Which is right?\u00a0 I believe there are other incantations that have to be done if the former is true.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-20 08:05:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 12:35:27-07:00",
    "text": "Section 8.2.8: \"In the RFC specifications that register new values for SDP \"media\", \u00a0  \"proto\", \"fmt\", \"bwtype\", \"nettype\", and \"addrtype\" parameters, the \u00a0  authors MUST include the following information for IANA to place in \u00a0  the appropriate registry:\" It doesn't look like all the fields that are listed after this text actually appear in the registries. For some of these I don't see why the information would be put into the registries (e.g., contact name, contact email address, since those appear in the RFCs themselves). I think this needs to be clarified.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-24 05:43:10-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 03:47:37-07:00",
    "text": "I'll raise Martin's comment to DISCUSS level: OLD \u00a0  decimal-uchar =\u00a0 \u00a0 \u00a0  DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / POS-DIGIT DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"1\" 2*(DIGIT)) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") DIGIT) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" \"5\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\")) NEW \u00a0  decimal-uchar =\u00a0 \u00a0 \u00a0  DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / POS-DIGIT DIGIT \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"1\" 2(DIGIT)) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\") DIGIT) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / (\"2\" \"5\" (\"0\"/\"1\"/\"2\"/\"3\"/\"4\"/\"5\")) END Is there a reason NOT to make this change, or was it just overlooked?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-19 07:53:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 11:31:43-07:00",
    "text": "I\u2019d like to escalate Alissa\u2019s point about the k= language in Section 7 (Security Considerations).\u00a0 It looks like the new Section 5.12 removes all of the historical language beyond saying it MUST NOT be used.\u00a0 This approach makes sense to me.\u00a0 However, the language in Section 7 could be read as conflicting with that.\u00a0 Specifically: \u00a0  Use of the \"k=\" line poses a significant security risk, since it \u00a0  conveys session encryption keys in the clear.\u00a0 SDP MUST NOT be used \u00a0  to convey keying material, unless it can be guaranteed that the \u00a0  channel over which the SDP is delivered is both private and \u00a0  authenticated. \u00a0  ... \u00a0  The \"k=\" line MUST \u00a0  NOT be used, as discussed in Section 5.12. The first sentence makes a strong statement.\u00a0 The first clause of the second sentence makes a more generic MUST NOT statement but the second clause seems to say that is acceptable under certain circumstances.\u00a0 The third sentence reiterates that k= MUST NOT be used.\u00a0 How should this be reconciled?\u00a0 Is the text suggesting that conveying keying materials outside of k= is acceptable over the right kind of channel?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 09:17:22-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-11 19:02:22-07:00",
    "text": "Let's discuss whether [ I-D.mizrahi-ippm-compact-alternate-marking ] needs to be a normative reference, to describe how the Hash selection method works for multipoint.\u00a0 This document alone does not even mention what is used as input to the hash (though I think I have a good guess based on the context).\u00a0 Even if the intent is that  RFC 5474  suffices (avoiding the \"dependency on individual document\" issue), that is also listed only as an informative reference. Also, if the grouping procedure (section 6.1) does in fact require a distinguished (but arbitrary?) choice of initial endpoint as I suspect it does, that should be clarified.\u00a0 (See COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-09-19 09:55:40-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 12:22:32-07:00",
    "text": "I was wondering about why this document is going for informational rather than proposed standard. I see that  draft-ietf-taps-interface-01  has a normative reference to it, so this is effectively setting up a downref situation. That isn't necessarily a problem, but if the point is for this document to recommend an actual minimal set of transport services to be supported and exposed via the API specified in  draft-ietf-taps-interface  and other APIs, shouldn't that set be normative?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-09-18 17:19:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-12 17:38:45-07:00",
    "text": "[My general summary view of this document is not really relevant to these Discuss points and appears in the COMMENT section.] This document includes a general discussion of the features/services that IETF transport protocols (TCP, MPTCP, SCTP, UDP, etc.) provide ... and also throws in LEDBAT congestion control, with no real coverage of all the other congestion control schemes the IETF provides.\u00a0 It seems that there should be some text/justification of why LEDBAT (but none of the others) fall into the same categorization as the general transport features.\u00a0 As far as I can tell, the idea is that there can be a \"low-impact background data transfer\" feature/service, which LEDBAT attempts to provide, but I'm basing that on  inference and not something explictily stated in the document. Section 3.3.2 and Appendix A.3.1 are limiting this \"minimal set\" of transport services to exclude discrete messages and allow only the provisioning for TCP-like byte streams.\u00a0 While I can understand the desire to make TCP the \"gold standard\", the surrounding discussion, particularly in A.3.1, seems to be a layering violation.\u00a0 That is, we are hearing that AFra-Bytestream requires receivers (i.e., applications) to be able to consume contiguous bytestreams.\u00a0 But this seems to really be a requirement on the application protocol to be self-framing (and to provide its own sequence numbers if needed)!\u00a0 Normally we think of an application protocol placing requirements on the transport, or a particular transport as being inappropriate for use with a given application protocol.\u00a0 So I think this document needs to more explicitly acknowledge that this is not a \"generic minimal set\" of transport features, but rather a minimal set that is applicable for many, but not all, applications: some application protocols have requirements that are not met by this \"minimal set\". In Section A.3.6, \"Data encryption\" and \"source authenticity\" are absent from the list of \"security related transport features\" (that are relegated to the other document); this seems like a fatal omission.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-06 12:32:30-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-17 18:28:24-08:00",
    "text": "Thanks for the work that the authors and working group put into this document. I have one DISCUSS-level comment that should be very easy to resolve, and a small number of editorial nits. --------------------------------------------------------------------------- \u00a79: Since this specification is adding new endpoints under /.well-known/est, it needs to update the \"Well-Known URIs\" registry so that the entry for \"est\" indicates this document (in addition to  RFC 7030 ).",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-01-06 09:20:49-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 05:26:59-08:00",
    "text": "Thank you for this well written document. I have a couple of small DISCUSS points and a few minor comments/questions that I would like to discuss. DISCUSS: 5.4.\u00a0 Message Bindings \u00a0  o\u00a0 The CoAP Options used are Uri-Host, Uri-Path, Uri-Port, Content- \u00a0 \u00a0 \u00a0 Format, Block1, Block2, and Accept.\u00a0 These CoAP Options are used \u00a0 \u00a0 \u00a0 to communicate the HTTP fields specified in the EST REST messages. \u00a0 \u00a0 \u00a0 The Uri-host and Uri-Port Options can be omitted from the COAP \u00a0 \u00a0 \u00a0 message sent on the wire. The statement above \u00a0 \u00a0 \u00a0 When omitted, they are logically \u00a0 \u00a0 \u00a0 assumed to be the transport protocol destination address and port \u00a0 \u00a0 \u00a0 respectively.\u00a0 Explicit Uri-Host and Uri-Port Options are \u00a0 \u00a0 \u00a0 typically used when an endpoint hosts multiple virtual servers and \u00a0 \u00a0 \u00a0 uses the Options to route the requests accordingly. and the last quoted statement: How can the sender know whether or not it is Ok to omit Uri-Host/Uri-Port? 7.\u00a0 Parameters \u00a0  It is recommended, based on experiments, \u00a0  to follow the default CoAP configuration parameters ([ RFC7252 ]). \u00a0  However, depending on the implementation scenario, retransmissions \u00a0  and timeouts can also occur on other networking layers, governed by \u00a0  other configuration parameters.\u00a0 When a change in a server parameter \u00a0  has taken place, the parameter values in the communicating endpoints \u00a0  MUST be adjusted as necessary. The last sentence: use of MUST with passive voice is really unhelpful here. Adjusted by whom? How can this MUST be satisfied?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-12-29 05:51:26-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-19 04:53:33-08:00",
    "text": "Section 5.6: The EST-coaps client MUST support \u00a0  Block1 only if it sends EST-coaps requests with an IP packet size \u00a0  that exceeds the Path MTU. I think the requirement for when Block1 is required to be supported in the above sentence is unclear. Is the intention to say: An EST-coaps MUST support block1 to be capable to send requests that would otherwise result in the reliance on IP level fragmentation?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2021-03-09 05:17:43-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-07 18:43:15-07:00",
    "text": "== Section 1 == \"At the time of writing, almost all this DNS traffic is currently sent \u00a0  in clear (i.e., unencrypted).\u00a0 However there is increasing deployment \u00a0  of DNS-over-TLS (DoT) [ RFC7858 ] and DNS-over-HTTPS (DoH) [ RFC8484 ], \u00a0  particularly in mobile devices, browsers, and by providers of anycast \u00a0  recursive DNS resolution services.\u00a0 There are a few cases where there \u00a0  is some alternative channel encryption, for instance, in an IPsec VPN \u00a0  tunnel, at least between the stub resolver and the resolver. \u00a0  Today, almost all DNS queries are sent over UDP [thomas-ditl-tcp]. \u00a0  This has practical consequences when considering encryption of the \u00a0  traffic as a possible privacy technique.\u00a0 Some encryption solutions \u00a0  are only designed for TCP, not UDP and new solutions are still \u00a0  emerging [ I-D.ietf-quic-transport ] [ I-D.huitema-quic-dnsoquic ].\" This text made me wonder about the value of publishing this bis document at this point in time. Things are evolving so rapidly that, with respect to several of the new parts of this document (e.g., the last few paragraphs of Sec. 6.1.1, Sec. 6.1.1.1, Sec. 6.1.1.2), an immutable summary designed to represent reality over the long term doesn't really seem feasible right now. Why not wait to see how QUIC, DOH, ADD, ODNS, etc. shake out in the next few years and take this up then? == Section 6.1.1.2 == \"Users will only be aware of and have the ability to control such \u00a0  settings if applications provide the following functions: \u00a0  o communicate clearly the change in default to users \u00a0  o provide configuration options to change the default \u00a0  o provide configuration options to always use the system resolver\" This doesn't seem true. If the third bullet isn't provided, users still have awareness and control. Also, the bullets seem redundant with the text above, as if this is saying \"users only have awareness and control if they have awareness and control.\" As a result I'm not sure what this text is really meant to convey.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-10-05 14:42:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-05 14:40:30-07:00",
    "text": "Apologies for changing my YES to a DISCUSS -- I found a later version of my notes on this draft. My DISCUS is specifically around the\"The Alleged Public Nature of DNS Data\" / \"It has long been claimed that \"the data in the DNS is public\" section -- it seems to be unnecessarily creating and then shooting down a strawman. The \"the data in the DNS is public\" aphorism talks is more about the confidentiality one can expect **publishing** data in the DNS, not the privacy of the lookups.\u00a0 This whole section (to my mind) undersells the threat that publishing something in the DNS and expecting it to remain private creates -- for example, I'd be extremely foolish to insert: my-password-fd345432233e.example.com  600 IN TXT \"Hunter2\" Services like Farsight Securities (excellent!) DNSDB will likely capture this almost as soon as I use it somewhere. In addition, the \"Due to the lack of search capabilities, only a given QNAME will reveal the resource records associated with that name\" sentence is either false, or at the very least, misleading. $ dig +dnssec  foo.ietf.org  | grep NSEC  clearly tells me that the names  etherpad.ietf.org  and  ftp.ietf.org  both exist, and  $ dig +dnssec  ftpa.ietf.org  | grep NSEC  tells me that the next name is  guides.ietf.org .... I think that the last 4 or 5 sentences of the section are useful, but that the rest of the section is actively dangerous as it is likely to be misunderstood... Please don't misunderstand - I still believe that the document itself is really important and useful, but the section seems dangerous.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-10-08 05:55:52-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-05 14:42:06-07:00",
    "text": "Apologies for changing my YES to a DISCUSS -- I found a later version of my notes on this draft. My DISCUS is specifically around the\"The Alleged Public Nature of DNS Data\" / \"It has long been claimed that \"the data in the DNS is public\" section -- it seems to be unnecessarily creating and then shooting down a strawman. The \"the data in the DNS is public\" aphorism talks is more about the confidentiality one can expect **publishing** data in the DNS, not the privacy of the lookups.\u00a0 This whole section (to my mind) undersells the threat that publishing something in the DNS and expecting it to remain private creates -- for example, I'd be extremely foolish to insert: my-password-fd345432233e.example.com  600 IN TXT \"Hunter2\" Services like Farsight Securities (excellent!) DNSDB will likely capture this almost as soon as I use it somewhere. In addition, the \"Due to the lack of search capabilities, only a given QNAME will reveal the resource records associated with that name\" sentence is either false, or at the very least, misleading. $ dig +dnssec  foo.ietf.org  | grep NSEC  clearly tells me that the names  etherpad.ietf.org  and  ftp.ietf.org  both exist, and  $ dig +dnssec  ftpa.ietf.org  | grep NSEC  tells me that the next name is  guides.ietf.org .... I think that the last 4 or 5 sentences of the section are useful, but that the rest of the section is actively dangerous as it is likely to be misunderstood. Please don't misunderstand - I still believe that the document itself is really important and useful, but the section seems dangerous (and yes, I realize that it is in  RFC7626 )",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-04-14 21:19:50-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-06 21:17:47-07:00",
    "text": "[ section 2.1 ] * \"may also force the use of NPTv6\" seems like it draws some conclusions. \u00a0 Perhaps something like: \u00a0 \"may also increase the perceived need for the use of NPTv6\"? [ section 2.2 ] * \"It must also be noted that there is no indication in the IPv6 packet \u00a0  as to whether the Next Protocol field points to an extension header \u00a0  or to a transport header.\" \u00a0 What is this trying to say?\u00a0 Is this about what 8200 calls the \"Next \u00a0 Header\" field?\u00a0 If so, the Next Header field indicates...the next \u00a0 header, and whether that's a transport header or not depends on its \u00a0 value. \u00a0 I guess I read this text as implying that the 8200 standard is somehow \u00a0 ambiguous about what NH means, but it's really not.\u00a0 It's just that \u00a0 NH does not always indicate a transport. [ section 2.3.2.4 ] * \"Only trivial cases [...] should have RA-guard...\" \u00a0 Only?\u00a0 This doesn't strike me as being obviously the best recommendation. \u00a0 Definitely in trivial cases it should be enabled, but surely it should \u00a0 also be enabled even in more complex cases, albeit ones where \u00a0 knowledgeable administrators can configure things appropriately \u00a0 (vis. the applicability statement in section 1.1)...maybe?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-10-06 22:57:38-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-05 06:33:59-07:00",
    "text": "Thank you for the work put into this document.  Please find below two blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Barry Leiba for his concise shepherd's write-up but very clear about the WG consensus. Thank you also to Donald Eastlake for this INT directorate review that I am vastly supporting: https://mailarchive.ietf.org/arch/msg/int-dir/6Ox8iEBMqXkUoC2aUEF3wi4-c5g/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Generic comment how are link-local address (LLA) with scope encoded ? I would expect CBOR to work also on LLA only networks... At the bare minimum, please state that link-local addresses cannot be encoded with their scope, hence, they cannot represent an interface. -- Section 3.1.3 -- How can 2 valid link-local addresses (fe80::1%eth0, fe80::1%eth1) can be represented in order to identity two interfaces ?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-10-06 18:49:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-10-06 18:47:42-07:00",
    "text": "Thanks for this document. In general I found it easy to read, blessedly concise, and useful. I do have one concern with how you treat the covert channel concern you raise, which I'm making a DISCUSS (which I think will be easily cleared). Section 4 says: \u00a0  even though variations like: \u00a0  54([44, h'20010db81233']) \u00a0  54([45, h'20010db8123f']) \u00a0  would be parsed in the exact same way; they MUST be considered \u00a0  invalid. You choose to use a  RFC 2119  keyword here, and this is in the encoder section, so presumably you are insisting that the encoder MUST... what? You already said, in an earlier paragraph, that the encoder MUST set the trailing bits to zero, so I can't figure out what the quoted text is telling me to do. (Presumably any compliant encoder won't produce the depicted values, and an encoder that's noncompliant for the purpose of deliberately exfiltrating data using this covert channel won't be put off by this MUST.) Then in Section 5 we have: \u00a0  A particularly paranoid decoder could examine the lower non-relevant \u00a0  bits to determine if they are non-zero, and reject the prefix.\u00a0 This \u00a0  would detect non-compliant encoders, or a possible covert channel. The fairly dismissive tone (\"paranoid decoder could\"), not to mention the preceding pseudocode, suggests that you have no real expectation the decoder will do anything to \"consider invalid\" values with nonzero low bits. So probably the MUST from Section 4 isn't meant to apply to the decoder. In short I don't understand what that clause in Section 4 is telling me to do. One fix would simply to weaken the text, as in \u00a0  would be parsed in the exact same way, they should not be  \u00a0  considered legitimate encodings. \u00a0   P.S.: The semicolon in the quoted text is also either wrong, or I'm even more confused about what's being specified than I thought I was.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-10-09 07:47:40-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 18:49:01-07:00",
    "text": "Thanks for this document. In general I found it easy to read, blessedly concise, and useful. I do have one concern with how you treat the covert channel concern you raise, which I'm making a DISCUSS (which I think will be easily cleared). Section 4 says: \u00a0  even though variations like: \u00a0  54([44, h'20010db81233']) \u00a0  54([45, h'20010db8123f']) \u00a0  would be parsed in the exact same way; they MUST be considered \u00a0  invalid. You choose to use a  RFC 2119  keyword here, and this is in the encoder section, so presumably you are insisting that the encoder MUST... what? You already said, in an earlier paragraph, that the encoder MUST set the trailing bits to zero, so I can't figure out what the quoted text is telling me to do. (Presumably any compliant encoder won't produce the depicted values, and an encoder that's noncompliant for the purpose of deliberately exfiltrating data using this covert channel won't be put off by this MUST.) Then in Section 5 we have: \u00a0  A particularly paranoid decoder could examine the lower non-relevant \u00a0  bits to determine if they are non-zero, and reject the prefix.\u00a0 This \u00a0  would detect non-compliant encoders, or a possible covert channel. The fairly dismissive tone (\"paranoid decoder could\"), not to mention the preceding pseudocode, suggests that you have no real expectation the decoder will do anything to \"consider invalid\" values with nonzero low bits. So probably the MUST from Section 4 isn't meant to apply to the decoder. In short I don't understand what that clause in Section 4 is telling me to do. One fix would simply be to weaken the text, as in \u00a0  would be parsed in the exact same way, they should not be  \u00a0  considered legitimate encodings. \u00a0   P.S.: The semicolon in the quoted text is also either wrong, or I'm even more confused about what's being specified than I thought I was.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-11 13:01:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 00:42:00-07:00",
    "text": "My apologies if this is super-obvious and I'm just missing it ... but Section 4.3 dictates that part of the value for the application-specific SRLG TLV is a \"Neighbor System-ID + pseudo-node ID (7 octets)\".\u00a0 Where are these defined?\u00a0 (We don't exactly say that we're reusing the structure from, e.g., TLV 138, which I note refers to the seventh octet as \"pseudonode number\", not \"pseudo-node ID\".\u00a0 Similarly for the interpretation of the SRLG value(s).\u00a0 Do we just need to reference that we're reusing the encoding from  RFC 5307  (or similar) or are some changes needed?",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-06-18 12:45:41-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 15:16:11-07:00",
    "text": "This should be simple to resolve - the use of the SR-TE term is out-of-alignment with other drafts, spring and idr. Suggest: Segment Routing Traffic Engineering/s/Segment Routing Policy and SRTE/s/SR Policy.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-06-11 15:29:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 12:29:20-07:00",
    "text": "An easy one: Sections 7.3 and 7.5 create new IANA registries with \"Expert Review\" rules, but Section 7.5 provides no particular guidance to the Designated Expert about how to review applications, as required by Section 4.5 of  BCP 26 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-23 13:13:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 19:15:28-08:00",
    "text": "I think we need to discuss how this document refers to the level of security provided by the network, \"insecure network\"s or portions thereof, etc..\u00a0 In the normal  RFC 3552  threat model, we assume the entire network is under the control of an attacker.\u00a0 Any exception to that is going to be treated as a special case (usually only grudgingly so), e.g., if a portion of a network is under administrative control of a single entity and physically controlled as well, or if a network uses MAC-layer security technologies.\u00a0 I don't think this mindset is well-reflected in the current text. I agree with Mirja that we need more clarity on usable security contexts for interoperable implementation.\u00a0 My suggestion would be to define a security context that is usable for normal Internet hosts over the normal Internet (i.e., not a stressed network) to have as a baseline secure configuration, and customizations for other environments would be treated as deviations from that well-established baseline in terms of algorithms and security strength.\u00a0 I furthermore note that even after reading draft-ietf-dtn-bpsec-interop-sc  I do not have a clear picture of exactly which bytes are used as input to the various cryptographic algorithms and how the output is encoded.\u00a0 For example, is the block data contents of a target block always going to be a fixed-length bstr?\u00a0 Can the process of applying protection change whether the #6.24 tag is present? I understand the need to provide a defined processing order for message deprotection (and thus to avoid having the same operation applied to the same target), but I still don't have a clear picture of why we can't define things in such a way that allows (e.g.) nested signatures over the same content block.\u00a0 I understand the current mechanics where in the abstract model we only can protect a single block at a time (not a combination of blocks), so that blindly applying the current mechanics to an attempt at a nested signature would produce the problematic ambiguity of processing order, but I don't understand why it has to be that way.\u00a0 Relatedly, I think that the current formulation where the target list can be freely modified/split into separate BIB/BCBs by any waypoint will probably leave us open to some semantic attacks that drop some blocks but not others, when there is supposed to be semantic interdependence between those blocks. The diagram in Figure 2 seems to incorrectly indicate a degree of freedom in the number of results per target: if we are applying the same operation to all blocks in the target array, the operation should produce the same number of results for all target blocks, thus constraining 'K' to be equal to 'M'. Exclusion of most of the block parameters from confidentiality processing seems to be a critical flaw in the cryptographic hygeine; I think we should include the Block Type Code, Block Number, possibly Block Processing Control Flags, CRC Type and CRC Field (if present), and Block Data Length fields as \"additional data\" input to the AEAD to provide integrity protection, as well as use them as input to BIB calculation.\u00a0 Failing to include these parameters seems to leave us prone to \"slice and dice\" style attacks.\u00a0 Also, the description in Section 4 is unclear about whether the surrounding CBOR array encoding is excluded from AEAD iput (though it doesn't really seem like it would make sense to re-encode as a one-item CBOR array prior to applying message protection, the current text is worded such that one might think the array framing is not explicitly excluded). Section 9.1 gives an example of using a (presumed unprotected in the absence of any disclaimer) cryptographic key as a security context parameter; given that (per Section 3.6) the parameters are included in the wire-format abstract security block, and not subject to BCB protection, this is wholly insecure and cannot reasonably be used as an example.\u00a0 (At least draft-ietf-dtn-bpsec-interop-sc  had a bit of note about \"encoded or protected by the key management system\" to give this a veneer of respectability.) There's a couple places (noted in the COMMENT) where we claim some combination of things to be \"insecure\" without justification; in the noted instances this doesn't seem to be immediately obvious, so I think the justification is needed (or the claim should be removed). Section 7 includes a note that \"It is recommended that security operations only be applied to the blocks that absolutely need them.\u00a0 If a BPA were to apply security operations such as integrity or confidentiality to every block in the bundle, regardless of need, there could be downstream errors processing blocks whose contents must be inspected or changed at every hop along the path.\"\u00a0 While this statement, taken literally, is true, it also seems inconsistent with, e.g.,  BCP 188 , as well as the  RFC 3552  threat model, let alone the BPSec threat model of Section 8.\u00a0 I suggest phrasing that makes applying security operations the default behavior and requiring justification to diverge from that.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-10 11:38:48-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-11-30 15:08:20-08:00",
    "text": "- Is this meant to obsolete  RFC 6257 ? - Section 3.8 says \"BCB blocks MUST NOT have the 'block must be removed from bundle if \u00a0 \u00a0 \u00a0 it can't be processed' flag set.\" However, the notes for this section ask that \"designers carefully consider the effect\" of setting this flag. I presume the latter should have been deleted? - Sec 11.3 specifies an unsigned integer with certain meanings attached to negative values.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-10 11:38:55-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-10 11:38:48-08:00",
    "text": "hanks for addressing (and correcting) my DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-02-03 03:17:07-08:00",
    "text": "Sec 1.2 says: \"A sample security \u00a0  context has been defined ([ I-D.ietf-dtn-bpsec-interop-sc ]) to support \u00a0  interoperability testing and serve as an exemplar for how security \u00a0  contexts should be defined for this specification.\" However I don't really understand how interoperability can be reached if there is not at least one security context that is mandatory to implement in this draft (especially as ietf-dtn-bpsec-interop-sc is expired for more than half a year already)...?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-06-23 12:31:00-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-21 07:38:52-07:00",
    "text": "** Section 5.\u00a0 There is seemingly conflicting guidance on the interpreting the E and L flag. Statement #1 \u00a0 \u00a0 \u00a0 When E flag is set to 0, the value of the L flag SHOULD be \u00a0 \u00a0 \u00a0 respected as selection criteria; Statement #2 \u00a0  When the L flag is set to 1 and the E flag is set to 0, then the PCE \u00a0  MUST consider the protection eligibility as a PROTECTION PREFERRED \u00a0  constraint. Statement #3 \u00a0  When L flag is set to 0 and E flag is set to 1, then the PCE MUST \u00a0  consider the protection eligibility as an UNPROTECTED MANDATORY \u00a0  constraint. -- The Statement #1 appears to be weaker (SHOULD) than Statement #2 and 3. -- What is the difference between \u201crespecting [something] in the selection criteria\u201d and \u201cconsider[ing] the protection eligibility\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-10-17 11:22:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-16 23:32:47-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ipsecme-mib-iptfs-06 CC @evyncke Thank you for the work put into this document (even if I am balloting a DISCUSS); Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Tero Kivinen for the shepherd's detailed write-up including the WG consensus *but* it lacks the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Inconsistent intended status & use of experimental code point This document is standard track, but the OID used in section 4.1 is 'experimental' and in section 4.2 `experimental 500` per  https://www.iana.org/assignments/smi-numbers/smi-numbers.xhtml . Please request IANA to assign an OID from the 1.3.6.1.2.1 tree.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-20 08:25:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-20 02:42:46-07:00",
    "text": "# GEN AD review of draft-ietf-ipsecme-mib-iptfs- CC @larseggert Thanks to Joel Halpern for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/5gau5fsdf6JutMgWnPRn9R_HVto ). ## Discuss ### Section 4.2, paragraph 28 ``` \u00a0 \u00a0 \u00a0 \u00a0  l2FixedRate OBJECT-TYPE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  SYNTAX\u00a0 \u00a0 \u00a0 CounterBasedGauge64 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  MAX-ACCESS\u00a0 read-only \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  STATUS\u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"TFS bit rate may be specified as a layer 2 wire rate.\u00a0 On \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  transmission, target bandwidth/bit rate in bps for iptfs \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  tunnel.\u00a0 This rate is the nominal timing for the fixed \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  size packet. If congestion control is enabled the rate \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  may be adjusted down (or up if unset).\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ::= { iptfsConfigTableEntry 5 } \u00a0 \u00a0 \u00a0 \u00a0  l3FixedRate OBJECT-TYPE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  SYNTAX\u00a0 \u00a0 \u00a0 CounterBasedGauge64 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  MAX-ACCESS\u00a0 read-only \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  STATUS\u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"TFS bit rate may be specified as a layer 3 packet rate. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  On Transmission, target bandwidth/bit rate in bps for \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  iptfs tunnel.\u00a0 This rate is the nominal timing for the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  fixed size packet. If congestion control is enabled the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  rate may be adjusted down (or up if unset).\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ::= { iptfsConfigTableEntry 6 } ``` I'm not sure what the intended meaning of the two \"or up if unset\" statements is. Even when congestion control is disabled (=unset), the given fixed rates will not be exceeded?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-10-20 08:47:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-19 06:06:21-07:00",
    "text": "Thanks for working on this specification. I am balloting a Discuss, so that we pick the correct default value of congestionControl object. - Section 4.2 says \u00a0 \u00a0 congestionControl OBJECT-TYPE \u00a0 \u00a0 \u00a0 \u00a0 SYNTAX\u00a0 \u00a0 \u00a0 TruthValue \u00a0 \u00a0 \u00a0 \u00a0 MAX-ACCESS\u00a0 read-only \u00a0 \u00a0 \u00a0 \u00a0 STATUS\u00a0 \u00a0 \u00a0 current \u00a0 \u00a0 \u00a0 \u00a0 DESCRIPTION \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"When set to true, the default, this enables the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 congestion control on-the-wire exchange of data that is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 required by congestion control algorithms as defined by \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  RFC 5348 .\u00a0 When set to false, IP-TFS sends fixed-sized \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 packets over an IP-TFS tunnel at a constant rate.\" \u00a0 \u00a0 \u00a0 \u00a0 DEFVAL { false } \u00a0 \u00a0 \u00a0 \u00a0 ::= { iptfsConfigTableEntry 2 } \u00a0   \u00a0  While the description says the default value should be true, the DEFVAL mentions \"false\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-04-01 18:06:58-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-03 08:11:23-07:00",
    "text": "Despite the length of the list of numbered points, this document is actually in pretty good shape -- most of them just relate to clarifying/correcting how this document interacts with other documents rather than issues with the way this mechanism works. (1) Section 4 calmly asserts that \"[i]n the STIR ecosystem, CA certificates may be used to sign PASSporTs\", but I could not find this documented in RFCs 8224, 8225, or 8226.\u00a0 If it is already documented somewhere, please provide a reference; if it is a new property of the architecture being asserted by this specification, we should be more clear about it, as well as how it is not entirely consistent with cryptographic best practice (see COMMENT). (It is perhaps unfortunate that  RFC 8225  did not talk about (extended) key usage values suitable for signing PASSporTs, though it is probably not appropriate to start doing so in this document.) (2) We are introducing new entities that act as X.509 CAs with this mechanism.\u00a0 Do we need to mandate that they provide CRLs/OCSP/etc. for making revocation information available?\u00a0 (\"This is already covered by RFC XXXX\" is a fine answer, though it is probably worth a reminder in the text.) (3) I think we are missing some exposition about how an SPC TNAuthList value is treated as \"encompassing\" specific telephone numbers/ranges controlled by the provider to which that SPC is assigned (more than just a mention in passing that the CA has to have access to the industry database), such that the CA cert might have the SPC form of TNAuthList but the child certificate a different form.\u00a0 I was also looking for some discussion of the related risk of skew if the database changes, but perhaps  https://tools.ietf.org/html/rfc8226#section-10  is enough to cover that.\u00a0 (It would be nice to have some data on the relative lifetime of database mappings and certificate lifetimes, though.) (4) We seem to have an internal inconsistency about whether alternative certification paths are allowed -- Section 6 implies that it is a very rigid procedure (and Section 7 requires AuthorityKeyIdentifier/SubjectKeyIdentifier matching), but Section 8.2 suggests the use of cross-signing and AIA for an alternate chain construction. (5) Section 9 contains a false statement that TLS subcerts has ways for the issuer of a (TLS) delegated credential to revoke that credential. https://tools.ietf.org/html/draft-ietf-tls-subcerts-09#section-7.3  is quite clear that expiration is the only mechanism to invalidate the delegated credential, with the risk of stolen/leaked delegated credentials limited by their short-lived nature. (6) Section 4.1 seems to waver on where the \"encompassing\" check is performed, leaving open the possibility that it is not performed at all. I think we need to be very explicit about what is required, not just what might be done or what is desirable.\u00a0 This might end up needing to be passing the buck (\"the authority for the deployment in question will specify which entity performs this validation\"), but at present it seems like there's a gap that needs to be filled in some manner. (7) Section 8.1 has what I think is a stale statement about ACME, relating to suitability of the certificate URL for use as \"x5u\" --  RFC 8555  only requres POST-AS-GET access, not the GET access that we imply. (See COMMENT for additional related points.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-21 10:22:06-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-24 20:42:38-07:00",
    "text": "Thanks for having the discussion with John and updating the document already; I benefitted a lot from being able to read the -11 that has started rolling in fixes from the prior discussion.\u00a0 My one new discuss point is relatively minor, all things considered, and is really just trying to nail down an aspect of internal consistency.\u00a0 (I also support Roman's disuss, but we don't need to rehash that here.) When we introduce the concept of gateways, we say that they can be attached to the Internet or a backbone network.\u00a0 We then go on to provide a mechanism for gateways to advertise to some tunnel ingress node the complete set of gateways for a given site.\u00a0 It seems that we do fairly consistently refer to this advertisement as being over \"the backbone network\", but I'm not seeing anything that clearly disclaims the applicability of this technique over the Internet itself.\u00a0 However, I think we need to have such a disclaimer, since we do have a clearly stated assumption that \"the connected set of DCs *and the backbone network connecting them* are part of the same SR BGP Link State (LS) instance ([ RFC7752 ] and [ I-D.ietf-idr-bgpls-segment-routing-epe ])\" (emphasis mine).\u00a0 If the intent is to only use this mechanism over \"in-BGP-LS-instance\" backbones and not over the Internet, we should explicitly set the scope of applicability and contrast a gateway as a generic concept and the gateway scenarios that this mechanism applies to.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-05-13 14:40:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-13 14:38:18-07:00",
    "text": "I have several points I\u2019d like to discuss, listed below from most general to most specific. 1. There\u2019s surprisingly little in this document that seems to be SR-specific (and what there is, has some problems, see below). Is there some reason you rule out interconnecting domains using other tunneling technologies? I ask this question first because if the answer were to be \u201coh huh, we don\u2019t need to make this SR-specific after all\u201d some of the other things I\u2019m asking about might go away. 2. There\u2019s no discussion about what trust model you\u2019re assuming. SR brings with it its own assumed trust model, laid out in  RFC 8402  as \u201cSR operates within a trusted domain\u201d (whatever *that* means). On the one hand, given you\u2019re tying yourself to SR you presumably are tied to its trust model. On the other hand, there are some tantalizing tidbits that suggest otherwise. I would be happier if there were some explicit description of the trust model you\u2019re presuming. It\u2019s hard to evaluate some aspects of the document without knowing if you\u2019re assuming the  RFC 8402  closed domain model, or something else. 3. The use of the term \u201cSR domain\u201d in this document appears inconsistent with its definition in  RFC 8402 . Here\u2019s that definition, from \u00a72: \u00a0  Segment Routing domain (SR domain): the set of nodes participating in \u00a0  the source-based routing model.\u00a0 These nodes may be connected to the \u00a0  same physical infrastructure (e.g., a Service Provider's network). \u00a0  They may as well be remotely connected to each other (e.g., an \u00a0  enterprise VPN or an overlay).\u00a0 If multiple protocol instances are \u00a0  deployed, the SR domain most commonly includes all of the protocol \u00a0  instances in a network.\u00a0 However, some deployments may wish to \u00a0  subdivide the network into multiple SR domains, each of which \u00a0  includes one or more protocol instances.\u00a0 It is expected that all \u00a0  nodes in an SR domain are managed by the same administrative entity. And notably, later in 8402 \u00a78 we are told that \u00a0  By default, SR operates within a trusted domain.\u00a0 Traffic MUST be \u00a0  filtered at the domain boundaries. Which specifically means, to take the MPLS instantiation of SR (\u00a78.1): \u00a0  SR domain boundary routers MUST filter any external traffic destined \u00a0  to a label associated with a segment within the trusted domain.\u00a0 This \u00a0  includes labels within the SRGB of the trusted domain, labels within \u00a0  the SRLB of the specific boundary router, and labels outside either \u00a0  of these blocks.\u00a0 External traffic is any traffic received from an \u00a0  interface connected to a node outside the domain of trust. More simply put, 8402 says you can\u2019t send an SR packet from outside an SR domain, into that domain. But your document is written in terms of a multiplicity of SR domains, for example this in Section 1: \u00a0  Tunnel Encapsulation attribute.\u00a0 The gateway in the ingress SR domain \u00a0  can now see all possible paths to X in the egress SR domain Maybe a quick fix, assuming you really do subscribe to the  RFC 8402  trust model, is to invent, define, and use the term \u201cSR subdomain\u201d and deem all the subdomains to be one SR domain, in the sense of  RFC 8402  \u00a72 \u2014 \u201cThey may as well be remotely connected to each other (e.g., an enterprise VPN or an overlay)\u201d seems to describe your situation pretty well.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-06-01 12:05:05-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-13 14:40:20-07:00",
    "text": "I have several points I\u2019d like to discuss, listed below from most general to most specific. 1. There\u2019s surprisingly little in this document that seems to be SR-specific (and what there is, has some problems, see below). Is there some reason you rule out interconnecting domains using other tunneling technologies? I ask this question first because if the answer were to be \u201coh huh, we don\u2019t need to make this SR-specific after all\u201d some of the other things I\u2019m asking about might go away. 2. There\u2019s no discussion about what trust model you\u2019re assuming. SR brings with it its own assumed trust model, laid out in  RFC 8402  as \u201cSR operates within a trusted domain\u201d (whatever *that* means). On the one hand, given you\u2019re tying yourself to SR you presumably are tied to its trust model. On the other hand, there are some tantalizing tidbits that suggest otherwise. I would be happier if there were some explicit description of the trust model you\u2019re presuming. It\u2019s hard to evaluate some aspects of the document without knowing if you\u2019re assuming the  RFC 8402  closed domain model, or something else. 3. The use of the term \u201cSR domain\u201d in this document appears inconsistent with its definition in  RFC 8402 . Here\u2019s that definition, from \u00a72: \u00a0  Segment Routing domain (SR domain): the set of nodes participating in \u00a0  the source-based routing model.\u00a0 These nodes may be connected to the \u00a0  same physical infrastructure (e.g., a Service Provider's network). \u00a0  They may as well be remotely connected to each other (e.g., an \u00a0  enterprise VPN or an overlay).\u00a0 If multiple protocol instances are \u00a0  deployed, the SR domain most commonly includes all of the protocol \u00a0  instances in a network.\u00a0 However, some deployments may wish to \u00a0  subdivide the network into multiple SR domains, each of which \u00a0  includes one or more protocol instances.\u00a0 It is expected that all \u00a0  nodes in an SR domain are managed by the same administrative entity. And notably, later in 8402 \u00a78 we are told that \u00a0  By default, SR operates within a trusted domain.\u00a0 Traffic MUST be \u00a0  filtered at the domain boundaries. Which specifically means, to take the MPLS instantiation of SR (\u00a78.1): \u00a0  SR domain boundary routers MUST filter any external traffic destined \u00a0  to a label associated with a segment within the trusted domain.\u00a0 This \u00a0  includes labels within the SRGB of the trusted domain, labels within \u00a0  the SRLB of the specific boundary router, and labels outside either \u00a0  of these blocks.\u00a0 External traffic is any traffic received from an \u00a0  interface connected to a node outside the domain of trust. More simply put, 8402 says you can\u2019t send an SR packet from outside an SR domain, into that domain. But your document is written in terms of a multiplicity of SR domains, for example this in Section 1: \u00a0  Tunnel Encapsulation attribute.\u00a0 The gateway in the ingress SR domain \u00a0  can now see all possible paths to X in the egress SR domain Maybe a quick fix, assuming you really do subscribe to the  RFC 8402  trust model, is to invent, define, and use the term \u201cSR subdomain\u201d and deem all the subdomains to comprise one SR domain, in the sense of  RFC 8402  \u00a72 \u2014 \u201cThey may as well be remotely connected to each other (e.g., an enterprise VPN or an overlay)\u201d seems to describe your situation pretty well.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-06-11 08:03:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 13:02:41-07:00",
    "text": "RFC8402  tells us: (a)\u201cSegment Routing domain (SR domain): the set of nodes participating in the source-based routing model \u2026\u00a0  (a.1) \u201cThese nodes may be connected to the same physical infrastructure (e.g., a Service Provider's network).\u201d (a.2) \u201cThey may as well be remotely connected to each other (e.g., an\u00a0 enterprise VPN or an overlay).\u201d (b) \u201cBy default, SR operates within a trusted domain.\u00a0 Traffic MUST be filtered at the domain boundaries.\u201d My understanding of this document is that it is an enabling capability to help establish SR domains of the like described in (a.2).\u00a0 What I see missing is text that provides the confidence suggested by the language of \u201ctrusted domain\u201d in (b). -- Section 1 hints at various VPN technologies perhaps being used\u00a0 \u201cThe various ASes that provide connectivity between the Ingress and Egress\u00a0  Domains could each be constructed differently and use different technologies such as IP, MPLS with global table routing native BGP to the edge, MPLS IP VPN, SR-MPLS IP VPN, or SRv6 IP VPN.\u201d\u00a0 However, the security properties of all of those aren\u2019t clear to a degree that would seem consistent with being a \u201ctrusted domain\u201d.\u00a0 For example, saying \u201cIP\u201d might suggest that naked IP packets with SR headers (with no additional security primitives) could be dropped onto the open Internet, or at least through networks not under the control the \u201cdata centers\u201d use case suggested by the name of the document.\u00a0  -- The discussion at  https://mailarchive.ietf.org/arch/msg/bess/zY783PgnXSCp6GNSRF4kY0diLYs/  around the forwarding plane trust model is also informative.\u00a0  It is noted that that the \u201ctransit nodes of the AS are not part of the domain.\u201d\u00a0 I could agree, but only to the degree that the SR packets are tunneled in such as way that suggested a trusted domain at least of equal security as (a.1). I think language is needed to describe the normative security requirements of the tunnels that will be created on top of the routes enables by this work to substantiate the claim that at a \u201ctrusted domain\u201d is being maintained.\u00a0 This has some overlap with John\u2019s text about clarify the proposed trust model.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-05-18 17:03:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-18 17:02:59-07:00",
    "text": "I hope that I'm just misunderstanding something obvious, but I strongly support John's DISCUSS -- when SR was \"approved\" it was with the understanding that it would only be used within \"real\" limited domains, and would never be sent outside of closed/limited network. The document says: \"The solution defined in this document can be seen in the broader context of SR domain interconnection in [ I-D.farrel-spring-sr-domain-interconnect ]. \", which says: \" Traffic originating in one SR domain often terminates in another SR domain, but must transit a backbone network that provides interconnection between those domains.\" -- is it unclear to me if this is really what is being proposed...",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-05-27 07:57:51-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 17:03:26-07:00",
    "text": "I hope that I'm just misunderstanding something obvious, but I strongly support John's DISCUSS -- when SR was \"approved\" it was with the understanding that it would only be used within \"real\" limited domains, and would never be sent outside of closed/limited network. The document says: \"The solution defined in this document can be seen in the broader context of SR domain interconnection in [ I-D.farrel-spring-sr-domain-interconnect ]. \", which says: \" Traffic originating in one SR domain often terminates in another SR domain, but must transit a backbone network that provides interconnection between those domains.\" -- is it unclear to me if this is really what is being proposed... I'm hoping that I'm really misunderstanding something here -- please educate me.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-27 19:15:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 20:53:50-08:00",
    "text": "Let's discuss whether it's appropriate to include vendor-specific functionality (e.g., linux NETKEY/XFRM marking) in a standards-track protocol/model. The ASN.1 GeneralName type is an abstract type; in order to represent it in a string we must have some discussion of how it is encoded.\u00a0 (A similar concern might apply to the other ASN.1 types used, such as DistinguishedName, though the latter does have a fairly well-established string presentation form, so the concern is of lesser magnitude there. That said,  RFC 5280  is not a suitable reference for the DistinguishedName string presentation form.) In a similar vein, the 'id-key' identity representation is listed as type 'string' but the description lists it as an \"opaque octet string\". YANG strings are not directly suitable for holding binary content (which is what an opaque octet string is), so either a scheme for encoding arbitrary binary content as a string is needed, the YANG 'binary' type should be used, or this node needs to be documented as only allowing valid Unicode (IIUC, in UTF-8 encoding, though https://tools.ietf.org/html/rfc6020#section-9.4  is not as clear about this as I would like). The two 'anti-replay-window' leafs are (1) using different-width types, and (2) do not have enough of a description to indicate what content they hold, especially whe combined with a default value of 32. (I mention both locations in the COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-24 13:52:04-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-01 23:35:22-08:00",
    "text": " general ] * Similar to df-bit and ecn, should there be a tunnel-grouping leaf that \u00a0 controls how inner DSCP marking should be reflected on the outer IPsec \u00a0 header? ( RFC 2983  suggests using multiple tunnels instead and warns about \u00a0 the danger of packet reordering as a result of variable DSCP marking (as \u00a0 well as the potential information leak as a security issue), so maybe this \u00a0 isn't important. \u00a0 Separately, what about a setting to explicitly configure the DSCP mark on \u00a0 the outer header for all encap'd packets? [ appendix A ] * I'm unclear on what bypass-dscp=true means.\u00a0 Does it mean that the DSCP \u00a0 value is *not* part of the traffic selector? \u00a0 Should this instead be called \"ignore-dscp\" or \"skip-dscp\"? * Related: does the dscp-mapping leaf only have significance if bypass-dscp \u00a0 is false?\u00a0 If so, is there some \"must ../bypass-dscp ...\" syntax that would \u00a0 be applicable?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-02-19 08:11:06-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 06:55:21-08:00",
    "text": "\u00a0 \u00a0 \u00a0 \u00a0 leaf ecn { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type boolean; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 default false; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Explicit Congestion Notification (ECN). If true \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 copy CE bits to inner header.\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Section 5.1.2 and Appendix C in  RFC 4301 .\"; \u00a0 \u00a0 \u00a0 \u00a0 } There is something wrong here, likely in the description of the option. This as the outer IP header on sender side needs to set ECN field to ECT to enable so that any CE marks can be received. I think it is reasonable to have an option to just enable ECN, but that requires several things. Secondly with the changes in  RFC 8311 , there might be need to be more explicit in the configuration of ECN to actually indicate which ECT value that should be set on send side for the established IPsec tunnel. Due to under discussion experiments with ECT values per  RFC 8311  we should verify that just copying the inner header value to the external is fine and don't break anything as path and/or marking behavior may not be the same.  I think there is also the question if  RFC 6040  needs to be referenced in this context to ensure that people pick up on that  RFC 6040  updates  RFC 4301 .",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-22 07:45:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-10 02:02:59-08:00",
    "text": "Updating my ballot after reviewing draft-ietf-ace-aif-06. Just want to make sure we don't miss anything, please feel free to correct me if I missed the mark here. FP:  https://datatracker.ietf.org/doc/html/draft-ietf-ace-aif-06#section-4  states: default values are the values \"URI-local- \u00a0  part\" for Toid and \"REST-method-set\" for Tperm, as per Section 3 of \u00a0  the present specification. \u00a0  A specification that wants to use Generic AIF with different Toid \u00a0  and/or Tperm is expected to request these as media type parameters \u00a0  (Section 5.2) and register a corresponding Content-Format \u00a0  (Section 5.3). FP: I wonder if this document should define a new media type parameter for Tperm (as REST-method-set is not appropriate for \"pub\"/\"sub\" value) and register a corresponding Content-Format as indicated in the paragraph above. CC'ing Carsten for his opinion.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-03-22 05:18:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 22:34:50-08:00",
    "text": "This should be quick to resolve.\u00a0 In Section 3.2: \u00a0  The Broker MUST NOT forward messages to unauthorized subscribers. \u00a0  There is no way to inform the Clients with invalid tokens that an \u00a0  authorization error has occurred other than sending a DISCONNECT \u00a0  packet.\u00a0 Therefore, the Broker SHOULD send a DISCONNECT packet with \u00a0  the reason code '0x87 (Not authorized)'. This seems like a contradiction.\u00a0 How is that SHOULD not a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-31 06:06:15-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-22 06:58:47-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ipsecme-yang-iptfs-08 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (very easy to address ;-) ), some non-blocking COMMENT points (also very easy to fix), and some nits. Special thanks to Tero Kivinen for the shepherd's detailed write-up including the WG consensus even if there is no justification for the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section A.2 wrong prefix size ? ``` \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2001:DB8::0/16 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2001:DB8::1:0/16 ``` Beside the lack of  RFC 5952  (see my comment below), is it on purpose that both prefix with a /16 are identical ? The authors probably mean a different prefix size rather than /16.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-08-31 06:37:25-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 07:18:11-07:00",
    "text": "Hi Chris, Don, This YANG module and document looks good to me. The one discuss issue that I wanted to check on the commented out when statements, e.g.,  \u00a0 \u00a0 \u00a0 \u00a0  uses ipsec-tx-stat-grouping { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  //when \"direction = 'outbound'\"; \u00a0 \u00a0 \u00a0 \u00a0  } Are these when statement meant to just be descriptive?\u00a0 If so, then writing them in plain English is probably better.\u00a0 Or otherwise, can they just be removed from the module, or is there another plan?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-20 14:18:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-15 06:48:43-07:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-assert-packing-10 CC @jgscudder Thanks for this document, it seems likely to be useful and my DISCUSS notwithstanding, for the most part I found it easy to read and understand.  ## DISCUSS I am ballotting DISCUSS because although I found the casual, expository style of Section 3.1.1 to be enjoyable to read as a tutorial, I'm concerned that it may not be as well-suited when being used as a reference specification for producing an implementation. And of course, that is the primary purpose of a Standards Track document. Most concerning is the mixture of actual requirements language, with language that's only exemplary -- I found it impossible to determine exactly what parts I have to strictly follow in order to produce a compliant implementation. Rather than call out any particular issue here, I refer to the comments section for my various specific points about Section 3.3.1. Let's discuss those, make any changes you agree to, or you can make the case that it's fine as it stands. That is to say, I don't expect this DISCUSS to be blocking in the long term, rather it's here to make sure we do have the discussion. Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-16 10:45:25-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-29 19:48:04-07:00",
    "text": "Thank you for writing this document; I'm really glad that it will be available to illuminate the particulars of BPsec usage and provide a default option when running BPsec in relatively bland environments. However, I think there are a few gaps between the current specification and a strong/reliable default security option. (D1) the construction for the HMAC input plaintext and GCM AAD seems to be \"malleable\" at the security context layer.\u00a0 That is, in order for the cryptographic integrity protection mechanism to provide strong guarantees for the application protocol's semantics, the mapping from protocol parameters (e.g., \"security target contents\", \"primary block\") to the actual byte string used as the IPPT/AAD inputs to HMAC/GMAC needs to be an injective mapping (in the mathematical sense).\u00a0 If injectivity does not hold, then there is more than one possible application semantics that could be perceived as valid upon successful validation of the authentication tag at the recipient; this \"malleability\" across different interpretations of the bytes covered by a given integrity tag gives an opening by which an attacker can target the application semantics. The current construction seems \"malleable\" because the scope flags are not protected in any way and could be modified by an attacker, and the scope flags affect which application protocol fields (and thus, semantics) are used to construct the IPPT/AAD.\u00a0 If the attacker modifies the messages to move those encoded bytes from one location to another, the modified message could still pass cryptographic verification but be interpreted with different semantics than intended.\u00a0 We do correctly note that the security context identifier and the security context parameters of the security block are not included in the input data, but the conclusion that \"successful verification implies that these parameters were unchanged from what the security source has specified\" does not seem entirely warranted without further analysis that relies on the internal structure of the different potential parts of the IPPT/AAD. [side note: the IETF security community tends towards \"always include as much information in the MAC as you can without breaking operations\", which would naively be everything included with scope flags 0x7.\u00a0 Always including everything removes the malleability, since there are no gaps to move around.\u00a0 But I think I can come up with scenarios where this flexibility would indeed be needed in BP operations, so my tentative conclusion is that the simple \"always MAC everything\" approach will not work here.] Specifically, to the extent that we may have injectivity, we seem to be relying on the specific encoding details of the different types of information that could be used in constructing the IPPT and AAD.\u00a0 Since the IPPT/AAD is currently just the concatenation (in a particular order) of any/all of a few pieces of data, we can only get injectivity if each of those pieces of data is self-framing and *self-identifying* by its encoded form.\u00a0 (If we, for example, prefixed each self-framing part with a type identifier for what followed, that would make the overall encoding self-identifying for what is contained therein.)\u00a0 E.g., the primary block is going to be a CBOR array with (at least?) 8 elements, starting with 0x0808, and is self-framing by virtue of being a CBOR object.\u00a0 But the \"security target other fields\" are not so clearly self framing, as it's more of a CBOR sequence with type code, block number, and control flags as three unsigned integers; we have to know a priori to read three CBOR unsigned integers and treat that as a single object. Furthermore, the \"BIB other fields\" (or \"BCB other fields\") are also three CBOR unsigned integers, and since it's possible for (e.g.) a BIB to be the security target of a BIB, the block type code cannot distinguish between a security target and the BIB information.\u00a0 Only the block number could, but IIRC the block number itself is malleable to an on-path attacker.\u00a0 And this analysis only covers the currently specified scope flags; any future additions might add new ways for injectivity to fail.\u00a0 It's much better to have a strong injective construction at the higher layer and not rely on the internal encoding details of the component pieces. So, I think we need to include at least the scope flags as part of the IPPT/AAD in order to provide injectivity.\u00a0 It might be worth considering adding additional framing and typing to make clear boundaries between the different parts of the IPPT/AAD, but my current understanding is that it would not be strictly necessary to do so. (D2) There seems to be some risk associated with the current HMAC construction, since the HMAC with a given key over a given plaintext will be the same each time it is calculated.\u00a0 In other protocol contexts, this has led to practical attacks and HMAC forgery, by using a side-channel to gain insight into the verifier's behavior and guessing the correct HMAC tag for a given (attacker-selected) plaintext a byte at a time.\u00a0 With only a modest number of trials (4k on average for HMAC-SHA-256, assuming a fully reliable side channel) this would let the attacker extract the valid HMAC tag that the verifier produced for comparison against the attacker's guess at the HMAC tag.\u00a0 Since this is the HMAC tag over the attacker's chosen plaintext, this lets the attacker obtain a valid HMAC tag without knowing the HMAC key. Now, it seems clear that in the preponderance of BP deployments there will not be an effective side channel available!\u00a0 But IMO this still reflects a fundamental cryptographic weakness in the protocol and we should make some effort to address it.\u00a0 There are a couple potential mitigation approaches off the top of my head, which can be combined if desired: include a nonce as part of the HMAC input (and encourage rejection of reused nonces), and require constant-time comparison of the supplied and expected authentication tag (to prevent using a side channel from reading it off byte by byte).\u00a0 I suspect that there may be some operational issues with the \"unique nonce per HMAC\" approach that would make it not terribly reliable in practice, but \"use a constant-time comparison\" should be fairly straightforward. (D3) While we do provide the standard guidance against using any given key with more than one algorithm (e.g., with HMAC-SHA-256 and AES256-GCM), there seem to be additional considerations relevant to this protocol that merit further discussion in the security considerations. Specifically, we make provision for an AES-KW wrapped key to be included along with the security payload and mandate that if present, such a key be used.\u00a0 Given that the parameter holding the wrapped key does not seem to be bound to a given message, it seems fairly straightforward for an in-network attacker to \"slice and dice\" the ciphertext and wrapped key away from each other, and cause any wrapped key it has seen to be attempted to be used with a given algorithm+ciphertext.\u00a0 This, in turn, would provide attacker-induced key reuse across algorithms, which is something that we want to avoid.\u00a0 While providing full protection against key reuse with different algorithms would prove fairly challenging and probably require significant state on the verifier/security destination, we should at least have some discussion of the situation, and could provide some modest mitigation techniques such as using distinct KEKs for receiving wrapped keys that have different intended usage.\u00a0 That is, one KEK for receiving AES keys, another for HMAC keys, etc..\u00a0 Attaching context (intended algorithm, etc.) to the KEK allows such context to be indirectly attached to the received wrapped keys, which otherwise would come without much context for intended usage.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-07-13 04:35:36-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-29 07:39:45-07:00",
    "text": "Thank you for the work on this document. I'd like to discuss the following point. I also have some non blocking comments, which I hope will help improve the document. Francesca 1. ----- FP: I agree with my colleagues that extensibility should be considered for algorithms. This document defines BIB-HMAC-SHA2 and BCB-AES-GCM, with the algorithms these security contexts provide. Adding support for one algorithm would need to define a new security context. Wouldn't it make sense to, instead, provide a way to add algorithms to the existing algorithms? For example, defining an IANA registry for each security context with the IDs of algorithms supported (taken from COSE). 2. ----- \u00a0 \u00a0 \u00a0 - Bit 2 (0x0003): Security Header Flag. FP: This should be (0x0004) and not (0x0003) (and same in a later section). Also, this is not wrong, but the bitmaps (here and everywhere else) could also be represented as 0b0100 in CBOR diagnostic notation, which to me is clearer. 3. ----- \u00a0 \u00a0 \u00a0 - Bits 8-15 are unassigned. FP: I am wondering why the limit on Bit 15, marked as unassigned: I think it would make sense to say Bits 8 and higher are unassigned. (This change would need to be reflected in the IANA sections) 4. ----- FP: this might be me missing some fundamental reading from bpsec, but I see that the blocks are defined as CBOR sequences. However, that is only mentioned in the appendix (meant to be informative): \u00a0  represented using CBOR structures.\u00a0 In cases where BP blocks (to \u00a0  include BPSec security blocks) are comprised of a sequence of CBOR \u00a0  objects, these objects are represented as a CBOR sequence as defined \u00a0  in [ RFC8742 ]. Is this defined somewhere else? If yes, could you add a pointer to the doc where it is defined? If not, this should be clarified, and specified earlier in the text, say in sections 3 and 4. 5. ----- \u00a0 \u00a0  [1, b'Twelve121212'] / Initialization Vector /, FP: I think the IV value is wrong here and should be h'5477656c7665313231323132'.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-07-09 13:25:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-25 13:20:36-07:00",
    "text": "There are several references to the possibility that the AES-GCM API doesn't allow for separation of the tag from the cipher text. I have not heard of products with this API but will accept that they exist. But I'm confused as to the handling of this case: (4.4.1) says the tag MUST be CBOR encoded and (4.8.1) says the tag MUST be reported in the security result; but how is this possible if the tag is not extractable from the ciphertext? Moreover, shouldn't there be a parameter or a scope flag somewhere that tells the receiver if the tag is in the cipher text? It would be hard to discern the sender's API a priori!",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-07-15 07:40:35-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-01 00:53:13-07:00",
    "text": "Sections 5.2 and 5.3 declare new IANA registries with Specification Required policies.\u00a0  BCP 26  ( RFC 8126 ) says of such registries that \"clear guidance to the designated expert should be provided when defining the registry\", but none is provided here.\u00a0 While that's obviously not a MUST, I would like to have a short discussion about why no such guidance is appropriate (or get some crafted and added).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-26 15:23:11-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-20 19:12:54-08:00",
    "text": "Section 9.\u00a0 The primary impact of the manipulating writable nodes appears to be characterized as DoS.\u00a0 Don\u2019t the possible consequences also include the ability to leak traffic outside the trusted domain or to route traffic through arbitrary paths of the attackers choosing potentially enable on-path inspection or manipulation of traffic; or avoidance of security controls?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-07-19 09:30:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-14 02:37:14-07:00",
    "text": "Hi, Thanks for this document, I think that it is a helpful update.\u00a0 Disclaimer, I'm not a security expert, but I would like to discuss some of the  RFC 2119  constraints that have been specified please: (1)  I find some of the 2119 language to be somewhat contradictory: \u00a0 *\u00a0 Implementations MUST NOT negotiate TLS version 1.1 [ RFC4346 ]. \u00a0 *\u00a0 Implementations MUST support TLS 1.2 [ RFC5246 ] and MUST prefer to \u00a0 \u00a0  negotiate TLS version 1.2 over earlier versions of TLS. The second sentence implies that a TLS 1.2 is allowed to negotiate earlier versions of TLS, but a previous statement indicates that this is not allowed.\u00a0 A similar contradiction appears for DTLS: \u00a0  *\u00a0 Implementations MUST NOT negotiate DTLS version 1.0 [ RFC4347 ]. \u00a0  *\u00a0 Implementations MUST support DTLS 1.2 [ RFC6347 ] and MUST prefer to \u00a0 \u00a0 \u00a0 negotiate DTLS version 1.2 over earlier versions of DTLS. (2)   \t\u00a0  *\u00a0 New protocol designs that embed TLS mechanisms SHOULD use only TLS\t  \t\u00a0 \u00a0 \u00a0 1.3 and SHOULD NOT use TLS 1.2; for instance, QUIC [ RFC9001 ]) took\t  \t\u00a0 \u00a0 \u00a0 this approach.\u00a0 As a result, implementations of such newly-\t  \t\u00a0 \u00a0 \u00a0 developed protocols SHOULD support TLS 1.3 only with no\t  \t\u00a0 \u00a0 \u00a0 negotiation of earlier versions. Why is this only a SHOULD and not a MUST?\u00a0 If a new protocol (rather than an updated version of an existing protocol) was being designed why would it be reasonable to design it to support TLS 1.2?\u00a0 If you want to keep these as SHOULD rather than MUSTs then please can the document specify under what circumstances it would be reasonable for a new protocol design to use TLS 1.2. (3)  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  When TLS-only \u00a0 \u00a0 \u00a0 communication is available for a certain protocol, it MUST be used \u00a0 \u00a0 \u00a0 by implementations and MUST be configured by administrators.\u00a0 When \u00a0 \u00a0 \u00a0 a protocol only supports dynamic upgrade, implementations MUST \u00a0 \u00a0 \u00a0 provide a strict local policy (a policy that forbids use of \u00a0 \u00a0 \u00a0 plaintext in the absence of a negotiated TLS channel) and \u00a0 \u00a0 \u00a0 administrators MUST use this policy. The MUSTs feel too strong here, since there are surely deployments and streams of data where encryption, whilst beneficial, isn't an absolute requirement? In addition \"MUST be used by implementations and MUST be configured by administrators\" also seem to conflict, i.e., if the implementation must use it then why would an administrator have to enable it? (4)\u00a0   \u00a0  When using RSA, servers MUST authenticate using certificates with at \u00a0  least a 2048-bit modulus for the public key.\u00a0 In addition, the use of \u00a0  the SHA-256 hash algorithm is RECOMMENDED and SHA-1 or MD5 MUST NOT \u00a0  be used ([ RFC9155 ], and see [CAB-Baseline] for more details). So, for clarity, this would presumably mean that SHA-256 is also preferred over say SHA-512?\u00a0 Is that the intention?\u00a0 Or would it be better if the SHOULD allowed stronger ciphers?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-06 20:47:03-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-16 06:48:13-08:00",
    "text": "My apologies for placing a Discuss so close to the telechat.\u00a0 I believe that both of these topics are comparatively minor and should be easy to resolve, but that it's important for the document to have a clear answer for them. I ask this with nospecific answer in mind that I need to hear -- per my comments on \u00a75.1.3, what are the actual requirements on the (cryptographic) protection of the State Cookie?\u00a0 I feel like I got different signals from different parts of the document, and it would be good to have consistent messaging throughout. Section 15.5 establishes a registry for payload protocol identifiers, but I am not sure how this registry is supposed to be able to effectively avoid collisions when we do not specify the endianness in which the value is represented on the wire (per \u00a73.3.1).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-11-03 02:12:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 06:34:07-07:00",
    "text": "In Section 7. there is discussion that CCFB will replace the ECN FB format. I find that appropriate however there is one function in ECN FB format that is not discussed here. Section 7.2.1 in  RFC 6679  states An immediate or \u00a0 \u00a0 \u00a0 early (depending on the RTP/AVPF mode) ECN feedback packet SHOULD \u00a0 \u00a0 \u00a0 be generated on receipt of the first ECT- or ECN-CE-marked packet \u00a0 \u00a0 \u00a0 from a sender that has not previously sent any ECT traffic.\u00a0 Each \u00a0 \u00a0 \u00a0 regular RTCP report MUST also contain an ECN Summary Report \u00a0 \u00a0 \u00a0 (Section 5.2).\u00a0 Reception of subsequent ECN-CE-marked packets MUST \u00a0 \u00a0 \u00a0 result in additional early or immediate ECN feedback packets being \u00a0 \u00a0 \u00a0 sent unless no timely feedback is required. There are no specification in this document that says that on reception of ECN-CE marks the feedback packet should be sent using early or immediate. That might not be required given a correctly configured session, where reporting occur on the time scale. However, I think some discussion of the usage of early reporting for ECN-CE mark is needed if longer reporting intervals are used.  Where there any discussion in the WG of this subject?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-09 07:38:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-09 03:01:09-07:00",
    "text": "Thank you for the work put into this document. It is really easy to read. Nevertheless, I am balloting a DISCUSS (see below), I sincerely hope that I am wrongly asserting the lack of IPv6 support for CurveCP else the easy way to clear my DISCUSS would be to mention this limitation in section 3 even if the focus of this I-D is on the API. Please find below some non-blocking COMMENTs. An answer will be appreciated. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == I question the inclusion of CurveCP in the mix as per  https://curvecp.org/addressing.html  it does not seem to support IPv6. At the bare minimum, the I-D should mention this restriction in section 3. (and I hope to be corrected about CurveCP IPv6 support).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-04-18 08:33:08-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-04-18 08:32:30-07:00",
    "text": "[Authors:\u00a0 Thank you for the work!\u00a0 There's no action required from you.\u00a0 My opinion below is to be discussed with the IESG.] I found this document very informative, and there is value in publishing it as an RFC.\u00a0 However, I don't believe it can pass the rough consensus bar set by rfc8789  to become an IETF Stream RFC. As mentioned by the Shepherd, this document is a \"description by matter specialists of an externally-defined link-layer\".\u00a0 The technology described is an overview of work done elsewhere.\u00a0 There was no discussion of the content on the mailing list, which shows only two messages from non-authors: one asking  for more information; the reply was a pointer to the LDACS external  specification [1] -- the other was the single WGLC reply from the document shepherd [2]. I want to discuss this question with the IESG:\u00a0 Can the IETF reach rough consensus on a document that describes someone else's technology?\u00a0 This  document is akin to many others that have been published through the ISE as,  for example, a vendor's implementation of a specific protocol.\u00a0  My opinion is that documents that describe someone else's technology cannot be published as IETF RFCs given the requirement in  rfc8789 . [1]  https://mailarchive.ietf.org/arch/msg/raw/iyext4Ub8MgUjNYYPE7XOPpq1Y0 [2]  https://mailarchive.ietf.org/arch/msg/raw/L-ByflWTn_3vcGC8NNfMO-blkJU",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-05-12 06:30:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-04-18 08:33:08-07:00",
    "text": "[Authors:\u00a0 Thank you for the work!\u00a0 There's no action required from you.\u00a0 My opinion below is to be discussed with the IESG.] I found this document very informative, and there is value in publishing it as an RFC.\u00a0 However, I don't believe it can pass the rough consensus bar set by rfc8789  to become an IETF Stream RFC. As mentioned by the Shepherd, this document is a \"description by matter specialists of an externally-defined link-layer\".\u00a0 The technology described is an overview of work done elsewhere.\u00a0 There was no discussion of the content on the mailing list, which shows only two messages from non-authors: one asking  for more information; the reply was a pointer to the LDACS external  specification [1] -- the other was the single WGLC reply from the document  shepherd [2]. I want to discuss this question with the IESG:\u00a0 Can the IETF reach rough consensus on a document that describes someone else's technology?\u00a0 This  document is akin to many others that have been published through the ISE as,  for example, a vendor's implementation of a specific protocol.\u00a0  My opinion is that documents that describe someone else's technology cannot be published as IETF RFCs given the requirement in  rfc8789 . [1]  https://mailarchive.ietf.org/arch/msg/raw/iyext4Ub8MgUjNYYPE7XOPpq1Y0 [2]  https://mailarchive.ietf.org/arch/msg/raw/L-ByflWTn_3vcGC8NNfMO-blkJU",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-10-25 09:09:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-12 06:30:47-07:00",
    "text": "[I'm updating the text of my DISCUSS ballot from Apr/18.\u00a0 This is a clarification  to avoid misinterpretations when considering the ballot in a general context.] [Authors:\u00a0 Thank you for the work!\u00a0 There's no action required from you.\u00a0 My opinion below is to be discussed with the IESG.] I found this document very informative, and there is value in publishing it as an RFC.\u00a0 However, I don't believe it can pass the rough consensus bar set by rfc8789  to become an IETF Stream RFC. As mentioned by the Shepherd, this document is a \"description by matter specialists of an externally-defined link-layer\".\u00a0 The technology described is an overview of work done in another standards development organization (SDO)  [1].\u00a0 There was no discussion of the content on the mailing list, which shows  only two messages from non-authors: one asking for more information; the reply  was a pointer to the LDACS external specification [2] -- the other was the  single WGLC reply from the document shepherd [3]. I want to discuss this question with the IESG:\u00a0 Can the IETF reach rough consensus on a document that describes technology developed by a different  SDO?\u00a0  My opinion is that documents that describe technology developed by a different  SDO cannot be published as IETF RFCs given the requirement in  rfc8789 . [1]  https://www.ldacs.com/wp-content/uploads/2013/12/SESAR2020_PJ14_D3_3_030_LDACS_AG_Specification_00_02_02-1_0.pdf [2]  https://mailarchive.ietf.org/arch/msg/raw/iyext4Ub8MgUjNYYPE7XOPpq1Y0 [3]  https://mailarchive.ietf.org/arch/msg/raw/L-ByflWTn_3vcGC8NNfMO-blkJU",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-11-06 11:31:16-08:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 08:39:25-07:00",
    "text": "Firstly thank you to the authors of the document for the good work. I however must agree with Alvaro's ballot and further expand on it.\u00a0 I have a concern that publishing a document that merely describes an outside standard, that is not developed within the IETF, could open a significantly problematic door to people developing standards outside of the IETF, and then using a mechanism like this, to effectively get a rubber stamp on something that the IETF has no control over.\u00a0 To me, this document would seem better suited to the ISE rather than the IETF track.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-10-21 06:50:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 01:41:13-07:00",
    "text": "Thank you for the work put into this document. It is also important for the IETF to welcome new work. The content is really interesting to read (especially for a private pilot!); albeit, it appears more like a roadmap / plan to use IETF protocols for aviation rather than being focused only on LDACS. Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. I also support Alvaro Retana's DISCUSS on using the right publication stream, which should have been ISE in this case as often done for documents describing specifications done outside the IETF. I notice that this document as an \"unknown\" status for the consensus boilerplate and setting it to \"No\" (if possible) would probably address Alvaro's concern. Special thanks to: - Pascal Thubert for the shepherd's write-up including the WG consensus and the intended status.  - Carlos Bernardos for his INT directorate review at  https://mailarchive.ietf.org/arch/msg/int-dir/oRK9fXWx48Xj6VhdJMMarEPFB3c/  which also raises the same issue as Alvaro but also has other points deserving a reply I hope that this helps to improve the document, Regards, -\u00e9ric As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 4 Raising a DISCUSS just to get a discussion with authors, RAW WG, ICAO representatives, and the community: \u00a0 \"There is currently no \"IPv6 over LDACS\" specification \u00a0  publicly available; however, SESAR2020 has started the testing of \u00a0  IPv6-based LDACS testbeds.\" Is the plan to have this \"IPv6 over LDACS\" be specified in an IETF WG (e.g., intarea) ? Or will ICAO work alone on this specification (and perhaps not using the experience of the IETF community)? ## Section 5.2.1 Let me share Carlos' point, which I second (it would be enough to state the intention about MIPv6 to address it): - \"Technically the FCI multilink concept will be realized by multi-homed mobile IPv6 networks in the aircraft.\" --> how is Mobile IPv6 going to be used and which specific protocol of the Mobile IPv6 family? just MIPv6 and/or PMIPv6? implications on mobility and RAW are unclear at this point (probably this is for the RAW WG to evaluate, but just wanted to point it out).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-31 19:29:57-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 20:23:57-07:00",
    "text": "** With the upfront acknowledgement that I have little familiarity with LDACS, I had significant difficulty in assessing the alignment of most this document to the defined charter of RAW.\u00a0 It appears to me that only a narrow portion of the document is in-charter scope. References were provided for LDACS (e.g., [ICAO2015]), but as they were behind a paywall I was not able to review them.\u00a0 Relying primarily on Section 7.3 and Figure 3 of the [MAE20192], it appears that LDACS is a series of technologies that operate below layer-3.\u00a0 Operating on top of LDACS at layer3+ is the FCI.\u00a0 Section 4 reminds us that \u201cThe IPv6 architecture for the aeronautical telecommunication network is called the FCI.\u201d\u00a0  Per the RAW charter, \u201cRAW will stay abstract to the radio layers underneath, addressing the Layer 3 aspects in support of applications requiring high reliability and availability.\u201d\u00a0 With that in mind, I was looking for the in scope RAW work items to produce \u201cUse Cases, Requirements, Architecture/Framework Aspects for a Wireless Network, and an Evaluation of Existing IETF Technologies and Gap Analysis\u201d for technologies at or above layer 3.\u00a0 In Section 5.2.3, I first found specifics on FCI that appear to a use cases within that scope.\u00a0 In Section 7.3.3,\u00a0 there is text on the SNP which describes activity germane to handling layer-3 services.\u00a0 However, this section also excludes this work as out of scope -- \u201c[t]his work is ongoing and not part of this document.\u201d In my assessment the overwhelming majority of the text in this document is describing technologies and architecture not in RAW\u2019s in-scope remit of layer 3+.  If the WG finds documenting this otherwise paywalled information in an information document valuable, I see no issue keeping this material in an Appendix.\u00a0 However, the framing of this document needs to be clearer to highlight the in-scope materials around FCI. ** Section 9.\u00a0 Please explicitly document the Security Considerations of FCI (i.e., the IPv6/layer behaviors).\u00a0 Is that Section 9.2? -- Section 9, Per \u201cThese requirements imply that LDACS must provide layer 2 security in addition to any higher layer mechanisms\u201d, it isn\u2019t clear how this is in-scope given the remit of RAW (see above). -- Section 9.1 is helpful background but what of that applies to layer 3?\u00a0 The specifics in the threat analysis of [STR2016] and the advent of SDRs appears to be largely data link considerations. -- Section 9.2\u00a0 How does [MAE20181] inform layer 3 threats as it\u2019s explicitly focused on data link issues? -- Section 9.3.\u00a0 Which of these security objectives apply to the FCI? -- Section 9.5.3.\u00a0 Architecturally, it isn\u2019t clear how IPSec, TLS are being used by the FCI.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-03-10 02:50:56-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-07 08:46:13-08:00",
    "text": "Hopefully an easy one to fix or clarify: \u00a0  *\u00a0 The set of numbers is converted into a single number REST-method- \u00a0 \u00a0 \u00a0 set by taking each number to the power of two and computing the \u00a0 \u00a0 \u00a0 inclusive OR of the binary representations of all the power \u00a0 \u00a0 \u00a0 values. I just wanted to check that this is expressed the right way round?\u00a0 I read \"taking each number to power of two\" as meaning taking the square of each method number.\u00a0 Whereas, I would have assumed that what you mean is \"two to the power of each method number\", i.e., each REST method is indicated by a binary bit position in a potentially 64 bit number? E.g., a/led should be 2^0 | 2^2 = 5",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-06-03 07:50:59-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 05:43:41-07:00",
    "text": "Thank you for the work on this document. (This is a \"let's talk\" DISCUSS, which I don't expect to hold after the telechat) I wonder if it wouldn't make sense to add a step where IANA gets the help of the designated experts from each respective registry when elements are added to the DNS class or RR type registries, either by the experts creating the substatements to be added, or at least checking and confirming those created by IANA. A couple of minor comments below. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-06-17 01:37:06-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-03 04:16:19-07:00",
    "text": "Hi, One issue that I think we should should discuss and resolve (sorry for the late discuss ballot): In section 4, it states: \u00a0  \"status\":\u00a0 Include only if a class or type registration has been \u00a0 \u00a0 \u00a0 deprecated or obsoleted.\u00a0 In both cases, use the value \"obsolete\" \u00a0 \u00a0 \u00a0 as the argument of the \"status\" statement. I know that we have had some previous discussion on this on Netmod, but, if  draft-ietf-netmod-yang-module-versioning-02  gets standardized then it will effectively evolve YANG's \"status deprecated\" into \"must implement or explicitly deviate\" and YANG's \"status obsolete\" into \"must not implement\".\u00a0 It wasn't clear to me that marking one of these fields as being deprecated in an IANA registry would mean that existing implementations must stop using it if they migrate to a new version of the generated YANG module.\u00a0 Hence, I think that at this stage, it may be safer to map IANA \"deprecated\" into YANG's \"status deprecated\"?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-25 01:13:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-20 05:02:51-07:00",
    "text": "# GEN AD review of  draft-ietf-dnsop-dnssec-bcp-05 CC @larseggert Thanks to Linda Dunbar for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/TNMpPSf36E8i5Nt96FoRSlbjPFA ). ## Discuss ### \"Abstract\", paragraph 1 ``` \u00a0 \u00a0  This document describes the DNS security extensions (commonly called \u00a0 \u00a0  \"DNSSEC\") that are specified RFCs 4033, 4034, 4035, and a handful of \u00a0 \u00a0  others.\u00a0 One purpose is to introduce all of the RFCs in one place so \u00a0 \u00a0  that the reader can understand the many aspects of DNSSEC.\u00a0 This \u00a0 \u00a0  document does not update any of those RFCs.\u00a0 Another purpose is to \u00a0 \u00a0  move DNSSEC to Best Current Practice status. ``` I don't understand what \"move DNSSEC to Best Current Practice status\" means in terms of the standards track. I'm all for advancing the RFC set that makes up DNSSEC along the standards track, but BCP it not part of that track. Publishing a BCP that normatively references some DNSSEC RFCs isn't doing anything in terms of moving them forward. ### Section 1.1, paragraph 2 ``` \u00a0 \u00a0  The DNSSEC set of protocols is the best current practice for adding \u00a0 \u00a0  origin authentication of data in the DNS.\u00a0 To date, no standards- \u00a0 \u00a0  track RFCs offer any other method for such origin authentication of \u00a0 \u00a0  data in the DNS. ``` Just because no other standards track RFCs compete with DNSSEC does not mean it is a BCP. A BCP is something else, i.e. \"The BCP subseries of the RFC series is designed to be a way to standardize practices and the results of community deliberations.\" [ RFC2026 ] ### Section 1.1, paragraph 1 ``` \u00a0 \u00a0  However, this low level of implementation does not affect whether \u00a0 \u00a0  DNSSEC is a best current practice; it just indicates that the value \u00a0 \u00a0  of deploying DNSSEC is often considered lower than the cost. ``` Protocols aren't BCPs. HTTP isn't the \"best current practice\" for transporting HTML either.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-10-19 23:01:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-17 18:07:41-07:00",
    "text": "Since  draft-ietf-dnsop-rfc5933-bis  is in IETF Last Call now, I think it is worth waiting on and updating this text: \u00a0  The GOST signing algorithm [ RFC5933 ] was also adopted, but \u00a0  has seen very limited use, likely because it is a national algorithm \u00a0  specific to a very small number of countries. To add a reference that RFCXXX updates the GOST algorithms for DNSSEC (but that it is uncertain at this point whether it will be widely adopted) I could be convinced for this document to not wait, but then I do think this paragraph should state that it is NOT RECOMMENDED to implement  RFC5933  since the underlying GOST algorithms have been deprecated by its issuer.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-28 15:09:56-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-28 14:23:30-08:00",
    "text": "Section 5 refers to a \"max_packet_size\" transport parameter but I do not see that parameter defined in the registry or  RFC 9000 . It seems that a transport parameter of that name was present in earlier versions of  draft-ietf-quic-transport , but got renamed to max_udp_payload_size in the -28, so hopefully this is just a trivial rename.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-22 06:35:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-14 14:15:17-07:00",
    "text": "Its is good to see that this document has continued to improve since I read the early versions. However, there are some one issues we do need to discuss if they should be better handled before this document is ready for publication.  A significant security vunerability in PERC that should be made more explicit and is totally missing is the risks with compromised endpoints. Beyond the very evident thing that this endpoint can decrypt all media it receives there are far more sinister risk here. Namely the potential for injection of media that attempts to impersonate another endpoints media stream. Most of SRTP's cipher suits only use symmetric crypto functions, thus enabling anyone with the key to send a packet with any SSRC, and have that being accepted as that source. Where it is has no practical usage in point to point communication, in conferencing it becomes an issue. It allows the usage of media level replay or deep fakes to be used to create media streams that are injected into the media distributors using an SSRC of another endpoint.  The mitiagations that are missing from this document. The fact that a media distributor that is not compromised or collaborating with the compromised endpoint could actually prevent such media injection by applying source filtering of SSRCs and drop all that aren't associated with the endpoint. The other potential mitigation is to introduce another cipher suit that uses a non symmetric integrity protection mechanism, such as TESLA to prevent this type of injection.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-06-05 13:42:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 18:52:28-07:00",
    "text": "I support Magnus\u2019s DISCUSS about the need to further discuss the impact of a compromised/rogue end-point.\u00a0 In addition to the impersonation of others in the conference, I am wondering about the impact (perhaps a DoS?) of rogue client flooding the conference with EKT Key updates.",
    "type": "Discuss"
  },
  {
    "ad": "Adrian Farrel",
    "end": "2015-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2015-03-03 14:09:09-08:00",
    "text": "Thank you for this document. It is really helpful to have a clear introduction to LISP, and I appreciate the hard work that has gone into producing this text. I have a small Discuss that is easily fixed. The essence is that you  should limit this document to a description of LISP and not try to use it to bash other solutions. In Section 4.2 \u00a0  On the contrary BGP is a \u00a0  push architecture, where the required network state is pushed by \u00a0  means of BGP UPDATE messages to BGP speakers. You will be aware of  RFC 5291  and the use of ORF to make BGP a pull-mode protocol. (I won't say to you that LISP is push mode because a Map-Reply pushes  the mapping information from the map server to the client :-) So, my advice is to describe LISP in this document and to not make comments about other systems. It isn't a beauty contest and it isn't wise to try to say \"my system is better/different from yours\". The solution is to just remove this sentence. Similarly in 7.1 \u00a0  BGP is the standard protocol to implement inter-domain routing.\u00a0 With \u00a0  BGP, routing information are propagated along the network and each \u00a0  autonomous system can implement its own routing policy that will \u00a0  influence the way routing information are propagated.\u00a0 The direct \u00a0  consequence is that an autonomous system cannot precisely control the \u00a0  way the traffic will enter the network. \u00a0  As opposed to BGP, a LISP site can strictly impose via which ETRs the \u00a0  traffic must enter the the LISP site network even though the path \u00a0  followed to reach the ETR is not under the control of the LISP site. Let's not get into the \"BGP this, BGP that\" debate. Just remove the  first paragraph and the first four words of the second paragraph. That way you avoid all contention and write a document about LISP.",
    "type": "Discuss"
  },
  {
    "ad": "Alia Atlas",
    "end": "2015-04-14 12:05:24-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 07:14:04-08:00",
    "text": "I support Adrian's discuss.\u00a0 In a similar vein: In Sec 3.2: Please either remove the claim of \"Such LISP capable routers, in most cases, only require a software upgrade.\" or explain how you can justify the need to add and remove new encapsulations and handle the various flag triggers and caching at line rate.\u00a0 There is no need for such marketing in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-04-14 13:56:06-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-04 18:08:42-08:00",
    "text": "It appears the SecDir review didn't make it to LISP list for some reason.\u00a0 There is one important security request from Radia's review and many other good suggestions. https://www.ietf.org/mail-archive/web/secdir/current/msg05415.html Expanding the Security Considerations section would be helpful, here is the background on the request: There is a security considerations section, which focuses on a class of denial of service attacks. There are presumably security considerations sections in the other documents, including one that focuses entirely on security, so it is not necessary that all security issues be brought up here. That said, I think that if you were to write an \"introduction to security considerations\", there are more important ones than the DoS threat. in particular, as a routing protocol care must be taken to make sure a bad actor cannot attract someone else's traffic with mechanisms like those we are trying to address with BGP security. Much of the routing information is maintained in a database \"like DNS\". If it *were* DNS, DNSSEC could be used to address the integrity issues. If it is home grown, some equivalent mechanism will be necessary.\u00a0 Why not use DNS?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-19 09:25:57-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-05 15:07:49-07:00",
    "text": "I must apologize first to the authors. Many months ago I promised to send a diff with language improvements, and I did not do so. Unfortunately, I do think the document needs this and the amount is too much to leave on the RFC Editor. I will send a separate diff for language improvements to the authors and not further comment on language in my ballot here. [1] Section 2: It suggests a partial SPI match can be used, based on the assumption that the SPI number is known to have mostly zeros because the device only uses a hardcoded limited set (eg 257 to 260). While this is true for the outbound SPI, this may not be true for the inbound SPI, especially if the peer is not a \"minimal ESP\" device but a regular multipurpose OS. I think some clarification is needed for this minimum implementation optimization. [2] Section 2.1: \u00a0 \u00a0 \u00a0  SPI that are not randomly generated over 32 bits may lead to privacy \u00a0 \u00a0 \u00a0  and security concerns. The \"may lead to security concerns\" would be something that at the very least needs to be understood and specified in the Security Considerations section. If it is too difficult to determine the concerns, perhaps this optimization should be removed from the draft. \u00a0 \u00a0 \u00a0  As a result, the use of alternative designs requires careful security \u00a0 \u00a0 \u00a0  and privacy reviews. If it is known this proposal requires careful security reviews, were these done? If so, why not replace this warning of danger with the actual output of those reviews? If reviews were not done, it would imply this document hasn't fully worked out its Security Considerations. [3] \u00a0 \u00a0 \u00a0  SPI can typically be used to implement a key update What is a \"key update\" in this context? It seems this section is suggesting to use part of the SPI octet space to signal things to another part of the code on the device? If so, would that code part then clear out those overloaded SPI octets or would they go (unencrypted!) over the network for everyone to see? [4] \u00a0 \u00a0 \u00a0  While the use of randomly generated SPIs may reduce the leakage or \u00a0 \u00a0 \u00a0  privacy of security related information by ESP itself, these \u00a0 \u00a0 \u00a0  information may also be leaked otherwise. This is not a strong argument. This sentence and the entire paragraph really seem to want to say something like \"if you can see the network packets, the information leak would already be present by seeing the encrypted traffic, irrespective of whether the SPI is truly random or selected in a way that identifies the manufacturer\" [5] \u00a0 \u00a0 \u00a0  The security of all data \u00a0 \u00a0 \u00a0  protected under a given key decreases slightly with each message I do not know of a generic claim like this for ESP. Can a reference be provided? In general, rekeying is done to avoid decrypting previous traffic in case of a key compromise. Or perhaps you mean the limits of algorithms like AES_CBC (or 3DES) with respect to birthday and collision attacks? eg the commonly used maximum of 2^32-1 crypto operations (which is not the same as maximum packets) In these cases, the SN is only relevant for very high speed links, eg gbps and would never apply to an IoT device that requires minimal ESP. [6] As noted in the TSVART review: \u00a0 \u00a0 \u00a0  Also, for devices that spend significant time sleeping, the SN \u00a0 \u00a0 \u00a0  would jump hugely on first waking. That shouldn't require any \u00a0 \u00a0 \u00a0  larger window (unless a stale packet from prior to the sleep was \u00a0 \u00a0 \u00a0  only released after a new packet on waking). But the receiver \u00a0 \u00a0 \u00a0  would need to be able to somehow detect massive jumps in the high \u00a0 \u00a0 \u00a0  order bits that are not communicated in the SN field. Perhaps the document can add more specific detail on how to use the commonly implemented time values into valid SNs that avoid ESN issues ? [7] \u00a0 \u00a0 \u00a0  so the constrained device may not proceed to such checks The language issue here inverts the meaning. What is meant is \"so the constrained device may omit such checks\" [8] \u00a0 \u00a0 \u00a0  TFC has not yet being widely adopted for standard ESP traffic. It is widely implemented (eg in Linux). I agree that using it seems rare. I am not convinced the reason for this is as is written. The issue I think more relates to deciding to what size to pad. The easiest is to use the MTU, but due to various encapsulation techniques (ESPinUDP, PPP-OE) it is not always clear what the MTU of the IPsec link is. And path MTU discovery with IPsec does not really work in practice. But if the application/device tends to send packets between 1 and say 125 bytes, it could always pad to 125 to not leak any information by packet size. The question on when to do this or not really depends on the traffic being protected. And if this the case, then it might be best to let the IKEv2 negotiation determine whether or not to use this - just like regular use of TFC. Regardless, TFC is optional and a minimum implementation can just omit it. Since this document would also be combined with efforts reducing sending bytes to preserve energy, it would make sense to avoid using TFC padding. Especially for sensors that for example just always send a one byte temperature value to begin with. \u00a0 \u00a0 \u00a0  Such information could be used by the attacker in case a vulnerability is \u00a0 \u00a0 \u00a0  disclosed on the specific device. I don't think \"vulnerability\" here is the issue. It could lead to exposing the size of the original packet being protected by IPsec, which could (or could not) leak information to an observer on the network. [9] \u00a0 \u00a0 \u00a0  a minimal ESP implementation may not generate such dummy packet. I think what is meant is \"MUST NOT generate\". [10] The Next Header Section is better named Dummy Packet. While it discusses the mandatory Next Header field, it really only states not to send Dummy Packets. But it almost reads as if the Next Header can be ignored or omitted. [11] \u00a0 \u00a0 \u00a0  4.\u00a0 Avoid Padding by sending payload data which are aligned to \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the cipher block length - 2 for the ESP trailer. Isn't this advise just moving the padding from the IPsec layer to the application layer? Eg the packet size or energy use would not be different if one implements this advise? [12] Would it be useful to be able to signal a \"mininum ESP\" via IKEv2? I can imagine a simple Notify could be used to signal this. A peer receiving this could then ensure it is behaving in a \"minimum ESP\" compatible way even if it is a multi-purpose OS.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-12 10:39:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 19:42:05-07:00",
    "text": "** Section 5.\u00a0 The paragraph starting with \u201cAs the generation of dummy packets \u2026\u201d would benefit from refinement.\u00a0 It starts with saying dummy packets \u201cmay be avoided\u201d, but the second half of the paragraph argues the opposite.\u00a0 The use cases of constrained devices concerned about device lifetimes (first half of the paragraph) doesn\u2019t seem mutually exclusive from those with dedicated applications (second half).\u00a0 I recommend being cleared on the assumptions guiding the use of dummy packets.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-13 20:48:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-07 15:26:33-07:00",
    "text": "This being a discuss ballot notwithstanding, the protocol mechanisms here seem pretty well thought-out; I'm just wanting changes to how they are described. There seems to be an internal inconsistency in Section 4.3, between \"[t]he PCE SHOULD add the scheduled LSP into its scheduled LSP-DB and update its scheduled TED\" and \"[t]he stateful PCE is required to update its local scheduled LSP-DB and scheduled TED\".\u00a0 (I think the \"SHOULD\" one is wrong, personally.) Let's also take a closer look at the precise interdependency between the B bit and PD bit -- Section 5.1 implies that the PD bit itself cannot be set in the absence of the B bit, referring forward to Section 5.2.2, but Section 5.2.2 seems to only say that you need both the B and PD bits set in order to send SCHED-PD-LSP-ATTRIBUTE.\u00a0 Bits being set as a prerequisite for sending the TLV is a subtly different condition than having the one bit itself depend on the other, with correspondingly different error handling. Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-13 20:48:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-13 20:48:26-07:00",
    "text": "This being a discuss ballot notwithstanding, the protocol mechanisms here seem pretty well thought-out; I'm just wanting changes to how they are described. There seems to be an internal inconsistency in Section 4.3, between \"[t]he PCE SHOULD add the scheduled LSP into its scheduled LSP-DB and update its scheduled TED\" and \"[t]he stateful PCE is required to update its local scheduled LSP-DB and scheduled TED\".\u00a0 (I think the \"SHOULD\" one is wrong, personally.) Let's also take a closer look at the precise interdependency between the B bit and PD bit -- Section 5.1 implies that the PD bit itself cannot be set in the absence of the B bit, referring forward to Section 5.2.2, but Section 5.2.2 seems to only say that you need both the B and PD bits set in order to send SCHED-PD-LSP-ATTRIBUTE.\u00a0 Bits being set as a prerequisite for sending the TLV is a subtly different condition than having the one bit itself depend on the other, with correspondingly different error handling. Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 7.3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-04 18:16:39-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-13 20:48:57-07:00",
    "text": "[edited to fix a typo in the section number, but otherwise unchanged from the original position on the -19] This being a discuss ballot notwithstanding, the protocol mechanisms here seem pretty well thought-out; I'm just wanting changes to how they are described. There seems to be an internal inconsistency in Section 4.3, between \"[t]he PCE SHOULD add the scheduled LSP into its scheduled LSP-DB and update its scheduled TED\" and \"[t]he stateful PCE is required to update its local scheduled LSP-DB and scheduled TED\".\u00a0 (I think the \"SHOULD\" one is wrong, personally.) Let's also take a closer look at the precise interdependency between the B bit and PD bit -- Section 5.1 implies that the PD bit itself cannot be set in the absence of the B bit, referring forward to Section 5.2.2, but Section 5.2.2 seems to only say that you need both the B and PD bits set in order to send SCHED-PD-LSP-ATTRIBUTE.\u00a0 Bits being set as a prerequisite for sending the TLV is a subtly different condition than having the one bit itself depend on the other, with correspondingly different error handling. Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 7.3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-07 17:44:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-04 18:16:39-07:00",
    "text": "Thanks for addressing my first two discuss points from the -19; it looks like the last one is still remaining (please note that I had a typo in my original ballot on the -19, referring to a section 3.3 when 7.3.3 was intended): Section 6.6 refers to the \"LSP-ERROR-CODE TLV (Section 7.3.3) which is not defined in this document, rather, the reference should be to \u00a7 7.3.3 of  RFC 8231 .",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-05-12 07:22:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-12 02:52:25-07:00",
    "text": "I've been sitting trying to work out in my mind if a BCP document should be requesting code points - and if I should change the position from a no objection to a discuss - and the more I think about this - I feel that a discuss here is probably the right option.  I'd like to discuss if both the sections of the document that utilize normative language and require additional code points aren't better suited to a standards track document.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-05-29 12:09:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-10 11:23:14-07:00",
    "text": "#1:\u00a0 This document updates  RFC 5155  but has no Updates: clause and no reference of this in the Abstract. In case this would not be seen as an Update:able offense, then the text \"Note that this specification updates [ RFC5155 ]\" should be changed :)",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2018-01-10 08:05:19-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-09 20:33:00-08:00",
    "text": "[This is a DISCUSS-DISCUSS, since I don't know the answer to my question. I expect to clear it after a little discussion. Likely at the first indication that one or another ADs hold the clue that I am missing :-)\u00a0 ] Is it reasonable to have a Yang module for an experimental protocol in a standards track RFC? What would that mean from a protocol maturity perspective? (I refer to the module for dense-mode PIM ( RFC 3973 ).",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2018-03-23 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-01-11 04:57:54-08:00",
    "text": "hanks to J\u00fcrgen, who reminded me that the YANG doctor feedback has not been addressed or replied to.https://datatracker.ietf.org/doc/review-ietf-pim-yang-12-yangdoctors-lc-schoenwaelder-2017-12-20/",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-08 13:21:12-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-01-08 08:55:29-08:00",
    "text": "Hello,\u00a0 Thanks for your work on this draft.\u00a0 If you could please update the draft to follow the YANG security template and be sure to list out the nodes in each of the sections if they are sensitive or security related (graceful restart could do some damage, etc.), that would resolve my discuss.\u00a0 Here's a link to the template and I'm not sure if there is a later version posted somewhere. There seems to be a number of rw in this draft (with some overlap between modules), is that why this step was left out? https://tools.ietf.org/html/rfc6087#section-6.1 Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2018-01-10 14:27:31-08:00",
    "end_reason": "position_updated",
    "start": "2018-01-08 13:21:12-08:00",
    "text": "Hello,\u00a0 Thanks for your work on this draft.\u00a0 If you could please update the draft to follow the YANG security template and be sure to list out the nodes in each of the sections if they are sensitive or security related (graceful restart could do some damage, etc.), that would resolve my discuss.\u00a0 Here's a link to the template and I'm not sure if there is a later version posted somewhere. There seems to be a number of rw in this draft (with some overlap between modules), is that why this step was left out? https://tools.ietf.org/html/rfc6087#section-6.1 The update in this draft appears to be the current, but please correct me if I am wrong and there is a later template: https://tools.ietf.org/html/draft-ietf-netmod-rfc6087bis-10#page-52 Thanks!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-23 19:33:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-22 10:14:55-07:00",
    "text": "Sections 4.16 and 4.17 have some discussion that suggests that the respective extended errors apply only to the current \"local hop\" of a DNS query, and thus should not be propagated by a resolver/forwarder as part of a response.\u00a0 If so, this would be at odds with the discussion in Section 3 that leaves such bhavior as merely \"implementation dependent\" (giving some MAY-level options).\u00a0 I'm not sure what the intent is, here, so let's talk about whether there's anything that should change.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-24 12:51:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-23 19:33:09-07:00",
    "text": "Sections 4.16 and 4.17 have some discussion that suggests that the respective extended errors apply only to the current \"local hop\" of a DNS query, and thus should not be propagated by a resolver/forwarder as part of a response.\u00a0 If so, this would be at odds with the discussion in Section 3 that leaves such bhavior as merely \"implementation dependent\" (giving some MAY-level options).\u00a0 I'm not sure what the intent is, here, so let's talk about whether there's anything that should change. [Also reminding myself to check that the allocation policy/ranges are updated per Donald Eastlake's LC review]",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-24 14:32:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 00:10:11-07:00",
    "text": "Thank you for the work put into this document. The document is clear, easy to read and quite useful. I have a trivial to fix DISCUSS about  BCP14  (see below). I hope that this helps to improve the document, Finally, I loved reading the acknowledgements section ;-) Regards, -\u00e9ric -- Section 1.1 -- Trivial to fix: please use  BCP 14  boilerplate (see  RFC 8174 ).",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-03-11 10:20:28-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 13:58:12-08:00",
    "text": "(1) This specification should formally Update  rfc8402 . What is the relationship between this document and  rfc8402 ?\u00a0 If this document details the concept introduced in  rfc8402 , why isn't there a formal Update relationship? Even the initial definition of SR Policy in this document (\u00a72) doesn't match what  rfc8402  says.\u00a0 This document defines it as \"a framework that enables the instantiation of an ordered list of segments\", while  rfc8402  states it is \"an ordered list of segments.\"\u00a0 In \u00a72.2, this document uses the term  \"segment-list\" for that. Besides the general topic of clarifying and updating what an SR Policy is, this document also includes other items that were not present in  rfc8402 ; the list includes: \u00a0  \u00a72.1: \"SR Policy MUST be identified through the tuple .\"\u00a0  There's not even a mention of \"color\" in  rfc8402 . \u00a0  \u00a72.1: \"The headend is specified as an IPv4 or IPv6 address and is expected  \u00a0  to be unique in the domain.\"\u00a0 Neither the mechanism to identify a node nor  \u00a0  the expectation is present in  rfc8402 . \u00a0  \u00a72.1: \"The endpoint is specified as an IPv4 or IPv6 address and is expected \u00a0  to be unique in the domain.\"\u00a0  Same as above. The SR Database is a new element not in the base architecture.\u00a0 The text in \u00a73 says that \"use of the SR-DB for computation and validation of SR Policies is outside the scope of this document\", but it is then mentioned and used in \u00a75.1/\u00a75.2. Accordingly, the added details require additional Security and Manageability considerations. I couldn't find a related discussion in the archive.\u00a0 If I missed it, please point me in the right direction. (2) \u00a75.1: \u00a0  Types A or B MUST be used for the SIDs for which the reachability \u00a0  cannot be verified.\u00a0 Note that the first SID MUST always be reachable \u00a0  regardless of its type. These two requirements and the text in the description of these types (\"...does not require the headend to perform SID resolution.\") results in a  contradiction: Types A and B are not to be resolved, but if they are the first  SID then they MUST.\u00a0 If it's not a contradiction, then Types A and B would not  be allowed to be the first SID, which is not correct because the most  straightforward mechanism to define a path is to list SR-MPLS Labels or SRv6  SIDs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-24 18:04:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 22:16:18-08:00",
    "text": "(1) I may just be misunderstanding things, but I'd like to pull on a thread in \u00a78.4 a bit more.\u00a0 We say that the headend H learns a BGP route that has a VPN label V, but then the following procedures seem to say that we install a route on the appropriate SR Policy P and that when we receive a packet that matches the route in question, push a label stack including the VPN label, and send the resulting packet out.\u00a0 Nowhere do we say to check the VPN status of the incoming packet, so this seems like it would open a hole in the VPN by allowing \"arbitrary\" incoming traffic (not marked as specific to V) to enter that VPN.\u00a0 Is the label V filling some other role than identifying a specific VPN of many VPNs that could run along the route R/r? (This is the only instance of the phrase \"VPN label\" in the document, and no reference is given, so I'm relying heavily on instinct to ascertain the intent here.) (2) The security considerations says that this document does not define any new protocol extensions and (accordingly) does not introduce any further security considerations.\u00a0 The first part of this seems false, not least since we define the meaning of the \"CO\" bits in the Color Extended Community.\u00a0 I'm pretty sure that makes the second part also false, and we need to discuss the security considerations relating to imposing SR Policies based only on color and not next-hop.\u00a0 Alvaro has also noted additional aspects where security considerations are missing. (3) The Discriminator as defined in \u00a72.5 does not seem wide enough to be able to provide the needed properties.\u00a0 Some later clarification in \u00a72.6 implies that the definition in \u00a72.5 is incomplete and the width is actually appropriate, but in either case \u00a72.5 seems inadequate in its current form. (Details in the COMMENT.) (4) Section 2.11 contains the statement, \"A valid SR Policy is instantiated in the forwarding plane.\" Is this a statement of fact (i.e., a consequence of the definition of \"valid\") or a mandate for something (e.g., the headend) to take action to make it so?\u00a0 Given that the point of SR is to be stateless on nodes other than the headend, I suspect the former, but if we are relying on the headend (or some other entity) to take action to ensure this is the case, that needs to be a clearly stated normative requirement. (5) Section 8.4 uses the phrase \"any AFI/SAFI of LISP [ RFC6830 ].\" There's nothing in the IANA registry for SAFI ( https://www.iana.org/assignments/safi-namespace/safi-namespace.xhtml ) about LISP, and  RFC 6830  doesn't talk about SAFI.\u00a0 What is this referring to?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 20:33:03-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-24 18:04:55-08:00",
    "text": "[removing topics that are addressed; the below are (verbatim) copies from my ballot on the -17, for topics that remain open] (3) The Discriminator as defined in \u00a72.5 does not seem wide enough to be able to provide the needed properties.\u00a0 Some later clarification in \u00a72.6 implies that the definition in \u00a72.5 is incomplete and the width is actually appropriate, but in either case \u00a72.5 seems inadequate in its current form. (Details in the COMMENT.) (4) Section 2.11 contains the statement, \"A valid SR Policy is instantiated in the forwarding plane.\" Is this a statement of fact (i.e., a consequence of the definition of \"valid\") or a mandate for something (e.g., the headend) to take action to make it so?\u00a0 Given that the point of SR is to be stateless on nodes other than the headend, I suspect the former, but if we are relying on the headend (or some other entity) to take action to ensure this is the case, that needs to be a clearly stated normative requirement.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:52:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:51:37-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:52:45-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:52:06-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:53:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:52:45-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong.And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:53:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:53:04-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:54:00-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:53:30-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? \u2028\u2028If that\u2019s so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:54:31-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:54:00-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:55:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:54:31-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? If that's so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 08:55:57-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 08:55:40-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? If that's so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. - Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don't see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.  \u2028- Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don\u2019t see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.\u2028\u2028  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-03-22 11:18:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 08:55:57-08:00",
    "text": "I\u2019ve done an initial review of this document and have several concerns I\u2019d like to discuss. I apologize for not also providing a full review as comments in this ballot, I judged it more important to begin the discussion about these points timely, than to provide all comments in a single message.  1. The shepherd writeup indicates that \u201cStandard Track is requested and indicated in the title page header. This is appropriate for a specification of packet steering into an SR policy needing interoperability between the ingress/source of the policy instantiation and the egress/destination of the policy termination.\u201d\u2028\u2028  I realize it\u2019s unusual to ask to discuss a shepherd writeup rather than the spec itself, but I think this one rises to the level. My concern is that this description (needing interoperability between the ingress and the egress) doesn\u2019t comport with my understanding of the Segment Routing architecture. Surely, one of the key value propositions of SR is that it\u2019s stateless everywhere other than the headend? Indeed, that\u2019s stated in the abstract. SR doesn\u2019t require the egress to even understand that it IS an egress of a SR Policy, it just does what the headers tell it to, right? If that's so, then the rationale given for the requested track must be wrong. :-( And that in turn leads me to ask, whether the track really is right. It seems to me that in most respects this is more an Informational document than a standards track one. That\u2019s not a value judgement in any respect, just a statement of fact \u2014 for the most part, it doesn\u2019t seem as though the information found in this document is needed in order to interoperate with another system. (Section 8.8 is an exception, I discuss that separately.)\u2028\u2028 Anyway, not to get too far ahead of myself, let\u2019s start by working on this question: is the shepherd writeup correct in saying that interoperability between headend and tailend is required? If so, can someone please characterize the nature of that interoperability, and put it in the context of SR\u2019s stateless nature? 2. It seems to me an unusual practice for this document to be defining semantics and even reserving values in a field allocated by a different document, by a different WG. I\u2019m referring here to the so-called \u201c\u2018Color-Only\u2019 bits\u201d discussed in Section 8.8. \u2028\u2028 - I would be more comfortable if the work were all done in one place, to the extent possible. - Given the fact this document is reaching in to a registry normally managed by IDR, was there any discussion with the IDR group? I don't see any evidence of a courtesy notification of the last call when I look at the IDR mailing list archive.  I\u2019ve also emailed the IDR list about this in connection with  draft-ietf-idr-segment-routing-te-policy , see  https://mailarchive.ietf.org/arch/msg/idr/yCcZdStmTR-FLUYGHTsLLBv5aWo/ \u2028\u2028 Relating this back to my previous question, it\u2019s evident that if this document is going to define semantics for the Color Extended Community Flags, then that makes it Standards Track because there is an interoperability factor to take into account (that's been imported from IDR). A more ideal solution would be to take care of that in the IDR document rather than putting it in this \u201carchitecture\u201d document, though. Surely, this kind of detail is implementation, not architecture?\u2028 Indeed, Ketan said in his reply to Matthew Bocci's RTG review, \"Given that this is an architecture document, it describes the architecture and not really the protocol mechanisms\"... but this section seems to be an exception to that aspiration. 3. Related to the above, at least one of the references listed as informational clearly has to be normative with the document as it stands.  draft-ietf-idr-segment-routing-te-policy  is the one I\u2019m thinking of, for example its use in \u00a72.4 seems like it may rise to the \"normative\" level, \u00a72.5 almost surely does, \u00a74.1 surely does, and \u00a78.8.1 is the icing on the cake because this document defines semantics for a field that isn\u2019t even allocated until and unless  draft-ietf-idr-segment-routing-te-policy  is published.\u2028 4. In \u00a72.1 you talk about the signaling of symbolic names for candidate paths. Although you are careful to say that such symbolic names are only used for presentation purposes, it seems to me they still could be considered a new potential source of vulnerability, since a string that has no sanity-checking whatsoever applied by the protocol can display literally anything to an operator viewing it. Shouldn\u2019t this be addressed in your Security Considerations? (For an example of a related Security Considerations, see  RFC 9003 . It\u2019s probably not the best example, but it\u2019s the one I had at my fingertips\u2026)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-03-20 06:38:39-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 14:05:57-08:00",
    "text": "There appear to be a few places where additional pointers or specification is needed to ensure interoperability. ** Section 2.5 \u00a0  When signaling is via PCEP, the method to uniquely signal an \u00a0  individual candidate path along with its discriminator is described \u00a0  in [ I-D.ietf-pce-segment-routing-policy-cp ].\u00a0  Where is the explanation of discriminator in this reference?\u00a0 \u201cDiscriminator\u201d appears in Sections 3.1, 3.2, 4.1.2, and 5.2.2.\u00a0 In the first three section it is simply named but not explained.\u00a0 In the last section, it isn\u2019t explained beyond being defined as 32-bits. ** Section 2.6.\u00a0  \u00a0 Candidate paths MAY also be assigned or signaled with a symbolic name \u00a0  comprising printable ASCII [ RFC0020 ] [ RFC5234 ] characters How these candidate paths names are signaled isn\u2019t defined.\u00a0 I believe it is per Section 5.2.3 of  draft-ietf-pce-segment-routing-policy-cp  and Section 2.4.7 of draft-ietf-idr-segment-routing-te-policy. ** Section 2.7.\u00a0 How is the candidate path preference signaled?\u00a0 Is that  draft-ietf-idr-segment-routing-te-policy-14 #section-2.4.1 and  https://datatracker.ietf.org/doc/html/draft-ietf-idr-segment-routing-te-policy-14#section-2.4.1?",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2018-04-16 17:11:33-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-16 08:54:25-07:00",
    "text": "Please consider this to be an opportunity to explain something to an AD who doesn't understand codecs super well ... so I doubt it will be hard to clear my Discuss. I'm not entirely comfortable that Section 8 isn't normative. Is the theory that if (for example) I decide that my H.264 format parameter maps onto a codec-independent parameter that you don't think it maps to, then you and I probably would probably end up ignoring the rid and doing what we would do, if one of us didn't support rids? If not, what's supposed to happen (normatively)?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-06-25 22:58:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-21 06:19:43-07:00",
    "text": "Thank you for the work put into this document. The comparison between the IPv4aaS technologies is well done. Please find below some blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Ron Bonica for the shepherd's write-up and the justification for the intended status, I would have appreciated a little more text about the WG consensus though.  Authors may also expect an internet directorate review by Dave Lawrence, the delay in the review should not hinder the publication process though. Finally, I would like to apologise for not sending those comments earlier (just before telechat! there is NO need to reply immediately) but also during the WG process as I try to follow closely the V6OPS work. I hope that this helps to improve the document, Regards, -\u00e9ric As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 2.2 A important and trivial to fix \"translates the IPv4 payload to public IPv4 source address using a stateful NAPT44\" => \"translates the IPv4 source address in the payload to public IPv4 source address using a stateful NAPT44\" ## Section 3.3 \"Here, the centralized network function (lwAFTR or BR) only needs to perform stateless encapsulation/decapsulation or NAT64\", actually in MAP-T, BR does translation. ## Section 3.4 I am afraid that the number of IPv4 public addresses that are required goes beyond this \"simple\" computation. There are also other constraints such as laws, MoU, rules and operators BCP, see: -  https://bipt.be/operators/publication/consultation-of-11-october-2016-regarding-the-conditions-of-use-of-ipv4cgn  (alas in French/Dutch) but meaning that in my country, Belgium, an IP address can be shared by 16 subscribers max -  https://www.europol.europa.eu/media-press/newsroom/news/are-you-sharing-same-ip-address-criminal-law-enforcement-call-for-end-of-carrier-grade-nat-cgn-to-increase-accountability-online",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-06-16 13:50:49-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-18 19:23:00-07:00",
    "text": "** Section 4.7 notes detailed connection level logging of user behaviors.\u00a0 Please discuss the privacy and security implications \u2013 securing these logs at rest from unauthorized access, retention, etc.  ** Section 8. \u00a0  According to the simplest model, the number of bugs is proportional \u00a0  to the number of code lines.\u00a0 Please refer to Section 4.4.3 for code \u00a0  sizes of CE implementations. What is the intent of this text and how should the reader use it to choose a IPv4aaS? Taking the simple model above and the text from Section 4.4.3 (\u201c\u2026 17kB, 35kB, 15kB, 35kB, and 48kB for 464XLAT, lw4o6, DS-Lite, MAP-E, MAP-T, and lw4o6 \u2026\u201d), is it suggesting that 464XLAT the most \u201csecure\u201d protocol because it\u2019s code size the smallest?\u00a0 How does that metric work across different implementation?\u00a0 I recommend removing this text.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-06 19:33:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-12-16 14:36:01-08:00",
    "text": "I'm going to defer this document's evaluation because I think there are several interrelated subtle issues that merit closer consideration than has been given so far.\u00a0 I will also invite the TLS WG to provide input on these issues, since they relate to rather fundamental issues of the operation of the TLS sub-protocols. Most of them concern the Commitment Message, in terms of what goals it aims to achieve, how it is specified, and what mechanism is used to effectuate it. To start with the easy one: currently the way in which the structure of the Commitment Message is described makes reference to many fields of TLS Record Layer structures in order to specify what is fundamentally a message on the TLS Application Data stream.\u00a0 This is a layering violation; I don't see any reason to say more than what was suggested in https://mailarchive.ietf.org/arch/msg/emu/ECgvnq-C_VVXT5bpvOowte8LBjw/  : \"the commit[ment] message is a single byte of [value] 0 in the application data stream\".\u00a0 All the bits about cryptographic protection and expansion of the plaintext in prepararation for record protection are just adding noise, and the interface between the TLS stack and the application is supposed to be a data-stream abstraction, not a record abstraction. Next, the whole reason for the existence of a Commitment Message seems under-justified -- the only mention I could find in the document is that it serves \"to decrease the uncertainty for the EAP-TLS peer\".\u00a0 What harm would be caused by a lack of certainty in this area?\u00a0 Why does waiting for an EAP-Success or EAP-Failure not provide a similar level of certainty? The document also suggests in several places that the Commitment Message can or should be sent at 0.5-RTT data in the same flight as the server Finished.\u00a0 The intent, as determined from the mailing list archive, seems to be to save a round-trip compared to a typical full message flow where the server does not send application data until after the client's Finished (and any application data alongside it) is received.\u00a0 In particular, this came out during discussion of how a TLS \"close_notify\" alert would be unsuitable for the role of the Commitment Message, since sending the \"close_notify\" in 0.5-RTT would prevent sending an alert if the client authentication failed, and the diagnostic value of such alerts is significant.\u00a0 This is where the issues start to become interrelated -- the Commitment Message as a new application-data construct is for the objective of reducing the number of round trips. However, TLS session resumption is also designed to reduce the number of round-trips (including by no longer needing to send potentially large TLS Certificate messages that get fragmented at the EAP layer, with the cost of a round trip per fragment), and there is a nasty interaction between the two mechanisms.\u00a0 Specifically, TLS 1.3 session resumption requires the use of a NewSessionTicket message, which is associated with a resumption secret; the resumption secret, in turn, is not available in the key schedule until the client Finished (and client authentication messages, if any) is available.\u00a0 While it is possible in many Web scenarios for NewSessionTicket to be issued in the 0.5-RTT flight, this is because the server can precompute what the valid client Finished would be and use that in the key schedule to precompute the resumption secret.\u00a0 If the client is to be authenticated, as is the case for the vast majority of EAP exchanges, then such precomputation is impossible, and the session ticket cannot be issued until the extra round trip is completed.\u00a0 The document contains no discussion of the inherent tradeoff between sending the commitment message in 0.5-RTT and using resumption, and this tradeoff seems to call into question the merits of choosing this mechanism to implement the commitment message, since... The commitment message as specified seems to itself be a layering violation.\u00a0 The TLS protocol itself consists of a few sub-protocols, e.g., the handshake protocol, record protocol, and alert protocol.\u00a0 The operation of the handshake protocol is supposed to be completely independent of the application-data record protocol (except to the extent that the handshake protocol supplies the keys used for cryptographic protection of application data records).\u00a0 In particular, there should not be any interaction between the handshake state machine and the application data.\u00a0 If there is to be a commitment made about the operation of the TLS handshake protocol, that more properly belongs in the handshake layer itself, or perhaps the alert layer if it relates to the overall operation of the TLS connection.\u00a0 It seems inappropriate and unsustainable to expect that an application-data message would affect the operation of the handshake layer. The use of application data for the commitment message also may have unfortunate interactions with other TLS-using EAP methods, which is very briefly mentioned as a possibility but not explored at all: \u00a0  While EAP-TLS does not protect any application data except for the \u00a0  Commitment Message, the negotiated cipher suites and algorithms MAY \u00a0  be used to secure data as done in other TLS-based EAP methods. If we are to expect this construction of commitment message to become the de facto standard for using TLS 1.3 with EAP, I think we need to consider whether other EAP methods that do need to actually protect application data with the TLS connection will be affected by this proposal to insert the EAP commitment message into the application data stream.\u00a0 This is worth particular consideration given that we require that \"EAP-TLS peer implementations MUST accept any application data as a Commitment Message from the EAP-TLS server to not send any more handshake messages\" -- these seem like new semantics that might be quite unexpected if applied to other EAP methods. There's also a few internal inconsistencies that raise to a discuss-level and will need to be resolved before publication: The body text around Figure 3 indicates that mutual authentication should be depicted, but the figure shows only normal server-only authentication. The example in Figure 8 needs a TLS CertificateRequest in there in order for the rest of the flow to make sense. Section 2.1.4 says that \"TLS warning alerts generally mean that the connection can continue normally and does not change the message flow.\" but this is no longer true with TLS 1.3 -- the only alerts sent at warning level are \"close_notify\" and \"user_cancelled\", both of which indicate that the connection is not going to continue normally. Section 2.1.9 claims that the largest size of a TLS record is 16387 octets, but by my count a TLSCiphertext can get up to 16643, since the length field \"MUST NOT exceed 2^14 + 256 bytes\" (and there's the other 3 bytes of header). Please also check the statements made about  RFC 8446  that I note in my comments on Section 5.1.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-07 16:17:02-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 19:33:35-07:00",
    "text": "Many thanks for the updates since the -13, the last version I reviewed. I'm happy to report that the structural issues I noted in that version have been addressed, and my new Discuss point is a fairly mundane one. In several sections, we say that the text \"updates Section X of [ RFC5216 ] by amending it with the following text\", but I'm quite unclear on exactly what that is intended to mean.\u00a0 Are we adding to the end, prepending to the beginning, replacing wholesale, replacing in part, or doing something else to the indicated text of  RFC 5216 ?\u00a0 I expect that just tweaking a few words can resolve the ambiguity, but am not sure which ones yet. It is also interesting to contrast the \"amending\" language with what we say in Sections 2.1.4 and 2.3 about \"replacing\" text from  RFC 5216  and the various places where we report a \"new section when compared to [ RFC5216 ]\".",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-01-11 07:16:09-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-05 04:27:21-08:00",
    "text": "Thank you for updating EAP to support TLS 1.3. This document is outside my area of expertise, and others will be able to give a better technical review. However, I do think that it would be useful to have a brief discussion with the authors/ADs about the structure of the document.\u00a0 I.e., this document leaves  RFC 5216  as an active updated RFC, although that RFC depends on TLS version 1.2 ( RFC 5246 ) that is obsoleted by TLS 1.3. I also note that this document contains 30 pages of updates to an RFC that is only 32 pages long. Taking both of these into consideration, I think that it would be better (and longer term probably an easier reference) if this document could stand on its own, by obsoleting  RFC 5216  and including any text from  RFC 5216  that is still relevant when using EAP with TLS 1.3. I appreciate that this would be a significant change and hence would welcome input from the authors and other ADs as to whether this change would be worth the effort. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-27 20:24:51-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 15:00:23-08:00",
    "text": "(1) Section 8.6 seems to have some conflicting requirements.\u00a0 The filtered property map response \"MUST include all the inherited property values for the requested entities and all the entities which are able to inherit property values from the requested entities.\"\u00a0 We then go on to say that to do this, the server MAY follow three rules, that themselves include SHOULD-level guidance, but don't say how the MUST is achieved if the SHOULDs or MAY are ignored.\u00a0 I was expecting to see a construction of the form \"SHOULD do X, but if not, MUST do Y\". (2) Many of the examples in Sections 10.X do not seem to match up with the prose that describes them and the previous data tables that they are intended to illustrate (see COMMENT).\u00a0 We should make sure that the examples are internally consistent. (3) Section 4.6.2 says: \u00a0  *\u00a0 Last, the entity domain types \"asn\" and \"countrycode\" defined in \u00a0 \u00a0 \u00a0 [ I-D.ietf-alto-cdni-request-routing-alto ] do not have a defining \u00a0 \u00a0 \u00a0 information resource.\u00a0 Indeed, the entity identifiers in these two \u00a0 \u00a0 \u00a0 entity domain types are already standardized in documents that the \u00a0 \u00a0 \u00a0 Client can use. But earlier we said that \"the defining information resource of a resource-specific entity domain D is unique\", but this seems to be saying that the defining information resource of domains of the \"asn\" and \"contrycode\" type are *not* unique, by virtue of not existing at all.\u00a0 How can we rectify these two statements?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:37:53-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 10:35:38-08:00",
    "text": "Thank you for the work on this document. Many thanks to Spencer Dawkins for his thoughtful review:  https://mailarchive.ietf.org/arch/msg/art/BcZimefF1WXXgcmg0qjc3P__EGg/  , and thanks to the authors for addressing it. I have two blocking comments, and some non blocking comments (to which I would still appreciate answers) below. Francesca 1. ----- Media type registration FP: I haven't seen the media type being reviewed by the media-type mailing list, as requested by  RFC 6838 . Before progressing the document, I would really appreciate the authors to post the registrations to the media-type mailing list for review. 2. ----- Sections 4.6.1, 12.2.2 and 12.3 FP: The use of the term \"unique\" when referred to media types and entity domains (or properties) is confusing - it makes it sound as if the authors mean that each different entity domain (or property) is to be associated with a different unique media type, which doesn't seem to be the intent. As this is related to the media type registration, I believe this should be clarified and possibly checked with the media type experts (so it would be good to copy paste the relevant text in the email to the media-type mailing list).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-25 05:58:04-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:37:53-08:00",
    "text": "Thank you for the work on this document. Many thanks to Spencer Dawkins for his thoughtful review:  https://mailarchive.ietf.org/arch/msg/art/BcZimefF1WXXgcmg0qjc3P__EGg/  , and thanks to the authors for addressing it. I have two blocking comments, and some non blocking comments (to which I would still appreciate answers) below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- Media type registration FP: I haven't seen the media type being reviewed by the media-type mailing list, as requested by  RFC 6838 . Before progressing the document, I would really appreciate the authors to post the registrations to the media-type mailing list for review. 2. ----- Sections 4.6.1, 12.2.2 and 12.3 FP: The use of the term \"unique\" when referred to media types and entity domains (or properties) is confusing - it makes it sound as if the authors mean that each different entity domain (or property) is to be associated with a different unique media type, which doesn't seem to be the intent. As this is related to the media type registration, I believe this should be clarified and possibly checked with the media type experts (so it would be good to copy paste the relevant text in the email to the media-type mailing list).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:36:20-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-27 06:27:50-07:00",
    "text": "In the thread with the Gen-ART reviewer, the rationale that was given for advancing this document now even though rfc6834bis is nascent was: \"We do not expect big changes in any bis document, since they are just the PS version of deployed technology.\" This seems somewhat less likely given the feedback received on the LISP documents on the telechat this week, so I'd like to discuss whether it really makes sense to advance this one now given its normative dependencies on 6834bis and 6830bis.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-24 17:45:20-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-27 04:38:45-07:00",
    "text": "[Unlike for the 683xbis documents, this is a more mundane Discuss, with one process issue and one issue of clarity with respect to randomness requirements, that should be fairly easy to resolve.] I think that 8060 needs to be a normative reference; it seems to be needed to implement the Multiple Data-Planes LCAF type.\u00a0 Arguably 6040 also should be, though that seems less clear-cut to me. (8060 would be a new normative downref and require another IETF LC, IIUC.) Section 3 notes: \u00a0 \u00a0 \u00a0 The encoding of the Nonce field in LISP-GPE, compared with the one \u00a0 \u00a0 \u00a0 used in [ I-D.ietf-lisp-rfc6830bis ] for the LISP data plane \u00a0 \u00a0 \u00a0 encapsulation, reduces the length of the nonce from 24 to 16 bits. \u00a0 \u00a0 \u00a0 As per [ I-D.ietf-lisp-rfc6830bis ], Ingress Tunnel Routers (ITRs) \u00a0 \u00a0 \u00a0 are required to generate different nonces when sending to \u00a0 \u00a0 \u00a0 different Routing Locators (RLOCs), but the same nonce can be used \u00a0 \u00a0 \u00a0 for a period of time when encapsulating to the same Egress Tunnel \u00a0 \u00a0 \u00a0 Router (ETR).\u00a0 The use of 16 bits nonces still allows an ITR to \u00a0 \u00a0 \u00a0 determine to and from reachability for up to 64k RLOCs at the same \u00a0 \u00a0 \u00a0 time. That seems to be missing the point of the nonce -- it's not just for unique  identification but also to prevent off-path attackers from guessing a valid value and spoofing a bogus map-reply!\u00a0 Using the entire 64k of nonce space means that such a spoofing attack can succeed pretty reliably (e.g., by over-claiming so that the response EID-prefix contains whatever the request was for).\u00a0 I think it's important to accurately describe what properties are required of indivdiual nonces and the combined set of active nonces, which this text seems to mischaracterize.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-25 17:19:48-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-24 17:45:20-07:00",
    "text": "Thank you for the updates in the -08! Can you please say \"partially mitigates\" instead of \"mitigates\" in \"However, the use of common anti-spoofing mechanisms such as uRPF mitigates this form of attack.\"? Now that  RFC 8060  is a normative reference, it's a downref that I believe will need to be IETF LC'd again.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-09 05:43:27-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 02:14:55-07:00",
    "text": "Section 4.2: To me it looks like this is normative reference to the : Such new encapsulated payloads, when registered with LISP- \u00a0  GPE, MUST be accompanied by a set of guidelines derived from \u00a0  [ I-D.ietf-tsvwg-ecn-encap-guidelines ] and [ RFC6040 ].",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-19 10:38:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-19 09:38:02-07:00",
    "text": "Sorry not an expert on 802.1Q, however, I think section 4.2 would need to say more about HOW the PCP should be mapped to DSCPs.  RFC8325  has shown that there is usually no straight forward approach and therefore more guidance might be needed. Further, I would guess one would also need to define a more concrete mapping for section 4.3 but here I'm really not an expert at all.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-19 10:38:37-07:00",
    "text": "Thanks for addressing the TSV-ART review (and Magnus for doing the review)! I assume that the proposed text will be incorporated in the next version. (Would have been even better if those (larger) changes would have been added before the doc was put on the telechat; please update as soon as possible so other AD can review that text as well).  However, I think the text still needs to say more about HOW the PCP should be mapped to DSCPs.  RFC8325  doesn't provide guidelines but a mapping for 802.11. Is the same mapping applicable here? Also, I'm not an expert for that part, but I guess there also is further guidance needed on HOW to map the VID...?",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-11-19 19:39:11-08:00",
    "text": "Thanks for all the work on this over the years. I have a few concerns that I think require discussion prior to publication: \u00a75.7: Is the \"description\" field expected to be human readable? If so, are there internationalization issues to consider? \u00a76.2, 5th paragraph: This says that if you get an error back for a configure message, you send a new configure message. This seems likely to cause an infinite loop unless some guidance is given about escaping the loop when the endpoints cannot agree on a configuration. \u00a77:\u00a0 I\u2019m confused by the versioning mechanisms. This section requires an endpoint to ignore unknown elements, but it also requires the peer to downgrade to the highest shared version. These requirements seem to be at cross purposes. If the peer downgrades, one should only see unknown elements in the case of implementation errors. The requirement to ignore unknown elements does not come for free; nor does the requirement to downgrade. \u00a75.1 and \u00a78: The use of the options message to negotiate extensions seems underspecified. How does an endpoint compare extensionType elements?\u00a0 Is a spec required or expected? Is the extension spec expected to register the URI for schemaRef somewhere? Does this need to be in IANA?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-09 18:03:15-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 10:25:40-08:00",
    "text": "Thanks for the generally clear and well-written document! I would like to discuss whether there needs to be more prominent coverage of timers/timeouts, especially as relating to the state machines.\u00a0 (I'd be happy to learn that this is well-covered elsewhere in the document set; I just haven't run into it yet.) In a similar vein, do we want to have any treatment of avoiding infinite loops (e.g., when a 'configure' or 'advertisement' is rejected in expectation of modification but the sending implementation continues to generate an identical message)? It is not clear to me that any change to the document text is needed in either case, but I don't know to what extent the topics have already been discussed.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-10-31 12:38:01-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-31 12:31:39-07:00",
    "text": "This document does not discuss any interactions with the transport protocol (e.g. who establishes the connection? what happens if the connections breaks; who should re-establish?). Also, I assume that SCTP is used (instead of TCP) because the idea is to use different SCTP streams for the different directions of the communication...? However, this is a complete guess, as the document does unfortunately not say nothing about the mapping of CLUE messages to SCTP sessions. In case all message are assumed to be send over the same stream instead, why is SCTP used and not TCP? Please provide more information and guidance on the use of SCTP!",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2021-12-10 07:47:37-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-26 06:12:46-08:00",
    "text": "Hi, thank you for your work. I have two points I'd like to discuss with you: 1/ You write: \u00a0  If the value of the OptionLength field is not equal to 4, the BFD \u00a0  Discriminator PIM Hello option is considered malformed, and the \u00a0  receiver MUST stop processing PIM Hello options. Do you mean ignore all other options that would be in the PIM Hello message? I rapidly skimmed through 7761 and could not find such requirement nor an indication that documents defining new Hello options would have to define how to treat options when at least one is malformed. It may be that I simply failed to find the relevant text in PIM specs but I'd nevertheless appreciate if you could elaborate a bit on this. 2/ Twice you write that a PIM-SM router MAY/can become a head. First time in 2nd paragraph of 2.1, and the second time in 2.2. \"become\" gives a sense of automation, meaning without human intervention, and this is apparently confirmed by section 2.2 where becoming a head is driven by the node becoming a GDR. The issue I have is that 8562 is pretty explicit about the fact that the transition to Up state for a head is administratively controlled. You take great care in reusing that word (The head router administratively sets the bfd.SessionState to Up in the MultipointHead session) but I'm not sure this is sufficient to make this an administratively driven action. Maybe it's simply a discussion about the meaning of \"administratively\", but according to the understanding I have of this word (which is influenced by the typical use of it in router implementations), it seems to me that this document departs from 8562. Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-11-01 13:21:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-26 07:29:12-07:00",
    "text": "olding a discuss on my own document as a marker to ensure that the IANA Review completes.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-04-24 05:52:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 06:45:56-07:00",
    "text": "Apologies as this may be a really silly question, but isn't it possible for traffic-rate-bytes and traffic-rate-packets to interfere with each other? That is, if by mistake a flow specification shows up containing both actions and they contradict each other (e.g., 0 bytes but 1M packets), how is that situation supposed to be handled?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-23 18:45:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-22 17:42:18-07:00",
    "text": "There might be a minor internal inconsistency to tidy up (or I might be misunderstanding things).\u00a0 Section 8 states that: \u00a0  Contrary to the behavior specified for the non-VPN NLRI, Flow \u00a0  Specifications are accepted by default, when received from remote PE \u00a0  routers. As far as I can tell, this is referring to the text in Section 6 where (for the non-VPN case) \"By default a Flow Specification NLRI MUST be validated such that it is considered feasible if and only if all of the below is true [...]\".\u00a0 But immediately following what I quote above is a statement that \"the validation proceure (section 6) [...] [is] the same as for IPv4\", which seems to be in conflict with this statement (\"contrary to\" vs. \"the same as\").",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-24 06:50:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-04-24 06:46:49-07:00",
    "text": "Thank you for the work put into this document. The document is clear, easy to read (I appreciated the given examples). Alas, due to overload of work, I had only a quick browse through the document with specific focus points and found nothing EXCEPT why having two different documents ? One for IPv4 and one for IPv6... I am more than surprized... hence my DISCUSS... This blocking DISCUSS can easily be fixed: e.g., with a RFC Editor note to make a cluster of this document and  draft-ietf-idr-flow-spec-v6  so that they are published together with adjacent RFC numbers. Please find below a couple on non-blocking COMMENTs. I hope that this helps to improve the document, Regards, -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-04-27 08:57:12-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-24 06:50:16-07:00",
    "text": "Thank you for the work put into this document. The document is clear, easy to read (I appreciated the given examples).  Alas, due to overload of work, I had only a quick browse through the document with specific focus points and found nothing EXCEPT why having two different documents ? One for IPv4 (with the core elements of the protocol) and one for IPv6 (with only the IPv6 specifics)... I am more than surprized to say the least... hence my DISCUSS... This blocking DISCUSS can easily be fixed: e.g., with a RFC Editor note to make a cluster of this document and  draft-ietf-idr-flow-spec-v6  so that they are published together with adjacent RFC numbers. Merging the two documents would be preferred but I understand that this is more work (albeit a missed opportunity). Please find below a couple on non-blocking COMMENTs. I hope that this helps to improve the document, Regards, -\u00e9ric",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-04-27 09:50:59-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-24 02:47:23-07:00",
    "text": "I don't know if this is a valid discuss point, so happy to be educated that it is always written this way and I'll remove my discuss ... I note that in 5 places this document has text that states the equivalent to \"SHOULD be set to 0 on encoding, and MUST be ignored during decoding.\" (example given below). Doesn't this make extending this in future more risky because if new meaning are given to these bits then there could be senders already transmitting non 0 values which a receiver might then misinterpret? Hence, I was surprised that the constraints did not also include a MUST on the encoding side (i.e. be strict in what you send ...), i.e. \"MUST be set to 0 on encoding, and MUST be ignored during decoding.\" Example: \u00a0  The extended is encoded as follows: \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |\u00a0  reserved\u00a0 \u00a0 |\u00a0  reserved\u00a0 \u00a0 |\u00a0  reserved\u00a0 \u00a0 |\u00a0  reserved\u00a0 \u00a0 | \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0  |\u00a0  reserved\u00a0 \u00a0 | r.|\u00a0 \u00a0 DSCP\u00a0  | \u00a0 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Figure 6: Traffic Marking Extended Community Encoding \u00a0  o\u00a0 DSCP: new DSCP value for the transiting IP packet. \u00a0  o\u00a0 reserved, r.: SHOULD be set to 0 on encoding, and MUST be ignored \u00a0 \u00a0 \u00a0 during decoding.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-21 15:28:20-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 13:29:48-07:00",
    "text": "The prose and tabular IANA considerations in \u00a711.3 are inconsistent about whether the End.X/LAN End.X SID sub-TLVs are allowed to appear in TLV 25.\u00a0 (I may have noted all instances in the prose, in my COMMENT, but it's worth checking for others.)",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-06-21 15:48:51-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 18:58:26-07:00",
    "text": "[ section 9 ] * I share the concerns of several of the others here about SRv6 SIDs being \u00a0 claimed to be IPv6 addresses but kinda not really being IPv6 addresses \u00a0 if their internal structure is exposed outside of the given SR router. \u00a0 If \"[i]t's usage is outside of the scope of this document\", can this be \u00a0 removed for now, and maybe take up the issue at some point in the future \u00a0 by which time a motivating use case might have presented itself?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-10-20 01:39:46-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-18 14:57:43-07:00",
    "text": "Thanks for the work on this document. I was not around for  RFC 8986 , and I am not sure I understand the use case fully (I agree with Ben there), but I'll trust the responsible AD and the wg. I'll also note that I was hoping to see \"Implementation status report\" in the draft, as mentioned in the shepherd writeup, and was disappointed not to find any. However, I'd like to discuss a number of points, mostly on the IANA considerations and on detailed fields descriptions. I also want to bring 7. below regarding the IANA registries names to your attention, although it's not a hill I am willing to die on (that one is a \"let's talk\" DISCUSS, the rest I hope can be acted upon). As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- Section 7.1 FP: The locator entries ASCII figure is not consistent with the descriptive text following it: specifically, Loc Size should follow Algorithm directly; instead, the picture seems to show there are 2 octets unused between Algorithm and Loc Size. 2. ----- \u00a0 \u00a0 \u00a0 Type: 5. FP: For consistency (and to make sure implementers don't rely on the ASCII figure), it would be good to indicate Type's length (1 octet I assume). 3. ----- \u00a0 \u00a0 Length: variable. FP: This does not help much understanding what this field is supposed to contain. 4. ----- Section 7.2 FP: Same issue as in 1. for the ASCII figure. 5. ----- Sections 8.1 and 8.2 FP: Same comments as 1. 2. and 3. 6. ----- \u00a0 If a behavior is advertised it MUST \u00a0  only be advertised in the TLV[s] as indicated by \"Y\" in the table \u00a0  below, and MUST NOT be advertised in the TLV[s] as indicated by \"N\" \u00a0  in the table below. FP: I find the sentence after the comma confusing, and don't understand the presence of the MUST NOT here. 7. ----- Section 11.1.1 FP: It sounds like a bad idea in general to have to rename the registry every time a TLV needs to be added to the registry... Maybe the wg and the AD should consider renaming the registries so not to have this sort of dependency. (I understand that this is a low priority comment, but still, it feels wrong to put in titles what would fit really well in a registry itself). This very much applies to Section 11.6 as well: the registry's name with the hierarchy of TLVs as part of the name feels like a really bad idea. That is typically data that goes into registries. 8. ----- Section 11.3 FP: The registry needs to be defined in the document. In particular, I see that IANA is interpreting the columns as \"Value\" \"Description\" \"Reference\"; is that right or should this be \"Type\" \"Description\" \"Reference\" (I see a mix of the two for different IANA registries)? 9. ----- Section 11.8 FP: Are bits 0, 2-15 reserved or unassigned? The terminology in section 2 is ambiguous, as it talks about \"reserved for future use\" (but the IANA section leaves them unassigned). Please clarify for IANA. 10. ----- Section 11.10 FP: Please define the registry (I assume it is going to be \"Bit #\", \"Name\", \"Reference\").",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-13 21:14:36-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 22:24:52-08:00",
    "text": "The original IAB charter in  RFC 2850  claims that the IAB is chartered both as a committee of the IETF and as an advisory body of the Internet Society. Can we change the charter and retain this dual status, without approval of the Internet Society? It seems this was already considered, in https://mailarchive.ietf.org/arch/msg/rfced-future/RMeW4u_-ZbeJ23oYUcZ9ZAg2kkY/  , but the mailarchive does not seem to find any evidence that any action was taken to consult the ISOC Board.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-03-10 07:53:42-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-08 23:10:46-08:00",
    "text": "his doc has a DOWNREF to Informational draft-iab-rfcedp-rfced-model,which I failed to include in the Last Call message.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-10 15:35:02-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-10 12:38:34-07:00",
    "text": "Do not panic! This should be trivial to address, probably by pointing me at something that I missed (very likely), or by dropping in a sentence to two into the document. The document starts off with: \"This document describes a method to transport Internet Key Exchange Protocol (IKE) and IPsec packets over a TCP connection for traversing network middleboxes that may block IKE negotiation over UDP.\" As far as I can tell (and again, it is likely that I missed something!) it doesn't really discuss the fact that the operator may be intentionally blocking IKE. For example, many enterprises really don't want their users to be building IPSec tunnels into/out of their network because they want to do DLP, firewalling, and so they block IKE to block IPSec. This may be a flawed concept, and you and I may think that it's a losing battle, but I really think that the document needs to at least discuss that this potentially bypasses intentional security controls. See:  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-09-14 14:45:07-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-14 14:25:46-07:00",
    "text": "(0) (I came to this realization rather late in my review process, so there may be places where the COMMENT and this discuss point are in disagreement; this DISCUS takes precedence.) I fear that the construction that separately distributes ENC_KEY and MAC_KEY in an attempt to achieve privilege separation is fatally flawed. In particular, the CBC encryption mode is a malleable encryption mode, in that flipping a bit of ciphertext will filp the corresponding bit of the next block of recovered plaintext (at the cost of completely garbling the recovered block containing the bit that was modified). Subsequent blocks are unaffected.\u00a0 Typically we combine CBC mode with a MAC such as HMAC in order to prevent such modifications from being exposed as attack vectors, and while we do use HMAC here for that purpose, we also introduce a separate class of actors that have access to the HMAC key but not the encryption key.\u00a0 Accordingly, those actors can produce a new, valid, integrity tag after making a modification to the ciphertext, allowing them to engage in attacks that make use of ciphertext malleability.\u00a0 Ciphertext malleability is particularly useful as an attack vector when the structure of the plaintext being encrypted is known, and there are portions of the plaintext that the application will either ignore if they are garbled or are expected to be near random in the normal case (and thus for which garbled output does not cause rejection by the application).\u00a0 In a SFC environment it seems highly likely that the structure of the plaintext will be known or guessable, and we don't have any real mechanisms to control what types of metadata go into encrypted context headers, so it seems that we must act as if we are exposed to this risk. While \u00a74.3 does have a note that use of GCM with HMAC is undesirable due to the additional authentication tag, it may be unavoidable in order to provide the properties that we need. (1) Section 5.1 describes the MAC as: \u00a0  Message Authentication Code:\u00a0  Covers the entire NSH data, excluding \u00a0 \u00a0 \u00a0 the Base header.\u00a0 The Additional Authenticated Data (defined in \u00a0 \u00a0 \u00a0 [ RFC7518 ]) MUST be the Service Path header, the unencrypted \u00a0 \u00a0 \u00a0 Context headers, and the inner packet on which the NSH is imposed. This description seems to exclude from the MAC most of the MAC context header itself (if we go by the corresponding figure), which is very bad for security.\u00a0 We definitely need to include under the MAC the MAC context header bits from metadata class through and including at least timestamp, and I think IV length as well.\u00a0 (The IV itself would be incorporated via the ciphertext, since the IV is an input to encryption, but since the IV length field indicates whether or not encryption was performed, we'd need to protect that information.) Similarly, Section 5.2 has the description: \u00a0  Message Authentication Code:\u00a0 Coves the entire NSH data.\u00a0 The \u00a0 \u00a0 \u00a0 Additional Authenticated Data (defined in [ RFC7518 ]) MUST be the \u00a0 \u00a0 \u00a0 entire NSH data (i.e., including the Base Header) excluding the \u00a0 \u00a0 \u00a0 Context Headers to be encrypted. which on the face of it includes the field that holds the MAC itself (and is not yet populated), i.e., is self-referential. I think we need to be much more precise about the construction of the AAD in both cases.\u00a0 It's possible that the HMAC construction for the no-encrypted-context-headers case can inherit a definition from the AAD description, but if not we'll need to have some more precision there as well. (2) In order for the MAC-only construction in \u00a77.2 to be compatible with the AEAD integrity tag construction, we would need to include the 64-bit AL after A.\u00a0 While HMAC is intrinsically immune to length-extension attacks, I think that having the explicit AL is useful to avoid any risk of malleability, since the same MAC_KEY is used for constructing both types of MACs. (3) Section 5.1 describes the Timestamp field as an \"unsigned 64-bit integer value\", which is inconsistent with the actual format given in Section 6. (4) Section 7.5 directs the verifier to check if \"the value of the newly generated digest is identical to the one enclosed in the NSH\".\u00a0 It is critical for the security of the system that this comparison be done in a constant-time manner that does not provide a side channel into whether the generated digest and the value in the NSH share a common substring. (5) Do the MAC context headers always have to be the last metadata entries in the packet (to simplify the cryptographic calculations)? Certainly the diagrams only show \"unencrypted context headers\" appearing prior to the MAC context header, so if we expect unencrypted context headers to appear after the MAC context header as well, we should be clear about that both in the figures and in the specification for how to prepare the AAD.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-09-13 06:54:22-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-13 05:17:34-07:00",
    "text": "Thank you for the work put into this document. Special thanks to Greg Mirsky for his shepherding especially about his summary of the WG consensus. Please find below some blocking DISCUSS point (which should be easy to fix), some non-blocking COMMENT points (but replies would be appreciated), and one nit. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == I failed to spot the order of the operations for the integrity and confidentiality operations, e.g., I did not find on what the HMAC is computed: in the unencrypted or encrypted field ? -- Section 5.1 -- What is the unit of \"key length\", I assume a length expressed in octets but it is not specified. -- Section 7.2 -- What is the \"A\" used in the HMAC computation ? The formula specifies HMAC-SHA-256-128() but what if another HMAC is used ? Section 7.3 use MAC() which is more flexible. As the MAC field is included in the integrity protected header, please specify the value of this field when computing the HMAC (I assume 0 but let's be clear) -- Section 7.5 -- What is the expected behavior when a NSH does not contain a \"MAC and Encrypted Metadata\" Context Header ? \u00a71 hints to packet drop ? Should there be a local policy for this case ?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-07-26 10:25:44-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-14 23:13:29-07:00",
    "text": "Enough other Area Directors have said, and I agree, that this should officially update  RFC 8300 , so I'd like to have the discussion.\u00a0 In particular, given that this was identified as a gap in  RFC 8300 , and since I don't see any explicit statement that this is meant to be an optional extension, shouldn't it be an update?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-09-18 14:14:55-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-13 12:02:24-07:00",
    "text": "** Section 4.6.\u00a0 This section explains that an upper NSH can be encapsulated in a lower NSH, and that \u201cthe Upper-NSH information is carried along the lower-level chain without modification.\u201d\u00a0 I read this to mean that the upper and lower NSH can independently be protected with different keys.\u00a0 The text even helpfully points out that \u201cKeying material used at the upper-level domain SHOULD NOT be the same as the one used by a lower-level domain.\u201d\u00a0 Such a construct suggests that there are multiple MAC/Encrypted Metadata context headers, one for the upper and another for the lower.\u00a0 However, Section 7.1 later notes that \u201cOnly one instance of \"MAC and Encrypted Metadata\" Context Header (Section 5) is allowed.\u201d\u00a0 This seems like conflict.\u00a0 What am I missing? ** Section 7.2.\u00a0 On computing the HMAC in an integrity only situation: -- This section defines the MAC as \u201cT = HMAC-SHA-256-128(MAC_KEY, A)\u201d.\u00a0 Previously, A was defined as the Additional Authenticated Data (per Section 4.2).\u00a0 Since this isn\u2019t the AEAD use case, there is no A. It seems that this should be something closer to: \u201cT = HMAC-SHA-256-128(MAC_KEY, )\u201d. -- The text would benefit from a description on how to serialize the packet for hashing.\u00a0 For example, Figure 6 and 7 are helpful logical descriptions of the integrity scope.\u00a0 However, the MAC field itself is depicted as part of the what should get hashed.\u00a0 Should that field be zeroed out? Removed?  ** Section 9. \u00a0  The attacks discussed in [ I-D.nguyen-sfc-security-architecture ] are \u00a0  handled owing to the solution specified in this document, except for \u00a0  attacks dropping packets.\u00a0  The above reference highlights the following attackers \u2013 \u201cThere are many types of compromised switches attack: packet dropping, packet duplicating, packet manipulating, incorrect forwarding,\u00a0 eavesdropping, weight adjusting, man-in-the-middle, state-spoofing, control-channel hijacking, etc.\u201d\u00a0 Per the security services in this document, it doesn\u2019t seem like all are mitigated by this draft as described above: -- packet dropping = noted as not being handled -- packet manipulating, eavesdropping, weight adjusting, man-in the-middle, state-spoofing, and control-channel hijacking = appear to be handled if both security services are applied -- packet duplicating = this draft doesn\u2019t not provide a standardized approach for mitigating this issue -- incorrect forwarding = doesn\u2019t appear to be mitigated.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-10 23:22:38-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-06 13:45:04-08:00",
    "text": "This is very much a \"discuss discuss\", and I am not strongly convinced that there is a problem here, but if there is a problem it is a fairly big one. This document defers creation of a downgrade protection mechanism for version negotiation; after all, if there is only one version in existence, there is nothing to negotiate.\u00a0 However, an effective downgrade protection mechanism requires support from all potentially affected parties in order to be reliable, so some careful thought is in order.\u00a0 If we limit ourselves to a mindset where QUIC versions are infrequent undertakings brought about by standards action (i.e., we don't have to worry until a \"v2\" exists), then deferring seems to be okay (but part of the Discuss is to confirm that my reasoning is valid). The main goal of downgrade protection is to be able to distinguish a node that only supports v1 (or in general, any single version, or set of versions that only has one overlapping version with the peer) from one that supports a different shared version but was tricked by an attacker into using v1 when it otherwise would have used a different version. I'll call that different version v2 for clarity.\u00a0 However, if the peer only supports v1, there's nothing to distinguish and nothing to negotiate; it suffices to ensure that all nodes that are capable of v2 support the downgrade protection scheme.\u00a0 That is, an attacker can only change the negotiated protocol version (as opposed to just causing connection failure, which can be done in many other ways) if there is some shared version other than v1 that would have been negotiated in the absence of the attacker.\u00a0 So, if v2 is definitly going to be defined+implemented before other versions, and all nodes that support v2 support downgrade protection, we are guaranteed that in any case where two peers would negotiate v2 in the absence of an attack, both peers support the downgrade protection mechanism and thus that mechanism will be effective in the face of an attack.\u00a0 Peers that don't support the mechanism only do v1 and so there is no downgrade possible when they are participating in the connection.\u00a0 (We would, of course, still need to be confident that we could define such a downgrade protection scheme in a backwards-compatible manner, though this seems like a fairly low bar given the extensibility provided by transport parameters and frame types.) However, it's not clear to me that this assumption holds that v2 is going to be the next version and that every node that implements v1 and some other version will definitely implement v2.\u00a0 In particular, we currently have a very open registration policy for new versions, and there may be a desire to have some custom version of QUIC, perhaps that only has a small difference from v1, and furthermore a desire to use that custom version when available but be able to use v1 when not available.\u00a0 There might be multiple such new versions in development in parallel, with no clear \"first new version\" tasked with the responsibility to develop a downgrade protection mechanism for global use.\u00a0 The interaction between multiple competing downgrade-protection mechanisms seems likely to become quite messy quite quickly, so I am inclined to see \"make each non-standards-track version specify their own downgrade protection\" as a non-starter. I think that the lack of a secure downgrade protection mechanism is fundamentally incompatible with an open procedure for creating new versions while claiming that the protocol is a secure protocol.\u00a0 While it would not be a pleasant choice, I think we might be forced to require standards action for new QUIC versions until we have a single global downgrade protection mechanism defined.\u00a0 Or perhaps I misunderstand the ecosystem that we are trying to produce, or am making erroneous assumptions.\u00a0 I'd love to hear more about how the WG decided to proceed with the current formulation, especially with regard to what consideration was given to non-standards-track new versions. The above notwithstanding, I support this protocol and I expect to change my position to Yes once this point is resolved in some manner.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-14 01:06:10-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-07 07:06:19-08:00",
    "text": "olding a discuss to verify the IANA question is standards action registries should mandate the experts review prior to the standards action.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-01-08 05:22:04-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-06 09:43:05-08:00",
    "text": "With so many \"Yes\" votes from other ADs, I feel like I'm swimming against the flow by raising a discuss ... Firstly, I would like the thank the authors and WG on such a well written document.\u00a0 I am\u00a0 supportive of this protocol and hope that it will be good for the Internet. However, I do have some discuss questions relating to the Spin Bit and the ability to manage and monitor networks.\u00a0 I appreciate that there has already been a lot of (presumably heated) discussion on the spin bit, which I've not read or participated in, but I am concerned about the operational manageability aspect of QUIC. Firstly, I have two comments on clarifying the spin bit behaviour/specification: 1) It would be helpful to clarify what the expected behaviour is for an implementation that chooses not to support the spin-bit.\u00a0 Does it just leave the bit set as 0, or is it meant to follow the same behaviour as if spin-bit is supported but disabled? 2) This may not be discuss worthy, but some of the spin bit behaviour is inconsistently defined between the quic transport and quic manageability drafts.\u00a0 Specifically: \u00a0 - The transport draft states that at least 1 in 16 connections \"MUST\" disable spinning, whereas the manageability draft states this as \"recommended\". \u00a0 - In the case that the spin bit is disabled, the transport draft uses \"RECOMMENDED\" to use a random value for each packet, or chosen independently for each connection.\u00a0 Whereas the manageability draft uses \"can\" and lists the two options in the opposite order. \u00a0  \u00a0 For this review, since it is in IESG review, I've presumed that the transport draft has the definitive definitions and the manageability draft is lagging. But my two main discuss questions/comments relate to whether the spin-bit, as specified in quic transport, achieves its goal.\u00a0 I appreciate that there are individuals who don't think that it is required at all, conversely some network operators believe that they will lose vital information needed to help manage their networks, and presumably we are trying to find a pragmatic compromise between these two positions. 1) I find it hard to understand why a server is allowed to independently decide whether or not to support the spin bit on a connection?\u00a0 Shouldn't the client (or administrator of the client system) that opened the connection be able to choose whether they want the RTT to be monitorable via the spin bit?\u00a0 What is the reasoning for allowing the server (or server administrator) to be able to independently be able to decide what is best for the client? 2) In the case that the spin-bit is disabled, I don't understand the benefit of injecting a random spin bit value in each packet rather than always setting it to a per connection random value.\u00a0 It seems that whether or not the randomness is injected, it is expected to be feasible to extract the RTT for those connections that are genuinely spinning the bit (or otherwise the spin bit is entirely pointless), but it just seems to make it computationally harder to extract the signal from the noise.\u00a0 Perhaps the goal here is reduce the ability for pervasive monitoring to occur, but that feels a bit like security through obscurity. Some enlightenment for these questions would be appreciated. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-15 16:30:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-11-17 09:22:44-08:00",
    "text": "Section 12 states the situation accurately \u2013 \u201cEach of the potential RAW use-cases will have security considerations from both the use-specific perspective.\u201d\u00a0 Where are these security and privacy considerations for these uses cases discussed?\u00a0 Are these in scope to solve for RAW?\u00a0 A select list to review would be: ** Section 3.*. Per the amusement park use case, what are the physical location tracking and surveillance considerations? ** Section 7.*.\u00a0 Per the vehicle platooning use case, what are the physical location tracking privacy considerations? ** Section 8.*. Per the edge robotics use case, what are the privacy considerations of the video surveillance? ** Section 9.*.\u00a0 Per the ambulance use case, what are the security considerations around exchanging health care information over a wireless WAN? A clearer distinction of what is to be addressed at the protocol level, and what seems like an application consideration is needed.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-03 20:35:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-30 18:55:29-07:00",
    "text": "This is an \"early warning\" discuss ballot, entered before I have done a full review of the document. As such, it is possible that the stated concern may in fact be a non-issue after closer examination, but the potential import of the concern seems to make it worth starting the discussion sooner rather than later. This document defines (among other things) a mechanism for carrying subscriber information in an NSH.\u00a0  RFC 8300  (NSH) notes both that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Metadata privacy and \u00a0  security considerations are a matter for the documents that define \u00a0  metadata format. and that: \u00a0 \u00a0 \u00a0 One useful element of providing privacy protection for sensitive \u00a0 \u00a0 \u00a0 metadata is described under the \"SFC Encapsulation\" area of the \u00a0 \u00a0 \u00a0 Security Considerations of [ RFC7665 ].\u00a0 Operators can and should \u00a0 \u00a0 \u00a0 use indirect identification for metadata deemed to be sensitive \u00a0 \u00a0 \u00a0 (such as personally identifying information), significantly \u00a0 \u00a0 \u00a0 mitigating the risk of a privacy violation.\u00a0 In particular, \u00a0 \u00a0 \u00a0 subscriber-identifying information should be handled carefully, \u00a0 \u00a0 \u00a0 and, in general, SHOULD be obfuscated. On the other hand, this document in its security considerations claims that: \u00a0  Data plane SFC-related security considerations, including privacy, \u00a0  are discussed in [ RFC7665 ] and [ RFC8300 ]. and does not seem to incorporate any discussion of the privacy and security considerations of the subscriber information metadata carried by the new format it conveys.\u00a0 Yes, it does note that all nodes with access to the information are part of the same trusted domain, but I do not think that is sufficient, especially given that personally identifiable information is often subject to strict compliance regimes. In short, 8300 and this document are referring to each other for privacy considerations, and the actual privacy considerations do not seem to be documented in either place. Additionally, I did not see any indication of how the subscriber-identifying information ought to be obfuscated (or an explanation of why it is okay to violate the SHOULD from 8300).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-03 20:36:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-11-03 20:35:55-08:00",
    "text": "Retaining my original Discuss position (without the \"early warning\" note), as it is the one that was supported by Martin D and Alvaro: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This document defines (among other things) a mechanism for carrying subscriber information in an NSH.\u00a0  RFC 8300  (NSH) notes both that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Metadata privacy and \u00a0  security considerations are a matter for the documents that define \u00a0  metadata format. and that: \u00a0 \u00a0 \u00a0 One useful element of providing privacy protection for sensitive \u00a0 \u00a0 \u00a0 metadata is described under the \"SFC Encapsulation\" area of the \u00a0 \u00a0 \u00a0 Security Considerations of [ RFC7665 ].\u00a0 Operators can and should \u00a0 \u00a0 \u00a0 use indirect identification for metadata deemed to be sensitive \u00a0 \u00a0 \u00a0 (such as personally identifying information), significantly \u00a0 \u00a0 \u00a0 mitigating the risk of a privacy violation.\u00a0 In particular, \u00a0 \u00a0 \u00a0 subscriber-identifying information should be handled carefully, \u00a0 \u00a0 \u00a0 and, in general, SHOULD be obfuscated. On the other hand, this document in its security considerations claims that: \u00a0  Data plane SFC-related security considerations, including privacy, \u00a0  are discussed in [ RFC7665 ] and [ RFC8300 ]. and does not seem to incorporate any discussion of the privacy and security considerations of the subscriber information metadata carried by the new format it conveys.\u00a0 Yes, it does note that all nodes with access to the information are part of the same trusted domain, but I do not think that is sufficient, especially given that personally identifiable information is often subject to strict compliance regimes. In short, 8300 and this document are referring to each other for privacy considerations, and the actual privacy considerations do not seem to be documented in either place. Additionally, I did not see any indication of how the subscriber-identifying information ought to be obfuscated (or an explanation of why it is okay to violate the SHOULD from 8300). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% To record some additional synthesis of the above (original) remark with my more thorough reading of the document: we are defining containers specifically to contain subscriber and performance policy identifiers/information.\u00a0 While the specific contents are out of scope for this document, we still are obligated to describe the general classes of issues that can arise due to conveying those types of information within a SFC domain.\u00a0 We should also give guidance on how to populate the contents of these context headers in a secure and privacy-supporting manner, including the use of indirect identification and obfuscation/encryption. Futhermore (and this part is not a discuss point but may lead to me switching my position to Abstain once the discusses are resolved), I have some misgivings about including subscriber identification information at all, and would prefer if it could instead be translated into the relevant policy information element(s) needed by the SFP in question before being applied to the NSH.\u00a0 For example, rather than saying \"this packet is from user X\" we could say \"this packet is part of quota bucket ABC (with bucket size Z) for time period Y\" to enforce per-user quota.\u00a0 While in this case the identifier would still ultimately lead back to an individual, the identifier would be rotated periodically, and it is possible to achieve some level of de-linkability as records age out (depending on how the \"ABC\" is generated, of course). I do recognize that even for non-quota use cases where a user is part of multiple distinct policy groups, the combination of those groups might still identify only a small anonymity set, but the overall privacy properties of such a design seem superior than consistent use of a persistent identifier or identifiers, in aggregate. I have an additional Discuss point after doing a more thorough review of the document -- I think there's a (minor) internal inconsistency within Section 3: \u00a0  Intermediary NSH-aware nodes have to preserve Subscriber Identifier \u00a0  Context Headers (i.e., the information can be passed to next hop NSH- \u00a0  aware nodes), but local policy may require an intermediary NSH-aware \u00a0  node to strip a Subscriber Identifier Context Header after processing \u00a0  it. since it seems to say that NSH-aware intermediary nodes both \"have to preserve\" and \"may strip\" a Service Identifier Context Header. Similar language is used to describe the Performance Policy Identifier Context Header, in Section 4, which would presumably receive a similar modification to the Subscriber Identifier case.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-10 06:41:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 20:36:05-08:00",
    "text": "Retaining my original Discuss position (without the \"early warning\" note), as it is the one that was supported by Martin D and Alvaro: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This document defines (among other things) a mechanism for carrying subscriber information in an NSH.\u00a0  RFC 8300  (NSH) notes both that: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Metadata privacy and \u00a0  security considerations are a matter for the documents that define \u00a0  metadata format. and that: \u00a0 \u00a0 \u00a0 One useful element of providing privacy protection for sensitive \u00a0 \u00a0 \u00a0 metadata is described under the \"SFC Encapsulation\" area of the \u00a0 \u00a0 \u00a0 Security Considerations of [ RFC7665 ].\u00a0 Operators can and should \u00a0 \u00a0 \u00a0 use indirect identification for metadata deemed to be sensitive \u00a0 \u00a0 \u00a0 (such as personally identifying information), significantly \u00a0 \u00a0 \u00a0 mitigating the risk of a privacy violation.\u00a0 In particular, \u00a0 \u00a0 \u00a0 subscriber-identifying information should be handled carefully, \u00a0 \u00a0 \u00a0 and, in general, SHOULD be obfuscated. On the other hand, this document in its security considerations claims that: \u00a0  Data plane SFC-related security considerations, including privacy, \u00a0  are discussed in [ RFC7665 ] and [ RFC8300 ]. and does not seem to incorporate any discussion of the privacy and security considerations of the subscriber information metadata carried by the new format it conveys.\u00a0 Yes, it does note that all nodes with access to the information are part of the same trusted domain, but I do not think that is sufficient, especially given that personally identifiable information is often subject to strict compliance regimes. In short, 8300 and this document are referring to each other for privacy considerations, and the actual privacy considerations do not seem to be documented in either place. Additionally, I did not see any indication of how the subscriber-identifying information ought to be obfuscated (or an explanation of why it is okay to violate the SHOULD from 8300). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% To record some additional synthesis of the above (original) remark with my more thorough reading of the document: we are defining containers specifically to contain subscriber and performance policy identifiers/information.\u00a0 While the specific contents are out of scope for this document, we still are obligated to describe the general classes of issues that can arise due to conveying those types of information within a SFC domain.\u00a0 We should also give guidance on how to populate the contents of these context headers in a secure and privacy-supporting manner, including the use of indirect identification and obfuscation/encryption. Futhermore (and this part is not a discuss point but may lead to me switching my position to Abstain once the discusses are resolved), I have some misgivings about including subscriber identification information at all, and would prefer if it could instead be translated into the relevant policy information element(s) needed by the SFP in question before being applied to the NSH.\u00a0 For example, rather than saying \"this packet is from user X\" we could say \"this packet is part of quota bucket ABC (with bucket size Z) for time period Y\" to enforce per-user quota.\u00a0 While in this case the identifier would still ultimately lead back to an individual, the identifier would be rotated periodically, and it is possible to achieve some level of de-linkability as records age out (depending on how the \"ABC\" is generated, of course). I do recognize that even for non-quota use cases where a user is part of multiple distinct policy groups, the combination of those groups might still identify only a small anonymity set, but the overall privacy properties of such a design seem superior than consistent use of a persistent identifier or identifiers, in aggregate. I have an additional Discuss point after doing a more thorough review of the document -- I think there's a (minor) internal inconsistency within Section 3: \u00a0  Intermediary NSH-aware nodes have to preserve Subscriber Identifier \u00a0  Context Headers (i.e., the information can be passed to next hop NSH- \u00a0  aware nodes), but local policy may require an intermediary NSH-aware \u00a0  node to strip a Subscriber Identifier Context Header after processing \u00a0  it. since it seems to say that NSH-aware intermediary nodes both \"have to preserve\" and \"may strip\" a Service Identifier Context Header. Similar language is used to describe the Performance Policy Identifier Context Header, in Section 4, which would presumably receive a similar modification to the Subscriber Identifier case.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-11-15 22:28:18-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 07:45:02-08:00",
    "text": "This looks like a significant problem. If I have missed anything in any reference this might be very simple to resolve. However, based on this document and looking at  RFC 8300  I think this document is lacking in discussion of the packet size impact of using both dynamic size headers, as well as there are no limits to how many are added. Thus, there are significant risk for this header to increase the packet size so much that it doesn't fit the underlying layer. And as Section 5 in  RFC8300  identifies there are no general solution provided in NSH. Thus, I really think this issues needs some discussion. Even if the actual result of this is a requirement on the control plane, the issue exists in the data plane and thus warrants discussion in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-12-10 13:18:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 05:54:40-08:00",
    "text": "There is no framework or guidance to reason about or mitigate the security and privacy risks of embedding sensitive, user identifying information into the network.\u00a0 The document does fairly note that the other SFC headers also don\u2019t have protection mechanisms either, but they do not enable use identification or tracking. During response to IESG ballots prior to mine, two related points were made: ** Using  draft-ietf-sfc-nsh-integrity-00  to mitigate risks \u2013 this might help, but the maturity of this document would suggest that additional discussion is required before it could be evaluated as a solution. ** surveillance as a use case (lawful intercept as an SFC [2]) \u2013 reinforces why a privacy framework is needed ( RFC6973  and 8165 are helpful references here) [1]  https://mailarchive.ietf.org/arch/msg/sfc/24Q52inJTpacY1HOlCHU8VTUkIw/ [2]  https://mailarchive.ietf.org/arch/msg/sfc/Knc9goUyEjiMLWHmf0K-NbHTpC8/",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-12-21 03:06:07-08:00",
    "end_reason": "position_updated",
    "start": "2022-10-26 02:08:59-07:00",
    "text": "# GEN AD review of  draft-ietf-lpwan-schc-over-nbiot-12 CC @larseggert ## Discuss ### Intended status SCHC is an IETF standard. The IETF should not standardize how another SDO should use SCHC in their architecture, unless that other SDO has specifically asked the IETF to do so. Has 3GPP done so? ### \"Abstract\", paragraph 1 ``` \u00a0 \u00a0  The 3rd Generation Partnership Project (3GPP) \u00a0 \u00a0  and the Narrowband Internet of Things (NB-IoT) architectures may \u00a0 \u00a0  adopt SCHC to improve their capacities. ``` Would 3GPP be surprised to see this recommendation by the IETF? Has this work item been liaised to and coordinated with 3GPP? Do they expect us to deliver it and do they agree on the content? ### Section 5.1, paragraph 1 ``` \u00a0 \u00a0  This section consists of IETF suggestions to the 3GPP. ``` The IETF isn't typically giving suggestions to other SDOs by publishing documents. We do that through liaison activities. Has this work item be liaised to 3GPP? Do they expect us to complete and publish the work so they can normatively refer to it?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-25 19:41:57-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-16 18:32:50-07:00",
    "text": "Let's discuss whether the currently specified procedures for reconstructing the target URI from a request-target in absolute-form provide adequate security properties, at the origin server.\u00a0 I'm specifically concerned about taking the scheme directly from the request target, i.e., making the distinction between the \"http\" and \"https\" schemes.\u00a0 The simple procedure of \"take the scheme from the request-target\" would seem to allow for the client to cause the server to engage processing for the \"https\" origin without receiving the protection that https is supposed to provide.\u00a0 (The converse case does not immediately seem to present much risk but is probably worth preventing as well on general principles of retaining consistency.)\u00a0 I don't remember seeing any text that would require the server to validate the scheme from the request-target against the actual properties of the transport (or the configured fixed URI scheme as might be provisioned with a trusted outbound gateway, etc.)\u00a0 While we do reference \u00a77.4 of [Semantics] with a note that reconstructing the target URI is only part of the process of identifying a target resource, that part of [Semantics] does not mention scheme validation as part of rejecting misdirected requests. Does the origin server need to validate the scheme from an absolute-form request-target?\u00a0 What is the scope of consequences if it fails to do so?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-06-10 13:04:24-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-10 04:41:09-07:00",
    "text": "his document seems to have unresolved IANA issues, so I am holding a DISCUSSfor IANA until the issues are resolved.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-05-19 02:39:04-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-18 03:16:11-07:00",
    "text": "Hi, Thanks for this short doc, and sorry for the discuss, but hopefully it is fairly easy to resolve ... I think that it would be helpful for this document to explicitly state how this attribute behaves in conjunction with the existing Administrative Group (color) TLV (1088).\u00a0 E.g., is the expectation that if this attribute is published then the 1088 attribute would also always be published (with the same first 32 bits)?\u00a0 Or is the expectation that this attribute can be published without the 1088 attribute being published at all? Similarly, if a client receives both attributes there are there any expectations to how it handles those, i.e., should it always use the new attribute in preference?\u00a0 Or otherwise, what should it do if the values were inconsistent between the two attributes? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-23 07:43:56-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-16 20:40:27-08:00",
    "text": "A few super-boring inconsistencies that make the document unfit to  publish as-is but should be mostly trivial to resolve ((3) and (4) might be a little tedious but should be mechanical): (1) Section 3.3.1 says: \u00a0 \u00a0 \u00a0 be silently dropped if not recognized.\u00a0 The code points for \u00a0 \u00a0 \u00a0 experimental use are taken from the ranges previously called \u00a0 \u00a0 \u00a0 'Vendor Private Use', the remainder of which now form part of 'RFC \u00a0 \u00a0 \u00a0 Required'. but I don't think this sentence matches what's proposed in Section 6.\u00a0 I am seeing the code points for experimental use coming out of the range that is currently described as \"specification required\", with the entirety of the range currently described as \"vendor private use\" being converted to FCFS. (2) Section 4.1 says: \u00a0  Mandatory and optional are used to indicate whether a response is \u00a0  needed if a TLV or sub-TLV is not understood on pages 14 and 15 in \u00a0  Section 3 of  RFC 8029 . but I think the text being modified is on pages 15 and 16 of  RFC 8029 (the page numbers are in the footer, not the header, of the plain text output format). (3) Section 6.2.3 describes changes to the procedures for the Sub-TLVs for TLV 6 sub-registry, but the changes described assume that the registration procedures are as described by  RFC 8029 .\u00a0 However, the registration procedures have already been changed by  RFC 8611 , so the changes described no longer make sense.\u00a0 (E.g., there is not currently a \"specification required\" procedure active for any range of this sub-registry.)\u00a0 We do, however, still need to make some changes to the registration procedures, specifically to convert the \"Private Use\" ranges to FCFS and carve out the \"Experimental Use\" blocks. (4) Table 22 (for Sub-TLVs for TLV 27 Assignments) seems to be a copy of Table 20 and does not reflect the current state of the sub-registry in question.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-02-28 10:48:32-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-16 02:37:59-08:00",
    "text": "Hi, I have a couple of concerns regarding the change from part of the registry from \"Private Use\" to \"FCFS\": (1) Am I right in thinking that this could, at least in theory, break existing deployments?\u00a0 E.g., two separate implementations could both be using TLV value 31744 under \"private use\", whereas now they would both be expected to register that TLV with IANA under FCFS, and obviously only one of them would be able to get the registration?\u00a0 Are the authors/WG/ADs aware with high confidence that no such deployments exist? (2) I find the \"updates\" tag for RFCs to be somewhat ambiguous as to what it means.\u00a0 Specifically, is someone who implements  RFC 8611  obliged to also implement  draft-ietf-mpls-lsp-ping-registries-update  when this becomes an RFC?\u00a0 Or are they allowed to take the previous interpretation of the \"private use\" in the IANA registries?\u00a0 Probably too late to change this now, but I wonder if it would have been better to bis  RFC 8611  instead so that  RFC 8611  could have been formally obsoleted by  draft-ietf-mpls-lsp-ping-registries-update  instead. An alternative solution would be to keep the \"Private Use\" space as defined in  RFC 8611 , and allocate new space for FCFS (24 entries) from the 15,000 entry \"RFC Required\" section of the TLV Id space instead.\u00a0 These would seem to make the new allocation scheme in  draft-ietf-mpls-lsp-ping-registries-update  entirely backwards compatible with any existing deployments.\u00a0 Was this approach considered and dismissed for some reason? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 18:02:57-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 07:25:28-08:00",
    "text": "This is probably a minor point, but I'm putting it in the Discuss section because one of the possible answers would be very problematic and I can't rule that scenario out with just the information at hand.\u00a0 As such (and per https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ ) a response is greatly appreciated, to help clarify the intended meaning and thus what (if any) changes to the document should be made in response. In Section 4.2 we have a couple tables listing RECOMMENDED and OPTIONAL features for different types of DUT/SUT.\u00a0 Do these recommendations relate to what features should be tested, what features should be enabled for use in normal operation, what features should be implemented in devices, or something else?\u00a0 The latter options seem a bit far afield from the stated scope of this document, and the particular recommendations listed probably do not have IETF Consensus as to general applicability (most notably for SSL Inspection).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-09-12 04:21:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 01:16:36-08:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS points (probably easy to address but really important), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Thanks to Toerless for his deep and detailed IoT directorate review, I have seen as well that the authors are engaged in email discussions on this review: https://datatracker.ietf.org/doc/review-ietf-bmwg-ngfw-performance-13-iotdir-telechat-eckert-2022-01-30/ Special thanks to Al Morton for the shepherd's write-up including the section about the WG consensus.  I hope that this helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics The document obsoletes  RFC 3511 , but it does not include any performance testing of IP fragmentation (which  RFC 3511  did), which is AFAIK still a performance/evasion problem. What was the reason for this lack of IP fragmentation support ? At the bare minimum, there should be some text explaining why IP fragmentation can be ignored.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-09-12 03:11:02-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 05:27:09-08:00",
    "text": "This document needs TSV and ART people to help with straightening out a lot of issues related to TCP, TLS, and H1/2/3. Large parts of the document don't correctly reflect the complex realities of what \"HTTP\" is these days (i.e., that we have H1 and H2 over either TCP or TLS, and H3 over only QUIC.) The document is also giving unnecessarily detailed behavioral descriptions of TCP and its parameters, while at the same time not being detailed enough about TLS, H2 and esp. QUIC/H3. It feels like this stared out as an H1/TCP document that was then incompletely extended to H2/H3. Section 4.3.1.1. , paragraph 2, discuss: >\u00a0 \u00a0 The TCP stack SHOULD use a congestion control algorithm at client and >\u00a0 \u00a0 server endpoints.\u00a0 The IPv4 and IPv6 Maximum Segment Size (MSS) >\u00a0 \u00a0 SHOULD be set to 1460 bytes and 1440 bytes respectively and a TX and >\u00a0 \u00a0 RX initial receive windows of 64 KByte.\u00a0 Client initial congestion >\u00a0 \u00a0 window SHOULD NOT exceed 10 times the MSS.\u00a0 Delayed ACKs are >\u00a0 \u00a0 permitted and the maximum client delayed ACK SHOULD NOT exceed 10 >\u00a0 \u00a0 times the MSS before a forced ACK.\u00a0 Up to three retries SHOULD be >\u00a0 \u00a0 allowed before a timeout event is declared.\u00a0 All traffic MUST set the >\u00a0 \u00a0 TCP PSH flag to high.\u00a0 The source port range SHOULD be in the range >\u00a0 \u00a0 of 1024 - 65535.\u00a0 Internal timeout SHOULD be dynamically scalable per >\u00a0 \u00a0  RFC 793 .\u00a0 The client SHOULD initiate and close TCP connections.\u00a0 The >\u00a0 \u00a0 TCP connection MUST be initiated via a TCP three-way handshake (SYN, >\u00a0 \u00a0 SYN/ACK, ACK), and it MUST be closed via either a TCP three-way close >\u00a0 \u00a0 (FIN, FIN/ACK, ACK), or a TCP four-way close (FIN, ACK, FIN, ACK). There are a lot of requirements in here that are either no-ops (\"SHOULD use a congestion control algorithm\"), nonsensical (\"maximum client delayed ACK SHOULD NOT exceed 10 times the MSS\") or under the sole control of the stack. This needs to be reviewed and corrected by someone who understands TCP.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-10-27 07:27:52-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-02 21:24:01-08:00",
    "text": "I may be wandering into unfamiliar territory here, i.e., how benchmarking specs are typically written, but this is sufficiently confusing that I'd like to discuss it. I note that  RFC 3511 , which this document obsoletes, didn't cite  RFC 2119  ( BCP 14 ) but rather defined those same key words on its own.\u00a0 Then it used SHOULD rather liberally, in a way that seems kind of peculiar to me (especially compared to the text of Section 6 of  RFC 2119 ).\u00a0 Do any of them matter to the outcome of the benchmark being constructed or executed?\u00a0 If so and they would spoil the test, shouldn't they be MUSTs?\u00a0 If not, why include them?\u00a0 Or in the alternative, why might I, as someone setting up a test, legitimately do something contrary to the SHOULD in each case (which \"SHOULD\" expressly permits)? This document does cite  BCP 14  directly, and then seems to take that curious pattern to the next level.\u00a0 Among the 130+ SHOULDs in here, I'm particularly confused by stuff like this in Section 4.3.1: \u00a0  This section specifies which parameters SHOULD be considered while \u00a0  configuring clients using test equipment.\u00a0  I have no idea what this means to the test.\u00a0 If I've simply thought about these parameters, have I met the burden here? This in Section 4.3.1.1 (\"TCP Stack Attributes\") seems an odd thing to have to stipulate: \u00a0 The client SHOULD initiate and close TCP connections. Then Section 7.1.3, which contains subsections about each of the test parameters for the benchmark described in Section 7.1, consists of this text: \u00a0  In this section, the benchmarking test specific parameters SHOULD be \u00a0  defined. As I read it, this is a self-referential SHOULD about this document!\u00a0 I'm very confused.\u00a0 This happens again in Section 7.2.3, 7.3.3, etc., up to 7.9.3, and even Appendix A.3.\u00a0 I think in each case you just want: \u00a0  This section defines test-specific parameters for this benchmark.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-13 11:44:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-02 14:39:27-08:00",
    "text": "** A key element of successfully running the throughput tests described in Section 7, appears to be ensuring how to configure the device under test.\u00a0 Section 4.2. helpfully specifies feature sets with recommendations configurations.\u00a0 However, it appears there are elements of under-specification given the level of detail specified with normative language.\u00a0 Specifically: -- Section 4.2.1 seems unspecified regarding all the capabilities in Table 1 and 2.\u00a0 The discussion around vulnerabilities (CVEs) does not appear to be relevant to configuration of anti-spyware, anti-virus, anti-botnet, DLP, and DDOS.\u00a0  -- Recognizing that NGFW, NGIPS and UTM are not precise product categories, offerings in this space commonly rely on statistical models or AI techniques (e.g., machine learning) to improve detection rates and reduce false positives to realize the capabilities in Table 1 and 2.\u00a0 If even possible, how should these settings be tuned?\u00a0 How should the training period be handled when describing the steps of the test regime (e.g., in Section 4.3.4? Section 7.2.4?) ** Appendix A.\u00a0 The KPI measures don\u2019t seem precise here \u2013 CVEs are unlikely to be the measure seen on the wire.\u00a0 Wouldn\u2019t it be exploits associated with a particular vulnerability (that\u2019s numbered via CVE)?\u00a0 There can be a one-to-many relationship between the vulnerability and exploits (e.g., multiple products affected by a single CVE); or the multiple implementations of an exploit.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-22 14:28:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-13 11:44:43-07:00",
    "text": "(Updated Ballot) -- [per -13] Recognizing that NGFW, NGIPS and UTM are not precise product categories, offerings in this space commonly rely on statistical models or AI techniques (e.g., machine learning) to improve detection rates and reduce false positives to realize the capabilities in Table 1 and 2.\u00a0 If even possible, how should these settings be tuned?\u00a0 How should the training period be handled when describing the steps of the test regime (e.g., in Section 4.3.4? Section 7.2.4?) [per -14] Thank for explaining that the training phase would not be included in the threat emulating in your email response.\u00a0 Since the goal of these document is specify reproducible testing, the primary text I was look for was an acknowledgment that the detection performance of some systems may be affected by learning from prior traffic.\u00a0 Any state kept by such systems much be reset between testing runs.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-06-19 09:31:12-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-19 00:17:54-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-stamp-srpm-12 Thank you for the work put into this document.  Please find below two blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and one nit. Special thanks to Tommy Pauly for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 3 Probably easy to fix :-) `The Session-Reflector SHOULD use the received Destination Node Address as the Source Address in the IP header of the reply test packet`. I am sure that the authors do not want to do spoofing, i.e., add some text about \"only if the Destination Node Address is one of the node addresses\" or similar. ## Section 4.1.1 Please add text similar to \"All other bits are reserved and must be transmitted as 0 and ignored by the receiver\".",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-06-29 13:32:08-07:00",
    "end_reason": "discuss_updated",
    "start": "2023-06-20 18:29:25-07:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-stamp-srpm-13 CC @jgscudder Thanks for this document. Despite the lengthiness of my ballot and DISCUSS section, I think this document is in reasonably good shape and will be ready to go after one more good editing pass. Thanks for your work on it, and thanks in advance for helping me work through my DISCUSS points. ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 3, not an address of the Session-Reflector, really? The description \"transmit test packets to the Session-Reflector with a different destination address that is not matching an address of the Session-Reflector\" appears to be inaccurate, at least for the use case you've presented: loopback is by definition an address of the Session-Reflector, and indeed of every IP-enabled node, is it not? So it's not right to say that the DA is \"not matching an address of the Session-Reflector\". As far as I can tell by skimming the STAMP base spec, STAMP is basically a host function. Presumably any packet whose DA was not an address of the Session-Reflector wouldn't be delivered to the host stack, and consequently wouldn't be processed. So it seems that perhaps this functionality is only for use when the DA is set to loopback. Is that correct? Is the entire effect of the Destination Node Address TLV to tell the target what SA to use in its reply, and for session identification (although the latter appears to be an inessential use since SSID would do the same job)? Once I have more confidence I understand what's really going on here, I may have some further suggestions for how to edit for clarity. According to my current understanding, it seems to me as though something along the lines of \"The Session-Sender may need to transmit test packets to an address of the Session-Reflector which is not suitable for use as the Source Address of the reply test packet. This TLV allows the Session-Sender to request the Session-Reflector to use a different Source Address in its reply test packet\" might work. ### Section 6, \"limited domain\" I'm concerned with the reliance on \"limited domain\" without doing the work to define what's meant. \u00a0  The usage of STAMP protocol is intended for deployment in limited \u00a0  domains [ RFC8799 ]. \u00a0   RFC 8762  doesn't indicate this, or at least, it has no mention of such in its Security Considerations section nor occurrence of the string \"limited\" anywhere in the RFC. Further,  RFC 8799  isn't a good reference. It's not an IETF document and doesn't itself claim to define what a limited domain is. From the  RFC 8799  abstract: \"Finally, it shows the need for a precise definition of \"limited domain membership\"\". That is, it identifies the need for a definition but doesn't claim to supply one.  RFC 8799  does provide, in Section 6, some guidance that might be helpful in defining what is meant by a \"limited domain\" in a specific context -- but it is up to the document defining that context, to define what it means by \"limited domain\". Some of the underlying STAMP documents do provide context about their assumptions of the deployment environment which might broadly speaking fit the \"limited domain\" rubric -- but they do so in specific terms. It's regrettable that the IETF has no document that defines \"limited domain\", but the fact remains that we don't. This deficiency might not be problematic except that you lean on it quite heavily in the last paragraph of the section: \u00a0  The STAMP extensions defined in this document may be used for \u00a0  potential \"proxying\" attacks.\u00a0 For example, a Session-Sender may \u00a0  specify a return path that has a destination different from that of \u00a0  the Session-Sender.\u00a0 But normally, such attacks will not happen in an \u00a0  SR domain where the Session-Senders and Session-Reflectors belong to \u00a0  the same domain. \u00a0   The \"but normally\" sentence really cries out for some more precise definition of what you think the security context is. Maybe there is a reference within the STAMP or SR document set that you can reference to provide this context, but  RFC 8799  is not sufficient.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-08-15 11:06:06-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-29 13:32:08-07:00",
    "text": "Thanks for your work to address my previous DISCUSS and COMMENTs. Although you've worked to remove the reliance of \"Limited Domain\" (thank you), regrettably the new text introduces a new, and I think also problematic, reliance on the SR Domain concept. To quote from my earlier email, On Jun 22, 2023, at 1:09 PM, John Scudder\u00a0 wrote: In looking over the new version, it occurred to me that although the document is called \u201c... for Segment Routing Networks\u201d and although that was the use case that motivated it, the only elements whose applicability actually is limited to SR are the Return Path SR-MPLS Segment-List Sub-TLV and the Return Path SRv6 Segment-List Sub-TLV. All the rest are generically applicable. This is basically a good thing IMO \u2014 one likes to see specs whose applicability is greater than just the use case that led to their development \u2014 but it does mean that \"The usage of STAMP protocol is intended for deployment in SR domains [ RFC8402 ]\u201d isn't sufficient, I\u2019m afraid \u2014 whether the use case that led to the development was restricted to SR or not, one can easily see how (for example) a Return Address Sub-TLV could be used outside of an SR deployment. That use might be by design, or it might be by an attacker. To repeat the concern in different words: You\u2019ve rewritten the first paragraph of the Security Considerations as \u00a0 The usage of STAMP extensions defined in this document is intended \u00a0 for deployment in SR domains [ RFC8402 ].\u00a0 It is assumed that a node \u00a0 involved in STAMP protocol operation has previously verified the \u00a0 integrity of the path and the identity of the far-end Session- \u00a0 Reflector. This eliminates the reliance on the Limited Domains RFC (good) but you\u2019re improperly (I think) assuming that you can rely on the SR domain definition instead. This is still true even though you changed \u201cSTAMP protocol\u201d (the version I commented on in the quote above) to \u201cSTAMP extensions\u201d. Again, to repeat: I don\u2019t think it\u2019s either reasonable or desirable to restrict the extensions you\u2019ve defined to be only for use in an SR domain, and therefore, I think the SecCons can\u2019t rest on the foundation of the SR document set. If you did want to rest on that foundation, I think you would have to be much more prescriptive about saying the extensions MUST NOT be processed other than in an SR context (that\u2019s probably not the right wording) \u2014 but I think that would be undesirable, and I think if you did want to make that change, it would be a pretty fundamental change requiring a new WGLC.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-08-04 06:55:34-07:00",
    "end_reason": "position_updated",
    "start": "2023-08-04 03:27:43-07:00",
    "text": "# GEN AD review of  draft-ietf-ippm-stamp-srpm-17 CC @larseggert Thanks to Joel Halpern for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/crZp5rrOYaDNMcoM95b5pFQBReo ). ## Discuss Two issues that I think will be quick to fix: ### Section 4, paragraph 12 ``` \u00a0 \u00a0  other Return Path TLVs if present.\u00a0 A Session-Reflector that supports \u00a0 \u00a0  this TLV MUST reply using the Return Path received in the Session- \u00a0 \u00a0  Sender test packet, if possible. ``` \"MUST ... if possible\" is an odd construction. Please rephrase and  clarify the requirements level. ### Section 4.1.3, paragraph 16 ``` \u00a0 \u00a0  The SRv6 Segment List contains a list of 128-bit IPv6 addresses \u00a0 \u00a0  representing the SRv6 SIDs.\u00a0 Length of the Sub-TLV modulo MUST be 0. ``` Modulo *what*?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2023-07-10 08:24:54-07:00",
    "end_reason": "position_updated",
    "start": "2023-06-22 07:27:26-07:00",
    "text": "I am balloting DISCUSS on this document because I do not believe the the document fully specifies the processing and behavior. It is sufficiently unclear in many places that I believe that it is not fully implementable by people not involved in its creation. Note that this was originally an Abstain, but on further consideration I feel it requires a DISCUSS. There are many examples of this, especially around the source and destination address text. For example: \"The Session-Sender may need to transmit test packets to the Session-Reflector with a different destination address that is not matching an address of the Session-Reflector e.g. when the STAMP test packet is encapsulated by a tunneling protocol e.g., encapsulated with an SR-MPLS Segment List and IPv4 header containing destination IPv4 address from 127/8 range or encapsulated with outer IPv6 header and Segment Routing Header (SRH) with inner IPv6 header containing IPv6 destination IPv6 address ::1/128.\" - I'm unable to parse this / how this is expected to work. If the sender sends packets to the reflector through a tunnel, isn't the packet decapsulated when it leaves the tunnel / link, and then the address should be that of the SR? Or are you saying that this is a function of the decapsulation, and whatever process does that should simply trust and process any STAMP packets, regardless of it if owns the address? It is also very unclear what exactly the behavior is intended to be for nodes when using \"different values of IPv4 destination address from 127/8 range may be used in the IPv4 header to measure different ECMP paths.\" - is the assumption that the Session-Reflector is listening on / will process any decapsulated packet destined to any address in 127/8? If so, that is really not clear. This text is also unclear: \"For security reasons (e.g., to avoid node discovery), the Session-Reflector SHOULD use the received Destination Node Address as the Source Address in the IP header of the reply test packet only if the Destination Node Address is one of the addresses on the node, instead of using its Node Address.\" - this sounds like a node should extract the packet, and use the received Destination Node Address as the Source Address if this address exists on the node. If this correct? If so, this is overriding the standard source address selection logic on the device, and can be used to cause packets to be emitted which bypass firewall filters (e.g: My management network is numbered out of 10/8, and I have firewall filters which only allow access to 10/8 from bastion stations. By using the described solution, I can send a STAMP packet to the node and set the Destination Node Address as 10.0.0.5 (an address on the device). This specifies that the Source Address of the return packet should be 10.0.0.5, regardless of if the packet is received on or processed by that interface. This allows filters which match on source address to be bypassed.) It is also unclear what you mean by \"e.g., to avoid node discovery\".  There is much in this document which is underspecified or hand-wavey, and, as such, I do not think that I can ballot No Objection in good faith.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-09-08 13:01:19-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-29 14:30:55-07:00",
    "text": "** Section 6. It may be inferred from the general requirements (Section 4.1) for \u00a0  provable ownership, provable binding, and provable registration, \u00a0  together with the identifier requirements (Section 4.2), that DRIP \u00a0  must provide: \u00a0  *\u00a0 message integrity \u00a0  *\u00a0 non-repudiation \u00a0  *\u00a0 defense against replay attacks \u00a0  *\u00a0 defense against spoofing Thanks for enumerating these highly desirable security properties as part of DRIP.\u00a0 A bit more clarifying language is needed to explain which communication paths in the DRIP architecture (Figure 3 and 4) have these properties and under what circumstances.\u00a0 Section 4.1 and 4.2 seem specific to properties between particular parties or messages.\u00a0 Likewise, subsequent text in this section such as \u201c\u2026 there may be caveats on the extent to which requirements can be satisfied \u2026\u201d seems to suggest these are not universal across the architecture.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-14 20:17:11-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-08 13:02:07-08:00",
    "text": "Secs 5.9.6 defines Maximum Reordering Tolerance with an example: \"The difference of sequence number values in \u00a0  consecutive packets at the Egress cannot be bigger than \u00a0  \"MaxMisordering + 1\".\" While this definition is actionable, it interacts uncomfortably with Maximum Consecutive Loss. If MCL < MRT, there are cases where it will violate MRT but not MCL, which would subvert the usually understood meaning of reordering. Moreover, if MaxMisordering is 3, the sequence 6, 4, 0 would not trigger this definition even though there is very significant reordering here. A better example would be \"When a packet arrives at the egress after a packet with a higher sequence number, the difference between the sequence number values cannot be bigger than \u00a0  \"MaxMisordering + 1\".\"",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-09-08 02:55:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-22 06:26:51-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ipsecme-iptfs-13 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Tero Kivinen for the shepherd's detailed write-up including the WG consensus, alas the justification of the intended status is missing :-( Please note that Tatuya Jinmei is the Internet directorate reviewer (at my request) and you may want to consider this int-dir review as well: https://datatracker.ietf.org/doc/review-ietf-ipsecme-iptfs-13-intdir-telechat-jinmei-2022-08-18/ I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 6.1 ``` \u00a0  An AGGFRAG payload is identified by the ESP Next Header value \u00a0  AGGFRAG_PAYLOAD which has the value 0x5.\u00a0 The value 5 was chosen to \u00a0  not conflict with other used values.\u00a0 The first octet of this payload \u00a0  indicates the format of the remaining payload data. ``` This is in direct conflict with  RFC 4303  (see below) IMHO as 5 is already allocated to ST ( RFC 1819 , which is still 'current' even if it was never used). But ESP  RFC 4303  section 2.6 says that this is an IP protocol number (and 5 is already allocated by the IANA): ``` \u00a0  The Next Header is a mandatory, 8-bit field that identifies the type \u00a0  of data contained in the Payload Data field, e.g., an IPv4 or IPv6 \u00a0  packet, or a next layer header and data.\u00a0 The value of this field is \u00a0  chosen from the set of IP Protocol Numbers defined on the web page of \u00a0  the IANA, e.g., a value of 4 indicates IPv4, a value of 41 indicates \u00a0  IPv6, and a value of 6 indicates TCP. ``` I.e., either this document needs to formally update  RFC 4303  by allowing any number or another IP protocol number must be requested to the IANA. ### Section 2.1, generic tunnel capability  ``` \u00a0  Other non-IP-TFS uses of this AGGFRAG mode have been suggested, such \u00a0  as increased performance through packet aggregation, as well as \u00a0  handling MTU issues using fragmentation.\u00a0 These uses are not defined \u00a0  here, but are also not restricted by this document. ``` Moreover, while IPSECme charter includes: ``` The demand for Traffic Flow Confidentiality has been increasing in the user community, but the current method defined in  RFC4303  (adding null padding to each ESP payload) is very inefficient in its use of network resources. The working group will develop an alternative TFC solution that uses network resources more efficiently. ``` it says nothing about a generic tunnelling protocol, which is usually INTAREA topic, and I cannot refrain from thinking that this tunnelling mechanism could be used on any connection-less transport, e.g., UDP or IP. Hence, this DISCUSS point is only to initiate a discussion with IPSECME chairs and AD; Christian Hopps has already given some explanations when I deferred this I-D. I understand that I am in the rough here (no reaction on int-area and int-dir review is positive). ### Section 2.2.6 Please also mention hop-limit and  RFC 8200 . ### Absence of ICMP considerations Should there be an equivalent of section 6 of  RFC 4301  about ICMP ? As several unprotected packets can be bundled together, some guidance to the implementers will be welcome.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-09-04 17:43:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 18:22:06-07:00",
    "text": "## Discuss ### S6.1 * I think this document should get a separate protocol value from the IANA \u00a0 \"Protocol Numbers\" registry, since that's where 4303 S2.6 clearly says they \u00a0 values come from. \u00a0 The \"value of 41 indicates IPv6\" makes it pretty clear where this field \u00a0 gets its values from. \u00a0  https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-09-09 04:20:38-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-23 08:06:07-07:00",
    "text": "# GEN AD review of  draft-ietf-ipsecme-iptfs-14 CC @larseggert Thanks to Peter E. Yee for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/VKlfYh3uoGomO4_Lv8e6kltl36g ). ## Discuss ### Section 2.4.1, paragraph 3 ``` \u00a0 \u00a0  For similar reasons as given in [ RFC7510 ] the non-congestion- \u00a0 \u00a0  controlled mode should only be used where the user has full \u00a0 \u00a0  administrative control over the path the tunnel will take.\u00a0 This is \u00a0 \u00a0  required so the user can guarantee the bandwidth and also be sure as \u00a0 \u00a0  to not be negatively affecting network congestion [ RFC2914 ].\u00a0 In this \u00a0 \u00a0  case, packet loss should be reported to the administrator (e.g., via \u00a0 \u00a0  syslog, YANG notification, SNMP traps, etc.) so that any failures due \u00a0 \u00a0  to a lack of bandwidth can be corrected. ``` There is a lot more nuance and there are a lot more restrictions in  RFC7510  that also apply here. If a non-congestion-controlled mode is desired, especially without even using  RFC8084  circuit breakers, similar mandatory text needs to be crafted for this mechanism. (I would also strongly suggest to require circuit breakers here.) ### Section 2.4.2, paragraph 0 ``` \u00a0 2.4.2.\u00a0 Congestion-Controlled Mode ``` This mode adds a LOT of complexity to this mechanism. Is this really needed? Could not  RFC8229  be used instead of defining an entirely separate congestion control scheme for (padded/fragmented) ESP? ### Section 2.4.2.1, paragraph 1 ``` \u00a0 \u00a0  In additional to congestion control, implementations MAY choose to \u00a0 \u00a0  define and implement circuit breakers [ RFC8084 ] as a recovery method \u00a0 \u00a0  of last resort.\u00a0 Enabling circuit breakers is also a reason a user \u00a0 \u00a0  may wish to enable congestion information reports even when using the \u00a0 \u00a0  non-congestion-controlled mode of operation. ``` This makes no sense. If implemented in addition to CC, circuit breakers will never fire, because a functioning congestion control algorithm will always maintain a send rate below the circuit breaker threshold. What would make sense is to use circuit breakers in the non-congestion-controlled case, to provide a safety mechanism in cases the network provisioning changes for an active tunnel. ### Section 3.1, paragraph 0 ``` \u00a0 3.1.\u00a0 ECN Support ``` There is a lot more nuance to this, as described in RC6040. This document needs to follow that existing standard rather than define another variant. ### Section 6.1.2, paragraph 9 ``` \u00a0 \u00a0  RTT: \u00a0 \u00a0 \u00a0 \u00a0 A 22-bit value specifying the sender's current round-trip time \u00a0 \u00a0 \u00a0 \u00a0 estimate in microseconds.\u00a0 The value MAY be zero prior to the \u00a0 \u00a0 \u00a0 \u00a0 sender having calculated a round-trip time estimate.\u00a0 The value \u00a0 \u00a0 \u00a0 \u00a0 SHOULD be set to zero on non-AGGFRAG_PAYLOAD-enabled SAs.\u00a0 If the \u00a0 \u00a0 \u00a0 \u00a0 RTT is equal to or larger than 0x3FFFFF the value MUST be set to \u00a0 \u00a0 \u00a0 \u00a0 0x3FFFFF. ``` This can only encode RTTs of up to around four seconds. That is too little for Internet usage. (Same concern about other 22-bit microsecond values below.)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-08-18 09:48:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-09 20:01:05-07:00",
    "text": "One point which I think will be simple to address: (6) As malformed packets are sometimes an attack vector, it would be good to specify behavior in response to pathological BlockOffsets, for instance: - What if two BlockOffset fields disagree? e.g., with 500 byte outer packets, what if the sequence of block offsets is {0, 750, 100}? Does the third packet have 250 or 100 bytes of the first data block? Drop the packet, kill the SA, ignore one and accept the other, or something else? - What if a pad block is in a packet with a BlockOffset greater than the packet length? Would the receiver skip over the specified bytes in the subsequent packet, even though padding is supposed to only be at the end of packets?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-08-25 08:19:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 00:36:36-07:00",
    "text": "Section 7.1 creates an IANA registry with \"Expert Review\" rules.\u00a0 Of such a registry, Section 4.5 of  RFC 8126  says, among other things: \u00a0  The required documentation and review criteria, giving clear guidance \u00a0  to the designated expert, should be provided when defining the \u00a0  registry. This document doesn't do so.\u00a0 Is that guidance available somewhere else, or should some be added here?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-23 15:44:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-23 15:43:16-07:00",
    "text": "I am strongly supporting Lars' DISCUSS points (actually, enough that I decided to ballot discuss too), especially that around Section 2.4.1, paragraph 3: \u00a0  The packet send \u00a0  rate is constant and is not automatically adjusted regardless of any \u00a0  network congestion (e.g., packet loss). \u00a0  For similar reasons as given in [ RFC7510 ] the non-congestion- \u00a0  controlled mode should only be used where the user has full \u00a0  administrative control over the path the tunnel will take.\u00a0 This is \u00a0  required so the user can guarantee the bandwidth and also be sure as \u00a0  to not be negatively affecting network congestion [ RFC2914 ].\u00a0 In this \u00a0  case, packet loss should be reported to the administrator (e.g., via \u00a0  syslog, YANG notification, SNMP traps, etc.) so that any failures due \u00a0  to a lack of bandwidth can be corrected. This is a largely unrealistic requirement -- unless you are specifically meaning \"a bump-in-the-wire deployment over a point to point link\" users fairly much never have control over the path that the tunnel will take. At some point the primary path **will** go down, and the tunnel will route over some backup path, most likely at 3AM on the Sunday that the CEO's daughter is getting married... It what you are describing really is \"only ever use this as a bump-in-the-wire over a PtP interface\" or \"make sure that the configured bandwidth is many many magnitudes smaller than the smallest link in the network, even when congested\", then please state that instead. As written, this text seems dangerous: you are basically handing an enterprise network admin a DoS cannon and washing your hands of the consequences.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-25 07:23:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-23 15:44:16-07:00",
    "text": "I supporting Lars' DISCUSS points, especially that around Section 2.4.1, paragraph 3: \u00a0  The packet send \u00a0  rate is constant and is not automatically adjusted regardless of any \u00a0  network congestion (e.g., packet loss). \u00a0  For similar reasons as given in [ RFC7510 ] the non-congestion- \u00a0  controlled mode should only be used where the user has full \u00a0  administrative control over the path the tunnel will take.\u00a0 This is \u00a0  required so the user can guarantee the bandwidth and also be sure as \u00a0  to not be negatively affecting network congestion [ RFC2914 ].\u00a0 In this \u00a0  case, packet loss should be reported to the administrator (e.g., via \u00a0  syslog, YANG notification, SNMP traps, etc.) so that any failures due \u00a0  to a lack of bandwidth can be corrected. This is a largely unrealistic requirement -- unless you are specifically meaning \"a bump-in-the-wire deployment over a point to point link\" users fairly much never have control over the path that the tunnel will take. At some point the primary path **will** go down, and the tunnel will route over some backup path, most likely at 3AM on the Sunday that the CEO's daughter is getting married... It what you are describing really is \"only ever use this as a bump-in-the-wire over a PtP interface\" or \"make sure that the configured bandwidth is many many magnitudes smaller than the smallest link in the network, even when congested\", then please state that instead. As written, this text seems dangerous: you are basically handing an enterprise network admin a DoS cannon and washing your hands of the consequences.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-26 12:18:04-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 07:23:38-07:00",
    "text": "[ Chat with Christian Hopps on the telechat -- I explained my concerns and Christian will add some text around how to deploy this safely / some background context. Even if you are the network admin and in complete control of the network, having some \"here are some things to keep in mind when deploying, like that that will ALWAYS use the configured bandwidth so make sure you will always have that free during failures and congestion and things like that...\" type warnings are helpful. ] Clearing my discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-09-08 07:59:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-25 06:39:41-07:00",
    "text": "Thanks for working on this specification. I found this spec to be a mix of transport and non-transport related topics and had to think a bit more due to lack of rational behind choices made. I would like to discuss - why there is no normative text (MUST/MUST NOT) for non-congestion controlled mode over operation in this specification that prohibits the use of non-congestion controlled mode out side of controlled environment?  I am also supporting Lars's discuss on 3.1 ECN support.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-12 06:32:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-22 20:16:15-07:00",
    "text": "(A simple editorial fix) Per Section 5.8.2 of [ I-D.ietf-ace-oauth-authz ], the name of the parameter in the C-to-AS communication is \u201cace_profile\u201d (not \u201cprofile\u201d).\u00a0 The \u201cace_profile\u201d parameter is mistakenly referenced as \u201cprofile\u201d in the following places: -- Section 3.2.1:  \u00a0  The response MAY contain a \"profile\" parameter with the value \u00a0  \"coap_dtls\" to indicate that this profile MUST be used for \u00a0  communication between the client and the resource server.\u00a0  -- Section 3.3.1:  \u00a0  If the \u00a0  profile parameter is present, it is set to \"coap_dtls\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-27 10:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-09 20:27:45-07:00",
    "text": "Should be a couple easy ones: Section 2.2 discusses the \"AT_MAC attribute from the EAP-Request/AKA-Reauthentication\" in the context of computing the EAP-SIM Session-Id, but there is no such EAP-Request message for EAP-SIM.\u00a0 Presumably it should be \"EAP-Request/SIM/Re-authentication\", and a similar change in Session 2.3 (which would need to cover both the AKA and SIM cases)? We need some kind of a reference for PEAP.\u00a0 (Is draft-josefsson-pppext-eap-tls-eap  tolerable?)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-05-17 22:18:49-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-16 23:09:54-07:00",
    "text": "Thank you for the work put into this document. Please find below one blocking\u00a0 DISCUSS point and one non-blocking one. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == While I am an expert neither in multicast not in VPN, I wonder why this document is only about IPv4 and not a single word is written about IPv6.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-04-12 13:25:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-12 06:35:43-07:00",
    "text": "Thank you for the work on this document. Many thanks to Tim Bray for his ART ART review:  https://mailarchive.ietf.org/arch/msg/art/SKUKjoE9bPh62XsVezoD5mPAkz4/ , and to the authors for addressing Tim's comments. I have one question for consideration (which will not require any textual changes to the document): is \"Standard Track\" the proper track of RFC for this document? I am happy to be told by the authors, working group or responsible AD that yes - this has been discussed and the consensus was that \"Standard Track\" is the most appropriate track for this document. Normally I would look for such information in the shepherd write-up, but unfortunately I can't find my answer there, nor through my superficial archive search. Note I am not questioning the need for this document, which I understand has been discussed and has consensus, barely its track - doesn't this fit better as Informational, or even BCP (although I concur with Murray, BCP does not seem appropriate)? Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2023-03-20 23:11:34-07:00",
    "end_reason": "position_updated",
    "start": "2022-11-30 07:19:52-08:00",
    "text": "Hi There, Firstly thanks for the document.\u00a0 I have two issues I'd like to discuss and see if we can find some clarity on. The first stems from  RFC8200  Section 4.8 Third Paragraph, which reads: New hop-by-hop options are not recommended because nodes may be \u00a0  configured to ignore the Hop-by-Hop Options header, drop packets \u00a0  containing a Hop-by-Hop Options header, or assign packets containing \u00a0  a Hop-by-Hop Options header to a slow processing path.\u00a0 Designers \u00a0  considering defining new hop-by-hop options need to be aware of this \u00a0  likely behavior.\u00a0 There has to be a very clear justification why any \u00a0  new hop-by-hop option is needed before it is standardized. I believe that the document potentially needs to spell out a clearer justification to meet the requirements laid out in the above text. The second question relates to dealing with IOAM in the context of SRv6.\u00a0 With the HbH option - this is processed on a hop-by-hop basis and, as per  RFC8200 , is placed directly after the IPv6 header.\u00a0 This I don't see as a problem.\u00a0 My question comes in the case of the destination option.\u00a0 In SRv6, where a SID is, for all intents and purposes, acting like an address - I'd like to see some text dealing with what happens when the DO is applied in the context of the SRv6 where the destination address is not a normal address - but rather an IPv6 SID.\u00a0  Does the router drop the entire packet?\u00a0 Does the router \"de-encap\" as if it were a tunneled packet? Basically - I see a situation where that could lead to undefined behavior that always makes me nervous.  Could the authors, therefore, expand slightly on how the destination option is handled in the context of SRv6 and its various flavors?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-03-06 02:17:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-29 04:53:22-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Marcus Ihlar for the shepherd's detailed write-up including the WG consensus *and* the justification of the intended status.  Please note that Dave Thaler is the Internet directorate reviewer (at my request) and you may want to consider this int-dir reviews as well when Tim will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-ippm-ioam-ipv6-options/reviewrequest/16642/ I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 5.1 ``` \u00a0 \u00a0 \u00a0 Operators of an IOAM \u00a0 \u00a0 \u00a0 domain SHOULD ensure that the addition of OAM information does not \u00a0 \u00a0 \u00a0 lead to fragmentation of the packet, e.g., by configuring the MTU \u00a0 \u00a0 \u00a0 of transit routers and switches to a sufficiently high value. ``` Should it be a MUST as IPv6 routers are unable to fragment an IPv6 packet ? Should \"e.g.\" be replaced by \"i.e.\" ?  Roman's DISCUSS points are also sensible.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2023-04-08 21:51:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-11-30 22:02:50-08:00",
    "text": "# Internet AD comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @ekline * Thanks to 6MAN chairs Bob, Ole, and Jen for their last-minute \u00a0 \"IPv6 Directorate\" reviews.\u00a0 Some of their comments are reflected below. * There was kind of leaning toward concluding that the rewriting of a \u00a0 Hop-by-Hop option's size was both against the spirit of  RFC 8200  and \u00a0 not actually against the letter.\u00a0 I'm not sure that's actually the case \u00a0 and so my biggest DISCUSS is this point (more below). ## Discuss ### S4 * I don't think the Incremental Trace Option is something that can be \u00a0 supported by current text in  RFC 8200 .\u00a0 While is makes sense to have this \u00a0 behavior described in  RFC 9197 , I don't think IPv6 HbH can support it. \u00a0 My rationale for seeing this as a protocol violation is as follows. \u00a0 \u00a0 -  RFC 8200  S4.2 says this about the on-path mutability bit and the \u00a0 \u00a0 \u00a0 expectations that result: \u00a0 \u00a0 \u00a0 \"\"\" \u00a0 \u00a0 \u00a0 The third-highest-order bit of the Option Type specifies whether or \u00a0 \u00a0 \u00a0 not the Option Data of that option can change en route to the \u00a0 \u00a0 \u00a0 packet's final destination.\u00a0 When an Authentication header is present \u00a0 \u00a0 \u00a0 in the packet, for any option whose data may change en route, its \u00a0 \u00a0 \u00a0 entire Option Data field must be treated as zero-valued octets when \u00a0 \u00a0 \u00a0 computing or verifying the packet's authenticating value. \u00a0 \u00a0 \u00a0 \"\"\" \u00a0 \u00a0 - Specifically, only the Option Data (not Option Length) is allowed to \u00a0 \u00a0 \u00a0 change.\u00a0 Any AH header, for example, would still have processed the \u00a0 \u00a0 \u00a0 entire option with only the Data being zeroed -- the existence of the \u00a0 \u00a0 \u00a0 option and the length of it would still have been part of the AH \u00a0 \u00a0 \u00a0 computation. \u00a0 Unless there's some misunderstanding here I think this option would need \u00a0 removing from the document. * I think text needs to be added to make it clear that whatever options are \u00a0 used they MUST be added, though not necessarily \"filled in\", by the \u00a0 originator of the packet (the node bearing the interface assigned the \u00a0 outermost Source Address). \u00a0 The reasoning here again is the defined behavior of AH processing.\u00a0 Any \u00a0 options, even on-path mutable ones, MUST be present in the Hop-by-Hop \u00a0 option when an AH is computed.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:31:37-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:30:36-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:31:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:31:37-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:32:07-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:31:49-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ```  First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:32:35-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:32:07-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document.  ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-11-29 10:47:35-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:32:35-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document. ``` First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-08 12:28:24-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-11-29 10:47:35-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-09 CC @jgscudder ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Structure of the document; Section 5 is vague The first part of the document, through Section 4, is unproblematic for me -- you're simply allocating some IPv6 extension header option types and defining how to use them to transport fields you defined in  RFC 9197 . Fine. But Section 5 is giving me a headache. For some reason, even though this is a Standards Track document, you've structured it as some rather high-level \"considerations\" (or are they \"requirements\"? It's unclear) and then some generally-worded polite suggestions about how you could deploy it this way or that way. Is there some reason you've shied away from being prescriptive in Section 5? As the document stands, I felt a bit like I'd been presented with a puzzle. \"The solution of this problem is left as an exercise for the student\" is great in textbooks, but not so wonderful in Standards Track documents. ### Section 5.1, C5 is problematic ``` An Autonomous System (AS) that inserts and leaks the IOAM data needs to be easy to identify for the purpose of troubleshooting, due to the high complexity in identifying the source of the leak. Such a troubleshooting process might require coordination between multiple operators, complex configuration verification, packet capture analysis, etc. This requirement may require additional option or fields to be defined to identify the domain that inserted the IOAM data, this is out of the scope of this document.  ```  First, just as in C4, the underlying assumption that it's OK if an AS \"leaks the IOAM data\" appears problematic. Second, how can you both say \"this is a requirement\" and in the same paragraph \"it's out of scope\"? Surely, if this functionality is required, a finished spec is required to support it. And if the spec isn't finished, we shouldn't be advancing it, the WG should take it up and finish it, then send it back when done. Is it that this isn't truly a requirement? Or is the spec incomplete? If neither, please help me understand.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-05-05 13:49:57-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-08 12:28:24-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-ippm-ioam-ipv6-options-10 CC @jgscudder ## DISCUSS Thanks for taking care of my previous DISCUSS! I'm so sorry to have to raise another one, related to the new text.  \u00a0  C1\u00a0 IOAM MUST be deployed as a limited domain feature as defined in \u00a0 \u00a0 \u00a0 [ RFC8799 ]. I applaud your desire to be prescriptive and concise. Unfortunately, I think there are a few problems here. First the small ones: you have  RFC 8799  as an Informative reference, which is problematic since you want to make adherence to it mandatory. But, if you move it to be a Normative reference (as seems indicated), then we encounter two further issues: first and less importantly, it\u2019s not an IETF document, so possibly needs to be treated as a downref?  But most importantly, as far as I can tell  RFC 8799  does not define \u201ca limited domain feature\u201d. It provides a taxonomy for talking about limited domains and various considerations, but nothing I would call a \u201cdefinition\u201d. I confess I\u2019ve only briefly reviewed 8799 just now, not fully re-read it, so maybe you will be able to point me to a clear and actionable definition, that an implementor of your spec could apply in order to comply with C1. If so, please do let me know what that definition is, and also update your reference to cite it specifically, rather than just the RFC number. In my own review of 8799, the closest I see is Section 6, \"Functional Requirements of Limited Domains\u201d. I will be a little surprised if you really want to require adherence requirements 1-11 in that section, though. Sadly, I suspect that you\u2019ll end up concluding that  RFC 8799  isn\u2019t fit for the purpose you\u2019re trying to use it for and that you\u2019ll need to write out in your own words what the specific requirements are for your case. It looks to me as though the taxonomy section of  RFC 8799  might be quite useful to you in that respect, indeed that seems to be partly what it\u2019s for: ``` A.9. Making Use of This Taxonomy This taxonomy could be used to design or analyze a specific type of limited domain. ``` It\u2019s unfortunate that we don\u2019t have a good, citable definition of \u201climited domain\u201d in our document set... but we don\u2019t. This might be merely because nobody has bothered to write it yet, although I think the real reason is more likely that it turns out to be a sticky problem to nail it down to a definition that is both general enough to be broadly applicable and specific enough to be actionable.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-01 19:01:11-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-22 12:09:24-08:00",
    "text": "Section 4 and  RFC9197  seem clear that IOAM traffic cannot leave the IOAM domain.\u00a0 However, this document seems to be suggesting behavior that violates this guidance.\u00a0 Specifically, in Section 5.1, it allows for the possibility of leaks per (a) and explicitly describe a use case where leaks are intentional (b). (a) Section 5.1.\u00a0 C3. \u00a0 \u00a0 \u00a0 IOAM domains MUST \u00a0 \u00a0 \u00a0 provide a mechanism to prevent data leaks or be able to ensure \u00a0 \u00a0 \u00a0 that if a leak occurs, network elements outside the domain are not \u00a0 \u00a0 \u00a0 affected (i.e., they continue to process other valid packets). (b) Section 5.1. C5. \u00a0 \u00a0 \u00a0 An Autonomous System (AS) that inserts and leaks the IOAM data \u00a0 \u00a0 \u00a0 needs to be easy to identify for the purpose of troubleshooting,... Furthermore, per (a), why are \u201cIOAM domains \u2026 provid[ing] a mechanism\u201d which suggests a feature rather than a required to explicitly prevent this behavior.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-13 12:15:36-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 10:40:00-07:00",
    "text": "I have a couple points for discussion, essentially relating to how much we're diverging from HTTP and to what extent the specifics of the divergence should be specifically mentioned in the document. (1) I'd like to dig a little more into the analogy with HTTP and whether we are artificially limiting ourselves: currently we only allow 0 or 1 content-codings to be specified, but per https://www.ietf.org/archive/id/draft-ietf-httpbis-semantics-19.html#name-content-encoding the HTTP ecosystem permits multiple codings to be applied in turn to the same representation.\u00a0 While the sensor data values are likely to be relatively small and applying multiple content-codings is not likely to be useful in such a scenario, this seems like something where we should only consciously diverge from HTTP, rather than inadvertently doing so. (2) Let's also discuss whether we want to reuse ABNF rule names from HTTP while having the rule content diverge, without specific enumeration of the divergence.\u00a0 So far I found instances where this document does not allow HTAB or obs-text in places that  draft-ietf-httpbis-semantics does, which may well be the right way to spell the rule, but seems to merit a little discussion.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-10-21 08:23:13-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 22:02:45-07:00",
    "text": "This should be easy to resolve: The SenML Labels registry specifies a column called \"EXT ID\" (or actually just \"EI\" in  RFC 8428 ) that is absent from the registrations in Section 8.\u00a0 If that column should be empty for these new registrations, that should be explicit rather than implicit.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-09 20:22:07-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 09:27:48-07:00",
    "text": "There are both pretty minor points, in the grand scheme of things, but I do think it would be hazardous to publish the document without addressing them. The semantics surrounding the \"external_id_hash\" TLS extension seem insufficiently specified to admit interoperable implementation.\u00a0 In Section 3.2 we read that it \"carries a hash of the identity assertion that communicating peers have exchanged\", as if there was a single distinguished identity assertion for the session.\u00a0 But, if we read on, we learn that there is not one identity assertion, but (in the general case) two, one for each party, and that what seems to actually be intended is that each party sends the hash of the identity assertion corresponding to the sender's identity, with the requirements to send an empty external_id_hash if the party in question is not providing identity bindings.\u00a0 Additionally, the text about having an empty \"external_id_hash\" extension in ClientHello or ServerHello/EncryptedExtensions is written in a way that implies that all parties generate a ClientHello and all parties generate a ServerHello or EncryptedExtensions message, whereas these are actually conditional on whether the party is acting as (D)TLS client or server. Similarly, the current text for the last sentence of Section 3.2 (\"In TLS 1.3, the \"external_id_hash\" extension MUST be sent in the EncryptedExtensions message.\") can be (mis)read as implying that all EncryptedExtensions messages sent by TLS servers that implement this specification must include this extension, which would violate the TLS extension-negotiation model since it mandates the server sending an extension without regard to the client having indicated support for the extension.\u00a0 Perhaps \"MUST NOT be sent in the TLS 1.3 ServerHello message\" conveys the restriction more clearly? (A similar comment applies to the corresponding statement in Section 4.3, which interestingly enough already has a \"In TLS 1.3, the \"external_session_id\" extension MUST NOT be included in a ServerHello.\" disclaimer in addition to the problematic sentence.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-12 16:01:02-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 19:24:16-07:00",
    "text": "(1) Section 3.2.\u00a0 There are a few places where further clarity on error handling would be helpful:  -- Per \u201cA peer that receives an \"external_id_hash\" extension that does not match the value of the identity binding from its peer MUST immediately fail the TLS handshake with an error\u201d, which TLS error alert? -- Per \u201cA peer that receives an identity binding, but does not receive an \u2018external_id_hash\u2019extension MAY choose to fail the connection\u201d, if it does \u201cfail the connection\u201d, with which error alert?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-20 14:03:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-14 16:07:30-08:00",
    "text": "Roman's comment touched on a related point, but I'd like to (hopefully briefly) discuss the way we encode certain opaque protocol fields. There are some places where we clearly intend a hex representation (a string with a pattern that's marked out as pairs of hex digits), but there are others where we just say \"type string\" with no indication of encoding, and even a \"type binary\".\u00a0 If we want the specification to admit interoperable implementation we need to be more clear about what encoding we expect for all of these nodes.\u00a0 I have noted most (possibly all, but please double check) in the COMMENT section, with a preference for \"type binary\" where we don't need to apply regex restrictions.\u00a0 But that's just a personal preference, and choosing to use hex (or base64, or any other well-defined) encoding will suffice to resolve the discuss point.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-12-15 07:55:43-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-14 22:57:26-08:00",
    "text": "This should be easy to resolve, but we have to ask as it's pretty important: Question 7 of the shepherd writeup, about the authors and  BCP 78 /79, appears not to have been answered.\u00a0 Were these declarations made?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-14 12:16:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-30 18:33:28-07:00",
    "text": "(1) I want to check on the DTLS version compatibility of this protocol.\u00a0 If there is a DTLS version dependency, as I suspect, then we need to document it more clearly or remove it. In particular, the current specification has the Key Distributor sending the MediaKeys message before it sends the DTLS (server) Finished message (\u00a75.4), which requires that the HBH keys are available at that point.\u00a0 While the TLS exporter interface used by  RFC 5764  to output keys is an interface that DTLS 1.3 also supports, that may not be the whole story.\u00a0 In particular, in (D)TLS 1.3 the order of client and server Finished messages is reversed, so that the server Finished is sent before the client has authenticated.\u00a0 When combined with the fact that the TLS 1.3 exporter interface does not incorporate the transcript hash of the client's authentication messages, this seems to imply that the key distributor would be releasing HBH keys prior to the client's authentication and prior to the completion of the DTLS 1.3 handshake. The behavior of the TLS 1.3 exporter was considered safe for regular TLS+TCP since the server will abort the connection and not pass any application data if the client's Finished or authentication is invalid, but it poses problems for applications that use only the TLS handshake and do not use the TLS record protection to cover application data. (EAP-TLS is a notable recent example where the protocol had to be modified in order to be secure when used with TLS 1.3.)\u00a0 DTLS-SRTP is also an application that uses only the (D)TLS handshake, and I am worried that releasing HBH keys prior to authenticating the client will also prove problematic in this situation. (2) I'll also mention here so that the IESG can talk about it during our telechat (but with no intent to insist on a change): this document specifies a versioned protocol and creates a registry.\u00a0 Are we happy with the current Informational status, as opposed to Proposed Standard? I do see that the topic was touched on in the shepherd writeup, but the treatment there did not feel especially compelling to me.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-28 16:05:15-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-14 12:16:30-07:00",
    "text": "Thank you for the updates in the -10; they are improvements. I also see that we had enough discussion of Informational vs Standards-Track for this document, with no one really wanting to push for it to be a Proposed Standard. Unfortunately, I think there are still a couple places remaining that aren't quite compatible with DTLS 1.3, and so an additional revision will be required. Section 5.4 (1) \u00a0 \u00a0 When sending the ServerHello message, the Key Distributor MUST insert \u00a0 \u00a0 its own unique identifier in the external_session_id extension. This \u00a0 \u00a0 value MUST also be conveyed back to the client via SDP as a tls-id \u00a0 \u00a0 attribute. In (D)TLS 1.3, the external_session_id extension goes in the EncryptedExtensions message, not the ServerHello.\u00a0 One way to handle this scenario in a DTLS-version-agnostic manner would be NEW: \u00a0 \u00a0 The Key Distributor MUST report its own unique identifier in the \u00a0 \u00a0 \"external_session_id\" extension.\u00a0 This extension is sent in the \u00a0 \u00a0 EncryptedExtensions message in DTLS 1.3, and the ServerHello in \u00a0 \u00a0 previous DTLS versions.\u00a0 This value MUST also be conveyed back to \u00a0 \u00a0 the client via SDP as a tls-id attribute. (2) \u00a0 \u00a0 The Key Distributor MUST send a MediaKeys message to the Media \u00a0 \u00a0 Distributor as soon as a HBH encryption key is computed. The MediaKeys \u00a0 \u00a0 message includes the selected cipher (i.e. protection profile), MKI \u00a0 \u00a0 [ RFC3711 ] value (if any), SRTP master keys, and SRTP master salt values. \u00a0 \u00a0 The Key Distributor MUST use the same association identifier in the \u00a0 \u00a0 MediaKeys message as is used in the TunneledDtls messages for the given \u00a0 \u00a0 endpoint. \"As soon as a HBH encryption key is computed\" is too soon. The key is available before the endpoint is authenticated, and a properly operating DTLS-SRTP session should not send media before the mutual authentication has completed; sending the HBH encryption key \"when available\" would allow the media distributor (which has no visibility into when the DTLS handshake is completed) to send media even though the authentication is not complete.\u00a0 I think it would be more appropriate to say that the MediaKeys message is sent when the DTLS handshake is complete, which is unambiguous and a condition that is universally applicable to all DTLS versions.\u00a0 That might be written as something like NEW: \u00a0 \u00a0 The Key Distributor MUST send a MediaKeys message to the Media \u00a0 \u00a0 Distributor immediately after the DTLS handshake completes. The MediaKeys \u00a0 \u00a0 message includes the selected cipher (i.e. protection profile), MKI \u00a0 \u00a0 [ RFC3711 ] value (if any), SRTP master keys, and SRTP master salt values. \u00a0 \u00a0 The Key Distributor MUST use the same association identifier in the \u00a0 \u00a0 MediaKeys message as is used in the TunneledDtls messages for the given \u00a0 \u00a0 endpoint.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-23 21:57:40-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-23 07:01:05-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-idr-bgp-ls-flex-algo-10 CC @evyncke Thank you for the work put into this document. It is important and easy to read (even if I may have missed some points, hence my DISCUSS ballot). Please find below one blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Jie Dong for the shepherd's detailed write-up including the WG consensus, alas there is no justification for the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 3.6 unknown ? ``` \u00a0 \u00a0 \u00a0 sub-TLV types: Zero or more sub-TLV types that are unknown or \u00a0 \u00a0 \u00a0 unsupported by the node originating the BGP-LS advertisement.\u00a0 The \u00a0 \u00a0 \u00a0 size of each sub-TLV type depends on the protocol indicated by the \u00a0 \u00a0 \u00a0 Protocol-ID field.\u00a0 For example, for IS-IS each sub-TLV type would \u00a0 \u00a0 \u00a0 be of size 1 byte while for OSPF each sub-TLV type would be of \u00a0 \u00a0 \u00a0 size 2 bytes. ``` How would an originating node know that some TLVs are unknown to it ? I am probably missing something obvious here, but some clarification text would be welcome. Or simply use 'unsupported'.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-08-23 05:42:06-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-08-23 05:41:39-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I found that document pretty easy to read, but there is one point that I think may be helpful to clarify, or otherwise an explanation as to why it shouldn't be clarified: In  draft-ietf-lsr-flex-algo-20 , when describing TLVs like \"IS-IS Flexible Algorithm Exclude Admin Group Sub-TLV\" it states: \u00a0  The IS-IS FAEAG Sub-TLV MUST NOT appear more than once in a single \u00a0  IS-IS FAD Sub-TLV.\u00a0 If it appears more than once, the IS-IS FAD Sub- \u00a0  TLV MUST be ignored by the receiver. However, I couldn't find any similar text in this document.\u00a0 My presumption would be that the FAD sub-TLVs cannot appear more then once, but this didn't obviously appear to be stated anywhere (maybe it is specified in the base BGP LS spec?).\u00a0 Does this need to be stated/clarified in this document at all?\u00a0 Also, is the expected behaviour clear if the FAD TLV is not well constructed? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-08-23 07:52:17-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-23 05:42:06-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I found the document to be pretty easy to read, but there is one point that I think may be helpful to clarify, or otherwise an explanation as to why it shouldn't be clarified: In  draft-ietf-lsr-flex-algo-20 , when describing TLVs like \"IS-IS Flexible Algorithm Exclude Admin Group Sub-TLV\" it states: \u00a0  The IS-IS FAEAG Sub-TLV MUST NOT appear more than once in a single \u00a0  IS-IS FAD Sub-TLV.\u00a0 If it appears more than once, the IS-IS FAD Sub- \u00a0  TLV MUST be ignored by the receiver. However, I couldn't find any similar text in this document.\u00a0 My presumption would be that the FAD sub-TLVs cannot appear more then once, but this didn't obviously appear to be stated anywhere (maybe it is specified in the base BGP LS spec?).\u00a0 Does this need to be stated/clarified in this document at all?\u00a0 Also, is the expected behaviour clear if the FAD TLV is not well constructed? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-08-24 08:41:49-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 07:30:28-07:00",
    "text": "Thanks for working on the this specification. I would like to discuss if Flexible Algorithm Unsupported sub-TLV type should be TBD when it is suggested to 1046 in section 5?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-11-01 07:32:00-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-31 19:56:48-07:00",
    "text": "This should be extremely straightforward: either there\u2019s a typo... or I simply don\u2019t understand.\u00a0 In the Abstract: \u00a0  Dissemination of Flow Specification Rules provides a Border Gateway \u00a0  Protocol extension for the propagation of traffic flow information \u00a0  for the purpose of rate limiting or filtering IPv4 protocol data \u00a0  packets. Is that supposed to say \u201cIPv6\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-11-16 01:45:18-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 10:26:51-08:00",
    "text": "A fairly minor point, but I think that allowing Type 13 (flow label) component values to be encoded as 2-byte quantities encourages the selection of non-random flow label values, and thus violates the guidance from  RFC 6437  that these values \"should be chosen such that their bits exhibit a high degree of variability\" and that \"third parties should be unlikely to be able to guess the next value that a source of flow labels will choose.\"\u00a0 While having the short 1-byte encoding for a flow label of 0 might be reasonable, a 2-byte label can represent at most 16 bits of the 20-bit identifier space, discouraging the use of the high 4 bits, when such bits of unpredictability are scarce already. Let's discuss how big an issue this is and what might be done to mitigate it. Please also confirm that we are providing all the information required of us by  RFC 5701  and 5575bis (see comments on Section 6.1); I am not sure whether I am reading the references correctly in these regards. There seems to be an error in the sample code (flow_rule_cmp_v6()): the snippet \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  if comp_a.offset < comp_b.offset: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  return A_HAS_PRECEDENCE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  if comp_a.offset < comp_b.offset: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  return B_HAS_PRECEDENCE duplicates the condition, whereas the condition should be swapped for correct operation.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-24 07:52:22-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 23:34:49-08:00",
    "text": "Thank you for the work put into this document. It is indeed due time to filter also those IPv6 packets ;-) Please find below one blocking DISCUSS point, some non-blocking COMMENT points, and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == I am puzzled by the absence of a flow spec for the first Next-Header being a specific value and by the absence of a flowspec for the occurence of any extension header in the extension header chain. Extension headers are an important difference compared to IPv4 and could be 'nasty' as well (e.g., hop-by-hop header). Why was this not considered by the authors ? Or is there another document in the WG to address this issue ?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-11 01:26:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-10 05:06:30-07:00",
    "text": "Zahed is still on leave and has not had a chance to review Magnus' earlier DISCUSS. I deferred this document last time it was on the agenda, but since Zahed is still not back, I will put in a placeholder DISCUSS for him, so that he has a chance to complete his review. I apologize to the authors and the WG for doing this; these are exceptional circumstances. I will clear this placeholder DISCUSS as soon as Zahed is able to resume as AD (or Martin Duke indicates that he has reviewed Magnus' DISCUSS.) All that said, I do have one DISCUSS item: DOWNREF from this Standards Track doc to Informational  RFC7497 . I didn't see this called out in the Last Call, and it's also not a document we have in the DOWNREF registry already.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-21 00:14:45-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-11 01:26:47-07:00",
    "text": "DOWNREF from this Standards Track doc to Informational  RFC7497 . I didn't see this called out in the Last Call, and it's also not a document we have in the DOWNREF registry already.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-03-12 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-02-25 06:18:17-08:00",
    "text": "A) Section 8. Method of Measurement I think the metrics are fine, what makes me quite worried here is the measurement method. My concerns with it are the following. 1. The application of this measurement method is not clearly scoped. Therefore I will assume that across the Internet measurements are possible. However in that context I think the definition and protection against severe congestion has significant short comings. The main reason is that the during a configurable time period (default 1 s) the sender will attempt to send at a specified rate by a table independently on what happens during that second.  2. The algorithm for adjusting rate is table driven but give no guidance on how to construct the table and limitations on value changes in the table. In addition the algorithm discusses larger steps in the table without any reflection of what theses steps sides may represent in offered load.  3. Third the algorithms reaction to any sequence number gaps is dependent on delay and how it is related to unspecified delay thresholds. Also no text discussion how these thresholds should be configured for safe operation.  B) Section 8. Method of Measurement There are no specification of the measurement protocol here that provides sequence numbers, and the feedback channel as well as the control channel. Is this intended to use TWAMP?  From my perspective this document defines the metrics on standards track level. However, the method for actually running the measurements are not specified on a standards track level. No one can build implementation. And if the section is intended to provide requirements on a protocol that performs these measurements I think several aspects are missing. There appear several ways forward here to resolve this; one is to split out the method of measurement and define it separately to standard tracks level using a particular protocol, another is to write it purely as requirements on a measurement protocols.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-02-24 23:46:19-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-24 23:29:24-08:00",
    "text": "Several of the SHOULDs in this document are giving me trouble.\u00a0 There are two categories in particular: As described in  RFC 2119 , we typically use this sort of language to describe interoperability or security concerns.\u00a0 How are the SHOULDs in Section 9 related to interoperability or security?\u00a0 Rather, they seem to be describing issues of presentation. Since a SHOULD leaves an implementer with a choice, it's preferable to see prose explaining why one might deviate from the SHOULD advice.\u00a0 Thus, the SHOULDs in Sections 5.3 and 6.3 leave me wondering under what circumstances an implementer might legitimately choose to do something else.\u00a0 If there are none, should it be a MUST?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-02-25 07:21:11-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 23:46:19-08:00",
    "text": "Several of the SHOULDs in this document are giving me trouble.\u00a0 There are two main categories, one in particular I'd like to discuss: As described in  RFC 2119 , we typically use this sort of language to describe interoperability or security concerns.\u00a0 How are the SHOULDs in Section 9 related to interoperability or security?\u00a0 Rather, they seem to be describing issues of presentation.\u00a0 Or is this another instance of the \"operational advice\" exception that's come up on other operational advice documents?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-02-25 06:47:07-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 05:56:05-08:00",
    "text": "There were Internationalization issues raised by John Klensin and Patrik F\u00e4ltstr\u00f6m that need to bbe addressed, and I haven\u2019t seen a response to them yet.\u00a0 The primary one involves cross-cultural understanding of the meaning of emoji symbols, and, thus, weather it makes sense to use the emoji symbols themselves as protocol elements, rather than defining specific protocol elements and letting the implementation select emoji based on regional/cultural custom.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-12 12:39:29-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-24 14:47:00-08:00",
    "text": "I thought you were going to clean up whether the Content-Disposition was \"React\" or \"Reaction\" based on the gen-art review, but the document still seems internally inconsistent about it. https://mailarchive.ietf.org/arch/msg/gen-art/zun860KMrKdwqyKSWbrvWSPMuYM/ indicates that \"React\" was the intent, but Sections 2 and 4.1 still use \"Reaction\", while the IANA Considerations register \"React\".\u00a0 Section 3 uses lowercase \"reaction\" in the context of a \"Content-Disposition\" header field as well.\u00a0 Section 7 mentions a \"Reaction capability\".",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-23 15:21:39-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 17:04:23-07:00",
    "text": "Thanks to everyone who has worked on this document. I generally agree with Benjamin's discuss points, and in particular agree with his comment that it's kind of hard to figure out how all these pieces work together. I have an additional issue that is somewhat related to some of the points he raised, but which is (I think) not completely covered. I'm really confused about what the purported privacy properties of this protocol are. In section 4.3 (which I *think* talks about globally-routable IP addresses, although this is a bit unclear), the document says: \u00a0  such an IID SHOULD guarantee a stable IPv6 address \u00a0  because each data link connection is uniquely identified by the pair \u00a0  of DSAP and SSAP included in the header of each LLC PDU in NFC (Aside: this \"should\" is a simple statement of fact, not a described behavior of the protocol, and so the use of RFC-2119-style all-caps is not appropriate.) The presence of \"a stable IPv6 address\" inherently implies the ability to track devices. Then, in section 7, I find the following text: \u00a0  ...the short address of \u00a0  NFC link layer (LLC) is not generated as a physically permanent value \u00a0  but logically generated for each connection.\u00a0 Thus, every single \u00a0  touch connection can use a different short address of NFC link with \u00a0  an extremely short-lived link. This text seems to imply that addressing information is, in general, not stable, which appears to flatly contradict the text in section 4.3. Please clarify, in section 4.3, what the duration of stability of these identifiers is.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:41:27-08:00",
    "end_reason": "position_updated",
    "start": "2019-03-13 07:49:22-07:00",
    "text": "I support Benjamin's DISCUSS point about large antennas.  RFC 2119  specifies the keywords \"RECOMMENDED\" and \"NOT RECOMMENDED.\" This document uses these in verb form (\"RECOMMEND\" and \"NOT RECOMMEND\"). Please change these instances so that the actual 2119 keywords are used. = Section 4.8 = I think the Gen-ART reviewer's question about fragmentation is unresolved. How is interoperability achieved if some nodes implement MIUX and not FAR, and some nodes implement FAR and not MIUX? It seems as though IPv6-over-NFC needs to be restricted to nodes that support one or the other (presumably MIUX). = Section 5.1 and 7 = Per the Gen-ART review, one of these sections needs to say something about how connecting to the Internet potentially changes the threat model for devices that were perhaps not originally envisioned to connect to the Internet.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 12:07:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-11 18:24:12-07:00",
    "text": "In general, I'm worried that this document is so unreadable that I can't give it a proper review.\u00a0 I just don't have a clear picture of how all the pieces fit together, and which pieces are new as opposed to reused from other specifications.\u00a0 That said, here are my notes as they stand at present. If I understand correctly, the statements about \"distance of 10 cm or less\" and \"safe\" or \"secure communications\" apply only for usage compliant with the relevant legal regulations.\u00a0 We cannot expect attackers to abide by such regulations, and large (directional) antennas and/or high-power transmitters should be presumed to expand that distance by some factor, in adversarial environments. Section 4.3 should probably provide some guidance on choosing the PRF F().\u00a0 We are implicitly relying on  RFC 7217  for a lot of things, some of which 7127 doesn't even cover, and the suggested construction in  RFC 7127  may not still be best practice. I don't understand why MIUX is not mandatory (and thus we could get rid of all the \"FAR is NOT RECOMMENDED\" stuff).\u00a0 Is there known demand for IPv6 over NFC on devices that cannot do MIUX? Some section-by-section points as well: Section 3.1 \u00a0  peer mode is used for ipv6-over-nfc.\u00a0 In addition, NFC-enabled \u00a0  devices can securely send IPv6 packets to any corresponding node on \u00a0  the Internet when an NFC-enabled gateway is linked to the Internet. I don't see anything in the document that justifies the usage of \"securely\". Section 3.4 \u00a0  When the MIUX parameter is encoded as a TLV option, the TLV Type \u00a0  field MUST be 0x02 and the TLV Length field MUST be 0x02.\u00a0 The MIUX \u00a0  parameter MUST be encoded into the least significant 11 bits of the \u00a0  TLV Value field.\u00a0 The unused bits in the TLV Value field MUST be set \u00a0  to zero by the sender and ignored by the receiver.\u00a0 A maximum value Either the MIUX occupies 11 bits and there are five unused bits to be set to zero, or the four bits marked in the figure are 1011 and there is only one unused bit (singular) to be marked as zero.\u00a0 This needs to be more clear, as right now I can't tell what's intended. Section 4.4 How does a device know that the link-local address is a public address? Section 4.5 \u00a0  o\u00a0 When an NFC-enabled device (6LN) is directly connected to a 6LBR, \u00a0 \u00a0 \u00a0 an NFC 6LN MUST register its address with the 6LBR by sending a How does the device know that it's talking NFC to a 6LBR as opposed to some non-border-router peer?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-22 12:07:46-07:00",
    "text": "I attempted to review the changes from -13 to -17, as well as look at the -17 in isolation, though I do not really have enough time available to do a proper review before my term as AD expires. I'm still worried that in general this document doesn't give a clear picture of how all the pieces fit together, and which pieces are new as opposed to reused from other specifications. I do appreciate many of the updates made to streamline the introductory text and keep it focused on what is relevant for this document. I am also happy to see that use of MIUX has been made mandatory so that the L2CAP FAR is not needed.\u00a0 However, I do not see much justification for the MUST-level requirement that the MIUX value be exactly 0x480. Is there some reason to forbid the negotiation of larger link MTU, if both parties are capable?\u00a0 I would have expected only a requirement that the MIUX value be at least 0x480. Section 4.3 should probably provide some guidance on choosing the PRF F().\u00a0 We are implicitly relying on  RFC 7217  for a lot of things, some of which 7127 doesn't even cover, and the suggested construction in  RFC 7127  may not still be best practice. I think the figure in Section 3.4 that lays out the encoding of the MIUX TLV is incomplete or inaccurate -- e.g., the third field shows only four bits but the labels indicate it should occupy six bits, and the range of values for the fourth field indicates it should occupy eleven bits but the column labels give it only ten. A section-by-section point as well: Section 4.5 \u00a0  o\u00a0 When an NFC-enabled 6LN is directly connected to a an NFC-enabled \u00a0 \u00a0 \u00a0 6LBR, the NFC 6LN MUST register its address with the 6LBR by How does the device know that it's talking NFC to a 6LBR as opposed to some non-border-router peer?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-13 21:20:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-03-13 21:19:42-07:00",
    "text": "I am unable to adequately review this document because the first normative reference and hence this DISCUSS is incomplete. \u00a0  [LLCP-1.3] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"NFC Logical Link Control Protocol version 1.3\", NFC Forum \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Technical Specification , March 2016. Does not appear to be publicly available (the web site contains a single-page PDF which reads in part \"To view the complete specification, go to  http://nfc-forum.org/our-  work/specifications-and-application-documents/specifications/nfc-forum- technical-specifications/. Complete the license agreement, and then download the specification.\"). Please supply an unencumbered specification and then I can rereview. I have read S 3.4 repeatedly, but am unable to work out the mapping of an IPv6 datagram to LLCP. Please provide a diagram that shows how this works and then perhaps I can assist you with the text.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2019-03-13 21:20:18-07:00",
    "text": "I am unable to adequately review this document because the first normative reference and hence this DISCUSS is incomplete (ordinarily this would conflict with the DISCUSS guidelines, but I believe it is necessary in this case). \u00a0  [LLCP-1.3] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"NFC Logical Link Control Protocol version 1.3\", NFC Forum \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Technical Specification , March 2016. Does not appear to be publicly available (the web site contains a single-page PDF which reads in part \"To view the complete specification, go to  http://nfc-forum.org/our-  work/specifications-and-application-documents/specifications/nfc-forum- technical-specifications/. Complete the license agreement, and then download the specification.\"). Please supply an unencumbered specification and then I can rereview. I have read S 3.4 repeatedly, but am unable to work out the mapping of an IPv6 datagram to LLCP. Please provide a diagram that shows how this works and then perhaps I can assist you with the text.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-01-12 10:23:01-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 02:15:28-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-6lo-nfc-19 CC @evyncke Thank you for the work put into this document. It could indeed be useful and it would deserve a high quality specification. Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Carles Gomez for the shepherd's detailed write-up including the WG consensus *and* the justification of the intended status. But, the write-up is incorrect about the downward reference as  https://datatracker.ietf.org/doc/draft-ietf-6lo-nfc/references/  indicates  RFC 3756  is a downref... Please note that Pascal Thubert is the Internet directorate reviewer (at my request) and you may want to consider this int-dir reviews as well when Pascal will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-6lo-nfc/reviewrequest/16761/ I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Tagging of references I have not checked all references, but at least  RFC 3633  should not be normative but only informative. Moreover,  RFC3633  is obsoleted by  RFC 8415  for 4 years. ### Section 3.4 As far as I understand the document and its relationship with NFC standards, then it is not up to the IETF to use normative language around MIUX (specified by NFC), so, the \"MUST\" below should rather be \"is\". ``` \u00a0  When the MIUX parameter is used, the TLV Type field MUST be 0x02 and \u00a0  the TLV Length field MUST be 0x02.\u00a0 The MIUX parameter MUST be \u00a0  encoded into the least significant 11 bits of the TLV Value field. \u00a0  The unused bits in the TLV Value field MUST be set to zero by the \u00a0  sender and ignored by the receiver. ``` The \"MUST\" in `The MIUX value MUST be 0x480 to support the IPv6 MTU requirement (of 1280 bytes).` is of course fine. Finally, please add a normative reference to  RFC 8200 . ### Section 4.2 Is this section normative ? There is no  BCP14  words in it. If normative, then how is Network_ID derived from any NFC parameter? ### Section 4.3 While not really a DISCUSS point, what is the link between DHCP-PD and a LLA ? Remove the part about getting a prefix. What is a `secured and stable IID` ? Do the authors mean a 'random and stable IID'? ### Section 4.4 and 5 In section 4.4: `NFC supports mesh topologies but ...` In section 5: `An NFC link does not support a star topology or mesh network topology` So, is mesh supported or not ? ### Section 4.5 Is this section normative ? There is no  BCP14  terms. Is there a IANA registry for \"Dispatch\" values ? If so, then please add a reference. It *seems* that the length is 1 octet, please specify the length of the value. ### Section 4.6 Possibly due to my ignorance of  RFC 6282 , but this document refers to TCP (section 4.1) while  RFC 6282  only compresses UDP ?  Is `6-bit NFC link-layer` the same as the `6-bit SSAP` discussed before ? I guess so but I should not guess but be sure. ### Section 4.8 Is this section normative about multicast replication ? ### Section 5.1 ``` \u00a0  Two or more 6LNs may be connected with a 6LBR, but each connection \u00a0  uses a different subnet. ``` Unsure whether 'subnet' means 'IPv6 prefix' or 'link' ? `the 6LBR MUST ensure address collisions do not occur` how can this goal be achieved.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2023-01-18 02:39:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 13:07:33-08:00",
    "text": "I share other ADs' concern about availability of the NFC spec, however it is my understanding that Erik has had access to it, and I trust he was able to do a full review of the draft. Given that, I would ballot No Objection. However I have identified what I think is a simple typo, but important enough to warrant a blocking comment. Section 4.8: > Length: > > This is the length of this option (including the type and length fields) in units of 8 octets. The value of this field is 1 for 6-bit NFC node addresses. I believe you meant \"in octets\" or \"in units of 8 bits\", right?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-12-13 23:22:29-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 04:27:50-08:00",
    "text": "# GEN AD review of  draft-ietf-6lo-nfc-19 CC @larseggert ## Discuss ### Section 9, paragraph 2 ``` \u00a0 \u00a0  [LLCP-1.4] \"NFC Logical Link Control Protocol, Version 1.4\", NFC \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Forum Technical Specification , January 2021. ``` Eric raised this for -13 in 2019 already: this specification does not seem to be publicly available? Did the NFC forum share a copy with the IETF WG that you could forward to the IESG for our review?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-12-30 14:37:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-12-28 06:59:32-08:00",
    "text": "(Preliminary ballot from an incomplete review of the document, but shared here for early awareness) Multiple prior DISCUSes were filed on the basis of concerns that the base normative references were not available.\u00a0 In response, the \"NFC LLC v1.4\" specification was shared. However, it appears additional normative references are needed to evaluate the security claims of the protocol (NFC LLC v1.4). Section 7 of this I-D says: \u00a0  Ad-hoc secure data transfer can be established between two \u00a0  communication parties without any prior knowledge of the \u00a0  communication partner.\u00a0 Ad-hoc secure data transfer can be vulnerable \u00a0  to Man-In-The-Middle (MITM) attacks.\u00a0 Authenticated secure data \u00a0  transfer provides protection against Man-In-The-Middle (MITM) \u00a0  attacks.\u00a0 In the initial bonding step, the two communicating parties \u00a0  store a shared secret along with a Bonding Identifier.\u00a0 For all \u00a0  subsequent interactions, the communicating parties re-use the shared \u00a0  secret and compute only the unique encryption key for that session. \u00a0  Secure data transfer is based on the cryptographic algorithms defined \u00a0  in the NFC Authentication Protocol (NAP). This text is a cut-and-paste verbatim from Section 3.2.5 of NFC Forum LLC specification previously shared as part of the last telechat.\u00a0 However the NAP is defined in yet another NFC Forum document.\u00a0 How does one access that?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-02-02 13:01:22-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-30 14:37:17-08:00",
    "text": "(revised) Multiple DISCUSes were filed during the March 2019 telechat on the basis of concerns that the underlying normative references were not available.\u00a0 In response, the \"NFC LLC v1.4\" specification was shared in advance of the December 2022 telechat. However, it appears additional normative references are needed to evaluate the security claims of the protocol (NFC LLC v1.4). Section 7.1 of NFC LLC v1.4 says: Secure data transfer uses the NFC Authentication Protocol [NAP]. This subsection defines three processes: Security Setup, Bonding Process and Authentication Process. All three processes are mappings of the corresponding processes with the same names defined in [NAP]. Section 7 of this I-D says: \u00a0  Ad-hoc secure data transfer can be established between two \u00a0  communication parties without any prior knowledge of the \u00a0  communication partner.\u00a0 Ad-hoc secure data transfer can be vulnerable \u00a0  to Man-In-The-Middle (MITM) attacks.\u00a0 Authenticated secure data \u00a0  transfer provides protection against Man-In-The-Middle (MITM) \u00a0  attacks.\u00a0 In the initial bonding step, the two communicating parties \u00a0  store a shared secret along with a Bonding Identifier.\u00a0 For all \u00a0  subsequent interactions, the communicating parties re-use the shared \u00a0  secret and compute only the unique encryption key for that session. \u00a0  Secure data transfer is based on the cryptographic algorithms defined \u00a0  in the NFC Authentication Protocol (NAP). The described security properties appear to depend on the \u201cNFC Authentication Protocol\u201d (NAP) which is neither formally referenced with a normative reference (like the NFC LLC v1.4 specification) and does not appear to be available.\u00a0 It is challenging to evaluate the security claims without it. Thank you to the document authors for responding to a preliminary version of this DISCUSS position which said that it is not possible to share the NAP specification. See  https://mailarchive.ietf.org/arch/msg/6lo/ii9ANOvsJKr08kr7oOCWQ635GtI/ .\u00a0 If the specification is not available, it isn\u2019t clear how the IETF consensus review process is possible.\u00a0 The shepherd write-up says \u201cAccess to the NFC spec has been available for those that have needed it.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-02-28 04:23:07-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-04 18:19:22-08:00",
    "text": "Thanks for working on this specification. Thanks to Wesley Eddy for his excellent TSVART review.  As I agree with the points brought up by the TAVART reviewer, I would like to discuss why the points made by the reviewer should not be considered for this specification.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-02-07 06:45:32-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-06 10:40:50-08:00",
    "text": "If I understand correctly, in JMAP transport confidentiality is required to use for requests and in WebSocket it is required to implement but not required to use. Which set of requirements applies to the binding specified in this document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-17 16:23:48-08:00",
    "end_reason": "position_updated",
    "start": "2020-01-07 13:08:25-08:00",
    "text": "I support Alissa's Discuss and suggest an approach of making a definitive statement about \"wss://\" usage, akin to  RFC 8620 's \"All HTTP requests MUST use the 'https://' scheme\". I don't understand how adding a \"pushState\" value to the StateChange object (Section 4.2.4.1) that reflects the state of \"ALL of the data types in the account\" can work, if the regular StateChange and notification flows are not tied to a specific account (and in fact the example in Section 7.1.1 of  RFC 8620  includes state changes about multiple accounts in a single StateChange) but rather the authentication credentials.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-18 16:15:54-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-03 06:58:37-08:00",
    "text": "Section 5.2.\u00a0 Per \u201cSample video test sequences are available at: [xiph-seq] and [HEVC-seq].\u00a0 The following two video streams are the recommended minimum for testing: Foreman and FourPeople.\u201d, these test sequences seems underspecified. ** Is the \u201crecommended\u201d here intended to be normative?\u00a0 There is no  RFC2119  boiler plate in this document to guide the parsing of the text. ** From the text, there wasn\u2019t much precision in where to find these recommended videos (Foreman and FourPeople).\u00a0 At the url pointed to by [HEVC-seq], I found the filenames \u201cFourPeople_1280x720_60.yuv\u201d and \u201cforeman15_4000.yuv\u201d, is that them? ** Is it expected for  http://www.netlab.tkk.fi/~varun/test_sequences/foreman15_4000.yuv  to be 0 bytes?\u00a0 I tried on 03/03/2020 at ~0950 EST ** Give that that one of the recommended urls doesn\u2019t work even before this draft is published, I have great reservation with keeping a normative \u201crecommended\u201d to such external repositories.\u00a0 However, providing pointers to repositories of \u201csample video test sequences\u201d makes sense to me and is helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-10-07 17:09:54-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-10-07 14:15:12-07:00",
    "text": "\"If a Shutdown Communication longer than 128 octets is sent to a BGP \u00a0  speaker that implements [ RFC8203 ], then that speaker will treat it as \u00a0  an error, the consequence of which is a log message.\u00a0 For this \u00a0  reason, operators would be wise to keep shutdown communications to \u00a0  less than 128 octets when feasible.\" I have a similar question to what \u00c9ric asked. Doesn't the above mostly undercut the value of doing this bis at all? If operators can't expect longer messages to be understood, under what circumstances will they send them? I'm not at all steeped in BGP operations, but was it considered to instead add a new subcode to the BGP Cease NOTIFICATION subcode registry to capture this case (admin reset or shutdown with long shutdown message)? That way at least those who want to use it can differentiate between recipients that don't support  RFC 8203 , those that do, and those that support longer communications.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-11-25 11:21:41-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-07 17:09:54-07:00",
    "text": "\"If a Shutdown Communication longer than 128 octets is sent to a BGP \u00a0  speaker that implements [ RFC8203 ], then that speaker will treat it as \u00a0  an error, the consequence of which is a log message.\u00a0 For this \u00a0  reason, operators would be wise to keep shutdown communications to \u00a0  less than 128 octets when feasible.\" I have a similar question to what \u00c9ric asked. Doesn't the above mostly undercut the value of doing this bis at all? If operators can't expect longer messages to be understood, will they implement some kind of policy logic or heuristics to decide when to try to send them and when not? Otherwise, under what circumstances will they send them? Was it considered to instead add a new subcode to the BGP Cease NOTIFICATION subcode registry to capture this case (admin reset or shutdown with long shutdown message)? That way at least those who want to use it can differentiate between recipients that don't support  RFC 8203 , those that do, and those that support longer communications. I'm not at all steeped in BGP so I'm happy to drop this if it's unworkable, but I wanted to ask.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-15 16:17:43-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 15:15:03-08:00",
    "text": "Section 3 Security and Encryption: Though 6LoWPAN basic specifications do \u00a0 \u00a0 \u00a0 not address security at the network layer, the assumption is that \u00a0 \u00a0 \u00a0 L2 security must be present.\u00a0 In addition, application-level \u00a0 \u00a0 \u00a0 security is highly desirable.\u00a0 The working groups [IETF_ace] and \u00a0 \u00a0 \u00a0 [IETF_core] should be consulted for application and transport \u00a0 \u00a0 \u00a0 level security.\u00a0 The 6lo working group has worked on address \u00a0 \u00a0 \u00a0 authentication [ RFC8928 ] and secure bootstrapping is also being \u00a0 \u00a0 \u00a0 discussed in the IETF.\u00a0 However, there may be other security \u00a0 \u00a0 \u00a0 mechanisms available in a deployment through other standards such \u00a0 \u00a0 \u00a0 as hardware-level security or certificates for the initial booting \u00a0 \u00a0 \u00a0 process.\u00a0 Encryption is important if the implementation can afford \u00a0 \u00a0 \u00a0 it. With the exception of authentication and secure bootstrapping, this text is vague on what security properties are to be considered.\u00a0 Likewise, saying \u201cencryption\u201d is not informative as it can help provide specific (but unnamed) security properties.\u00a0 What is intended is not clear.\u00a0 Specifically: -- What is the \u201cL2 security\u201d that \u201cmust be present\u201d specifically?\u00a0 What properties are being addressed (e.g., confidentiality?\u00a0 Authenticity?) -- What is \u201capplication-level security\u201d that is \u201cdesirable\u201d? -- \u201cAffordability\u201d on what dimension per the supporting encryption?\u00a0 Is that a notional budget for the application, power/battery, etc?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2019-08-29 14:19:29-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 23:37:07-07:00",
    "text": "Thanks to everyone who invested time in developing this mechanism. I have two blocking comments that should be quite easy to resolve. --------------------------------------------------------------------------- \u00a75: >\u00a0 MASA URI is \"https://\" iauthority \"/.well-known/est\". This doesn't make sense: iauthority is a component of IRIs, not of URIs. In URIs this is simply an \"authority.\" It's not simply a terminology distinction: converting from an iauthority to an authority requires idna encoding. Please consult with an IRI expert (which I do not consider myself to be) to work out the proper terminology and procedures here.\u00a0 If you need help finding an expert, please let me know and I'll track someone down for you. --------------------------------------------------------------------------- \u00a75.8: >\u00a0 Rather than returning the audit log as a response to the POST (with a >\u00a0 return code 200), the MASA MAY instead return a 201 (\"Created\") >\u00a0 RESTful response ([ RFC7231 ] section 7.1) containing a URL to the >\u00a0 prepared (and easily cachable) audit response. The DISCUSS portion of my comment on this text is that it is unclear about how the URL is to be returned. It can just as easily be interpreted as returning it in a \"Location\" header field as it could as returning it in the response body -- or maybe somewhere else entirely (e.g., a link relation).\u00a0 This ambiguity will cause an interop issue. Please be explicit about precisely how the value is conveyed. While not part of the DISCUSS, I also have a fairly serious comment on the phrasing and citation of\u00a0 \"return a 201 (\"Created\") RESTful response ([ RFC7231 ] section 7.1)\". Section 7.1 points to the top-level discussion of Control Data header fields, rather than any general discussion of RESTful responses.\u00a0 It's worth noting that the term \"RESTful\" never appears in  RFC 7231 , so it's really unclear what section this was attempting to target. Perhaps 6.3.2?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-11 06:23:05-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-11 06:20:30-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. 1) In Section 5: \u00a0  o\u00a0 In the language of [ RFC6125 ] this provides for a SERIALNUM-ID \u00a0 \u00a0 \u00a0 category of identifier that can be included in a certificate and \u00a0 \u00a0 \u00a0 therefore that can also be used for matching purposes.\u00a0 The \u00a0 \u00a0 \u00a0 SERIALNUM-ID whitelist is collated according to manufacturer trust \u00a0 \u00a0 \u00a0 anchor since serial numbers are not globally unique. I think now you are just inventing things. Please define what exactly SERIALNUM-ID is. Cut & paste text from  RFC 6125 , if needed. 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? 3) In 5.8 \u00a0  This is done with an HTTP GET using the operation path value of \u00a0  \"/.well-known/est/requestauditlog\". Here you say to use HTTP GET. \u00a0  The registrar SHOULD HTTP POST the same registrar voucher-request as But you only define how to use POST. I think the first \"GET\" is supposed to be \"POST\". 4) In 5.8.1: Format of different fields is not defined, so this is not interoperable. 5) In 8.1: \u00a0  This document extends the definitions of \"est\" (so far defined via \u00a0   RFC7030 ) in the \" https://www.iana.org/assignments/well-known-uris/ \u00a0  well-known-uris.xhtml\" registry as follows: \u00a0  o\u00a0 add /.well-known/est/requestvoucher (see Section 5.5 ) \u00a0  o\u00a0 add /.well-known/est/requestauditlog (see Section 5.7) The .well-known URIs IANA registry doesn't list anything below the first level (i.e. \"est\" in your case). So I think you really want to have 2 IANA actions here: a) Add the reference to this document as another reference for \"est\". b) create a new registry of \"est\" URIs and add your 2 URIs above to it and also populate other entries from the original EST RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-07-15 02:30:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-11 06:23:05-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) In Section 5: \u00a0  o\u00a0 In the language of [ RFC6125 ] this provides for a SERIALNUM-ID \u00a0 \u00a0 \u00a0 category of identifier that can be included in a certificate and \u00a0 \u00a0 \u00a0 therefore that can also be used for matching purposes.\u00a0 The \u00a0 \u00a0 \u00a0 SERIALNUM-ID whitelist is collated according to manufacturer trust \u00a0 \u00a0 \u00a0 anchor since serial numbers are not globally unique. I think now you are just inventing things. Please define what exactly SERIALNUM-ID is. Cut & paste text from  RFC 6125 , if needed. 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? 3) In 5.8 \u00a0  This is done with an HTTP GET using the operation path value of \u00a0  \"/.well-known/est/requestauditlog\". Here you say to use HTTP GET. \u00a0  The registrar SHOULD HTTP POST the same registrar voucher-request as But you only define how to use POST. I think the first \"GET\" is supposed to be \"POST\". 4) In 5.8.1: Format of different fields is not defined, so this is not interoperable. 5) In 8.1: \u00a0  This document extends the definitions of \"est\" (so far defined via \u00a0   RFC7030 ) in the \" https://www.iana.org/assignments/well-known-uris/ \u00a0  well-known-uris.xhtml\" registry as follows: \u00a0  o\u00a0 add /.well-known/est/requestvoucher (see Section 5.5 ) \u00a0  o\u00a0 add /.well-known/est/requestauditlog (see Section 5.7) The .well-known URIs IANA registry doesn't list anything below the first level (i.e. \"est\" in your case). So I think you really want to have 2 IANA actions here: a) Add the reference to this document as another reference for \"est\". b) create a new registry of \"est\" URIs and add your 2 URIs above to it and also populate other entries from the original EST RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-16 09:14:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-15 02:30:30-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) In Section 5: \u00a0  o\u00a0 In the language of [ RFC6125 ] this provides for a SERIALNUM-ID \u00a0 \u00a0 \u00a0 category of identifier that can be included in a certificate and \u00a0 \u00a0 \u00a0 therefore that can also be used for matching purposes.\u00a0 The \u00a0 \u00a0 \u00a0 SERIALNUM-ID whitelist is collated according to manufacturer trust \u00a0 \u00a0 \u00a0 anchor since serial numbers are not globally unique. I think now you are just inventing things. Please define what exactly SERIALNUM-ID is. Cut & paste text from  RFC 6125 , if needed. 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? 3) Resolved 4) In 5.8.1: Format of different fields is not defined, so this is not interoperable. 5) In 8.1: \u00a0  This document extends the definitions of \"est\" (so far defined via \u00a0   RFC7030 ) in the \" https://www.iana.org/assignments/well-known-uris/ \u00a0  well-known-uris.xhtml\" registry as follows: \u00a0  o\u00a0 add /.well-known/est/requestvoucher (see Section 5.5 ) \u00a0  o\u00a0 add /.well-known/est/requestauditlog (see Section 5.7) The .well-known URIs IANA registry doesn't list anything below the first level (i.e. \"est\" in your case). So I think you really want to have 2 IANA actions here: a) Add the reference to this document as another reference for \"est\".  -- This was addressed. b) create a new registry of \"est\" URIs and add your 2 URIs above to it and also populate other entries from the original EST RFC.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-16 09:22:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-16 09:14:15-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) Resolved 2) In 5.6: \u00a0  assertion:\u00a0 The method used to verify assertion.\u00a0 See Section 5.5.5. Section 5.5.5 doesn't define syntax of this field in enough details to implement. Can it contain one of the allowed values (like C enum)? \u2014 I couldn\u2019t quite figure out what was changed from wdiff. I don\u2019t think this was addressed. 3) Resolved 4) In 5.8.1: Format of different fields is not defined in enough details, so this is not interoperable. Please specify what format is used for dates and nonces. 5) Resolved",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-09-17 04:17:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-09-16 09:22:17-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) Resolved 2) Resolved 3) Resolved 4) In 5.8.1: Format of different fields is not defined in enough details, so this is not interoperable. Please specify what format is used for dates and nonces. 5) Resolved",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-10-16 03:42:49-07:00",
    "end_reason": "position_updated",
    "start": "2019-09-17 04:17:15-07:00",
    "text": "Thank you for this document. Despite comments/DISCUSSes raised, this was a good read. I agree with DISCUSS points from Alissa, Adam and Roman. 1) Resolved 2) Resolved 3) Resolved 4) In 5.8.1: Format of different fields is not defined in enough details, so this is not interoperable. Are numeric fields always represented as JSON numbers? 5) Resolved",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-10-16 07:49:58-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 13:42:22-07:00",
    "text": "I apologize if I'm misunderstanding how this works, but I didn't see much discussion in the document about the implications of the manufacturer going out of business. Specifically, it seems like if a device ships with BRSKI as its only available mechanism for bootstrapping and the manufacturer goes out of business before the device is enrolled, the ability for the device to function securely on the network may be significantly impaired if not impossible. It seems like this document needs to make clear to manufacturers that a fallback manual enrollment mechanism of some sort needs to be implemented along with BRSKI in order to avoid this situation. = Section 1.3.1 = \"But this solution is not exclusive to large equipment: it is intended \u00a0  to scale to thousands of devices located in hostile environments, \u00a0  such as ISP provided CPE devices which are drop-shipped to the end \u00a0  user.\" I don't quite understand how this squares with the scope limitation described in Section 1 and Section 9. If the whole network is professionally managed by the ISP, what part would be the \"hostile environment\"?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:49:43-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-16 07:56:11-07:00",
    "text": "Apologies for the multiple emails, I failed to realize there was a new Gen-ART review for this document. The follow-up from the Gen-ART review seems to indicate that a YANG doctor review of this document is needed and/or that the YANG issues raised by Tom Petch need fixing. Is there a plan to get either of those done?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-17 07:08:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 22:30:04-07:00",
    "text": "(1) The text of the document suffers from lack of clarity throughout about whether the nonce-ful operation is mandatory or not, with several figures and discussions making declarative statements about nonce usage and others saying that nonce usage is optional. (See COMMENT.) (2) There also seems to be internal inconsistency about the proximity assertion process (and, any sort of assertion in a voucher-request at all, it seems).\u00a0 I've tried to note some locations in the Comment section. (3) There are other internal inconsistencies as well, including about section references for when various behaviors occur (see COMMENT). (4) In Section 5.6.1 \u00a0  The pledge MUST verify that the voucher nonce field is accurate and \u00a0  matches the nonce the pledge submitted to this registrar, or that the \u00a0  voucher is nonceless (see Section 7.2). Is the pledge supposed to accept a nonceless voucher in response to a nonce-ful voucher request? (5)  RFC7951  is cited for the audit log response, but I cannot find the underlying YANG module that is JSON-encoded using the  RFC 7951 procedures. Furthermore, I don't think the \"nonce\" handling (with explicit \"NULL\" string where base64-encoded binary data might be expected) would be consistent with the 7951 rules. (5) the new /enrollstatus EST endpoint seems under-specified. (6) In Section 7.2: \u00a0  The pledge can choose to accept vouchers using less secure methods. \u00a0  These methods enable offline and emergency (touch based) deployment \u00a0  use cases: \u00a0  1.\u00a0 The pledge MUST accept nonceless vouchers.\u00a0 This allows for a use It's very unclear to me what this \"MUST\" means, especially so given that the entire section 7 is declared to be non-normative.\u00a0 Is it that the client \"can choose\" whether it \"MUST accept nonceless vouchers\"? That would seem to make the MUST basically ineffective. More broadly, if the entire Section 6 is non-normative, why is there any normative language in it? (7) the new /enrollstatus and /voucher_status well-known EST endpoints are not registered in Section 8.1 (7.1) I think we also need to register the \"urn:ietf:params:xml:ns:yang:ietf-mud-brski-masa\"\u00a0 XML namespace. (8) The versioning mechanism for Pledge BRSKI Status Telemetry is underspecified, including the interaction with new registered values. (9) The versioning mechainsm for the MASA audit log response is underspecified, including whether a registry of field names is appropriate. (10) The term PKIX seems to be incorrectly used a few times; it refers to the Internet PKI, and so things like a private PKI internal to a manufacturer would probably not be best described as such.\u00a0 Such private PKIs can of course still reuse the protocols and mechanisms developed for PKIX, and it's accurate to describe them as such. (11) In a few places we describe the voucher-request in terms of its YANG structure but do not say that it has to be wrapped in a signed CMS object as is done for the  RFC 8366  voucher. (12) Maybe this is a \"discuss discuss\", but why do we need SHA-1 in the domainID calculation? (13) In Section 5.5.1: \u00a0  As described in [ RFC8366 ] vouchers are normally short lived to avoid \u00a0  revocation issues.\u00a0 If the request is for a previous (expired) \u00a0  voucher using the same registrar then the request for a renewed \u00a0  voucher SHOULD be automatically authorized.\u00a0 The MASA has sufficient I don't understand what \"for a previous (expired) voucher\" means. Is it something like \"containing the same content as a previous voucher request for which a voucher was issued\", with the presumption that the voucher expired before the pledge could successfully imprint, so it needs to try again?\u00a0 Or does this extend to longer timescales, like a device that gets deployed for a couple years and is\u00a0 then reset to factory settings and has to rebootstrap but is still by the same registrar? (14) In Section 5.6: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 The server MUST answer with a suitable 4xx \u00a0  or 5xx HTTP [ RFC2616 ] error code when a problem occurs.\u00a0 In this \u00a0  case, the response data from the MASA MUST be a plaintext human- \u00a0  readable (ASCII, English) error message containing explanatory \u00a0  information describing why the request was rejected. It seems hard to support this stance on internationalization in 2019. (15) In Section 5.9.4: \u00a0  To indicate successful enrollment the client SHOULD re-negotiate the \u00a0  EST TLS session using the newly obtained credentials.\u00a0 This occurs by \u00a0  the client initiating a new TLS ClientHello message on the existing \u00a0  TLS connection.\u00a0 The client MAY simply close the old TLS session and \u00a0  start a new one.\u00a0 The server MUST support either model. Is this supposed to be sending a new TLS ClientHello in the application data channel or as a new handshake message (aka \"renegotiation\")?\u00a0 The latter is not possible in TLS 1.3 and is generally disrecommended anyways even in TLS 1.2.\u00a0 I would strongly suggest to remove the \"renegotiation\" option and just leave \"close the connection and start a new connection/handshake\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-17 18:25:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-17 07:08:34-07:00",
    "text": "Thanks for the time and attention to detail put into addressing my previous Discuss and Comment points.\u00a0 I have one new Discuss-level point and one that I think may have been missed (probably because I inadvertently numbered two points with the same number). (16) The audit log response (Section 5.8.1) describes the nonce as a JSON string, but the  RFC 8366  nonce is a binary value.\u00a0 I think we need to describe some mapping procedure (such as always base64-encoding as is done for domainID, even if the original nonce is itself base64-encoded random data) in order to be fully functional. % (1) The text of the document suffers from lack of clarity throughout about % whether the nonce-ful operation is mandatory or not, with several % figures and discussions making declarative statements about nonce usage % and others saying that nonce usage is optional. (See COMMENT.) [keep in mind when reading] % (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-23 22:35:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-17 18:25:00-07:00",
    "text": "Thanks for the time and attention to detail put into addressing my previous Discuss and Comment points.\u00a0 I have one new Discuss-level point and one that I think may have been missed (probably because I inadvertently numbered two points with the same number). (16) The audit log response (Section 5.8.1) describes the nonce as a JSON string, but the  RFC 8366  nonce is a binary value.\u00a0 I think we need to describe some mapping procedure (such as always base64-encoding as is done for domainID, even if the original nonce is itself base64-encoded random data) in order to be fully functional. % (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-28 20:53:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-23 22:35:24-07:00",
    "text": "Thanks for the time and attention to detail put into addressing my previous Discuss and Comment points.\u00a0 I have one new Discuss-level point and one that I think may have been missed (probably because I inadvertently numbered two points with the same number). (16) The audit log response (Section 5.8.1) describes the nonce as a JSON string, but the  RFC 8366  nonce is a binary value.\u00a0 I think we need to describe some mapping procedure (such as always base64-encoding as is done for domainID, even if the original nonce is itself base64-encoded random data) in order to be fully functional. % (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object. Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-20 14:31:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-10-28 20:53:53-07:00",
    "text": "% (5.1) the new /enrollstatus EST endpoint seems under-specified. Shame on me, I reused (5) for two points and have renumbered this to (5.1) so we don't miss it again.\u00a0 We don't anywhere give a formal description of the contents of the POST body; there's just an example JSON object. The -29 reworks the definition of the 'nonce' field to be: \u00a0 \u00a0 \u00a0 strong random or pseudo-random number nonce (see [ RFC4086 ] section \u00a0 \u00a0 \u00a0 6.2).\u00a0 As the nonce is usually generated very early in the boot \u00a0 \u00a0 \u00a0 sequence there is a concern that the same nonce might generated \u00a0 \u00a0 \u00a0 across multiple boots, or after a factory reset.\u00a0 Difference \u00a0 \u00a0 \u00a0 nonces MUST NOT generated for each bootstrapping attempt, whether \u00a0 \u00a0 \u00a0 in series or concurrently.\u00a0 The freshness of this nonce mitigates \u00a0 \u00a0 \u00a0 against the lack of real-time clock as explained in Section 2.6.1. This needs to either be \"Different nonces MUST be generated\" or \"the same nonce MUST NOT be reused\"; this mashup is no good. Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-03 10:43:47-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-20 14:31:04-08:00",
    "text": "Thanks for providing a clear specification of the /enrollstatus EST endpoint in the -30.\u00a0 The following two points still seem unaddressed, though. The -29 reworks the definition of the 'nonce' field to be: \u00a0 \u00a0 \u00a0 strong random or pseudo-random number nonce (see [ RFC4086 ] section \u00a0 \u00a0 \u00a0 6.2).\u00a0 As the nonce is usually generated very early in the boot \u00a0 \u00a0 \u00a0 sequence there is a concern that the same nonce might generated \u00a0 \u00a0 \u00a0 across multiple boots, or after a factory reset.\u00a0 Difference \u00a0 \u00a0 \u00a0 nonces MUST NOT generated for each bootstrapping attempt, whether \u00a0 \u00a0 \u00a0 in series or concurrently.\u00a0 The freshness of this nonce mitigates \u00a0 \u00a0 \u00a0 against the lack of real-time clock as explained in Section 2.6.1. This needs to either be \"Different nonces MUST be generated\" or \"the same nonce MUST NOT be reused\"; this mashup is no good. Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-02-24 11:25:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-01-03 10:43:47-08:00",
    "text": "I think we're down to just: Email exchange with mcr notes: >\u00a0 \u00a0  > An RFC Editor note about the  RFC 8366  assignment of OID >\u00a0 \u00a0  > 1.2.840.113549.1.9.16.1.40 was removed from -23 to -28; do the examples >\u00a0 \u00a0  > properly use that assigned OID now? >  > We got a MASA URL Extension OID for: >\u00a0 \u00a0 1.3.6.1.5.5.7.1.32 >  > the examples date from before that, and do not use it yet. We need to fix the examples before publication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-30 17:03:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-24 11:25:17-08:00",
    "text": "Thanks for the updated examples using the allocated MASA URL extension OID! Unfortunately, I think there are still some inconsistencies in the examples to resolve: The MASA cert/key is identical to the \"manufacturer key pair for IDevID signatures\" (C.1.1 and C.1.2).\u00a0 (It shows the MASA Subject CN, so maybe  just the included file was typo'd?)\u00a0 The example IDevID cert shows an issuer name that doesn't match the cert given. (Also the MASA cert doesn't have a randomized serial number but the registrar one does.) The registrar-to-MASA voucher request in C.2.2 seems to have a CMS SignedData with the SignerIdentifier identifying the \"Unstrung Fountain Root\" (i.e,. the root CA used for these examples) instead of the expected \" fountain-test.example.com \".\u00a0 Am I misreading the ASN.1 dump? (We do seem to send both certificates.) The voucher response from MASA to Registrar seems to be signed by the \" highway-test.example.com  CA\" (which would be the \"manufacturer key pair for IDevID signatures\" that we don't have in the -35 since the MASA certificate is repeated), not the MASA's cert from C.1.1.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-02 18:56:08-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-30 17:03:27-07:00",
    "text": "Thanks for the updates leading to the -39; I believe we're almost there! Unfortunately, it seems that the \"pinned-domain-cert\" in the issued voucher is the registrar's cert, not the CA cert.\u00a0 (Given that the documented workflow is to extract this CA cert from the registrar-voucher-request CMS object, and the registrar-voucher-request in our examples does include both the registrar cert and the CA cert, I wonder if this reflects a bug in the code itself used to generate the examples, in that it picks the wrong cert?)\u00a0 My understanding is that the protocol requires this field to be populated by a CA cert, and the registrar's cert is not a CA cert. I am very hopeful that we can just regenerate the voucher without having to redo the rest of the examples, since we have all the keys and certificate enshrined in the document already, and my apologies for not noticing whether this issue was present in previous revisions as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-08-30 00:47:09-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-10 03:25:08-07:00",
    "text": "Thank you (and so many friends in the authors' list!) for the work put into this document; it took a while to get to this stage ;-) The intersection with MUD is also a nice feature. I have a couple of DISCUSSes (probably easy to fix) and _several_ COMMENTs and some nits (after a couple of nits, I stopped marking them). I also stopped writing COMMENTs after section 5.3. Regards, -\u00e9ric == DISCUSS == TLS is assumed to be used but I failed to find WHICH version of TLS MUST be used. The only reference in the reference section is version 1.2. Probably worth to refer to this version in the text as well and use version 1.3 of TLS. -- Section 2.3.1 -- Does the \"serial number\" need to be unique per vendor ? I guess so then I strongly suggest to use a different word than \"serial number\" (e.g. unique device ID) as a vendor can have multiple products in its portfolio, each having a different set of unique \"serial numbers\". -- Section 3.3 -- The example 1 does not include the mandatory (per YANG module) serial-number. It should also state that the cert is not included for saving space in this document. -- Section 4.1 -- There are TWO back-off mechanisms: one for the method and one for the proxy but no description on how those mechanisms interact together. -- Section 4.3 -- Probably a naive question about GRASP (that I do not know), but in the example there is \"IPPROTO_TCP, 80\" that seems to indicate the use of plain HTTP and no TLS at all. Is it an issue ? Is there a reason why IPv6 ULA are used rather than the documentation prefix ?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-07-15 02:43:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-11 06:40:28-07:00",
    "text": "Hi,  A. This is really a discuss discuss. With to little time to dig into the details it appears that this protocol is making i hack of its interface towards the its transport. It appears to attempt to use an HTTP rest interface, but then it is also have a lot of talking about requirement for the TLS connection underlying the HTTP. So to illustrate the issue I see here is what happens if one like to use QUIC as the underlying transport for the rest interface rather than TCP/TLS? So can this document achieve a clearer interface to the lower layers so that it will be simpler to move the protocol to another underlying version of the HTTP \"transport\"?  B. Section 5.6:  The server MUST answer with a suitable 4xx \u00a0  or 5xx HTTP [ RFC2616 ] error code when a problem occurs. Referencing  RFC 2616  that has been obsolete by  RFC 7230  and companions. I do note that there are no normative reference for that part in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-07-10 09:14:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 09:13:50-07:00",
    "text": "I support Eric\u2019s Discuss position. Also a big thanks to Christian Huitema\u2019s thorough SECDIR reviews and the associated improvements made as a result.\u00a0 I have a few more items:  (1) Section 5.7.\u00a0 The format of a pledge status telemetry message seems underspecified.  ** what are all of the fields (e.g., version appears in the example but no the text) ** what are the field formats (e.g., the format of the status field is inferred from the unlabeled example ** which fields are mandatory? ** Per the JSON snippet, is that normative is some way in describing the format? ** Also, how does a server receiving the telemetry messages behave when receiving unexpected JSON attributes?  (2) Section 5.8.1.\u00a0 The format of the MASA audit log seems underspecified.\u00a0 Is the JSON snippet presented here normative to describe the MASA audit log response? (3) Why is Section 7.x in this document if it explains how to use BRSKI but is considered non-normative?  -- How should implementers take this language? -- Why are normative sections, like Section 11, discussing it? (4) Thank you for documenting \u201cmanufacturer control issues\u201d in Sections 10.3 and 10.4.\u00a0 It helpfully lays justifies the current design approach.\u00a0 I strongly concur with the premise that \u201cfacilitate[ing] a few new operat[i]onal modes without making any changes to the BRSKI protocol\u201d is exactly what is needed.\u00a0  My concern is that even with the current applicability statement in Section 9, the current text appears to have only standardized the first part of the lifecycle that BRSKI equipment might see -- equipment on first sale as long as the manufacturer supports it or stays in business.\u00a0 The text doesn\u2019t appear to cover the practical aspects of the proposed mitigations in Section 10.5 or the situations described in Section 10.3/10.4 \u2013 various situations possible in the full lifecycle usage of a BRSKI device and needed support the \u201cadditional operational modes\u201d.\u00a0 Specifically: ** There appears to be little discussion on how owners/manufacturers/vendors can facilitate second sale/used equipment beyond narrative words (in Section 10.3 and 10.4) ** There is appears to be little discussion on how to practically implement a MASA (i.e., the offline use case).\u00a0 For example, (Per Section 10.5) \u201cA manufacturer could provide a mechanism to manage the trust anchors and built-in certificates (IDevID) as an extension.\u00a0 This is a substantial amount of work, and may be an area for future standardization work\u201d.\u00a0 Without the ability to change anchors on the device the additional operational modes such as offline mode seems challenging.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-16 18:08:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-10 09:14:30-07:00",
    "text": "I support Eric\u2019s Discuss position. Also a big thanks to Christian Huitema\u2019s thorough SECDIR reviews and the associated improvements made as a result.\u00a0 I have a few more items:  (1) Section 5.7.\u00a0 The format of a pledge status telemetry message seems underspecified.  ** what are all of the fields (e.g., version appears in the example but no the text) ** what are the field formats (e.g., the format of the status field is inferred from the unlabeled example ** which fields are mandatory? ** Per the JSON snippet, is that normative is some way in describing the format? ** Also, how does a server receiving the telemetry messages behave when receiving unexpected JSON attributes?  (2) Section 5.8.1.\u00a0 The format of the MASA audit log seems underspecified.\u00a0 Is the JSON snippet presented here normative to describe the MASA audit log response? (3) Why is Section 7.x in this document if it explains how to use BRSKI but is considered non-normative?  -- How should implementers take this language? -- Why are normative sections, like Section 11, discussing it? (4) Thank you for documenting \u201cmanufacturer control issues\u201d in Sections 10.3 and 10.4.\u00a0 It helpfully lays justifies the current design approach.\u00a0 I strongly concur with the premise that \u201cfacilitate[ing] a few new operat[i]onal modes without making any changes to the BRSKI protocol\u201d is exactly what is needed.\u00a0  My concern is that even with the current applicability statement in Section 9, the current text appears to have only standardized the first part of the lifecycle that BRSKI equipment might see -- equipment on first sale as long as the manufacturer supports it or stays in business.\u00a0 The text doesn\u2019t appear to cover the practical aspects of the proposed mitigations in Section 10.5 or the situations described in Section 10.3/10.4 \u2013 various situations possible in the full lifecycle usage of a BRSKI device and needed support the \u201cadditional operational modes\u201d.\u00a0 Specifically: ** There appears to be little discussion on how owners/manufacturers/vendors can facilitate second sale/used equipment beyond narrative words (in Section 10.3 and 10.4) ** There is appears to be little discussion on how to practically implement a MASA (i.e., the offline use case).\u00a0 For example, (Per Section 10.5) \u201cA manufacturer could provide a mechanism to manage the trust anchors and built-in certificates (IDevID) as an extension.\u00a0 This is a substantial amount of work, and may be an area for future standardization work\u201d.\u00a0 Without the ability to change anchors on the device the additional operational modes such as offline mode seems challenging.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-05 15:21:22-08:00",
    "end_reason": "position_updated",
    "start": "2019-10-16 18:08:51-07:00",
    "text": "One remaining item of clarity in the Section 7 from my previous DISCUSS position: ** Section 7.\u00a0 Per \u201cThis section is considered non-normative in the generality of the protocol.\u00a0 Use of the suggested mechanism here MUST be detailed in specific profiles of BRSKI, such as in Section 9.\u201d -- Can you please clarify \u201cnon-normative in the generality of the protocol\u201d?\u00a0 If I take the perspective of an implementer, it seems like a black-and-white issue \u2013 either this section is normative or not (I either have to conform or not).\u00a0  -- what this MUST is requiring isn\u2019t clear.\u00a0 Practically, why would using any of these mechanisms in this section require further elaboration? I\u2019d offer an alternative introduction to this section to address these ambiguities: OLD \u00a0  A common requirement of bootstrapping is to support less secure \u00a0  operational modes for support specific use cases.\u00a0 The following \u00a0  sections detail specific ways that the pledge, registrar and MASA can \u00a0  be configured to run in a less secure mode for the indicated reasons. \u00a0  This section is considered non-normative in the generality of the \u00a0  protocol.\u00a0 Use of the suggested mechanism here MUST be detailed in \u00a0  specific profiles of BRSKI, such as in Section 9. NEW A common requirement of bootstrapping is to support less secure operational modes for support specific use cases.\u00a0 This section suggests a range of mechanisms that would alter the security assurance of BRSKI to accommodate alternative deployment architectures and mitigate lifecycle management issues identified in Section 10.4 \u2013 10.7.\u00a0 They are presented here as informative (non-normative) design guidance for future standardization activities.\u00a0 It would be expected that subsets of these mechanisms could be profiled with an accompanying applicability statements similar to the one described in Section 9.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-01-04 06:28:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 18:30:13-08:00",
    "text": "** Section 4.2.1. The example has a few easy to fix issues: --\u00a0 Typo in JSON.\u00a0 Missing comma between array elements in \u201cids\u201d OLD \u00a0 \u00a0 \u00a0 \"ids\" : [ \u00a0 \u00a0 \u00a0 \u00a0 \"Gc0854fb9fb03c41cce3802cb0d220529e6eef94e\" \u00a0 \u00a0 \u00a0 \u00a0 \"not-a-blob\" \u00a0 \u00a0 \u00a0 ], NEW \u00a0 \u00a0 \u00a0 \"ids\" : [ \u00a0 \u00a0 \u00a0 \u00a0 \"Gc0854fb9fb03c41cce3802cb0d220529e6eef94e\", \u00a0 \u00a0 \u00a0 \u00a0 \"not-a-blob\" \u00a0 \u00a0 \u00a0 ], -- The second request (\u201cR2\u201d) sets properties of \u201cdata:asText\u201d and \u201cdata:asBase64\u201d.\u00a0 However, the response only returns a value for \u201cdata:asText\u201d.\u00a0 Shouldn\u2019t it have returned the same data in both formats? ** Section 5 \u00a0  If a server might sometimes return all names empty rather than \u00a0  putting a blobId in the notFound response to a Blob/get, then the \u00a0  server SHOULD always return the same type of response, regardless of \u00a0  whether a blob exists but the user can't access it, or doesn't exist \u00a0  at all.\u00a0 This avoids leaking information about the existence of the \u00a0  blob. Can these behaviors be clarified?\u00a0  -- If this text introducing a new, normative behavior that if a blobId is not found or the user isn\u2019t authorized, a get query response could just be both an empty \u201clist\u201d and \u201cnotFound\u201d?\u00a0 I don\u2019t see that described elsewhere. -- The consistency in behavior for not found and or not authorized makes sense exactly for the reason described.\u00a0 Therefore, why the SHOULD?\u00a0 What would be the circumstances where leaking the existence of the blob is acceptable?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-10 18:06:01-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 22:55:28-07:00",
    "text": "In Section 3.3: \u00a0  The SHA-3 hash algorithms have a significantly different structure \u00a0  than the SHA-2 hash algorithms.\u00a0 One of the benefits of this \u00a0  differences is that when computing a shorter SHAKE hash value, the \u00a0  value is not a prefix of the result of computing the longer hash. I did not think this was the case -- the sponge construction seems to only use the 'd' parameter to truncate the output stream, but 'd' does not seem to otherwise cause the output stream to vary.\u00a0 Indeed, Section 4 of FIPS-202 concludes: % Note that the input d determines the number of bits that Algorithm 8 % returns, but it does not affect their values. Am I misunderstanding what the quoted statement is trying to convey?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-03-09 01:36:27-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 06:21:58-08:00",
    "text": "First part is a formality discuss that likely is fairly easy to resolve So this document uses formal syntax, however it does not explicitly reference which. So I noticed  RFC 5228  that do reference  RFC 4234  which is now obsolete, and the current in force version of ABNF is  RFC 5234 . Also as no WSP are included in the rules, this document appears to use ABNF to express  RFC 5228  grammar and not parsing syntax. So please clarify prior to the usages what the formal language is and what it represents.  So this needs to be done prior to Section 5. But, can you please check that you actually have the same level of\u00a0 formal syntax in Section 5 that goes through  RFC 8580  as what is in Section 8. Otherwise please clarify both.  Secondly, I do consider the defining text first paragraph of in Section 4.1 so hard to interpret that it must be fixed prior to publication. So although you already are going to address it based on discussion of Martin Duke's comment, I want to hold a discuss on this.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-03-30 16:48:03-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-14 02:29:17-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-opsawg-add-encrypted-dns-11 CC @evyncke Thank you for the work put into this document. Once the trivial DISCUSS is addressed, I will be happy to ballot a YES. Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Bernie Volz for the shepherd's detailed write-up including the WG consensus even if the justification of the intended status is rather vague.  Other thanks to Tatuya Jinmei, the Internet directorate reviewer (at my request), please consider this int-dir review: https://datatracker.ietf.org/doc/review-ietf-opsawg-add-encrypted-dns-10-intdir-telechat-jinmei-2023-03-09/  (and I have read Med's replies and resolution of the issues) I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### What to do with non-permitted DHCP option ? Sections 3.1 and 3.2 contain text like `Permitted DHCPv6 options in the DHCPv6-Options Attribute are maintained by IANA in the registry created in Section 8.4.1.` but I was unable to find anywhere in the document what is the expected behaviour of a RADIUS client receiving a non-permitted DHCP option ? At the bare minimum, I would expect the I-D to mention \"non-permitted DHCP options MUST silently be ignored by the RADIUS client\" Or did I fail to find a similar statement in the text ?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-08-20 13:30:34-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 18:56:17-08:00",
    "text": "(1) Controllers and other nodes. Background: This document defines the new SFC NLRI, which has two distinct route types, originated by either a node hosting an SFI or a Controller.\u00a0 Each route type has a specific function and it is reasonable to expect that the originators represent different nodes in the network, with different functions, location, etc..\u00a0 BGP Capabilities Advertisement doesn't have a route type granularity; instead, a BGP speaker known to support the SFC NLRI could originate any type of route. The facts above open the possibility that any node in the network can originate an SFPR and take over an SFP.\u00a0 \u00a73.2.2 does a very good job of explaining the potential existence of multiple Controllers and even offers the appropriate tie breaker to take control of the SFP: \"MUST use the SFPR with the numerically lowest SFPR-RD\".\u00a0  The document proposes no mitigation to the possibility of any node (a rogue node, for example) issuing SFPRs.\u00a0 The assumption (\u00a72.2) of \"BGP connectivity between the Controllers and all SFFs\" introduces also the ability to locate a rogue controller anywhere; I interpret \"BGP connectivity\" to include the presence of a router reflector (for example), which then allows distribution of SFPRs without going through a central policy point.  On one hand I think this condition is a feature (the Controller can be anywhere), but the case of a rogue node that wants to act as a controller is not considered. To address this issue, I would like to see text that (1) acknowledges the issue (maybe in the security considerations section), and (2) discusses operational considerations for the placement, control, filtering, etc. of Controllers and the corresponding UPDATES from them and/or other nodes in the network.\u00a0 IOW, the considerations around proper initial setup of the system should be clear. (2) New Flow Specification Traffic Filtering Action \u00a77.4 (Flow Spec for SFC Classifiers) defines a new Traffic Filtering Action to be used with the Flow Specification NLRI.\u00a0 rfc5775bis allows for any combination of Traffic Filtering Actions to be present, but this document says that \"other action extended communities MUST NOT be present\".\u00a0 I believe that specifying the use of treat-as-withdraw is ok as a case of Traffic Filtering Action Interference -- I just say \"ok\" because it is not clear to me (nor explained anywhere) why other Traffic Filtering Actions cannot be used; for example, I could imagine rate-limiting the traffic into an SFP. What concerns me more (and the reason for this DISCUSS point) is that  rfc5575 -only implementations will not consider the new Traffic Filtering Action, but could, depending on the components encoded in the NLRI, take actions based on other Traffic Filtering Actions.\u00a0 The result can then be an inconsistent application of Traffic Filtering Actions in the network -- for example, some nodes may want to drop the matching traffic (traffic-rate of 0), while others may want to have the same traffic entering an SFP. What are the operational considerations of using the new Traffic Filtering Action in a network where \"legacy\" (rfc5575bis-only) nodes exist?\u00a0 Is there a potential migration path?\u00a0 What might be the impact?\u00a0 How can correct operation be verified? (3) Use of the Control Plane This last point is not specifically for the authors, but for the Responsible AD and the Chairs for the sfc WG (cc'd). The SFPRs are built on, among other things, knowledge of the SFT(s) supported at a specific node.\u00a0 I note that only one Special Purpose SFT is defined in this document.\u00a0 The lack of SFT definitions means that no actual SFP can be instantiated.\u00a0 IOW, without additional work to define new SFTs it seems to me that the control plane as specified in this document cannot be used. :-( I couldn't find any related work (referencing this document) where new SFTs are proposed/defined.\u00a0 What are the plans to develop that work?\u00a0 Is there interest in the sfc WG to take advantage of the control plane?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-21 14:12:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-18 15:01:48-08:00",
    "text": "Section 3.2.1.3 seems to talk about intermingling SFIR-RDs and SFIR Pool Identifiers in a common list, but I do not see how it's defined to intermingle the (six-octet) Pool Identifier Value with the (eight-octet) RDs. Section 3.1 seems to allow multiple SFIRs associated with a given RD, but the rest of the document seems to assume that any RD has at most one associated SFIR (as is stated explicitly for SFPRs).\u00a0 (A few specific mentions in the COMMENT.) Within my own limited understanding, it seems like this document is expanding the boundaries of the SFC Architecture in ways not envisioned by  RFC 7665  or 8300, and the shepherd writeup is pretty quiet on to what extent this architectural change is accepted by the WG (as opposed to being contained to just the BGP control plane mechanism).\u00a0 I'd like to get a positive affirmation from someone more familiar with the discussions that this is moving the architecture in the right direction with respect to things like: - the introduction of the Service Function Type intermediate \u00a0 classification - the more prominent treatment of looping, jumping, and branching as \u00a0 operations within a single SFP without reclassification by using the \u00a0 \"Change Sequence\" SFT entries to indicate these behaviors within the \u00a0 SFP definition itself (I note that  RFC 7665  does not mention \"jump\" at all) - the introduction of \"gaps\" in the SI sequence of a given SFP With respect to SFT in particular, it sounds like this is intended to help with scalability, which makes the genart reviewer's comment about lack of implementation experience particularly poingant.\u00a0 It seems like SFIR pools perform a similar role, though of course not identical; I didn't get a clear sense of why pools without SFTs are insufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-21 15:15:12-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-21 14:12:34-07:00",
    "text": "I think we may still need some text changes to clarify how the joint list of SFIR-RD and SFIR Pool Identifier Extended Communities is constructed and interpreted, and potentially need to register an RD Type matching the other (TBD6+TBD7) values we allocate. (I'm also not entirely clear how the IPv6 addresses interact with 8-byte RDs.) A longer description of these topics is written up at https://mailarchive.ietf.org/arch/msg/bess/wVDRF4ni0bGhNazvWoFi8BwJ_Vg/ but is not quite appropriate for this standalone context.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-08-25 05:10:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 11:15:00-08:00",
    "text": "* Section 9 cites a number of references (which cite additional references) on BGP security.\u00a0 My summary of the highlights is: (1)  RFC4271  => TCP MD5 ( RFC2385 ) is a MUST  (2)  RFC4271  => consider  RFC 3562  for key management guidance (3) ietf-idr-tunnel-encaps => caution on Tunnel Encapsulation attribute (4)  rfc4364  => TCP MD5 is a non-rfc2119 \u201cshould\u201d (5)  rfc4364  => don\u2019t make connections with untrusted peers (6)  RFC7432  => references the utility of TCP-AO ( RFC5925 ) - Could the text articulate more clearly de-conflict (1), (4) and (6) \u2013 what is the recommended approach? - a discuss-discuss \u2013 Given the green field nature of this specification (the shepherd\u2019s report notes no implementation) and the assumed SFC deployment model (not the internet; a single provider\u2019s operational domain where key management should be easier), could a more robust transport security option such as BGP over IPSec be RECOMMENDED?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2018-07-19 14:06:52-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-03 14:18:31-07:00",
    "text": "I will apologize in advance because this document may be sort of a casualty of this DISCUSS. I should have raised my point below at least two years ago if not four years ago when the first iana-* YANG module was registered, but the thought did not occur to me until now.  It gives me some pause to see the name \"iana\" embedded in the file name, module name, namespace, and prefix of the module being defined in Sec. 2.12. I realize there is precedent here, but I question whether tying these kinds of modules specifically to IANA as the protocol parameter registry operator by name puts them on the most stable deployment footing under all possible circumstances. I am personally pleased as punch with the service we get from IANA, but that doesn't mean \"IANA\" will always be the name of the registry operator. The more modules that get created with this embedding, the more of them that may need to change in the unlikely event that the name of the registry operator changes. Lots of RFCs would need to change too, but embedding the name extends the potential problem to the modules themselves. It wasn't clear to me whether there is some ops-area-wide convention around the embedding of \"iana\" in the names of modules to be maintained by IANA. I don't see this specifically referenced in  RFC 7950  or  RFC 6020 . So I'd like to discuss whether a different naming convention could be established and used in this document and others going forward.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-08-02 18:18:21-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-03 13:21:16-07:00",
    "text": "Section 2.1 describes a scheme wherein an IGP may generate events that cause BFD sessions to be created/destroyed; this effectively is proxying commands from IGP over the local BFD API, which brings the authentication and authorization of the IGP into scope, even if the local BFD configuration access is authenticated.\u00a0 (That is, the proxying component is always authenticated, but now bears responsibility for performing authentication/authorization/sanity checks on commands before proxying them.)\u00a0 Since IGP security is a topic for elsewhere, the changes to this document seem scoped to documenting the requirements on the IGP/local proxy for these checks, and arguably for only allowing authenticated IGP events to create authenticated BFD sessions (though arguably not as well, for the latter, since this is a YANG model document and not an architecture document).",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-07-04 11:17:08-07:00",
    "end_reason": "position_updated",
    "start": "2018-07-04 10:17:20-07:00",
    "text": "Don't panic, this should be an easy DISCUSS to clear, but I think it important for interoperability. In multiple places, you have: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions-up? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions-down? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +--ro number-of-sessions-admin-down? I'm a little confused by the meaning of the counters, and didn't see them clearly defined anywhere. Apologies if I missed it... Are \"number-of-sessions-admin-down\" included in \"number-of-sessions-down\"?  Is 'number-of-sessions' always equal to 'number-of-sessions-up' + 'number-of-sessions-down', or is it always equal to 'number-of-sessions-up' + 'number-of-sessions-down' + 'number-of-sessions-admin-down', or are there other cases? E.g: I have created 10 sessions (because I have 10 interfaces). 5 of them are down because there is no peer, 3 of them I've configured to be down (admin down), and so 2 of them are up. What should be in each of: number-of-sessions? number-of-sessions-up? number-of-sessions-down? number-of-sessions-admin-down?",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-04-12 10:44:34-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-07 19:04:37-07:00",
    "text": "Section 2.3: \u00a0  EVPN Network OAM mechanisms MUST provide in-band monitoring \u00a0  capabilities. As such, OAM messages MUST be encoded so that they \u00a0  exhibit identical entropy characteristics to data traffic in order \u00a0  that they share the same fate. It\u2019s not obvious to me what you mean by \u201cidentical entropy characteristics to data traffic\u201d. Surely, different flows may have different entropy characteristics, so, *which* data traffic? Similarly, with which data traffic are you saying the OAM messages must share fate?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-31 14:47:43-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-12-28 14:29:34-08:00",
    "text": "This is cool stuff.\u00a0 I assure you I'm going to ballot \"Yes\" after what's below is cleared up. There's no IANA Considerations section.\u00a0 Was this intentional?\u00a0 I ask for a few reasons: (1) It's expected (required?), with no actions for IANA, to expressly include a section that says so.\u00a0 It's conspicuously missing here. (2) Why is there no registry for custom properties?\u00a0 I can see that Section 4.5 takes a run at dealing with the collision risk by SHOULDing a particular way of naming custom properties, but it feels to me like a registry is the right way to deal with this.\u00a0 As a consumer of this work, I might not want to reveal (via names) which DNS implementation I'm using, for example. (3) I have a similar question about groups in Section 4.4.2; \"nodnssec\" is an example of something that we might want to register with global semantics, or more generally, that some values might be common in implementations and therefore worth documenting. (4) Do we need a registry of names that are special in the context of catalog zones, e.g., \"zones\", \"ext\", \"group\", \"version\", \"coo\", \"invalid\"? Separately: What action should be taken if a nameserver is already authoritative for a zone (say, is a primary), yet it receives a catalog update that now contains that same zone?\u00a0 This seems like a possible attack that should be discussed.\u00a0 I guess the second-last paragraph of Section 7 covers this, though indirectly.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2023-02-14 10:57:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-31 14:47:43-08:00",
    "text": "This is cool stuff.\u00a0 I assure you I'm going to ballot \"Yes\" after what's below is cleared up. There's no IANA Considerations section.\u00a0 Was this intentional?\u00a0 I ask for a few reasons: (1) It's expected (\"should\", per  BCP 26 ), with no actions for IANA, to expressly include a section that says so.\u00a0 It's conspicuously missing here. (2) Why is there no registry for custom properties?\u00a0 I can see that Section 4.5 takes a run at dealing with the collision risk by SHOULDing a particular way of naming custom properties, but it feels to me like a registry is the right way to deal with this.\u00a0 As a consumer of this work, I might not want to reveal (via names) which DNS implementation I'm using, for example. (3) I have a similar question about groups in Section 4.4.2; \"nodnssec\" is an example of something that we might want to register with global semantics, or more generally, that some values might be common in implementations and therefore worth documenting. (4) Do we need a registry of names that are special in the context of catalog zones, e.g., \"zones\", \"ext\", \"group\", \"version\", \"coo\", \"invalid\"? Separately: What action should be taken if a nameserver is already authoritative for a zone (say, is a primary), yet it receives a catalog update that now contains that same zone?\u00a0 This seems like a possible attack that should be discussed.\u00a0 I guess the second-last paragraph of Section 7 covers this, though indirectly.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-07 07:46:54-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-03 20:05:35-08:00",
    "text": "# Sec AD review of  draft-ietf-dnsop-dns-catalog-zones-08 CC @paulwouters Please refer to  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/  for more information about how to handle DISCUSS and COMMENT positions.  This review uses the format specified in  https://github.com/mnot/ietf-comments/  which allows automated tools to process items (eg to produce github issues) Note that I am a happy user of catalog zones since a few months. While I originally thought this seemed like an \"if all you have is a DNS hammer\" solution, it actually has some very clear advantages over other configuration synchronization methods. Thanks for this work, I am a fan! I do have some issues I'd like to discuss though :) ## DISCUSS ### Section 4.3.1 Versioning What should one do if the version supported is lower than the version of zone received? Attempt to understand it? preventively fail? Are version 1 and 2 compatible? In what ways are they not? Should perhaps version 1 catalog zones always be ignored ? ### Group Properties It seems like Section 4.4.2 defines \"group properties\" that are standardized, while Section 4.5 specifies Private Use group properties. But there is actually no registry created for Group Properties, and no definitions other than \"examples\" are given. This makes the status of, for example \"nodnssec\", unclear. Is this a custom (eg bind implementation only) property or is this really a custom private use entry, in which case the example is bad as it belongs under .bind.ext. Since \"nodnssec\" seems a real use case, why does this document not create an IANA registry for Catalog Zone Group Properties and places \"nodnssec\" in it? ### 5.3 \"MUST be removed\"? ``` \u00a0 \u00a0 \u00a0 \u00a0 Only when the zone was configured from a specific catalog zone, \u00a0 \u00a0 \u00a0 \u00a0 and the zone is removed as a member from that specific catalog \u00a0 \u00a0 \u00a0 \u00a0 zone, the zone and associated state (such as zone data and DNSSEC \u00a0 \u00a0 \u00a0 \u00a0 keys) MUST be removed. ``` What is \"removed\" here? I think perhaps it should be limited to \"MUST no longer be served\". For example, it would be bad if the operator made an error, and ended up briefly removing the zone and \"removing\" (aka destroying) some private DNSSEC keys, complicating the zone restoration. Also, perhaps the implementation wants to simply keep the state on disk but move it to a /var/lib/xxx/zones/archived/ directory. The use of \"remove\" sounds like that might not be allowed. ### Operational Considerations What are the risks and benefits of Extension group properties? Should one try to standardize these instead? Why is this document not doing that based on its operational experience with eg bind and knot and powerdns ? ### Security Considerations Dealing with high value domains eg  gmail.com  is missing. If a large DNS hoster would enable catalog zones for its customers, how can it prevent rogue takeovers? If fully automated, it can never be safely deployed. If each zone needs a manual check, well than we don't really have \"catalog zones\" auto-populating name servers. Is there an expectation that nameservers can do some authorization call before adding a new domain that is already delegated elsewhere? Eg if GoDaddy uses catalog zones, and I am their tiny customer with \" nohats.ca \" and then add a new zone \" gmail.com \", that could cause a significant disruption. Especially if the malicious person would create another domain that depends on \" gmail.com \" in such a way that GoDaddy's servers will start sending \" gmail.com \" data in their additional data reply for other domains. The section only has a \"consumer(s) MAY \", which in my opinion, is far too weak as a security control. As the above example shows, it is just too easy to start poisoning nameservers via implementations that skip this one MAY clause in the Security Considerations.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-02-27 11:46:17-08:00",
    "end_reason": "discuss_updated",
    "start": "2023-02-27 11:45:08-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop (I guess this is true but maybe you should review 7761 to make sure this is true!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: ``` Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message. ```",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-02-27 11:46:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2023-02-27 11:46:17-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop. (I guess this is true but maybe you should review 7761 to make sure!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: ``` Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message. ```",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-02-27 11:46:55-08:00",
    "end_reason": "discuss_updated",
    "start": "2023-02-27 11:46:30-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop. (I guess this is true but maybe you should review 7761 to make sure!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: ``` Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message. ``` x",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-01 17:12:13-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-27 11:46:55-08:00",
    "text": "# John Scudder, RTG AD, comments for  draft-ietf-pim-null-register-packing-14 CC @jgscudder ## DISCUSS The document is quite terse. In some respects this is admirable and welcome (the low page count is nice). But it seems as though \u2014 even if it\u2019s \u201cobvious\u201d \u2014 it would be worth\u00a0 mentioning that the semantics of a packed message with N members are exactly the same as the semantics of the equivalent N non-packed messages. In particular, there seems to be quite a bit of machinery in  RFC 7761  that's driven by transmission or receipt of these messages; it would be desirable to have specific, unambiguous language in the spec that makes it crystal clear that the packed equivalents of the messages apply everywhere the non-packed ones do, and everything that applies to the non-packed versions applies equally to the packed versions. For example, a timer for a given (S,G) that would be reset by receipt of a Register-Stop MUST also be reset by that (S,G) occurring within a Packed Register-Stop. (I guess this is true but maybe you should review 7761 to make sure!) If you think this is already explicit, please help me see where. One fix could be to add something like this to Sections 3 and 4: \u00a0  Sending or receiving a Packed\u00a0 message is the equivalent, for all purposes, of sending or receiving an individual\u00a0 message for each (S,G) represented in the packed message.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-03-02 02:28:39-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-28 02:24:56-08:00",
    "text": "# GEN AD review of  draft-ietf-pim-null-register-packing-14 CC @larseggert Thanks to Behcet Sarikaya for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/EyaOvVl155DHm7IhDZUBHOqRijY ). ## Discuss ### Section 7, paragraph 2 ``` \u00a0 \u00a0  For IPv6 PIM Packed Null-Register messages or PIM Packed Register- \u00a0 \u00a0  Stop messages, the DR MUST perform Path MTU Discovery.\u00a0 For IPv4, the \u00a0 \u00a0  DR SHOULD perform Path MTU Discovery.\u00a0 This allows the DR to fragment \u00a0 \u00a0  packets as needed.\u00a0 However, in order to avoid fragmentation \u00a0 \u00a0  altogether, a DR sending packed registers SHOULD limit the number of \u00a0 \u00a0  records such that the message can fit within the Path MTU.\u00a0 A record \u00a0 \u00a0  consists of a Group Address and Source Address pair. ``` *How* is the DR supposed to perform PMTUD? If this is defined in another PIM doc, please normatively reference that. Otherwise, specify here. Also, isn't the goal of PMTUD is to avoid fragments, not to allow \"the DR to fragment packets as needed\"?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2023-03-26 16:55:00-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-01 00:17:46-08:00",
    "text": "Feel free to set me straight here if I'm wrong, but: Section 2 says: \"This section allocates a bit ...\" Doesn't this mean either (a) there should be a registry for these bits, and if there is, there should be one or more corresponding IANA actions; or (b) this document should update  RFC 7761  so that the allocation of a previously reserved bit is discoverable somehow?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-03-09 00:17:57-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-27 04:47:03-08:00",
    "text": "Hi, Thanks for this document.\u00a0 I've flagged this as discuss because I found part of the spec to by unclear: (1) p 3, sec 3.\u00a0 PIM Packed Null-Register message format \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |PIM Ver| Type\u00a0 |Subtype|\u00a0 FB\u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Checksum\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0  Group Address[1]\u00a0  (Encoded-Group format)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0  Source Address[1]\u00a0 (Encoded-Unicast format)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  . \u00a0 \u00a0 \u00a0 .\u00a0 \u00a0  Group Address[N]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 . \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0  Source Address[N]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Figure 2: PIM Packed Null-Register message format I'm not familiar with PIM, but it wasn't clear to me how the receiver infers how many addresses are in the message.\u00a0 E.g., I note that the Join/Prune Message Format contains a count \"Num Groups\", but conversely the \"Hello Message Format\" does not include a count of options.\u00a0 Hence, I presume that the N, the address count, is inferred by the packet length?\u00a0 If so, would that be worth stating here (and in section 4)?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-03-02 04:04:20-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-28 11:54:06-08:00",
    "text": "Thanks for working on this document. I would like to discuss - what is the \"P\" bit in section 2 and what is \"FB\" in section 3? without proper description of those fields this specification will be confusing to be implemented. May be I have missed something in the referenced specifications, in that case I would prefer to have the references properly stated here. I also support Lars's and Rob's discuss.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-30 13:23:50-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-09 15:15:22-07:00",
    "text": "The situation w.r.t. MOP values 5, 6, and 7 seems inconsistent to me. We are not allocating them, but we are changing the  RFC 6550  behavior in the presence of at least one of them (but are not currently claiming to Update 6550).\u00a0 I have some further thoughts in the COMMENT section, but I don't think the current state is consistent enough to be approved as-is.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-11-11 08:27:05-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-02 10:27:44-07:00",
    "text": "Now that I know that an IANA registry exists for MOP, codepoint 7 should be included in the IANA considerations for the \"Mode of Operation\" Registry.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 11:29:08-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 19:08:01-07:00",
    "text": "In Section 3.1.2, we say that: \u00a0  o\u00a0 If the target SID (2001:db8:B:4::) is not locally instantiated, \u00a0 \u00a0 \u00a0 the packet is discarded However,  RFC 8754  \u00a74.3.2 seems to say that the next header is processed in this case.\u00a0  Only if the target SID is both not locally instantiated and does not represent a local interface will the packet be discarded, if I understand correctly.\u00a0 (Similarly for the analogous statement in \u00a73.2.2.) There's also quite a few other internal incosistencies in this document, such as copy/paste chunks that refer to \"N4\" as executing a given SID in a scenario where it is actually a different node doing so, many instances where a given IP address or SID does not match up with the addressing structure listed in Section 1.3, places where we seem to say that an SR ingress node can be a classic IPv6 node that lacks SRv6 capabilities, etc.\u00a0 Individually, many of these would be nit-level (and indeed are called out specifically in the NITS section of my ballot comment), but collectively they seem to indicate a document that is not yet in publishable state.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-06-02 11:50:09-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-01 14:48:10-07:00",
    "text": "Thank you for the work put into this document. It is comforting (even if not surprising) that the simple \"good old\" ping/traceroute work on a SRv6 network ;-) Thanks to Carlos Bernardos for his INT-REVIEW at  https://datatracker.ietf.org/doc/review-ietf-6man-spring-srv6-oam-10-intdir-telechat-bernardos-2021-05-28/ Thanks to Ole Tr\u00f8an for his shepherd document even if I regret the lack of justification for 'standards track'. Especially, because the abstract is mainly about ping/traceroute, hence should be informational but the O-flag is indeed standard track. So, all in all, this is OK. Please find below two blocking but trivial DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated), and one nit. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2.1 -- As \"a penultimate segment SHOULD NOT be a Penultimate Segment Pop (PSP) SID\" is normative, then the network programming  RFC 8986  should be a normative reference. Trivial to fix. -- Section 9.2 -- Trivial to fix,  RFC 8174  should be normative.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-01-31 13:16:51-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 18:48:03-07:00",
    "text": "I can't get past the feeling this document is really two different documents mashed together. One is a Standards Track, 6man document, that defines the O-flag. All the meat of that document is in \u00a72.1 and \u00a72.2, it would make a nice, compact, readable 3 or 4 page RFC (maybe a little more once all the boilerplate was in). The other is an Informational, SPRING document, that talks about use cases at some length. It seems both cruel and counterproductive to force SRv6 implementors who are implementing the O-flag to read through the entire balance of the document just to be sure they haven't missed something important. Remember these documents will live a long time, and it seems irresponsible to clutter the essential document set with inessential use cases. My suggestion is to split the document as outlined above.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-06-02 09:47:03-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-24 11:52:38-07:00",
    "text": "I would like to clarify that when the pseudocode says \"Send the copied packet, along with a timestamp to the OAM process for telemetry data collection and export,\" that this \"process\" is colocated on the router, and that this process further digests the data so that there is much less than 1 packet going out of the box per O-bit packet processed. If there is a case where each O-bit packet generates an entire packet going off the router to a controller or external OAM process, there are extremely unfortunate corner cases that are not sufficiently mitigated by rate-limiting.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-10 11:47:01-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-02 18:42:57-07:00",
    "text": "The privacy implications of the O-flag needs to be more clearly articulated.\u00a0 It provides a dual use capability -- there is tangible benefit for OAM use cases, but also reduces the friction for surveillance uses cases. The SECDIR review ( https://mailarchive.ietf.org/arch/msg/secdir/FeTu7x7-okw7w7-T6dZRFhJHpAo/ ) pointed this out in -09.\u00a0 The changes made to the Security Considerations in -10 were helpful, but primarily focused on reiterating the security assumptions of the SR domain boundary and the degree of protection of the SRH.\u00a0  My recommendation would be for an explicit Privacy Considerations section with the following (approximate) text: NEW 7.\u00a0 Privacy Considerations The per-packet marking capabilities of the O-flag provides a granular mechanism to collect telemetry.\u00a0 When this collection is deployed by an operator with knowledge and consent of the users, it will enable a variety of diagnostics and monitoring to support the OAM and security operations use cases needed for resilient network operations.\u00a0 However, this collection mechanism will also provide an explicit protocol mechanism to operators for surveillance and pervasive monitoring use cases done contrary to the users\u2019 consent.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-21 19:01:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 07:07:13-07:00",
    "text": "Let's discuss whether we need to be a bit more clear about what behavior should be expected when the exclude-lite leaf has value true vs. false -- the apparent inconsistency between \"exclude\" in the leaf name and the positive verb \"track\" in the description left me confused.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-07-21 01:36:48-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 02:55:15-07:00",
    "text": "Hi, I appreciate that this YANG model has already passed a YANG doctor review, but this discuss is to understand the reasoning as to why both IGMP snooping and MLD snooping are in the same YANG module, yet have top level features to separate their functionality. \u00a0 \u00a0 4. IGMP and MLD Snooping YANG Module \u00a0 \u00a0 \u00a0 feature igmp-snooping { \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Support IGMP snooping.\"; \u00a0 \u00a0 \u00a0 \u00a0 reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"RFC 4541\"; \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 feature mld-snooping { \u00a0 \u00a0 \u00a0 \u00a0 description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Support MLD snooping.\"; \u00a0 \u00a0 \u00a0 \u00a0 reference \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"RFC 4541\"; \u00a0 \u00a0 \u00a0 } It seems strange to me to have the entire YANG Model split under two separate feature statements. I believe that it would have been better to split this into two separate YANG models, both following the same structure.\u00a0 Possibly, a common YANG module could have been used to share groupings and definitions, but even then duplicating the contents of the model so that the description statements could be correct/accurate would be more helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-16 20:44:50-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-14 15:52:18-08:00",
    "text": "[[ discuss ]] [ section 4.1 ] * I haven't tried to read the IEEE documents referenced here, but I'm \u00a0 hoping this question can be easily addressed by those who have. \u00a0 Can this Destination MAC rewriting (\"replace ... with alternate values\") \u00a0 ever affect IP and IP-related traffic that might carry MAC addresses, \u00a0 like ARP or NDP? \u00a0 If there could be impact to MAC-carrying traffic like ARP/NDP then it \u00a0 seems likely that more text is required here about that interaction \u00a0 (and I should probably figure out how to go read those references \u00a0 documents/clauses).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-09 20:00:31-08:00",
    "end_reason": "position_updated",
    "start": "2018-11-19 15:55:04-08:00",
    "text": "Section 11.2 of the IANA considerations lists an actual OID value to use for the \"sip.clue\" media feature tag, but the IANA last call review indicates that the decimal value for sip.clue will be assigned at registration, so it is incorrect to claim that it will be 1.3.6.1.8.4.29. Squatting on the next available codepoint like this is quite risky and I really want to discourage this practice.\u00a0 We had a lot of trouble in TLS recently with *three* different extensions attempting to use the same codepoint, which was not fun to resolve.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-02-03 04:14:33-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-16 06:57:16-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-opsec-indicators-of-compromise-03 CC @evyncke Thank you for the work put into this document. It is interesting and an easy read and so refreshing to read the British \"defense\" ;-) Once my DISCUSS is cleared, I intend to ballot a YES. Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Jen Linkova for the shepherd's detailed write-up including the WG consensus (always low response rate in OPSEC) *and* the justification of the intended status.  Other thanks to Dave Thaler, the Internet directorate reviewer (at my request), please consider this int-dir review: https://datatracker.ietf.org/doc/review-ietf-opsec-indicators-of-compromise-03-intdir-telechat-thaler-2023-01-13/ Dave has raised interesting issues in the text, notably linked to IP addresses, that I fully second; _I have yet to read any reply from the authors_, but the review was posted just before the week-end and we are on the blue Monday. I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 3.1 no IPv6 data I am *really* surprised to only see IPv4 addresses in the numbers, even if today AlienVault has 7k IPv6 addresses as IoC vs. 3M IPv4 addresses. Please include some IPv6 statistics. I appreciate that this issue does not really comply to a DISCUSS point but it is so easy to address and I would like to start a discussion with the authors and the AD.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-23 19:49:53-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-02-23 19:49:02-08:00",
    "text": "lease update to reflect the changes made in draft-ietf-calext-eventpub-extensions(e.g., there is no longer STRUCTURED-LOCATION and VLOCATION plays a similarrole).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-02 15:27:59-08:00",
    "end_reason": "position_updated",
    "start": "2021-02-23 19:49:53-08:00",
    "text": "lease update to reflect the changes made in draft-ietf-calext-eventpub-extensions-17(e.g., there is no longer STRUCTURED-LOCATION and VLOCATION plays a similarrole).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-11-29 10:59:15-08:00",
    "text": "(1)  RFC 8300  is pretty clear that \"Metadata privacy and security considerations are a matter for the documents that define metadata format.\"\u00a0 Some of the metadata context headers defined in this document clearly have privacy considerations that need to be documented (e.g., policy ID and source/destination group serve to concretely identify flows that are related in some way), though some may not have much that needs documenting (e.g., the forwarding context metadata seems to just be extracting out information that is already present in the packet being wrapped).\u00a0 Regardless, we need to have some discussion of the privacy and security considerations of the new metadata context headers, even if that is just \"no new considerations\" for some of them. (2) I think we need to discuss the Flow ID context header further.\u00a0 Is it intended to just be a container to hold a flow identifier already present in the contained packet (such as the IPv6 Flow Label or MPLS Entropy Label that are called out), or can it also be used to apply a new flow identifier at the SFC layer? The named examples of a flow ID are both 20 bits long; if that is an exhaustive listing, shouldn't we update the figure accordingly (to include Length=3, four leading bits of padding, and a trailing byte of padding)?\u00a0 If that is not an exhaustive listing and longer flow identifiers are expected, how do we know what length of flow identifier is being conveyed? (3) If we are to allow for specifying the \"logical grouping of source and/or destination objects\" in \u00a74.6 (emphasis on \"and/or\"), but the context header always conveys both a source group and dest group field, do we need to reserve a dedicated value for \"no group information specified\"?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:38:22-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-29 02:59:01-08:00",
    "text": "Thank you for the work on this document. I have some comments, mostly having to do with clarifications and improvement of text for readability. I'd like answers to two main points: first - I believe the lack of normative references to the documents that define the fields this document registers into IANA is important enough to warrant some discussion. Second - I'd like some clarification about interoperability. More details below. Francesca 1. ----- \u00a0 \u00a0 \u00a0 Tenant ID: Represents an opaque value pointing to Orchestration \u00a0 \u00a0 \u00a0 system-generated tenant identifier.\u00a0 The structure and semantics \u00a0 \u00a0 \u00a0 of this field are deployment specific. FP: I am worried about interoperability, as the field is defined as deployment specific. Could you clarify why you don't think this is an issue? Also, please add a normative reference to the section and document defining tenant identification. 2. ---- Section 4.3 FP: Same comment as above for Node ID: please add a reference and explain interoperability, as this is defined as deployment specific. 3. ----- Sections 4.4, 4.5 FP: I do think these fields need references to the documents they are defined in. (I am aware section 2.1 and the normative references should help, but I think it would be much clearer to have direct links to the right place in the text.) For Flow ID, if I understand correctly, this document defines it high level and gives examples of what value it can take. I would clarify that in the first paragraph of the section (as you do for Section 4.6), instead of having the references only in the \"Length\" paragraph.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-11 05:35:42-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 14:38:22-08:00",
    "text": "Thank you for the work on this document. I have some comments, mostly having to do with clarifications and improvement of text for readability. I'd like answers to two main points: first - I believe the lack of normative references to the documents that define the fields this document registers into IANA is important enough to warrant some discussion. Second - I'd like some clarification about interoperability. More details below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0 \u00a0 \u00a0 Tenant ID: Represents an opaque value pointing to Orchestration \u00a0 \u00a0 \u00a0 system-generated tenant identifier.\u00a0 The structure and semantics \u00a0 \u00a0 \u00a0 of this field are deployment specific. FP: I am worried about interoperability, as the field is defined as deployment specific. Could you clarify why you don't think this is an issue? Also, please add a normative reference to the section and document defining tenant identification. 2. ---- Section 4.3 FP: Same comment as above for Node ID: please add a reference and explain interoperability, as this is defined as deployment specific. 3. ----- Sections 4.4, 4.5 FP: I do think these fields need references to the documents they are defined in. (I am aware section 2.1 and the normative references should help, but I think it would be much clearer to have direct links to the right place in the text.) For Flow ID, if I understand correctly, this document defines it high level and gives examples of what value it can take. I would clarify that in the first paragraph of the section (as you do for Section 4.6), instead of having the references only in the \"Length\" paragraph.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-31 00:49:09-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-11 05:35:42-08:00",
    "text": "Thank you for the work on this document, and for partly addressing my previous DISCUSS. I only have the one point about interoperability left, which I believe requires some additional clarification in the text. More details below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0 \u00a0 \u00a0 Tenant ID: Represents an opaque value pointing to Orchestration \u00a0 \u00a0 \u00a0 system-generated tenant identifier.\u00a0 The structure and semantics \u00a0 \u00a0 \u00a0 of this field are deployment specific. FP: I am worried about interoperability, as the field is defined as deployment specific. Could you clarify why you don't think this is an issue? Please see the telechat minutes for more details about the discussion and context of this comment:  https://www6.ietf.org/iesg/minutes/2021/narrative-minutes-2021-12-02.txt",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-01-11 06:43:43-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 11:28:01-08:00",
    "text": "1. I notice that in his RTGDIR review of version 08 [*], Stig Venaas suggested some improvements to the security considerations section. This was subsequently discussed and Yuehua Wei proposed some new text [**] for version 09. That text isn\u2019t present, and I don\u2019t see any further resolution on the mailing list either. I\u2019d appreciate it if the topic were closed by either adding the proposed text, or some other text to resolve Stig\u2019s concern, or explanation of why no change was made. [*]  https://datatracker.ietf.org/doc/review-ietf-sfc-nsh-tlv-08-rtgdir-lc-venaas-2021-09-29/ [**]  https://mailarchive.ietf.org/arch/msg/sfc/Q2Snf_ZLTkJ1augbaWpmNYlwFBU/ 2. In \u00a78.2, the two first references, [GROUPBASEDPOLICY] and [GROUPPOLICY] are deficient. At a minimum, a reference should provide enough information to allow a reader to straightforwardly determine how to retrieve it. This is true even if it\u2019s not an openly-available online source. These two references have less than the bare bones, I don\u2019t know how to find them or refer to them.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-01-27 11:51:35-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 22:34:21-08:00",
    "text": "I'm having trouble understanding the first thing you've got in Section 7.\u00a0 You have one table of assignments to make, but you're referencing two distinct sub-registries under \"Network Service Header (NSH) Parameters\", namely \"NSH MD Class\" and \"NSH IETF-Assigned Optional Variable-Length Metadata Types\".\u00a0 There doesn't appear to be a \"metadata context type registry\".\u00a0 I think this change clarifies what you mean, but please tell me if I'm wrong: OLD: \u00a0  IANA is requested to assign the following types from the \"NSH IETF- \u00a0  Assigned Optional Variable-Length Metadata Types\" (0x0000 IETF Base \u00a0  NSH MD Class) registry available at [IANA-NSH-MD2]: \u00a0  This document defines the following new values (Table 1) in the \u00a0  Network Service Header (NSH) metadata context Type registry: NEW: \u00a0  IANA is requested to assign the following types (Table 1) from the IETF \u00a0  Review range in the \"NSH MD Class\" sub-registry of the \"Network Service \u00a0  Header (NSH) Parameters\" registry:",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-04-26 08:36:42-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-20 09:39:51-07:00",
    "text": "Setting this ballot as DISCUSS for now, pending the resolving of Ben's DISCUSS items. Donald Eastlake communicated changes that will resolve these, so waiting on that new ID.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-08-22 13:10:44-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 00:10:54-07:00",
    "text": "In Section 3.2, there's this field definition: \u00a0  Reserved\u00a0 \u00a0 \u00a0 \u00a0 This field SHOULD be ignored by the receiver. I'm worried about interoperability here.\u00a0 \"SHOULD\" allows a choice.\u00a0 As written, I would be within the protocol if I decided to interpret this field, even if the other participants put junk here.\u00a0 Wouldn't it be better to say this is a \"MUST\", or require that it be all zero bits (at least in this version)?\u00a0 If you really think this needs to be a \"SHOULD\", I suggest explaining the choice that's being made available to an implementer here.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-09-08 02:29:23-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 03:37:05-07:00",
    "text": "Hi, I had a couple of minor discuss comments to clarify a couple of points that seemed unclear: 1) Definition of Sequence Number: \u00a0  Sequence Number An optional 32-bit sequence number starting from 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  and increasing by 1 for each following monitored \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  packet from the same flow at the encapsulating node. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The Sequence Number, when combined with the Flow ID, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  provides a convenient approach to correlate the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  exported data from the same user packet. Please can you clarify.\u00a0 Is this every packet in the flow (presumably not)?\u00a0 Does monitored packet means just those with the DEX option?\u00a0 Could it include other packets  2. Optional field ordering. \u00a0  Optional fields The optional fields, if present, reside after the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Reserved field.\u00a0 The order of the optional fields is \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  according to the respective bits that are enabled in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  the Extension-Flags field.\u00a0 Each optional field is 4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  octets long. Please can clarify that the order is from most significant bit to least significant bit of the option field. 3. Allocation is based on the \"RFC \u00a0  Required\" procedure, as defined in [ RFC8126 ]. Given the number of extensions is so limited, is RFC required (e.g. allows ISE) really a strict enough allocation policy? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-09-23 05:25:33-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 06:34:56-07:00",
    "text": "It isn\u2019t clear whether DEX can be exported outside of the IOAM domain.\u00a0 If it can, more is needed to describe the implications.\u00a0 There are the following related statements: (a) Section 3.1.2 says: \u00a0  Exported packets SHOULD NOT be exported over a path or a tunnel that \u00a0  is subject to IOAM direct exporting. (b) Section 6 says: \u00a0  IOAM is assumed to be deployed in a restricted administrative domain, \u00a0  thus limiting the scope of the threats above and their affect.\u00a0 This \u00a0  is a fundamental assumption with respect to the security aspects of \u00a0  IOAM, as further discussed in [ RFC9197 ]. \u00a0   (c) Section 6 says: \u00a0  Although the exporting method is not within the scope of this \u00a0  document, any exporting method MUST secure the exported data from the \u00a0  IOAM node to the receiving entity.\u00a0 Specifically, an IOAM node that \u00a0  performs DEX exporting MUST send the exported data to a pre- \u00a0  configured trusted receiving entity.\u00a0 Furthermore, an IOAM node MUST \u00a0  gain explicit consent to export data to a receiving entity before \u00a0  starting to send exported data. Statement (b) is the usual caveat that IOAM traffic stays inside the domain.\u00a0 However, this new option type is something different \u2013 there are the packets themselves and the telemetry generated from them (i.e., the export packets).\u00a0 Statement (c) is clear and helpful but doesn\u2019t resolve if these entities are in the IOAM domain.\u00a0 Statement (a) seems to mitigation for not creating loops but like (c) silent on clarifying whether in the IOAM domain. If export can only happen in the IOAM domain, consider adding something as simple as the following in the Security Considerations: NEW: DEX exporting MUST NOT be to entities outside of the IOAM domain.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-09-19 14:08:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-29 14:19:53-07:00",
    "text": "Thanks for working on this specification.  Thanks to Colin Perkins for his valuable TSVART review. I find the TSVART early reviewer's concern on rate limiting the exported traffic triggered by DEX Option-type as only protection mechanism ( https://mailarchive.ietf.org/arch/msg/tsv-art/1WNgYWGJmxLd4f3RAiDk-LJ-S8Y/ ) very valid but haven't seen it addressed. In this discuss, I would like to bring back attention to that concern and would like to discuss why there should not be a circuit breaker kind of functionality required here? I also think this specification should be explicit about not exporting IOAM data to any receiver outside of IOAM limited domain. Hence supporting Roman's discuss. for example - The introduction section can state- OLD text- \u00a0  A \u00a0  \"receiving entity\" in this context can be, for example, an external \u00a0  collector, analyzer, controller, decapsulating node, or a software \u00a0  module in one of the IOAM nodes. New text- \u00a0  A \u00a0  \"receiving entity\" in this context can be, for example, an external \u00a0  collector, analyzer, controller, decapsulating node, or a software \u00a0  module in one of the IOAM nodes with in IOAM limited domain.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-04-05 05:04:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-05 04:39:15-07:00",
    "text": "There might be a serious issue in label definition. 5.1.3.\u00a0 Label Parameter \u00a0  The 'label' parameter indicates the name of the channel.\u00a0 It \u00a0  represents a label that can be used to distinguish, in the context of \u00a0  the WebRTC API [WebRtcAPI], an RTCDataChannel object from other \u00a0  RTCDataChannel objects.\u00a0 This parameter maps to the 'Label' parameter \u00a0  defined in [ I-D.ietf-rtcweb-data-protocol ].\u00a0 The 'label' parameter is \u00a0  optional.\u00a0 If it is not present, then its value defaults to the empty \u00a0  string. \u00a0 label-opt\u00a0 \u00a0 \u00a0  = \"label=\" quoted-string \u00a0 quoted-string\u00a0  = DQUOTE *(quoted-char / escaped-char) DQUOTE \u00a0 quoted-char\u00a0 \u00a0  = SP / quoted-visible \u00a0 quoted-visible\u00a0 = %x21 / %x23-24 / %x26-7E ; VCHAR without \" or % \u00a0 escaped-char\u00a0 \u00a0 = \"%\" HEXDIG HEXDIG I interpret that as the intention is to enable the SDP Attribute to carry the label as defined in W3C API. That value is in the current candidatate specification an  https://www.w3.org/TR/webrtc/  as an USVSsting ( https://heycam.github.io/webidl/#idl-USVString ). And in the reference version of the WebRTC API as an DOMstring. Both are not limited to ASCII and may contain any Unicode characters. Thus the escaping mechanism defined appear to be insufficient.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-05-08 00:50:50-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-05 05:04:28-07:00",
    "text": "There might be a serious issue in label definition. 5.1.3.\u00a0 Label Parameter \u00a0  The 'label' parameter indicates the name of the channel.\u00a0 It \u00a0  represents a label that can be used to distinguish, in the context of \u00a0  the WebRTC API [WebRtcAPI], an RTCDataChannel object from other \u00a0  RTCDataChannel objects.\u00a0 This parameter maps to the 'Label' parameter \u00a0  defined in [ I-D.ietf-rtcweb-data-protocol ].\u00a0 The 'label' parameter is \u00a0  optional.\u00a0 If it is not present, then its value defaults to the empty \u00a0  string. \u00a0 label-opt\u00a0 \u00a0 \u00a0  = \"label=\" quoted-string \u00a0 quoted-string\u00a0  = DQUOTE *(quoted-char / escaped-char) DQUOTE \u00a0 quoted-char\u00a0 \u00a0  = SP / quoted-visible \u00a0 quoted-visible\u00a0 = %x21 / %x23-24 / %x26-7E ; VCHAR without \" or % \u00a0 escaped-char\u00a0 \u00a0 = \"%\" HEXDIG HEXDIG I interpret that as the intention is to enable the SDP Attribute to carry the label as defined in W3C API. That value is in the current candidatate specification an  https://www.w3.org/TR/webrtc/  as an USVSsting ( https://heycam.github.io/webidl/#idl-USVString ). And in the reference version of the WebRTC API as an DOMstring. Both are not limited to ASCII and may contain any Unicode characters. Thus the escaping mechanism defined appear to be insufficient.  I think the \"quoted-string\" need a definition of what type of string this truly are so that it is clear what a character in the string is.  In addition the specification of escaping is undersspecified. I would recommend at least adding discussion of the need and how to escape DQUOTE and % that can be relatively common operations.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-25 11:13:05-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-09 12:58:56-07:00",
    "text": "(1) Section 5.2.1.\u00a0 The ABNF of stream-id of \u201cdcsa-value = stream-id \u2026\u201d does not appear to be defined explicitly or by reference in the draft. (2) Section 6.6, \u201c\u2026 the offerer SHALL include previously negotiated SDP attributes \u2026 associated with the channel\u201d.\u00a0 What is the behavior of the receiver if the attributes included by the offerer are NOT those that were previously negotiated?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-11 21:03:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-06 10:41:04-07:00",
    "text": "Inclusion of an \"implementation requirement\" column in the IANA registries implies a need for a defined procedure to make changes to existing registrations.\u00a0 With only a \"specification required\" procedure, it seems there would need to be a \"change controller\" column as well. Furthermore, is it expected that anyone with any specification could set, e.g., an implementation requirement of \"MUST\"?\u00a0 It seems like this attribute might be better left for the RFCs defining the protocol, to be modified by an updating RFC... If we are to retain the Implementation Status appendix in the final RFC, the boilerplate will need some changes, and I think those changes should get review prior to AUTH48.\u00a0 For example, \"at the time of posting of this Internet-Draft\" will make no sense in an RFC, and the relationship to  RFC 7942  is not quite as clear given that we diverge from its recommendations.\u00a0 \"[A]ssist the IETF in its decision process\" does not seem to apply after the IETF has made its decision, though the disclaimer about endorsement seems highly important to retain. This seems to be related to Roman's Discuss point, but the document seems to be inconsistent as to the primary purpose of the mechanism -- Section 1.1 says that it is to verify \"authenticity\" of a stand-alone zone, whereas the Introduction implies that \"integrity\" is primary (with authenticity as an add-on \"when used in combination with DNSSEC), and the Abstract refers to \"accuracy and completeness\".\u00a0 In particular, it is easy to read references to \"integrity\" (and, indeed, the Abstract itself) as referring to something akin to a transport checksum instead of a cryptographic message integrity code.\u00a0 I think the document needs to be much more clear, and consistent, about what properties it aims to provide.\u00a0 (I do not believe that the \"authenticity\" property can be provided without DNSSEC, and Roman covers the cryptographic integrity case in his ballot position.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-12 09:23:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-05 19:47:01-07:00",
    "text": "Section 6.1.\u00a0  My read of the text is that the security properties are intended to be independent of the transport protocol.\u00a0 With that assumption and the validation procedures in Section 4, I need help understanding the security properties the client can rely on in the absence of DNSSEC.\u00a0 Consider the following scenarios and attacker types; and the assurances a client could have when retrieving the zone file from the server: With an on-path attacker (and trusted server hosting the zone file) ** No DNSSEC; No Secure transport = integrity: NO; authenticity = NO ** No DNSSEC; Secure transport = integrity: YES (from the on-path attacker); authenticity = NO ** DNSSEC = integrity: YES; authenticity = YES With a rogue server hosting the zone file (but is not the operator of the zone) ** No DNSSEC; No Secure transport = integrity: NO; authenticity = NO ** No DNSSEC/Secure transport = integrity: NO; authenticity = NO ** DNSSEC = integrity: YES; authenticity = YES The text states that: The zone digest allows the recipient of a zone to verify its \u00a0  integrity.\u00a0 In conjunction with DNSSEC, the recipient can \u00a0  authenticate that it is as published by the zone originator. Can the means to realize integrity without DNSSEC unless there is a reliance on transport security of some form be clarified.\u00a0 Minimally, it seems like this section needs cautionary text (likely with normative language) to the effect of \u201cZONEMD information from zone files lacking DNSSEC support or that were shared over \u2018unsecure transport\u2019 cannot be relied upon for cryptographic integrity assurance.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-01-06 09:47:08-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 03:42:07-08:00",
    "text": "Hi, A trivial discuss that should hopefully be easy to resolve, and it is plausible that the resolution may end up being in the QUIC transport document: In this document, the unused bits are defined as: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Figure 4: Version Negotiation Packet \u00a0  Only the most significant bit of the first byte of a Version \u00a0  Negotiation packet has any defined value.\u00a0 The remaining 7 bits, \u00a0  labeled Unused, can be set to any value when sending and MUST be \u00a0  ignored on receipt. In the QUIC transport document, they are defined as this: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Figure 14: Version Negotiation Packet \u00a0  The value in the Unused field is selected randomly by the server. \u00a0  Clients MUST ignore the value of this field.\u00a0 Servers SHOULD set the \u00a0  most significant bit of this field (0x40) to 1 so that Version \u00a0  Negotiation packets appear to have the Fixed Bit field. I would have expected that these two should be consistent as to whether the Fixed Bit SHOULD be set to 1 or not.\u00a0 Given  draft-thomson-quic-bit-grease-00 , it might be better if the SHOULD is removed from QUIC transport, but I will defer to the experts here. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-19 15:14:35-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-19 15:14:10-08:00",
    "text": "It looks like the indentation in the example MAIN PROGRAM in Appendix C is incorrect, or at least confusing, in the \"do forever\" loop therein. Specifically, assuming semantic whitespace as in Python, we never actually perform grasp negotiation for the \"good_peer in peers\" case. Additionally, I think we may have a risk of getting stuck in a loop making no progress so long as good_peer remains in the set of discovered peers but does not have enough resources available for our request/negotiation to succeed.\u00a0 I think we want to clear out good_peer if a negotiation fails to avoid that scenario.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-01-26 19:48:07-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-19 15:14:35-08:00",
    "text": "It looks like the indentation in the example MAIN PROGRAM in Appendix C is incorrect, or at least confusing, in the \"do forever\" loop therein. Specifically, assuming semantic whitespace as in Python, we never actually perform grasp negotiation for the \"good_peer in peers\" case. Additionally, I think we may have a risk of getting stuck in a loop making no progress so long as good_peer remains in the set of discovered peers but does not have enough resources available for our request/negotiation to succeed.\u00a0 I think we want to clear out good_peer if a negotiation fails, to avoid that scenario.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-27 05:05:26-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-18 18:13:53-08:00",
    "text": "** Section 3.1 and 3.2.  (a) (Section 3.1) \u201c\u2026 the secure bootstrap process itself may include special-purpose ASAs that run in a constrained insecure mode.\u201d,  (b) (Section 3.2) \u201c \u2026 the ACP formation process itself may include special-purpose ASAs that run in a constrained insecure mode.\u201d What is meant by \u201cspecial-purpose\u201d (i.e., how is that different than an ASA that isn\u2019t special purpose) and what are the security properties of a \u201cconstrained insecure mode\u201d?\u00a0 Is this text saying that the secure bootstrapping and ACP formation might not always be done securely? (b) reads like it could be DULL-GRAP (Section 2.5.2 of  draft-ietf-anima-grasp ) but it isn\u2019t clear.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-10 04:38:11-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-09-10 04:36:02-07:00",
    "text": "Hi, Thank for you this YANG module.\u00a0 It is great to see IETF progressing publishing more YANG configuration/management models, to thank you for the time and effort that have put into this. I support Roman's discuss regarding the security considerations, but would also like to add one of my own: In my experience, having some instance data examples (e.g., see Appendix D of  RFC 8022 ) greatly helps readers understand the structure of the YANG module and get a good feel for how the YANG model is used.\u00a0 Was adding instance data examples considered for this document?\u00a0 Do the authors that think it would be possible to add some examples? I've also added some comments on the YANG model below that probably need to be addressed but I didn't want to overload the main discuss point. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-10-23 11:51:51-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-10 04:38:11-07:00",
    "text": "Hi, Thank for you this YANG module.\u00a0 It is great to see IETF progressing publishing more YANG configuration/management models, to thank you for the time and effort that you have put into this. I support Roman's discuss regarding the security considerations, but would also like to add one of my own: In my experience, having some instance data examples (e.g., see Appendix D of  RFC 8022 ) greatly helps readers understand the structure of the YANG module and get a good feel for how the YANG model is used.\u00a0 Was adding instance data examples considered for this document?\u00a0 Do the authors that think it would be possible to add some examples? I've also added some comments on the YANG model below that probably need to be addressed but I didn't want to overload the main discuss point. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-20 03:46:13-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-08 15:36:53-07:00",
    "text": "** Section 11.\u00a0 Thanks for enumerating the sensitive read operations.\u00a0 It looks like the sensitive writes aren\u2019t described.\u00a0 Wouldn\u2019t it be a problem for arbitrary writes to occur to /rt:routing/mpls/*?\u00a0 I recommend using the \"template language\" of \"There are a number of data nodes defined in these YANG modules that are writable/creatable/deletable ... These are the subtrees and data nodes and their sensitivity/vulnerability:\" to provide this easy fix.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-01-12 02:55:33-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-22 04:36:16-08:00",
    "text": "# GEN AD review of  draft-ietf-cdni-additional-footprint-types-05 CC @larseggert Thanks to David Schinazi for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/-wFk1qr6NmJErpMO7olE-DGXdEA ). ## Discuss Should this document also update  RFC 9241 ?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-04-13 00:37:20-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-12 03:03:36-07:00",
    "text": "# GEN AD review of  draft-ietf-oauth-dpop-14 CC @larseggert ## Discuss ### Section 12.7.1, paragraph 3 ``` \u00a0 \u00a0  However, the initial registration of the nonce claim by [OpenID.Core] \u00a0 \u00a0  used language that was contextually specific to that application, \u00a0 \u00a0  which was potentially limiting to its general applicability. \u00a0  \u00a0 \u00a0  This specification therefore requests that the entry for nonce in the \u00a0 \u00a0  IANA \"JSON Web Token Claims\" registry [IANA.JWT] be updated as \u00a0 \u00a0  follows to reflect that the claim can be used appropriately in other \u00a0 \u00a0  contexts. ``` Is OpenID as the change controller OK with the IETF changing the IANA registry in this way?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 10:41:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-03 01:53:12-08:00",
    "text": "The IANA Considerations section seems incomplete. Looking over the registries at https://www.iana.org/assignments/alto-protocol/alto-protocol.xhtml  and comparing against the mechanisms defined in this document, it seems that we need to register the \"ane-path\" Cost Metric.\u00a0 More worryingly, there is no registry on that page in which the \"array\" cost mode could be registered, and it seems that using any value other than \"numerical\" or \"ordinal\" would violate a \"MUST\" in \u00a710.5 of  RFC 7285 .\u00a0 This seems to present some procedural difficulties, especially now that this document is targeting Experimental status rather than Proposed Standard (which, to be clear, I think was the right thing to do).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-01-26 12:55:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-30 07:33:47-08:00",
    "text": "Thanks for documenting the increased risk of exposing sensitive topology information and the potentially of this data being exploited for a highly targeted DoS attack in Section 11.\u00a0 While this significant problem is documented, the mitigation for this fundamental issue is underspecified.\u00a0 The security of this extension is predicated on the ANE obfuscation procedures, but those specifics are not provided. In my review, there doesn\u2019t appear to be wide operational usage or implementations of this extension to inform these obfuscation procedures.\u00a0 Furthermore, it appears that these procedures remain an open research question.\u00a0 I appreciate the helpful references to the academic papers in Section 11 ([NOVA], [RESA][ MERCATOR])\u00a0 but their practical applicability to the generic capability provided by this extension appears to be difficulty to align and be caveated.\u00a0 For example, [RESA] and [MERCATOR] made what appear to be significant assumptions on their approaches, \u201cIn this paper, we assume a semi-honest security model, i.e., the aggregator and all member networks will not deviate from the security protocol, but merely try to gather information during the execution of the protocol\u201d.\u00a0  I believe this document needs to be provide a stronger applicability statement constraining where it can be fielded and what assumptions are made about the trust models.\u00a0 Additionally, given the uncertainty on the generic feasibility of obfuscation, this document should be published as experimental.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-02 16:53:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-26 12:55:49-08:00",
    "text": "(Updated ballot to make the remaining issues clear) Thanks for the update in -20 and in particular all of the new language in the Security considerations to discuss applicability and obfuscation procedures.\u00a0  In these edits in response to the earlier DISCUSS text, the following sentence was introduced into Section 11: For settings where the ALTO server and client are not\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  in the same trust domain, Digital Right Management (DRM) techniques\u00a0 \u00a0 \u00a0 \u00a0 \u00a0   and legal contracts protecting the sensitive Path Vector information\u00a0 \u00a0 \u00a0 \u00a0   MUST be applied. It appears to be trying to provide guidance on how to ensure that only the expected ALTO clients get the sensitive path information in the case where the server and clients are in different trust domains.\u00a0 This new language contains normative guidance to using DRM techniques.\u00a0 Given this is a normative \u201cMUST\u201d, the specifics of \u201cDRM techniques\u201d is under-specified.\u00a0 Independent of that, DRM techniques I quickly think of provides object security (i.e., embedding a security envelope of some form directly in the data it is trying to protect).\u00a0 How would that mesh with the specified format for the path information in this document?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-16 20:32:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 14:36:17-08:00",
    "text": "As Mirja maybe already noted, Section 3.4.3 says: \u00a0  Section 8.3 of the RTP Specification [ RFC3550 ] recommends using a \u00a0  single SSRC space across all RTP sessions for layered coding.\u00a0 Based \u00a0  on the experience so far however, we recommend to use a solution with \u00a0  explicit binding between the RTP streams that is agnostic to the used \u00a0  SSRC values.\u00a0 That way, solutions using multiple RTP streams in a This sounds an awful lot like we're trying to update the recommendations from  RFC 3550 , and looks like different text than was discussed in Mirja's ballot thread.\u00a0 Let's discuss whether the formal Updates: mechanism is appropriate here or we should consider rewording.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-25 07:48:24-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 08:37:09-07:00",
    "text": "** Section 6.4.2.\u00a0 My read of Figure 3 is that the suggested architecture can be incrementally deployed.\u00a0 My other read is that it appears that this staged deployment isn\u2019t safe outside of controlled environments (i.e., for the Internet) until after phase 1.\u00a0 Assuming this is accurate, please add clear normative language that partial roll-outs of the L4S architecture MUST NOT occur outside of controlled environment until .",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-06-02 07:47:14-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 23:16:15-07:00",
    "text": "Paul said: > I think that SHOULD can be a MUST. Although one could question the 2119 usage as it seems to be a directive to a document author and not a protocol action. So I would also be okay with lowercasing this. I'm ambivalent about the first sentence, but I concur strongly with the second; use of  BCP 14  language to establish a requirement against some future document seems quite unconventional to me.\u00a0 Can we talk about why this is necessary and/or appropriate?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-03 08:16:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 20:11:26-07:00",
    "text": "Probably an easily answered issue, but I am not too familiar with ALTO. \u00a0 \u00a0  The string MUST be no more than 32 characters, and it MUST NOT contain characters other than [...] Are there implementations that already deployed a cost string with more than 32 characters or characters not in this newly imposed set of characters? What should happen if that is in use? That is, is this protocol modification potentially breaking interoperability with older implementations?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-05-31 06:00:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-25 08:05:27-07:00",
    "text": "Hi, This is a \"discuss\" discuss, as in I'm not sure the document is wrong, but I thought that it would be helpful to flag this for further discussion. In  RFC 7285 , cost-mode is defined as a field that MUST take one of two string values, either \"numerical\" or \"ordinal\".\u00a0 I'm not really familiar with  RFC 7285 , and in particular, whether a receiver is required to explicitly check that the received data must take one of these two values, or whether a reasonable implementation could check for a single value, and if doesn't match that value assume that it must be the other value (since there are only two allowed values).\u00a0 Obviously, moving to more than two values could then cause this assumption to break in existing implementations.\u00a0 Was this issue considered and discussed by the WG?\u00a0 It looks like alto does support a versioning mechanism (i.e., by defining new media types) that might allow the definition of this field to be upgraded in a safer way.\u00a0 Was that approach considered? Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-29 14:40:27-07:00",
    "end_reason": "position_updated",
    "start": "2022-08-24 08:46:14-07:00",
    "text": "Section 4.3. In order to coexist safely with other Internet traffic, a scalable \u00a0  congestion control MUST NOT tag its packets with the ECT(1) codepoint \u00a0  unless it complies with the following bulleted requirements: Based on the use of \u201cMUST NOT\u201d, my read of this text is that all subsequent list items must comply with this list.\u00a0 List items #3, 5 and 6 include SHOULD clauses.\u00a0 How an implementer mix the \u201cMUST\u201d and and SHOULD clause? As simply fix might be to drop the \"MUST NOT\" in the preamble to the bulleted list.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-13 14:26:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 15:51:34-08:00",
    "text": "The following points notwithstanding, I'm excited to see this mechanism get specified and am looking forward to balloting Yes once my concerns are resolved.\u00a0 Thank you for writing this document (and implementing it, etc.)! There seems to be an internal inconsistency in the normative guidance for how long a given cookie value should be accepted.\u00a0 Section 4.3 says that \"[t]he DNS Server SHOULD allow Cookies within 1 hour period in the past and 5 minutes into the future to allow operation of low volume clients and some limited time skew between the DNS servers in the anycast set\" (before going on to recommend that the server generates a new cookie if it receives one from the client that is more than half an hour old).\u00a0 In contrast, Section 5 says \"[t]he operator SHOULD wait at least longer than the period clients are allowed to use the same Server Cookie, which SHOULD be half an hour, see Section 4.3\".\u00a0 If I'm reading correctly the \"1 hour\" in Section 4.3 is supposed to line up with the \"half an hour\" in Section 5, but does not. Also, as was mentioned in the secdir review thread, I think we should clearly state what properties we require of a MAC in order to be a useful server cookie (including why the chosen inputs are the right thing to MAC!)\u00a0 That is, what message is being authenticated, and why is that a useful message to authenticate? I will also take this opportunity to consult the CFRG on the suitability of SipHash-2-4 for its stated purpose, though I do not feel a strong need to delay IESG approval of this document until a positive answer is received.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-11-27 14:41:40-08:00",
    "text": "(0) As written, the validation procedures for the authority token contain a gaping security hole.\u00a0 In particular, \u00a76 has us use the public key of the certificate referenced by the token's \"x5u\" parameter, without checking that that \"x5u\" value (or the certificate it references) is a trusted issuer of authority tokens.\u00a0 This in essence boils down to \"go fetch a certificate from an attacker provided location and verify that the signature over the attacker-provided token was made by that attacker-provided certificate\".\u00a0 This is trivial for an attacker to achieve and provides no security value.\u00a0 We need to know that the token issuer is trusted and authorized to issue this class of token. The companion document  draft-ietf-acme-authority-token  does describe the need for this mutual trust relationship, but it is negligent for us to provide a step-by-step procedure here that omits this step. (1) Related to my discuss on  draft-ietf-acme-authority-token , we should be clear on which document is the authoritative specification for \"token-authority\" usage; at present the description seems to be split across the two documents. (2) Section 3 \u00a0  The format of the string that represents the TNAuthList MUST be \u00a0  constructed as a base64 [ RFC4648 ] encoding of the TN Authorization \u00a0  List certificate extension ASN.1 object.\u00a0 The TN Authorization List \u00a0  certificate extension ASN.1 syntax is defined in [ RFC8226 ] section 9. Does it need to be the (base64 encoding of the) DER encoding of the ASN.1 object?\u00a0 Or do we allow less stringent ASN.1 encoding rules? (Similarly in \u00a75.4.) (3) I think my discuss point on  draft-ietf-acme-authority-token  about how the issuer is identified will also apply (with slight modification) to this document -- in \u00a75.1 we have text that indicates either \"iss\" or \"x5u\" identifies the issuer, which I do not believe to be accurate. (4) This document claims to define the \"atc\" claim, but draft-ietf-acme-authority-token  also claims to do so.\u00a0 I note that the IANA registration is currently in the other document, but this one has a more accurate/fleshed-out description of the contents, including the various keys that are present in the JSON object.\u00a0 (The other document says it's an \"array\", not an object!) (5) The end of \u00a75.5 has some guidance on HTTP response codes in various failure cases.\u00a0 The proposed behavior provides a trivial side channel to an attacker as to whether a given account ID exists (404 vs 403), and I think we should avoid providing such a side channel, returning 403 for most failures. (6) The validation procedure in \u00a76 just says to check that the \"fingerprint\" claim is \"valid\".\u00a0 I think we should be more specific and say that it must match the account key of the client making the request.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-10-20 12:47:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-11-26 23:52:31-08:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS point (but trivial to fix), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Rich Salz for the shepherd's write-up about the WG consensus (and I noted the mix of STIR & ACME). I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == A very trivial one: please use the more recent  BCP14  template (incl.  RFC 8174 ) ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:36:39-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-30 03:23:14-08:00",
    "text": "Thank you for the work on this document. Many thanks to Sean Turner for his in-depth review, which uncovered a number of points worth fixing:  https://mailarchive.ietf.org/arch/msg/art/6gRj3ieBe2mIdCa10IfOIoFf7Eg/ Additionally, I have one more non blocking comment below. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-06-30 09:11:33-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 14:36:39-08:00",
    "text": "Thank you for the work on this document. Many thanks to Sean Turner for his in-depth review, which uncovered a number of points worth fixing:  https://mailarchive.ietf.org/arch/msg/art/6gRj3ieBe2mIdCa10IfOIoFf7Eg/ Additionally, I have one more non blocking comment below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-10-23 08:35:48-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 21:30:43-08:00",
    "text": "A couple of easy but necessary ones: Please use the correct  BCP 14  boilerplate in Section 2, and I believe those references need to be normative. Also, I think this document, like  draft-ietf-acme-authority-token , needs a normative reference to  RFC 4648  if it's going to use base64url().",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-07 18:50:09-08:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 09:10:25-07:00",
    "text": "Picking up a Discuss for Francesca: Many thanks to Sean Turner for his in-depth review, which uncovered a number of points worth fixing:  https://mailarchive.ietf.org/arch/msg/art/6gRj3ieBe2mIdCa10IfOIoFf7Eg/ Additionally, I have one more non blocking comment below. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-31 16:23:32-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-06 12:46:45-07:00",
    "text": "If we are providing BCP-level requirements for time-based loss detection via absence of protocol-level acknowledgment, for new protocols, it seems appropriate to mandate that the acknowledgment signal is reliable, i.e., not spoofable by at least an off-path attacker, and ideally not spoofable by an on-path attacker either.\u00a0 I would love for this to be a cryptographically protected mechanism, but expect that I can't get away with mandating something that strong, and that something with \"enough bits of entropy\" will suffice.\u00a0 (I'd prefer \"enough\" to be 128 but could perhaps be persuaded that a lower value is appropriate as a minimum requirement.) Point S.3 in Section 3 indicates that \"[t]he requirements in this document apply only to endpoint-to- endpoint unicast communication. Reliable multicast (e.g., [ RFC5740 ]) protocols are explicitly outside the scope of this document.\"\u00a0 This limitation of scope should be reflected in the document's title, Abstract, and Introduction. I would also like to get an explicit confirmation that the various (non-)requirements on the details of exponential backoff and reduced weighting for old FT samples are as-intended (see COMMENT). Specifically, are there limitations on the base of the exponent for the exponential backoff, and is there a requirement to give more recent FT samples more precedence than older FT samples when computing an RTO estimate?",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2023-02-02 07:20:01-08:00",
    "end_reason": "position_updated",
    "start": "2023-02-02 00:50:07-08:00",
    "text": "Thanks for the solid work on this document. One comment that I'd like to discuss, I believe the reference to ietf-shmoo-remote-fee should be normative, since this document makes reference to a long term commitment to free remote participation, and to my knowledge absent the shmoo-remote-fee document that isn't a commitment that is codified.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-10-24 18:48:48-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-24 16:24:36-07:00",
    "text": "RFC 3326  doesn't specify what the receiver will do if two reason values have the same protocol value. Are we reasonably sure that existing implementations of SIP won't throw an error if they get this, or does there need to be some sort of negotiation mechanism?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-10-27 13:38:47-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-25 14:13:58-07:00",
    "text": "I understand the document is changing an existing MUST, and the change itself seems fine. But I do wonder about the operational effect of this. What if a sip stack complying to this new RFC talks to an old sip stack complying to the old RFC. Is it known what the most widely used sip stacks do in the case of receiving a duplicate message for the same protocol? Will it just ignore the duplicate ? If so, should this document specify that the order of these might be important ? Will it fail the entire sip packet? If so, should this document specify to only use this when the other end is known to implement this RFC? Should there be a fallback mechanism that will only sent the 1 most important \"reason\" if it looks the other end is failing on our message with multiple reasons? The WG might have experience or testing that is not obvious to me (or other readers of the document). Perhaps a short Operational Considerations Section would be appropriate ?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-02 15:16:56-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 14:40:15-07:00",
    "text": "Should we say something about which order the sorting criteria are applied (first to last vs last to first) when multiple sortItems are specified in a query? I recognize that in the HATEOS model, the actual JSONPaths reported by the server should be used by the client to determine what a given sort property does, but it also seems like it would be confusing for this document to specify (e.g.) an \"email\" property with specific JSONPath, and then have a server go off and use \"email\" to mean something else, even if that is just the addition of \"pref\" as discussed at the end of Section 2.3.1.\u00a0 Do we want to try to have the properties defined by this document be universally defined and encourage the use of new/different property names for variations on them?\u00a0 (The answer may well be \"no\", but the answer is not intuitively clear to me.)\u00a0 To put it another way, is the list in Section 2.3.1 normative, or just an example?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-10-02 15:55:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 06:33:26-07:00",
    "text": "** Canonical Reference for JSONPath.\u00a0 Section 2.1/2.3.1 describes field(s) whose syntax is in JSONPath.\u00a0 The shepherd\u2019s note acknowledges that there is no good reference for JSONPath.\u00a0 Nevertheless, the text needs to be clearer on where to turn to for guidance. (1) Section 2.3.1 says: \u201cSuch a reference could be \u00a0  expressed by using a JSONPath.\u00a0 The JSONPath in a JSON document \u00a0  [ RFC8259 ] is equivalent to the XPath [ W3C.CR -xpath-31-20161213] in a \u00a0  XML document.\u00a0  (2) The JSONPaths are provided according to the Goessner v.0.8.0 \u00a0  specification [GOESSNER-JSON-PATH].  (3) Further documentation about \u00a0  JSONPath operators used in this specification is included in \u00a0  Appendix A. Taking the perspective of the implementer, which of these three resources is canonical for understanding JSONPath: (a) [ W3C.CR -xpath-31-20161213] = a reference marked normative that has nothing to do with JSON but suggests equivalence through a few examples. (b) [GOESSNER-JSON-PATH] = a reference marked as informative which is being used to describe the normative mapping between JSONPaths of the RDAP fields in the text, and is the actual description of the JSONPath syntax.\u00a0 The shepherd\u2019s note points out the difficulty of using this as a normative reference (c) Appendix A = self-contained text which describes JSONPath independent of (a) and (c).\u00a0 As an aside, I\u2019m not sure of the completeness of this write-up. Additionally, the IETF is currently considering it\u2019s own version of JSONPath --  https://datatracker.ietf.org/doc/charter-ietf-jsonpath/ IMO, the fig leaf of citing [ W3C.CR -xpath-31-20161213] is inappropriate (as in, it isn\u2019t the actual reference) and unnecessary (as in, it\u2019s just there to meet the letter of having a normative reference).\u00a0 I recommend being practical about the need: -- Use language to the effect of saying the \u201cJSONPath used here is a flavor defined in XXX\u201d -- Make \u201cXXX\u201d be Appendix A. -- Bolster Appendix A to say something to the effect of \u201cthis version of JSONPath is inspired by [ W3C.CR -xpath-31-20161213] (informative reference) and an articulation of what is used in production [GOESSNER-JSON-PATH] (informative reference)\u201d; and where necessary, add more language around the syntax. This approach will also allow for new JSONPath WG to define a variant which is not strictly compatible (if that\u2019s where the work goes). I\u2019m open to an alternative approach.\u00a0 I just want to end up with a single clear reference of where to read about this documents particular JSONPath syntax. ** Section 2.4.\u00a0 Does this specification provide any normative guidance of \u201ccursor\u201d beyond an opaque value constrained by ABNF?\u00a0 The text notes the notion of \u201coffsets\u201d, \u201climits\u201d, and \u201ckeys\u201d, Base64, CSV but these appear to be referenced as examples.\u00a0 However, Appendix B contains normative language around \u201climit\u201d and \u201coffset\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-12-01 05:36:52-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-28 13:08:51-08:00",
    "text": "# Sec AD review of  draft-ietf-ipsecme-ikev2-multiple-ke-10 CC @paulwouters Please refer to  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ for more information about how to handle DISCUSS and COMMENT positions. This review uses the format specified in  https://github.com/mnot/ietf-comments/  which allows automated tools to process items (eg to produce github issers) Let me first apologize to Valery for not getting to review this document earlier. He surely reminded me enough times to do it before it landed at the IESG. This is a very well written document. Thanks to everyone involved. While I have a few DISCUSS comments, these should be easy to address or convince me why no changes are required. Note to self (and Valery):  draft-kampati-ipsecme-ikev2-sa-ts-payloads-opt  needs to be updated to support this document. It currently only supports sending one KE payload. ## DISCUSS ### IANA entries mentions in the Introduction ? Shouldn't the introduction mention this draft introduces the IKE_FOLLOWUP_KE Exchange and the STATE_NOT_FOUND Notify Message Type, along with additional entries to the (now renamed) Key Exchanges Methods registry? ### Additional key exchanges DoS ? The following paragraph raised an issue for me: ``` \u00a0  If the responder selects NONE for some Additional Key Exchange types \u00a0  (provided they are proposed by the initiator), then the corresponding \u00a0  IKE_INTERMEDIATE exchanges MUST NOT take place. ```\u00a0 \u00a0  If the initiator's local policy requires at least one Additional Key Exchange, an attacker sending back a quick reply with only NONE replies would be a DoS. I think similar to like the original IKE_SA_INIT, perhaps we need to give some advise that if the local policy would lead to permanent failure, that it should wait for other (more legitimate) responses to this IKE_SA_INIT ? ### ADDITIONAL_KEY_EXCHANGE ``` \u00a0  After IKE SA is created the window size may be greater than one and \u00a0  multiple concurrent exchanges may be in progress, it is essential to \u00a0  link the IKE_FOLLOWUP_KE exchanges together ``` I had some trouble figuring out why these are needed. For Child SA rekeys, these would not be needed, because we would have an old SPI and MSGID that would make the order obvious. But for adding addtional Child SA's, we have no old SPI. But we have a new SPI on the initiator (and then a new SPI on the responder in the answer. Since these are coupled by MSGID, I wonder if ADDITIONAL_KEY_EXCHANGE is really needed? Looking at the useful appendix examples, I realise that the IKE_FOLLOWUP_KE exchange does not have an SA payload so no SPI, so it makes sense to me now. Perhaps a sentence in the document would be useful to explain this? I still do not know why not to use the SPI as value for ADDITIONAL_KEY_EXCHANGE instead of an opaque linking blob? The SPI is traditionally our linking blob. Could the IKE_FOLLOWUP_KE set the SPI value in the IKE header instead of using a new ADDITIONAL_KEY_EXCHANGE payload and use that with the MSGID as linking blob? ### State loss issue ```\u00a0 \u00a0   \u00a0  After receiving this notification the initiator MAY start \u00a0  a new CREATE_CHILD_SA exchange which may eventually be followed by \u00a0  the IKE_FOLLOWUP_KE exchanges, to retry the failed attempt.\u00a0 If the \u00a0  initiator continues to receive STATE_NOT_FOUND notifications [...] ``` How could this happen? If the state was lost, eg due to reboot, there would need to come a new IKE SA, that can then send a new CREATE_CHILD_SA. I don't see how that could lead to another STATE_NOT_FOUND. But the paragraph then also continues with \"and delete [the] IKE SA\". But this IKE SA is brand new?  I would just remove this entire paragraph as I think this cannot happen. Or at least it is not a special case and existing abort code handles this already. ### IKE session resumption Should there be a section updating  RFC 5723  Section 5.1, or is the method there specified quantum-safe if the initial IKE SA was protected using this document's mechanism? See  https://www.rfc-editor.org/rfc/rfc5723.html#section-5.1 I think the IKE resumption can work \"as normal\", as no KE payload is involved in the resumption, but it would be nice if a sentence somewhere in this document could confirm this.  Also  RFC 5723  states: ``` The keys and cryptographic protection algorithms should be at \u00a0 \u00a0 \u00a0 least 128 bits in strength. ``` IF we live in Grover universe, perhaps that should be 256 bits in strength? And since we are making things quantum safe with this document, perhaps we should then at least state session tickets should be 256 bits. Note if we do, then this document must Update:  RFC 5723 . Perhaps this note on 5723 can be added in the Security Considerations Section paragraph that talks about Grover and Shor. ### non-fatal NO_PROPOSAL_CHOSEN? ``` \u00a0  In this case, the responder may respond with \u00a0  non-fatal error such as NO_PROPOSAL_CHOSEN notify message type. ```\u00a0 \u00a0   Technically, this error is non-fatal. But in this context, wouldn't it be fatal if the responder insists on additional exchanges during the initial exchange and the initiator doesn't suppor this? It is sort of a lame duck IKE SA ? :) Also the \"may\" responder is unclear to me. What other response could there be and why? ### misplaced text? ``` \u00a0  Note that if the initial IKE SA is used to transfer sensitive \u00a0  information, then this information will not be protected using the \u00a0  additional key exchanges [...] ``` This paragraph appears in the Section \"Interaction with Childless IKE SA\", but should probably be moved to the Security Considerations section. ### IKE_FOLLOWUP_KE name I find the name IKE_FOLLOWUP_KE a little confusing, as this exchange applies to IKE and IPsec SA rekey negotiations. Why is it not called FOLLOWUP_ADDITIONAL_KE ? Or CREATE_CHILD_SA_FOLLOWUP(_KE) (a sort of bad name too but that at least follows the bad name from the original IKEv2 spec) ### authentication ? ```  \u00a0 \u00a0 \u00a0 \u00a0 This document does not address authentication since it is less urgent \u00a0 \u00a0 \u00a0 \u00a0 at this stage. ``` While true, it does state that PPKs can be used. It might also want to say that no IKE protocol level changes would be needed for authentication. A new  RFC 7427 Digital Signature algorithm that is quantum-safe could be defined for X.509 and would become available immediately without any IKEv2 level changes. So in a way, this issue will be addressed but no IKEv2 document is needed for that. Perhaps this can be clarified in the draft? Related to this is text in the Security Considerations: ``` \u00a0  In particular, the authenticity of the SAs established \u00a0  under IKEv2 is protected using a pre-shared key, RSA, DSA, or ECDSA \u00a0  algorithms. ```  This text is also incorrect as  RFC 7427  allows us to use post-quantum authentication algorithms that have a SubjectPublicKeyInfo (SPKI) definition. There might not be any now, but there will presumbly be some in the future. ### AH Section 4 lists AH. Is there much point in using this document when deploying AH? The idea was the protect against _future_ quantum computers breaking encryption, not MITM style packet modification. So using AH (or ESP_NULL) with this document seems pointless :) And the Security Considerations kind of agree with me here: ``` \u00a0  Until quantum computers \u00a0  become available there is no point in attacking the authenticity of a \u00a0  connection because there are no possibilities for exploitation. ```",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-22 18:05:36-08:00",
    "end_reason": "position_updated",
    "start": "2021-08-25 23:59:54-07:00",
    "text": "I think there's an issue with the pseudocode in Figure 6.\u00a0 While I understand that it's pseudocode, any reasonable interpretation I can come up with for the \"~\" and \"&=\" operators seems to result in performing an operation logically equivalent to: X = AdjacentBits[SI] Packet->BitString = Packet->BitString & ~X & X that can be optimized to Packet->BitString = 0 and I do not think that the only bits that are supposed to be set in the outgoing packet/packet copy are the ones for which DNC is set -- bits that we did not find in our BIFT should remain set in outgoing packets. (Slightly more detail in the COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-08-25 09:13:56-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-25 06:50:38-07:00",
    "text": "Hi, I would like to please double check with the authors, responsible AD, and IESG that publishing this as standards track is the right choice (as opposed to experimental). From the first line of the introduction: \"BIER-TE is based on architecture, terminology and packet formats with \u00a0  BIER as described in [ RFC8279 ] and [ RFC8296 ]. Both  RFC 8279  and  RFC 8296  are experimental RFCs, hence (1) I wanted to check that by publishing this draft as Std Track, that this draft isn't being built on an unstable footing. This draft has a normative reference to  RFC 8279 , but only an informative reference to  RFC 8296 . Hence, I further wanted to check: (2) Should  RFC 8296  really be a normative reference? (3) The IETF LC announcement didn't seem to flag the downref to  RFC 8279 .\u00a0  RFC 8067  says that is not strictly required, but in this case I think that would have been useful. I can see from the document history that the WG has flip-flopped on whether this document should be experimental or stds track, but I couldn't quickly find this discussion, and it wasn't covered in shepherds writeup.\u00a0 If it is possible for someone to provide a quick summary as to why it is okay and right to publish this as standards track that would be appreciated.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-06-11 05:35:17-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-06-10 14:56:44-07:00",
    "text": "This should be simple to resolve - the use of the SR-TE term is out-of-alignment with other drafts, spring and idr. Suggest: Segment Routing Traffic Engineering/s/Segment Routing Policy and SRTE/s/SR Policy.",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2020-06-22 12:00:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 05:35:17-07:00",
    "text": "This should be simple to resolve - the use of the SR-TE term is out-of-alignment with other drafts, spring and idr. Suggest: Segment Routing Traffic Engineering/s/Segment Routing Policy and SRTE/s/SR Policy. And this should be obvious, the abstract justifies the need for this document because routers assume RSVP-TE on a link based on an OSPF advertisement. But that's an implementation shortcut and needs to be noted as that. Sure, it was ok when everything was RSVP/RSVP-TE. But let's not make it a \"BCP\". This needs to be corrected to say \"Some implementations..\". I would suggest aligning this abstract with the ISIS draft and move this paragraph to later in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-06-23 03:42:49-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 07:32:00-07:00",
    "text": "I found parts of this document hard to understand, but I'm not familiar with the specifics of the protocols. This discuss is in the vein of \"I think that folks might struggle to implement this correctly/consistently\".\u00a0  In particular I had some questions/concerns about section 5 which, if clarified, would probably help this document. In Section 5: \u00a0  The ASLA sub-TLV is an optional sub-TLV and can appear multiple times \u00a0  in the OSPFv2 Extended Link TLV and OSPFv3 Router-Link TLV.\u00a0 The ASLA \u00a0  sub-TLV MUST be used for advertisement of the link attributes listed \u00a0  at the end on this section if these are advertised inside OSPFv2 \u00a0  Extended Link TLV and OSPFv3 Router-Link TLV.\u00a0 It has the following \u00a0  format: I think that it would be useful to clarify when/why the ASLA sub-TLV can be included multiple times.\u00a0 I.e. when different applications want to control different link attributes. \u00a0  Standard Application Identifier Bits are defined/sent starting with \u00a0  Bit 0.\u00a0 Undefined bits which are transmitted MUST be transmitted as 0 \u00a0  and MUST be ignored on receipt.\u00a0 Bits that are not transmitted MUST \u00a0  be treated as if they are set to 0 on receipt.\u00a0 Bits that are not \u00a0  supported by an implementation MUST be ignored on receipt. It was not clear to me what it means if the SABM (or UDABM) fields are entirely empty.\u00a0 This paragraph states that they are treated as if they are 0, but sections 8 and 11 imply that if the field is omitted then it acts as if all applications are allowed.\u00a0 Section 12.2 implies that if the field is omitted then it is as if all applications are allowed unless there there is another ASLA with the given application bit set, in which case it is treated as being a 0 again.\u00a0 I think that this document would be helped if the specific behaviour was defined in section 5, retaining the justification/clarification in the subsequent sections. It is also not entirely clear to me exactly how the bits are encoded on the wire.\u00a0 My assumption is that if bit 0 is set, then this would sent the highest bit of the first byte.\u00a0 E.g. 0x80?\u00a0 Is that correct?\u00a0 If not, then I think that the document needs more text, if so, then an example of the encoding may still aid readability. \u00a0  User Defined Application Identifier Bits have no relationship to \u00a0  Standard Application Identifier Bits and are not managed by IANA or \u00a0  any other standards body.\u00a0 It is recommended that bits are used \u00a0  starting with Bit 0 so as to minimize the number of octets required \u00a0  to advertise all UDAs. Doesn't this need more constraints to ensure easy interop (i.e. bits default to 0).\u00a0 Otherwise, it would seem that anyone is allowed to put any value in this field that they like that could harm interop, or otherwise it might be tricky to compare a 4 byte UDABM to an 8 byte UDABM? \u00a0  This document defines the initial set of link attributes that MUST \u00a0  use the ASLA sub-TLV if advertised in the OSPFv2 Extended Link TLV or \u00a0  in the OSPFv3 Router-Link TLV.\u00a0 Documents which define new link \u00a0  attributes MUST state whether the new attributes support application \u00a0  specific values and as such MUST be advertised in an ASLA sub-TLV. \u00a0  The link attributes that MUST be advertised in ASLA sub-TLVs are: I think that I get what this means, but I find the last two sentences slightly jarring given than the ASLA TLV is optional.\u00a0 Perhaps predicate both of these constraints with \"(if supproted)\".\u00a0 E.g., something like,   Documents which define new link  attributes MUST state whether the new attributes support application  specific values and as such MUST be advertised in an ASLA sub-TLV (if supported).  The link attributes that MUST be advertised in ASLA sub-TLVs (if supported) are: Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-06-23 08:58:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-08-26 14:28:55-07:00",
    "text": "There seems to be an internal inconsistency regarding the format of the data payload: at the start of Section 4 we see that \"When present, the data field contains a list of identifiers or assignments in the form <>[=<>],<>[=<>],...\u00a0 where <> is the ASCII name of a system or peer variable specified in  RFC 5905  and <> is expressed as a decimal, hexadecimal or string constant in the syntax of the C programming language\", but later on we see that the Read Status reply \"contains a list of binary-coded pairs <> <>, one for each currently defined association.\u00a0 The \"binary-coded\" (with, apparently, implicit length) seems at odds with the ASCII key/value assignment pairs. The description of the Configure(8) command as \"The command data is parsed and applied as if supplied in the daemon configuration file\" lacks any reference to what that format is or how one might know what format the peer expects.\u00a0 This does not seem sufficiently specified so as to admit interoperable implementation. The description of the Read MRU(10) command also seems underspecified. What name=value pairs affect the selection of records (and how)?\u00a0 Is there a particular name used with name=value pair for the returned nonce, or how is the returned nonce framed?\u00a0 If it's implementation-specific, say so. The only currently specified authentication scheme for these commands appears to be DES-CBC-MAC, from Appendix C of  RFC 1305 .\u00a0 ( RFC 5905 suggests that existing implementations, however, use a different keyed-MD5 scheme that is similarly flawed.)\u00a0 As a CBC-MAC, this mechanism is subject to an extension attack, allowing an attacker to observe an existing valid packet and construct a forged packet with valid MAC by appending additional data at the end.\u00a0 This, therefore, fails to actually provide the key property of authentication.\u00a0 There are additional fundamental issues with the NTP authentication format (independently of the DES-CBC-MAC scheme), which may not quite rise to DISCUSS-level, and accordingly are listed in the COMMENT section.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-22 10:27:22-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-06-23 08:58:12-07:00",
    "text": "[updating version to which ballot position applies, since the -10 does not seem to have addressed the core topics.\u00a0 \u00a0 Furthermore, a 20- or 24-**bit** authenticator will have its own problems to cover, though 20- or 24-**byte** authenticators would be more reasonable.] There seems to be an internal inconsistency regarding the format of the data payload: at the start of Section 4 we see that \"When present, the data field contains a list of identifiers or assignments in the form <>[=<>],<>[=<>],...\u00a0 where <> is the ASCII name of a system or peer variable specified in  RFC 5905  and <> is expressed as a decimal, hexadecimal or string constant in the syntax of the C programming language\", but later on we see that the Read Status reply \"contains a list of binary-coded pairs <> <>, one for each currently defined association.\u00a0 The \"binary-coded\" (with, apparently, implicit length) seems at odds with the ASCII key/value assignment pairs. The description of the Configure(8) command as \"The command data is parsed and applied as if supplied in the daemon configuration file\" lacks any reference to what that format is or how one might know what format the peer expects.\u00a0 This does not seem sufficiently specified so as to admit interoperable implementation. The description of the Read MRU(10) command also seems underspecified. What name=value pairs affect the selection of records (and how)?\u00a0 Is there a particular name used with name=value pair for the returned nonce, or how is the returned nonce framed?\u00a0 If it's implementation-specific, say so. The only currently specified authentication scheme for these commands appears to be DES-CBC-MAC, from Appendix C of  RFC 1305 .\u00a0 ( RFC 5905 suggests that existing implementations, however, use a different keyed-MD5 scheme that is similarly flawed.)\u00a0 As a CBC-MAC, this mechanism is subject to an extension attack, allowing an attacker to observe an existing valid packet and construct a forged packet with valid MAC by appending additional data at the end.\u00a0 This, therefore, fails to actually provide the key property of authentication.\u00a0 There are additional fundamental issues with the NTP authentication format (independently of the DES-CBC-MAC scheme), which may not quite rise to DISCUSS-level, and accordingly are listed in the COMMENT section.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-25 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2022-03-22 10:27:22-07:00",
    "text": "[updating version to which ballot position applies, since the -11 does not seem to have addressed the core topics.\u00a0 \u00a0 Furthermore, a 20- or 24-**bit** authenticator will have its own problems to cover, though 20- or 24-**byte** authenticators would be more reasonable.] There seems to be an internal inconsistency regarding the format of the data payload: at the start of Section 4 we see that \"When present, the data field contains a list of identifiers or assignments in the form <>[=<>],<>[=<>],...\u00a0 where <> is the ASCII name of a system or peer variable specified in  RFC 5905  and <> is expressed as a decimal, hexadecimal or string constant in the syntax of the C programming language\", but later on we see that the Read Status reply \"contains a list of binary-coded pairs <> <>, one for each currently defined association.\u00a0 The \"binary-coded\" (with, apparently, implicit length) seems at odds with the ASCII key/value assignment pairs. The description of the Configure(8) command as \"The command data is parsed and applied as if supplied in the daemon configuration file\" lacks any reference to what that format is or how one might know what format the peer expects.\u00a0 This does not seem sufficiently specified so as to admit interoperable implementation. The description of the Read MRU(10) command also seems underspecified. What name=value pairs affect the selection of records (and how)?\u00a0 Is there a particular name used with name=value pair for the returned nonce, or how is the returned nonce framed?\u00a0 If it's implementation-specific, say so. The only currently specified authentication scheme for these commands appears to be DES-CBC-MAC, from Appendix C of  RFC 1305 .\u00a0 ( RFC 5905 suggests that existing implementations, however, use a different keyed-MD5 scheme that is similarly flawed.)\u00a0 As a CBC-MAC, this mechanism is subject to an extension attack, allowing an attacker to observe an existing valid packet and construct a forged packet with valid MAC by appending additional data at the end.\u00a0 This, therefore, fails to actually provide the key property of authentication.\u00a0 There are additional fundamental issues with the NTP authentication format (independently of the DES-CBC-MAC scheme), which may not quite rise to DISCUSS-level, and accordingly are listed in the COMMENT section.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-12-10 07:55:39-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 12:48:34-07:00",
    "text": "I find myself in agreement with Eric Vyncke's remarks about a document claiming to provide \"current but historic\" protocol details.\u00a0 Is this because NTPv3 is still in use?\u00a0 But the title talks about NTPv4.\u00a0 Shouldn't this document have \"Historic\" status?\u00a0 The shepherd writeup says that's the intent, but that's not what the document's title page says. Let's sort this out.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-04-09 02:00:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 05:29:55-07:00",
    "text": "Section 4.1:  \u00a0  The offerer and answerer MUST NOT include the max-retr or the max- \u00a0  time attribute parameters in the 'dcmap' attribute.  This is just an example of a issue that is exists in basically all of the  RFC 2119  terminolgy using sentences in this section. The formulation is that the offerer or answerer must do something with attributes or parameters of the dcmap attribute. However, it is not stated to be specific to the dcmap attribute that specifically specify something for a T.140 SCTP stream. I think that scope restriction needs to be made more explicit for these  RFC 2119  statements. Else they would have applicability as soon as one support this specification.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-04-09 09:26:00-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-04 18:02:27-07:00",
    "text": "I am confused as to the expected/allowed behavior regarding the cps attribute parameter. In  RFC 4103  Section 6 it says receivers MUST be able to handle temporary bursts over the cps rate but senders MUST stay below the rate. In section 5.3 it says senders \u201ccan\u201d (probably need a 2119 word here) buffer blocks to stay below cps. There is a 500ms limit so this has its limitations. Shouldn\u2019t the buffer time be unbounded if characters are coming in at a rate above cps? Meanwhile in section 4.2.1 it suggests that receivers use sendOnly or inactive (I presume these are the right direction values) to effectively flow control the incoming data. 4566bis seems to only envision this at the start of a channel. What is the impact of pending data if the directionality of the channel changes? How does this interact with the maximum buffer time? I suggest 4.2.1 be clearer on what actions a cps sender and receiver MAY/SHOULD/MUST take, and make sure there aren\u2019t contradictory requirements.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-10-14 22:38:20-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-01 18:16:44-07:00",
    "text": "Perhaps the most minor thing that could be Discuss-level, and should be trivial to resolve, but: The \"i-e\" leaf in groupings prefix-ipv4-std and neighbor does not say whether boolean value true corresponds to internal or external.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-15 14:40:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-10-01 13:28:36-07:00",
    "text": "Section 7.\u00a0 A DISCUSS for discussion.\u00a0 Thanks for this enumeration of writeable and readable nodes which could be considered sensitive.\u00a0 Per the list of nodes that could expose the topology of the network, wouldn\u2019t the following also have sensitive topology information: -- /isis/local-rib -- /isis/hostnames Furthermore, shouldn\u2019t the log files also be protected as the errors or status posted there could also leak topology information: -- /isis/spf-log -- /isis/lsp-log",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-02-02 09:25:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 19:19:44-08:00",
    "text": "Thanks to Wes for his SECDIR review:  https://datatracker.ietf.org/doc/review-ietf-jmap-quotas-07-secdir-lc-hardaker-2022-11-17/ Some of his feedback seems to have already made it into the latest version of the document. I feel the types of quota limits has an interoperability issue ? There are three limits: limit, warnLimit and softLimit. First, it would make sense to rename the confusingly named \"limit\" to hardLimit. I was puzzled about warnLimit not being the same as softLimit. What other things does softLimit do than warn the user? Well, that is explained below this and turns out to be \"whatever the mailserver wants this to be\". This is not good for user expectations, unless they would get a detailed description along with the warning what things will get blocked at the softLimit level, as there is no longer a universal concept of what would happen at the softLimit level. The examples in the document do not seem to use the description field for this required user feedback. So when I get a warning from softLimit from Hotmail, this could cause different limitations from when I get a warning from Gmail. But as far as I can tell, the warning appears identical if the softLimit is hit? Or did I miss where custom text can be given to the enduser for such triggers?",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2017-02-27 11:39:52-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 13:01:52-08:00",
    "text": "olding a DISCUSS pending the outcome of the discussion stemming from the DE's review. See https://www.ietf.org/mail-archive/web/clue/current/msg05066.html",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2017-01-19 07:08:00-08:00",
    "end_reason": "position_updated",
    "start": "2017-01-18 12:47:55-08:00",
    "text": "I plan to ballot \"yes\" for this, but there's an issue in section 9 that I think needs to be fixed first: In the second paragraph, the draft says \"CLUE endpoints MUST support RTP/ SAVPF and DTLS-SRTP keying [ RFC5764 ].\" But the framework draft goes further by saying that media MUST be secured, and that DTLS-SRTP SHOULD be used unless the media is secured by some other mechanism. I think that readers will expect the mapping spec to be authoritative about that sort of thing. It's likely to be misleading to have it mention the requirement to support RTP/SAVPF and DTLS-SRTP without also mentioning the MUST be secured, SHOULD be used requirements. This can easily be fixed by mentioning the additional requirements and citing the framework.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-10-08 07:54:16-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-06 11:21:18-07:00",
    "text": "Thank you for the work on this document. Many thanks to Harald Alvestrand for the ART ART review:  https://datatracker.ietf.org/doc/review-ietf-regext-epp-registry-maintenance-17-artart-lc-alvestrand-2021-09-13/ . I agree with his comments, and thank you to the authors for working with him to fix those points. I will hold a DISCUSS until the update answering the two first comments about \"weak definitions\", the \"formatting issues\" comment, and the date-format comment is published. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-09 17:18:27-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 23:30:01-07:00",
    "text": "It's possible that I just misunderstand what is required to go where, but for several (possibly only CSV?) elements, the body text claims that \"[t]he attribute \"isRequired\" MUST equal \"true\".\" but the corresponding examples do not consistently list the \"isRequired\" attribute. (Sometimes they do, but not always.)\u00a0 Shouldn't the examples be consistent with the protocol requirements?\u00a0 I note some examples in my COMMENT section but this should not be treated as an exhaustive list. A similar property (again, if I understand correctly) holds for the \"parent\" attribute of various elements (which is definitely only a thing for the CSV objects).. The claim in the IANA Considerations regarding \"URI assignments have been registered by the IANA\", accompanied by specific URN namespace/schema values, is codepoint squatting, in the absence of a disclaimer about being \"requested values\".\u00a0 The registration policy is only Specification Required, so there is no formal guarantee that we can actually get these values. At least one of the examples shows RSA/MD5 DNSSEC key records.\u00a0 RSA/MD5 usage is specifically disallowed (see  RFC 6944  and  RFC 8624 ); please replace with a more modern algorithm.\u00a0 (One location noted in the COMMENT, along with some SHA-1 usage that should probably go as well.)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-04-27 05:15:39-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-25 08:53:08-07:00",
    "text": "** Section 1.2. \u00a0  When both vulnerability and software inventory \u00a0  information is available from the same location, both sbom and vuln \u00a0  nodes MUST indicate that. What are \u201csbom and vuln nodes\u201d?\u00a0 Those names don\u2019t map to YANG model described in Section 3.\u00a0 Is this \u201csbom-url\u201d and \u201cvuln-url\u201d?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-02-23 16:34:15-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 15:40:30-08:00",
    "text": "This is probably just my own ignorance, but I see two potential problems in Sec 4.1. - 'The identity of \"ipskx\" as sent on the wire is ImportedIdentity, i.e., the serialized content of ImportedIdentity is used as the\u00a0 content of PskIdentity.identity in the PSK extension.' IIUC ImportedIdentity has a maximum length of 2^17 + 2. But the Identity field in the PSK option has a maximum length of 2^16-1. I presume this never actually happens, but the spec should handle the boundary condition, perhaps by limiting the first two fields of Imported Identity to sum to 2^16-5 bytes or something. - It says 'Endpoints SHOULD generate a compatible \"ipskx\" for each target ciphersuite they offer.' but then the example shows two ciphers that equire only one derived key. Do you mean \"hash algorithm\" instead of \"ciphersuite\"? TLS_AES_128_GCM_SHA256 and TLS_CHACHA20_POLY1305_SHA256 are different ciphersuites according to  RFC 8446 .",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-07 06:08:06-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-06 04:10:44-08:00",
    "text": "Preliminary DISCUSS, I am likely to Defer the document, as I have more detailed comments. Routing decisions, discovery of endpoints to contact for forwarding and retry strategies are listed as out-of-scope for this document. This is not sufficient for writing an interoperable implementation, unless there is a separate document that provides such details.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-10 03:57:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-07 06:08:06-08:00",
    "text": "I am looking forward for this document to be finished and approved as an RFC. Before I can recommend this, I have several DISCUSS points and comments that I would like to address: 1) Routing decisions, discovery of endpoints to contact for forwarding and retry strategies are listed as out-of-scope for this document. This is not sufficient for writing an interoperable implementation, unless there is a separate document that provides such details. Below I describe 3 relevant places in the text and suggest some possible ways of addressing my DISCUSS: 5.4. Bundle Forwarding \u00a0  Step 2: The bundle protocol agent MUST determine whether or not \u00a0  forwarding is contraindicated (that is, rendered inadvisable) for \u00a0  any of the reasons listed in Figure 4. In particular: \u00a0 \u00a0  . The bundle protocol agent MAY choose either to forward the \u00a0 \u00a0 \u00a0 \u00a0 bundle directly to its destination node(s) (if possible) or to \u00a0 \u00a0 \u00a0 \u00a0 forward the bundle to some other node(s) for further \u00a0 \u00a0 \u00a0 \u00a0 forwarding. The manner in which this decision is made may \u00a0 \u00a0 \u00a0 \u00a0 depend on the scheme name in the destination endpoint ID and/or Lack of this information (how node to forward to are discovered) would prevent interoperability. (By comparison, SMTP specification which has somewhat similar design contains information about how next nodes to forward to are selected.) I think you need to create a new section in this document specifying requirements on URI scheme documents and include this as a MUST level requirement there. (If you already have a document that does this, you can just normatively point to it.) \u00a0 \u00a0 \u00a0 \u00a0 on other state but in any case is beyond the scope of this \u00a0 \u00a0 \u00a0 \u00a0 document. If the BPA elects to forward the bundle to some other \u00a0 \u00a0 \u00a0 \u00a0 node(s) for further forwarding but finds it impossible to \u00a0 \u00a0 \u00a0 \u00a0 select any node(s) to forward the bundle to, then forwarding is \u00a0 \u00a0 \u00a0 \u00a0 contraindicated. \u00a0 \u00a0  . Provided the bundle protocol agent succeeded in selecting the \u00a0 \u00a0 \u00a0 \u00a0 node(s) to forward the bundle to, the bundle protocol agent \u00a0 \u00a0 \u00a0 \u00a0 MUST subsequently select the convergence layer adapter(s) whose \u00a0 \u00a0 \u00a0 \u00a0 services will enable the node to send the bundle to those \u00a0 \u00a0 \u00a0 \u00a0 nodes.\u00a0 The manner in which specific appropriate convergence \u00a0 \u00a0 \u00a0 \u00a0 layer adapters are selected is beyond the scope of this \u00a0 \u00a0 \u00a0 \u00a0 document. Similar to the above: lack of description of how convergence layers are discovered (for example this might include discovery using DNS or something else) or, alternatively, a mandatory to implement convergence layer would affect interoperability. I think you need to add this as a requirement to section 7 (\"Services Required of the Convergence Layer\"). Also having some (even non normative) information about which convergence layer to select if multiple are available would be useful. \u00a0 \u00a0 \u00a0 \u00a0 If the agent finds it impossible to select any \u00a0 \u00a0 \u00a0 \u00a0 appropriate convergence layer adapter(s) to use in forwarding \u00a0 \u00a0 \u00a0 \u00a0 this bundle, then forwarding is contraindicated. \u00a0  Step 5: When all selected convergence layer adapters have informed \u00a0  the bundle protocol agent that they have concluded their data \u00a0  sending procedures with regard to this bundle, processing may depend \u00a0  on the results of those procedures.\u00a0 If completion of the data \u00a0  sending procedures by all selected convergence layer adapters has \u00a0  not resulted in successful forwarding of the bundle (an \u00a0  implementation-specific determination that is beyond the scope of \u00a0  this specification), then the bundle protocol agent MAY choose (in \u00a0  an implementation-specific manner, again beyond the scope of this \u00a0  specification) to initiate another attempt to forward the bundle. Similar to the above: retries affect interoperability and should be documented as description of a convergence layer document. I think you need to add this as a requirement to section 7 (\"Services Required of the Convergence Layer\"). \u00a0  In that event, processing proceeds from Step 4 of Section 5.4. 2) As pointed out by Benjamin Schwartz: In Section 5.4.2 Consistency: This section relies on the presence of a Previous Node block, but nothing in the forwarding procedure instructs any agent to add a Previous Node block. Correctness: If two nodes both opt to return failed bundles, how are they to avoid a ping-pong loop? 3) As pointed out by Benjamin Schwartz: In Section 5.6 Error handling: What about CBOR parsing failures?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-02-20 03:29:34-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-10 03:57:49-08:00",
    "text": "I am looking forward for this document to be finished and approved as an RFC. Before I can recommend this, I have several DISCUSS points and comments that I would like to address: 1) Retry strategies are listed as out-of-scope for this document. This is not sufficient for writing an interoperable implementation, unless there is a separate document that provides such details. Below I describe 1 remaining relevant place in the text and suggest some possible ways of addressing my DISCUSS: \u00a0  Step 5: When all selected convergence layer adapters have informed \u00a0  the bundle protocol agent that they have concluded their data \u00a0  sending procedures with regard to this bundle, processing may depend \u00a0  on the results of those procedures.\u00a0 If completion of the data \u00a0  sending procedures by all selected convergence layer adapters has \u00a0  not resulted in successful forwarding of the bundle (an \u00a0  implementation-specific determination that is beyond the scope of \u00a0  this specification), then the bundle protocol agent MAY choose (in \u00a0  an implementation-specific manner, again beyond the scope of this \u00a0  specification) to initiate another attempt to forward the bundle. Similar to the above: retries affect interoperability and should be documented as description of a convergence layer document. I think you need to add this as a requirement to section 7 (\"Services Required of the Convergence Layer\"). \u00a0  In that event, processing proceeds from Step 4 of Section 5.4. [Two other cases were addressed in -23] 2) [Addressed in -23] 3) [Addressed in -23]",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-11-30 10:38:23-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-06 03:04:13-08:00",
    "text": "\u00a710.3/\u00a710.4: \u00a0  The registration policy for this namespace is changed to \"Standards \u00a0  Action\". Given the limited number of bits available, the allocation \u00a0  should only be granted for a standards-track RFC approved by the \u00a0  IESG. The original BP work ( rfc5050 ) is a product of the IRTF.\u00a0 The new registration policy blocks the ability for anyone outside the IETF to register new values.\u00a0 I understand the need to conserve resources, and the intent to Obsolete  rfc5050  in a separate document, which should mean that future work on the BP is done in the IETF.\u00a0 That process hasn't been done yet. I am balloting DISCUSS on this point of the process so that the needed steps can catch up and the group of documents can progress together. [Note that changing the registration policy to allow work from outside the IETF to use the registries would also lead me to clear this DISCUSS.\u00a0 However, I don't think that is necessary.]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-23 18:23:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-05 19:17:07-08:00",
    "text": "I support Roman's Discuss. (1) It's not clear to me that we should be defining new (near-)application-layer protocols on the standards track without mandatory security mechanisms.\u00a0 Even  draft-ietf-dtn-bpsec  defines a \"BPSec threat model\" that is largly the same as the  RFC 3552  threat model, in which the network is completely untrusted and to provide end-to-end communications we must supply additional security mechanisms, yet BPSec is not required to implement or use.\u00a0 I could perhaps see room for allowing waypoint nodes that do not act as endpoints to remain security-unaware, but the justification for security-unaware endpoints seems quite lacking. (2) The state machine for transitions between singleton EID and non-singleton EID seems highly unclear to be usable in a globally synchronized manner (I refer specifically to the text in Section 4.1.5.2: \"A node's membership in a given singleton endpoint MUST be sustained at least until the nominal operation of the Bundle Protocol no longer depends on the identification of that node using that endpoint's ID\").\u00a0 Distinction between singleton-EID and non-singleton EID may need to be made an explicit protocol element. (3) The forwarding procedure in Section 5.4 refers to a \"data label extension block (to be defined in a future document)\" with no reference; it doesn't really seem like this sort of speculative forward-looking statement is appropriate in a Proposed Standard. (4) We discuss using a Previous Node block to \"return a bundle to sender\" when forwarding failed, but do not discuss whether Previous Node should be added (or updated or removed) on transmission, receipt, or both. (5) The extensibility story seems incompletely described: what should an implementation do upon receiving a bundle with an unrecognized control flag bit set, or a block with an unrecognized control flag set? (6) The use of absolute times for creation timestamps suggests a strong dependence on accurate time (for nodes that do not acknowledge their lack of an accurate clock); the consequences of the failure of accurate time should be discussed in the security considerations section. (7) Section 4.1.6 should make a statement regarding whether leap seconds are included or excluded from the count of seconds since the DTN epoch. (8) The definition of Fragment offset needs to specify whether the lowest allowed byte index is zero or 1 (I believe zero, from other discussion). (9) Bundle status reports are only defined to include the creation timestamp of the bundle whose status is being reported on, but not the sequence number thereof.\u00a0 Since we allow nodes without accurate clocks to use a creation timestamp of zero and rely solely on the sequence number to identify bundles, it seems that the status reports for such bundles are effectively useless without the sequence number information. (10) Please resolve the internal inconsistency in Section 10.6 that simultaneously claims that potential bundle protocol URI scheme types are integers of undefined length and only have 255 available codepoints (i.e., definite length).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-30 14:08:31-07:00",
    "end_reason": "position_updated",
    "start": "2020-10-23 18:23:33-07:00",
    "text": "[Retaining (1) as placeholder for ongoing discussions; (11) is new] (1) It's not clear to me that we should be defining new (near-)application-layer protocols on the standards track without mandatory security mechanisms.\u00a0 Even  draft-ietf-dtn-bpsec  defines a \"BPSec threat model\" that is largly the same as the  RFC 3552  threat model, in which the network is completely untrusted and to provide end-to-end communications we must supply additional security mechanisms, yet BPSec is not required to implement or use.\u00a0 I could perhaps see room for allowing waypoint nodes that do not act as endpoints to remain security-unaware, but the justification for security-unaware endpoints seems quite lacking. (11) The ABNF for the \"dtn\" URI scheme does not seem to allow for a URI of \"dtn:none\".\u00a0 We may need to consult the ART ADs to determine how problematic this is, as this is a bit outside my area of expertise.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-04 06:49:15-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-02-06 07:20:16-08:00",
    "text": "olding discuss to ensure IANA is satisfied.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-29 05:34:43-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 06:49:15-08:00",
    "text": "Holding discuss to ensure IANA is satisfied. Taking over Mirja's discuss. There need to be a requirement on all convergence layers to provide congestion control or some other type of rate control.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-10-30 10:13:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-29 05:34:43-07:00",
    "text": "olding discuss to ensure IANA is satisfied, which they are pending 2 minor editorial fixes.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-02-03 03:08:33-08:00",
    "text": "I looked up  RFC 4838  and there is a section on congestion control, however it only says: \"Congestion control is an ongoing research topic.\" Unfortunately this document also doesn't give any further advise about congestion control but as a PS it really should. I understand that the bundle protocol is basically an application layer protocol on top of a transport that should care about congestion control, however, the document doesn't talk much about anything related to that underlying protocol. It would be important to specify requirements for the underlying transport protocol, indicating that is must be congestion controlled or rate limited (see  RFC8085  as a reference for rate limiting of (uni-direction) UDP-based protocols). Further this sentence in Sec 5.1 needs more clarification: \u201cFor this reason, the generation of status reports MUST be \u00a0  disabled by default and enabled only when the risk of excessive \u00a0  network traffic is deemed acceptable.\u201d It is not clear when it makes sense to enable and if enables one should probably also implement some filtering and rate limiting.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-24 11:17:50-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-05 17:00:40-08:00",
    "text": "** Section 4.1.5.1. Can the permissible schemes for the Endpoint ID URL be clarified. Initially the text says: The scheme identified by the < scheme name > in an endpoint ID is a \u00a0  set of syntactic and semantic rules that fully explain how to parse \u00a0  and interpret the SSP. The set of allowable schemes is effectively \u00a0  unlimited. Any scheme conforming to [URIREG] may be used in a bundle \u00a0  protocol endpoint ID. [URIREG] would suggest that any schema in IANA \"Uniform Resource Identifier (URI) Schemes\" Registry\u2019 is valid.\u00a0 However, later, the text says: The first item of the array SHALL be the code number identifying the \u00a0  endpoint's URI scheme [URI], as defined in the registry of URI \u00a0  scheme code numbers for Bundle Protocol maintained by IANA as \u00a0  described in Section 10. [URIREG]. This text suggests that the new Bundle Protocol URI Scheme Type registry should govern the EID schemes.\u00a0 However, then the text again cites URIREG.\u00a0 Perhaps the intent is that URI's valid per [URIREG] would be registered in the new bundle protocol registry and values in this new registry would be used.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-05-10 09:31:36-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-24 16:20:57-07:00",
    "text": "I have a few important items I believe needs fixing, but I believe those are still fairly easy to address. #1 payload format of ENCDNS_DIGEST_INFO I believe the proposed syntax for ENCDNS_DIGEST_INFO in this document should not be specified this way. Depending on the use of this payload, it has a different field construction. That is, we have two different kinds of ENCDNS_DIGEST_INFO, which would make defining this field (eg in C headers or in a class object) impossible without splitting it into two different names and definitions. Either all the fields must be identical, with optional 0 lengths field omitted, or the draft should define ENCDNS_DIGEST_INFO_REQUEST and ENCDNS_DIGEST_INFO_RESPONSE with their different field types. This can be further seen by the difficulty to read the examples in the appendici with the ENCDNS_DIGEST_INFO() syntax. If one ENCDNS_DIGEST_INFO type is used, I think the syntax for both request and response should be:  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-----------------------------+-------------------------------+ |R|\u00a0 \u00a0 \u00a0 \u00a0  Attribute Type\u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Length\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | +-+-----------------------------+---------------+---------------+ | Num Hash Algs |\u00a0 ADN Length\u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | +---------------+---------------+\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  + ~\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Authentication Domain Name\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ~ +-------------------------------+-------------------------------+ | Digest Hash Alg Identifier\u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ~ +-------------------------------+\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  + ~\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Certificate Digest\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ~ +-------------------------------+-------------------------------+ (eg as the current \"response\" version) And Num Hash Algs, ADN Length and Digest Hash Alg Identifier are mandatory fields in both the request and the response. I would also always list these 3 fields in the presentation format of ENCDNS_DIGEST_INFO() as used in the appendici examples. I would rename \"Hash Alg Identifier\" to \"Digest Hash Alg Identifier\" to make it more obvious that is what the hash algorithm is for. #2 Updates  RFC 8598 \u00a0 \u00a0 \u00a0 \u00a0 Note: [ RFC8598 ] requires INTERNAL_IP6_DNS (or INTERNAL_IP4_DNS) \u00a0 \u00a0 \u00a0 \u00a0 attribute to be mandatory present when INTERNAL_DNS_DOMAIN is \u00a0 \u00a0 \u00a0 \u00a0 included. This specification relaxes that constraint This clearly updates  RFC8598 , but the document is lacking an Update: clause. Please add the Update clause and mention the update in the abstract/introduction. #3 Security Considerations \u00a0 \u00a0 \u00a0 \u00a0 The initiator may trust the encrypted DNS resolvers supplied by \u00a0 \u00a0 \u00a0 \u00a0 means of IKEv2 from a trusted responder more than the locally \u00a0 \u00a0 \u00a0 \u00a0 provided DNS resolvers, especially in the case of connecting \u00a0 \u00a0 \u00a0 \u00a0 to unknown or untrusted networks (e.g., coffee shops or hotel \u00a0 \u00a0 \u00a0 \u00a0 networks). This does not seem to be a \"Security Consideration\". Also, before this draft, receiving an (unencrypted) DNS server supplied by IKEv2 would also be more trusted. In general, VPN clients trust the \"VPN provided nameserver\" more than the local network one, irrespective of transport encryption. Perhaps this sentence can just be deleted? #4 Appendix A.2 and A.3 \u00a0 \u00a0 \u00a0 \u00a0 Legacy VPN service providers usually preserve end-users' data \u00a0 \u00a0 \u00a0 \u00a0 confidentiality by sending all communication traffic through an \u00a0 \u00a0 \u00a0 \u00a0 encrypted tunnel. What is \"legacy\" about this? I do not understand the point that A.2 is trying to make?  Similarly, I don't understand Appendix A.3. The VPN service is not involved in \"allowing\" an application to send traffic through the tunnel. It is the VPN client that decided whether or not to send its traffic through the tunnel or not. Also VPNs typically are configured to be either split-tunnel or not. This can be, be hardly ever is, dynamic. I don't understand what A.3 is trying to convey as example use related to the encrypted dns capability of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-04-27 06:54:13-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-27 02:19:22-07:00",
    "text": "Hi, Thanks for this document. This should be a trivial discuss to resolve, and only flagging it as a discuss because I think that it makes the spec unclear (or wrong): (1) p 4, sec 3.1.\u00a0 ENCDNS_IP* Configuration Payload Attributes \u00a0  *\u00a0 IP Address(es) (variable) - Includes one or more IP addresses that \u00a0 \u00a0 \u00a0 can be used to reach the encrypted DNS resolver identified by the \u00a0 \u00a0 \u00a0 Authentication Domain Name.\u00a0 For ENCDNS_IP4 this field contains \u00a0 \u00a0 \u00a0 one or more 4-octet IPv4 addresses, and for ENCDNS_IP6 this field \u00a0 \u00a0 \u00a0 contains one or more 16-octet IPv6 addresses. Shouldn't this be zero or more IP addresses?\u00a0 Otherwise, the example that only contains a domain and no IP address appears to be invalid.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-04-28 05:16:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-26 16:15:02-07:00",
    "text": "Thanks for working on this specification.  I don't have transport related issues on this specification. However, this specification relaxes constrains imposed by  RFC8598  but references it informatively. I think it should reference  RFC8598  as normative reference and also should clearly indicate that in the document header and abstract. I am assuming this is an oversight but want to discuss it.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-16 05:09:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 05:59:44-07:00",
    "text": "I have a few small points (one is confusing enough to warrant a quick discussion), but they affect clarity of the specification: In Section 5: \u00a0  o\u00a0 OTL (3 bits) : Length of OTD field as an unsigned 3-bit integer, \u00a0 \u00a0 \u00a0 encoding the length of the field in hex digits.\u00a0 If OTL == 0, the \u00a0 \u00a0 \u00a0 OTD field is not present.\u00a0 The value of OTL MUST NOT exceed the \u00a0 \u00a0 \u00a0 value of DTL plus one. \u00a0 \u00a0 \u00a0 *\u00a0 For example, DTL = 0b0000 means the deadline time in the 6LoRHE \u00a0 \u00a0 \u00a0 \u00a0  is 1 hex digit (4 bits) long.  Ok, so 0b0000 ==> (0 + 1) * 4, means 4 bits. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 OTL = 0b111 means the \u00a0 \u00a0 \u00a0 \u00a0  origination time is 7 hex digits (28 bits) long. Is my math wrong or is your example wrong? 0b111 == 7. So (7 + 1) * 4 would be 32 bits.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 10:52:15-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:59:16-07:00",
    "text": "The Gen-ART reviewer made the following observation, which I'd like to discuss: There is a serious problem with the last 5 paragraphs of section 8, \"Synchronization Aspects\":\u00a0 they seem to assume that the time representation for the Deadline Time and Origination Time values will wrap around, that is, that the representation is the absolute value modulo the size of the field.\u00a0 In addition, there is a lack of clarity how the new epoch point will be chosen after the value wraps around. This seems to contradict the earlier sections of the document which speak of the values as if they are always to be considered as absolute values on a time scale selected by the TU field, viz., either the NTP time scale (in seconds) or the network's ASN numbering. It's possible that four of these paragraphs are intended to only apply to the use of TU = 00, the NTP time scale, and perhaps that usage of the header is understood not to be completely specified yet. However, the final paragraph discusses TU = 10 (the ASN time scale), and claims that wrapping of the DT value is intended.\u00a0 This is relevant to current implementations. Some sort of resolution of this is needed; as the document stands it is self-inconsistent.\u00a0 One possible resolution would be to omit these paragraphs.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-05-12 06:54:16-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-12 06:53:07-07:00",
    "text": "This should be easy to explain and clear up, bit I have to ask, as I don\u2019t see anything about it in the document: what deters entities from using this with a short deadline time in order to get expedited delivery, when they don\u2019t need it?\u00a0 How does this help a network if, ultimately, every transmission specifies a very short delivery time?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-07-08 19:03:58-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-12 06:54:16-07:00",
    "text": "This should be easy to explain and clear up, but I have to ask, as I don\u2019t see anything about it in the document: what deters entities from using this with a short deadline time in order to get expedited delivery, when they don\u2019t need it?\u00a0 How does this help a network if, ultimately, every transmission specifies a very short deadline time?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2019-09-03 01:11:13-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-13 06:41:03-07:00",
    "text": "The security consideration section have significant short comings as this mechanism enables multiple ways to attack both the packet and the system to my understanding. I would appreaciate your clarifications on these matters.  First of all by changing the dead-line so that it gets dropped because it is already late, alternatively move the deadline time out further in time (later), so that the forwarders may deliver it so late that the receiver considers it to late.  Secondly, there is the question if extensive use of this header will cause overload or affect the scheduling of packet transmission affect other traffic negatively. There appear to exist potential for new ways of bad interflow interactions here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-29 07:00:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-16 06:22:32-07:00",
    "text": "I support Magnus\u2019s DISCUSS #1 (and perhaps we are noting the same thing) The current Security Considerations text needs explicit discussion of the impact of the deadline being manipulated.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-01-17 08:30:22-08:00",
    "end_reason": "position_updated",
    "start": "2023-01-05 03:43:36-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-dmm-srv6-mobile-uplane-23 CC @evyncke Thank you for the work put into this document. I always like the use of innovative technologies. Please find below two blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Sri Gundavelli for the shepherd's detailed write-up including the very descriptive WG consensus ***but*** the justification of the intended status is plain wrong as it is about the original intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Intended status  The shepherd's write-up is about a standard track intended status, but this document text & meta-data say informal. I know the sad history of the intended status as well as that the IETF Last Call was done a 2nd time for 'informational', but I am afraid that the shepherd's write-up must be updated. ### Section 2.2 What is \"gNB\" ? (I know the term, but a reference and definition should be given) Unsure how to parse the bullet list as `SRH[n]: A shorter ` appears in the middle of apparently a single list. Or is it two lists ? Then what is the relationship with the 2nd list ? (possibly just a formatting issue).",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-03-17 18:13:18-07:00",
    "end_reason": "position_updated",
    "start": "2023-01-18 18:46:33-08:00",
    "text": "# Sec AD review of  draft-ietf-acme-subdomains-06 CC @paulwouters Please refer to  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/ for more information about how to handle DISCUSS and COMMENT positions. This review uses the format specified in  https://github.com/mnot/ietf-comments/ which allows automated tools to process items (eg to produce github issues) ## DISCUSS ### Zone bondary implications ``` \u00a0  the ACME client need only fulfill an \u00a0  ownership challenge against an ancestor domain identifier. ``` This document seems to have a \"Public Suffix List\" issue and no Security Considerations to cover this. PSL is mentioned in  RFC 8555 , but limited to the context of wildcards. The draft hints at the server being able to allow or not allow subdomain issuance but provides little guidance.\u00a0 I think at minimum, advise should be given not to allow issuance where it crosses a label that is present in the Public Suffix List (PSL). Additionally, it could say this should not be allowed for the root one or TLD zones, and that care should be taken with Empty Non Terminals (ENS), eg \" co.uk \". Currently, for a TLD to obtain a rogue certificate, it has to take over a child zone by issuing new NS records or issue a (DNSSEC signed) A or AAAA record directly into the child domain abusively crossing the zone cut. These are auditable or rejectable as these DNSSEC keys are not used fo subdomains in normal deployment. With this document, they just need to issue a TXT record into their own zone, which is indistinguishable from a normal operation of a DNSSEC zone key signing its own zone content. So I believe some security guidance here would be useful. ### Post compromise security This document allows an authorization object to be used in the future for additional sub/super domain ACME certificates. This does seem like a new security concern without a matching security consideration. While without this document, abuse could happen for an individual domain, this can now be extended to all domains under or one or more levels above it. An attacker could copy this object and use it at a much later date to issue fraudulent certificates for many subdomains. Related: Is there a way to indicate with ACME that this object should be de-authorized, to gain some post compromise security? I did not see anything listed in the security considerations of  RFC8555 . I did not see any recommendations for the expire: field in  RFC 8555 's Security Considerations Section. ### Wildcards? It is unclear to me how DNS wildcards, eg \"*.nohats.ca\" should be handled? Do they fall within the permissions granted by \"subdomainAuthAllowed\"?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-02-23 14:00:03-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-18 21:38:06-07:00",
    "text": "There are a number of things I\u2019d like to discuss, because I find them not understandable.\u00a0 Perhaps it\u2019s simply because I\u2019m not a codec expert, but, while I understand that this is written for readers who will actually be implementing he FFV1 codec, some of them will also not be \u201cexperts\u201d.\u00a0 That said, I\u2019m sure some of this is just a case of \u201cgive Barry some clue and it\u2019s fine.\u201d \u2014 Section 2.1 \u2014 You use the term \u201csymbol\u201d here and later, without defining it, and I don\u2019t know what it is.\u00a0 A byte?\u00a0 A character?\u00a0 A string of bits?\u00a0 What length? \u2014 Section 3.8.1.1 \u2014 I\u2019m not sure how to interpret the stuff in this section.\u00a0 First, I don\u2019t know why there are seven \u201cfigures\u201d, with no captions nor other explanation.\u00a0 Second, I\u2019m having trouble making sense out of things like this: \u00a0  S_(i + 1, C_(i)) =\u00a0 zero_state_(S_(i, C_(i)))\u00a0 AND \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 l_(i) =\u00a0 L_(i)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 AND \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 t_(i) =\u00a0 R_(i) - r_(i)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <== \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 b_(i) =\u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 <==> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 L_(i) <\u00a0 R_(i) - r_(i) Can you explain how this is meant to be read?\u00a0 Maybe it\u2019s just me, and maybe after you explain it I\u2019ll whack myself on the head and say, \u201cDoh!\u201d Third, you say, \u201cS_(0, i) is the i-th initial state,\u201d but you haven\u2019t previously introduced the term \u201cstate\u201d, and I don\u2019t know what it means. \u2014 Section 3.8.1.2 \u2014 \u00a0  \"get_rac\" returns a boolean, computed from the bytestream as \u00a0  described in Section 3.8.1.1. I see nothing in Section 3.8.1.1 that describes get_rac. \u2014 Section 3.8.1.3 \u2014 \u00a0  At keyframes all Range coder state variables are set to their initial \u00a0  state. What does \u201cat keyframes\u201d mean? \u2014 Section 3.8.1.5 \u2014 This is just a list of numbers with no explanation.\u00a0 It needs text explaining what it means. \u2014 Section 3.8.2.2 \u2014 \u00a0  The level is identical to the predicted one. \u00a0  The run and the first different level are coded. What does \u201clevel\u201d mean?\u00a0 It\u2019s not defined anywhere. \u2014 Section 4.3.1 \u2014 \u00a0  \"reserved_for_future_use\" has semantics that are reserved for future \u00a0  use. Yes, that seems rather obvious, though it\u2019s oddly worded.\u00a0 But then you say what to do with \u201cthis value\u201d, and nowhere do you say what the value is.\u00a0 How does one know?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-12-01 13:59:51-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-07 08:51:26-07:00",
    "text": "A simple clarification. Section 6. \u00a0  Implementations of the FFV1 codec need to take appropriate security \u00a0  considerations into account, as outlined in [ RFC4732 ] RFC4732  only covers DoS.\u00a0 A buffer overflow (as described in the subsequent text of this paragraph) in a codec implementation could have dramatically more significant consequences for the endpoint (or the services it provides) than a DoS.\u00a0 It could potentially lead to arbitrary remote code execution on the system (barring defensive mitigations provided by sandboxing in the app, OS execution protections; and/or end-point protection software) which pretty much enables an attacker to do anything of their choosing on the system.\u00a0 Please note that.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-17 21:26:15-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-09 11:47:44-07:00",
    "text": "As was the case for Murray, I'm unconvinced that I have understood what Section 3 intended to convey.\u00a0 However, I am balloting Discuss because my current best understanding is for a statement that seems inconsistent with my understanding of how the partial response mechanism works.\u00a0 In particular, how would the topmost objects be returned according to different field sets, if there's only a single query parameter and (I assume) all topmost objects are the results of the same single query?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-09-06 11:17:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-05 14:22:20-07:00",
    "text": "Probably I'm just not properly aware of details in the referenced RFCs, but I had a few questions that came to mind. [ section 2 ] * How are multiple keys encoded in a fieldSet parameter value?\u00a0 An example \u00a0 would be welcome. * What should be done with a query containing an empty fieldSet? \u00a0 E.g. ...?...&foo=bar&fieldSet=&baaz=quux [ section 2.1 ] * How much data transfer is actually saved if servers are supposed to send \u00a0 these subsetting_metadata structures in every response?\u00a0 Are we just \u00a0 swapping data bytes transferred for meta-data bytes transfered?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-26 17:59:11-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-07 07:02:49-08:00",
    "text": "We say that we adhere to the guidelines of  RFC 3552 , yet we do not mention that it may be impossible to achieve our goals \"in the face of a highly capable adversary, such as the one envisioned by the Internet Threat Model of  BCP 72  [ RFC3552 ] that can arbitrarily drop or delay any or all traffic\" (to quote from a recent DetNet RFC that does cover this topic,  RFC 8939 ).\u00a0 I think that in order to fully adhere to  RFC 3552 , we need to be more explicit about how we have to assume a reduced attacker capability set in order to make any progress at all.\u00a0 A good place for this discussion would be near where we state that security a DetNet starts with a scrupulously well-designed and well-managed engineered network in Section 1 -- the goal of having the well-managed network is to exclude some of the more powerful adversary capabilities from the Internet Threat Model.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-02-02 02:13:15-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-22 06:11:58-08:00",
    "text": "Section 3.1: \u00a0  A DetNet system security designer relies on the premise that any \u00a0  resources allocated to a resource-reserved (OT-type) flow are \u00a0  inviolable, in other words there is no physical possibility within a \u00a0  DetNet component that resources allocated to a given flow can be \u00a0  compromised by any type of traffic in the network; this includes both \u00a0  malicious traffic as well as inadvertent traffic such as might be \u00a0  produced by a malfunctioning component, for example one made by a \u00a0  different manufacturer. Can we really ensure that a malfunctioning component can't compromise the resources of another one. The most simple example I would have is a router with a malfunction rewriting the destination address or flow label of a packet causing the packet to change the flow it is belonging too, thus if occurring for any significant amount of packets causing overflow in the next hop router when the original and the remarked flow compete for the same resources assigned. The only way to ensure that this happens is to verify a strong header integrity protection at each point a decision on how to forward, classify or remark the flow is done. So Section 3.3 indicate that this is an issue, but only discusses how it can be solved over ethernet. This issue hasn't been well handled in either the MPLS or IP detnet data planes as no additional mechanism was required to ensure this criteria is meet.  So I think the requirement that also malfunctions in equipment don't result in flow violations is hard, and will require that the already approved data plane specification needs additional mechanism that verify all data used on each occasion the data is used. Neither MPLS nor IP as currently specified fulfill this, not even against non-malicious malfunctions or corruption type malfunctions. Then we have those malfunction that breaks the network or where control plane information provided is being corrupted.  I have only looked a bit deeply on one type of malfunction that I know that can occur. I convinced that this document will indicate a number of additional potential ways things can go wrong that can't be determined without additional mechanisms and likely additional per packet fields. Thus, I think we need to discuss if the security properties matches the actual approved data plane, or if the property is so important that the data plane specification is moved back to the WG to be fixed?  I would also recommend that you don't indicate that a different manufacturer can be blamed. Isn't a malfunction going to occur where they occur, it is not like a single vendor network will be without malfunctions due to hardware issue, nor have its set of software bugs.  Section 9.1: \u00a0  The IP protocol has a long history of security considerations and \u00a0  architectural protection mechanisms.\u00a0 From a data plane perspective \u00a0  DetNet does not add or modify any IP header information, so the \u00a0  carriage of DetNet traffic over an IP data plane does not introduce \u00a0  any new security issues that were not there before, apart from those \u00a0  already described in the data-plane-independent threats section \u00a0  Section 5, Security Threats. The above requirement from Section 3.1 in regards to IP header fields used for flow classification are not automatically fulfilled without additional mechanisms. Thus, I would claim that DETNET unless Section 3.1 requirement is minimized will require support for a strong integrity mechanism over all headers. So if this needs to be keyed or not is totally dependent on if malicious modifications of packet headers needs to be taken into account or not.  Section 9.2:  Same as previous issue but for integrity over the MPLS headers.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-02-03 08:00:54-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-06 14:34:41-08:00",
    "text": "** Section 5.1 and Figure 1.\u00a0 Thanks for separating the different kinds of attackers.\u00a0 As it relates to \u201cinternal vs external\u201d where are the details of what DetNet traffic is encrypted or authenticated to create a distinction between internal and external; and to rule out certain attack to external actors per Figure 1? ** I may not fully understand the architecture, but these threats and mitigations didn\u2019t seem to align: --\u00a0 Section 7.1.\u00a0 Per path redundancy being able to mitigate Section 5.2.7 (time sync), which is just reference to  RFC7384 , how does a  RFC8655  style PREOF mitigate a grandmaster time source attack per Section 3.2.10 of  RFC7384 ?\u00a0 Is the intent here that all  RFC7384  attacks are mitigated? -- Section 7.5.\u00a0 \u201cReconnaissance attacks (Section 5.2.6) can be mitigated by using encryption\u201d seems like too strong of a statement.\u00a0 Some traffic analysis should be still be possible. -- Section 7.6.\u00a0 Per \u201cThese mechanisms can be used to mitigate various attacks on the controller plane as described in Section 5.2.5 \u2026\u201d, can it be clarified how these security properties will protect against controller compromise (Section 5.2.5.2).",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-07-25 19:24:49-07:00",
    "end_reason": "position_updated",
    "start": "2021-06-16 13:33:08-07:00",
    "text": "Thank you for this quite masterfully done mammoth undertaking!\u00a0 I expect to ballot Yes pending discussion of one point. I'm looking at the following text in Section 4.3.4 relating to how to handle certificate validation failures for https: \u00a0  If the certificate is not valid for the URI's origin server, a user \u00a0  agent MUST either notify the user (user agents MAY give the user an \u00a0  option to continue with the connection in any case) or terminate the \u00a0  connection with a bad certificate error.\u00a0 [...] Given the discussion up in \u00a73.5 about requirements to \"notify\" the user vs requiring \"confirmation\" from the user, I don't think that just \"MUST notify the user\" is sufficient to prevent the user-agent from continuing, since it is sufficient to just write a log entry as the means to notify the user.\u00a0 Is the intent to require confirmation of the action to continue in the face of such an error (which, again per \u00a73.5 could be a pre-configured confirmation)?\u00a0 An intent to require \"confirmation\" (vs mere \"notification\") seems consistent with the subsequent text placing requirements on automated clients and would be more consistent with my understanding of general IETF consensus for securing protocols",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-19 17:54:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-14 23:54:22-08:00",
    "text": "The volume of my comments notwithstanding, this document was actually quite nice to read.\u00a0 I think that these discuss points, at least, should be fairly straightforward to resolve. (1) In a number of places we have text roughly of the form: \u00a0 \u00a0 String values based on a\u00a0 from   MUST NOT be used, as these values are less concise than \u00a0 \u00a0 their index value equivalent. This seems like it could have some nasty interactions with updates to the IANA registry in question, especially if consumers attempt to enforce the MUST NOT.\u00a0 Consider a version scheme \"foo\", used by an implementation M to emit CoSWID tags.\u00a0 Implementation M is old and predates \"foo\"'s registration, so it uses the text form.\u00a0 Implementation N postdates \"foo\"'s registration and knows to use the integer form for encoding it.\u00a0 But if N insists on the integer form for decoding, it will reject M's tags, and needlessly so.\u00a0 So I think we need a warning that the \"MUST NOT\" is only for encoding, and that decoders MUST accept both forms (at least for names not listed in this document). (2) Section 4.1 contains SHOULD-level guidance to use the \"semver\" version scheme when the value matches the semantic versioning syntax.\u00a0 That seems like it would be highly problematic if the version number only happens to match the syntax by accident and does not actually match the semantic versioning semantics.\u00a0 Shouldn't we be giving recommendations based on the underlying (intended) semantics rather than just the syntax? (A similar concern might apply to the recommendation to use any scheme other than \"alphanumeric\", but there are not really well-known semantics for the \"alphanumeric\" syntax such that expectations of semantics would fail to be met if the wrong version scheme was assigned.) (3) The integer values assigned to link ownership values disagree between Table 5 and the CDDL.\u00a0 (The IANA registry guidance matches Table 5.) I did not attempt to obtain a copy of ISO/IEC 19770-2:2015 to confirm whether it uses integer identifiers that we want to maintain compatibility with -- the prose in \u00a74.3 is a little unclear as to whether such compatibility is relevant since it only talks about \"values\" that are to match. (4) It's quite possible that I'm just confused about one or both of the statements in question, but it seems like there may be some inconsistency between \u00a72.7's \"This specification does not define how to resolve an XPath query in the context of CBOR\" and \u00a75.2's \"This XPath is evaluated over SWID or CoSWID tags found on a system\" (with, IIRC, a couple other relevant mentions elsewhere).\u00a0 My understanding is that a CoSWID tag is intrinsically represented in a CBOR form, so I'm not sure how one could cause an XPath evaluation to match without having defined semantics for evaluating that query in a CBOR context. (5) There are a couple of references to first-come, first-served allocations for SWID index value registrations (e.g., \u00a72's \"new constructs are assigned a unique index value on a first-come, first- served basis\", \u00a76.2.1's \"New index values will be provided on a First Come First Served as defined by [ BCP26 ]\", but I do not see any direction to IANA to create a registry using such an allocation policy for any range of the registry in question.\u00a0 It seems like this indicates some internal inconsistency to be resolved, but I'm not entirely sure what the proper resolution is. (6) Section 6.2.2 attempts to provide a namespaced scheme for distributed allocation of unique (collision-free) names for private-use index values, but I do not think it admits a unique partition into \"domain.prefix\" and \"name\" by treating U+002D HYPHEN-MINUS as a separator, since that character is valid in both LDH hostnames and in NMTOKEN names.\u00a0 This makes it impossible to guarantee uniqueness, since we could have different partitionings of the same consolidated name into the underlying components. (7) We seem to have conflicting statements in \u00a77 about how a signed CoSWID tag is represented.\u00a0 First we say that \"[a] CoSWID tag MUST be wrapped in a COSE Single Signer Data Object (COSE_Sign1) that contains a single signature and MUST be signed by the tag creator\", but just a few paragraphs later we say that \"[t]he COSE_Sign structure that allows for more than one signature to be applied to a CoSWID tag MAY be used\", but following the MAY would violate the MUST.\u00a0 Furthermore(!), the last paragraph of the section says only that \"[a] CoSWID SHOULD be signed, using the above mechanism\", which again is in conflict with the MUST.\u00a0 (Section 8 goes on to admit the possibility of unsigned tags as well as both forms of signed tag, and Section 9 includes \"a signature provided by the supplier if present in the CoSWID tag\".) (8) Table 1 seems to be missing an entry for $$resource-collection-extension, defined in \u00a72.9.2 and appearing in multiple other locations.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-03-21 05:55:01-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 02:28:41-08:00",
    "text": "Hi, Sorry, but I have a couple of issues that it would be helpful to discuss ... 1.\u00a0 While an attempt to align \u00a0  SWID and CoSWID tags has been made here, future revisions of ISO/IEC \u00a0  19770-2:2015 or this specification might cause this implicit \u00a0  information model to diverge, since these specifications are \u00a0  maintained by different standards groups. This text concerns me, in that it seems that the IETF is expecting or allowing the SWID and CoSWID specification to diverge. Would it be possible to have stronger text here? E.g., to indicate:  - the intent is to keep the two spec's consistent.  - nothing should be added to CoSWID without working with ISO/IEC to update CoSWID  - if SWID evolves then CoSWID should be similarly updated. Or, otherwise, are ISO/IEC okay with the IETF effectively forking their specification in future? 2. \u00a0  [SEMVER]\u00a0  Preston-Werner, T., \"Semantic Versioning 2.0.0\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 . I want to check whether this URL is stable enough for a normative reference.\u00a0 During the YANG Semver work we discovered, that despite the Semver specification stating that is follows the Semver rules, in fact it doesn't! Specifically, the specification has been updated without changing the version number.\u00a0 The proposed solution for the YANG semver draft was to reference a specific data and revision of the \"YANG Semver 2.0.0\" specification in github.  the YANG Semver 2.0.0 specification on a given data. \u00a0  [semver]\u00a0  \"Semantic Versioning 2.0.0 (text from June 19, 2020)\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 . Would doing something similar be wise here? Thanks, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-01 11:02:39-07:00",
    "end_reason": "position_updated",
    "start": "2018-08-01 08:52:08-07:00",
    "text": "Section 6.10.4: \"The value of the Interface Identifier is left for future definitions.\" I don't understand how this is usable without some definition. I.e., if I assign every interface ID in my ACP to be 0, it's not going to work. Could you elaborate about what is expected in this field?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-08-12 20:46:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-08-12 08:42:37-07:00",
    "text": "I still have more to review here -- I'm about \u2153 of the way through -- but I wanted to get this in sooner, rather than waiting. This DISCUSS should be easy to resolve: it's mostly that I find the text in Section 6.5 related to Bob and Alice to be confusing and unclear.\u00a0 I see that EKR also found it so and asked for the step-by-step diagram, which does help.\u00a0 But I find the whole Bob/Alice thing to be messy and wish you could instead use some functionally descriptive terms for the roles, rather than using arbitrary names that aren't meaningful and lead the reader to say, \"Wait, which one is Bob now?\" Specifically: \u2014 Section 6.5 \u2014 \u00a0 \u00a0 \u00a0 The node with the \u00a0 \u00a0 \u00a0 lower Node-ID in the ACP address of its ACP certificate becomes \u00a0 \u00a0 \u00a0 Bob, the one with the higher Node-ID in the certificate Alice.\u00a0 A \u00a0 \u00a0 \u00a0 peer with an empty ACP address field in its ACP certificate \u00a0 \u00a0 \u00a0 becomes Bob (this specification does not define such peers, only \u00a0 \u00a0 \u00a0 the interoperability with them). What\u2019s with \u201cbecomes Bob\u201d and \u201cAlice\u201d here?\u00a0 Without any introduction I don\u2019t know what\u2019s going on.\u00a0 Do you mean something like, \u2018One node has a lower Node-ID in the ACP address of its ACP certificate than the other.\u00a0 For this discussion, we will call that node \u201cBob\u201d, and the other \u201cAlice\u201d.\u2019 ?\u00a0 Or do you mean something else?\u00a0 And then what does the next sentence mean? \u00a0  For example, originally Bob could have been the initiator of one ACP \u00a0  secure channel protocol that Bob prefers and the security association \u00a0  succeeded.\u00a0 The roles of Bob and Alice are then assigned and the \u00a0  connection setup is completed. Again I\u2019m confused: you\u2019re talking about Bob doing something, and *then* the role of Bob is assigned?\u00a0 What does that mean?\u00a0 How can we talk about Bob doing something before we know who Bob is? And are there no more descriptive terms to use here, as opposed to \u201cBob\u201d and \u201cAlice\u201d?\u00a0 Something like \u201cinitiator\u201d and \u201cresponder\u201d, or whatever, which might be easier to follow? I also have an easy-to-address issue here: \u2014 Section 6.7.3.1.2 \u2014 \u00a0  The IKEv2 Diffie-Hellman key exchange group 19 (256-bit random ECP), \u00a0  listed as a SHOULD, is to be configured, along with the 2048-bit MODP \u00a0  (group 14). I don\u2019t understand the requirement level here, because I\u2019m not sure what \u201cis to be configured\u201d means.\u00a0 You mention \u201cSHOULD\u201d, but then \u201cis to be configured\u201d seems to say that it has to be supported.\u00a0 And you seem to be saying that he same requirement, whatever it is, applies to both group 19 and group 14... but I\u2019m not certain about that.\u00a0 Can you please rephrase this to make the requirements clearer?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-09-11 08:35:29-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 20:46:02-07:00",
    "text": "This DISCUSS should be easy to resolve: it's mostly that I find the text in Section 6.5 related to Bob and Alice to be confusing and unclear.\u00a0 I see that EKR also found it so and asked for the step-by-step diagram, which does help.\u00a0 But I find the whole Bob/Alice thing to be messy and wish you could instead use some functionally descriptive terms for the roles, rather than using arbitrary names that aren't meaningful and lead the reader to say, \"Wait, which one is Bob now?\" Specifically: \u2014 Section 6.5 \u2014 \u00a0 \u00a0 \u00a0 The node with the \u00a0 \u00a0 \u00a0 lower Node-ID in the ACP address of its ACP certificate becomes \u00a0 \u00a0 \u00a0 Bob, the one with the higher Node-ID in the certificate Alice.\u00a0 A \u00a0 \u00a0 \u00a0 peer with an empty ACP address field in its ACP certificate \u00a0 \u00a0 \u00a0 becomes Bob (this specification does not define such peers, only \u00a0 \u00a0 \u00a0 the interoperability with them). What\u2019s with \u201cbecomes Bob\u201d and \u201cAlice\u201d here?\u00a0 Without any introduction I don\u2019t know what\u2019s going on.\u00a0 Do you mean something like, \u2018One node has a lower Node-ID in the ACP address of its ACP certificate than the other.\u00a0 For this discussion, we will call that node \u201cBob\u201d, and the other \u201cAlice\u201d.\u2019 ?\u00a0 Or do you mean something else?\u00a0 And then what does the next sentence mean? \u00a0  For example, originally Bob could have been the initiator of one ACP \u00a0  secure channel protocol that Bob prefers and the security association \u00a0  succeeded.\u00a0 The roles of Bob and Alice are then assigned and the \u00a0  connection setup is completed. Again I\u2019m confused: you\u2019re talking about Bob doing something, and *then* the role of Bob is assigned?\u00a0 What does that mean?\u00a0 How can we talk about Bob doing something before we know who Bob is? And are there no more descriptive terms to use here, as opposed to \u201cBob\u201d and \u201cAlice\u201d?\u00a0 Something like \u201cinitiator\u201d and \u201cresponder\u201d, or whatever, which might be easier to follow? I also have a few easy-to-address issues here: \u2014 Section 6.7.3.1.2 \u2014 \u00a0  The IKEv2 Diffie-Hellman key exchange group 19 (256-bit random ECP), \u00a0  listed as a SHOULD, is to be configured, along with the 2048-bit MODP \u00a0  (group 14). I don\u2019t understand the requirement level here, because I\u2019m not sure what \u201cis to be configured\u201d means.\u00a0 You mention \u201cSHOULD\u201d, but then \u201cis to be configured\u201d seems to say that it has to be supported.\u00a0 And you seem to be saying that he same requirement, whatever it is, applies to both group 19 and group 14... but I\u2019m not certain about that.\u00a0 Can you please rephrase this to make the requirements clearer? \u2014 Section 6.7.5 \u2014 \u00a0  A baseline ACP node MUST support IPsec natively and MAY support IPsec \u00a0  via GRE.\u00a0 If GRE is supported, it MAY be preferred over native IPec. But Section 6.7.3.2 says: \u00a0  If IKEv2 initiator and responder support IPsec over GRE, it has to be \u00a0  preferred over native IPsec. Which is it?\u00a0 \u201cMAY\u201d be preferred?\u00a0 Or \u201chas to be preferred\u201d? \u2014 Section 6.10.6 \u2014 \u00a0  IANA is asked need to assign a new \"type\" for each new addressing \u00a0  sub-scheme.\u00a0 With the current allocations, only 2 more schemes are \u00a0  possible, so the last addressing scheme MUST provide further \u00a0  extensions (e.g., by reserving bits from it for further extensions). I don\u2019t understand the first sentence.\u00a0 It doesn\u2019t parse, for one thing, so please fix that.\u00a0 And it would be better to clearly match it with the corresponding request in the IANA Considerations section. For the second sentence (the DISCUSS part), I\u2019m very skeptical that this is the right approach: if you\u2019re already acknowledging that \u201conly\u201d 2 schemes are possible now, it seems time *now* to prepare the way for additional ones, rather than waiting.\u00a0 What\u2019s the reasoning for putting in a warning rather than just doing it, especially as you\u2019re setting up a new registry anyway?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-16 15:42:01-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-08-01 17:29:51-07:00",
    "text": "This is a really exciting protocol to read about -- the prospect of dropping a bunch of just-manufactured devices in place, spinning up a registrar (and maybe a MASA), and getting a control plane like magic is pretty impressive.\u00a0 That said, I don't believe that this document is ready to publish as-is.\u00a0 I have a list of specific points below for discussion, but it may be more effective to strip down the document a lot (providing a well-defined core protocol and leaving out speculative future work, along the lines of Alissa's comments) and only then start to work on specific rough spots. In particular, in its current form, it's not clear to me why this document is targeting the standards-track -- there are lots of places where determinations of what works best or how to do some things is left for future work.\u00a0 Are there lots of implementations or consumers clamoring for this stuff that it makes sense to go for PS as opposed to Experimental (so as to figure out what works and nail down a slimmer protocol for the standards track)?\u00a0 I see in A.4 that the choice of RPL was motivated by experience with a pre-standard version of ACP; it would have been great to hear more about those deployments in an Implementation Status section (per RFC 7942 ) or the Shepherd writeup. I also think the document needs to be more clear about what security properties it does or does not intend to provide: we hear in the abstract and introduction that ACP will be \"secure\" (and similar platitudes are repeated throughout), but we don't really get a sense of the specifics until Section 4, with ACP5.\u00a0 This has a MUST for authenticated and \"SHOULD (very strong SHOULD)\" be encrypted.\u00a0 But text elsewhere in the document seems to be using \"secure\" to also mean encrypted, and there is even one place that flatly asserts that \"ACP mandates the use of encryption\".\u00a0 This internal inconsistency needs to be resolved, at a minimum, and ideally the intended posture more clearly conveyed.\u00a0 (It's also not really stated under what cases encryption would not be used, so that the \"very strong SHOULD\" could not be a MUST.) Section 3.2 claims that the ACP provides \"additional security\" for bootstrap mechanisms due to the hop-by-hop encryption.\u00a0 But in what sense is actual additional security gained?\u00a0 Against an attacker with what capabilities?\u00a0 If there is security gain from such hop-by-hop encryption, doesn't that point to a weakness in the bootstrap scheme? I think there needs to be some justification of why rfc822Name is chosen over a more conventional structure in the otherName portion of the subjectAltName, which is explicitly designed to be extensible. The requirement in Section 6.1.2 for CRL and OCSP checks seem impossible to satisfy for a greenfield node without non-ACP connectivity, as it must join the ACP domain (and supposedly validate the CRL and OCSP validity before doing so) before establishing an ACP link with its peer, but cannot validate anything with no connectivity. Throughout, the document seems to implicitly conflate authentication with authorization.\u00a0 I understand that the main authorization check is just the domain membership test in Section 6.1.2; nonetheless, as a pedagogical matter I cannot support propagating their conflation. In a few places, the MTI cryptographic mechanisms are under-specified, whether the cipher mode for IKE or the TLS ciphersuites.\u00a0 I have attempted to note these locations in my section-by-section comments. Section 6.11.1.14 places a normative (\"SHOULD\") requirement on the RPL root, but if I understand correctly the RPL root is automatically determined within the ACP, and thus the operator does not a priori know which node will become the RPL root.\u00a0 Am I misunderstanding, or is this effectively placing this requirement on all ACP nodes? The IANA considerations specifically do register SRV.est in the GRASP Objective Names Table, and then follows up with a paragraph that this is only a \"proposed update\".\u00a0 I don't know if there's actually anything problematic here, but the document does need clarity on what is proposed for future work and what is to be done now.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-22 08:50:22-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-16 15:42:01-07:00",
    "text": "[trimming to just the topics still under discussion; no change to the text of the remaining items even though some changes have been made to the document] I think there needs to be some justification of why rfc822Name is chosen over a more conventional structure in the otherName portion of the subjectAltName, which is explicitly designed to be extensible. In a few places, the MTI cryptographic mechanisms are under-specified, whether the cipher mode for IKE or the TLS ciphersuites.\u00a0 I have attempted to note these locations in my section-by-section comments. Section 6.11.1.14 places a normative (\"SHOULD\") requirement on the RPL root, but if I understand correctly the RPL root is automatically determined within the ACP, and thus the operator does not a priori know which node will become the RPL root.\u00a0 Am I misunderstanding, or is this effectively placing this requirement on all ACP nodes?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-01 15:36:19-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 16:46:20-07:00",
    "text": "Hopefully just a couple easy ones... I made a pass over Ekr's ballot comments (nominally on the -16, though some of the quoted text doesn't seem to match up with that version). We're generally in good shape there, but I wanted to check on the point regarding a \"downgrade defense on the meta-negotiation between the protocols\", which in theory would allow an attacker to force the use of IPsec or DTLS or whatever other protocol has a weakness.\u00a0 It seems like there may have been some confusion about DULL vs ACP GRASP in play here, especially with respect to when there might be the possibility of multiple secure channels.\u00a0 My current understanding is that there is not a major issue here, but let's confirm that: DULL GRASP runs only over a local link (using link-local addresses), and as currently defined has the option of flooding advertisements that use either DTLS or IKEv2 to establish the ACP secure channel.\u00a0 DULL GRASP has no cryptographic protections at all, so if there is somehow (e.g., on a multi-access link) an attacker on the link, they could drop or rewrite some announcements to force either DTLS or IKEv2 to be used for secure channel establishment even if the other would normally have been preferred.\u00a0 On directly-connected wired links, such tampering may be unlikely (but not beyond the capabilities of, e.g., a nation-state or well-funded attacker, especially for, e.g., long fiber runs.)\u00a0 By itself, this is not useful, since both DTLS and IKEv2+ESP are believed to be secure, but if some future vulnerability is discovered the downgrade might allow for the vulnerability to be exploited in cases it would not otherwise have been usable.\u00a0 Countermeasures to allow detection of this kind of tampering are possible -- include as part of the DTLS or IKEv2 exchange (or the first operation after it) a preference-ordered list of supported secure channel mechanisms, and bail out if the mechanism being used is not the most-preferred shared mechanism -- but will still fail if the vulnerability in question is sufficiently severe to allow handshake forgery. ACP GRASP is different, in that it (1) runs over the ACP, so any on-path attack to drop/rewrite GRASP would have as a prerequisite an attacker in the ACP, and (2) unicast GRASP is protected end-to-end by TLS.\u00a0 However, it seems like broadcast/flooded ACP GRASP objectives will only have the hop-by-hop ACP protection and so would in theory also be subject to a downgrade attack if there was an in-ACP on-path attacker.\u00a0 It also seems like there's a general expectation that ACP services will run over TLS, and the option of \"TLS *or* DTLS (or something else)\" is not expected to be common, so the existence of a downgrade to a different protocol is rare as well. While I would like to be able to defend against downgrade attacks by an in-ACP on-path attacker, I recognize that it's a defensible position to take that we assume all entities in the ACP to remain secure and just accept the corresponding risks in the case of compromise.\u00a0 Similarly, for \"big iron\" router deployments, physical links are the norm and the DULL GRASP downgrade attack may not be a practical concern; I would again like to have the mechanisms in place to be able to detect downgrade if, for example, deployments broaden to the use of radio technologies, but the absence of such a mechanism does not seem like a critical flaw at this time.\u00a0 So, to be clear, the DISCUSS here is just to be sure that we're all on the same page as to what point Ekr was making and the current state of affairs; given my current understanding, I'm not holding a DISCUSS point for \"add the downgrade-detection mechanism\" (though I do encourage it). It looks like Section 6.1.3 is missing a \"rule 6: verify that the acp-address/prefix in the certificate matches the address being used to talk to the peer\", if I'm reading between the lines properly.\u00a0 (If not, and this is just skew introduced by editing, my comments about references to a non-existent rule 6 apply, see COMMENT.)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-08-01 16:56:34-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D9959 I found this document extremely hard to follow due to a large number of grammar errors. It really needs a very thorough copy-edit pass, which I believe is beyond the RFC-editor's usual process. Ideally, the WG would do this. DETAIL S 6.1.1. >\u00a0 \u00a0 \u00a0 each other.\u00a0 See Section 6.1.2.\u00a0 Acp-domain-name SHOULD be the FQDN >\u00a0 \u00a0 \u00a0 of a DNS domain owned by the operator assigning the certificate. >\u00a0 \u00a0 \u00a0 This is a simple method to ensure that the domain is globally unique >\u00a0 \u00a0 \u00a0 and collision of ACP addresses would therefore only happen due to ULA >\u00a0 \u00a0 \u00a0 hash collisions.\u00a0 If the operator does not own any FQDN, it should >\u00a0 \u00a0 \u00a0 choose a string (in FQDN format) that intends to be equally unique. These rules do not seem to be strong enough. Unless you have disjoint trust anchors, there is a potential for cross-domain attac. S 6.1.2. >\u00a0 \u00a0 \u00a0 See section 4.2.1.6 of [ RFC5280 ] for details on the subjectAltName >\u00a0 \u00a0 \u00a0 field. >\u00a0   >\u00a0  6.1.2.\u00a0 ACP domain membership check >\u00a0   >\u00a0 \u00a0 \u00a0 The following points constitute the ACP domain membership check of a What is the relationship of these rules to the existing 5280 rules? S 6.1.2. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 The peer has proved ownership of the private key associated with >\u00a0 \u00a0 \u00a0 \u00a0  the certifictes public key. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 The peer's certificate is signed by one of the trust anchors >\u00a0 \u00a0 \u00a0 \u00a0  associated with the ACP domain certificate. So you don't allow chaining? It seems later that you say you do, but this language prohibits it. S 6.1.3.1. >\u00a0 \u00a0 \u00a0 The objective value \"SRV.est\" indicates that the objective is an >\u00a0 \u00a0 \u00a0 [ RFC7030 ] compliant EST server because \"est\" is an [ RFC6335 ] >\u00a0 \u00a0 \u00a0 registered service name for [ RFC7030 ].\u00a0 Future backward compatible >\u00a0 \u00a0 \u00a0 extensions/alternatives to [ RFC7030 ] may be indicated through >\u00a0 \u00a0 \u00a0 objective-value.\u00a0 Future non-backward compatible certificate renewal >\u00a0 \u00a0 \u00a0 options must use a different objective-name. EST runs over HTTPS. What is the certificate that the server presents? S 6.4. >\u00a0 \u00a0 \u00a0 information in the ACP Adjacency table. >\u00a0   >\u00a0 \u00a0 \u00a0 The ACP is by default established exclusively between nodes in the >\u00a0 \u00a0 \u00a0 same domain.\u00a0 This includes all routing subdomains.\u00a0 Appendix A.7 >\u00a0 \u00a0 \u00a0 explains how ACP connections across multiple routing subdomains are >\u00a0 \u00a0 \u00a0 special. I must be missing something, but how do you know what the routing domain is of an ACP node? I don't see it in the message above. Is it in some common header? S 6.5. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 Once the first secure channel protocol succeeds, the two peers >\u00a0 \u00a0 \u00a0 \u00a0  know each other's certificates because they must be used by all >\u00a0 \u00a0 \u00a0 \u00a0  secure channel protocols for mutual authentication.\u00a0 The node with >\u00a0 \u00a0 \u00a0 \u00a0  the lower Node-ID in the ACP address becomes Bob, the one with the >\u00a0 \u00a0 \u00a0 \u00a0  higher Node-ID in the certificate Alice. A ladder diagram would really help me here, because I'm confused about the order of events. As I understand it, Alice and Bob are both flooding their AN_ACP objectives. So, Alice sees Bob's and starts trying to connect to Bob. But Bob may not have Alice's objective, right? So, in the case you describe below, she just has to wait for it before she can try the remaining security protocols? I note that you have no downgrade defense on the meta-negotiation between the protocols, so an attacker could potentially force you down to the weakest joint protocol. Why did you not provide a defense here? S 6.7.1.1. >\u00a0 \u00a0 \u00a0 To run ACP via IPsec natively, no further IANA assignments/ >\u00a0 \u00a0 \u00a0 definitions are required.\u00a0 An ACP node that is supporting native >\u00a0 \u00a0 \u00a0 IPsec MUST use IPsec security setup via IKEv2, tunnel mode, local and >\u00a0 \u00a0 \u00a0 peer link-local IPv6 addresses used for encapsulation.\u00a0 It MUST then >\u00a0 \u00a0 \u00a0 support ESP with AES256 for encryption and SHA256 hash and MUST NOT >\u00a0 \u00a0 \u00a0 permit weaker crypto options. This is not sufficient to guarantee interop. Also, this is an odd cipher suite chioice. \u00a0 \u00a0 Why are you requiring AES-256 rather than AES-128? \u00a0 \u00a0 Why aren't you requiring AES-GCM? \u00a0 \u00a0 Why aren't you requiring specific key establishment methods (e.g., ECDHE with P-256...) S 6.7.2. >\u00a0   >\u00a0 \u00a0 \u00a0 To run ACP via UDP and DTLS v1.2 [ RFC6347 ] a locally assigned UDP >\u00a0 \u00a0 \u00a0 port is used that is announced as a parameter in the GRASP AN_ACP >\u00a0 \u00a0 \u00a0 objective to candidate neighbors.\u00a0 All ACP nodes supporting DTLS as a >\u00a0 \u00a0 \u00a0 secure channel protocol MUST support AES256 encryption and MUST NOT >\u00a0 \u00a0 \u00a0 permit weaker crypto options. This is not sufficiently specific to guarantee interoperability. Which cipher suites? Also, why are you requiring AES-256 and not AES-128? S 6.7.3. >\u00a0   >\u00a0 \u00a0 \u00a0 A baseline ACP node MUST support IPsec natively and MAY support IPsec >\u00a0 \u00a0 \u00a0 via GRE.\u00a0 A constrained ACP node that can not support IPsec MUST >\u00a0 \u00a0 \u00a0 support DTLS.\u00a0 An ACP node connecting an area of constrained ACP >\u00a0 \u00a0 \u00a0 nodes with an area of baseline ACP nodes MUST therefore support IPsec >\u00a0 \u00a0 \u00a0 and DTLS and supports threefore the baseline and constrained profile. These MTIs do not provide interop between constrained and baseline nodes, because a baseline node might do IPsec and the constrained node DTLS. S 6.10.2. >\u00a0 \u00a0 \u00a0 \u00a0  hash of the routing subdomain SHOULD NOT be assumed by any ACP >\u00a0 \u00a0 \u00a0 \u00a0  node during normal operations.\u00a0 The hash function is only executed >\u00a0 \u00a0 \u00a0 \u00a0  during the creation of the certificate.\u00a0 If BRSKI is used then the >\u00a0 \u00a0 \u00a0 \u00a0  BRSKI registrar will create the domain information field in >\u00a0 \u00a0 \u00a0 \u00a0  response to the EST Certificate Signing Request (CSR) Attribute >\u00a0 \u00a0 \u00a0 \u00a0  Request message by the pledge. you need to lay out the security assumptions here. It's not difficult to create a new domain with the same 40bit hash. If you have a private CA, this probably isn't an issue, but if you are sharing a public CA, it would allow me to produce a domain with other people's addresses. S 8.1.1. >\u00a0 \u00a0 \u00a0 configured to be put into the ACP VRF.\u00a0 The ACP is then accessible to >\u00a0 \u00a0 \u00a0 other (NOC) systems on such an interface without those systems having >\u00a0 \u00a0 \u00a0 to support any ACP discovery or ACP channel setup.\u00a0 This is also >\u00a0 \u00a0 \u00a0 called \"native\" access to the ACP because to those (NOC) systems the >\u00a0 \u00a0 \u00a0 interface looks like a normal network interface (without any >\u00a0 \u00a0 \u00a0 encryption/novel-signaling). This seems pretty unclear. Is the idea that you connect natively to the ACP Connect node and then it forwards your packets over the ACP? Does that mean they need to be GRASP or whatever? I think that's what you are saying below. S 8.1.5. >\u00a0 \u00a0 \u00a0 interface is physically protected from attacks and that the connected >\u00a0 \u00a0 \u00a0 Software or NMS Hosts are equally trusted as that on other ACP nodes. >\u00a0 \u00a0 \u00a0 ACP edge nodes SHOULD have options to filter GRASP messages in and >\u00a0 \u00a0 \u00a0 out of ACP connect interfaces (permit/deny) and MAY have more fine- >\u00a0 \u00a0 \u00a0 grained filtering (e.g., based on IPv6 address of originator or >\u00a0 \u00a0 \u00a0 objective). Given that this is an important security requirement, it seems like it should be a normative requirement that it be filtered. S 9.1. >\u00a0 \u00a0 \u00a0 same trust anchor, a re-merge will be smooth. >\u00a0   >\u00a0 \u00a0 \u00a0 Merging two networks with different trust anchors requires the trust >\u00a0 \u00a0 \u00a0 anchors to mutually trust each other (for example, by cross-signing). >\u00a0 \u00a0 \u00a0 As long as the domain names are different, the addressing will not >\u00a0 \u00a0 \u00a0 overlap (see Section 6.10). Why does it require the *trust anchors* to trust each other? Can't the endpoints just have the union of the trust anchors. This is way underspecified for actual implementation. S 10.2.1. >\u00a0 \u00a0 \u00a0 registrar can rely on the ACP and use Proxies to reach the candidate >\u00a0 \u00a0 \u00a0 ACP node, therefore allowing minimum pre-existing (auto-)configured >\u00a0 \u00a0 \u00a0 network services on the candidate ACP node.\u00a0 BRSKI defines the BRSKI >\u00a0 \u00a0 \u00a0 proxy, a design that can be adopted for various protocols that >\u00a0 \u00a0 \u00a0 Pledges/candidate ACP nodes could want to use, for example BRSKI over >\u00a0 \u00a0 \u00a0 CoAP (Constrained Application Protocol), or proxying of Netconf. I am finding it very difficult to work out the security properties of this mechanism and the security considerations do not help. What can a malicious registrar do? For that matter, you say \"uncoordinated\", so does that mean anyone in the ACP can just decide to be a registrar? S 11. >\u00a0   >\u00a0  11.\u00a0 Security Considerations >\u00a0   >\u00a0 \u00a0 \u00a0 An ACP is self-protecting and there is no need to apply configuration >\u00a0 \u00a0 \u00a0 to make it secure.\u00a0 Its security therefore does not depend on >\u00a0 \u00a0 \u00a0 configuration. This is not true. You need to configure the trust anchor and the domain name. S 11. >\u00a0 \u00a0 \u00a0 \u00a0  all products. >\u00a0   >\u00a0 \u00a0 \u00a0 There is no prevention of source-address spoofing inside the ACP. >\u00a0 \u00a0 \u00a0 This implies that if an attacker gains access to the ACP, it can >\u00a0 \u00a0 \u00a0 spoof all addresses inside the ACP and fake messages from any other >\u00a0 \u00a0 \u00a0 node. You need to be clear that the security is just group security and that any compromised ACP node compromises the entire system.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-10-07 17:07:09-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-13 01:19:01-07:00",
    "text": "[ section 2 ] * \"It is the approximate IPv6 counterpart of the IPv4 private address \u00a0 ([ RFC1918 ]).\" \u00a0 I understand the intent but I don't think this statement is complete. I \u00a0 think we shouldn't let this sentence out into the wild as is since it could \u00a0 be read without any context nor even any pretense of interest in nuance. \u00a0 May I suggest: \u00a0 \"It is often thought of as the approximate IPv6 counterpart of the IPv4 \u00a0 private address space ([ RFC1918 ]), though it is in fact meaningfully \u00a0 different in important and subtle ways [and upon which this document relies].\" [ section 6.10.2 ] * Please clarify the table at the end of this section.\u00a0 It looks like only \u00a0 two Types are listed, but should all 4 bit values be present?\u00a0 Where are the \u00a0 Z, F, and V bits in the address? \u00a0 I realize these are defined in the following sections, so it probably \u00a0 suffices to say something like \"The Z, F, and V bits are allocated from \u00a0 within the sub-scheme portion of the address according to the following \u00a0 sections...\" or something. \u00a0 Unassigned/unused Type values should maybe be listed in the table as \u00a0 \"Reserved\"? [ section 8.1.3 ] * Why is an RIO for ::/0 with a lifetime of 0 required?\u00a0 Doesn't it suffice \u00a0 it set the default router lifetime to 0?\u00a0 Separately, are all nodes required \u00a0 to be Type C?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-14 20:02:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 20:01:33-07:00",
    "text": "** As normative behavior is specific for BRSKI (e.g., Section 6.1.5 and 6.1.5.5), please make it a normative reference ** Figure 2\u2019s definition of acp-address is \u2018acp-address = 32HEXLC | \"0\"\u2019.\u00a0 The following text references a 32HEXDIG but that isn\u2019t in the definition of acp-address. -- Section 6.1.2.\u00a0 \u2018Nodes complying with this specification MUST be able to receive their ACP address through the domain certificate, in which case their own ACP domain certificate MUST have the 32HEXDIG \"acp-address\" field.\u2019 -- Section 6.1.3.\u00a0 \u2018The candidate peer certificate's acp-node-name has a non-empty acp-address field (either 32HEXDIG or 0, according to Figure 2).\u2019 ** Precision in bounding the cipher selection.  -- Section 6.7.2.\u00a0 Per \u201cSymmetric encryption for the transmission of secure channel data MUST use encryption schemes considered to be security wise equal to or better than AES256\u201d, which property of AES-256 is being considered for this assessment? -- Section 6.8.2.\u00a0 Per \u201cTLS for GRASP MUST offer TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 and TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 and MUST NOT offer options with less than 256bit AES or less than SHA384\u201d, please state this more precisely. -- Is it that AES-128 shouldn\u2019t be used or that that AES-256 has a certain key strength to which to adhere to? -- Is it that SHA-224 or SHA256 shouldn\u2019t be used (staying in the SHA-2 family) or is it a certain number of bits of security ? ** The text specifies the need for physical controls.\u00a0 Please be more specific on the appropriate degree of that physical control or how that decision should be made; and explicitly explain threat of concern. -- Section 8.1.1.\u00a0 \u201cThus, the ACP connect interface and NOC systems connected to it needs to be physically controlled/secured.\u201d -- Section 8.1.5.\u00a0 \u201c\u2026 the ACP connect link and the nodes connecting to it must be in a contiguous secure\u00a0  environment, hence assuming there can be no physical attack against the devices.\u201d ** (\u201cdiscuss discuss\u201d) Section 8.1.2.\u00a0 What is the normative behavior being specified in this section?\u00a0 Specifically, what is the additional or more restrictive behavior for the circumstance is where an ACP node is virtualized. ** Section 8.2.1.\u00a0 (I\u2019m no ABNF expert \u2026) Per the ABNF in Figure 17, the \u201c//=\u201d notation isn\u2019t valid.\u00a0 I think you want: OLD \u00a0 \u00a0  method //= [ \"DTLS\",\u00a0 \u00a0 port ] NEW \u00a0 \u00a0  method =/ [ \"DTLS\",\u00a0 \u00a0 port ] ** Section 10.2.1.\u00a0 Per \u201cAn attacker will not be able to join the ACP unless having a valid domain certificate, also packet injection and sniffing traffic will not be possible due to the security provided by the encryption protocol.\u201d, please be clearer: -- on path attacker = no packet injection -- on path attacker = only traffic analysis when sniffing -- compromised node = can inject traffic ** Section 11.\u00a0 Per \u201can ACP is self-protecting and there is no need to apply configuration to make it secure\u201d, if this assertion is going to be made: -- please specify the security services/properties in a normative section (not in the informative text in Section 10). -- please also be clear on what configuration is being referenced. ** Section 11.\u00a0 Per the list of factors on which ACP depends, it seems like the following are missing: -- the security properties of the enrollment protocol  -- that the security considerations of EST and BRSKI apply (or if not, why not)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-08-10 18:29:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-14 20:02:50-07:00",
    "text": "** As normative behavior is specific for BRSKI (e.g., Section 6.1.5 and 6.1.5.5), please make it a normative reference ** Figure 2\u2019s definition of acp-address is \u2018acp-address = 32HEXLC | \"0\"\u2019.\u00a0 The following text references a 32HEXDIG but that isn\u2019t in the definition of acp-address. -- Section 6.1.2.\u00a0 \u2018Nodes complying with this specification MUST be able to receive their ACP address through the domain certificate, in which case their own ACP domain certificate MUST have the 32HEXDIG \"acp-address\" field.\u2019 -- Section 6.1.3.\u00a0 \u2018The candidate peer certificate's acp-node-name has a non-empty acp-address field (either 32HEXDIG or 0, according to Figure 2).\u2019 ** Precision in bounding the cipher selection.  -- Section 6.7.2.\u00a0 Per \u201cSymmetric encryption for the transmission of secure channel data MUST use encryption schemes considered to be security wise equal to or better than AES256\u201d, which property of AES-256 is being considered for this assessment? -- Section 6.8.2.\u00a0 Per \u201cTLS for GRASP MUST offer TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 and TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 and MUST NOT offer options with less than 256bit AES or less than SHA384\u201d, please state this more precisely. -- Is it that AES-128 shouldn\u2019t be used or that that AES-256 has a certain key strength to which to adhere to? -- Is it that SHA-224 or SHA256 shouldn\u2019t be used (staying in the SHA-2 family) or is it a certain number of bits of security ? ** The text specifies the need for physical controls.\u00a0 Please be more specific on the appropriate degree of that physical control or how that decision should be made; and explicitly explain threat of concern. -- Section 8.1.1.\u00a0 \u201cThus, the ACP connect interface and NOC systems connected to it needs to be physically controlled/secured.\u201d -- Section 8.1.5.\u00a0 \u201c\u2026 the ACP connect link and the nodes connecting to it must be in a contiguous secure\u00a0  environment, hence assuming there can be no physical attack against the devices.\u201d ** (\u201cdiscuss discuss\u201d) Section 8.1.2.\u00a0 What is the normative behavior being specified in this section?\u00a0 Specifically, what is the additional or more restrictive behavior for the circumstance is where an ACP node is virtualized. ** Section 8.2.1.\u00a0 (I\u2019m no ABNF expert \u2026) Per the ABNF in Figure 17, the \u201c//=\u201d notation isn\u2019t valid.\u00a0 I think you want: OLD \u00a0 \u00a0  method //= [ \"DTLS\",\u00a0 \u00a0 port ] NEW \u00a0 \u00a0  method =/ [ \"DTLS\",\u00a0 \u00a0 port ] ** Section 10.2.1.\u00a0 Per \u201cAn attacker will not be able to join the ACP unless having a valid domain certificate, also packet injection and sniffing traffic will not be possible due to the security provided by the encryption protocol.\u201d, please be clearer: -- on path attacker = no packet injection -- on path attacker = only traffic analysis when sniffing -- compromised node = can inject traffic ** Section 11.\u00a0 Per \u201can ACP is self-protecting and there is no need to apply configuration to make it secure\u201d, if this assertion is going to be made: -- please specify the security services/properties in a normative section (not in the informative text in Section 10). -- please also be clear on what configuration is being referenced. ** Section 11.\u00a0 Per the list of factors on which ACP depends, it seems like the following are missing: -- the security properties of the enrollment protocol  -- that the security considerations of EST and BRSKI apply (or if not, why not)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:14:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-10 18:29:12-07:00",
    "text": "(pruned down to the remaining issue) ** Section 11.\u00a0 Per the list of factors on which ACP depends, it seems like the following are missing: -- the security properties of the enrollment protocol -- that the security considerations of EST and BRSKI apply (or if not, why not)",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2018-06-08 17:40:03-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-06 10:34:46-07:00",
    "text": "I'm balloting DISCUSS, but I think that this should be relatively simple to address: The document says things like:\"Today, the management and control plane of networks typically runs in the global routing table, which is dependent on correct configuration and routing.\" and \"Context separation improves security, because the ACP is not \u00a0  reachable from the global routing table. \" The term \"global routing table\" is widely used and understood to mean the global BGP routing table, or Internet global routing table. I understand that you are using it in the \"default VRF\" meaning, but I think that it is really important to clarify / disambiguate this the first time you use it.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-05-04 23:08:44-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-01 23:46:33-07:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Greg Mirsky for the shepherd's detailed write-up including the WG consensus ***and*** the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric # DISCUSS (blocking) As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is just a request to have a discussion on the following topics: ## Section 3 This is probably due to my lack of knowledge about NSH... So, a simple discussion over email will probably be enough to clear my DISCUSS points. RFC 9197  has an incremental tracing (section 4.4.1), how does it impact the length of the IOAM header in this case? Assuming that this header size is increased, I suggest to add some text about increasing the length field of IOAM header. `When a packet with IOAM is received at an NSH based forwarding node such as an Service Function Forwarder (SFF) that does not understand IOAM header, it SHOULD drop the packet.` is actually a copy of  RFC 8300  ```\u00a0  Packets with Next Protocol values not supported SHOULD be silently dropped \u00a0 \u00a0 \u00a0 by default, although an implementation MAY provide a configuration \u00a0 \u00a0 \u00a0 parameter to forward them. ``` and not a new behaviour. So, let's rather be clear and use a structure like \"Per section 2.2 of  RFC 8300 , ...\" followed by the  RFC 8300  text. While very similar to Jim Guichard's DISCUSS point, it is related to another part of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Jim Guichard",
    "end": "2023-05-04 15:27:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-28 12:29:29-07:00",
    "text": "- Section 3:  \u00a0  The IOAM-Data-Fields MUST follow the definitions corresponding to \u00a0  IOAM-Option-Types (e.g., see Section 5 of [ RFC9197 ] and Section 3.2 \u00a0  of [ I-D.ietf-ippm-ioam-direct-export ]) The above reference to  RFC9197  is incorrect although a simple fix. The IOAM-Option-Types are defined in Section 4 of that document not Section 5. Adding a DISCUSS as this reference is important enough to not just be a comment. Note that the same incorrect reference is used later on in Section 3 and must be corrected also.  - Section 3: \u00a0  The operator MUST ensure that all nodes along the service path support IOAM.\u00a0 Otherwise \u00a0  packets with IOAM are likely to be dropped per [ RFC8300 ]. This text needs clarification as  RFC8300  says nothing about IOAM specifically and dropping of OAM packets is discussed in that RFC here ->  https://www.rfc-editor.org/rfc/rfc8300#:~:text=O%20bit%3A%20%20Setting,disabled%20by%20default . The authors should clarify exactly what they mean by the above text and clarify what specifically in  RFC8300  would cause packets to be dropped if a node does not support IOAM.  - IANA Considerations: The text says \"IANA is requested to allocate protocol numbers for the following \"NSH Next Protocol\" related to IOAM\" but there is no reference to the correct registry. NSH Next Protocol allocations can be found here: https://www.iana.org/assignments/nsh/nsh.xhtml#next-protocol  and they are part of the Network Service Header (NSH) Parameters registry. Please provide an accurate reference to the Network Service Header (NSH) Parameters registry for IANA. - Section 5: Another incorrect reference needs to be corrected. \"For additional IOAM related security considerations, see Section 10 in [ RFC9197 ].\". It is actually section 9 of that RFC so please correct the reference.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-05-05 02:42:02-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-02 05:52:37-07:00",
    "text": "Hi, Thanks for this document. A couple of discuss points that I raised only because I find the spec to be unclear which should be be easy to clarify: (1) p 2, sec 3.\u00a0 IOAM encapsulation with NSH \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The operator MUST \u00a0  ensure that all nodes along the service path support IOAM. Is it actually 'all nodes along the service path' or \"SFC aware nodes along the service path\" that MUST support IOAM? (2) p 3, sec 3.\u00a0 IOAM encapsulation with NSH \u00a0 \u00a0 \u00a0 IOAM HDR Len:\u00a0 8 bit Length field contains the length of the IOAM \u00a0 \u00a0 \u00a0 \u00a0  header in 4-octet units. Does this mean quantized to 4 byte units, or that the actual length in bytes is 4 * \"Hdr Len\" field?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-05-04 13:49:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-01 07:36:02-07:00",
    "text": "(revised ballot) ** Section 5. \u00a0  IOAM is considered a \"per domain\" feature, where one or several \u00a0  operators decide on leveraging and configuring IOAM according to \u00a0  their needs. This seems like an an expansion of the applicability statement of IOAM.\u00a0 I don\u2019t see reference to multiple operators in Section 3 of  RFC9197 .\u00a0 Please explicitly cite the  RFC9197  applicability statement to be clear that scope is not being expanded and and consider if discussion of multiple operators is needed.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-03-25 06:11:23-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 19:18:30-07:00",
    "text": "Section 4.5.2: \u00a0  Implementations which choose to generate an alert instead, MUST \u00a0  generate error alerts to avoid attacks where the attacker repeatedly \u00a0  probes the implementation to see how it responds to various types of \u00a0  error.\u00a0 Note that if DTLS is run over UDP, then any implementation I just don\u2019t understand this, despite having hopped over to  RFC 8446  Sections 6 and 6.2. Is the intention that \u201cerror alert\u201d implies closure of the association? That doesn\u2019t seem to be exactly what 8446 says \u2014 it says the receiver of the alert closes the connection, but it doesn\u2019t mandate this for the sender (except in the case of \u201cfatal alert\u201d messages, where \u201cfatal\u201d seems like the exception that proves the rule).  It may be that \u201ceveryone knows\u201d an error alert is the same as termination, but it\u2019s not obvious in the plain English of the text I reviewed. Or maybe I\u2019m barking up the wrong tree and this isn't what the text quoted above is even driving at.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-04-08 13:21:11-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 14:41:54-07:00",
    "text": "In Sec 5.8.2, it is a significant change from DTLS 1.2 that the initial timeout is dropping from 1 sec to 100ms, and this is worthy of some discussion. This violation of  RFC8961  ought to be explored further. For a client first flight of one packet, it seems unobjectionable. However, I'm less comfortable with a potentially large server first flight, or a client second flight, likely leading to a large spurious retransmission. With large flights, not only is a short timeout more dangerous, but you are more likely to get an ACK in the event of some loss that allows you to shortcut the timer anyway (i.e. the cost of long timeout is smaller) Relatedly, in section 5.8.3 there is no specific recommendation for a maximum flight size at all. I would think that applications SHOULD have no more than 10 datagrams outstanding unless it has some OOB evidence of available bandwidth on the channel, in keeping with de facto transport best practice. Finally, I am somewhat concerned that the lack of any window reduction might perform poorly in constrained environments. Granted, doubling the timeout will reduce the rate, but when retransmission is ack-driven there is essentially no reduction of sending rate in response to loss. I want to emphasize that I am not looking to fully recreate TCP here; some bounds on this behavior would likely be satisfactory. Here is an example of something that I think would be workable. It is meant to be a starting point for discussion. I've asked for some input from the experts in this area who may feel differently. - In general, the initial timeout is 100ms. - The timeout backoff is not reset after successful delivery. This allows the \"discovery\" in bullet 1 to be safely applied to larger flights. - For a first flight of > 2 packets, the sender MUST either (a) set the initial timeout to 1 second OR (b) retransmit no more than 2 packets after timeout. - flights SHOULD be limited to 10 packets - on timeout or ack-indicated retransmission, no more than half (minimum one) of the flight should be retransmitted The theory here is that it's responsive to RTTs > 100ms, but small flights can be more aggressive, and large flows are likely to have ack-driven retransmission.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-19 15:22:24-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 09:52:19-07:00",
    "text": "I support Roman's discuss. I don't think this document is sufficiently clear about the limits of the scope of what it's trying to do. An ideal solution in this space would protect both the confidentiality of device configuration in transit and the authenticity (and authorization status) of configuration to be used by the device.\u00a0 This document makes no real effort to do the latter, with the device accepting any configuration file that comes its way and is encrypted to the device's key (or not encrypted, as the case may be), and with no attempt to keep the device's public key secret (which is just as well). I would expect some disucssion of this being highly desirable, but also requiring more complicated machinery (per, e.g., BRSKI and other voucher-based methods) and that this document aims to provide something much simpler, at the cost of only providing limited protection. However, even the confidentiality protection has only a limited realm of applicability, and it seems to fall apart in some plausible threat models. The security considerations rightly note that an attacker with physical access can likely extract the device private key, retrieve the encrypted configuration file, and decrypt the configuration contents.\u00a0 However, I don't think this possibility is necessarily limited to an attacker with physical access.\u00a0 An attacker on the network in the IXP/POP has several routes to getting attacker-controlled configuration on the device, whether by uploading to the configuration server, spoofing the DHCP response to point to the attacker's configuration server, rewriting traffic between the device and the configuration server, etc.\u00a0 Once the attacker has configuration on the device, they have a foothold by which to gain remote access and use whatever interfaces the device provides for decrypting configuration files and learning their contents (potentially even by installing a \"backdoor-type\" access mechanism and then running the normal install process for the legitimate encrypted configuration, and using the backdoor to return and retrieve the plaintext configuration information). While this level of attacker control taking over a device in the process of being installed is not a new attack with the encrypted configuration, it does still limit the extent to which confidentiality protection for configuration data is actually achievable, and I don't think the current document text provides an accurate description of the risk and what protection is provided.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-18 15:19:40-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-05-18 15:19:21-07:00",
    "text": "** Section 3.2.\u00a0 If keying material is being distributed as a certificate, do the expected behaviors of certificate process apply?\u00a0 For example, how is expiration handled? --\u00a0 If a customer downloads a certificate from the publication server and it is expired, what should be done? -- If a certificate is loaded in the TPM of the device, should the client stop accepting configurations if it expires? ** Section 4.3.\u00a0 \u201cAfter retrieving the config file, the device needs to determine if it is encrypted or not.\u00a0 If it is not encrypted, the existing behavior is used.\u201d\u00a0 What downgrade protection is assumed or recommended here.\u00a0 A rogue data center employee could re-target a DHCP response to a server of choice which provides only unencrypted, tainted configuration.\u00a0 It would seem that a device expecting an encrypted configuration should not accepted unencrypted ones (or at least this should be a policy consideration).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-06-24 07:06:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-18 15:19:40-07:00",
    "text": "** Section 3.2.\u00a0 If keying material is being distributed as a certificate, do the expected behaviors of certificate process apply?\u00a0 For example, how is expiration handled? --\u00a0 If a customer downloads a certificate from the publication server and it is expired, what should be done? -- If a certificate is loaded in the TPM of the device, should the client stop accepting configurations if it expires? ** Section 4.3.\u00a0 \u201cAfter retrieving the config file, the device needs to determine if it is encrypted or not.\u00a0 If it is not encrypted, the existing behavior is used.\u201d\u00a0 What downgrade protection is assumed or recommended here.\u00a0 A rogue data center employee could re-target a DHCP response to a server of choice which provides only unencrypted, tainted configuration.\u00a0 It would seem that a device expecting an encrypted configuration should not accepted unencrypted ones (or at least this should be a policy consideration).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-05 07:46:13-08:00",
    "end_reason": "position_updated",
    "start": "2020-03-04 07:16:02-08:00",
    "text": "Please let me know if I've misunderstood the test execution protocol incorrectly: Section 6.\u00a0 Per the paragraph \u201cThe evaluation of the test cases are intended to carry out in a controlled lab environment \u2026 It is important to take appropriate caution to avoid leaking non-responsive traffic from unproven congestion avoidance techniques onto the open Internet\u201d, this is good guidance in general case.\u00a0 However, in the case of this document how applicable is it?\u00a0 Didn\u2019t Section 3 (\u201cWe, therefore, recommend that a cellular network simulator is used for the test cases defined in this document \u2026\u201d and practically establish it can\u2019t be done without simulation with the scenario of the underground mine) and Section 4 (\u201cWe recommend to carry out the test cases as defined in this document using a simulator, such as [NS-2] or [NS-3]).\u00a0  If all the testing is supposed to be in a simulator how is it leaking out onto the internet?\u00a0 As far as I can tell, this helpful text is common in RMCAT document, but in this case could it please be tailored for the proposed testing regime.\u00a0  Perhaps something on the order adding text on the order of \u201cGiven the difficulty of deterministic wireless testing, it is RECOMMENDED and expected that the tests described in this document would be done via simulation.\u00a0 However,\u00a0 \u201d",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-03-09 13:08:41-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-08 17:15:36-08:00",
    "text": "Thanks for your work on this document. I'd like to discuss what it says about ISOC's role. In \u00a73.11 regarding ISOC, we have \u00a0  Internet standardization is an organized activity of the Internet \u00a0  Society (ISOC), with the Board of Trustees being responsible for \u00a0  ratifying the procedures and rules of the Internet standards process \u00a0  [ISOCIETF]. Looking at ISOCIETF, I don\u2019t see this in plain language anywhere. The strings \u201crules\u201d and \u201cratify\u201d don\u2019t appear, and \u201cprocedure\u201d doesn\u2019t appear anywhere relevant. The primary relevant section is \u00a74, \u201cISOC's Role in the IETF Standards Process\u201d, which lists several specifics in the first paragraph: \u00a0  ISOC plays a small role in the IETF standards process.\u00a0 In \u00a0  particular, ISOC assists the standards process by appointing the IETF \u00a0  NomCom chair and by confirming IAB candidates who are put forward by \u00a0  the IETF NomCom, as described in [ RFC8713 ], and by acting as the last \u00a0  resort in the appeals process, as described in [ RFC2026 ]. There are also indirect things mentioned later (liaisons, indirect support programs). But none of these things seem to rise to the level of \u201cratifying the procedures and rules of the Internet standards process.\u201d We also have, in \u00a76 of ISOCIETF, some words about the IETF Trust, ending in \u00a0 \u00a0 \u00a0 One of the IETF \u00a0  Trust's trustees is appointed by the ISOC's Board of Trustees. This, again, doesn\u2019t seem to rise to the level of \u201cratifying the procedures and rules of the Internet standards process.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-03-10 07:53:27-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-08 23:17:06-08:00",
    "text": "his doc has a DOWNREF to Informational draft-iab-rfcedp-rfced-model,which I failed to include in the Last Call message.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-09 14:40:57-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-09 12:59:19-08:00",
    "text": "A minor note, but IMO an important one: The document says it is about the production of \"IETF standards\", which I believe is a term being used colloquially. I would like the Introduction to be a bit more clear about whether the scope of this is (1) Production of Standards Track documents; (2) Production of IETF stream documents; or (3) Production of RFCs If (1) or (2), the text about the IRTF stream in (3.7) is out of scope. If the answer is (3), there ought to be an ISE section and a sentence about the IAB stream. Regardless of which, as this is an introductory document, the introduction would usefully help to disambiguate those concepts.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-03-11 16:01:31-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-03-10 08:02:53-08:00",
    "text": "Huge apologies on DISCUSSing this so late in the process. I completely missed this until it was pointed out. I have 2 issues, one is editorial, but sufficiently important that it reaches DISCUSS level.  The document uses the singular Editor and Author (and similar) -- it does says: \"This document refers to individual roles in the singular, such as \"a Document Editor.\" and then mentions that \"many roles are filled by more than one person at the same time\" with a reasonable justification for this. I'd like to DISCUSS this decision -- I've very concerned that newcomers to the process (and outsiders) will search for things like \"IETF author\" or \"editor\" or similar (e.g Chair), and only read the descriptions, not the terminology / disclaimer at the top. Again, I understand that this was done for clarity, but suspect that the audience was for the IETF community, and the potential for confusion by outsiders and newcomers was not considered. I think that the (much messier) \"The Document Editor(s) or Author(s)\" or \"The Document Editors or Authors\" or similar. In addition, a related issue is: \"When a document is composed and edited mainly by an individual, they may be referred to as the Document Author.\" This very strongly implies (or even states) that, if there is more than one person writing this, then they are not authors / that you cannot have more than one person being referred to as Document Authors. This certainly doesn't agree with my understanding.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-03-13 14:30:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-11 16:01:31-08:00",
    "text": "Thank you for addressing my concerns. Also: Argh! I replied to Rich thanking him for the changes, but forgot to actually remove the DISCUSS position; apologies for the delay.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2021-02-23 12:56:07-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 06:16:52-07:00",
    "text": "Let's resolve the document status issue -- it was last-called as Proposed Standard, it's listed as Informational, but it seems like it should be a BCP. I support Rob's DISCUSS and I believe the  RFC 8174  boilerplate should be used.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-02-09 23:41:21-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 04:16:07-07:00",
    "text": "Thank you for the work put into this easy-to-read document.  I support Erik Kline's DISCUSS points.  Please find below a couple of non-blocking COMMENT points and one nit but please also check: -\u00a0 Suresh Krishnan's IoT directorate review:   https://datatracker.ietf.org/doc/review-ietf-v6ops-cpe-slaac-renum-05-iotdir-telechat-krishnan-2020-10-21/ - Sheng Jiang's Internet directorate review:    https://datatracker.ietf.org/doc/review-ietf-v6ops-cpe-slaac-renum-05-intdir-telechat-jiang-2020-10-19/ I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == As observed by Sheng in his review and by Rob Wilton, the use of normative-looking \"MUST\" is unusual in an informational document even with the section 2 about requirement languages as the use of uppercase could confuse the reader; or at least limit their use in the L-* text in section 3. Also, note that  RFC 2119  has been updated by  RFC 8174 .\u00a0 The precedent set by  RFC 7084  seems a bad one. I will trust the responsible AD decision on this topic.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-02-24 22:21:34-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-21 22:37:27-07:00",
    "text": "[ section 3.2 ] * I absolutely agree in principle at these other lifetimes should be updated \u00a0 to the shorter of the two applicable lifetimes, but I'm worried that this \u00a0 text is not sufficiently precise.\u00a0 Specifically, this recommendation only \u00a0 applies to options that depend in any way on the change in the delegated \u00a0 prefix, yes?\u00a0 Perhaps just this qualifier is sufficient? \u00a0 For example, none of these comparative lifetime recommendations apply to \u00a0 a stable ULA for a router that meets requirements ULA-[1..5] and chooses \u00a0 to advertise a ULA /48 RIO and maybe even a ULA DNS server, I think. \u00a0 That being said, should this document also be saying that the ULA-derived \u00a0 options SHOULD prefer the ND_{P,V}_LIMIT lifetime values, in case a reboot \u00a0 causes a new ULA to be generated (i.e. the one supposedly in stable storage \u00a0 is lost or otherwise unrecoverable)?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-02-22 02:20:32-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-19 11:49:24-07:00",
    "text": "Hi, Hopefully this isn't hard to resolve, but I don't understand the meaning of the text in section 2: \u00a0 \u00a0 2.\u00a0 Requirements Language \u00a0 \u00a0 \u00a0  Take careful note: Unlike other IETF documents, the key words \"MUST\", \u00a0 \u00a0 \u00a0  \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \u00a0 \u00a0 \u00a0  \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are not used as \u00a0 \u00a0 \u00a0  described in [ RFC2119 ].\u00a0 This document uses these keywords not \u00a0 \u00a0 \u00a0  strictly for the purpose of interoperability, but rather for the \u00a0 \u00a0 \u00a0  purpose of establishing industry-common baseline functionality.\u00a0 As \u00a0 \u00a0 \u00a0  such, the document points to several other specifications (preferable \u00a0 \u00a0 \u00a0  in RFC or stable form) to provide additional guidance to implementers \u00a0 \u00a0 \u00a0  regarding any protocol implementation required to produce a \u00a0 \u00a0 \u00a0  successful CE router that interoperates successfully with a \u00a0 \u00a0 \u00a0  particular subset of currently deploying and planned common IPv6 \u00a0 \u00a0 \u00a0  access networks. \u00a0 \u00a0 \u00a0  Note: the aforementioned terms are used in exactly the same way as in \u00a0 \u00a0 \u00a0  [ RFC7084 ], with the above explanation copied verbatim from \u00a0 \u00a0 \u00a0  Section 1.1 of [ RFC7084 ]. This paragraph tells me how these words are not used. But it doesn't seem to explain how they are meant to be interpreted. My only assumption is that these words have no special meaning in this document at all, but they than raises the question as to why not to write them all in lower case.\u00a0 Alternatively, following the standard  RFC 2119  rules and boilerplate would also seem to make sense ...",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-04-22 14:27:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 07:11:27-08:00",
    "text": "I am balloting DISCUSS because I believe that the document is missing important considerations/details related to the operation of Babel in a network.\u00a0 I hope these points should be easy to address. This draft describes destination-first forwarding.\u00a0 If I understand correctly, for the table in \u00a74: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  destination\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 source\u00a0 \u00a0  next-hop \u00a0 \u00a0 \u00a0  2001:DB8:0:1::/64\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ::/0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 A \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ::/0\u00a0 \u00a0  2001:DB8:0:2::/64\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 B ...and the example presented of a \"source 2001:DB8:0:2::42 and destination 2001:DB8:0:1::57\", the result is that the packet is forwarded to A.\u00a0 Is this the correct interpretation?\u00a0 If so, then I believe there are important assumptions made that are not mentioned.\u00a0  In line with this document being \"applicable to small networks\" (\u00a71),  BCP 84 /\u00a74.3 recommends the following:  \u00a0  For smaller edge networks that use provider-based addressing and \u00a0  whose ISPs implement ingress filters (which they should do), the \u00a0  third option is to route traffic being sourced from a given \u00a0  provider's address space to that provider. Given that the draft provides no details, I assume that being \"compatible with [ BCP84 ]\" (\u00a71) means at least that Babel nodes aim to \"route traffic being sourced from a given provider's address space to that provider\". (a) While I understand the table above is just an example, it can be interpreted as indicating that B is the provider that assigned the 2001:DB8:0:2::/64 prefix.\u00a0 If traffic sourced from that prefix is sent to A, then there's a good chance that the packet will be dropped (in line with  BCP 84 ,  BCP 38 , etc.). Maybe the table is not intended to illustrate the routing table at a multihomed edge router. Still, it shows how easy it is to define a policy that may not result in the expected behavior because of the destination-first operation.\u00a0 Please add some guidance on the advertisements and how they may interact in the routing table.\u00a0  Note that what I'm asking for may just be a good example of what to do/not to do.\u00a0  rfc8678 /\u00a75 presents an example of how the forwarding table is constructed based on a set of routes -- something like that would be great! (b) How is the source address selected by the host?\u00a0  rfc8678  uses guidance from  rfc8028  and other RFCs as part of a set of \"Mechanisms for Hosts To Choose Good Default Source Addresses in a Multihomed Site\".\u00a0  rfc8678  significantly differs from this document in that it assumes source-first forwarding when discussing the selection of the source address.\u00a0 Are any of the recommendations in  rfc8678  applicable here? I may be missing something, but it seems to me that the current standards-based recommendations/mechanisms don't easily apply to this specification.\u00a0 I don't think there's anything wrong with doing things a different way -- but I expect those differences to be explicitly explained. SS-ROUTING suggests a trial-and-error mechanism: for \"destination addresses...the sending host tries them all...similarly, all possible source addresses are tried in turn.\"\u00a0 Is that the expectation here? Even though this document is about Babel and not the host, I would like to see a (short) discussion about how the host is expected to behave (or what it needs to consider) in light of the destination-first operation.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-11-05 01:32:40-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 23:48:21-08:00",
    "text": "Thank you for the work put into this document. The document is easy to read albeit not always clear and specific (see later). The topic of source address dependent routing is really critical for IPv6 deployment, so, I really appreciate your work on the topic Please find below one blocking DISCUSS point (trivial to fix), some non-blocking COMMENT points, and some nits. I also second Warren's DISCUSS on the lack of clarity in the section 4 example I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Please update IPv6 reference from  RFC 2460  to  RFC 8200 : I told you that this was an easy to fix DISCUSS point",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-04-21 08:18:36-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-04 17:24:14-08:00",
    "text": "I am concerned about the congestion implications of this architecture. If there are P prefixes in the network, the number of TLVs exchanged potentially goes from P to P^2. Perhaps this is an unrealistic use case. But are there any safeguards in the protocol against this happening (e.g. limitations on size/freq of updates?) Or ought there to be some operational guidance to be somewhat selective about source prefixes?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-04-21 10:15:57-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-05 05:08:14-08:00",
    "text": "Please see the comment below for further description. My specific discuss issue relates to clarifying the indexes of the 'source' and 'route' tables to indicate whether they are replacing the 'prefix-len' elements of the existing 3 tuple indexes, or adding additional elements to the existing index, effectively making them 5 tuple indexes.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-04-21 07:46:11-07:00",
    "end_reason": "position_updated",
    "start": "2020-11-03 15:24:31-08:00",
    "text": "I apologize for being rushed, and not balloting earlier, but I feel like I must have missed something fundamental here. The example in Section 4 (Data Forwarding) illustrates an issue, but doesn't actually *state* which (A or B) next hop will be used.  The text then says that: \"A Babel implementation MUST choose routing table entries by using the so-called destination-first ordering,\". I interpret this to mean that the packet \"with source 2001:DB8:0:2::42 and destination 2001:DB8:0:1::57\" should use next-hop A. This means that you will be sending the packet to the destination with no regard for if the provider connected to next-hop A carries/announces 2001:DB8:0:2::/64. If if it doesn't, this will look like a spoofing attack, and the ISP will (rightly) drop it.  The only way that I can see this working is if: 1: destination routes never point \"outside\" the network (and so will never hit inbound  BCP38  filters) or 2: destination routes always \"match\" - if you install x:y:z::/q pointing at next-hop A, you also install the same router pointing at next-hop B (this is pointless). Please help me understand what I'm missing here -- routing on destination to an ISP (which is what I'm assuming based on the \"small networks\" statement) seems like it will route packets with ISP B sources addresses to ISP A, running into  BCP38 /anti-spoofing filters.  BCP84  also covers a number of scenarios - it sounds like you are referring to Section 4.3.\u00a0 Send Traffic Using a Provider Prefix Only to That Provider, but that is exactly what is not happening above. Again, I'm assuming that I'm just missing something blindingly obvious here, but it would be good to figure out what, so the document can be clarified and others don't fall into the same trap...",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-10-06 04:52:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-05 07:17:09-07:00",
    "text": "I am balloting DISCUSS because I believe that operational and security considerations need to be addressed or at least mentioned. I believe these points should be easy to address with some additional text. (1) When is a router's participation in a particular Flex-Algorithm advertised? It seems to me that there might be a \"chicken-and-egg\" problem that should at least be mentioned in the Operational Considerations.\u00a0 Let me explain: \u00a711: \u00a0  When a router is configured to support a particular Flex-Algorithm, \u00a0  we say it is participating in that Flex-Algorithm. \u00a75: \u00a0  To guarantee loop-free forwarding for paths computed for a particular \u00a0  Flex-Algorithm, all routers that (a) are configured to participate in \u00a0  a particular Flex-Algorithm, and (b) are in the same Flex-Algorithm \u00a0  definition advertisement scope MUST agree on the definition of the \u00a0  Flex-Algorithm.\u00a0 The following procedures ensure this condition is \u00a0  fulfilled. These statements make it look like support for a particular Flex-Algorithm is advertised when the routing process is enabled -- because the router is \"configured to support/participate\".\u00a0 However, at this point, the router may not have received a FAD for the Flex-Algorithm it is advertising support for. Besides the number of the Flex-Algorithm, the participation advertisement implies support for a specific Metric-Type and Calc-Type.\u00a0 But, again, nodes may be advertising this support blindly if the FAD is not known yet. Presumably, the operator configures support for a specific Flex-Algorithm with a FAD in mind.\u00a0 IOW, there should be no surprises.\u00a0 However, I would like to see the relationship between the support/participation configuration and the FAD components explicitly called out. Note that this issue is related to the ability of an attacker to hijack a particular Flex-Algorithm, but oriented at the ability of the operator to cause harm to their network. (2) Related to the point above.  What should a node configured to advertise support for a specific Flex-Algorithm do if it receives a FAD that it cannot support?\u00a0 For example, if the calc-type is unknown or unsupported. [\u00a713 already addresses the case of an unsupported metric-type.] (3) The Security Considerations section says that the attacks listed can be addressed through authentication.\u00a0 However, it fails to consider what a rogue node (one that is authenticated and taken over by an attacker) can do.\u00a0  This type of attack is not preventable through authentication, and it is not different from advertising any other incorrect information through IS-IS/OSPF.\u00a0 It should be mentioned in the Security Considerations section. Also, the effect of a hijacked/modified FAD may result in traffic not being delivered at all -- for example, by using an unsupported Metric-Type or Calc-Type.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-04-27 07:22:41-07:00",
    "end_reason": "position_updated",
    "start": "2023-04-25 09:17:41-07:00",
    "text": "Thanks for this clean, easy-to-review document.  I do have one point I'd like to flag. I'm making this a DISCUSS to ensure the IESG has a chance to discuss the point raised, and intend to clear after the telechat.  In his review ( https://datatracker.ietf.org/doc/review-ietf-spring-nsh-sr-11-rtgdir-lc-bryant-2022-05-28/ ) Stewart Bryant makes a good point: ``` There is one point that the IESG should ponder. The authors have asked for a IP type assignment. This is a limited registry that needs to last the lifetime of the IP protocol suite. NSH started its life 9 years ago and has been a standard for 4 years and in all this time has not needed such as allocation. Neither SRv6 nor NSH are petite or lightweight protocols. So I wonder if the identification of NSH should happen at the IP layer as proposed, or whether an intermediate multiplexing layer such as UDP should be used? The extra processing for UDP is one test and the extra MTU is 8 octets. The decision for the IESG is whether in their view the extent of deployment and the gain in performance is such that they should authorise the allocation of the IP type. ``` AFAICT the argument against using a UDP encap is \"it's more overhead\" (which is true, but I think Stewart's point is that the UDP overhead is pretty small as a fraction of the SRv6 and NSH overheads). Anyway, it seems like it would be good to at least consider this question.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-11-22 08:57:45-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-19 14:48:33-08:00",
    "text": "I'm having trouble seeing how we got here; this registry architecture is hard to understand, and past actions appear to violate  RFC 3692 . 1.  RFC7153  designated 0x80-0x8f as experimental and then immediately defines 0x80 as the gateway to a further subregistry of FCFS/IETF review codepoints. This does not appear to be \"Reserved for Experimental Use\" in the  RFC 3692  sense, in that it is not meant to be used only by explicit experiments. (It's a standards track document). 2.  RFC8955  compounds it by taking another 2 (of 15 remaining!) experimental codepoints in a standards-track document, for a similar purpose. I agree with this draft's reclassification of the 3 codepoints, as it recognizes reality that they are apparently no longer safe for  RFC 3692  experiments. But I would also like to verify that this behavior will not continue: future standards-track allocations, including those pointing to more subtypes (\"Part 4\", etc), will draw from the FCFS range, not Experimental. Furthermore, experiments (with a draft or not) that use one of these experimental codepoints should be reassigned a FCFS codepoint if they move to Standards track.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2021-11-18 16:22:28-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-18 16:19:14-08:00",
    "text": "Hi, Thank you for your work. Maybe I'm missing something obvious, but why doesn't this document update 8955 just like it updates 7153? I'm asking because your document modifies the allocation policy of the 0x80-0x8F range, as well as the names of 0x80, 0x81, 0x82 (and of sub-types registries) but at the same time it seems to me that 7153 only covers the allocation policy of the 0x80-0x8F range and 0x80 (and its sub-type registry), while it's 7674/8955 which seems to cover 0x81 and 0x82 (and their sub-types registries). Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Martin Vigoureux",
    "end": "2021-11-23 06:18:59-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-18 16:22:28-08:00",
    "text": "Hi, Thank you for your work. Maybe I'm missing something obvious, but why doesn't this document update 8955 just like it updates 7153? I'm asking because your document modifies the allocation policy of the 0x80-0x8F range, as well as the names of 0x80, 0x81, 0x82 (and of their sub-types registries), and at the same time it seems to me that 7153 covers the allocation policy of the 0x80-0x8F range but only 0x80 (and its sub-type registry), while it's 8955 which seems to cover 0x81 and 0x82 (and their sub-types registries). Thank you",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-09-03 05:59:41-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-06 13:30:33-07:00",
    "text": "Thanks for writing this document. Section 6.1 says: \"Developers MAY develop new protocols or applications that rely on IP \u00a0  fragmentation if the protocol or application is to be run only in \u00a0  environments where IP fragmentation is known to be supported.\" I'm wondering if there should be a bit more nuance here to make the recommendation clearer. Do we think there is a case where an application protocol developed in the IETF will be known to only run in environments where fragmentation is supported? If we don't think developing such a protocol would be in scope for the IETF, then I'm wondering if that case should be called out explicitly with a stronger normative requirement.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2023-03-27 06:16:00-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 07:10:53-08:00",
    "text": "This document attempts to do two things: specify \"unsolicited BFD\" and define a YANG model for its management.\u00a0 I am happy to include both in the same document, but the specification of the protocol mechanisms falls short and results in a document that lacks clarity.\u00a0 While YANG is the preferred management mechanism, it should be possible to implement and manage the feature without the model. Most of my concerns are from Section 2 (line numbers from idnits): 154\t\u00a0  Passive unsolicited BFD support MUST be disabled by default, and MUST 155\t\u00a0  require explicit configuration to be enabled.\u00a0 On the passive side, 156\t\u00a0  the desired BFD parameters SHOULD be configurable.\u00a0 The passive side 157\t\u00a0  MAY also choose to use the parameters that the active side uses in 158\t\u00a0  its BFD Control packets.\u00a0 The \"My Discriminator\", however, MUST be 159\t\u00a0  chosen to allow multiple unsolicited BFD sessions. (A) \"the desired BFD parameters SHOULD be configurable\" Which parameters are those?\u00a0 The YANG model uses bfd-types:base-cfg-parms, which only includes a basic set.\u00a0 The point here is that this document's specification part is incomplete because it doesn't specify which parameters \"SHOULD be configurable\". (B) The YANG model offers global and per-interface configuration options.\u00a0 The specification doesn't discuss hierarchical configuration or whether one type should take precedence over the other.\u00a0 [Related to Rob's DISCUSS.] This point was discussed on the mailing list, where it was pointed out that per-interface configuration should override global configuration [1], but that discussion is not reflected in the document. [1]  https://mailarchive.ietf.org/arch/msg/rtg-bfd/GI_eNtxcEeh2_vTl9zfq7K6V1X4 171\t\u00a0  When the passive side receives an incoming BFD Control packet on a 172\t\u00a0  numbered interfaces, the source address of that packet MUST belong to 173\t\u00a0  the subnet of the interface on which the BFD packet is received.\u00a0 The 174\t\u00a0  source address of the BFD Control packet SHOULD be validated against 175\t\u00a0  expected routing protocol peer addresses on that interface. (C) \"SHOULD be validated\"  What does validating the source address \"against expected routing protocol peer addresses on that interface\" entail?\u00a0 Is it just a comparison?\u00a0 Please be explicit on what the normative behavior should be. When is it ok to not validate?\u00a0 Why is this behavior recommended and not required? If the validation is performed, is there an expected action if the source address does not correspond to an \"expected routing protocol peer addresses on that interface\"?\u00a0 Where does this \"expected\" list come from?\u00a0 On a LAN, it seems like any address would be valid since a router doesn't know the list of IGP neighbors beforehand. 177\t\u00a0  The passive side MUST then start sending BFD Control packets and 178\t\u00a0  perform the necessary procedure for bringing up, maintaining and 179\t\u00a0  tearing down the BFD session.\u00a0 If the BFD session fails to get 180\t\u00a0  established within certain specified time, or if an established BFD 181\t\u00a0  session goes down, the passive side SHOULD stop sending BFD Control 182\t\u00a0  packets and MAY delete the BFD session created until BFD Control 183\t\u00a0  packets are initiated by the active side again. (D) \"If the BFD session fails to get established within certain specified time...\" [nit] s/within certain specified time/within a certain specified time Where does a \"certain specified time\" come from?\u00a0 Is it configurable?\u00a0 Does it correspond to any of the state variables in  rfc5880 ? (E) \"SHOULD stop sending BFD Control packets\" When is it ok not to stop sending BFD control packets?\u00a0 Why would the node continue sending packets if the session is not established (or goes down)?\u00a0 Why is this behavior recommended and not required? 185\t\u00a0  When an Unsolicited BFD session goes down, an implementation MAY 186\t\u00a0  retain the session state for a period of time.\u00a0 Retaining this state 187\t\u00a0  can be useful for operational purposes. (F) Not exactly a contradiction, but confusing normative statements (between this paragraph and the one before): \"MAY delete\" vs \"MAY retain\" for the same event (\"BFD session goes down\").",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-04-11 07:04:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 06:27:20-08:00",
    "text": "# GEN AD review of  draft-ietf-bfd-unsolicited-11 CC @larseggert Thanks to Dan Romascanu for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/2NcfuVBkWLD_CcQyTciwKOz2Xac ). ## Discuss ### Section 7.1, paragraph 3 ``` \u00a0 \u00a0  The same security considerations and protection measures as those \u00a0 \u00a0  described in [ RFC5880 ] and [ RFC5881 ] apply to this document.\u00a0 In \u00a0 \u00a0  addition, with \"unsolicited BFD\" there is potential risk for \u00a0 \u00a0  excessive resource usage by BFD from \"unexpected\" remote systems.\u00a0 To \u00a0 \u00a0  mitigate such risks, the following measures are mandatory: \u00a0 \u00a0  *\u00a0 Limit the feature to specific interfaces, and to single-hop BFD \u00a0 \u00a0 \u00a0 \u00a0 with \"TTL=255\" [ RFC5082 ]. \u00a0 \u00a0  *\u00a0 Apply \"policy\" to allow BFD packets only from certain subnets or \u00a0 \u00a0 \u00a0 \u00a0 hosts. \u00a0 \u00a0  *\u00a0 Deploy the feature only in certain \"trustworthy\" environment, \u00a0 \u00a0 \u00a0 \u00a0 e.g., at an IXP, or between a provider and its customers. \u00a0 \u00a0  *\u00a0 Use BFD authentication, see [ RFC5880 ].\u00a0 In some environments, e.g. \u00a0 \u00a0 \u00a0 \u00a0 when using an IXP, BFD authentication can not be used because of \u00a0 \u00a0 \u00a0 \u00a0 the lack of coordination into the operation of the two endpoints \u00a0 \u00a0 \u00a0 \u00a0 of the BFD session.\u00a0 In other environments, e.g. when BFD is used \u00a0 \u00a0 \u00a0 \u00a0 to track the next hop of static routes, it is possible to use BFD \u00a0 \u00a0 \u00a0 \u00a0 authentication: this comes with the extra cost of configuring \u00a0 \u00a0 \u00a0 \u00a0 matching key-chains at the two endpoints.\u00a0 If BFD authentication \u00a0 \u00a0 \u00a0 \u00a0 is used, the Meticulous Keyed SHA1 mechanism SHOULD be used. ``` BFD can be configured to send large volumes of traffic, and it sends it without congestion control. When a past IESG approved BFD for standardization in that form, it was exactly because both endpoints needed to be configured, which significantly reduces the possibility/impact of unilateral misconfiguration. I don't believe the suggestions above provide nearly the same level of protection. Also, if (all of?) these are mandatory, that needs to be made very clear, i.e., using  RFC2119  terms here and elsewhere in the document (where it currently says these mechanisms are recommended...)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2023-04-18 08:56:16-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-12 09:03:13-08:00",
    "text": "Hi, Thanks for this document. Please see my comments below for more details, but I'm balloting discuss on 3 points: (1) The document is somewhat unclear as to whether the configuration is applied hierarchically (I presume that it is, if not then my second discuss point is not valid and can be ignored). (2) As specified, I don't think that the hierarchical configuration will work, because the interface level leaf \"defaults\" will override an explicit value configured globally.\u00a0 I.e., logically, the interface level leaf, if in scope, will always have a value. (3) The document should provide an instance-data example in the appendix to illustrate the use of this configuration. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-03-26 23:47:56-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 09:00:29-08:00",
    "text": "** Section 7.1 Limit the feature to specific interfaces, and to single-hop BFD \u00a0 \u00a0 \u00a0 with \"TTL=255\" [ RFC5082 ]. Section 2.2 of  RFC5082  says \u201cset the TTL on the protocol packets to 255 (the maximum possible for IP) and then reject any protocol packets that come in from configured peers that do NOT have an inbound TTL of 255\u201d. Guidance on dropping the packets based on TTL in  RFC5082  appears to be missing here.\u00a0  ** Section 7.1.\u00a0 The following considerations are inconsistent:  -- \u201cTo mitigate such risks, the following measures are mandatory: \u2026 Apply \"policy\" to allow BFD packets only from certain subnets or hosts.\u201d Editorially (not discuss but related), why is policy in quotes? Requiring this check conflicts with the less rigorous SHOULD in Section 2: \u201cThe source address of the BFD Control packet SHOULD be validated against expected routing protocol peer addresses on that interface.\u201d -- \u201cTo mitigate such risks, the following measures are mandatory: \u2026 Use BFD authentication, see [ RFC5880 ].\u00a0 In some environments, e.g. when using an IXP, BFD authentication can not be used \u2026 If BFD authentication is used, the Meticulous Keyed SHA1 mechanism SHOULD be used.\u201d The text first says using BFD authentication is mandatory, but then says it is not possible in certain environments.\u00a0 Later is states that \u201cif BFD is used\u201d, but the text already said it was mandatory.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-04-19 01:21:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-12-14 11:32:26-08:00",
    "text": "Thanks for working on this specification.  Thanks to Magnus Westerlund for the TSVART review, based on that review and my own read, I am supporting both Lars's and Roman's discuss. On top of that, as this document claims - \"with \"unsolicited BFD\" there is potential risk for excessive resource usage by BFD from \"unexpected\" remote systems\". This translates to me as potential injection of huge amount of traffic which is lacking a self-regulation mechanism in this specification. To large degrees the traffic volume could have random effects on the routing plane and what links are considered up etc. We can hide all these by saying \"Deploy the feature only in certain \"trustworthy\" environment\"\", then I am completely missing the definition of \"trustworthy\" environment\". I would like to discuss that.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-19 19:40:23-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-19 19:39:31-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, Figure 8 --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is inteded to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-19 19:41:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-19 19:40:23-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, and Figure 8. --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is inteded to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-06-19 19:41:59-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-06-19 19:41:18-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, and Figure 8. --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is intended to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-07-06 15:55:20-07:00",
    "end_reason": "position_updated",
    "start": "2018-06-19 19:41:59-07:00",
    "text": "Thanks to everyone who put in the hard work to make this document happen. I have found a blocking issue that I believe should be easy to address; but (due to the potential impact on interoperability) document publication does need to be blocked pending resolution of this issue. The problem is that the SDP examples in this document are not consistent with the syntax and semantics defined in draft-ietf-mmusic and  draft-ietf-avtext-rid , as described below. --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=rid:1 send pt=97 max-width=1280;max-height=720 >\u00a0 a=rid:2 send pt=98 max-width=320;max-height=180 >\u00a0 a=rid:3 send pt=99 max-width=320;max-height=180 >\u00a0 a=rid:4 recv pt=97 The final syntax for RID ended up with PT being treated the same as other parameters, and therefore requiring a semicolon delimiter between it and stream restrictions. So this example should read: \u00a0  a=rid:1 send pt=97;max-width=1280;max-height=720 \u00a0  a=rid:2 send pt=98;max-width=320;max-height=180 \u00a0  a=rid:3 send pt=99;max-width=320;max-height=180 \u00a0  a=rid:4 recv pt=97 --------------------------------------------------------------------------- \u00a74, Figure 1: >\u00a0 a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:RtpStreamId Although the SDES item is called \"RtpStreamId,\" the URN registered for its identification is urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id -- see section 4.3 of draft-ietf-avtext-rid. This example should read: \u00a0  a=extmap:1 urn:ietf:params:rtp-hdrext:sdes:rtp-stream-id --------------------------------------------------------------------------- The preceding two comments regarding SDP syntax also apply to Figure 2, Figure 5, Figure 6, Figure 7, and Figure 8. --------------------------------------------------------------------------- Figure 8 (which is missing a figure label): >\u00a0 a=rid:5 send pt=99,102;max-br=64000 >\u00a0 a=rid:6 send pt=100,97,101,102 The selection of \"5\" and \"6\" for these RIDs goes against the advice in section 3.3 of  draft-ietf-avtext-rid ; and, even worse, may give the incorrect impression that RID space is shared between media sections. Please adjust them to be 1 and 2 instead of 5 and 6. Also, if LPC is intended to be used with the first RID (as is suggested by the text above the example), then your \"pt\" value needs to be \"pt=99,102,98\" -- otherwise, the RID will prevent the use of PT 98. Remember: RID defines *restrictions*. If you say \"pt\" and then don't list a PT in it, then that missing PT is strictly forbidden from appearing with that RID. There is a similar problem with the video section, which needs to read as follows to match the explanatory text: \u00a0  a=rid:1 send pt=103,105,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:2 send pt=104,106,107;max-width=1280;max-height=720;max-fps=30 \u00a0  a=rid:3 send pt=103,105,107;max-width=640;max-height=360;max-br=300000 \u00a0  a=rid:4 send pt=104,106,107;max-width=640;max-height=360;max-br=300000",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-07 21:13:34-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-28 16:05:20-08:00",
    "text": "I don't think there's enough clarity on what authentication schemes are supported and how the YANG configuration interacts with MSDP operation. If I'm reading^Wsearching through  RFC 3618  correctly, the only supported authentication mechanism is TCP-MD5 ( RFC 2385 ), and there have been no updates to  RFC 3618  that are indicated in the RFC database.\u00a0 However, RFC 2385  is obsoleted by  RFC 5925  (TCP-AO).\u00a0 Can TCP-AO be used with  MSDP?\u00a0 What protocol elements or operation are controlled by the \"authentication\" container?\u00a0 What algorithms are valid for use with the \"password\" case?\u00a0  RFC 8177  is the sole reference for both the \"key-chain\" leaf and the \"password\" case, but that does not seem a sufficient reference from which to implement.  Also, there are a couple of elements in the \"state-attributes\" container that say they indicate a time when something will/did happen and measure it in seconds.\u00a0 I don't see an indication of what the reference point is for them, though -- \"seconds since when?\".\u00a0 Further context in the  COMMENT to avoid too much quoted text here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-21 17:50:06-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-02 09:39:23-08:00",
    "text": "This yang modules makes use of  RFC8177 \u2019s ietf-key-chain module.\u00a0 Please add a reference to this draft inheriting  RFC8177 \u2019s security considerations and associated considerations (see  draft-ietf-ospf-yang  for reusable language).\u00a0  Please also clarify the link between the password and  RFC8177  per the following snippet of the YANG module in the Security Considerations. \u00a0 \u00a0 grouping authentication-container { ... \u00a0 \u00a0 \u00a0 container authentication { \u00a0 \u00a0 \u00a0 \u00a0 if-feature peer-authentication; ... \u00a0 \u00a0 \u00a0 \u00a0 choice authentication-type { ... \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 case password {",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-26 21:48:49-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-13 15:33:11-07:00",
    "text": "(1) The statement \"Bytes with no bits set at the end of the byte string are removed.\" in Section 6.7 seems confusing to the point of being potentially harmful, and I'm not sure why it needs to be there.\u00a0 In the context it appears in, it seems to leave the value to be used for the bit string offset in an ambiguous state.\u00a0 If the intent is that such strings should not be generated (and MAY/SHOULD/MUST be rejected by recipients), that's okay, but having them silently ignored is very surprising and may merit discussion. (2) I think we should discuss the relationship between this document and draft-ietf-core-sid , which are before the IESG at the same time.\u00a0 This document says that core-sid is \"one example for\" a specification defining the management of SIDs, but  draft-ietf-core-sid  claims to be the document that \"defines the semantics, the registration, and assignment processes of YANG SIDs\".\u00a0 I'm having a hard time seeing the two statements as compatible with each other, but maybe I'm missing something. (3) The second example of instance-identifier using SID (\u00a76.13.1) seems malformed, with \"key name country\" appearing under both \"list user\" and \"list authorized-key\" and no \"country\" leaf within \"list user\" other than the one under \"list authorized-key\".\u00a0 (The actual identityref example appears to correctly only use \"name\" as the key for \"list user\" and not \"list authorized-key\".) (4) Relatedly, the second example of instance-identifier by name (\u00a76.13.2) does not show a country for \"authorized-key\", and I'm not sure if that's a valid way to represent the given YANG element.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-01-05 09:15:44-08:00",
    "end_reason": "position_updated",
    "start": "2021-07-15 06:35:13-07:00",
    "text": "Thanks for this document, it is good work, and I think that there specification is almost there, but that the text could be tightened up in a few places. 1. The document should be clearer on its use of terminology around schema nodes.\u00a0 Mostly the encoding related to YANG data nodes, not YANG schema nodes.\u00a0 I've provided more information in the comments section. 2. As also raised by Ben, this document should probably cover the YANG data structure extension in  RFC 8791 .\u00a0 This could potentially be done in addition to rc:yang-data, but perhaps better in its place. 3. Did the WG consider supporting encoding YANG metadata ( RFC 7952 )?\u00a0 Presumably this would be expected to be covered as future work? 4. How does the CBOR encoding of SIDs apply to YANG features?\u00a0 This draft references features and the SID draft allows SIDs for them, but I don't understand how they are used in the encoding (since features don't appear in the instance data, they are only at the schema level).  5. I also support Ben's second discuss point.\u00a0 I think that as written, this draft needs a normative reference to the SID draft.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2018-05-10 06:28:12-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-09 09:27:16-07:00",
    "text": "I would like to DISCUSS about the Intended Status of this document -- with the Chairs and AD. I have to confess that I haven't been following the homenet WG as closely as I probably should have.\u00a0 Hopefully that means that the topic below has been discussed and documented already, making this DISCUSS easy to resolve. Back in 2015, the then-Chairs and the AD posted a note titled \"Routing Design Team outcome and next steps\"[1]; in it, they declared \"rough consensus that Babel[*] shall be the \u201cmandatory to implement\u201d routing protocol for Homenet routers, albeit only on an Experimental basis at this time...we solicit Experimental Internet Drafts to document Homenet-specific profiles of any applicable routing solution and to report results of any relevant experimentation and implementation.\u00a0 We expect that this decision will be revisited in a future Standards Track document based on specifications and running code available at that time.\" My interpretation of the above text is that Babel is MTI, but that the work (documents) will be Experimental...and that this decision could change in the future (most likely towards confirming and moving to the Standards Track).\u00a0 This document was originally adopted as Experimental.\u00a0 I didn't find an explicit discussion on the list about changing that original overall direction, nor another declaration by the Chairs/AD.\u00a0 I did find find a thread in which one of the Chairs (Barbara) asked about the status for this document (and this document only)[2]; the initial question was framed around the references being Standards Track documents (HNCP and rfc6126bis) -- just one answer came back (from the author of this document)... I'm treating this point as a DISCUSS because I think that the WG consensus may have not been determined to change the original declaration from the Chairs/AD (from 2015).\u00a0 In my interpretation of that original declaration, moving Babel to the Standards Track means a recognition that it will be *the* protocol going forward (which changes that initial \"only on an Experimental basis at this time\" phrase), is something that should be discussed explicitly, and not just in light of this one document.\u00a0 That is the part that I haven't seen. I note that in the conclusion of the thread about the status of this document [3] Barbara does include reasoning that may result in changing the original declaration (as does the Shepherd writeup), for example: \"there exist multiple, interoperable implementations\" and \"no drafts proposing other homenet routing protocol profiles have been submitted\"...but those points don't seem to have been considered/discussed by the WG (they were not in the original message and I didn't find another thread -- I also looked at the minutes of the last couple of IETF meetings). To be clear, I have no objection with Babel being used in homenet applications, or with it being the Standard protocol.\u00a0 My point here is that it is not clear to me that the WG explicitly reached consensus to change the declaration from the Chairs/AD.\u00a0 I will be happy to clear this DISCUSS when the Chairs/AD point me to the discussion that I missed, or simply tell me that the declaration from 2015 is no longer valid and that the WG knows, or that they believe that the thread discussing this document is enough to call consensus...or something to that effect. [1]  https://mailarchive.ietf.org/arch/msg/homenet/kiI7pIYfpgT2Qrfx1VBAwng7_QY [2]  https://mailarchive.ietf.org/arch/msg/homenet/5L5WYN14gDCamP7qlknJmWkeU5M [3]  https://mailarchive.ietf.org/arch/msg/homenet/35EU8oBr8hunvvSRYUStypZIPVU",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-09-27 11:14:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-15 06:05:29-07:00",
    "text": "I am balloting DISCUSS because I believe the specification is not clear enough. (1) The document recommends (5 separate times) that an ID \"SHOULD be identical to the value advertised\" in an existing TLV. If the other TLV is advertised, when is it ok for the values not to be the same?\u00a0 Why is this action recommended and not required? Should the receiver of these TLVs take any action if the values are not identical? (2) \u00a73.1: The requirement for the Router ID to be unique within the flooding scope of the LSP has been removed.\u00a0  Please help me understand why this change is ok.\u00a0 If the Router ID can be used to identify \"the router who generates the inter-AS reachability TLV\", not requiring unique values seems to go counter to that idea.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-12 05:53:35-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-22 20:27:51-07:00",
    "text": "(A simple editorial fix) Per Section 5.8.2 of [ I-D.ietf-ace-oauth-authz ], the name of the parameter in the C-to-AS communication is \u201cace_profile\u201d (not \u201cprofile\u201d).\u00a0 The \u201cace_profile\u201d parameter is mistakenly referenced as \u201cprofile\u201d in the following place: (a) Section 3.2.\u00a0  \u00a0  The AS can signal that the use of OSCORE is REQUIRED for a specific \u00a0  access token by including the \"profile\" parameter with the value \u00a0  \"coap_oscore\" in the access token response",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-06 18:54:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-18 19:53:19-07:00",
    "text": "Thanks for this document; it will be very nice to have this more-structured mechanism available for future HTTP header (and trailer) fields. (0) There seem to still be a few lingering internal inconsistencies that merit further discussion. Most notably, there is the inherent risk of skew when both prose algorithms and ABNF constructions are provided for the same structures. While Section 1.2 is careful to disclaim that the prose algorithm takes precedence over the ABNF for parsing, to my reading the coverage in the following paragraph of serialization procedures imply that it is the ABNF that is authoritative.\u00a0 In particular, \"[i]mplementations MAY vary from the specified behavior so long as the output still matches the ABNF\" seems to admit deviations from the prose algorithms but require compliance with the ABNF, in effect making the ABNF take precedence over the prose algorithm.\u00a0 Having a different description of the procedure normative for generation vs. consumption invites interoperability-affecting feature skew, such as the handling of empty lists as Julian noted on the list. Similarly, Section 3.1.1's prose says that inner lists are delimited \"by a single space\", but the ABNF uses (1*SP), allowing for more than one space. Additionally, when Section 4.2.3.2 discusses parsing parameter map keys, the handling for duplicate map key names is specified as overwriting the previous value, in contrast to the prose description (Section 3.1.2) that describes these keys as \"unique within the scope [of] the Parameters they occur within\".\u00a0 (While dictionary key names might be expected to have a similar behavior, I did not find conflicting text for that behavior.) Finally, at a prose level we employ needlessly different descriptions in several places for what is effectively the same procedure; while I do not think any of these affect interoperability (and thus the full details are in the COMMENT section), it does seem to be continuing the theme.\u00a0 (These are things like how we describe the algorithm to skip implicit-true for booleans, whether we initialize the output string to the empty string only to immediately add a constant literal character to it vs. initializing the output string to that literal character, etc.) A couple other points that may need further discussion: (1) What aspect(s) of structured field processing are case (in)sensitive? The only mentions I see of case sensitivity are in Section 4.2 discussing header field names and (implicitly) Section 4.2.2 discussing a \"character-for-character\" comparison of dictionary key names, but of course we cite  RFC 5234  for ABNF, which uses case-insensitive matching. On the other hand, base64 encoding requires case sensitivity for successful round-tripping of arbitrary binary data. (2) One of the stated goals of this document is to define intentionally strict processing rules, but there are several places where we could have removed additional optionality but elected to not do so.\u00a0 What is the criterion for \"too far\" towards strictness?\u00a0 For example, Section 4.2.7 gives optionality with respect to base64 padding (see COMMENT).",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-04 02:02:53-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 09:14:08-07:00",
    "text": "A. Section 3.1: \u00a0  The ABNF for Lists in HTTP fields is: \u00a0  sh-list\u00a0 \u00a0 \u00a0  = list-member *( *SP \",\" *SP list-member ) \u00a0  list-member\u00a0  = sh-item / inner-list \u00a0  Each member is separated by a comma and optional whitespace. To me there is a clarity issue that could lead to interoperability issues. Namely the difference in the meaning of whitespace between  RFC 7230  and this document. Structured headers appear to not allow the HTAB that  RFC7230  allows. And that is fine, but I would expect this to be more clearly discussed. If the intention was to allow for HTAB you need to use WSP rather than SP in above rule.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-05-20 08:25:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-17 15:17:15-07:00",
    "text": "This is probably a simple one, and perhaps I'm missing something obvious: Throughout Section 3, the document specifies minimum data structure sizes (1024 list members, 256 inner list members, 64-character keys, etc.) that the receiver MUST be able to process. What is the desired behavior if any of these data structures exceeds what the receiver can process? Must it skip the entire field, or can it process the first N entries and then ignore the rest? Given the \"Intentionally Strict Processing\" principle, it would be good to spell this out.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-21 05:31:59-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-20 13:29:32-07:00",
    "text": "(I appreciate that this is pseudo-code which has inherent ambiguity sometimes, so please let me know if I've interpreted it in an unintended way) ** Section 4.2.6.\u00a0 There appears to be an inconsistency here in my reading of the algorithm given the ABNF in Section 3.3.4 -- Let\u2019s assume of token of input_string =\u201c*foo\u201d -- Step 1: pass since input_string[0] = \u201c*\u201d -- Step 2: Set output_string = \u201c\u201d -- Step 3: pass since input_string[0] = \u201c*\u201d, -- Step 3.1: input_string[0] is still \u201c*\u201d and not a tchar, \u201c:\u201d or \u201c/\u201d causing a output_string=\u201d\u201d to be returned  This doesn\u2019t seem correct. ** Section 4.2.7.\u00a0 The parsing guidance doesn\u2019t follow for me given the ABNF in Section 3.3.5. -- Let\u2019s assume input_string = \u201c:cHJldGVuZCB0aGlzIGlzIGJpbmFyeSBjb250ZW50Lg==:\u201d, the example in Section 3.3.5 -- Step 1: pass since input_string[0] = \u201c:\u201d -- Step 2: Set input_string = \u201ccHJldGVuZCB0aGlzIGlzIGJpbmFyeSBjb250ZW50Lg==:\u201d -- Step 3: pass since the last character of input_string is \u201c:\u201d -- Step 4: Set b64_content = \u201ccHJldGVuZCB0aGlzIGlzIGJpbmFyeSBjb250ZW50Lg==\u201d -- Step 5 says \u201cconsume the \u201c:\u201d character at the beginning of the input_string, but there is no such character.\u00a0 It was discarded in Step 2.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-10-13 15:07:24-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-28 12:09:35-07:00",
    "text": "I applaud the deliberate consideration being provided for security matters.\u00a0 My concern is about the symmetry between the security claims being made and the level of detail being provided in the mechanisms. ** Definition of a HHIT. Various security claims are made about the HHIT down to specifying cryptographic algorithms and resistance to attacks.\u00a0 However, this document provides inconsistent and vague definitions for a HHIT.\u00a0 Surprisingly, it doesn\u2019t cite draft-ietf-drip-rid.\u00a0 It is difficult to assess these claims given the lack of information on a HHIT.\u00a0 I would have expected this architecture document to make high-level claims and leave the details to a standards-track document.\u00a0 A few places to source the HHTI definitions: -- Section 3 says \u2018\u2026 explains the use of Hierarchical Host Identity Tags (HHITs) [ RFC7401 ] \u2026\u201d,  RFC7401  defines HIT but not HHIT. -- Section 3 also says \u2018Self-asserting in this usage means that, given the Host Identity (HI), the HHIT ORCHID construction and a signature of the registry on the HHIT \u2026\u201d, but as doesn\u2019t explain that connection -- A few places in the text suggest that HHIT, as the name suggest are hierarchical, and this hierarchy is key to ensuring security properties (e.g., Section 3.2. \u201cThe cryptographically-bound addition of the Hierarchy \u2026\u201d; Section 3.4 says \u201cTo provide this, each HHIT embeds plaintext information designating the hierarchy within which it is registered and a cryptographic hash of that information concatenated with the entity's public key, etc. provides examples of computing a HHIT by encoding a HHIT\u201d; and Section 4.2.1. \u201cThe HHIT hierarchy\u00a0 can provide the needed scalability and management structure\u201d).\u00a0 Where is that hierarchy explained in this document?   This is up to the WG, but IMO, the discussion about cryptographic properties would be better suited in the document providing the specifics ( draft-ietf-drip-rid ) and the top-level security properties cited by reference here.\u00a0  ** Verification process of claims/assertions. -- Section 3.2.\u00a0 Each Observer device SHOULD be \u00a0  provisioned either with public keys of the DRIP identifier root \u00a0  registries or certificates for subordinate registries. -- Section 3.2 ... prepopulating small caches on Observer devices with Registry public \u00a0  keys and a chain of Attestations or Certificates (tracing a path \u00a0  through the Registry tree).\u00a0  Where is the behavior ensuring a trust relationship between registries described?\u00a0 These are no chains certificates in the X.509 sense. Where is the link between the \u201cDRIP identifier root registries\u201d and the verification of UA traffic?\u00a0 Is that  draft-ietf-drip-auth ? -- Section 5. \u00a0  Optimization of different DRIP Authentication Messages\u00a0 allows an \u00a0  Observer, without Internet connection (offline) or with (online), to \u00a0  be able to validate a UAS DRIP ID in real-time.\u00a0 First is the sending \u00a0  of Broadcast Attestations (over DRIP Link Authentication Messages) \u00a0  [ I-D.ietf-drip-auth ]\u00a0 containing the relevant registration of the UA's \u00a0  DRIP ID in the claimed Registry.\u00a0 Next is sending DRIP Wrapper \u00a0  Authentication Messages that sign over both static (e.g., above \u00a0  registration) and dynamically changing data (such as UA location \u00a0  data).\u00a0 Combining these two sets of information, an Observer can \u00a0  piece together a chain of trust and real-time evidence to make their \u00a0  determination of the UA's claims. How does the use of specific message work if the Observer is offline? As noted above, this is up to the WG, but IMO there is a level of detail here that distracts from the discussion of the architecture.\u00a0 It would be best covered by reference.  ** Section 9 \u00a0  Broadcast RID messages can contain Personally Identifiable \u00a0  Information (PII).\u00a0 A viable architecture for PII protection would be \u00a0  symmetric encryption of the PII using a session key known to the UAS \u00a0  and its USS ... Per \u201cA viable architecture ...\u201d, I\u2019m not sure how to read all the text after the first sentence given this phrasing.\u00a0 Is the rest of the text the official \u201cDRIP architecture\u201d or an example? I\u2019m assuming the former and believe it would benefit from its own set of security considerations.\u00a0 A few initial questions: -- Are there channel security requirements between the decryption oracle/key escrow or distribution server/USS and the Observer? -- Is there a strong authentication/authorization model to gain services from the USS? -- How does this oracle or key server approach work in the case an offline observer?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-21 17:55:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-18 18:53:16-07:00",
    "text": "The description of the QUOTA response in \u00a74.2.1 only says that the response can occur due to GETQUOTA and GETQUOTAROOT, but it is also described as a possible result of SETQUOTA, in \u00a74.1.3.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-10-21 07:36:26-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-11 05:58:12-07:00",
    "text": "DOWNREF [ RFC5257 ] from this Proposed Standard to Experimental  RFC5257 , which the IESG needs to approve on the telechat. (No action for the authors.) I'll note that the ballot write-up suggests a status-change for  RFC5257 , in case an ART AD feels inclined to take this on.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-02-10 19:53:33-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-13 01:11:43-07:00",
    "text": "I agree with Roman that the authorization model seems under-developed. While I recognize that there is need for flexibility across various deployments, I think that we should be providing a default model (and procedures for it) that will apply in many cases, and let deployments specify alternate models if needed.\u00a0 This stuff is hard enough to get right that we should have a secure option that people can use if they don't need to have customized details.\u00a0 (To be clear, I agree with the change of focus from -24 to -25 on the properties that a security policy needs to provide and/or consider, as that is fundamentally the important thing.\u00a0 I just want a fallback/default option that \"does something reasonable in most cases\" in addition. Doing that by reference to some other existing thing would be fine, if such a thing exists.) In particular, the current text seems to rely on the authorization model including: (1) the RD knowing how clients will be using it (and thus what properties the RD needs to enforce), which in the general case cannot be known (though for static networks it could be), yet I don't see any discussion that indicates this as a prerequisite; and (2) the client either knowing out-of-band that an entity is authorized to act as a RD or just blindly trusting any of the unauthenticated (*) advertisement mechanisms.\u00a0 (* Yes, there may be some protection in the network on subscribing to the relevant multicast address, DNS-SD, etc., but the client cannot a priori know that such protections are in place.) Relatedly, the naming model and naming authority should have some clearer discussion.\u00a0 We do mention in Section 7 the possibility for a weak naming model where the RD is responsible for enforcing uniqueness of names but otherwise link attributes are the primary authorization criteria (vs. a traditional scheme with a naming authority and naming hierarchy), but with naming as a fundamental prerequisite of any authentication/authorization scheme, I think clearer discussion of how a naming model is to be selected (and, perhaps more importantly, that it must be fixed as part of a given deployment) for a given network is needed. If I understand correctly, we have some codepoint squatting going on in the examples (e.g., for resource types). We should talk about the security properties of the various RD discovery mechanisms that are defined.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-02-01 03:13:11-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-05 00:31:27-07:00",
    "text": "Thank you for the work put into this document. I am little puzzled by the document shepherd's write-up dated more than one year ago (the responsible AD has even changed and the change is not reflected in the write-up)... while well-written this write-up seems to indicate neither a large consensus nor a deep interest by the CORE WG community. But, I am trusting the past and current responsible ADs on this aspect. Did the authors check with 6MAN WG about the new RDAO option for IPv6 NDP ? I was unable to find any 6MAN email related to this new NDP option and, after checking with the 6MAN WG chairs, they also do not remember any discussion. BTW, I appreciated the use of ASCII art to represent an entity-relationship diagram ! Please find below a couple of non-blocking COMMENTs (and I would appreciate a reply to each of my COMMENTs) and 2 blocking DISCUSS points (but only trivial actions/fixes are required). I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.1 -- It will be trivial to fix, in IPv6 address configuration (SLAAC vs. DHCP) is orthogonal to DHCP 'other-information'. E.g., even if address is configured via SLAAC, DHCPv6 other-information can be used to configure the Recursive DNS Server (or possibly the RD). -- Section 4.1.1 -- Another trivial DISCUSS to fix: in which message is this RDAO sent ? I guess unicast Router Advertisement but this MUST be specified.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-01-29 14:27:36-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 00:05:52-07:00",
    "text": "[[ discuss ]] [ section 4.1.1 ] * Did this get presented to 6man at any point, either via mail to the list or \u00a0 chair or in a presentation slot at an IETF meeting or a 6man interim? \u00a0 I feel confident that there would be no objection to the option as described \u00a0 here, but the working group should have its chance to make an evaluation \u00a0 irrespective of my opinion. \u00a0 --- \u00a0 If this is to be used when link-local methods don't work, another option \u00a0 would have been to add an RD PVD API key and recommend including a PVD \u00a0 option. [ section 4.1.1 & 9.2 ] * Please clarify which ND messages can carry an RDAO.\u00a0 I suspect they should \u00a0 only appear in RAs, but it would be good to state the expectation explicitly. [ Appendix A. ] * Can you explain the ff35:30:2001:db8:1 construction?\u00a0  RFC 3306  section 4 \u00a0 defines some fine-grained structure, and I'm wondering how a group ID of 1 \u00a0 is selected/computed/well known.\u00a0 If there is already a COAP document \u00a0 describing this vis.  RFC 3307  section 4.*, perhaps it's worth dropping a \u00a0 reference in here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-11-15 16:21:25-08:00",
    "end_reason": "position_updated",
    "start": "2020-08-11 19:57:28-07:00",
    "text": "There appear to be a few areas of straightforward, under-specified elements of the authorization model.\u00a0  -- How does the RD know that a node claiming to be a CT is in fact a CT and is permitted to register on behalf of end-points?\u00a0 It seems like there is a missing, simple statement to make that this is configured out of band with the RD?\u00a0 Or is that carrier somehow in a authentication credentials?\t -- Is there are reason why there is not normative guidance requiring the RD to check whether authentication clients are authorized to register particular resources?\u00a0 Section 7.1 covers the issue, but all of Section 7.* is explicitly noted as informative.\u00a0 Section 8.1. says \u201cEndpoint authentication needs to be checked independently of whether there are configured requirements on the credentials for a given endpoint name (Section 7.1) or whether arbitrary names are accepted (Section 7.1.1)\u201d but this text seems to frame it as authentication issue.\u00a0 Section 8.2 seems to stress only the distinction between the registration and lookup API. -- Section 8.1.\u00a0 Per \u201cIf the server does not check whether the identifier provided in the DTLS handshake matches the identifier used at the CoAP layer then it may be inclined to use the endpoint name for looking up what information to provision to the malicious device.\u201d, this is good advice.\u00a0 If DTLS PSK and RPK are used, what identifiers does the RD have to check to ensure the DTLS and CoAP layers match?\u00a0 Per 9.1.3.1. (for PSK) and 9.1.3.2.1 (for RPK) of  RFC7252  there is the notion of identifiers for DTLS but those don\u2019t manifest in CoAP?\u00a0 Additionally, when DTLS with a certificate is used, is it intended to compare the subjectAltName with the authority in the Registration Base URI (i.e., which exact certificate fields should it compare with the CoAP)?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-08-01 07:21:51-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 20:24:58-07:00",
    "text": "# Internet AD comments for { draft-ietf-add-dnr-11 } CC @ekline ## Discuss This seem like exceptionally minor points, but are hopefully easily dispatched. ### S4.1, S5.1, S6.1 * The example ADN encoding in S4.1 shows that the trailing null byte is \u00a0 included in the encoding (the label length of the DNS root). \u00a0 This raises the question: why do any of these options need an explicit \u00a0 ADN length?\u00a0 Given: the ADN is a mandatory message element, must be the \u00a0 first element in the message, and there can be no more than one such \u00a0 element, it seems that parsing bounded by the overall option length \u00a0 and validating the \"RFC1035-ness\" :-) of the span preceding the null byte \u00a0 might save a byte or two? \u00a0 (For comparison: the  RFC 8801  PVD ID FQDN did not require a length hint.) ### S4.1, 6.1 * If an ADN length is to be retained in these messages, why is the ADN length \u00a0 2 bytes in the IPv6 variants whereas in the DHCPv4 option a 1 byte length \u00a0 suffices?\u00a0 I know it seems silly to DISCUSS a 1 byte difference, but I \u00a0 figured it would be easy to either explain or fix. * Similarly, why is the Addr Length 2 bytes? \u00a0 My reckoning of a 1-byte addr length would be the ability to list up to \u00a0 15 IPv6 addresses for a single ADN.\u00a0 With 2 bytes a network can advertise \u00a0 ... over 4000 of them (for a single ADN)? My suspicion is that the variable length nature of the ADN component means these options are easily pushed out of 2/4/8 byte alignment, and there may not be much benefit to attempting to adhere to something that only appears like it might align well. (Being parsimonious with bytes may be more of a concern for RAs than DHCP.)",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-08-03 10:44:23-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 12:00:30-07:00",
    "text": "After reading this document, I am unclear if it is permitted to omit IP addresses from the Encrypted DNS Option. It doesn't help that there are few normative keywords below: (3.1.6) \"In contexts where putting additional complexity on requesting hosts is acceptable, returning an ADN only can be considered.\" (3.1.8) \"the client makes the following validation checks:... the option includes at least one valid IP address and the \"alpn\" service parameter.\" (3.1.9) \"It is RECOMMENDED that at least the following DNR information... A list of IP addresses to locate the encrypted DNS resolver.\" The option formats seem to allow the possibility of having zero addresses. (\"0\" is a multiple of 4 and 16). I *think* you are saying it is possible to include an ADN, IP address(es), or both, but not neither, with \"both\" being RECOMMENDED. But that isn't really compatible with the client rejecting those as invalid in (3.1.8). If that is accurate, I would recommend: - deleting \"at least one valid IP address and\" from (3.1.8) - Updating (3.1.9) to say that while both are RECOMMENDED, at least one of ADN and IP Address(es) MUST be included.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-07-15 15:00:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-07-13 12:46:33-07:00",
    "text": "# Internet AD comments for { draft-ietf-add-dnr-11 } CC @paulwouters ## Discuss The overarching issue of the ADD WG in general is the concern that using the local network's DNS server (encrypted or not) is a privacy concern. With HTTP dying and HTTPS sealing the last plain-text with Encrypted Client Hello (ECH), DNS is the last resort of getting to know the enduser's intent of where they are trying to connect to. There are many parties interested in seeing the DNS query content, but the enduser is rarely able to determine whether the local network used can be trusted. This is true for coffee shops, hotels, malls but also their home ISP. The only clear case of trust is the enterprise user, who is provisioned (forced) via their enterprise management to use specific DNS resolvers. There are a number of well-known public DNS services such as Google DNS (8.8.8.8), Quad9 (9.9.9.9) and Cloudflare (1.1.1.1). Arguably, these servers have a better reputation of protecting the enduser's privacy than most local networks, as endusers cannot trust most local networks they use. The question all of this raises is, whether the user isn't better of just never trusting or using the local network's DNS server, whether encrypted or not. In that case, all of these ADD documents have little value. For example, we see this already with Firefox and its TRR program https://wiki.mozilla.org/Trusted_Recursive_Resolver  and to some extend with the Android phone \"private DNS\" feature https://www.howtogeek.com/795644/how-to-enable-secure-private-dns-on-android/ On the other hand, we have the argument of, if the enduser is using the local unencrypted DNS, it might as well use the local encrypted DNS. While this is true if this decision is hidden from the enduser, if the enduser believes they are using \"encrypted DNS\", they might not be aware that this encrypted connection still reveals all privacy sensitive data to the local network entity (or its trusted third party). An aware enduser might also make different choices when they think their DNS is \"safely encrypted\", such as visiting the website of an abortion provider. That is, the ADD specifications might lure the enduser in a false sense of security. To me this is one of the biggest issues while reviewing the ADD drafts. Are these drafts potentially harmful to the enduser, or does it only offer improvements to the status quo of the current common (non-encrypted) DNS topologies? While the latter could be true, I do believe based on the development seen at Google/Android and Mozilla/Firefox, I think we are already far into the phase where the enduser only decides _which_ remote trustworthy encrypted DNS service they are going to use and as such only use the local network DNS to kickstart their internet connection (captive portal, paywall) after which they switch to remote encrypted DNS service. And that of course, raises an issue with DNS security providers, who wish to monitor and firewall all their DNS clients' DNS requests to improve enduser security. This includes government mandates to ISPs to filter certain DNS requests for local legal reasons. Which again raises the issues of where such filtering power can be abused by authoritative regimes, restrictive cults (eg scientology netnanny). To summarize, I am really on the fence with respect to all the ADD drafts. While \"encrypted DNS\" is always better than \"unencrypted DNS\", the overarching issue of \"never use or trust the local DNS resolvers\" trumps the DNR /DDR protocols. For those who can dictate how their users MUST use DNS (eg Enterprise usage, parental control, opt-in security software), device provisioning/configuration options are available that require no ADD protocols with the exception of draft-ietf-add-svcb-dns. ### Encrypted DNS servers need a public FQDN because otherwise you cannot get a certificate for all connecting clients that are not provisioned with a private/enterprise CA. How do home users run their own without having a public domain? And how do I authenticate the encrypted DNS on 10.1.1.1 that has no FQDN? (and really, has no verifiable identity at all) ### \u00a0 \u00a0  The DNS client verifies the connection based on PKIX validation No CRLs, OneCRL updates, no OCSP, no Certificate Transparency is available without functional DNS. So full PKIX validation as specified here is not available. ### \u00a0 \u00a0  The DNS client uses Web PKI trust anchors by default unless \u00a0 \u00a0  configured otherwise. CAB/Forum is currently, as far as I know, not taking encrypted DNS into account for their BR's. Also, every OS and even some applications use their own \"webpki\" root store that differs from each other. This can lead to interoperability issues. ### Spoofing attacks are mentioned in the document. Obtain _any_ certificate from Let's Encrypt via ACME, eg using \" something.example.com \", then spoof authentication-domain-name on the wifi. While this attack might be blocked by the AP not allowing wifi clients to send packets to each other, this is not true for all networks, and especially not for home networks where the goal is for local clients to be able to connect to each other. Is there a better way to lock the authentication-domain-name? One possible method might be to bind it to the ESSID. eg if the ESSID is  wifi.nohats.ca . one could only allow authentication-domain-name to be a name within  nohats.ca . Some method of reducing the scope of this attack is needed I believe. ### \u00a0  authentication-domain-name (variable length):\u00a0 A fully qualified \u00a0 \u00a0 \u00a0 domain name of the encrypted DNS resolver.\u00a0 This field is \u00a0 \u00a0 \u00a0 formatted as specified in Section 10 of [ RFC8415 ]. \u00a0 \u00a0 \u00a0 An example of the authentication-domain-name encoding is shown in \u00a0 \u00a0 \u00a0 Figure 2.\u00a0 This example conveys the FQDN \" doh1.example.com .\", and \u00a0 \u00a0 \u00a0 the resulting Option-length field is 18. \u00a0 \u00a0 \u00a0  +------+------+------+------+------+------+------+------+------+ \u00a0 \u00a0 \u00a0  | 0x04 |\u00a0  d\u00a0 |\u00a0  o\u00a0 |\u00a0  h\u00a0 |\u00a0 1\u00a0  | 0x07 |\u00a0  e\u00a0 |\u00a0  x\u00a0 |\u00a0  a\u00a0 | \u00a0 \u00a0 \u00a0  +------+------+------+------+------+------+------+------+------+ \u00a0 \u00a0 \u00a0  |\u00a0  m\u00a0 |\u00a0  p\u00a0 |\u00a0  l\u00a0 |\u00a0  e\u00a0 | 0x03 |\u00a0  c\u00a0 |\u00a0  o\u00a0 |\u00a0  m\u00a0 | 0x00 | \u00a0 \u00a0 \u00a0  +------+------+------+------+------+------+------+------+------+ The draft says \"as specified in Section 10 of [ RFC8415 ]\" but that is just a redirect to Section 3.1 of [ RFC1035 ] which doesn't tell me how to encode the NAME. For example, I do not understand why one \".\" is encoded as 0x07 and another \".\" is 0x03 ? ### \u00a0 \u00a0 \u00a0 Addr Length:\u00a0 Length of enclosed IPv6 addresses in octets.\u00a0 When \u00a0 \u00a0 \u00a0 present, it MUST be a multiple of 16. Why not just a one octet counter then? The number of IPv6 addresses that follow. Then the length of the Addr field becomes counter times 16 octets. That seems more constrained than \"multiple of 16\" ### \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The diagrams lack reference octets. What is the width ? or 4 rows ? or ? I assume this is supposed to be 4 octets wide and 16 octets total? eg I would write: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ (also my pet peeve is people using +-+-+-+ instead of -----) ### \u00a0 \u00a0 \u00a0  A value of zero means that this Authentication Domain Name MUST no \u00a0 \u00a0 \u00a0  longer be used. Why not just omit the entry ? Are clients supposed to keep old entries for their entire lifetime even if when asking a new list, those entries no longer appear? That is not clear from this document. Either that should be made explicit, or the values of 0 should not be allowed. ### \u00a0  By default, Encrypted DNS connections received from outside the local \u00a0  network MUST be discarded by the encrypted DNS forwarder in a CPE. What is an \"encrypted DNS forwarder in a CPE\"? This is not defined in the document and I am confused. I assume the CPE announces some encrypted DNS server as either itself or to some external IP at the ISP network? If itself, how can it get a real FQDN the client can verify with PKIX using CAB/Forum ? If to an external IP, isn't it just acting as a NAT/router forwarding packets and then what does it mean to be an \"encrypted DNS forwarder\" ? ### \u00a0  This recommendation is meant to isolate local network \u00a0  DNS resolver services from the public Internet and prevent external \u00a0  attacks against the local Encrypted DNS resolver. \u00a0  If the DHCP responses or RAs are dropped by the attacker, the client \u00a0  can fallback to use a preconfigured encrypted DNS resolver. This raises the big question of why you think that strategy is a \"fallback strategy\" and not the default behaviour of the client. Wouldn't it be more secure if there is no DHCP/RA drop attacks possible? See my introduction text. ### Multihoming is declared out of scope, but realistically most devices we are talking about here are phones, and those are all multihomed. So I feel pretty strongly that it should not be left out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-08 15:18:53-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-15 15:00:09-07:00",
    "text": "# Internet AD comments for { draft-ietf-add-dnr-11 } CC @paulwouters ## Discuss ### How and where a user decides to send their DNS queries impacts their privacy. But the document lists no Privacy Considerations section as per  RFC 6973 ### Encrypted DNS servers need a public FQDN because otherwise you cannot get a certificate for all connecting clients that are not provisioned with a private/enterprise CA. How do home users run their own without having a public domain? And how do I authenticate the encrypted DNS on 10.1.1.1 that has no FQDN? (and really, has no verifiable identity at all) ### \u00a0 \u00a0  The DNS client verifies the connection based on PKIX validation No CRLs, OneCRL updates, no OCSP, no Certificate Transparency is available without functional DNS. So full PKIX validation as specified here is not available. ### \u00a0 \u00a0  The DNS client uses Web PKI trust anchors by default unless \u00a0 \u00a0  configured otherwise. CAB/Forum is currently, as far as I know, not taking encrypted DNS into account for their BR's. Also, every OS and even some applications use their own \"webpki\" root store that differs from each other. This can lead to interoperability issues. ### Spoofing attacks are mentioned in the document. Obtain _any_ certificate from Let's Encrypt via ACME, eg using \" something.example.com \", then spoof authentication-domain-name on the wifi. While this attack might be blocked by the AP not allowing wifi clients to send packets to each other, this is not true for all networks, and especially not for home networks where the goal is for local clients to be able to connect to each other. Is there a better way to lock the authentication-domain-name? One possible method might be to bind it to the ESSID. eg if the ESSID is  wifi.nohats.ca . one could only allow authentication-domain-name to be a name within  nohats.ca . Some method of reducing the scope of this attack is needed I believe. ### \u00a0 \u00a0 \u00a0 Addr Length:\u00a0 Length of enclosed IPv6 addresses in octets.\u00a0 When \u00a0 \u00a0 \u00a0 present, it MUST be a multiple of 16. Why not just a one octet counter then? The number of IPv6 addresses that follow. Then the length of the Addr field becomes counter times 16 octets. That seems more constrained than \"multiple of 16\" ### \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The diagrams lack reference octets. What is the width ? or 4 rows ? or ? I assume this is supposed to be 4 octets wide and 16 octets total? eg I would write: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 \u00a0  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ipv6-address\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 +---------------------------------------------------------------+ (also my pet peeve is people using +-+-+-+ instead of -----) ### \u00a0 \u00a0 \u00a0  A value of zero means that this Authentication Domain Name MUST no \u00a0 \u00a0 \u00a0  longer be used. Why not just omit the entry ? Are clients supposed to keep old entries for their entire lifetime even if when asking a new list, those entries no longer appear? That is not clear from this document. Either that should be made explicit, or the values of 0 should not be allowed. ### \u00a0  By default, Encrypted DNS connections received from outside the local \u00a0  network MUST be discarded by the encrypted DNS forwarder in a CPE. What is an \"encrypted DNS forwarder in a CPE\"? This is not defined in the document and I am confused. I assume the CPE announces some encrypted DNS server as either itself or to some external IP at the ISP network? If itself, how can it get a real FQDN the client can verify with PKIX using CAB/Forum ? If to an external IP, isn't it just acting as a NAT/router forwarding packets and then what does it mean to be an \"encrypted DNS forwarder\" ? ### \u00a0  This recommendation is meant to isolate local network \u00a0  DNS resolver services from the public Internet and prevent external \u00a0  attacks against the local Encrypted DNS resolver. \u00a0  If the DHCP responses or RAs are dropped by the attacker, the client \u00a0  can fallback to use a preconfigured encrypted DNS resolver. This raises the big question of why you think that strategy is a \"fallback strategy\" and not the default behaviour of the client. Wouldn't it be more secure if there is no DHCP/RA drop attacks possible? ### Multihoming is declared out of scope, but realistically most devices we are talking about here are phones, and those are all multihomed. So I feel pretty strongly that it should not be left out of scope.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-07-18 03:55:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-14 03:59:50-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I think that what is being proposed here is useful. I have one minor discuss comment, where I am really just asking for a bit more clarity over which fields are optional in the protocol extensions: \u00a0  ipv6-address(es) (variable length):\u00a0 Indicates one or more IPv6 \u00a0 \u00a0 \u00a0 addresses to reach the encrypted DNS resolver.\u00a0 An address can be \u00a0 \u00a0 \u00a0 link-local, ULA, or GUA.\u00a0 The format of this field is shown in \u00a0 \u00a0 \u00a0 Figure 3. Should this be 0 or more IPv6 addresses if this field is optional (as per the description in option length)?\u00a0  In general, I found it slightly unclear as to which fields are optional to include and which are always present.\u00a0 Possibly, explicitly indicating which fields are optional would add clarity.\u00a0 A similar comment applies to the DHCPv4 packet format, and IPv6 RAs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-31 16:59:42-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-11 10:55:23-07:00",
    "text": "I'm concerned that the scheduling function for autonomous cells can cause an infinite loop in the case of hash collision -- Section 3 specifies that AutoTxCell always takes precedence over AutoRxCell, but if those two cells collide, the corresponding cells on the peer in question will also collide.\u00a0 If both peers try to send at the same time and the hashes collide, they will both attempt to transmit indefinitely and never be received. There seems to be some \"passing the buck\" going on with respect to rate-limiting unauthenticated (join) traffic: draft-ietf-6tisch-minimal-security  (Section 6.1.1) says that the SF \"SHOULD NOT allocate additional cells as a result of traffic with code point AF43\"; this document is implementing a SF, and yet we try to avoid the issue, saying that \"[t]he at IPv6 layer SHOULD ensure that this join traffic is rate-limited before it is passed to 6top sublayer where MSF can observe it\".\u00a0 I think we need a clear and consistent story about where this rate-limiting is supposed to happen.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-02 20:37:56-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-31 16:59:42-07:00",
    "text": "I'm concerned that the scheduling function for autonomous cells can cause an infinite loop in the case of hash collision -- Section 3 specifies that AutoTxCell always takes precedence over AutoRxCell, but if those two cells collide, the corresponding cells on the peer in question will also collide.\u00a0 If both peers try to send at the same time and the hashes collide, they will both attempt to transmit indefinitely and never be received. [I have been persuaded that the rate-limiting situation does not present an inconsistency between documents]",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-05-08 10:18:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-09 17:25:16-07:00",
    "text": "Section 3.\u00a0 Can the normative reference for the SAX algorithm be clarified.\u00a0 The text cites [SAX-DASFAA], but this is an informative reference (and an academic paper with no URL).\u00a0 Appendix B, appears to also describe an algorithm but the introduction describes the text as \u201can example implementation SAX hash function\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-12-15 00:44:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-02 07:46:29-08:00",
    "text": "So there might be something missing here in regards to zero-checksum in UDP when using IPv6. So Section 3.1 in  RFC 7510  discusses this for MPLS over UDP and have some considerations that needs to be done if one are intending to use zero checksum. To me it appears that DETNET flows can not be guaranteed to always fulfill these, and in case you think you can motivate it should probably be stated explicitly and normatively allow it. So if it can't be guaranteed to fulfill these requirements then the next question exists: Do the possibility to use zero-checksum for this flow become something the control plane needs to signal it?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-15 23:32:47-07:00",
    "end_reason": "position_updated",
    "start": "2021-07-01 01:23:19-07:00",
    "text": "Does the 'poll' leaf contain a value measured in seconds as currently stated, or a log2 seconds value (what the \"8-bit signed integer\" of that name in  RFC 5905  holds)?\u00a0 If the former, it should be a wider type than uint8 in order to be able to represent the full set of values. Let's also take another look at the use of nacm:default-deny-all for sensitive authentication-related nodes.\u00a0 My understanding is that typically we only block of the actual secret key material in this way and let the associated metadata (key names, algorithms, etc.) be retrieved.\u00a0 The current module may have default-deny-all in more places than is needed, and we show an example of retrieving key information that ought to have been denied by this ACL. It seems that the current module does not use  RFC 8177  key-chain functionality (despite listing  RFC 8177  as a reference).\u00a0 It seems that best practices for cryptographic configuration would be to use the key-chain functionality, though I may be misunderstanding things.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-02-10 06:08:07-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-28 03:15:08-07:00",
    "text": "Thank you for the work put into this document.  Special thanks for Dieter Sibold as the document shepherd write-up includes text about the WG consensus. Please find below one blocking DISCUSS point (but really trivial and easy to address), some non-blocking COMMENT points (but replies would be appreciated), and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric -- Section 13.1 -- As  RFC 7317  is imported by the YANG module, it must be a normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-10 06:56:34-08:00",
    "end_reason": "position_updated",
    "start": "2021-06-30 09:15:39-07:00",
    "text": "Thank you for the work on this document. I have a simple-to-solve DISCUSS point, and some non blocking comments. Francesca 1. ----- \u00a0 \u00a0 \u00a0 \u00a0 leaf clock-precision { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type int8; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 units \"Hz\"; FP: I believe the units should be seconds here.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2021-04-21 11:10:39-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-20 15:31:08-07:00",
    "text": "This should be a trivial to clear DISCUSS. This text terrifies me: \"It is not considered a fatal error to receive an OPEN message whose (non-extended) Optional Parameters Length value is not 255, and whose first Optional Parameter type code is 255 -- in this case the encoding of this specification MUST be used for decoding the message. A warning MAY be logged.\" It smacks of trying to be too clever, and that the correct response (IMO) when trying to set up a session with something obviously broken is to abort and throw an error. However, I'm sure that there was some discussion, and that the WG decided that this was a good idea; unfortunately I was unable to find anything discussion on this, so all I'm asking for is some reassurance that this was discussed and that this behavior was chosen as a good idea...",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-08 06:03:52-07:00",
    "end_reason": "position_updated",
    "start": "2019-06-25 10:14:42-07:00",
    "text": "I have a small discuss that should be easy to address: Sec 4.3: \" The number of retries are implementation and deployment \u00a0  dependent.\" (and also sec 4.4 point 6) Please specify a maximum number of retries and also a minimum retry interval (of e.g. 3 sec best with exponential back-off)!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-02 17:06:28-07:00",
    "end_reason": "position_updated",
    "start": "2019-03-07 05:59:33-08:00",
    "text": "I think we need to have a bit more clarity on exactly how/what parts of 4916 are updated (per Section 4.3).\u00a0 Thta is, we have some text that's indented as if it's supposed to be logically inserted into a \"revised 4916\", but no indication of where or whether anything else is removed. Furthermore, that text includes section references to portions of 4916 that are incorrect; normally an Update: would point to such text and say \"this is removed\" or \"this is replaced by \", and the current formulation looks like it's constructing a virtual document that is internally inconsistent.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-04-08 19:01:09-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-07 20:24:49-07:00",
    "text": "\u2014 Section 3.1 \u2014 I don\u2019t understand \u201cthe client\u2019s priority decision\u201d: what decision is that?\u00a0 And what\u2019s the point of giving the server a list of algorithms here, given that they all have to be ones that are supported by the server?\u00a0 Won\u2019t the server always have to use the first one in the list?\u00a0 If not, please add some text explaining what the server does. \u2014 Section 3.2 \u2014 \u00a0  If the preview is not available, the server MUST return NIL as the \u00a0  PREVIEW response.\u00a0 A NIL response indicates to the client that \u00a0  preview information MAY become available in a future PREVIEW FETCH \u00a0  request.\u00a0 Note that this is semantically different than returning a \u00a0  zero-length string, which indicates an empty preview. I think the MUST here is hard to follow, because the text doesn\u2019t make a clear enough distinction between \u201cpreview is not available\u201d and \u201can empty preview\u201d.\u00a0 Can you expand the text a bit to explain the distinction more clearly, as this is a protocol requirement?\u00a0 Also, as I noted in response to Meral\u2019s Gen-ART review it would be good to be clear how encrypted messages should be handled in this regard. \u2014 Section 4.1 \u2014 \u00a0  The preview text MUST be treated as text/plain MIME data by the \u00a0  client. I think this requires a normative reference to  RFC 2046 . \u2014 Section 5.1 \u2014 The way you have LAZY working isn\u2019t really consistent with the IMAP protocol model.\u00a0 In that model, the client would not have to ask for the preview twice, one with LAZY and one without.\u00a0 Instead, with LAZY, the server would return FETCH PREVIEW responses when it could \u2014 perhaps some in the first set of FETCH responses, and some, where the PREVIEW part was missing before, in unsolicited FETCH responses when the preview became available.\u00a0 That way, the server has the responsibility of setting off a separate task to generate the previews, and to send them to the client when it has them (at which point it either saves the for future FETCHes or doesn\u2019t). As it\u2019s written here, the client has to open a separate IMAP session with the server and ask a second time for the previews it\u2019s missing \u2014 a separate session to avoid blocking other action on the main session.\u00a0 And if the server has spun off a task to preemptively generate them because the client asked once (a good practice, given the description here) it has to retain them for some indefinite period waiting for the client to ask again. Why was this not done with the first mechanism? \u2014 Section 7 \u2014 As was mentioned in Ben\u2019s review, either the ABNF for \u201ccapability\u201d is in error (it should not include \u201cpreview-mod-ext\u201d) or the description needs to be significantly beefed up.\u00a0 I\u2019m guessing that the intent is that PREVIEW= capabilities include both algorithms and modifiers, that PREVIEW=FUZZY is required, that the presence of any preview algorithm implies PREVIEW=LAZY such that the latter not only need not be specified, but is not permitted to be.\u00a0 So we might have \u201cPREVIEW=FUZZY PREVIEW=FURRY PREVIEW=SLEEPY\u201d, which would mean we support the algorithms FUZZY and FURRY, and the modifiers LAZY and SLEEPY.\u00a0 Is that correct? That seems somewhat obtuse to me, overloading the PREVIEW= capability and inviting confusion. \u2014 Section 8 \u2014 It seems like a bad idea to have to keep the IMAP Capabilities registry in sync with the two new registries: as it stands, when you add a new algorithm you have to add it to the Preview Algorithms registry, and also add a corresponding entry in the Capabilities registry... and similarly for a modifier, if I have that right above. Why not follow the model of AUTH= and RIGHTS=, and just reserve the PREVIEW= capability in the registry, allowing it to apply to entries from the two new registries?\u00a0 That avoids inconsistencies in registrations if we later add algorithms or modifiers.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-09-17 09:12:23-07:00",
    "end_reason": "evaluation_closed",
    "start": "2019-04-08 19:01:09-07:00",
    "text": "\u2014 Section 3.1 \u2014 I don\u2019t understand \u201cthe client\u2019s priority decision\u201d: what decision is that?\u00a0 And what\u2019s the point of giving the server a list of algorithms here, given that they all have to be ones that are supported by the server?\u00a0 Won\u2019t the server always have to use the first one in the list?\u00a0 If not, please add some text explaining what the server does. \u2014 Section 3.2 \u2014 \u00a0  If the preview is not available, the server MUST return NIL as the \u00a0  PREVIEW response.\u00a0 A NIL response indicates to the client that \u00a0  preview information MAY become available in a future PREVIEW FETCH \u00a0  request.\u00a0 Note that this is semantically different than returning a \u00a0  zero-length string, which indicates an empty preview. I think the MUST here is hard to follow, because the text doesn\u2019t make a clear enough distinction between \u201cpreview is not available\u201d and \u201can empty preview\u201d.\u00a0 Can you expand the text a bit to explain the distinction more clearly, as this is a protocol requirement?\u00a0 Also, as I noted in response to Meral\u2019s Gen-ART review it would be good to be clear how encrypted messages should be handled in this regard. \u2014 Section 4.1 \u2014 \u00a0  The preview text MUST be treated as text/plain MIME data by the \u00a0  client. I think this requires a normative reference to  RFC 2046 . \u2014 Section 7 \u2014 As was mentioned in Ben\u2019s review, either the ABNF for \u201ccapability\u201d is in error (it should not include \u201cpreview-mod-ext\u201d) or the description needs to be significantly beefed up.\u00a0 I\u2019m guessing that the intent is that PREVIEW= capabilities include both algorithms and modifiers, that PREVIEW=FUZZY is required, that the presence of any preview algorithm implies PREVIEW=LAZY such that the latter not only need not be specified, but is not permitted to be.\u00a0 So we might have \u201cPREVIEW=FUZZY PREVIEW=FURRY PREVIEW=SLEEPY\u201d, which would mean we support the algorithms FUZZY and FURRY, and the modifiers LAZY and SLEEPY.\u00a0 Is that correct? That seems somewhat obtuse to me, overloading the PREVIEW= capability and inviting confusion. \u2014 Section 8 \u2014 It seems like a bad idea to have to keep the IMAP Capabilities registry in sync with the two new registries: as it stands, when you add a new algorithm you have to add it to the Preview Algorithms registry, and also add a corresponding entry in the Capabilities registry... and similarly for a modifier, if I have that right above. Why not follow the model of AUTH= and RIGHTS=, and just reserve the PREVIEW= capability in the registry, allowing it to apply to entries from the two new registries?\u00a0 That avoids inconsistencies in registrations if we later add algorithms or modifiers.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-04-10 06:34:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-05 14:05:07-07:00",
    "text": "I wavered a lot about whether this was DISCUSS-worthy, but it seems like we should at least talk about how big a risk for future confusion there is: I'm a little confused by the ABNF for 'capability' in Section 7 -- it seems to allow for (e.g.) PREVIEW=LAZYV2, but the introduction and Section 3.1 talk only about *algorithms* in PREVIEW capability responses (and not modifiers).\u00a0 Is the intent to have capability tags for (non-mandatory) priority modifiers?",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-10-05 01:54:02-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-23 02:25:24-07:00",
    "text": "Hi, Thanks for this document.\u00a0 I found it easy to read and understand, but have one potential issue that probably warrants a bit of discussion.\u00a0 I don't have any great knowledge of IMAP, so this may already be handled elsewhere, but I had a concern about returning zero-length strings under error conditions. \u00a0  It is possible that the server has determined that no meaningful \u00a0  preview text can be generated for a particular message, and that \u00a0  decision won't change later.\u00a0 Examples of this involve encrypted \u00a0  messages, content types the server does not support previews of, and \u00a0  other situations where the server is not able to extract information \u00a0  for a preview.\u00a0 In such cases, the server MUST return a zero-length \u00a0  string.\u00a0 Clients SHOULD NOT send another FETCH for a preview for such \u00a0  messages.\u00a0 (As discussed previously, preview data is not immutable so \u00a0  there is chance that at some point in the future the server would be \u00a0  able to generate meaningful text.\u00a0 However, this scenario is expected \u00a0  to be rare so a client should not continually send out requests to \u00a0  try to capture this infrequent occurrence.) \u00a0  \u00a0  ... A server MUST NOT return NIL \u00a0  to a FETCH PREVIEW request made without the LAZY modifier. When the LAZY modifier is not being used, then what would be returned if the server was transiently unable to return the preview for any reason?\u00a0 Does it still have to return a zero-length string in this error case?\u00a0 Is there some way that the server can indicate that it cannot satisfy the request now but without indicating that no preview is available?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-30 09:34:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-03 13:22:32-07:00",
    "text": "(1) Retention practices of cached previews Section 1 says \u201cUsing server generated previews allows global generation once per message, and then cached indefinitely\u201d.\u00a0 Why cache indefinitely, especially if the source messages has been expunged?\u00a0 For privacy reasons, couldn\u2019t this caching be consistent with the retention of the email. In Section 9, Security Considerations, there needs to be discussion of this retention too.\u00a0 Perhaps text like:  \u201cImplementations that pre-generate and store previews MUST ensure that the stored preview is also deleted when the corresponding mail message is expunged.\u201d (2) Protection of previews at rest In Section 9, Security Considerations, there needs to be discussion about the potential sensitivity of these previews and the need to protect them.\u00a0 Perhaps text like: \u201cJust as the messages they summarize, previews may contain sensitive information.\u00a0 When stored, these previews MUST be protected with equivalent authorization and confidentiality controls as the source message.\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-11-30 12:56:14-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-29 07:59:06-08:00",
    "text": "Should these not be a rw value?  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro filter-mode\u00a0 \u00a0 \u00a0 enumeration \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro group* [group-address] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro group-address \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 +--ro source* [source-address] The example in the appendix shows these values being set (so rw): \u00a0 \u00a0 \u00a0 \u00a0 \"group-address\": \"233.252.0.23\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"filter-mode\": \"include\",",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-12-20 04:09:37-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-01 05:35:54-08:00",
    "text": "Hi, My discuss covers two of comments below that I would like to have some discussion on to resolve (further details are in my comments below): (1) The addition/default of the \"enable\" leaf. (2) Name of the interface_name list key rather than just name. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-11-30 18:33:15-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-11-30 18:09:14-08:00",
    "text": "Thank you for being responsive to the SECDIR review threat to improve the security considerations text.\u00a0 Specifically,  https://mailarchive.ietf.org/arch/msg/secdir/GUvFWXP7n9IjXW8xlIdMS5ZE5u0/ . Even after these edits, there are a few straightforward ambiguities to clear up. (a) Section 2.\u00a0 \u201cWhen a network's endpoints do not represent individual users (e.g. in industrial, datacenter, and infrastructure contexts), network operations can often benefit from large-scale data collection without breaching user privacy.\u201d Is network telemetry architecture being restricted to such a limited applicability?\u00a0 To quote the original SECDIR thread, is this saying \u201cThe Network Telemetry Framework is not applicable to networks whose endpoints represent individual users, such as general-purpose access networks\u201d?\u00a0 If so, I\u2019d recommend being that explicit. (b) Section 2.1.\u00a0 \u201cTo preserve user privacy, the user packet content should not be collected.\u201d This is a great principle, but extremely nuanced and potentially complicated to implement.\u00a0 Is this saying (using the words of this framework), \u201cTo preserve the privacy of end-users, no user packet content should be collected.\u00a0 Specifically, the data objects generated, exported, and collected by the Network Telemetry Framework should not include any packet payload from traffic associated with end-users systems\u201d?  (c) Section 2.5.\u00a0 Please use stronger and consistent language. OLD Disclaimer: large-scale network data collection is a major threat to\t user privacy [ RFC7258 ].\u00a0 The network telemetry framework presented in\t this document should not be applied to collect and retain individual\t user data or any data that can identify end users without consent.\t Any data collection or retention using the framework must be tightly\t limited to protect user privacy. NEW Large-scale network data collection is a major threat to user privacy and may be indistinguishable from pervasive monitoring [ RFC7258 ].\u00a0 The network telemetry framework presented in this document must not be applied to generating, exporting, collecting, analyzing or retaining individual user data or any data that can identify end users or characterize their behavior without consent. The principles described in (a), (b) and (c) seems sufficiently important they shouldn\u2019t be scattered across the document.\u00a0 Please either make an applicability statement section early in the document or a dedicated privacy consideration section.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-12-02 06:45:16-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-30 18:33:15-08:00",
    "text": "Thank you for being responsive to the SECDIR review thread to improve the security considerations text.\u00a0 Specifically,  https://mailarchive.ietf.org/arch/msg/secdir/GUvFWXP7n9IjXW8xlIdMS5ZE5u0/ . Even after these edits, there are a few straightforward ambiguities to clear up. (a) Section 2.\u00a0 \u201cWhen a network's endpoints do not represent individual users (e.g. in industrial, datacenter, and infrastructure contexts), network operations can often benefit from large-scale data collection without breaching user privacy.\u201d Is network telemetry architecture being restricted to such a limited applicability?\u00a0 To quote the original SECDIR thread, is this saying \u201cThe Network Telemetry Framework is not applicable to networks whose endpoints represent individual users, such as general-purpose access networks\u201d?\u00a0 If so, I\u2019d recommend being that explicit. (b) Section 2.1.\u00a0 \u201cTo preserve user privacy, the user packet content should not be collected.\u201d This is a great principle, but extremely nuanced and potentially complicated to implement.\u00a0 Is this saying (using the words of this framework), \u201cTo preserve the privacy of end-users, no user packet content should be collected.\u00a0 Specifically, the data objects generated, exported, and collected by the Network Telemetry Framework should not include any packet payload from traffic associated with end-users systems\u201d?  (c) Section 2.5.\u00a0 Please use stronger and consistent language. OLD Disclaimer: large-scale network data collection is a major threat to\t user privacy [ RFC7258 ].\u00a0 The network telemetry framework presented in\t this document should not be applied to collect and retain individual\t user data or any data that can identify end users without consent.\t Any data collection or retention using the framework must be tightly\t limited to protect user privacy. NEW Large-scale network data collection is a major threat to user privacy and may be indistinguishable from pervasive monitoring [ RFC7258 ].\u00a0 The network telemetry framework presented in this document must not be applied to generating, exporting, collecting, analyzing or retaining individual user data or any data that can identify end users or characterize their behavior without consent. The principles described in (a), (b) and (c) seems sufficiently important they shouldn\u2019t be scattered across the document.\u00a0 Please either make an applicability statement section early in the document or a dedicated privacy consideration section.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2016-08-04 06:58:18-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-04 02:19:44-07:00",
    "text": "Thanks, I think this is a very useful and well written document. Sorry for my late discuss but I don't think this is anything complicated to address. Based on the TSV review I agree that this document should say more about congestion control. While the TSV reviewer (Thanks Allison!) only proposes to refer  draft-ietf-avtcore-rtp-circuit-breakers-17  and  draft-ietf-rmcat-cc-requirements-09 , I would even prefer to have a normative sentence that says that congestion control MUST be implemented for all traffic flows.  Please also provide the update on DSCP\u00a0 black-holing (in the middle of a flow) as mentioned by David Black.",
    "type": "Discuss"
  },
  {
    "ad": "Stephen Farrell",
    "end": "2016-08-03 09:00:56-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-03 07:51:08-07:00",
    "text": "I'd like to briefly chat about one aspect of this... Section 3.4: Allowing configuration of STUN/TURN servers from JS makes it easier for a calling server to track a user's call meta-data, if the JS supplied configuration is e.g. always preferred.\u00a0 Shouldn't a browser prefer locally configured servers if those exist and can be used?\u00a0 Or are there other things to be said about which STUN/TURN servers to use when there are multiple choices? (Apologies if this is handled by ICE already, I forget;-)",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-02 20:59:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-02 20:58:01-07:00",
    "text": "Thanks for writing this draft. It really helped clarify a lot of things for me. I do have a concern though. In Section 3.3.\u00a0 Usage of temporary IPv6 addresses, the draft states \" The IPv6 default address selection specification [ RFC6724 ] specifies \u00a0  that temporary addresses [ RFC4941 ] are to be preferred over permanent \u00a0  addresses.\" While this is technically true, this is only the seventh rule in an ordered list of eight rules. e.g. A valid permanent address would be preferred over a deprecated temporary address based on Rule 3. If a host had only a valid permanent address and a deprecated temporary address, the mechanism specified in the draft would result in no addresses being made available, whereas the permanent address would have been an acceptable choice using  RFC6724 .  So, it is not entirely clear to me what the draft is trying to accomplish. It says  \"\u00a0  However, this rule is not completely obvious in the ICE scope.\u00a0 This \u00a0  is therefore clarified as follows:\"   What rule is this talking about when it says \"this rule\"? Similarly, it also says \"When a client gathers all IPv6 addresses on a host...\" but it is not clear what \"client\" the draft is referring to.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-02 20:59:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2016-08-02 20:59:15-07:00",
    "text": "Thanks for writing this draft. It really helped clarify a lot of things for me. I do have a concern though. In Section 3.3.\u00a0 Usage of temporary IPv6 addresses, the draft states \" The IPv6 default address selection specification [ RFC6724 ] specifies \u00a0  that temporary addresses [ RFC4941 ] are to be preferred over permanent \u00a0  addresses.\" While this is technically true, this is only the seventh rule in an ordered list of eight rules. e.g. A valid permanent address would be preferred over a deprecated temporary address based on Rule 3. If a host had only a valid permanent address and a deprecated temporary address, the mechanism specified in the draft would result in no addresses being made available, whereas the permanent address would have been an acceptable choice using  RFC6724 .  So, it is not entirely clear to me what the draft is trying to accomplish. It says  \"\u00a0  However, this rule is not completely obvious in the ICE scope.\u00a0 This \u00a0  is therefore clarified as follows:\"   What rule is this talking about when it says \"this rule\"? Similarly, it also says \"When a client gathers all IPv6 addresses on a host...\" but it is not clear what \"client\" the draft is referring to.  I think if you can clarify what you want to achieve we can work together on some replacement text.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2016-08-04 05:32:56-07:00",
    "end_reason": "position_updated",
    "start": "2016-08-02 20:59:27-07:00",
    "text": "Thanks for writing this draft. It really helped clarify a lot of things for me. I do have a concern though. In Section 3.3.\u00a0 Usage of temporary IPv6 addresses, the draft states \" The IPv6 default address selection specification [ RFC6724 ] specifies \u00a0  that temporary addresses [ RFC4941 ] are to be preferred over permanent \u00a0  addresses.\" While this is technically true, this is only the seventh rule in an ordered list of eight rules. e.g. A valid permanent address would be preferred over a deprecated temporary address based on Rule 3. If a host had only a valid permanent address and a deprecated temporary address, the mechanism specified in the draft would result in no addresses being made available, whereas the permanent address would have been an acceptable choice using  RFC6724 .  So, it is not entirely clear to me what the draft is trying to accomplish. It says  \"\u00a0  However, this rule is not completely obvious in the ICE scope.\u00a0 This \u00a0  is therefore clarified as follows:\"   What rule is this talking about when it says \"this rule\"? Similarly, it also says \"When a client gathers all IPv6 addresses on a host...\" but it is not clear what \"client\" the draft is referring to.  I think if you can clarify what you want to achieve with the address selection we can work together on some replacement text.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2023-01-04 01:14:33-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 00:12:16-08:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-opsawg-service-assurance-yang-10 CC @evyncke Thank you for the work put into this document. A very interesting piece of work and a well-written piece of text (even if I am balloting DISCUSS). The examples are also helping. Please find below some DISCUSS points (+ suggestions), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Michael Richardson for the shepherd's detailed write-up including the WG consensus *but* it lacks the justification of the intended status. It would have been nice to list the implementations (even if I know one). Please note that Tommy Pauly is the Internet directorate reviewer (at my request) and you may want to consider this int-dir reviews as well when Tommy will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-opsawg-service-assurance-yang/reviewrequest/16806/ Also, thanks to the WG chairs and the responsible AD to bundle this I-D and its companion to the same IESG telechat: it helps a lot! I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ###  BCP14  template As noted by  https://author-tools.ietf.org/api/idnits?url=https://www.ietf.org/archive/id/draft-ietf-opsawg-service-assurance-yang-10.txt  and Lars, the  BCP14  template is not correct even if it is required for a proposed standard (it mentions  BCP13  ;-) ). As I have further DISCUSS issues below, I am raising the trivial  BCP14  issue to a blocking DISCUSS. ### Section 3.3 To my SQL eyes, it hurts to use a -1 value for health-score when there is no value. There is no \"mandatory true\" statement for this leaf, i.e., it can be absent in the telemetry. Is there a semantic difference between the absence of health-score and the value of -1 ? Is the SAIN collector expected to process those 2 cases differently ? Suggest to either remove the -1 sentinel value, or add \"mandatory true\" attribute, or be specific about the difference (if any). ### Section 4 It is unclear from this section whether it applies to IETF-specified YANG modules only? I.e., may a vendor augment this IETF YANG module in its own namespace ? I guess so, but worth writing it (or restrict this section to future IETF work only).",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-12-15 07:33:08-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-15 00:22:37-08:00",
    "text": "We can probably sort this out during the IESG telechat, but I want to be sure it's flagged. A number of the shepherd writeup questions were hastily answered and the information we need is largely missing.\u00a0 For instance: -- > What type of RFC publication is being requested on the IETF stream (Best > Current Practice, Proposed Standard, Internet Standard, > Informational, Experimental or Historic)? Why is this the proper type > of RFC? Do all Datatracker state attributes correctly reflect this intent? yes. -- There are three questions here, and only the last of them can be answered \"yes\".\u00a0 The second one is the most interesting one. -- > Several IETF Areas have assembled lists of common issues that their > reviewers encounter. For which areas have such issues been identified > and addressed? For which does this still need to happen in subsequent > reviews? no. -- I don't understand. -- > Have reasonable efforts been made to remind all authors of the intellectual > property rights (IPR) disclosure obligations described in  BCP 79 ? To > the best of your knowledge, have all required disclosures been filed? If > not, explain why. If yes, summarize any relevant discussion, including links > to publicly-available messages when applicable. yes. -- So something's been filed, or reasonable reminders were sent?\u00a0 The datatracker appears to imply this must mean the latter, but it would be great to be clear.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-02 07:48:12-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-29 13:36:57-08:00",
    "text": "There are two errata reports against  RFC 7484 , both in status \"reported\" ( https://www.rfc-editor.org/errata_search.php?rfc=7484&rec_status=15 ). Part of the requirements for advancing a document to Internet Standard is to address all errata reports against the original document.\u00a0 On a superficial reading of the diff from  RFC 7484  to this document it does appear that changes are included that would address these two errata reports, but that should probably be acknowledged in the text, and the responsible AD should use the RFC Editor's errata tool to process the reports accordingly.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-01-25 14:29:36-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-01 02:39:12-08:00",
    "text": "Thank you for the work put into this document. Special congratulations for having THREE implementations including one by the author. Please find below one blocking DISCUSS point (trivial to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). I am also sympathetic to Ben Kaduk's DISCUSS point. Special thanks to Jasdip Singh for the shepherd's write-up including the section about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric -- Section 5.2 -- The end of this section uses \" https://example.net/rdaprir2/ip/2001:0db8:1000::/48 \" (not  RFC 5952  compatible with the leading zero in front of \"db8\") as an example but this example seems to contradict section 3.1.1 of  RFC 9082 .",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-24 19:46:43-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-08 06:05:54-07:00",
    "text": "I support Roman's DISCUSS. I'm also unclear on the over-arching recommendation this document is making for securely deploying this protocol. Given that the protocol itself is insecure, I would have expected some normative requirement for correcting that (e.g., Minimally, Babel deployments MUST be secured using a lower-layer security mechanism, Babel over DTLS, or HMAC-based authentication.) This still would not bring it into line with  BCP 61  Section 7, but perhaps there is some argument for making an exception for this protocol.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-08-07 06:28:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 06:27:33-07:00",
    "text": "I really enjoyed reading this document!\u00a0 Thank you for the work and time that has gone into it. However, I don't think that this specification is ready to be published as a Proposed Standard.\u00a0 In general, I don't think that the document is clear or specific enough to be considered in the Standards Track -- that is the main reason for this DISCUSS. (A) Clear Defaults and Operational Guidance While I appreciate Babel's flexibility in terms of the ability to use different strategies, I believe that both defaults and clear guidance should be provided.\u00a0 Given that \"not all...strategies will give good results\" and that in most cases these are listed as possible choices, I don't think that this document \"has resolved known design choices\" [ BCP9 /rfc7127].\u00a0 The cost/metric computation and route selection specially concern me because I believe that a robust/clear specification is at the heart of any routing protocol. In general what I am looking for to resolve this part of the DISCUSS are two items: (1) Clear defaults.\u00a0 For example, Appendix B talks about constants/default values.\u00a0 I would assume that, given the existing experience, that the values there are probably sensible defaults.\u00a0 Is that not the case?\u00a0  (2) Operational Considerations.\u00a0 Given that Babel can be (and is) used in different environments, I would like to see guidance to operators as they deploy the protocol in their networks.\u00a0 An example of the type of discussion I would like to see expanded is: \"a mobile node that is low on battery may choose to use larger time constants (hello and update intervals, etc.) than a node that has access to wall power\" (\u00a71.1).\u00a0 Consider \u00a72 in  rfc5706  (Operational Considerations - How Will the New Protocol Fit into the Current Environment?). I believe that both items are important, specially in a protocol as flexible as Babel.\u00a0 Some of this guidance could have been included in  draft-ietf-babel-applicability  -- but this information is not there either. (B) Error Handling Many sections of the document describe functionality, or even Normatively mandate it, but there is no discussion about Error Handling. (1) Router-Id Setting \u00a74.5: \u00a0  o\u00a0 the current router-id; this is undefined at the start of the \u00a0 \u00a0 \u00a0 packet, and is updated by each Router-ID TLV (Section 4.6.7) and \u00a0 \u00a0 \u00a0 by each Update TLV with Router-Id flag set. It took me some time to figure out the reason for being able to carry the router-id in two different places inside the same packet, which is my interpretation of the \"and\" above.\u00a0 Let me see if I understood:\u00a0 a packet can carry multiple updates...updates contain routes that were either originated by the local node, OR, learned from other routers...the router-id matches the originator...\u00a0 So...if a packet carries multiple updates, some locally originated and some learned, then it is possible for the packet to first include (for example) a Router-ID TLV (indicating router-id_A), followed by some Update TLVs (without the R-bit set), than then some other Update TLVs (with the R-bit set)...\u00a0  Did I understand correctly?\u00a0 If so, I think there are significant pieces of this operation that are not clearly specified in the document.\u00a0 There is mention of the effect of the Router-ID TLV (or the Update TLV w/R=1) on subsequent Update TLVs...there is an very subtle hint (for my taste) in \u00a74.5 (Parser state) about the state learned for each packet from those TLVs...but there is no explicit text that talks about the need for strict ordering when sending and later when processing...it is all simply implied. What should happen if no Router-Id has been defined?\u00a0 For example, an Update (R = 0) is received but no Router-ID TLV is present...\u00a0 What if the Router-ID TLV is present, but *after* the Update?\u00a0 There are many possible combinations... (2) Default Prefix Similar comments as above...\u00a0 \"P (Prefix) flag...establishes a new default prefix for subsequent Update TLVs with a matching address encoding within the same packet\" (\u00a74.6.9).\u00a0  What if an update with an AE that allows compression is received *before* the one that sets the new default prefix? (3) Next Hop \u00a74.6.9: \u00a0  The next-hop address for this update is taken from the last preceding \u00a0  Next Hop TLV with a matching address family (IPv4 or IPv6) in the \u00a0  same packet even if it was otherwise ignored due to an unknown \u00a0  mandatory sub-TLV; if no such TLV exists, it is taken from the \u00a0  network-layer source address of this packet. What if the Next Hop TLV doesn't exist and the network-layer doesn't correspond to the address family in the Update?\u00a0 For example, let's say IPv6 is used as the network-layer protocol and the Update contains IPv4 prefixes... (4) For the Normative behavior listed here (I may have missed other instances), I have basically the same question: what should a receiver do if it is not the case? - \u00a73.8.1.2: \"A node MUST NOT increase its sequence number by more than 1 in response to a seqno request.\" - \u00a74: \"A Babel packet MUST be sent as the body of a UDP datagram, with network-layer hop count set to 1...\"\u00a0  - \u00a74.6.9: \"If the metric is finite, AE MUST NOT be 0.\u00a0 If the metric is infinite and AE is 0, Plen and Omitted MUST both be 0.\"\u00a0  - \u00a74.6.10: \"...if AE is 0 (in which case Plen MUST be 0 and Prefix is of length 0).\" - \u00a74.6.10/\u00a74.6.11: Is AE 3 a valid value in a request?\u00a0 I assume it isn't.\u00a0 What should a receiver do if AE = 3. (C) Mandatory Bit \u00a74.4: \"The most-significant bit of the sub-TLV, called the mandatory bit...\"\u00a0 The most significant bit of which part of the sub-TLV?\u00a0 As written, that bit would be the first one in the Type, which corresponds to the text in the IANA section.\u00a0 Please be specific. In the IANA considerations section, please include the whole registry in the table to avoid confusion. Note that because of the mandatory bit, the 128-239 range should be Reserved...but it is currently marked as Unassigned.\u00a0 Even worse, value 128 is assigned already [ draft-ietf-babel-source-specific ].\u00a0 The impact may not be too bad because I doubt that Pad1 would need to be mandatory, but it at least causes confusion and inconsistency, and (as currently specified) there would be no way to differentiate between Pad1 and the Source Prefix sub-TLV.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-08-03 07:12:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 06:28:50-07:00",
    "text": "I really enjoyed reading this document!\u00a0 Thank you for the work and time that has gone into it. However, I don't think that this specification is ready to be published as a Proposed Standard.\u00a0 In general, I don't think that the document is clear or specific enough to be considered in the Standards Track -- that is the main reason for this DISCUSS. (A) Clear Defaults and Operational Guidance While I appreciate Babel's flexibility in terms of the ability to use different strategies, I believe that both defaults and clear guidance should be provided.\u00a0 Given that \"not all...strategies will give good results\" and that in most cases these are listed as possible choices, I don't think that this document \"has resolved known design choices\" [ BCP9 /rfc7127].\u00a0 The cost/metric computation and route selection specially concern me because I believe that a robust/clear specification is at the heart of any routing protocol. In general what I am looking for to resolve this part of the DISCUSS are two items: (A1) Clear defaults.\u00a0 For example, Appendix B talks about constants/default values.\u00a0 I would assume that, given the existing experience, that the values there are probably sensible defaults.\u00a0 Is that not the case?\u00a0  (A2) Operational Considerations.\u00a0 Given that Babel can be (and is) used in different environments, I would like to see guidance to operators as they deploy the protocol in their networks.\u00a0 An example of the type of discussion I would like to see expanded is: \"a mobile node that is low on battery may choose to use larger time constants (hello and update intervals, etc.) than a node that has access to wall power\" (\u00a71.1).\u00a0 Consider \u00a72 in  rfc5706  (Operational Considerations - How Will the New Protocol Fit into the Current Environment?). I believe that both items are important, specially in a protocol as flexible as Babel.\u00a0 Some of this guidance could have been included in  draft-ietf-babel-applicability  -- but this information is not there either. (B) Error Handling Many sections of the document describe functionality, or even Normatively mandate it, but there is no discussion about Error Handling. (B1) Router-Id Setting \u00a74.5: \u00a0  o\u00a0 the current router-id; this is undefined at the start of the \u00a0 \u00a0 \u00a0 packet, and is updated by each Router-ID TLV (Section 4.6.7) and \u00a0 \u00a0 \u00a0 by each Update TLV with Router-Id flag set. It took me some time to figure out the reason for being able to carry the router-id in two different places inside the same packet, which is my interpretation of the \"and\" above.\u00a0 Let me see if I understood:\u00a0 a packet can carry multiple updates...updates contain routes that were either originated by the local node, OR, learned from other routers...the router-id matches the originator...\u00a0 So...if a packet carries multiple updates, some locally originated and some learned, then it is possible for the packet to first include (for example) a Router-ID TLV (indicating router-id_A), followed by some Update TLVs (without the R-bit set), than then some other Update TLVs (with the R-bit set)...\u00a0  Did I understand correctly?\u00a0 If so, I think there are significant pieces of this operation that are not clearly specified in the document.\u00a0 There is mention of the effect of the Router-ID TLV (or the Update TLV w/R=1) on subsequent Update TLVs...there is an very subtle hint (for my taste) in \u00a74.5 (Parser state) about the state learned for each packet from those TLVs...but there is no explicit text that talks about the need for strict ordering when sending and later when processing...it is all simply implied. What should happen if no Router-Id has been defined?\u00a0 For example, an Update (R = 0) is received but no Router-ID TLV is present...\u00a0 What if the Router-ID TLV is present, but *after* the Update?\u00a0 There are many possible combinations... (B2) Default Prefix Similar comments as above...\u00a0 \"P (Prefix) flag...establishes a new default prefix for subsequent Update TLVs with a matching address encoding within the same packet\" (\u00a74.6.9).\u00a0  What if an update with an AE that allows compression is received *before* the one that sets the new default prefix? (B3) Next Hop \u00a74.6.9: \u00a0  The next-hop address for this update is taken from the last preceding \u00a0  Next Hop TLV with a matching address family (IPv4 or IPv6) in the \u00a0  same packet even if it was otherwise ignored due to an unknown \u00a0  mandatory sub-TLV; if no such TLV exists, it is taken from the \u00a0  network-layer source address of this packet. What if the Next Hop TLV doesn't exist and the network-layer doesn't correspond to the address family in the Update?\u00a0 For example, let's say IPv6 is used as the network-layer protocol and the Update contains IPv4 prefixes... (B4) For the Normative behavior listed here (I may have missed other instances), I have basically the same question: what should a receiver do if it is not the case? - \u00a73.8.1.2: \"A node MUST NOT increase its sequence number by more than 1 in response to a seqno request.\" - \u00a74: \"A Babel packet MUST be sent as the body of a UDP datagram, with network-layer hop count set to 1...\"\u00a0  - \u00a74.6.9: \"If the metric is finite, AE MUST NOT be 0.\u00a0 If the metric is infinite and AE is 0, Plen and Omitted MUST both be 0.\"\u00a0  - \u00a74.6.10: \"...if AE is 0 (in which case Plen MUST be 0 and Prefix is of length 0).\" - \u00a74.6.10/\u00a74.6.11: Is AE 3 a valid value in a request?\u00a0 I assume it isn't.\u00a0 What should a receiver do if AE = 3. (C) Mandatory Bit \u00a74.4: \"The most-significant bit of the sub-TLV, called the mandatory bit...\"\u00a0 The most significant bit of which part of the sub-TLV?\u00a0 As written, that bit would be the first one in the Type, which corresponds to the text in the IANA section.\u00a0 Please be specific. In the IANA considerations section, please include the whole registry in the table to avoid confusion. Note that because of the mandatory bit, the 128-239 range should be Reserved...but it is currently marked as Unassigned.\u00a0 Even worse, value 128 is assigned already [ draft-ietf-babel-source-specific ].\u00a0 The impact may not be too bad because I doubt that Pad1 would need to be mandatory, but it at least causes confusion and inconsistency, and (as currently specified) there would be no way to differentiate between Pad1 and the Source Prefix sub-TLV.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-22 13:14:01-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 15:13:10-07:00",
    "text": "I don't think that all of the arithmetic specified in Section 3.2.1 is well defined.\u00a0 Specifcally, the formulations involving bitwise AND assume that the input to the bitwise AND is nonnegative, which does not seem to be implied by the other stated constraints.\u00a0 (For example, an \"integer n\" may well be negative.)\u00a0 Some discussion of the representation of negative integers would then be needed, and then whether the mathematical operation is performed in an abstract infinite-precision machine or in a realizable approximation, etc..\u00a0 It might be simpler to just use the modular arithmetic flavor and avoid any of the issues that can arise when providing two alternative definitions that are intended to be equivalent (since there is always a risk of edge cases). Section 3.5.2 needs to explicitly say that the c and m arguments to M() are the local link cost and the advertised metric, e.g., \"the function M(c, m) used for computing a metric from a locally computed link cost c and the metric m advertised by a neighbor\". Section 3.8.2.1 notes that \"[d]ue to duplicate suppression, only a small number of such requests will actually reach the source.\" (for seqno requests intending to avoid starvation).\u00a0 But Section 3.8.1.2 only has a SHOULD-level requirement to suppress duplicate seqno requests, so I think there is an internal inconsistency. I think we may need to have a discussion about the feasibility of multicast acknowledgment requests with only a 16-bit nonce.\u00a0 With random assignment of nonces the risk of birthday collisions becomes uncomfortably large, and non-random assignments are likely to have worse pathologies.\u00a0 (A pointer to a previous discussion of this topic would, of course, short-circuit a lot of it if not all of it.)\u00a0 Are we willing to make hard assumptions about the maximum size of a multicast domain and the risk of collision we are willing to accept? The discussion in Section 4.6.9 of computing the prefix from an Update message (and parser state) seems a little underspecified when the prefix length is not a multiple of 8 bits.\u00a0 (Additionally, \"Plen\" is not described as measuring bits, explicitly, for any of the PDU descriptions that I remember.)\u00a0 Specifically, the \"Prefix\" description does not mention that any trailing bits must be set to zero, but the subsequent discussion about the prefix is \"computed as follows\" refers to assembling the prefix as a collection of octets, including trailing zero octets, implying that the computed prefix is the full length of the address type. I appreciate that we have some discussion in Section 4.5 about the need for a stateful parser for the babel packet body; this seems like one of the riskiest areas of the protocol from the implementation perspective. However, I think it would be even more helpful to explicitly call out what pieces of state are needed, what protocol elements affect the state, and what ordering requirements (or non-requirements) there are for the interactions between the different protocol elements that affect parser state.\u00a0 Can we have a discussion about whether it's appropriate to add some text along these lines?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-07 04:29:27-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 04:28:53-07:00",
    "text": "I have a couple of points that needs addressing before this document can move forward. Most of them should the straight forward to address. My main point is about network load. Thanks for discussing network load and correctly adding some warnings at the right places, however, for a PS track document I would like to see more than this. Usually it's good provide default values were suitable (as this often is what people will then pick if there is no good reason to diverge) and more important I really like to see min/max values. Note that  RFC8085  recommend a minimal interval of 3 seconds which probably is also a good hard boundary here.  More concretely I think there are these cases that need more guidance: - Section 3.7.2. (Triggered Updates) advises to send a message multiple times for redundancy in case of loss. 5 and 2 are mentioned as example values. Please provide a normative default value and a normative maximum value here. Moreover the spec should also require to pace out these messages and avoid \"tail loss\" by overloading the local queue.\u00a0 (See also section 3.8.2.1) -Section\u00a0 3.8.1.1.\u00a0 (Route Requests) says: \"Full route dumps MAY be rate-limited, especially \u00a0  if they are sent over multicast.\" I think this should at least be a SHOULD. Please also provide further guidance about to appropriately rate limit and think about other cases where a recommend to implement rate-limiting could make sense. - In section 4.1.1 the update interval needs a lower limit (e.g. 3 seconds) and a recommend default value would be could as well (Note that there are other part in section 3 where the update value is discussed as well). - Section 3.8.2.4. mentions network load when requests are sent to all neighbours after reboot. Please provide more guidance about how to pace out these requests. - Section 3.8.1.2.\u00a0 (Seqno Requests) discusses hop count values but could maybe also give more concrete guidance. I would assume that the hop count value of the current active route is usually know. Maybe that knowledge could be used to pick an appropriate value? Two other smaller discuss points/questions/comments: 1) Sec 4.6.8. (Next Hop): If I interpret this correctly, address compression is allowed for the next hop field and therefore this TLV would actually not be self-terminating. What do I miss? 2) This document needs to specify a registration policy also for each of\u00a0 the already existing registries given this document obsoletes  RFC7557 .",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-07 05:14:32-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 04:29:27-07:00",
    "text": "I have a couple of points that needs addressing before this document can move forward. Most of them should the straight forward to address. My main point is about network load. Thanks for discussing network load and correctly adding some warnings at the right places, however, for a PS track document I would like to see more than this. Usually it's good provide default values were suitable (as this often is what people will then pick if there is no good reason to diverge) and more important I really like to see min/max values. Note that  RFC8085  recommend a minimal interval of 3 seconds which probably is also a good hard boundary here.  More concretely I think there are these cases that need more guidance: - Section 3.7.2. (Triggered Updates) advises to send a message multiple times for redundancy in case of loss. 5 and 2 are mentioned as example values. Please provide a normative default value and a normative maximum value here. Moreover the spec should also require to pace out these messages and avoid \"tail loss\" by overloading the local queue.\u00a0 (See also section 3.8.2.1) - Section\u00a0 3.8.1.1.\u00a0 (Route Requests) says: \"Full route dumps MAY be rate-limited, especially \u00a0  if they are sent over multicast.\" I think this should at least be a SHOULD. Please also provide further guidance about to appropriately rate limit and think about other cases where a recommend to implement rate-limiting could make sense. - In section 4.1.1 the update interval needs a lower limit (e.g. 3 seconds) and a recommend default value would be could as well (Note that there are other part in section 3 where the update value is discussed as well). - Section 3.8.2.4. mentions network load when requests are sent to all neighbours after reboot. Please provide more guidance about how to pace out these requests. - Section 3.8.1.2.\u00a0 (Seqno Requests) discusses hop count values but could maybe also give more concrete guidance. I would assume that the hop count value of the current active route is usually know. Maybe that knowledge could be used to pick an appropriate value? Two other smaller discuss points/questions/comments: 1) Sec 4.6.8. (Next Hop): If I interpret this correctly, address compression is allowed for the next hop field and therefore this TLV would actually not be self-terminating. What do I miss? 2) This document needs to specify a registration policy also for each of\u00a0 the already existing registries given this document obsoletes  RFC7557 .",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-07 02:03:50-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 05:14:32-07:00",
    "text": "(Sorry I forgot two points about the appendix; see one in the discuss section and one in the comment section) I have a couple of points that needs addressing before this document can move forward. Most of them should the straight forward to address. My main point is about network load. Thanks for discussing network load and correctly adding some warnings at the right places, however, for a PS track document I would like to see more than this. Usually it's good provide default values were suitable (as this often is what people will then pick if there is no good reason to diverge) and more important I really like to see min/max values. Note that  RFC8085  recommend a minimal interval of 3 seconds which probably is also a good hard boundary here.  More concretely I think there are these cases that need more guidance: - Section 3.7.2. (Triggered Updates) advises to send a message multiple times for redundancy in case of loss. 5 and 2 are mentioned as example values. Please provide a normative default value and a normative maximum value here. Moreover the spec should also require to pace out these messages and avoid \"tail loss\" by overloading the local queue.\u00a0 (See also section 3.8.2.1) - Section\u00a0 3.8.1.1.\u00a0 (Route Requests) says: \"Full route dumps MAY be rate-limited, especially \u00a0  if they are sent over multicast.\" I think this should at least be a SHOULD. Please also provide further guidance about to appropriately rate limit and think about other cases where a recommend to implement rate-limiting could make sense. - In section 4.1.1 the update interval needs a lower limit (e.g. 3 seconds) and a recommend default value would be could as well (Note that there are other part in section 3 where the update value is discussed as well). - Section 3.8.2.4. mentions network load when requests are sent to all neighbours after reboot. Please provide more guidance about how to pace out these requests. - Section 3.8.1.2.\u00a0 (Seqno Requests) discusses hop count values but could maybe also give more concrete guidance. I would assume that the hop count value of the current active route is usually know. Maybe that knowledge could be used to pick an appropriate value? Three other smaller discuss points/questions/comments: 1) Sec 4.6.8. (Next Hop): If I interpret this correctly, address compression is allowed for the next hop field and therefore this TLV would actually not be self-terminating. What do I miss? 2) This document needs to specify a registration policy also for each of\u00a0 the already existing registries given this document obsoletes  RFC7557 . 3) Appendix D (Stub Implementations) contain normative language and therefore should probably be moved into the body of the draft.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-11-11 12:45:40-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 12:19:44-07:00",
    "text": "Security Considerations.\u00a0 While the high level statement of Babel being \u201can insecure protocol\u201d is accurate and clear, precisely enumerating the threats is needed to motivate the selection of the appropriate mitigations.\u00a0  (1) Per \u201cAny attacker can misdirect data traffic by advertising routes with a low metric or a high seqno.\u201d: -- Can the \"any\" of the attacker be scoped any more? -- Explain why this is possible \u2013 because Babel peers are not authenticated and Babel messages aren\u2019t integrity/replay protected -- Discuss the impact of this misdirection: denial of service (dropping the traffic and against a given target), eavesdropping, or allowing for the possibility of traffic modification (depending on upper level security mechanisms) \u2013  RFC4593  covers a number of them -- Note that because Babel messages aren\u2019t encrypted any on-path attacker can gather the routing topology (2) The rest of this paragraph describes the security properties conveyed by link-layer security, IPSec, BABEL-HMAC and BABEL-TLS.\u00a0 They all make sense.\u00a0 Please be explicit that IPSec or BABEL-TLS address all of the above described attacks.\u00a0 BABEL-HMAC addresses only somet. (3) Per \u201cHMAC is simpler and does not depend on DTLS, and therefore its use is RECOMMENDED whenever both mechanisms are applicable\u201d, can you explain this recommendation and the circumstances where \u201cboth mechanisms are applicable\u201d.\u00a0 If one wants to ensure confidentiality, it can\u2019t be realized with HMAC \u2013 they aren\u2019t equal. (4) Per \u201cThe privacy issues that this causes can be mitigated somewhat by using randomly chosen router-ids and randomly chosen IP addresses, and changing them periodically, who\u2019s IP address should be randomly chosen the Babel node or the mobile device? In other sections: (5) Appendix C: Per the last paragraph, \u201cThe packet trailer is intended to carry cryptographic signatures \u2026\u201d, to what security mechanism is that referring?\u00a0 Where is that defined? (6) Appendix D: Is the stub implementation guidance normative?\u00a0 If so, will it satisfy all of the  RFC2119  language in this document? (7) Appendix E.\u00a0 Please explicitly state that the sample implementation is non-normative.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-08-08 05:48:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-08 05:45:32-07:00",
    "text": "Thanks for your work on this well written document. Most of the issues I found have been covered in the ballot positions of my esteemed colleagues. I did have one major concern that I would like to see addressed though. This is in regard to backward compatibility with  RFC6126  implementations. Due to the addition of the mandatory bit and the processing associated with it, I would think that the new implementations will not be able to properly interoperate with the existing  RFC6126  implementations. Is my understanding correct? If so, I would like to see some text explaining what is the expected behavior when deploying into legacy environments.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2019-08-20 13:57:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-08 05:48:03-07:00",
    "text": "Thanks for your work on this well written document. Most of the issues I found have been covered in the ballot positions of my esteemed colleagues. I did have one major concern that I would like to see addressed though. This is in regard to backward compatibility with  RFC6126  implementations. Due to the addition of the mandatory bit and the processing associated with it, I would think that the new implementations will not be able to properly interoperate with the existing  RFC6126  implementations. Is my understanding correct? If so, I would like to see some text explaining what is the expected behavior when deploying into legacy environments. If not, I would greatly appreciate an explanation and I will clear.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-17 20:53:45-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-18 14:19:46-08:00",
    "text": "In Section 2.3 we refer to the datagram_tag plus layer-2 sender address as being \"a globally unique identifier for the datagram\", but I think this can only hold within some time-bounded window (e.g., the lifetime of the packet), since the tag space is finite and reuse somewhat inevitable.\u00a0 [The simplest way to resolve this is probably to just remove the definition from this document and refer to draft-ietf-6lo-minimal-fragment  for definitions.] I think we should be more clear about whether a \"FULL bitmap\" always has 32 bits set to one, or if \"merely\" having as many bits as the sender sent fragments set to one also counts as \"FULL\".\u00a0 The current text seems to invite different interpretations by implementations.\u00a0 (If FULL does mean all 32 bits, then the semantics of the other case seem unclear to me.) What's the transition/backwards-compatibility story?\u00a0 That is, how does a sender know that all nodes on the path support the RFRAG dispatch types, and what happens if they are sent anyway and get to a node that doesn't implement them? I have grave misgivings about allowing a packet (as identified by sender and tag) to be refragmented by the sender so that a single fragment sequence number is used for fragments of different lengths.\u00a0 We do not seem to provide a mechanism to distinguish which variant of that fragment is being ack'd, which could lead to disagreement between sender and receiver as to whether a full packet is reconstructed. Brainstorming, it might be possible to allow such refragmenting at the sender by using a Fragment_Size of zero to indicate \"this fragment is superseded\" and allocating new sequence number for all its components. (I didn't attempt to do an exhaustive check on whether that proposal is flawed and Fragment_Size of zero already has some existing semantics that would be in conflict.)",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-22 11:09:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 05:55:15-08:00",
    "text": "Thanks for this well written document, however, I have a couple points below that need further clarification, all mostly related to congestion control. From an editorial point of view most of this is discussed either in the intro text of section 6, then some part in 7.1, and some in the appendix C. I would really recommend you to instead have a separate section that much clearer states what should be done by default (probably no dynamically window but a small fixed window with maybe size of 1) and what could be don as further optimisation, and also to discuss the parameter/variables there before the algorithms are discussed. And a bit of a provoking question: wouldn't it be easier to just use a reliable transport protocol on top? If this mechanism is intended to be used over a short path with a few hops only (in a local network), I think this should be stated more clearly at the beginning of the document.  In the appendix you state this: \" In addition, deploying such a mechanism requires \u00a0  that the end-to-end transport is aware of the delivery properties of \u00a0  the underlying LLN,...\" But I'm not sure what you mean...? Can you further explain? 1) Sec 6: \"Upon exhaustion of the retries the \u00a0  sender may either abort the transmission of the datagram or retry the \u00a0  datagram from the first fragment with an 'X' flag set in order to \u00a0  reestablish a path and discover which fragments were received over \u00a0  the old path in the acknowledgment bitmap. \" I'm not sure about this \"or\". Why should the first fragment be more successful than any other which requests an ACK? Also if you really want to keep this condition, you need to specify it better. How often do you retry? I guess you need to set the PTO again...? Further the RTO should also implement an exponential back-off. 2) sec 6.3: \"Upon an acknowledgment with a NULL bitmap, the sender endpoint \u00a0  MUST abort the transmission of the fragmented datagram with one \u00a0  exception: In the particular case of the first fragment, it MAY \u00a0  decide to retry via an alternate next hop instead.\" What's mean with \"In the particular case of the first fragment\"? And does this mean it should retry only with the first fragment or the whole transmission. However, if this signal is from the receiving endpoint why should that endpoint change it mind only if a different path is used? If the assumption is that this NULL bitmap is sent by an intermediate node? However, then it would make sense to\u00a0 rather signal this information explicitly (e.g. using a flag). 3) Sec 7.1 (and to some extend sec 6) \"\u00a0  OptWindowSize:\u00a0 The OptWindowSize is the value for the Window_Size \u00a0 \u00a0 \u00a0 that the sender should use to start with.\u00a0 It is greater than or \u00a0 \u00a0 \u00a0 equal to MinWindowSize.\u00a0 It is less than or equal to \u00a0 \u00a0 \u00a0 MaxWindowSize.\u00a0 The Window_Size should be maintained below the \u00a0 \u00a0 \u00a0 number of hops in the path of the fragment to avoid stacking \u00a0 \u00a0 \u00a0 fragments at the bottleneck on the path.\u00a0 If an inter-frame gap is \u00a0 \u00a0 \u00a0 used to avoid interference between fragments then the Window_Size \u00a0 \u00a0 \u00a0 should be at most on the order of the estimation of the trip time \u00a0 \u00a0 \u00a0 divided by the inter-frame gap.\" This needs normative language and more explanation. I recommend to even say that if no congestion control (as discussed in the appendix) is applied, the Window MUST be set to 1. Further, the assumption that the window can or should be set to (at maximum) the number of hop does seem correctly to me. No matter how many hops there are packets are only queued at the bottleneck (the link where the current rate is smaller than the sending rate) and it depends on the sending rate of the bottleneck link how many packets need to be queued. This is completely independent of the number of hops. Further, even if that would be true, as long as this document does not discuss also away to estimate or know the number of hops, this advise would unfortunately be useless... Further I don't think pointing to  rfc6298  for RTT calculation is sufficient (as done in the appendix).  rfc6298  assume frequent ACKs and a reasonably large window, which is both not the case here. All in all, any window adjustments itself are not described at all. What should be done when a congestion marking is received? How does the window need to be adjusted based on an RTO? When should the window be increased again? And how much? 4) Sec 7.1.: Inline with the TSV-ART review (Thanks Collin!), the parameters need more guidance. Especially for he number of retries it should be possible to recommend a default value (e.g. 3) and it would be good to also give an upper limits (MUST NOT be larger than X). Similar for the window size: there should be also at least a default value (see comment above). And further the RTO needs further explanation about how to find a reasonable value. If the RTO is configured (and not estimated dynamically) e.g. it could be set to 3x the maximum expected RTT in the respective network. And it would be even better to provide a minimum default (initial) value. Not that TCP is also designed to work on a large variety of timescales and a minimum initial value of 1s is seen as safe for all Internet scenarios. It's really important to also provide some recommendations like this here. 5) Sec 7.2: \"The management system should monitor the number of retries and of ECN \u00a0  settings that can be observed from the perspective of both the sender \u00a0  and the receiver, and may tune the optimum size of Fragment_Size and \u00a0  of Window_Size, OptFragmentSize, and OptWindowSize, respectively, at \u00a0  the sender.\" This does not see seem correct, as OptFragmentSize and OptWindowSize are the initial values which are configured and therefore should not be changed dynamically. Only Fragment_Size and Window_Size are changes. Further the network should also normatively state somewhere that Fragment_Size and Window_Size MUST not grow above the configured max value. That seems obvious but it's better to be explicit and use normative language respectively. 6) Further sec 7.2 says: \"The inter-frame gap is another tool that can be \u00a0  used to increase the spacing between fragments of the same datagram \u00a0  and reduce the ratio of time when a particular intermediate node \u00a0  holds a fragment of that datagram.\" However, inter-frame gap is a configuration parameter and this is the first time that adapting it dynamically is mentioned here. If you want to adapt it dynamically you need to add more information.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-03-06 12:22:47-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 13:48:58-08:00",
    "text": "[ Be ye not afraid - this should be easy to address.]  \"datagram_size: The size of the datagram in its Compressed Form before it is fragmented. The datagram_size is expressed in a unit that depends on the MAC layer technology, by default a byte.\" and: \"Fragment_Size:\u00a0 10-bit unsigned integer; the size of this fragment in a unit that depends on the MAC layer technology.\u00a0 Unless overridden by a more specific specification, that unit is the octet, which allows fragments up to 1024 bytes.\" I spent quite a while going though the document, looking at the 13 places where you use 'byte' and 3 where you use 'octet', trying to figure out if there is a reason that different terms are used. Normally I'd just say \"meh, these are synonyms\" and ignore it, but in this particular specification (because of the \"by default\" / \"Unless overridden\") I think it is actually important.... Can you standardize on one of the other, or provide more explanatory text if there is a reason?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-03-11 11:52:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-11 11:51:34-07:00",
    "text": "This is a process DISCUSS.\u00a0 I don't believe the status of this document as a BCP belonging to  BCP 25  was discussed in the WG or with the IETF community. The Charter for the git WG only explicitly mentions  BCP 9 : \u00a0  The documents produced by this group will not alter the Internet Standards  \u00a0  Process ( BCP 9 ). They will describe how to work within it. Whether working  \u00a0  groups choose to use GitHub or the documented policies to support their work  \u00a0  will remain entirely at their discretion. However, including this document as a part of  BCP 25  (IETF Working Group Guidelines and Procedures) results in the interpretation that it represents consensus on how WGs should proceed -- and not that the decision \"to use GitHub or the documented policies...[is]...entirely at their discretion.\" My reading of the mailing list is that the current RFC Editor note (in which appending the document to  BCP 25  is requested) was added only after the topic was brought up in the Genart LC review. IOW, both (1) the process of reaching the conclusion that this document belongs in  BCP 25 , and (2) the concept that this document would be part of  BCP 25 , are the subject of my DISCUSS.\u00a0 \u00a0 I would like for the IESG to discuss this topic.\u00a0  Not expecting this document to be part of  BCP 25 , or having an explicit discussion with the community about it, would lead me to clear my DISCUSS. ==== [Non blocking comment.\u00a0 I'm including it here because it is related to the status of the document.] This document would be very good Informational document.  I am not a regular GitHub user (and none of the WGs I'm responsible for use it as part of their process), but I have no reason to doubt that the text represents what is believed to be the best way to use GitHub within the IETF process.\u00a0 However, the designation as a BCP can create confusion.\u00a0 [Again, this is a non-blocking comment.]",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-03-20 11:14:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-11 11:52:53-07:00",
    "text": "This is a process DISCUSS.\u00a0 I don't believe the status of this document as a BCP belonging to  BCP 25  was discussed in the WG or with the IETF community. The Charter for the git WG only explicitly mentions  BCP 9 : \u00a0  The documents produced by this group will not alter the Internet Standards  \u00a0  Process ( BCP 9 ). They will describe how to work within it. Whether working  \u00a0  groups choose to use GitHub or the documented policies to support their work  \u00a0  will remain entirely at their discretion. However, including this document as a part of  BCP 25  (IETF Working Group Guidelines and Procedures) results in the interpretation that it represents consensus on how WGs should proceed -- and not that the decision \"to use GitHub or the documented policies...[is]...entirely at their discretion.\" My reading of the mailing list is that the current RFC Editor note (in which appending the document to  BCP 25  is requested) was added only after the topic was brought up in the Genart LC review.\u00a0 [Did I miss the discussion?] IOW, both (1) the process of reaching the conclusion that this document belongs in  BCP 25 , and (2) the concept that this document would be part of  BCP 25 , are the subject of my DISCUSS.\u00a0 \u00a0 I would like for the IESG to discuss this topic.\u00a0  Not expecting this document to be part of  BCP 25 , or having an explicit discussion with the community about it, would lead me to clear my DISCUSS. ==== [Non blocking comment.\u00a0 I'm including it here because it is related to the status of the document.] This document would be very good Informational document.  I am not a regular GitHub user (and none of the WGs I'm responsible for use it as part of their process), but I have no reason to doubt that the text represents what is believed to be the best way to use GitHub within the IETF process.\u00a0 However, the designation as a BCP can create confusion.\u00a0 [Again, this is a non-blocking comment.]",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-03-10 06:05:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-08 23:44:41-07:00",
    "text": "I have a really simple thing to discuss before I move to a \u201cyes\u201d ballot: \u2014 Section 4.1.3 \u2014 \u00a0  Chairs need to assess whether the \u00a0  arguments offered represent new information or not.\u00a0 This can require \u00a0 some discussion to determine accurately.\u00a0 Resolved issues MUST remain \u00a0  closed unless there is consensus to reopen an issue. There seems to be an inconsistency here: WGCs decide whether new information has been given, so it would seem that it\u2019s the WGCs who decide that an issue should be reopened.\u00a0 But then we say there has to be consensus for it.\u00a0 In addition to that appearing inconsistent, I\u2019m not clear how one would determine whether there\u2019s rough consensus to reopen an issue, if doing so were controversial.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-03-11 17:33:05-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-10 10:45:09-07:00",
    "text": "I originally balloted Abstain, but this is (and has been) bothering me enough that I'm changing it to a discuss. This feels like additional centralization / control / process, without good justification. I happen to use GitHub for my documents (along with discussion / agreement with co-authors), but in personal repos. Our documents include something like: \"[ This document is being collaborated on in Github at  https://github.com/wkumari/ .\u00a0 The most recent\u00a0 version of the document, open issues, and so on should all be available there.\u00a0 The authors gratefully accept pull requests. ]\" This document contains a lot of text about setting up, administering, etc a WG organization / repos -- but there is no good justification (that I could find) on what advantages this has over simply encouraging people use GitHub (because it is easy, and well known), and keeping things in their own repos. If WG documents include a pointer (like above) to the repo, everyone can find it, and we don't need all this. This smacks of scope-creep / chairs having control and process where it a: isn't needed and b: isn't helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-08-02 13:15:41-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 13:50:42-07:00",
    "text": "\u00a77 (\"Results of the Alternate Marking Experiment\") makes several  recommendations about the use of one or two flag bits: \u00a0 \u00a0 \u00a0 One flag: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 3.1, while delay measurement MAY be done according to the \u00a0 \u00a0 \u00a0 single-marking method described in Section 3.2.1.\u00a0 Mean delay \u00a0 \u00a0 \u00a0 (Section 3.2.1.1) is NOT RECOMMENDED since it implies more \u00a0 \u00a0 \u00a0 computational load. \u00a0 \u00a0 \u00a0 Two flags: packet loss measurement SHOULD be done as described in \u00a0 \u00a0 \u00a0 Section 3.1, while delay measurement SHOULD be done according to \u00a0 \u00a0 \u00a0 double-marking method Section 3.2.2.\u00a0 In this case single-marking \u00a0 \u00a0 \u00a0 MAY also be used in combination with double-marking and the two \u00a0 \u00a0 \u00a0 approaches provide slightly different pieces of information that \u00a0 \u00a0 \u00a0 can be combined to have a more robust data set. These recommendations are good, as they are the result of experimentation.\u00a0  However, they don't provide any deployment or operational guidelines of when  is it ok to follow them and when it isn't.\u00a0 For example, for the one flag case,  when it is ok to not measure packet loss as described in \u00a73.1?\u00a0 Why is the use  of that mechanism only recommended and not required? I have the same questions for all the recommendations and optional indications  in the text above.\u00a0 To clear this DISCUSS I expect deployment or operational  recommendations that can be used as implementation/deployment guidance.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-08-25 23:00:24-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 05:22:19-07:00",
    "text": "# \u00c9ric Vyncke, INT AD, comments for  draft-ietf-ippm-rfc8321bis-02 CC @evyncke Thank you for the work put into this document.  Please find below one blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Please note that Tim Winters is the Internet directorate reviewer (at my request) and you may want to consider this int-dir review as well when Tim will complete the review (no need to wait for it though): https://datatracker.ietf.org/doc/draft-ietf-ippm-rfc8321bis/reviewrequest/16061/ Special thanks to Tommy Pauly for the shepherd's detailed write-up including the WG consensus and the justification of the intended status.  I hope that this review helps to improve the document, Regards, -\u00e9ric ## DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ### Section 5 Unsure whether I understand correctly: ``` \u00a0  Color switching is the reference for all the network devices, and the \u00a0  only requirement to be achieved is that all network devices have to \u00a0  recognize the right batch along the path. ``` Why do *all network devices* have to recognize the right batch? Isn't this transparent for them?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-08-29 02:08:20-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 13:18:20-07:00",
    "text": "# GEN AD review of  draft-ietf-ippm-rfc8321bis-02 CC @larseggert Thanks to Elwyn Davies for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/tX3DO8ZB3yeiaKC_xnI1khVAcss ). ## Discuss ### Section 3.1, paragraph 5 ``` \u00a0 \u00a0  The rest of the document assumes that the blocks are created \u00a0 \u00a0  according to a fixed timer.\u00a0 The switching after a fixed number of \u00a0 \u00a0  packets is an additional possibility but its detailed specification \u00a0 \u00a0  is out of scope. ``` This should more strongly say that the use fixed timers are REQUIRED when implementing the spec. This document should then also be stripped of all text discussing the \"fixed number of packets\" approach, to improve clarity. (You could move it to a non-normative appendix, if there is a desire to keep the text around.) ### Section 3.1, paragraph 16 ``` \u00a0 \u00a0  Two different strategies that can be used when implementing the \u00a0 \u00a0  method: ``` If both of these strategies are part of the standard, concrete guidance needs to be given when to use one or the other. The text below about \"a limited number of traffic flows\") is too unspecific. ### Section 3.2, paragraph 1 ``` \u00a0 \u00a0  The same principle used to measure packet loss can be applied also to \u00a0 \u00a0  one-way delay measurement.\u00a0 There are three alternatives, as \u00a0 \u00a0  described hereinafter. ``` As above, there is a lot of discussion text around these alternatives, but no concrete guidance when one SHOULD be used but not the other two. If that guidance cannot be given, I wonder if we have enough deployment experience to lift this to the Standards Track. ### Section 5, paragraph 1 ``` \u00a0 \u00a0  This document introduces two color-switching methods: one is based on \u00a0 \u00a0  a fixed number of packets, and the other is based on a fixed timer. \u00a0 \u00a0  But the method based on a fixed timer is preferable because it is \u00a0 \u00a0  more deterministic, and it is considered in the document. ``` Section 3.1 says that the fixed-number-based approach is out of scope for this specification. The text above is inconsistent with that. Again, please remove the text that talks about the option that is not actually part of the intended standard (or move it to an appendix.)",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-09-08 02:19:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-14 01:09:09-07:00",
    "text": "Sorry, another discuss, but hopefully a trivial one to resolve. I found this text to be a unclear regarding passive vs hybrid: \u00a0  Therefore, the Alternate-Marking Method could be considered Hybrid or \u00a0  Passive, depending on the case.\u00a0 In the case where the marking method \u00a0  is obtained by changing existing field values of the packets the \u00a0  technique is Hybrid.\u00a0 In the case where the marking field is \u00a0  dedicated, reserved, and included in the protocol specification, the \u00a0  Alternate-Marking technique can be considered as Passive. Please can you clarify the third sentence, to clarify that the marking is done at source, or at least outside the controlled domain?\u00a0 I.e., I presume that even if there were some reserved bits in the protocol header for colouring packets, that were then written at the edge of the controlled domain, then this would be a active rather than passive measurement? Thanks, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-05 09:40:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-11 10:58:52-07:00",
    "text": "Please clarify the expected deployment model of this approach. (a) Section 7.1 \u00a0  For security reasons, the Alternate Marking Method is RECOMMENDED \u00a0  only for controlled domains. (b) Section 10 \u00a0  This document specifies a method to perform measurements in the \u00a0  context of a Service Provider's network and has not been developed to \u00a0  conduct Internet measurements, so it does not directly affect \u00a0  Internet security nor applications that run on the Internet. The text in (a) suggests that deployment can occur on the Internet (although it isn\u2019t recommended).\u00a0 However, (b) and other documents out of IPPM (e.g.,  RFC9197 ) seem to suggest that OAM meta-data must be filtered.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-08-26 12:28:10-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 17:41:53-07:00",
    "text": "Section 7.1 says: \"The Alternate Marking Method is an example of a solution limited to a controlled domain [ RFC8799 ]. A controlled domain is a managed network that selects, monitors, and controls access by enforcing policies at the domain boundaries, in order to discard undesired external packets entering the domain and check internal packets leaving the domain. [...] It must be possible to control the domain boundaries, and use specific precautions if traffic traverses the Internet.\" \"Controlled domain\" isn't a magic incantation you invoke to make all security issues disappear. Your definition of controlled domain sounds suspiciously like \"the network should magically stop bad packets, and evil people wanting to do bad things!!!!\".  RFC8799  does not define what makes a domain, nor how the boundary is protected. Instead, it \"it shows the need for a precise definition of \"limited domain membership\" and for mechanisms to allow nodes to join a domain securely and to find other members, including boundary nodes.\" and notes that \"the Internet does not have a well-defined concept of limited domains\" and further that \"Domain boundaries that are defined administratively (e.g., by address filtering rules in routers) are prone to leakage caused by human error, especially if the limited domain traffic appears otherwise normal to the boundary routers.\u00a0 In this case, the network operator needs to take active steps to protect the boundary.\" The document states that \"For security reasons, the Alternate Marking Method is RECOMMENDED only for controlled domains.\" - but you have not defined how a network operator is expected to define and enforce the domain boundary; simply saying that the network should select, monitor, and control access by enforcing policies at the domain boundaries, in order to discard undesired external packets doesn't explain how the network should do this. How exactly does the network know what packets are marked? How does the operator filter these? What matching rule can be applied at the boundary to make sure that marked packets do not enter or exit the network?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-08-29 01:57:07-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 04:58:17-07:00",
    "text": "Thanks for working on this specification. My fellow AD colleagues have already put discusses on the concerns I have. Overall, I found this document easy to ready but lacking some clarity on the assumptions and instructions. For, this I am supporting Roman's and Lars's discuss. Apart from those I have one additional concern. ## Section 7 : says - \u00a0 \u00a0 \u00a0 In the case where the marking method is applied by changing existing \u00a0  fields of the packets, it is RECOMMENDED to use an additional flag or \u00a0  some out-of-band signaling to indicate if the measurement is \u00a0  activated or not in order to inform the measurement points. \u00a0 It is not clear who is changing existing fields of which packets? It needs more specific description for at least which packets are we talking about (IP packets? ) and what additional flag we are referring to here.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-17 18:12:58-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 13:54:02-07:00",
    "text": "I support Roman's Discuss.\u00a0 Isn't there a straightforward translation of the \"div\" procedures to the nested \"div-o\" chain?\u00a0 Why would that not be applicable? I had two other points for discussion: (1) IANA seems unhappy (the expert review identified issues).\u00a0 What's the plan to address them? (2) The following text from the Security Considerations seems inconsistent to me: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 However, \u00a0  including this information about forwarding is at the discretion of \u00a0  the retargeting entity, so if there is a requirement to keep the \u00a0  original called number confidential, no PASSporT should be created \u00a0  for that retargeting - the only consequence will be that downstream \u00a0  entities will be unable to correlate an incoming call with the \u00a0  original PASSporT without access to some prior knowledge of the \u00a0  policies that could have caused the retargeting. I don't understand this -- if the idea is to keep the original called number confidential, wouldn't this necessitate *not giving the original PASSporT to the called entity*, since the original PASSporT includes the original call destination?\u00a0 Without the original PASSporT at all, of course it can't be correlated to an incoming call...\u00a0 (Even in the OOB case, would the post-retargeting called entity even be able to retrieve/decrypt the original PASSporT?)\u00a0 Is this intended to only apply to some non-SIP case?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-07-23 14:21:52-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-07 12:35:21-07:00",
    "text": "Section 5.\u00a0 The text notes that procedures for the authentication and verification service for the \u201cdiv-o\u201d claim will be \u201cleft to future work\u201d.\u00a0 Can the rational for this deferral be explained.\u00a0 Creating an interoperable solution without this guidance seem challenging as it would be crucial guidance on processing this newly introduced claim.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:59:29-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 08:12:03-08:00",
    "text": "I support Alvaro's DISCUSS point #2. I'm confused about what the registration policy is for metrics in the new registry. If it is Specification Required, then the places in the document that assume new metrics are defined in an RFC need to be generalized, because Specification Required need not involve any RFC at all. I have an additional concern about this text: \"If the proposed registry entry is defined in an RFC but is not yet \u00a0  widely deployed, there SHOULD be a statement in the RFC that says the \u00a0  proposed registry entry is not ready for registration, and use SHOULD \u00a0  employ a private/experimental ID.\u00a0 It is the responsibility of the \u00a0  document authors to submit the request to IANA when the proposed \u00a0  registry entry is ready for official registration.\" This appears to put a requirement on RFCs to include language that is not timeless and may later become out of date. That is, if this guidance is followed but a metric is later widely deployed, the RFC would have to be updated just to remove the text about the metric not being ready for registration. It seems better to just give guidance about which identifier range registration requests should target, and to give guidance to the designated experts about how to evaluate requests in different ranges.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2019-12-05 10:00:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 14:37:11-08:00",
    "text": "I have two separate issues that I would like to DISCUSS. (1) Approval of the initial performance metrics entries (in  draft-ietf-ippm-initial-registry ). This document describes the format of the registry, and the initial entries are defined in draft-ietf-ippm-initial-registry.\u00a0 However, the registration policy of Specification Required would not be met if the entries in  draft-ietf-ippm-initial-registry  are approved without expert review. As I mentioned in my ballot for  draft-ietf-ippm-initial-registry , I believe that because both documents are being processed at the same time, and the new entries have been reviewed by the WG, IESG Approval [ rfc8126 ] can be used.\u00a0  I can think of at least three ways to address this DISCUSS point (there may be others): a. Designated Experts for this document can be assigned and the formal review can be done. b. The text in this document can explicitly say that the entries in  draft-ietf-ippm-initial-registry  are to be approved using IESG Approval. c. The Responsible AD can add a Management Item to the Telechat for the IESG to explicitly approve (beyond approval for the publication of  draft-ietf-ippm-initial-registry ) the new entries. I am ok with either choice, but would prefer Option c because it would be faster and cause less churn. (2) \u00a78.1 (Adding new Performance Metrics to the Performance Metrics Registry) defines the following process for entries that are \"not yet widely deployed\": \u00a0  If the proposed registry entry is defined in an RFC but is not yet \u00a0  widely deployed, there SHOULD be a statement in the RFC that says the \u00a0  proposed registry entry is not ready for registration, and use SHOULD \u00a0  employ a private/experimental ID.\u00a0 It is the responsibility of the \u00a0  document authors to submit the request to IANA when the proposed \u00a0  registry entry is ready for official registration. Considering the Specification Required policy and the fact that the RFC has already gone through all the reviews required for publication (including expert review, as mentioned in the same section), how will it work for the \"authors to submit the request to IANA when the proposed registry entry is ready for official registration\"?\u00a0 What specification will be presented to IANA to satisfy the registration requirement?\u00a0  It seems to me that the statement mentioned above would prevent the official registration in the first place, and that same statement (still present in the RFC) should prevent a second review of the same document from resulting in an official registration. This process needs more discussion and clarity for it to work. [Not part of this DISCUSS point, but related.]\u00a0  a. Section 8 talks about instructions about handling of the registry.\u00a0 Perhaps it should be part of the IANA Considerations section. b. \u00a77.1.1 contains additional instructions for IANA, including the reservation of a private/experimental range of Identifiers.\u00a0 This test should also be part of the IANA Considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-07 11:38:54-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 14:26:04-08:00",
    "text": "The ABNF for linkparam (\u00a78.2) incorporates a \"langparam\" production, but that is not defined in any of this document,  RFC 5455 ,  RFC 8288 , or  RFC 7986 .\u00a0 We need to define it somehow, whether by reference or directly. RFC 5545  does define a LANGUAGE parameter (our prose references a \"LANG\" parameter) and languageparam ABNF production, which is perhaps the simplest explanation for what was intended.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-06-02 07:54:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-01 10:07:27-07:00",
    "text": "As far as I can tell, CMP provides multiple optional levels of encryption and authentication to protect its messages and components of that message. However, I gather that the transport substrate is allowed to be HTTP without TLS. Given that, how does this protocol defend against version downgrade attacks? If an on-path attacker responds to a client message with an error message requiring an older version, do all configurations of CMP detect the intervention?",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-10 11:42:31-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-05-31 14:56:50-07:00",
    "text": "As a reviewer, and therefor I suspect also implementors, needing to read current + old and then compare it to new is very confusing. If this is for a few paragraphs I can see the point but throughout the entire long document? It prevented me from doing a full review. The document also \u201cupdates\u201d the IANA Considerations which is not a real process we have. We only have new IANA Considerations and I don\u2019t think we should tell IANA to decode their instructions based on a diff with another rfc.  Please tell me how this document would not be simply better if the diffing and replacing is done for the reader by obsoleting the old documents and creating one new clear readable document? If the WG could not do this, how can we expect an implementer to do this ? This deliverable might have been good for the WG for tracking purposes but I don\u2019t think it works as an RFC for the intended target audience.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-29 14:31:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-10 11:42:31-07:00",
    "text": "As a reviewer, and therefor I suspect also implementors, needing to read current + old and then compare it to new is very confusing. If this is for a few paragraphs I can see the point but throughout the entire long document? It prevented me from doing a full review. The document also \u201cupdates\u201d the IANA Considerations which is not a real process we have. We only have new IANA Considerations and I don\u2019t think we should tell IANA to decode their instructions based on a diff with another rfc.  Please tell me how this document would not be simply better if the diffing and replacing is done for the reader by obsoleting the old documents and creating one new clear readable document? If the WG could not do this, how can we expect an implementer to do this ? This deliverable might have been good for the WG for tracking purposes but I don\u2019t think it works as an RFC for the intended target audience. UPDATE: I've completed my review of -21: #1: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This is a \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  very sensitive service and therefore needs specific \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  authorization.\u00a0 This authorization is with the CA \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  certificate itself.\u00a0 Alternatively, the CA MAY delegate the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  authorization by placing the id-kp-cmKGA extended key usage \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  in the certificate used to authenticate the origin of the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  generated private key or the delegation MAY be determined \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  through local configuration of the end entity. These two MAYs are related, you MUST do one or the other. The text as it can be interpreted to not perform either MAYs. #2 \u00a0  Such validity periods SHOULD \u00a0  NOT be used for protection of CMP messages and key generation. \u00a0  Certificates containing one of the above EKUs SHOULD NOT use \u00a0  indefinite expiration date. This leaves a rather unspecified part on the implementer. What time period is too much? Clearly something between a few seconds and indefinite, but what is it? Can this document make a recommendation ? #3  Throughout the document, Section references for the to-be-patched RFC are turned into links for this RFC, eg in the text \"Replace Section 5.1.3.4 - Multiple Protection\" in Section 2.6 where the section title has a bad link but the section body has the right link. Please verify all of these references and fix where needed. #4 \u00a0 \u00a0 \u00a0 It MAY \u00a0 \u00a0 \u00a0 include the original PKIMessage from the EE in the generalInfo \u00a0 \u00a0 \u00a0 field of PKIHeader of a nested message (to accommodate, for \u00a0 \u00a0 \u00a0 example, cases in which the CA wishes to check POP or other \u00a0 \u00a0 \u00a0 information on the original EE message). If a CA wishes to do so, it would REQUIRE this original PKIMessage. Would it not be better to say \"It MUST include the original PKIMessage\" ? It seems also generally better to send the originals along with the modification so that the next step can (optionally!) authenticate the previous step. Otherwise, there is a lot of implied trust that should be modeled in the Security Considerations.  #5 In Section 2.20, it talks abot updating 4210's Section 7. It suggests removing the first 3 paragraphs with replacement text. However, the text removed describes the behaviour in a version agnostic way that I think is more clear than the replacement text. \u00a0 \u00a0 \u00a0 If the client does not accept EnvelopedData, but EncryptedValue, \u00a0 \u00a0 \u00a0 then it MUST use cmp2000. Why not cmp1999? Because EncryptedValue is valid for cmp1999  RFC2510  as well? Are we assuming cmp1999 is completely dead and no longer deployed? In general I would clarify section 2.20 better. More clearly subdivide client and server, and leave a version of the text in Section 7 before section 7.1 intact. Also, it seems the into in the original Section 7 really covers the protocol behaviour. I am not sure why there are subsections with specific version numbers in 4210 nor do I understand why this has to be patched to an even more elaborate versioning, and mentioning EncryptedValue vs EncryptedEnvelope. It seems the section 7 overview covers all behaviour already. #6 Section 3.4 \"patches\" the IANA Considerations. I'd rather we didn't do this and add a clear new IANA Considerations section with clear complete instructions to IANA as to what changes to make, but I understand perhaps why to do this from a readability point of view. But at the very least leave a note to the RFC Editor to confirm all IANA Actions for this document are summarized in this document's IANA Considerations. \u00a0 \u00a0 < TBD: The temporary registration of cmp URI suffix must be updated \u00a0  from provisional to permanent. > IANA will do this when the document goes from draft to RFC. So this comment can safely be removed. \u00a0  < TBD: A new protocol registry group \"Certificate Management Protocol \u00a0  (CMP)\" (at  https://www.iana.org/assignments/cmp ) and an initial entry \u00a0  'p' must be registered. > Same here. Section 4 IANA Considerations should contain a copy of the \"patch\" instructions as a clear instruction to IANA so they can make the changes without them needing to \"patch\" the old RFC to obtain the instructions. Even if this sounds redundant in this document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-07 06:35:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-26 20:44:08-07:00",
    "text": "I have grave concerns about the suitability of LISP as a whole, in its present form, for advancement to the Standards-Track.\u00a0 While some of my concerns are not specific to this document, as the core protocol (data-plane) spec, it seems an appropriate place to attach them to. I am told, out of band, that the intended deployment model is no longer to cover the entire Internet (c.f. the MISSREF-state draft-ietf-lisp-introduction 's \"with LISP, the dge of the Internet and the core can be logically separated and interconnected by LISP-capable routers\", etc.), and that full Internet-scale operation is no longer a goal.\u00a0 However, since that does not seem to be reflected in the current batch of documents up for IESG review, I am forced to ballot on them \"as-is\", namely as targetting global Internet deployment.\u00a0 The requirements placed on the mapping system are so stringent so as to be arguably unachievable at Internet-scale, though that arguably has more of an interaction with the control-plane than the data-plane.\u00a0 It's still in scope here, though, as part of the overall description of the protocol flow. There are an almost innumerable number of downgrade attacks possible, and the control-plane and data-plane security mechanisms are not normative dependencies of the current corpus of documents, and as such are not up for consideration as mitigating the security concerns with the core documents. Section 3 defines the EID-to-RLOC Datbaase: \u00a0  EID-to-RLOC Database:\u00a0  The EID-to-RLOC Database is a global \u00a0 \u00a0 \u00a0 distributed database that contains all known EID-Prefix-to-RLOC \u00a0 \u00a0 \u00a0 mappings.\u00a0 Each potential ETR typically contains a small piece of \u00a0 \u00a0 \u00a0 the database: the EID-to-RLOC mappings for the EID-Prefixes \u00a0 \u00a0 \u00a0 \"behind\" the router.\u00a0 These map to one of the router's own \u00a0 \u00a0 \u00a0 globally visible IP addresses.\u00a0 Note that there MAY be transient \u00a0 \u00a0 \u00a0 conditions when the EID-Prefix for the site and Locator-Set for \u00a0 \u00a0 \u00a0 each EID-Prefix may not be the same on all ETRs.\u00a0 This has no \u00a0 \u00a0 \u00a0 negative implications, since a partial set of Locators can be \u00a0 \u00a0 \u00a0 used. No compelling architecture for a trustworthy global distributed database has been presented that I've seen so far, and LISP relies heavily on the mapping system's database for its functionality.\u00a0 I am concerned that so many requirements are placed on the mapping system so as to be in effect unimplementable, in which case it would seem that the architecture as a whole (that is, for a global Internet-scale system) is not fit for purpose. Section 4.1's Step (6) only mentions parsing \"to check for format validity\".\u00a0 I think it is appropriate to mention (and refer to) source authentication checks as well, since bad Map-Reply data can allow all sorts of attacks to occur. There are some fairly subtle ordering requirements between the order of entries in Map-Reply messages and the Locator-Status-Bits in data-plane traffic (so that the semantic meaning of the status bits are meaningful), which is only given a minimal treatment in the control-plane document.\u00a0 The need for synchronization in interpreting these bits should be mentioned more prominently in the data-plane document as well. The usage of the Instance ID does not seem to be adequately covered; from what I've been able to pick up so far it seems that both source and destination participants must agree on the meaning of an Instance ID, and the source and destination EIDs must be in the same Instance.\u00a0 This does not seem like it is compatible with Internet scale, especially if there are only 24 usable bits of Instance ID. There seems to be a lot of intra-site synchronization requirements, notably with respect to Map-Version consistency, the contents and ordering of locator sets for EIDs in the site, etc.; the actual hard requirements for synchronization within a site should be clearly called out, ideally in a single location. The security considerations attempt to defer substantially to the threat-analysis in  RFC 7835 , which does not really seem like a complete threat analysis and does not provide analysis as to what requirements are placed on the boundaries between the different components of LISP (data plane, control plane, mapping system, various extensions, etc.).\u00a0 The secdir reviewer had some good thoughts in this space. The security considerations throughout the LISP documents place a heavy focus on the risk of over-claiming for routing EID-prefixes.\u00a0 This is a real concern, to be clear, but it should not overshadow the risk of an attacker who is able to move traffic around at will, strip security protections, cause denial of service, alter data-plane payloads, etc. Similarly, this document's security considerations call out denial of service as a risk from Map-Cache insertion/spoofing, but the risks from an attacker being able to read and modify the traffic, perhaps even without detection, seems a much greater threat to me. I am not convinced that this protocol meets the current IETF requirements for the security properties of Standards-Track Protocols without at least LISP-SEC as a mandatory-to-implement component, and possibly additional or stronger requirements.\u00a0 (I did not do a full analysis of the system in the presence of those security mechanisms, since that is not what is being presented for review.) Having an EID that is associated to user-correlatable devices has severe privacy considerations, but I could not find this mentioned anywhere in all of the LISP documents I've read so far.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-02 14:39:29-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-07 06:35:02-08:00",
    "text": "Section 3 still contains text: \u00a0  EID-to-RLOC Database:\u00a0  The EID-to-RLOC Database is a global \u00a0 \u00a0 \u00a0 distributed database that contains all known EID-Prefix-to-RLOC that indicates that the mapping database is a single, global, distributed database; we had previously agreed that the target scope was much more narrow.\u00a0 I could perhaps charitably assume that this instance was missed as an editing error because the phrase \"global distributed database\" spans a line break, but given that this specific instance was called out in my previous discuss position, it is fairly hard to do so. Also in Section 3: \u00a0  Endpoint ID (EID):\u00a0  An EID is a 32-bit (for IPv4) or 128-bit (for \u00a0 \u00a0 \u00a0 IPv6) value used in the source and destination address fields of \u00a0 \u00a0 \u00a0 the first (most inner) LISP header of a packet.\u00a0 [...] 6833bis says (section 5.8) that the inner header can use either RLOC or EID addresses in the header address fields, which contradicts this statement. The various places where we mention \"gleaming\" or similar unauthenticated (un-path-verified?) schemes for learning mapping information should all mention at their description that they are susceptible to spoofing and link to the security considerations. I'm still concerned about the synchronization requirements between map-version changes and LSB usage; with the currently described technology it seems almost inevitable for race conditions around RLOC changes to cause ITRs to make incorrect routing decisions due to misinterpreted status bits. It's unclear whether it's even worth trying to tackle this problem before the map-versioning document is more advanced along in the process, though. (Several comments throughout are relevant, especially those on Section 13.1.) I agree with Warren that clarity on whether traffic is buffered or dropped during the lookup process is needed (e.g., in Section 6). Also in the vein of Warren's comments, in Section 7.1 I was expecting (from our previous discussions) that some text would be added about the determination of L being something that is \"performed once by the administrator of the LISP deployment and treated as a constant across the deployment\". The discussion of Instance IDs remains incomplete, with no discussion of within what scope their values must be unique (as truncated to 24 bits). Similarly (also Section 8), \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Multiple \u00a0  Data-Planes can use the same 32-bit space as long as the low-order 24 \u00a0  bits don't overlap among xTRs. That's a pretty lousy property to have in a PS specification. Section 13 \u00a0  When a Locator record is removed from a Locator-Set, ITRs that have \u00a0  the mapping cached will not use the removed Locator because the xTRs \u00a0  will set the Locator-Status-Bit to 0.\u00a0 So, even if the Locator is in \u00a0  the list, it will not be used.\u00a0 For new mapping requests, the xTRs \u00a0  can set the Locator AFI to 0 (indicating an unspecified address), as \u00a0  well as setting the corresponding Locator-Status-Bit to 0.\u00a0 This I do not remember there being an ordering (or even consistency) requirement on the ITR-RLOC entries in the Map-Request, so it's unclear that just replacing one entry with an AFI-0 entry would convey this information.\u00a0 I suppose that using only a single ITR-RLOC entry, with AFI 0, would provide a usable signal to the ETR, but that does not seem to be what is being described here.\u00a0 (Also, on a rhetorical point, please clarify that the \"as well as\" is for setting the LSB to 0 in data packets; Map-Requests do not include any LSBs.) \u00a0  If many changes occur to a mapping over a long period of time, one \u00a0  will find empty record slots in the middle of the Locator-Set and new \u00a0  records appended to the Locator-Set. At some point, it would be \u00a0  useful to compact the Locator-Set so the Locator-Status-Bit settings \u00a0  can be efficiently packed. This text, implying that compactification must wait for some unspecified later event, seems to be assuming some requirement to preserve order of Locator-Set entries that I cannot find a description of in either 6830bis or 6833bis. Do RFCs 6831 and 8378 need to be normative references for how to do multicast as an optional protocol feature (recalling that https://www.ietf.org/blog/iesg-statement-normative-and-informative-references/ clarifies that references that are relevant only for optional features are still classified as normative)? In Section 16: \u00a0  A complete LISP threat analysis can be found in [ RFC7835 ].\u00a0 In what RFC 7835  remains an incomplete analysis; please stop referring to it as such. \u00a0  of time.\u00a0 The goal is to convince the ITR that the ETR's RLOC is \u00a0  reachable even when it may not be reachable.\u00a0 If the attack is I think Warren is correct that there is also an attack that lies in convincing an ITR that an ETR is not reachable even when it is reachable. The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. Section 4.1's Step (6) only mentions parsing \"to check for format validity\".\u00a0 I think it is appropriate to mention (and refer to) source authentication checks as well, since bad Map-Reply data can allow all sorts of attacks to occur. There are some fairly subtle ordering requirements between the order of entries in Map-Reply messages and the Locator-Status-Bits in data-plane traffic (so that the semantic meaning of the status bits are meaningful), which is only given a minimal treatment in the control-plane document.\u00a0 The need for synchronization in interpreting these bits should be mentioned more prominently in the data-plane document as well. The usage of the Instance ID does not seem to be adequately covered; from what I've been able to pick up so far it seems that both source and destination participants must agree on the meaning of an Instance ID, and the source and destination EIDs must be in the same Instance.\u00a0 This does not seem like it is compatible with Internet scale, especially if there are only 24 usable bits of Instance ID. There seems to be a lot of intra-site synchronization requirements, notably with respect to Map-Version consistency, the contents and ordering of locator sets for EIDs in the site, etc.; the actual hard requirements for synchronization within a site should be clearly called out, ideally in a single location. The security considerations attempt to defer substantially to the threat-analysis in  RFC 7835 , which does not really seem like a complete threat analysis and does not provide analysis as to what requirements are placed on the boundaries between the different components of LISP (data plane, control plane, mapping system, various extensions, etc.).\u00a0 The secdir reviewer had some good thoughts in this space. I am not convinced that this protocol meets the current IETF requirements for the security properties of Standards-Track Protocols without at least LISP-SEC as a mandatory-to-implement component, and possibly additional or stronger requirements.\u00a0 (I did not do a full analysis of the system in the presence of those security mechanisms, since that is not what is being presented for review.) [ed. even though LISP-SEC has been promoted to MTI, it remains difficult to be confident in the results of a full system analysis due to the number of other outstanding issues with the core documents.\u00a0 Consider the risk Ekr noted yesterday in email about tampering with the Map-Request causing apparently-valid repsonses that convey incorrect results with respect to the original query.]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-30 14:21:42-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-02 14:39:29-07:00",
    "text": "Updating for the -27 by removing points that are fully addressed but leaving points that I still want to have further discussion on.\u00a0 It may be most expedient to continue discussion on my -26 ballot thread. Please also note that the COMMENT section was entirely refreshed for the -26 and had a few additions as I read the -27. The various places where we mention \"gleaming\" or similar unauthenticated (un-path-verified?) schemes for learning mapping information should all mention at their description that they are susceptible to spoofing and link to the security considerations. [ed. I have noted offlist to the authors some specific locations] Section 13 \u00a0  When a Locator record is removed from a Locator-Set, ITRs that have \u00a0  the mapping cached will not use the removed Locator because the xTRs \u00a0  will set the Locator-Status-Bit to 0.\u00a0 So, even if the Locator is in \u00a0  the list, it will not be used.\u00a0 For new mapping requests, the xTRs \u00a0  can set the Locator AFI to 0 (indicating an unspecified address), as \u00a0  well as setting the corresponding Locator-Status-Bit to 0.\u00a0 This I do not remember there being an ordering (or even consistency) requirement on the ITR-RLOC entries in the Map-Request, so it's unclear that just replacing one entry with an AFI-0 entry would convey this information.\u00a0 I suppose that using only a single ITR-RLOC entry, with AFI 0, would provide a usable signal to the ETR, but that does not seem to be what is being described here.\u00a0 (Also, on a rhetorical point, please clarify that the \"as well as\" is for setting the LSB to 0 in data packets; Map-Requests do not include any LSBs.) \u00a0  If many changes occur to a mapping over a long period of time, one \u00a0  will find empty record slots in the middle of the Locator-Set and new \u00a0  records appended to the Locator-Set. At some point, it would be \u00a0  useful to compact the Locator-Set so the Locator-Status-Bit settings \u00a0  can be efficiently packed. This text, implying that compactification must wait for some unspecified later event, seems to be assuming some requirement to preserve order of Locator-Set entries that I cannot find a description of in either 6830bis or 6833bis. [ed. these previous two items are rather poorly described; another thread is ongoing to try to clarify both my concerns and how they might be addressed] I think Warren is correct that there is also an attack that lies in convincing an ITR that an ETR is not reachable even when it is reachable. The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. There are some fairly subtle ordering requirements between the order of entries in Map-Reply messages and the Locator-Status-Bits in data-plane traffic (so that the semantic meaning of the status bits are meaningful), which is only given a minimal treatment in the control-plane document.\u00a0 The need for synchronization in interpreting these bits should be mentioned more prominently in the data-plane document as well. The usage of the Instance ID does not seem to be adequately covered; from what I've been able to pick up so far it seems that both source and destination participants must agree on the meaning of an Instance ID, and the source and destination EIDs must be in the same Instance.\u00a0 This does not seem like it is compatible with Internet scale, especially if there are only 24 usable bits of Instance ID. There seems to be a lot of intra-site synchronization requirements, notably with respect to Map-Version consistency, the contents and ordering of locator sets for EIDs in the site, etc.; the actual hard requirements for synchronization within a site should be clearly called out, ideally in a single location. The security considerations attempt to defer substantially to the threat-analysis in  RFC 7835 , which does not really seem like a complete threat analysis and does not provide analysis as to what requirements are placed on the boundaries between the different components of LISP (data plane, control plane, mapping system, various extensions, etc.).\u00a0 The secdir reviewer had some good thoughts in this space. [We're getting closer to something that's possible to properly analyze, but I haven't done that analysis yet]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-01-12 21:12:13-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-30 14:21:42-08:00",
    "text": "Thank you for all the updates in the -28; we're making great progress! My ballot on the -26 included: % The usage of the Instance ID does not seem to be adequately covered; from % what I've been able to pick up so far it seems that both source and % destination participants must agree on the meaning of an Instance ID, and % the source and destination EIDs must be in the same Instance.\u00a0 This does % not seem like it is compatible with Internet scale, especially if there are % only 24 usable bits of Instance ID. The -28 now says that the whole LISP deployment has to agree on the meaning of Instance ID values (thank you!), but I'm still not entirely sure if the source and destination EIDs need to belong to the same Instance. If they do need to be in the same Instance, I think we should note that (but if not, then the current text should be fine as-is). My apologies if this was already covered and I just forgot. [Someone (me?) still owe some analysis on the security considerations at the boundaries of the various components in the ecosystem.\u00a0 Deborah putting this back on an IESG telechat as a returning item might be the most expedient way to get this to happen, sadly.]",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-08 21:19:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-01-12 21:12:13-08:00",
    "text": "[Someone (me?) still owe some analysis on the security considerations at the boundaries of the various components in the ecosystem.\u00a0 Deborah putting this back on an IESG telechat as a returning item might be the most expedient way to get this to happen, sadly.]",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-27 05:17:56-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3126 See my DISCUSS on 6833bis for overall issues. This is just detailed issues on 6830bis as I went through it. DETAIL S 4.1. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 RLOC (outer-header source IP address) in a received LISP packet. >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Such a cache entry is termed a \"glean mapping\" and only contains >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 a single RLOC for the EID in question.\u00a0 More complete information >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 about additional RLOCs SHOULD be verified by sending a LISP Map- >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Request for that EID.\u00a0 Both the ITR and the ETR MAY also >\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 influence the decision the other makes in selecting an RLOC. This seems like it introduces an immediate overclaiming problem. S 10. >\u00a0 \u00a0 \u00a0 When an ETR decapsulates a packet, it will check for any change in >\u00a0 \u00a0 \u00a0 the 'Locator-Status-Bits' field.\u00a0 When a bit goes from 1 to 0, the >\u00a0 \u00a0 \u00a0 ETR, if acting also as an ITR, will refrain from encapsulating >\u00a0 \u00a0 \u00a0 packets to an RLOC that is indicated as down.\u00a0 It will only resume >\u00a0 \u00a0 \u00a0 using that RLOC if the corresponding Locator-Status-Bit returns to a >\u00a0 \u00a0 \u00a0 value of 1.\u00a0 Locator-Status-Bits are associated with a Locator-Set This seems to enable a pretty obvious denial of service attack in which you send\u00a0 a message with all LSBs set to 0. S 10. >\u00a0 \u00a0 \u00a0 list returned by the last Map-Reply will be set to zero for that >\u00a0 \u00a0 \u00a0 particular EID-Prefix.\u00a0 Refer to Section 16 for security related >\u00a0 \u00a0 \u00a0 issues regarding Locator-Status-Bits. >\u00a0   >\u00a0 \u00a0 \u00a0 When an ETR decapsulates a packet, it knows that it is reachable from >\u00a0 \u00a0 \u00a0 the encapsulating ITR because that is how the packet arrived.\u00a0 In It doesn't even know this. It just knows that that's been claimed by someone who can generate traffic to it. S 10.1. >\u00a0 \u00a0 \u00a0 NOT use the lack of return traffic as an indication that the ETR is >\u00a0 \u00a0 \u00a0 unreachable.\u00a0 Instead, it MUST use an alternate mechanism to >\u00a0 \u00a0 \u00a0 determine reachability. >\u00a0   >\u00a0  10.1.\u00a0 Echo Nonce Algorithm >\u00a0   This mechanism seems sufficient to verify unreachability but is not a secure test of reachability because the nonce is way too short. S 16. >\u00a0 \u00a0 \u00a0 Map-Versioning is a Data-Plane mechanism used to signal a peering xTR >\u00a0 \u00a0 \u00a0 that a local EID-to-RLOC mapping has been updated, so that the >\u00a0 \u00a0 \u00a0 peering xTR uses LISP Control-Plane signaling message to retrieve a >\u00a0 \u00a0 \u00a0 fresh mapping.\u00a0 This can be used by an attacker to forge the map- >\u00a0 \u00a0 \u00a0 versioning field of a LISP encapsulated header and force an excessive >\u00a0 \u00a0 \u00a0 amount of signaling between xTRs that may overload them. Can't I also set a super-high version number, thus gagging updates?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-11-29 16:30:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-08 22:28:46-07:00",
    "text": "[ section 8 ] * I think the currently architecture of IPv6 is such that at a minimum this \u00a0 doc should say that instances SHOULD NOT be used when the inner traffic is \u00a0 IPv6 as overlapping IPv6 prefixes are best and fairly easily avoided and \u00a0 folks should be encouraged to avoid recreating some of the limitations that \u00a0 were unavoidable in IPv4. [ section 12 ] * When the outer header is IPv6, the flow label may also be set a la  RFC 6438 . * When the inner header is IPv6, the flow label may also be a factor in the \u00a0 hashing (6348, if the flow label is non-zero a la 6437). [ section 16 ] * Is it worth adding an extra warning about gleaning mappings for EIDs that \u00a0 the ETR would otherwise have routed internally via the IGP? * In addition to basic uRPF, can an ETR do LISP-specific uRPF, i.e. look up \u00a0 the source EID in the mapping system and check that the source RLOC is within \u00a0 the set returned?\u00a0 If so, the document might mention it.\u00a0 If not, it might \u00a0 be good state explicitly that LISP does not afford this kind of uRPF check.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:03:35-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:02:50-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. While I fully support xTRs sending and processing ICMP packets, they don't always work in the public internet due to ICMP black holes and the like.  https://datatracker.ietf.org/doc/draft-ietf-tsvwg-datagram-plpmtud/ , which is the RFC Editor queue, would be a more reliable way to determine the Path MTU. Regrettably, the LISP data plane doesn't have a method to pad or otherwise modify the size of its packets besides IP fragmentation, nor to acknowledge those packets beyond the insecure Nonce. It would be best if the ITRs and ETRs had some sort of reliable way to send and acknowledge packets to each other of variable size. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither. - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:04:31-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:03:35-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. While I fully support xTRs sending and processing ICMP packets, they don't always work in the public internet due to ICMP black holes and the like.  https://datatracker.ietf.org/doc/draft-ietf-tsvwg-datagram-plpmtud/ , which is the RFC Editor queue, would be a more reliable way to determine the Path MTU. Regrettably, the LISP data plane doesn't have a method to pad or otherwise modify the size of its packets besides IP fragmentation, nor to acknowledge those packets beyond the insecure Nonce. It would be best if the ITRs and ETRs had some sort of reliable way to send and acknowledge packets to each other of variable size. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither. - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:05:02-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:04:31-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither. - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-03 12:05:38-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:05:02-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither? - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-08-12 09:55:24-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-03 12:05:38-07:00",
    "text": "Having read this document front to back for the first time, I found it quite hard to figure out what can actually safely done over the public internet, and what can be only be done in trusted environments. I realize that this is probably because the no-internet provisions entered late in the game. If it were my document, I might reorganize it to make the distinction more clear (i.e. present the internet-safe dataplane spec and then have additional sections about insecure add-ons). That said, at this stage in the game I'd be happy to have a new section that clarified what is what. For example (assuming I'm reading it correctly, which is my point) NEW: \" Section 4 and a half. Deployment on the Public Internet Many of the mechanisms in this document are intended for deployment in controlled, trusted environments, and are insecure for use over the public internet. In particular, on the public internet xTRs: * SHOULD set the N, L, E, and V bits in the LISP header (sec 5.3) to zero; * SHOULD NOT use gleaning as a method for Route Locator Selection (Sec 9); * SHOULD NOT use any data plane methods described in Section 10 for Routing Locator Reachability, instead relying solely on control plane methods; * SHOULD NOT use any data plane methods described in Section 13 to update the EID-to-RLOC mapping, instead relying solely on control plane methods. \" END Perhaps my text is inaccurate, but something to that effect would be very helpful. Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither? - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows? Sec 9. I don't understand what this sentence means: \"The client-side ITR controls how traffic is returned and can alternate using an outer-header source RLOC, which then can be added to the list the server-side ETR uses to return traffic.\" This would appear to be the inverse of the \"Routing Locator Hashing\" discussion in Section 12, which provides a technique for switching destination RLOC. Is this \"alternation\" of source RLOC mean to be done on hashed 5-tuple basis (i.e. each flow uses only one source RLOC)? If not, would this involve potentially sending packets for one flow on different interfaces with different path characteristics, causing packet reordering. Or perhaps you mean each packet is sent from the same interface with a spoofed source RLOC, which creates interesting issues for ICMP returns and the like.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-09-09 15:02:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-12 09:55:24-07:00",
    "text": "Thanks for the adding the \u201cpublic internet\u201d explanation and clarifying how multipath routing works. Remaking Discuss issues:  Sec 5.3 What is in the Nonce/Map-Version field if both the N and V bits are zero? Sec 7.2 The stateful MTU design does not incorporate any security measures against ICMP spoofing. At the very least, the ITR needs to make sure that some fields in the outer IP and UDP headers are hard to guess, and that this information is stored to verify that the ICMP message came from on-path. If this is not possible, the design is not safe to use over IPv4.\u00a0 If hard-to-guess information is not available to be stored deeper in the packet, then it is not safe over IPv6 either. Sec 7.2 There is a fourth situation which can arise. If the ETR receives an ICMP packet from an EID in its network. I have a couple of questions about what should happen in this case: - How is this communicated to the sender of the flow that triggered the message? Is there an \"outer\" ICMP to the ITR, and \"inner\" ICMP to the source EID, both, or neither? - Is the ETR responsible for enforcing the MTU to that EID for subsequent flows?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-11 03:29:03-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-10 09:01:45-07:00",
    "text": "Unfortunately ECN decapsulation is slightly more complicated than described in section 5.3. Please check section 3.2 in  rfc6040  and revise accordingly (maybe also provide a pointer to  rfc6040  instead or in addition to  rfc3168 )! (Also it seems like the text on ECN is simply just twice in sec 5.3; not sure that is helpful). Further, also in sec 5.3: \"The inner-header 'Differentiated Services Code Point' (DSCP) field \u00a0 \u00a0 \u00a0 (or the 'Traffic Class' field, in the case of IPv6) SHOULD be \u00a0 \u00a0 \u00a0 copied from the outer-header DSCP field ('Traffic Class' field, in \u00a0 \u00a0 \u00a0 the case of IPv6) considering the exception listed below.\" However, I didn't find any exception listed. However seeting the DSCP field might also be matter of local policy. E.g. if DSCP is not used for a different purposed in the receiver side lisp network, it could make sense to restore/keep the orginial value in the inner header. Sec 7.1. only takes about ICMPv6 \"Packet Too Big\" packets while \"IPv4-encapsulated packet with the DF bit set to 1\" should be addressed as well. I would like to see another need in section 12 explicitly stating that the source port SHOULD be the same for all packet belong to the same flow.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2018-09-11 08:17:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-11 03:29:03-07:00",
    "text": "Unfortunately ECN decapsulation is slightly more complicated than described in section 5.3. Please check section 3.2 in  rfc6040  and revise accordingly (maybe also provide a pointer to  rfc6040  instead or in addition to  rfc3168 )! (Also it seems like the text on ECN is simply just twice in sec 5.3; not sure that is helpful). Further, also in sec 5.3: \"The inner-header 'Differentiated Services Code Point' (DSCP) field \u00a0 \u00a0 \u00a0 (or the 'Traffic Class' field, in the case of IPv6) SHOULD be \u00a0 \u00a0 \u00a0 copied from the outer-header DSCP field ('Traffic Class' field, in \u00a0 \u00a0 \u00a0 the case of IPv6) considering the exception listed below.\" However, I didn't find any exception listed. However seeting the DSCP field might also be matter of local policy. E.g. if DSCP is not used for a different purposed in the receiver side lisp network, it could make sense to restore/keep the orginial value in the inner header. Sec 7.1. only takes about ICMPv6 \"Packet Too Big\" packets while \"IPv4-encapsulated packet with the DF bit set to 1\" should be addressed as well. I would like to see another need in section 12 explicitly stating that the source port SHOULD be the same for all packet belong to the same flow. Sec 5.3 says \"Both N- and V-bits MUST NOT be set in the same packet.\" What happens if both bits are set? The 'Nonce/Map-Version' is just ignored, or maybe the packet should be dropped or something? Please clarify in the doc!",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-11 08:17:28-07:00",
    "text": "I have a couple of smaller discuss points with should be straight-forward to address and one more high-level discussion point that might not have a solution (depending on the deployment status of LISP I guess) but I would like to at least have a discussion. I start with the straight-forward onces: 1) Unfortunately ECN decapsulation is slightly more complicated than described in section 5.3. Please check section 3.2 in  rfc6040  and revise accordingly (maybe also provide a pointer to  rfc6040  instead or in addition to  rfc3168 )! (Also it seems like the text on ECN is simply just twice in sec 5.3; not sure that is helpful). 2) Further, also in sec 5.3: \"The inner-header 'Differentiated Services Code Point' (DSCP) field \u00a0 \u00a0 \u00a0 (or the 'Traffic Class' field, in the case of IPv6) SHOULD be \u00a0 \u00a0 \u00a0 copied from the outer-header DSCP field ('Traffic Class' field, in \u00a0 \u00a0 \u00a0 the case of IPv6) considering the exception listed below.\" However, I didn't find any exceptions listed later in the doc. However, setting the DSCP field might also be matter of local policy. E.g. if DSCP is not used for a different purpose in the receiver side LISP network, it could make sense to restore/keep the original value in the inner header. 3) Sec 7.1. only takes about ICMPv6 \"Packet Too Big\" packets while \"IPv4-encapsulated packet with the DF bit set to 1\" should be addressed as well. 4) I would like to see another sentence in section 12 explicitly stating that the source port SHOULD be the same for all packet belong to the same flow. 5) Sec 5.3 says \"Both N- and V-bits MUST NOT be set in the same packet.\" What happens if both bits are set? The 'Nonce/Map-Version' is just ignored, or maybe the packet should be dropped or something? Please clarify in the doc! 6) And now the more-discussion-needed point: So my underlying concern is the same as brought up by the TSV-ART review that lisp information are not end-to-end integrity protected or authenticated. However, while briefly thinking about how this could be eventually realized, I noticed that there is actually no mechanism to extend the LISP header in any way. There is no version, no option and the LISP header seems to have a fixed, implicitly specified length without an explicit length field. This seems too late to add any kind of extensibility mechanism at this stage of the protocols lifetime, however, I would still like to discuss if there was any discussion about extensibility, what was the reason to chose this approach, and potential if some background about the choice should be given in the doc.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:30:52-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-07 15:03:28-07:00",
    "text": "** Section 1.1. The applicability statement of \u201clarge set of cooperating entities seeking to communicate over the public Internet or other large underlay IP infrastructures\u201d seems inconsistent with many of the protocol mechanics described.\u00a0 Specifically, most of the capabilities in the LISP header (Locator-Status-Bits, Echo-nonce mechanism, Map-Versioning, Instance ID) and the \u201cGleaning mechanism\u201d are explicitly noted as not being suitable for Internet use.\u00a0 This section needs to be explicit that only a subset of the protocol is suitable for the Internet.\u00a0 Likewise, it should be clearer about what is assumed elements of the closed network are trusted for what particular behaviors. ** Section 16. Per \u201cLocator-Status-Bits, echo-nonce and map-versioning SHOULD NOT be used over the public Internet and SHOULD only be used in trusted and closed deployments\u201d -- not disagreement.\u00a0 However, under what circumstances would they be used on the internet to warrant a SHOULD NOT instead of a stronger MUST NOT? ** Section 8.\u00a0 Per \u201cParticipants within a LISP deployment must agree on the meaning of Instance ID values.\u00a0 The source and destination EIDs MUST belong to the same Instance ID.\u201d\u00a0 Could parties agree that the Instance ID is 802.1Q tags and send those across the internet?\u00a0 Recommend stronger cautionary language on using Instance ID.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-11-18 13:24:23-08:00",
    "end_reason": "position_updated",
    "start": "2020-09-18 06:30:52-07:00",
    "text": "** Section 8.\u00a0 Per \u201cParticipants within a LISP deployment must agree on the meaning of Instance ID values.\u00a0 The source and destination EIDs MUST belong to the same Instance ID.\u201d\u00a0 Could parties agree that the Instance ID is 802.1Q tags and send those across the internet?\u00a0 Recommend stronger cautionary language on using Instance ID.",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2018-10-01 19:44:22-07:00",
    "end_reason": "position_updated",
    "start": "2018-09-26 22:28:02-07:00",
    "text": "* Section 7.1.  This should be an easy fix but I would like to see it fixed before publication. When talking about IPv6 packets being larger than L, the correct behavior should be to send an ICMPv6 message with Type 2 (Packet Too Big) instead of the Destination Unreachable (Type 1) message as specified in the text. The text *is correct* for IPv4 messages with the DF bit set where the Destination Unreachable (Type 3) is the right kind of message to send.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2019-06-17 16:56:32-07:00",
    "end_reason": "position_updated",
    "start": "2019-02-05 18:21:49-08:00",
    "text": "I read much of this on a plane while overtired, so it is entirely possible / probable that I've completely misunderstood something(s) obvious. Many of the below are probably simple to address, and either I simply need to be educated, or just there needs to be a bit more text / detail provided.  1: \"3.\u00a0 The ITR sends a LISP Map-Request as specified in [ I-D.ietf-lisp-rfc6833bis ].\u00a0 Map-Requests SHOULD be rate-limited.\" What does the ITR do with the packet while waiting for the Map-Request to complete? Must it buffer the packets or can it discard them? If the former, for how long must it buffer? When you say \"SHOULD be rate-limited\", can you provide guidance on rates? 1 request per second? 1 million per second? Is this rate-limit per destination or per device?  Apologies if this is clearly stated in  RFC6833 (bis) - I only skimmed it, and didn't see an answer there.  2: \"6. ... Note that the Map-Cache is an on-demand cache. An ITR will manage its Map-Cache in such a way that optimizes for its resource constraints.\" Presumably I could cause this cache to thrash / overflow by looking at the RLOC database, and choosing EIDs to send traffic to which all require different cache entries, causing the cache to overflow (or, at least, causing maximum cache pressure). This seems like an ideal DoS vector. It seems that there should be more guidance provided on how to size the Map-Cache / the expected order of the cache size, even if it is ultimately an implementation issue (e.g: is a Map-Cache of 100 entries OK for an ITR? or should it be O(1000)? Or roughly size(database)/2? Having multiple devices with small caches, and a bot which does the above seems like a global risk). I'm quite confused by much of the MTU / Fragmentation stuff -- I did read the documents on a plane after not getting much sleep, and so it is entirely possible / probable that I'm just being stupid, but there are bits which don't seem to make sense to me. 3: \"2.\u00a0 Define L to be the size, in octets, of the maximum-sized packet an ITR can send to an ETR without the need for the ITR or any intermediate routers to fragment the packet.\" How do I know what L is? The document \"RECOMMENDS that L be defined as 1500\" -- but 1500 isn't universally true (if it were, we would never have to do Path MTU). What happens when the *actual* MTU on the path is e.g 1476 because there is a tunnel on the path?  The text also mentions \"which is less than the ITR\u2019s estimate of the path MTU between the ITR and its correspondent ETR\" - this implies that the ITR is tracking / estimating the MTU, which a: doesn't align with the rest of the text, or b: sounds like the stateful solution below. I have reread this multiple times, but it still feels like it is avoiding the issue by defining it to not exist. 4: \"Note that reassembly can happen at the ETR if the encapsulated packet was fragmented at or after the ITR.\" - I think that there needs to be more text / description about resource constraints on routers performing reassembly of fragments - in most cases a router doesn't have to / isn't expected to have to reassemble transit packets from arbitrary sources on the Internet (things where routers may reassemble are aimed at the control plane which can be rate-limited, or are from expected source addresses). It seems that spoofing lots of initial fragments without the final one will be a tax on the router.  5: \"Instead of using the Map-Cache or mapping system, RLOC information MAY be gleaned from received tunneled packets or Map-Request messages. A \"gleaned\" Map-Cache entry, one learned from the source RLOC of a received encapsulated packet, is only stored and used for a few seconds, pending verification.\" - it seems that this is ripe for abuse (or I'm missing in the cache expiration). I want to hijack traffic from Site X to well known Service Y, so I look up Service Y and save the TTL from the Map-Reply. I then start spoof packets listing myself as the ETR - eventually Site X will glean from my spoofed packets, and start sending traffic to me - yes, this will only work for a few seconds -- but as soon as I stop getting packets from site X, I know site X has verified the entry and discovered it is wrong... and that the TTL is now being deprecated. I start a timer, and second or two less than the TTL later I start spoofing packets again, knowing that site X will soon expire the cache entry and will once again be willing to accept mine again. A: I get some Site X to Site Y traffic for a few seconds every TTL seconds, and B: the loss of this traffic is a signal that TTL seconds again it will need to be refreshed.   6: \"10.1.\u00a0 Echo Nonce Algorithm\" -- If I spoof lots of packets with the N- and E-bits set, the receiving ETR will need to keep false state, and presumably I can overfill a cache. This will cause the ETR to not be able to include the received nonce on legitimate traffic, and so the ITR on the far side will think this ETR is down. This seems like a fairly easy DoS. I'm guessing that this can be worked around by not setting the E bit in the RLOC-probe Map-Reply message, but this feels like a dangerous foot gun, and should at least be noted. Note that this is different to the \"Note the attacker must guess a valid nonce the ITR is requesting to be echoed within a small window of time.\u00a0 The goal is to convince the ITR that the ETR\u2019s RLOC is\u00a0 reachable even when it may not be reachable.\"\u00a0 attack listed in the document in that a: it doesn't require any guessing, and b: makes an ETR appear down, not up.  The document does mention \"... attack can be mitigated by preventing RLOC spoofing in the network by deploying uRPF  BCP 38  [ RFC2827 ].\" - while that may be true for many of the above,  BCP38  is far from being universally deployed, and this feels similar to solving world hunger by saying everyone must have enough food. :-) Again, apologies if I've completely misunderstood something, clue-bat gladly accepted...",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2017-08-17 15:53:02-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-16 16:04:48-07:00",
    "text": "Section 5.4 says: \u00a0  NOTE: A new DTLS association can be established based on changes in \u00a0  either an SDP offer or answer.\u00a0 When communicating with legacy \u00a0  endpoints, an offerer can receive an answer that includes the same \u00a0  fingerprint set and setup role.\u00a0 A new DTLS association MUST still be \u00a0  established if such an answer was received as a response to an offer \u00a0  which requested the establishment of a new DTLS association. Unless I've misunderstood something important, this isn't going to work with legacy implementations, unless you also specify that an \"offer which requested the establishment of a new DTLS association\" must also change something else that the legacy answerer will recognize as requiring a new DTLS association. For example, if I send a re-offer with a changed tls-id but the same fingerprint, setup, and transport, the far end will have no reason to think it needs to establish a new DTLS association. So I'll sit there waiting for a new association to be established, and the remote side will never send one. This doesn't seem backwards-compatible. At the very least, more text needs to be added explaining how this is intended to work.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-08-31 04:00:56-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-14 03:09:50-07:00",
    "text": "This is a fine document, but I have one [hopefully easy to answer] question and a couple of other minor ones: In Section 5.1.\u00a0 General \u00a0  Endpoints MUST support the cipher suites as defined in [ RFC8122 ]. I don't see any ciphers specified in that RFC. Can you clarify what you mean?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2017-10-27 12:10:50-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 16:06:59-07:00",
    "text": "1. Assuming I understand this document correctly, it conflicts with the guidance in JSEP. Specifically, S 4 says: \u00a0  No default value is defined for the SDP 'tls-id' attribute. \u00a0  Implementations that wish to use the attribute MUST explicitly \u00a0  include it in SDP offers and answers.\u00a0 If an offer or answer does not \u00a0  contain a 'tls-id' attribute (this could happen if the offerer or \u00a0  answerer represents an existing implementation that has not been \u00a0  updated to support the 'tls-id' attribute), unless there is another \u00a0  mechanism to explicitly indicate that a new DTLS association is to be \u00a0  established, a modification of one or more of the following \u00a0  characteristics MUST be treated as an indication that an endpoint \u00a0  wants to establish a new DTLS association: \u00a0  o\u00a0 DTLS setup role; or \u00a0  o\u00a0 fingerprint set; or \u00a0  o\u00a0 local transport parameters; or \u00a0  o\u00a0 ICE ufrag value This seems to say that if there is no tls-id attribute, then an ICE restart (which necessitates a ufrag change) requires a DTLS restart. JSEP isn't incredibly clear on this point, but 5.7.3 seems to say that tls-id neeed not be present: \u00a0 \u00a0 \u00a0 *\u00a0 tls-id value, which MUST be set according to \u00a0 \u00a0 \u00a0 \u00a0  [ I-D.ietf-mmusic-dtls-sdp ], Section 5.\u00a0 If this is a re-offer \u00a0 \u00a0 \u00a0 \u00a0  and the tls-id value is different from that presently in use, \u00a0 \u00a0 \u00a0 \u00a0  the DTLS connection is not being continued and the remote \u00a0 \u00a0 \u00a0 \u00a0  description MUST be part of an ICE restart, together with new \u00a0 \u00a0 \u00a0 \u00a0  ufrag and password values.\u00a0 If this is an answer, the tls-id \u00a0 \u00a0 \u00a0 \u00a0  value, if present, MUST be the same as in the offer. I believe that the first sentence is in error, as we clearly can't have JSEP implementations requiring that tls-id be present. \u00a0  ... \u00a0   \u00a0  o\u00a0 If the remote DTLS fingerprint has been changed or the tls-id has \u00a0 \u00a0 \u00a0 changed, tear down the DTLS connection.\u00a0 This includes the case \u00a0 \u00a0 \u00a0 when the PeerConnection state is \"have-remote-pranswer\".\u00a0 If a \u00a0 \u00a0 \u00a0 DTLS connection needs to be torn down but the answer does not \u00a0 \u00a0 \u00a0 indicate an ICE restart or, in the case of \"have-remote-pranswer\", \u00a0 \u00a0 \u00a0 new ICE credentials, an error MUST be generated.\u00a0 If an ICE \u00a0 \u00a0 \u00a0 restart is performed without a change in tls-id or fingerprint, \u00a0 \u00a0 \u00a0 then the same DTLS connection is continued over the new ICE \u00a0 \u00a0 \u00a0 channel. \u00a0 \u00a0 \u00a0  I think the best interpretation of this is that if tls-id is not present (and hence unchanged) then ICE restart does not cause DTLS restart. This is also my memory of the consensus in RTCWEB. In any case, these two documents clearly must match. 2. S 4 says: \u00a0  The mux category [ I-D.ietf-mmusic-sdp-mux-attributes ] for the 'tls- \u00a0  id' attribute is 'IDENTICAL', which means that the attribute value \u00a0  must be identical across all media descriptions being multiplexed \u00a0  [ I-D.ietf-mmusic-sdp-bundle-negotiation ]. This is not actually what JSEP requires: \u00a0  different categories.\u00a0 To avoid unnecessary duplication when \u00a0  bundling, attributes of category IDENTICAL or TRANSPORT MUST NOT be \u00a0  repeated in bundled m= sections, repeating the guidance from \u00a0  [ I-D.ietf-mmusic-sdp-bundle-negotiation ], Section 8.1.\u00a0 This includes I suspect this is old text. 3. S 7.1 says: \u00a0  If DTLS is transported on top of a connection-oriented transport \u00a0  protocol (e.g., TCP or SCTP), where all IP packets are acknowledged, This is incorrect, because none of these protocols ack all IP packets. \u00a0  all DTLS packets associated with a previous DTLS association MUST be \u00a0  acknowledged (or timed out) before a new DTLS association can be \u00a0  established on the same instance of that transport (5-tuple). More generally, I'm not sure that this is useful, because the required semantic isn't *acknowledged* but rather that the receiver can appropriately demux. So, say you just stop sending DTLS on connection A and start sending on B, what's the delimiter, given that you don't require close_notify here? IIRC, we just decided to punt on this whole thing. Does anyone try to have successive connections over the same transport, even when it's connection oriented? 4. The demux instructions seem to have gotten lost from 6.7.1. At minimum these need a reference to  RFC 7983 .",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-08-15 07:47:15-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-08-15 07:37:23-07:00",
    "text": "This is nothing big and should be easy to fix: On section 7.1, of course... \"If DTLS is transported on top of a connection-oriented transport \u00a0  protocol (e.g., TCP or SCTP), where all IP packets are acknowledged, \u00a0  all DTLS packets associated with a previous DTLS association MUST be \u00a0  acknowledged (or timed out) before a new DTLS association can be \u00a0  established on the same instance of that transport (5-tuple).\" I don't think this would be nessecary for QUIC. The point here is, I believe, not the fact that TCP and SCTP are connection-oriented, but that re-transmissions cannot be easily distinguished from the original packets. So the point is rather the use of a reliable protocol that retransmits in a specific way. However, why would you use DTLS with TCP instead of TLS? And I also don't think you want to use DTLS with QUIC because it has it's own crypto. I guess the recommendation should rather be that reliable transports should use TLS, and if DTLS is needed a new DTLS connection can only be established if there is not retransmission ambiguity which is always the case when all outstanding packets are ack'ed or considered lost (timed out).\u00a0 Or am I missing the point?",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2017-10-05 05:34:59-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-15 07:47:15-07:00",
    "text": "This is nothing big and should be easy to fix: On section 7.1, of course... \"If DTLS is transported on top of a connection-oriented transport \u00a0  protocol (e.g., TCP or SCTP), where all IP packets are acknowledged, \u00a0  all DTLS packets associated with a previous DTLS association MUST be \u00a0  acknowledged (or timed out) before a new DTLS association can be \u00a0  established on the same instance of that transport (5-tuple).\" I don't think this would be necessary for QUIC. The point here is, I believe, not the fact that TCP and SCTP are connection-oriented, but that re-transmissions cannot be easily distinguished from the original packet. So the point is rather the use of a reliable protocol that retransmits in a specific way. However, why would you use DTLS with TCP instead of TLS? And I also don't think you want to use DTLS with QUIC because it has it's own crypto. I guess the recommendation should rather be that reliable transports should use TLS, and if DTLS is needed a new DTLS connection can only be established if there is not retransmission ambiguity which is always the case when all outstanding packets are ack'ed or considered lost (timed out).\u00a0 Or am I missing the point?",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2020-01-23 15:15:08-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 23:03:58-07:00",
    "text": "Thanks to everyone who has worked on documenting the TACACS+ protocol as it is used today. I understand the desire to publish this document as a status other than Historic, as the protocol remains in use today. However, the shortcomings cited in the \"Security Considerations\" section are quite profound, and really bear highlighting in the document way before we get into what is fundamentally end material. I have serious misgivings about publishing this document as anything other than Historic without some prominent text early in the document (e.g., in the Introduction section) that warns implementors of the several caveats detailed in section 10 and its subsections. They don't need to be explained here, but some language along the lines of the following really needs to be present in order to scope the document: \u00a0  Note that the original TACACS+ implementations did not address all of the \u00a0  baseline security concerns which are considered when designing modern \u00a0  protocols.\u00a0 This document does not change this situation, and implementors \u00a0  should use caution when evaluating the suitability of TACACS+ for any given \u00a0  use.\u00a0 Please see section 10 for additional details. --------------------------------------------------------------------------- \u00a74.6: >\u00a0 To ensure interoperability of current deployments, the TACACS+ client >\u00a0 and server MUST handle user fields and those data fields used for >\u00a0 passwords as 8-bit octet strings.\u00a0 The deployment operator MUST >\u00a0 ensure that consistent character encoding is applied from the end >\u00a0 client to the server.\u00a0 The encoding SHOULD be UTF-8, and other >\u00a0 encodings outside printable US-ASCII SHOULD be deprecated. Without specification of preparation profiles for usernames and passwords, this is an incomplete specification of how to transmit non-ASCII usernames and passwords. While there are other solutions, the easy way to address this is to normatively reference  RFC 7613 , and select one of its username preparation profiles, and indicate its password preparation profile. The most basic problem here is that I might create a username and/or password on a machine that uses one mapping for a non-ASCII character, and later try to log in on a machine that uses a different, but semantically equivalent, mapping for that same character. This is a clear interop issue.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-15 23:20:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-15 11:48:29-07:00",
    "text": "I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) 4.6.\u00a0 Text Encoding \u00a0  All text fields in TACACS+ MUST be printable US-ASCII, excepting Please add a reference to  RFC 20  (for US-ASCII) here. Without out it \"printable\" has no meaning. \u00a0  special consideration given to user field and data fields used for \u00a0  passwords. \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0  client to the server.\u00a0 The encoding SHOULD be UTF-8, and other Please add Normative  RFC 3629  reference here for UTF-8. \u00a0  encodings outside printable US-ASCII SHOULD be deprecated. I am not sure what this mean. You didn't define allowed encoding (really you mean charsets). 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-05-16 10:26:50-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-15 23:20:57-07:00",
    "text": "(One small addition to my earlier comments, see new DISCUSS point 6) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) 4.6.\u00a0 Text Encoding \u00a0  All text fields in TACACS+ MUST be printable US-ASCII, excepting Please add a reference to  RFC 20  (for US-ASCII) here. Without out it \"printable\" has no meaning. \u00a0  special consideration given to user field and data fields used for \u00a0  passwords. \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0  client to the server.\u00a0 The encoding SHOULD be UTF-8, and other Please add Normative  RFC 3629  reference here for UTF-8. \u00a0  encodings outside printable US-ASCII SHOULD be deprecated. I am not sure what this mean. You didn't define allowed encoding (really you mean charsets). 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ?",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-17 12:10:33-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-16 10:26:50-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) 4.6.\u00a0 Text Encoding \u00a0  All text fields in TACACS+ MUST be printable US-ASCII, excepting Please add a reference to  RFC 20  (for US-ASCII) here. Without out it \"printable\" has no meaning. \u00a0  special consideration given to user field and data fields used for \u00a0  passwords. \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0  client to the server.\u00a0 The encoding SHOULD be UTF-8, and other Please add Normative  RFC 3629  reference here for UTF-8. \u00a0  encodings outside printable US-ASCII SHOULD be deprecated. I am not sure what this mean. You didn't define allowed encoding (really you mean charsets). 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. 8) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. 9) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-18 03:37:37-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-17 12:10:33-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) Resolved 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Later in 5.1: \u00a0  A printable US-ASCII string indicating the remote location from which \u00a0  the user has connected to the client.\u00a0 It is intended to hold a \u00a0  network address What are the allowed formats for IPv4 and IPv6? Or is this just human readable? \u00a0  if the user is connected via a network, a caller ID \u00a0  is the user is connected via ISDN or a POTS, or any other remote \u00a0  location information that is available. 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. 8) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. 9) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-18 04:17:26-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-18 03:37:37-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) Resolved 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Addressed 4) In 5.4: \u00a0  If the information being requested by the server form the client is \u00a0  sensitive, then the server should set the TAC_PLUS_REPLY_FLAG_NOECHO \u00a0  flag.\u00a0 When the client queries the user for the information, the \u00a0  response MUST NOT be echoed as it is entered. What does the last sentence mean? (When is it ever echoed?) Are you missing a forward reference or some explanation of echoing? 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. 8) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. 9) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-18 06:28:46-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-18 04:17:26-07:00",
    "text": "(I have incorporated DISCUSS portion of Alissa's DISCUSS, see DISCUSS points #7-#9) I appreciate that this is documenting an existing protocol and I am very glad that it is being documented. However there are several things which are still not documented well enough/not in enough details to implement. So I would like to discuss these issues before recommending approval of this document: 1) Resolved 2) In 5.1: \u00a0  The printable US-ASCII name of the client port on which the \u00a0  authentication is taking place, This doesn't mean anything. Is there a registry? It doesn't look like you are using transport service name registry for this. Is it a fixed list? \u00a0  and its length in bytes.\u00a0 The value \u00a0  of this field is client specific.\u00a0 (For example, Cisco uses \"tty10\" \u00a0  to denote the tenth tty line and \"Async10\" to denote the tenth async \u00a0  interface).\u00a0 The port_len indicates the length of the port field, in \u00a0  bytes. 3) Addressed 4) Addressed 5) KRB5 and KRB4 need normative references. 6) Does this document need to obsolete  RFC 1492 ? 7) Addressed 8) Addressed 9) Addressed",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2020-03-19 08:24:34-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-18 06:28:46-07:00",
    "text": "hank you for addressing most of my DISCUSS/comments. Only one little thing remains:KRB5 and KRB4 need normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-05-16 10:29:18-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 11:55:36-07:00",
    "text": "(1) The Gen-ART reviewer Stewart Bryant (SB) asked the following: \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MAX := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_ROOT := 0x0f \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_USER := 0x01 \u00a0 \u00a0  TAC_PLUS_PRIV_LVL_MIN := 0x00 SB> Where are these defined? Please define the semantics of these values. (2) Stewart also noted the following: \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ASCII := 0x01 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_PAP := 0x02 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_CHAP := 0x03 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_ARAP := 0x04 (deprecated) \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAP := 0x05 \u00a0 \u00a0  TAC_PLUS_AUTHEN_TYPE_MSCHAPV2 := 0x06 SB> There are lots of lists similar to the above. SB> I have not checked them all, but a number of the types  SB> in this and subsequent parts of the design don't seem SB> to be defined or have a definitive reference The way I would say this is that the document seems to be written for people who have already deployed this protocol, and elides details that would make it comprehensible to a new implementor. But it also contemplates the prospect of new implementations. If new implementations are actually expected (which I was surprised about, but can believe), I agree with Stewart that each of the field values need a definition that explains its semantic. If new implementations are not expected, then the reference to new implementations should be removed. (3) How is \"secure deployment\" defined? Since this is used as a restriction in several places, I think it needs to be defined precisely.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-09-22 10:59:31-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 22:10:21-07:00",
    "text": "I support the DISCUSS ballots by Alexey and Roman, as well as the comments by Deborah and Alissa that more text be in the introduction about the status and limitations here. I also need to add to Alexey\u2019s DISCUSS on 4.6, Text Encoding: \u00a0  To ensure interoperability of current deployments, the TACACS+ client \u00a0  and server MUST handle user fields and those data fields used for \u00a0  passwords as 8-bit octet strings.\u00a0 The deployment operator MUST \u00a0  ensure that consistent character encoding is applied from the end \u00a0 client to the server. This is a mine field.\u00a0 Treating passwords as raw octets without concern for encoding and normalization can cause authentication failures and can be used to attack systems where non-ASCII passwords are in use. Suppose I enter \u201ccr\u00e8me br\u00fbl\u00e9e\u201d as my password. How that\u2019s represented in UTF-8 depends upon my input device, as there are at least two valid representations of each accented vowel.\u00a0 Without normalization/canonicalization, passwords entered on different input devices might not match, blocking my access.\u00a0 And we haven\u2019t touched on bidirectional issues (mixing, say, Hebrew and English characters). The precis framework has detailed explanations of how to deal with usernames and passwords \u2014 see  RFC 8265  (and, for the overall precis framework,  RFC 8264 ). \u00a0  The encoding SHOULD be UTF-8, and other \u00a0  encodings outside printable US-ASCII SHOULD be deprecated.\u201d This doesn\u2019t make sense with respect to how we use \u201cdeprecated\u201d.\u00a0 You need to say \u201care deprecated\u201d, meaning that we recommend against using them.\u00a0 There\u2019s no  BCP 14  \u201cSHOULD\u201d involved here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-15 12:12:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-15 12:10:45-07:00",
    "text": "(1) I appreciate the deliberate and thoughtful attempt in this section to enumerate the possible risks/attacks and mitigations of the protocol as is.\u00a0 In addition to the top-level risks in Section 10.1, I can see the value of maintaining symmetry between Sections 5+10.2; 6+10.3 and 7+10.4.\u00a0 In the spirit of the middle ground this draft is trying to realize (document the as-is, but highlight the issues), I have the following feedback: (a) Section 10.1.\u00a0 I recommend replacing the first three paragraphs of Section 10.1 (\u201cTACACS+ protocol does not \u2026\u201d, \u201cWhile the protocol \u2026\u201d, and \u201cEven though \u2026\u201d) with the following text partially synthesized from Joe Salowey\u2019s review ( https://mailarchive.ietf.org/arch/msg/secdir/rsqrNbVEKph1RdWh836Ard73pHs ) with the current introduction: TACACS+ protocol does not include a security mechanism that would meet modern-day requirements.\u00a0 These security mechanisms would be best referred to as \u201cobfuscation\u201d and not \u201cencryption\u201d since they provide no meaningful integrity, privacy or replay protection.\u00a0 An attacker with access to the data stream should be assumed to be able to read and modify all TACACS+ packets. Without mitigation, a range of risks such as the following are possible: Accounting information may be modified by the man-in-the-middle attacker, making such logs unsuitable and untrustable for auditing purposes. Invalid or misleading values may be inserted by the man-in-the-middle attacker in various fields at known offsets to try and circumvent the authentication or authorization checks even inside the obfuscated body. (b) I recommend finding an alternative home and strengthening the text \u201cFor this reason, deployments SHOULD NOT use connections with TAC_PLUS_UNENCRYPTED_FLAG, as mentioned in the Best Practices section (Section 10.5)\u201d.\u00a0 It seemed odd to mix deployment guidance in a list of risks as currently written.\u00a0 I take Andrej Ota\u2019s point from  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  that there is no harm in requiring the obfuscation, such as it is.\u00a0 Furthermore, why couldn\u2019t this be MUST NOT use? (c) Section 10.5.3.\u00a0 I concur with the SECDIR recommendation and the follow-up discussion with Andrej Ota per  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  which would: s/stronger authentication/less weak/ (2) Section 10.2.\u00a0 I\u2019m confused by the deprecation of TAC_PLUS_AUTHEN_STATUS_FOLLOW but a seemingly weaker \u201cSHOULD NOT be used in modern deployments\u201d.\u00a0 I was expecting a MUST NOT. (3) Section 10.4.\u00a0 Why shouldn\u2019t accounting sessions also use secure transport per 10.5 (like 10.3 and 10.4) given the risks outlined in the text?\u00a0 I was expecting to see this section open with \u201cAccounting Session SHOULD be used via a secure transport (see Best Practices section (Section 10.5))\".",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-24 13:21:34-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-15 12:12:12-07:00",
    "text": "(1) I appreciate the deliberate and thoughtful attempt in this section to enumerate the possible risks/attacks and mitigations of the protocol as is.\u00a0 In addition to the top-level risks in Section 10.1, I can see the value of maintaining symmetry between Sections 5+10.2; 6+10.3 and 7+10.4.\u00a0 In the spirit of the middle ground this draft is trying to realize (document the as-is, but highlight the issues), I have the following feedback: (a) Section 10.1.\u00a0 I recommend replacing the first three paragraphs of Section 10.1 (\u201cTACACS+ protocol does not \u2026\u201d, \u201cWhile the protocol \u2026\u201d, and \u201cEven though \u2026\u201d) with the following text synthesized from Joe Salowey\u2019s LC review ( https://mailarchive.ietf.org/arch/msg/secdir/rsqrNbVEKph1RdWh836Ard73pHs ) and the current introduction: TACACS+ protocol does not include a security mechanism that would meet modern-day requirements.\u00a0 These security mechanisms would be best referred to as \u201cobfuscation\u201d and not \u201cencryption\u201d since they provide no meaningful integrity, privacy or replay protection.\u00a0 An attacker with access to the data stream should be assumed to be able to read and modify all TACACS+ packets. Without mitigation, a range of risks such as the following are possible: Accounting information may be modified by the man-in-the-middle attacker, making such logs unsuitable and untrustable for auditing purposes. Invalid or misleading values may be inserted by the man-in-the-middle attacker in various fields at known offsets to try and circumvent the authentication or authorization checks even inside the obfuscated body. (b) I recommend finding an alternative home and strengthening the text \u201cFor this reason, deployments SHOULD NOT use connections with TAC_PLUS_UNENCRYPTED_FLAG, as mentioned in the Best Practices section (Section 10.5)\u201d.\u00a0 It seemed odd to mix deployment guidance in a list of risks as currently written.\u00a0 I take Andrej Ota\u2019s point from  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  that there is no harm in requiring the obfuscation, such as it is.\u00a0 Furthermore, why couldn\u2019t this be MUST NOT use? (c) Section 10.5.3.\u00a0 I concur with the SECDIR recommendation and the follow-up discussion with Andrej Ota per  https://mailarchive.ietf.org/arch/msg/secdir/UgtsSfh1RaauNoMRi87FRqtI0YI  which would: s/stronger authentication/less weak/ (2) Section 10.2.\u00a0 I\u2019m confused by the deprecation of TAC_PLUS_AUTHEN_STATUS_FOLLOW but a seemingly weaker \u201cSHOULD NOT be used in modern deployments\u201d.\u00a0 I was expecting a MUST NOT. (3) Section 10.4.\u00a0 Why shouldn\u2019t accounting sessions also use secure transport per 10.5 (like 10.3 and 10.4) given the risks outlined in the text?\u00a0 I was expecting to see this section open with \u201cAccounting Session SHOULD be used via a secure transport (see Best Practices section (Section 10.5))\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-03-23 13:45:17-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-23 12:53:43-07:00",
    "text": "This document changes the registration policy to \"Expert Review\" which, as even quoted in this document, \"has no requirement for a formal document\".\u00a0 Yet the specific guidance to the expert is written as if there will always be a document: consider \"[i]f the document is not adopted by the IDR Working Group\", \"IANA will update [...] a reference to the associated document\", \"[i]n the event that the document is\", ... Is there a requirement for a document or not?\u00a0 (Alternately, what happens if there is a request with no associated document?)",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-03-25 07:42:16-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-24 12:07:49-07:00",
    "text": "I'm putting in a \"discuss\" DISCUSS that I expect to clear during the call. Several other ADs raised issues that deserve discussion. While they may not fall under the \"discuss criteria\", they also don't fall under the \"discuss non-criteria\" and I want to make sure we spent some time on discussing them.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-03-16 11:50:08-07:00",
    "end_reason": "position_updated",
    "start": "2021-03-16 11:39:09-07:00",
    "text": "I would like to understand the intent of this document a little better. RFC 8126  subtly implies that \"Expert Review\" is a little laxer than \"specification required\". But the guidance to experts in this draft seems to closely match \"IETF Review\" (sec 4.8 of 8126) except that it allows documents to get an allocation at an earlier stage in the process. The shepherd comment that \"RFC Required\" was an alternative proposal also indicates that the intent to become more, not less, strict. Indeed, the main change appears to be eliminating allocations to non-IETF-stream documents. So why not simply change the registry to \"IETF Review\" and allow provisional allocations? It would be much easier to use established mechanisms and standard definitions than rewriting them in this document. Is the SHOULD in Sec 2.1 carrying a lot of weight here?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-23 23:27:58-07:00",
    "end_reason": "position_updated",
    "start": "2022-10-20 04:18:41-07:00",
    "text": "# GEN AD review of  draft-ietf-pce-lsp-extended-flags-07 CC @larseggert Thanks to Roni Even for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/J2jEQIJoyAsZEbtU5IK14E3yROA ). ## Discuss ### 2119 terms This document has some ambiguities that would be clarified by using RFC2119  terms in a few more places: #### Section 3.2, paragraph 2 ``` -\u00a0 \u00a0 Note that PCEP peers MAY encounter varying lengths of the LSP- -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^\u00a0 -------- +\u00a0 \u00a0 Note that PCEP peers MUST handle varying lengths of the LSP- +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^ +++++ ``` #### Section 3.2, paragraph 3 ``` -\u00a0 \u00a0 than it currently supports or understands, it will simply ignore the -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^^^^^^^^ +\u00a0 \u00a0 than it currently supports or understands, it MUST ignore the +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^ ``` #### Section 3.2, paragraph 4 ``` -\u00a0 \u00a0 than the one supported by the implementation, it will consider the -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^^^^ ^^^^^^ ^ +\u00a0 \u00a0 than the one supported by the implementation, it MUST treat the +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ^^^^ ^^ ^^ ``` #### Section 5, paragraph 2 ``` -\u00a0 \u00a0 not understood by an implementation would be ignored.\u00a0 It is expected -\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^^ +\u00a0 \u00a0 not understood by an implementation MUST be ignored.\u00a0 It is expected +\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^^^^ ```",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2020-09-01 21:08:39-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-26 12:00:01-07:00",
    "text": "An easy one, but necessary IMHO: I'm confused by the IANA Considerations section.\u00a0 It looks like a verbatim copy from  RFC 5549  which made the original registration for \"Extended Next Hop Encoding\", but this isn't actually a new registration.\u00a0 Shouldn't this therefore be something like the following? NEW: RFC 5549  added \"Extended Next Hop Encoding\" to the Capability Codes registry, which was created by [ RFC5492 ].\u00a0 IANA is requested to update the definition of that entry to refer instead to this document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-25 19:12:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-20 22:01:35-07:00",
    "text": "There seems to be a bit of internal inconsistency in Appendix B.2: \u00a0  Names of PSDs participating in PSD DMARC must be registered this new \u00a0  registry.\u00a0 New entries are assigned only for PSDs that require use of \u00a0  DMARC.\u00a0 [...] These two sentences seem to be in conflict, since a PSD can participate in PSD DMARC without requiring use of DMARC for all its subdomains.\u00a0 The rest of the section is clear that the registry is only intended to be for PSDs that do require the use of DMARC for subdomains, so I expect that a minor tweak to the wording of \"PSDs participating in PSD DMARC\" would be an appropriate fix.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-01 20:39:28-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-18 00:31:01-08:00",
    "text": "Thank you for this document (and its predecessor); it's important to get these points clarified, and sooner rather than later.\u00a0 I expect that the following few issues should be quickly resolvable. Section 11.10.1 includes a reference to \"Section 11.7.2.1 of  RFC5661 \", but this document is obsoleting that document.\u00a0 It seems internally inconsistent to both obsolete and depend on the same source -- if we rely on that content, it should be included in this document. This is somewhat awkward since the limited nature of the update results in my not having the full context of the rest of the document; with that limitation in my understanding in mind, I'd like to confirm that we're comfortable with the use of \"network address\" in the context of trunking/migration, specifically the extent to which we do not discuss port numbers.\u00a0 The relevant XDR types do allow for optional port numbers to be included, with a default to be used when not specified, but in this document we do have a new note that different ports may be used for different connection types to the same logical server, and also that different ports \"is not the essence of the distinction between the two endpoints\".\u00a0 I think there might be cases where the port is relevant for a distinction, but the main ones I can think of are of questionable relevance (essentially, roughly equivalent to multiple userspace NFS servers on a single host but in different trust/privilege domains) -- I'd like another opinion or several. In a similar \"discuss discuss\" vein, Section 11.10.8 describes a scenario that does not give much clarity, at a protocol level, into what degree of replication synchronization a client can expect from a given file system that advertises multiple replicas.\u00a0 I recognize that this is de facto just stating the deployed reality, but it's also hard to feel good about having this level of ambiguity in a propsed standard, and the (unchanged) text in Section 11.5.5 seems to impose a stricter consistency requirement, at least on potential migration targets.\u00a0 (A bit more detail in the COMMENT section.) Section 11.13.2 mentions that \"[i]ssues connected with a client impersonating another by presenting another client's id string are discussed in Section 21\", but I failed to find this discussion in Section 21.\u00a0 (The discuss-level issue is just the internal inconsistency; there's a decent argument that this is covered by Appendix C's \"not written in accord with  RFC3552 \".\u00a0 Though if the text was already written for  draft-ietf-nfsv4-mv1-msns-update , not including it here seems a little silly.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-23 09:35:22-07:00",
    "end_reason": "position_updated",
    "start": "2022-01-31 14:22:06-08:00",
    "text": "It looks like we may have a setup where a compliant RP and compliant CA/repository fail to interoperate.\u00a0 This is sufficiently surprising that I want to confirm that it's the intended behavior.\u00a0 In particular, both manifests and CRLs have thisUpdate and nextUpdate fields, and since issuing an update to one requires issuing an update to the other (though the CRL is always actually generated first), it is only natural for us to give guidance that the times in question should match between manifest and corresponding CRL.\u00a0 However, we do this only as RECOMMENDED/SHOULD-level guidance, and accompany it by guidance to RPs that they SHOULD NOT reject a manifest of the fields do not match the CRL.\u00a0 Accordingly, when a CA violates the first SHOULD and issues manifeset+CRL with mismatched thisUpdate/nextUpdate, and an RP violates the second SHOULD (NOT) and rejects such a setup, the RP will be unable to get any RPKI data for that CA.\u00a0 (As a tangent, we also have one place where we give related guidance that the validity period of the single-use EE cert that signs the manifest match the thisUpdate/nextUpdate period, which we might want to keep in mind if we make any changes in this space.) It looks like  RFC 6486  had a conditional MUST-level requirement that *if* a manifest encompasses a CRL, then the \"nextUpdate\" fields MUST match (no guidance on thisUpdate), which we change to a statement of fact that each  manifest does encompass a CRL and guidance that the \"nextUpdate\"s SHOULD match. Additionally,  RFC 6486  had a MUST-level requirement for the validity period of the EE cert to exactly match the thisUpdate/nextUpdate time interval of the manifest, which we currently are relaxing to a SHOULD. Often in this scenario we would strengthen one of the SHOULDs to be a MUST so that interoperability is guaranteed, but I'm not sure that I see a clear argument for which requirement is better to make the MUST.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2023-03-16 14:16:13-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-16 07:42:47-07:00",
    "text": "Adding a discussion point: considering that this document contradicts the recommendation in  RFC 9319 , which is a BCP, shouldn't it update  RFC 9319 , and shouldn't it be a BCP? The BCP issue has already been raised, but I don't think the update thing has been mentioned. It seems as though it's the kind thing to do for users of  BCP 185  -- it's the way we have, in our document set, of saying \"oh hi, please don't assume all the information is just in this document here, please go check there too\".",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2023-05-07 15:11:48-07:00",
    "end_reason": "position_updated",
    "start": "2023-03-13 11:04:46-07:00",
    "text": "From the abstract, it seems this document is strongly urging some best practise. Why is this document Informational and not a BCP ? Unfortunately, the shepherd did not explain that. \u00a0  Any ROA object that includes resources which are a) no longer contained in the new CA certificate, or b) [...] , will be rejected as invalid. Isn't a) the normal expected case? I understand case b) but why is case a) listed here? Or is this saying a ROA with 10 prefixes, of which 1 prefix is no longer in the parent CA, will cause the entire ROA with 10 prefixes to be invalid, and not retain 9 valid prefixes? If so, I think the text should be clarified to say that more clearly. If no so, then I think this case should be omitted from the sentence as it wouldn't be relevant to a \"problem case\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-08-17 17:51:11-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-21 21:26:43-07:00",
    "text": "The example JWK for cryptosuite 1 in \u00a75.1 is not well-formed.\u00a0  RFC 8037 key-exchange uses a crv of \"X25519\" and a kty of \"OKP\". (See COMMENT for more quibbles with \u00a75.1.) I think Appendix E is also using the wrong \"kty\" for X25519 (but is properly using \"X25519\" as the \"crv\"). I'd also like to discuss our treatment of channel binding, as the current mention seems dangerously incomplete.\u00a0 I don't remember if there is generic discussion of channel binding in the core EAP RFCs (if so, a specific reference would help), but otherwise if we're going to mention that protocol elements can be used for channel binding we should give some indication of how to actually do so in a secure manner (e.g., what protocol element needs to be verified against external channel information and what to do if they don't match).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-07-30 12:51:39-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-19 15:37:04-07:00",
    "text": "Thank you for the work on this document. I have a couple of blocking comments related to the IANA section, which should be easy to fix, plus some minor non blocking comments below. Francesca 1. ----- Section 5. FP: IANA is requested to create a sub registry to the EAP registry, but there is no actual \"Nimble out-of-band authentication for EAP Parameters\" registry defined, nor values registered in it. Either this is a new page or (I would suggest) the subregistries are just created directly under the EAP page. 2. ----- Section 5.1 and following FP: This document defines several new registry with policy Specification required, which will need designated experts.  https://tools.ietf.org/html/rfc8126#section-5.3  states that: \u00a0  When a designated expert is used, the documentation should give clear \u00a0  guidance to the designated expert, laying out criteria for performing \u00a0  an evaluation and reasons for rejecting a request.\u00a0 In the case where I believe designated expert guidance should be added to this document.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-10-26 13:43:17-07:00",
    "end_reason": "position_updated",
    "start": "2018-10-25 07:19:38-07:00",
    "text": "Section 9.2 says: \u00a0  An autonomic network consists of autonomic devices that form a \u00a0  distributed self-managing system.\u00a0 Devices within a domain share a \u00a0  common trust anchor and thus implicitly trust each other.\u00a0 [...] This seems to be a fundamental misstatement of how trust anchors work.\u00a0 Sharing a trust anchor means that you are willing to trust the same entity, the holder of the private key for that trust anchor. It does not imply any relationship between the two entiteis that trust the trust anchor. To be clear,\u00a0 I think that the authors do understand the actual trust and security situation here, and the rest of the subsection makes sense; I just think that this text needs to be changed to make the situation clear to the reader in an accurate way.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-09 07:40:56-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-05 04:07:18-07:00",
    "text": "This is a fine document and I only found a few minor things that should be easy to fix. In 4.1: \u00a0  The candidate attribute can itself be extended.\u00a0 The grammar allows \u00a0  for new name/value pairs to be added at the end of the attribute. \u00a0  Such extensions MUST be made through IETF Review or IESG Approval \u00a0  [ RFC8126 ] and the assignments MUST contain the specific extension and \u00a0  a reference to the document defining the usage of the extension. This is effectively creating a new registry, but this information is not present in the IANA Considerations section.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-08-14 10:33:21-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-09 07:40:56-07:00",
    "text": "This is a fine document and I only found a few minor things that should be easy to fix. Thank you for addressing my comments. Unfortunately it doesn't look like my DISCUSS point was addressed yet. Also, your IANA change introduced another issue. 1) In 5.1: \u00a0  The candidate attribute can itself be extended.\u00a0 The grammar allows \u00a0  for new name/value pairs to be added at the end of the attribute. \u00a0  Such extensions MUST be made through IETF Review or IESG Approval \u00a0  [ RFC8126 ] and the assignments MUST contain the specific extension and \u00a0  a reference to the document defining the usage of the extension. This is effectively creating a new registry, but this information is not present in the IANA Considerations section. So you need to do one of the following: a) Remove the last sentence b) Reword it to only talk about IETF stream documents for defining extensions (IESG can't really do what you ask, unless you have an IANA registry established for these.) c) Move this text to the IANA considerations and update it to properly define a new IANA registry. 2) In 10.2: You removed the following text: \u00a0  o\u00a0 Name, Email, and Address of a contact person for the registration\t \t\t   \u00a0  o\u00a0 Organization or individuals having the change control I think removing (postal) Address is a good thing. However the rest of this is still needed, as IANA uses this information to decide whether a person/organization is allowed to update an existing registry entry. So please consider adding it back or explain why this information is not needed for a registry where external organizations can add value (without publishing an RFC).",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2019-08-09 05:56:23-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-06 08:59:20-07:00",
    "text": "Apologies for multiple ballot emails, wrapped up a bit too soon the first time. I'm confused about Section 7. The mechanisms in  RFC 4091  and  RFC 4092  were deprecated in  RFC 5245 , and this is mentioned in  RFC 8445 . Why does this specification then need to additionally normatively recommend the use of ICE for dual-stack scenarios? This could be interpreted as saying that ANAT is an alternative option for this use case, but it shouldn't be according to  RFC 8445 .",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-09 11:38:44-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-05 17:14:00-07:00",
    "text": "A fairly minor point, but the example in Section 4.6 is not compliant with the rest of the document.\u00a0 Specifically, any implementation *of this document* must include the \"ice2\" ice-option in addition to any other option being used, per Section 3.2.1.5.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-13 18:25:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-09 11:38:44-07:00",
    "text": "A fairly minor point, but the example in Section 5.6 is not compliant with the ABNF for the ice-options production, which uses SP to separate different ice-option-tag values; the example uses a comma.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-13 18:34:33-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-05 19:28:32-07:00",
    "text": "(1) Section 8.1. Per \u201cThese require techniques for message integrity and encryption for offers and answers, which are satisfied by the TLS mechanism [ RFC3261 ] when SIP is used\u201d, the guidance is right (use TLS), but this reference is outdated.\u00a0 Section 26.2.1 of  RFC3261  provides rather old guidance on the ciphersuite.\u00a0 Is there a reason why not to use  BCP195  for guidance on versions/ciphersuites? (2) Section 8.2.1, The \u201cvoice hammer attack\u201d appears to be an artifact of SDP.\u00a0 The text explicitly notes that this attack is not \u201cspecific to ICE but that ICE can help provide a remediation\u201d (aside, should \u201cremediation\u201d be \u201cmitigation\u201d).\u00a0 However, the preceding introductory section (8.2) explicitly says \u201cthere are several attacks possible with ICE\u201d.\u00a0 These two statements aren\u2019t consistent. (3) Section 8.2.2.\u00a0 This section reads like an operational consideration.\u00a0 The setup scoped in the parent Section 8.2, \u201cthere are several attacks possible with ICE when the attacker is an authenticated and valid participant in the ICE exchange\u201d, isn\u2019t discussed here (i.e., how is the presence or absence of an ALG germane to an attacker who is a participant in the ICE exchange) (4) Section 8.\u00a0 Is there a reason why the security considerations from  RFC8445  are not noted as also applying (e.g., Section 19.1 - .4.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-06 22:33:26-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 18:43:58-07:00",
    "text": "(Arguably a \"discuss discuss\".) If we don't have any worked examples of signatures with message recovery, should we include that possibility in the Internet Standard version of the protocol?\u00a0 Some of the description around how the details of this would work remain unclear to me.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-29 05:19:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-18 06:11:02-07:00",
    "text": "Sorry for the late discuss, however rather than deferring the review two weeks we agreed that I would do a later review.  This relates to the registries created in  RFC 8152 . These registries do exist, however the registry rules will not be documented in the replacement standards track document that is in force. And if you look at the IANA page for the COSE regsistries ( https://www.iana.org/assignments/cose/cose.xhtml#algorithms ), they simply reference back to  RFC 8152  which after approval of this document will be an obsoleted RFC.  Thus, I am of the opinion that the rules for expert review and other registration rules for an IETF created registry should exist in an current in force RFC that is referenced by the registry. Thus, I would propose that the registration rule texts from Section 16 in  RFC 8152  is included in Section 12 of this document and also request the IANA to update the registry references to point to the new document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-08 04:20:36-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 19:07:57-07:00",
    "text": "Are the wrong data structures being referenced or did I misunderstand something? ** Section 5.\u00a0 Per \u201cAbbreviated counter signatures use the structure COSE_Countersign1\u201d, this doesn\u2019t seem consistent with the more detailed write-up in Section 5.2 which says that \u201cThe byte string representing the signature value is placed in the CounterSignature0 attribute\u201d.\u00a0 The document makes no other reference to COSE_Countersign1.\u00a0  The shepherd write-up notes that \u2018one item to note is the decision to keep the context string \"COSE_Countersign1\" for abbreviated countersignatures\u2019.\u00a0 However, I found no such reference in Step 1 of Section 4.4 (page 22) which enumerated the possible strings. ** What is the intended name of the structure for the Counter Signature -- is it COSE_Countersignature or COSE_Countersign? -- Table 1, Section 2, Section 4.4 and Section 5.1 (to include the CDDL) reference COSE_Countersignature but -- Section 5. Per \u201cFull counter signatures use the structure COSE_Countersign \u2026\u201d -- Section 5.1.\u00a0 Per \u201cA tagged COSE_Countersign structure \u2026\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-02-16 03:42:49-08:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-16 01:49:29-08:00",
    "text": "FC 6125 use needs more details. <>",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-04-24 03:16:18-07:00",
    "end_reason": "discuss_updated",
    "start": "2017-02-16 03:42:49-08:00",
    "text": "When referencing  RFC 6125  you need to provide more details. In particular, you need to pretty much answer every question in section 3 of  RFC 6125 :  One example of how this might look like is in Section 9.2 of . For your convenience the relevant text is pasted below: \u00a0  Routers MUST also verify the cache's TLS server certificate, using \u00a0  subjectAltName dNSName identities as described in [ RFC6125 ], to avoid \u00a0  man-in-the-middle attacks.\u00a0 The rules and guidelines defined in \u00a0  [ RFC6125 ] apply here, with the following considerations: \u00a0 \u00a0 \u00a0 Support for DNS-ID identifier type (that is, the dNSName identity \u00a0 \u00a0 \u00a0 in the subjectAltName extension) is REQUIRED in rpki-rtr server \u00a0 \u00a0 \u00a0 and client implementations which use TLS.\u00a0 Certification \u00a0 \u00a0 \u00a0 authorities which issue rpki-rtr server certificates MUST support \u00a0 \u00a0 \u00a0 the DNS-ID identifier type, and the DNS-ID identifier type MUST be \u00a0 \u00a0 \u00a0 present in rpki-rtr server certificates. \u00a0 \u00a0 \u00a0 DNS names in rpki-rtr server certificates SHOULD NOT contain the \u00a0 \u00a0 \u00a0 wildcard character \"*\". \u00a0 \u00a0 \u00a0 rpki-rtr implementations which use TLS MUST NOT use CN-ID \u00a0 \u00a0 \u00a0 identifiers; a CN field may be present in the server certificate's \u00a0 \u00a0 \u00a0 subject name, but MUST NOT be used for authentication within the \u00a0 \u00a0 \u00a0 rules described in [ RFC6125 ]. The only thing missing from the above is explicit mentioning that SRV-ID and URI-ID are not used. (I think the same should apply to your document.)",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2017-07-21 04:08:03-07:00",
    "end_reason": "position_updated",
    "start": "2017-04-24 03:16:18-07:00",
    "text": "Thank you for addressing my DISCUSS about use of  RFC 6125 . I have one\u00a0 new small issue from your recent change in In 5.2.3 (that was addressing my comment to include a response example): the example doesn't include Content-Type and (possibly) Transfer-Encoding header fields. Without these it doesn't look syntactically correct.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-07-03 11:58:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-07-02 13:20:42-07:00",
    "text": "This is a \"discuss discuss\" -- it's an important question and I'd like to talk about it, but it's not clear that any change to the document will be needed. Once this (and some of the more substantive items in the Comment section) is resolved, I'd be happy to ballot Yes. The introduction notes as an advantage of JWT that: \u00a0  (d)\u00a0 (collection minimization) The request can be signed by a third \u00a0 \u00a0 \u00a0 \u00a0 party attesting that the authorization request is compliant with \u00a0 \u00a0 \u00a0 \u00a0 a certain policy.\u00a0 For example, a request can be pre-examined by \u00a0 \u00a0 \u00a0 \u00a0 a third party that all the personal data requested is strictly \u00a0 \u00a0 \u00a0 \u00a0 necessary to perform the process that the end-user asked for, \u00a0 \u00a0 \u00a0 \u00a0 and statically signed by that third party.\u00a0 The authorization \u00a0 \u00a0 \u00a0 \u00a0 server then examines the signature and shows the conformance \u00a0 \u00a0 \u00a0 \u00a0 status to the end-user, who would have some assurance as to the \u00a0 \u00a0 \u00a0 \u00a0 legitimacy of the request when authorizing it.\u00a0 In some cases, \u00a0 \u00a0 \u00a0 \u00a0 it may even be desirable to skip the authorization dialogue \u00a0 \u00a0 \u00a0 \u00a0 under such circumstances. I'm pretty uncomfortable about suggesting that the authorization dialogue can/should be skipped; do we need to keep this example? Maybe just talking about what an expected use case could be would help alleviate my unease.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-11 08:52:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-07-03 11:58:53-07:00",
    "text": "My apologies; my previous position was incomplete.\u00a0 Updated to note namespacing issues, and one minor terminology nit about \"DNS-ID\". There seem to be some pretty serious namespacing issues that are not discussed at all in this document.\u00a0 Specifically, using JWT as a container for OAuth 2.0 authorization request parameters (including extension parameters) introduces the usage of many new names (of JSON name/value pairs) into the JWT claims namespace.\u00a0 Furthermore, the addition is not bounded, as any new OAuth extension parameters are implicitly permitted to be used as well!\u00a0 The IANA Considerations make no mention of the collapsed namespace for JWT claims and OAuth 2.0 (authorization request) parameters, leaving substantial potential for collisions in the future. Relatedly, using \"application/jwt\" as the Content-type of the HTTP response from dereferencing the request_uri with no explicit indication of the type/profile of JWT used (whether in the content type or in the JWT claims themselves) gives some risk of misinterpretation of the content.\u00a0 Consider, for example, when that request_uri is dereferenced not by the authorization server in the process of fulfilling an authorization request, but instead by some other service that expects a different type of JWT. This second point is a \"discuss discuss\" -- it's an important question and I'd like to talk about it, but it's not clear that any change to the document will be needed. The introduction notes as an advantage of JWT that: \u00a0  (d)\u00a0 (collection minimization) The request can be signed by a third \u00a0 \u00a0 \u00a0 \u00a0 party attesting that the authorization request is compliant with \u00a0 \u00a0 \u00a0 \u00a0 a certain policy.\u00a0 For example, a request can be pre-examined by \u00a0 \u00a0 \u00a0 \u00a0 a third party that all the personal data requested is strictly \u00a0 \u00a0 \u00a0 \u00a0 necessary to perform the process that the end-user asked for, \u00a0 \u00a0 \u00a0 \u00a0 and statically signed by that third party.\u00a0 The authorization \u00a0 \u00a0 \u00a0 \u00a0 server then examines the signature and shows the conformance \u00a0 \u00a0 \u00a0 \u00a0 status to the end-user, who would have some assurance as to the \u00a0 \u00a0 \u00a0 \u00a0 legitimacy of the request when authorizing it.\u00a0 In some cases, \u00a0 \u00a0 \u00a0 \u00a0 it may even be desirable to skip the authorization dialogue \u00a0 \u00a0 \u00a0 \u00a0 under such circumstances. I'm pretty uncomfortable about suggesting that the authorization dialogue can/should be skipped; do we need to keep this example?",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-06-22 14:04:14-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-16 02:02:19-07:00",
    "text": "This should be quick to clear up, but the IANA Considerations section has a few issues: Section 5.1 declares a new registry with a Specification Required policy.\u00a0  RFC 8126  explains what this means in its Section 4.6, and notes that this will result in a Designated Expert being appointed, and further stipulates that \"clear guidance to the designated expert should be provided when defining the registry\".\u00a0 However, none is evident here.\u00a0 Was this an oversight? Section 5.2 declares a new registry with a First Come First Served policy.\u00a0  RFC 8126 , Section 4.4, covers this, and says in pertinent part, \"... in addition to the contact person field or reference, the registry should contain a field for change controller.\"\u00a0 That's absent here, so please add one. In Section 5.3, the \"Required Parameters\" and \"Optional Parameters\" need to be \"N/A\", not \"None\".\u00a0 See  RFC 6838 , Section 5.6.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-23 19:02:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-15 15:37:11-07:00",
    "text": "Thanks to Yoav Nir for the secdir review. I agree with Yoav and would like to see his comment addressed: The document defines a CBOR-encoded problem details structure, similar to the JSON- or XML-encoded structure defined in  RFC 7807 . As such, the security considerations for it mostly mirror those of  RFC 7807 , and that is all that the Security Considerations section says.\u00a0 Following this reference, the Security Considerations section of 7807 urges caution when defining new problem types for fear of leaking sensitive information in the relevant fields of new types. There is, however, a difference between 7807 and this document. In 7807 different problems are identified by \"type\". In this document, there is no explicit type. Instead, there are basic details that are defined, plus a registry of standard and custom extra attributes that can be defined. The security considerations section in 7807 is phrased in terms of new types. Security considerations text written specifically for this documentation would not mention new types (which don't exist), but new detail entries. Still, the message would be the same. When defining new detail entries, care should be taken that they do not leak sensitive information.\u00a0 Yet because of the difference, I believe that the text should be written specifically for this document, not just referenced from 7807.",
    "type": "Discuss"
  },
  {
    "ad": "Benoit Claise",
    "end": "2017-09-23 09:14:54-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 00:56:41-07:00",
    "text": "1. I agree with Tim Wicinski's OPS DIR point about IANA. \u00a0 \u00a0 The content appears to be fine, but there are some outdated (the biggest one is \u00a0 \u00a0 5226 replaced by 8126), but its the IANA section which appears the most \u00a0 \u00a0 confusing. \u00a0 \u00a0 7.1 OSPF Router Information (RI) Registry -\u00a0 appears fine \u00a0 \u00a0 7.2 OSPF Tunnel Encapsulation Attribute Sub-TLV Registry \u00a0 \u00a0 This one defines the values being defined/allocated from \"This Document\" but in \u00a0 \u00a0 Section 5, each Sub-TLV is defined in other documents, so it's totally \u00a0 \u00a0 confusing. 2. It's not clear which of the following sub-TLVs are required/relevant/interconnected in the Encapsulation Capability TLV \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0\u00a0 \u00a0 Reserved\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 1\u00a0 \u00a0 Encapsulation\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 2\u00a0 \u00a0 Protocol Type\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 3\u00a0 \u00a0 Endpoint\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 4\u00a0 \u00a0 Color\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 5\u00a0 \u00a0 Load-Balancing Block\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 6\u00a0 \u00a0 IP QoS\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 7\u00a0 \u00a0 UDP Destination Port\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This document The only hint is: \u00a0 \u00a0 \u00a0 Value (variable): Zero or more Tunnel Encapsulation Attribute Sub- \u00a0 \u00a0 \u00a0 TLVs as defined in Section 5. Zero? really, what's the point? Now, from an operational point of view, which sub-TLVs are required/make sense? Are some sub-TLVs irrelevant without others? Ex: Color without Encapsulation Could we have multiple identical sub-TLVs? Ex: Color",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2017-09-18 13:25:43-07:00",
    "end_reason": "position_updated",
    "start": "2017-08-30 19:49:55-07:00",
    "text": "* There seems to be an difference between this document's definition of sub-TLVs (with 2 octet types and lengths) and those of  RFC5512  (with 1 octet types and lengths). So I am surprised to see the document point to the  RFC5512  based TLVs for both syntax and semantics (Sections 5.1, 5.2, 5.3 ...) . Can you please explain how these sub-TLVs are encoded on the wire to be compatible with this draft?",
    "type": "Discuss"
  },
  {
    "ad": "Jim Guichard",
    "end": "2023-06-30 05:48:10-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-01 07:19:56-07:00",
    "text": "I am wondering why this is an informational document when it uses reserved bits from both QUIC and TCP headers (?). If those reserved bits are used by the mechanisms described in this document but there is no \"official\" allocation of the bits then future documents that wish to use these bits will be limited and/or clash with an Informational RFC. Adding a DISCUSS as although this is not a technical area of expertise for me, it seems unusual and I would like to better understand the document track selection.  I also do not see a transport area directorate review and in fact the document shepherd highlights that the document could benefit from such a review. Given that the bits introduced in the document are suggested to be carried in the QUIC and TCP headers using their reserved bits, then a review by the area responsible for those transport protocols seems mandatory.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2023-08-16 01:49:09-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-24 06:55:13-07:00",
    "text": "Thanks for working on this specification. I hope it will be helpful for the valid network observer who does the flow measurement (given that the end-points actually implements the markings). Thanks to Colin Perkins for the TSVART review ( https://mailarchive.ietf.org/arch/msg/ippm/OMrRG_0CG8uRHVz0o6ivqRD8T6g/  ) and also Lucas Pardue ( https://mailarchive.ietf.org/arch/msg/ippm/RgtxAHmJfANjlfPkn1Jb4Hbbcs8/  ) for his review of the document. Both reviews had led to changes in the document which should improve and clarify the specification even more. As I agree with both the reviewers , even though I have already see some resolutions, I am holding this discuss to make sure agreed resolutions are landed in the document we approve.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-08-23 14:40:48-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-08-23 14:39:27-07:00",
    "text": "This is a process DISCUSS. The datatracker indicates that the intended status of this document is Internet Standard.\u00a0 However, two process points are not being followed: 1- The replaced document ( rfc7816 ) is an Experimental RFC.\u00a0 According to  rfc6410 , the Standards Track maturity levels first go through a Proposed Standard. 2-  rfc6410  requires a 4-week IETF LC to move to Internet Standard, but the LC for this document lasted only 2. Moving the intended status of this document to Proposed Standard would be one way to address this DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-08-23 15:08:37-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-23 14:40:48-07:00",
    "text": "This is a process DISCUSS (directed at the responsible AD). The datatracker indicates that the intended status of this document is Internet Standard.\u00a0 However, two process points are not being followed: 1- The replaced document ( rfc7816 ) is an Experimental RFC.\u00a0 According to  rfc6410 , the Standards Track maturity levels first go through a Proposed Standard. 2-  rfc6410  requires a 4-week IETF LC to move to Internet Standard, but the LC for this document lasted only 2. Moving the intended status of this document to Proposed Standard would be one way to address this DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-09-01 13:15:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-24 05:23:10-07:00",
    "text": "Thank you for the work put into this document. A simple but efficient technique. Please find below one blocking DISCUSS point (probably easy to address). Please also address Jean-Michel Combes' INTDR review at  https://datatracker.ietf.org/doc/review-ietf-dnsop-rfc7816bis-10-intdir-telechat-combes-2021-08-20/ Special thanks to Tim Wicinski for his shepherd's write-up notably about the WG consensus. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 2.1 -- I support Erik Kline's COMMENT on this and am raising it to a blocking DISCUSS. A/ in all the discussion in the last \u00a7, a AAAA would have the same benefit when compared to a NS QTYPE. Or what did I miss ? B/ the last two sentences \"Another potential benefit...happy eyeballs query for the A QTYPE.\" are puzzling as using A QTYPE will actually only cache the A answer for the minimized request and more and more Internet users are using IPv6 nowadays (and possibly even more recursive DNS servers). Hence, I would welcome some discussion in the last \u00a7 about the benefit of using A QTYPE rather than AAAA QTYPE and, as suggested by Erik Kline, please remove the last 2 sentences.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2023-01-09 05:52:27-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-22 04:55:56-08:00",
    "text": "# GEN AD review of  draft-ietf-lpwan-schc-over-sigfox-18 CC @larseggert ## Discuss ### Section 3.6.1.3.1, paragraph 11 ``` \u00a0 \u00a0  When using the Single-byte SCHC Header for Uplink Fragmentation, the \u00a0 \u00a0  Fragmentation Header MUST be of 8 bit size, and it is composed as \u00a0 \u00a0  follows: \u00a0 \u00a0  *\u00a0 RuleID size: 3 bits \u00a0 \u00a0  *\u00a0 DTag size (T): 0 bit \u00a0 \u00a0  *\u00a0 Fragment Compressed Number (FCN) size (N): 5 bits \u00a0 \u00a0  *\u00a0 As per [ RFC8724 ], in the No-ACK mode the W (window) field is not \u00a0 \u00a0 \u00a0 \u00a0 present. \u00a0 \u00a0  *\u00a0 Regular tile size: 11 bytes \u00a0 \u00a0  *\u00a0 All-1 tile size: 0 to 10 bytes \u00a0 \u00a0  *\u00a0 Inactivity Timer: Application-dependent.\u00a0 The default value is 12 \u00a0 \u00a0 \u00a0 \u00a0 hours. \u00a0 \u00a0  *\u00a0 RCS size: 5 bits ``` The fragmentation header fields in this list add up to much more than 8 bit, some are zero, and for the inactivity timer, no encoded length is given at all? Many similar lists in this document have similar issues.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2023-02-02 13:29:45-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-29 20:48:26-08:00",
    "text": "** Section 3.2.  \u00a0  Messages sent from the Device to the Network are delivered by the \u00a0  Sigfox network (NGW) to the Network SCHC C/D + F/R through a \u00a0  callback/API with the following information: \u00a0  ...  \u00a0  *\u00a0 Device Geolocation (optional) In some circumstances, sending device location information is privacy sensitive.\u00a0 Please provide a pointer or summary text for the relevant security considerations. ** Section 5.\u00a0 The security considerations describe a collection of security services such as authenticity, confidentiality, and replay protection for the Sigfox protocol.\u00a0 However, none of these appear to be described in in this document and no references are provided. -- Per confidentiality: although not cited, Section 5.3 (\u201cApplicative payload encryption\u201d) of  https://storage.googleapis.com/public-assets-xd-sigfox-production-338901379285/6f9a5819-5aa1-4fde-a2b7-eb1ad5193829.pdf  (which is the PDF link describing v1.6 of the SigFoxx protocol from the URL cited at [sigfox-spec]) says: [snip start] Payload encryption is a procedure that encrypts the payload of applicative messages over the air, in both uplink and downlink communication. It uses an AES128 algorithm in mode CTR with an encryption key (Ke), unique per end-point. The procedure is specified in a dedicated Sigfox specification document. [snip end] What is the \u201cdedicated Sigfox specification\u201d? -- Per the \u201cThe radio protocol authenticates and ensures the integrity of each message\u201d is that described in Section 3.8 of [sigfox-spec]? Please describe these security mechanisms or cite them.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-03 06:05:47-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-12-01 10:18:09-08:00",
    "text": "I support Erik's discuss. I see that Roman has already suggested adding normative language regarding the limitation to a single administrative domain (in addition to the \"MUST filter by default for EBGP sessions\"), which I agree with. However, I think there is an additional consideration regarding the limitation of use to a single administrative domain, wherein the domain of use for the tunnel encapsulation attribute may diverge from the domain of use of segment routing, that seems to place this document in conflict with the requirements of  RFC 8402 .\u00a0 In particular, RFC 8402  says, for SR-MPLS and SRv6, that boundary routers \"MUST filter any external traffic\", and additionally for SRv6 that \"explicit routing information MUST NOT be leaked through the boundaries of the administrered domain\".\u00a0 In \u00a73.7 of this document, though, we find that for the Prefix-SID sub-TLV, \"the receiving BGP speaker need not even be in the same Segment Routing Domain as the tunnel's egress endpoint, and there is no implication that the prefix-SID for the advertised prefix is the same in the Segment Routing domains of the BGP speaker that originated the sub-TLV and the BGP speaker that received it\", which seems to suggest violation of the  RFC 8402  requirement.\u00a0 I think we need to have greater clarity on what relationship is actually intended between the SR domain and the tunnel encapsulation usage domain, and if they are to diverge, we need to both somehow rectify this behavior with RFC 8402  and to very clearly document how the 8402-mandated filtering at the SR domain boundary is supposed to happen when the boundary includes tunneled traffic. I also would like to ensure that we have had adequate discussion of the relationship between this document and  RFC 8365 .\u00a0 The IESG has received comments recently (in the context of a different document) that it is irresponsible to effectively obsolete or deprecate existing work without identifying or explicitly updating such work, and without indicating whose responsibility it is to find discrepancies.\u00a0 That seems like it might apply to what's currently in Appendix A, which on first reading suggests \"there might be a problem here, but we aren't saying exactly what or how to fix it, or even who is going to do that work\".",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-01-11 14:58:44-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-03 06:05:47-08:00",
    "text": "[Updated to remove the point about the \"relationship between this document and  RFC 8365 \"; no other changes] I support Erik's discuss. I see that Roman has already suggested adding normative language regarding the limitation to a single administrative domain (in addition to the \"MUST filter by default for EBGP sessions\"), which I agree with. However, I think there is an additional consideration regarding the limitation of use to a single administrative domain, wherein the domain of use for the tunnel encapsulation attribute may diverge from the domain of use of segment routing, that seems to place this document in conflict with the requirements of  RFC 8402 .\u00a0 In particular, RFC 8402  says, for SR-MPLS and SRv6, that boundary routers \"MUST filter any external traffic\", and additionally for SRv6 that \"explicit routing information MUST NOT be leaked through the boundaries of the administrered domain\".\u00a0 In \u00a73.7 of this document, though, we find that for the Prefix-SID sub-TLV, \"the receiving BGP speaker need not even be in the same Segment Routing Domain as the tunnel's egress endpoint, and there is no implication that the prefix-SID for the advertised prefix is the same in the Segment Routing domains of the BGP speaker that originated the sub-TLV and the BGP speaker that received it\", which seems to suggest violation of the  RFC 8402  requirement.\u00a0 I think we need to have greater clarity on what relationship is actually intended between the SR domain and the tunnel encapsulation usage domain, and if they are to diverge, we need to both somehow rectify this behavior with RFC 8402  and to very clearly document how the 8402-mandated filtering at the SR domain boundary is supposed to happen when the boundary includes tunneled traffic.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-01-09 22:55:49-08:00",
    "end_reason": "position_updated",
    "start": "2020-11-30 21:28:25-08:00",
    "text": "[ section 3.3.1 ] * The text about \"[a]ny one-octet value can be transported\" leaves me \u00a0 wondering about how values that result in ECN bits being set should be \u00a0 treated. \u00a0 I think there needs to be some recognition here that the DSCP part of \u00a0 the octet is only 6 bits (2474 section 3), and that bits 6 & 7 \"MUST/SHOULD \u00a0 be zero on transmission and MUST/SHOULD be ignored by the recipient\". \u00a0 Another way to ask the question here is: if ECN is not to be specified as \u00a0 part of this octet (and IMHO it should not be), which ranges of 6 bit \u00a0 values are permitted: [0..63], with the understanding this will be shifted \u00a0 before setting the octet, or [0,4,8,12,...,252]?\u00a0 Given the text \"It \u00a0 specifies the setting of the one-octet...\", I think it implies the latter, \u00a0 but some clarification would, I think, be helpful.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-15 08:51:54-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-03 02:52:15-08:00",
    "text": "So this is really to start a discussion of how the framework approach of this document may not be explicit enough on what combination is actually viable combination and have existing specification for how to deal with a number of behaviors for tunnels. So my view after having read this one is that the signalling is specified in a two tier fashion, with an outer encapsulation that can be IPvX, IPvX/UDP for example and then a tunnel protocol like GRE, VXLAN, L2TPv3. So I don't believe all combinations of outer encapsulation and tunnel protocol is actually defined. This document does not provide a table with the reference for where the actual data plan specification for combinations are provided. I think it would be good if there actually existed such a table/list.  The next aspect of this discuss is the difficulty in determining if the provided sub-TLVs are sufficient. I will mention a number of potential ones that I wonder if they are necessary to configure these combinations.  To build on Erik Kline's discuss. So are for all these combinations when IP is the outer encapsulation is the egress ECN behavior to correctly mark or drop inner payload well defined. If the egress is not guaranteed to do the correct, then I think a configuration option is required.  When using UDP encapsulation combined with IPv6 there is the question if one can safely use zero-checksum. Per  RFC 6935  and  RFC 6936  some consideration is needed to determine if the inner payload is safe to combine with zero checksum. So this requires the combination of tunnel protocol and inner payload to determine this. So I think some of these tunnel protocols have text on this, but I don't know which combinations have this specified. And also here arise a question if some of these will also need a configuration option as there exist some inner payloads that could not be safe and thus a different tunnel with checksum enabled may be required.  When using UDP encapsulation I am wondering over source port usage. To my knowledge some of these protocols like VXLAN do defines that source ports are picked randomly to ensure header hashing will provide different values for different inner flows. So is there a need in any of this cases to identify a single source port?  So I at least are unable to determine if this specification are containing all necessary attributes when it doesn't have identification of what combinations it expect to work, and what behavior on the above aspects is just working.  So lets start discussing what needs to be addressed here if any.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-07 14:02:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-03 07:02:48-08:00",
    "text": "Per the conversation on my original COMMENT (thanks for the quick response),  https://mailarchive.ietf.org/arch/msg/idr/hV2t6-8mq2dOvmXO-PvLuiON5o4/ , I'm escalating this item to a DISCUSS.\u00a0  Section 11 However, it is intended that the Tunnel Encapsulation  attribute be used only within a well-defined scope, e.g., within a set of Autonomous Systems that belong to a single administrative entity. As this applicability text should be read as a normative SHOULD, please provide a discussion on the risks of open Internet usage in the Security Considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-10-07 07:19:37-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-28 11:34:41-07:00",
    "text": "Holding this point because we should discuss it; this might be a problem to be solved by a different document, in which case I'll lift it. Section 8 of  RFC8126  says that bis documents should update the reference in IANA registries to replace obsolete documents with not-obsolete ones. It appears that 3658 didn't have a \"bis\" document but clearly was replaced by three others. I don't really understand how they fully obsolete 3658 if there are still registries hanging out there. Regardless, perhaps this draft is an opportunity to update the reference to these registries? Or is 3658 not \"really\" obsolete?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-03-02 07:17:00-08:00",
    "end_reason": "position_updated",
    "start": "2018-12-05 13:53:28-08:00",
    "text": "This is a process DISCUSS. This document replaces  draft-randriamasy-alto-cost-calendar , but this information is not reflected in the datatracker.\u00a0 The individual draft has an IPR declaration attached to it [1], but the failure to link the two documents has resulted in the IPR indication not carrying over.\u00a0  The direct effect is that the IETF Last Call [2] explicitly says that \"No IPR declarations have been submitted directly on this I-D.\" The Shepherd writeup says that \"The entire author team has confirmed conformance with  BCP 78 /79 with the shephered.\" -- but that doesn't indicate whether IPR is present or not, just conformance.\u00a0 In looking through the mailing list archive, I couldn't find mention of the IPR at adoption [3] [4] or at WGLC [5]. The declaration was made early in the process [6], and there was no discussion in the WG about it.\u00a0 I can see how it would be easy to overlook. Nonetheless, it is necessary for the WG (and the IETF as a whole) to explicitly consider the declaration before proceeding with the publication of this document. [1]  https://datatracker.ietf.org/ipr/2392/ [2]  https://mailarchive.ietf.org/arch/msg/alto/LI01TfoTCnJRDImEUXA-9x8KsZ4 [3]  https://mailarchive.ietf.org/arch/msg/alto/xFErWArHhpF-0ZVR_1BAhgzRj3k [4]  https://mailarchive.ietf.org/arch/msg/alto/-D7cj6qoD-Q3ye3rpuj8li2xWms [5]  https://mailarchive.ietf.org/arch/msg/alto/67W_XuMfu7JMXQEEZFLkulw_xBI [6]  https://mailarchive.ietf.org/arch/msg/ipr-announce/lnZ65z15_Dn3bylJp7h9rGHxZFk",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-02-28 08:55:09-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-26 00:56:34-08:00",
    "text": "Very easy-to-fix issue with date format specification: \u2014 Section 5 \u2014 \u00a0  Both extensions need to return calendar start time (calendar-start- \u00a0  time, a point in time), which MUST be specified using the HTTP header \u00a0  fields format specified in [ RFC7231 ] where, however, timestamps are \u00a0  still displayed with the acronym \"GMT\" rather than \"UTC\": \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Date: Tue, 15 Nov 2014 08:12:31 GMT The problem with this text is that 7231 specifies three formats and you don\u2019t make it clear which one you want, other than by example.\u00a0 The lack of a section reference doesn\u2019t help (7231 is not small), but that wouldn\u2019t be sufficient anyway.\u00a0 I suggest this: NEW Both extensions return calendar start time (calendar-start-time, a point in time), which MUST be specified as an HTTP \u201cDate\u201d header field using the IMF-fixdate format specified in Section 7.1.1.1 of [ RFC7231 ].\u00a0 Note that the IMF-fixdate format uses \u201cGMT\u201d, not \u201cUTC\u201d, to designate the time zone, as in this example: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Date: Tue, 15 Nov 2014 08:12:31 GMT END \u2014 Section 5.1.2 \u2014 \u00a0  For example: suppose the \"calendar-start-time\" member has value \"Mon, \u00a0  30 Jun 2014 at 00:00:00 GMT\", the \"time-interval-size\" member has That isn\u2019t a valid calendar-start-time value unless you remove \u201c at\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Ben Campbell",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-12-04 20:35:56-08:00",
    "text": "Thanks for the work on this document. I see value, but have a couple of points I think need to be resolved prior to publication: \u00a73.1, definition of \"time-interval-size\": What is the reasoning behind using a string to define the unit? That requires text parsing/comparison to determine the interval. I assume this is intended more for machine use than for human use. Did the working group consider making this a multiple of some primitive time interval? E.g. number of seconds, or perhaps number of minutes? it seems like that would be easier (and therefore less error prone) to interpret. If there is a reason to use a text field, is there an enumeration of legal unit values? Can I use \"12 parsecs\"? \u00a74.1.2, last paragraph: \"The ALTO Client thus may use the same calendar for the next 4 days starting at \"calendar-start-time\" and will only need to request a new one for Friday July 4th at 00:00:00 GMT.\" This implies that if an ALTO server delivers a calendar with a long duration, it cannot make changes to the metrics in that calendar, or if it does make them it cannot expect the client to learn about those changes. Is that the intent? If so, it seems to contradict language in the security considerations (\u00a76) that future events may change and that the client should ensure information updates. (The operational considerations [\u00a77] also say the client does not need to query again during the calendar duration.)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-09 17:20:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-03 14:14:36-08:00",
    "text": "hat's the justification for removing the 'constraints' field ofReqEndpointCostMap, compared to RFC 7285?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-06-02 06:27:39-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-02 01:40:04-07:00",
    "text": "Thanks for the effort to produce\u00a0 this\u00a0 YANG model, I always fascinate by the work done in creating the YANG models. I have found inconsistencies in the classification of normative references and informative references, hence, would like to discuss those. Some examples below- - in the terminology section while\u00a0 [ RFC6241 ], [ RFC7950 ], [ RFC8466 ], [ RFC4026 ], and [ RFC8309 ] are normative references, [ RFC8969 ] and [ RFC8340 ] are not. But clearly this document uses terms defined in those documents and I as a reader had to open those RFCs to understand what the terms are and without that I would not be possible to understand this document. - sometimes the this document is correctly referring to other documents as normative, as terms or processes are defines there but sometimes it is not. for example - \u00a0 \u00a0 'signaling-option': Indicates a set of signaling options that are specific to a given VPN network access, e.g., a CE ID ('ce-id' identifying the CE within the VPN) and a remote CE ID as discussed in Section 2.2.2 of [ RFC6624 ]. Now, without understanding what is discussed or defined in  RFC6624  it was hard for me to understand the node/leaf mentioned in this document. Thus, I felt\u00a0 RFCC6624 should be a normative reference but it was not.  - The reference modules from this document cannot be informative reference, can they? For example in section 8.1 it says - \u00a0  This module references [ RFC3032 ], [ RFC4446 ], [ RFC4448 ], [ RFC4553 ], [ RFC4618 ], [ RFC4619 ], [ RFC4717 ], [ RFC4761 ], [ RFC4816 ], [ RFC4842 ], and [ RFC5086 ]. however,  RFC4842  and  RFC5086  is informative reference. I would say, please go through the document and correctly categorise all the references.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-02-17 07:39:42-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 08:39:25-08:00",
    "text": "I'd started balloting this as Abstain, but while writing up the ballot I realized that it's important enough that it deserves to be DISCUSSed. This is clearly clever, but feels to me like it might fall into \"Oo, you are so sharp you\u2019ll cut yourself one of these days\"[0] territory. I'm not saying that the \"v4-via-v6\" is a *bad* idea, but I really don't think that it should be introduced / documented in a Standards Track Babel document - it touches core plumbing, and should be discussed and documented in a V6OPS (or 6MAN) document, and then this document includes it by reference. If this was only ever going to used in Babel environments I'd be much less concerned, but I suspect (hope?) that future solutions will want to do very similar things, and that it needs to be reviewed with an assumption that it might get widely used. It should documented in a \"self contained\" manner so it can be cleanly referenced - at the moment, a reference would need to point at bits of Section 1 and 3, and there is some feeling of \"this is probably safe, the 192.0.0.8 bit might make operations / debugging a bit harder, but... \u00af\\_(\u30c4)_/\u00af\" If this has already received significant discussion in V6OPS / similar, or if it is already clearly documented elsewhere[1], I'll clear my DISCUSS and Abstain or support it. I'm sure that this DISCUSS will be frustrating to the authors/WG - I'm doing so because I'd like to see this technique more able to be used (and make sure that there aren't any sharp pointy bits), not because I think it's a bad idea...  [0]: quote from Terry Pratchett, Thief of Time [1]: I suspect it is already documented somewhere, but the closest I can think is  RFC7600  - \"IPv4 Residual Deployment via IPv6 - A Stateless Solution (4rd)\", an Experimental document which is noticeably different to this. If it *is* already documented somewhere else though, then why is this not just referencing that instead?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-13 19:50:30-07:00",
    "end_reason": "position_updated",
    "start": "2020-09-22 12:31:36-07:00",
    "text": "Thanks for this document; it's generally in good shape even though I do want to discuss a few specific points. (1) I'm a bit confused by the indication that we can use linkIds to link to a vCard representation of a participant or location -- if I understand correctly that representation would occupy the \"description\" property of the linked object, but the \"description\" is (at least for locations) supposed to be \"human-readable\", which is perhaps only debatably an apt description of a vCard object. (2) Given the language in Section 1.4.7 about needing to denote on a per-object basis when Ids have semantic meaning outside of the object in which they are defined, I think we need a stronger/clearer statement in Section 4.2.5 that the location Ids have global semantics within a calendar, Section 4.4.5 that participant Ids have global semantics, within a calendar, etc.\u00a0 (My preference would be to reverse the sense of the language in \u00a71.4.7 rather than add language to each instance of Ids with global semantics; see COMMENT.) (3) We may want to discuss the scheduleSequence semantics/usability in the face of a user/\"participant\" that has multiple clients.\u00a0 It seems to me that there is not much preventing the different clients from sending (different) responses that use the same sequence number, and I'm also not sure whether the client is supposed to keep local state on what sequence number to use next or just to increment any value received from the server. (4) I strongly recommend that all the examples not reuse UUIDs for different things (e.g., I see \"2a358cee-6489-4f14-a57f-c104db4dc2f1\" as all of: simple event, location (FRA Airport), location (Math lab room 1), location (Big Auditorium), and virtualLocation (ChatMe).\u00a0 The Section 6.9 example at least rises to Discuss-level (IIUC) as inconsistent with the protocol requirements, since the location id is used for two different locations in sibling events. (5) Additionally, the Section 6.3 example seems malformed, since the \"entries\" array contains as its second element a key/value pair, not a (jstask) object.\u00a0 (Erik noted this as a Comment-level point, it seems, so this is more a note to myself to confirm that it's fixed than informing you of the issue.) (6) Can we briefly discuss the use of the \"/\" character in time zone identifiers in \u00a74.7.2?\u00a0 Specifically, this text: \u00a0  o\u00a0 It MUST start with the \"/\" character (ASCII decimal 47; also see \u00a0 \u00a0 \u00a0 Sections 3.2.19 of [ RFC5545 ] and 3.6. of [ RFC7808 ] for discussion \u00a0 \u00a0 \u00a0 of the forward slash character in time zone identifiers). (a) I see no discussion of the forward slash character in section 3.6 of  RFC 7808 . (b) Also, Section 3.2.19 of  RFC 5545  seems to basically be saying \"there might one day be one (or more!) global registry for time zones, but we don't know of one and can't point you to it\" ... is this really the semantics we want to continue to enshrine?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-29 21:53:43-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-10 18:45:05-07:00",
    "text": "I think we need to check the [MAC] reference; following links (and chasing redirects) seems to only find a 1985 publication that talks about DES, with no mention of AES-CBC-MAC.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2021-03-12 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-01-21 06:52:17-08:00",
    "text": "I realize this was discussed during IETF last call, but the document still seems unclear on whether the contents of security.txt are meant to be consumed by a human or a machine. In some places the syntax of fields is specified in detail, which would imply machine readability is expected. The ABNF is provided, although it is not normative. The registry policy does not require any formal specification of the format of new fields nor a requirement that field formats even be documented. In short, I can't tell whether security.txt files are meant to be machine-consumable. If they are, then the registry entries need to be more tightly specified and the ABNF should probably be normative. If they're not, I'm not sure why the field definitions are constrained to specific formats beyond saying whether they should be URIs or free text.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-03-12 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2021-01-19 09:58:59-08:00",
    "text": "I have a few issues I\u2019d like to get resolve before I move to \u201cno objection\u201d.\u00a0 I think it will be an easy discussion and quick resolution. \u2014 Section 3.1 \u2014 \u00a0  A \"security.txt\" file that is found in a file system MUST only apply \u00a0  to the folder in which it is located and that folder's subfolders. \u00a0  The file does not apply to any of the folder's parent or sibling \u00a0  folders. You don\u2019t say what happens if there are nested security.txt files.\u00a0 What\u2019s the scope in this situation (which file applies to folder1; which applies to folder1/subfolder)?: /example/security.txt /example/folder1/ /example/folder1/security.txt /example/folder1/subfolder/ I think the document needs to make this clear. \u00a0  # This security.txt file applies to IPv4 address of 192.0.2.0. \u00a0  https://192.0.2.0/.well-known/security.txt I\u2019m uncomfortable with trying to restrict the scope depending upon how the file was retrieved.\u00a0 If  www.example.com  resolves to 192.0.2.0, then it should not matter whether the file is retrieved via\u00a0 or\u00a0 (or via the corresponding v6 address). \u2014 Section 3.6 \u2014 Your examples lack the EXPIRES field that you say MUST be present. \u2014 Section 5 \u2014 \u00a0  The expected file format of the security.txt file is plain text (MIME \u00a0  type \"text/plain\") as defined in section 4.1.3 of [ RFC2046 ] and is \u00a0  encoded using UTF-8 [ RFC3629 ] in Net-Unicode form [ RFC5198 ]. In Section 3 you say that for HTTP: \u00a0  It MUST have a Content-Type of \"text/plain\" with the \u00a0  default charset parameter set to \"utf-8\" (as per section 4.1.3 of \u00a0  [ RFC2046 ]). It would be best to have the format requirement be consistent, however it\u2019s retrieved, so \u201cMUST\u201d (rather than \u201cexpected\u201d) is right, no? The ABNF needs some work.\u00a0 DISCUSS-level issues here, with less important ones below: \u00a0 signed\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 sign-header unsigned sign-footer No, the signed body doesn\u2019t just have a header and footer around the unsigned plain text.\u00a0 A signed body would have an unsigned body, *followed by* a sign-header, a signature, and a sign-footer. \u00a0 unsigned\u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 *line (contact-field eol) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line (expires-field eol) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line [lang-field eol] *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; order of fields within the file is not important I found this confusing, with \u201c*line\u201d repeated all over the place and with \u201ccontact-field\u201d both here and in the \u201cfield\u201d construct, but as I worked it out I see that it\u2019s correct (though defnitely confusing).\u00a0 But while the order of the fields mostly doesn\u2019t matter, the order of the Contact fields, if there are more than one, does matter.\u00a0 So you\u2019ll have to tweak this a bit. Give the above, I suggest this: \u00a0 unsigned\u00a0 \u00a0 \u00a0 \u00a0  =\u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (contact-field eol) ; one or more required \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 (expires-field eol) ; exactly one required \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [lang-field eol] ; exactly one optional \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 *line \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; order of fields within the file is not important \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; except that if contact-field appears more than once \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ; the order of those indicates priority (Section 3.5.3) \u00a0 field\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 =\u00a0 ; optional fields \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ack-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 can-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 contact-field / ; optional repeated instances \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 encryption-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 hiring-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 policy-field / \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ext-field What do you think?",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-24 11:02:56-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-22 02:52:17-07:00",
    "text": "Taking over Alissa's discuss, because I see no changes in -11 related to it: > I realize this was discussed during IETF last call, but the document still > seems unclear on whether the contents of security.txt are meant to be consumed > by a human or a machine. In some places the syntax of fields is specified in > detail, which would imply machine readability is expected. The ABNF is > provided, although it is not normative. The registry policy does not require > any formal specification of the format of new fields nor a requirement that > field formats even be documented. In short, I can't tell whether security.txt > files are meant to be machine-consumable. If they are, then the registry > entries need to be more tightly specified and the ABNF should probably be > normative. If they're not, I'm not sure why the field definitions are > constrained to specific formats beyond saying whether they should be URIs or > free text.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-01-22 21:02:11-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-01-20 21:21:53-08:00",
    "text": "Sorry to pile on, but I'm really not clear on the whole filesystem portion of this. \u00a0  A \"security.txt\" file that is found in a file system MUST only apply \u00a0  to the folder in which it is located and that folder's subfolders. \u00a0  The file does not apply to any of the folder's parent or sibling \u00a0  folders. I take this to mean if I want to report a vulnerability related to the filesystem or something in it (a vulnerable binary, perhaps, or a writable password file, I should look for \"security.txt\" in the directory of interest and use that one; if it's missing, I walk upwards until I find one, and use the first one I found.\u00a0 (If that's not correct, then this needs to be clarified, or given the other DISCUSSes, it may need to be clarified anyway.) What if I want to report something unrelated to the filesystem?\u00a0 Suppose I somehow acquire a root shell on a machine I shouldn't be able to access, and that process has no current working directory.\u00a0 I look around and find \"security.txt\" files in several directories.\u00a0 Which one do I use?\u00a0 Sitting at a shell prompt doesn't automatically map to a place in the filesystem tree where I should start looking.",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2021-03-31 11:51:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-22 21:02:11-08:00",
    "text": "Sorry to pile on, but I'm really not clear on the whole filesystem portion of this. \u00a0  A \"security.txt\" file that is found in a file system MUST only apply \u00a0  to the folder in which it is located and that folder's subfolders. \u00a0  The file does not apply to any of the folder's parent or sibling \u00a0  folders. I take this to mean if I want to report a vulnerability related to the filesystem or something in it (a vulnerable binary, perhaps, or a writable password file), I should look for \"security.txt\" in the directory of interest and use that one; if it's missing, I walk upwards until I find one, and use the first one I found.\u00a0 (If that's not correct, then this needs to be clarified, or given the other DISCUSSes, it may need to be clarified anyway.) What if I want to report something unrelated to the filesystem?\u00a0 Suppose I somehow acquire a root shell on a machine I shouldn't be able to access, and that process has no current working directory.\u00a0 I look around and find \"security.txt\" files in several directories.\u00a0 Which one do I use?\u00a0 Sitting at a shell prompt doesn't automatically map to a place in the filesystem tree where I should start looking.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-04-22 02:13:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-21 02:14:28-08:00",
    "text": "Hi, Thank you for this document.\u00a0 I like that it provides a fairly simple solution to providing vulnerability reporting information, although I also have some sympathy with the observation that if the server is compromised then security.txt could also be compromised. However, I have a concern about the document both being machine readable and also including an expiry date.\u00a0 This would seem to offer an easy mechanism to probe websites for those that have out of date security.txt files and hence may have more lax security practices, or potentially help provide indirect information about what software versions a website might be using.\u00a0 Alternatively, this will end up as Barry has suggested, with lots of old expiry dates. Arguably, the best alternative might be just to not provide a date at all, and rely on the humans to check the provenance of the information, and treat it with suitable caution.\u00a0 An alternative possibility could be just to define a field for when the information was last updated.\u00a0 This doesn't go out of date, but helps provide some clue as to whether the information might be stale or not. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-01-20 16:45:40-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-01-20 15:29:00-08:00",
    "text": "** The concept of operations for the file-based approach seems under-specified in a few ways: -- Section 3.1 says: A \"security.txt\" file that is found in a file system MUST only apply to the folder in which it is located and that folder's subfolders. The file does not apply to any of the folder's parent or sibling folders. Unless I missed it, a \u201cuse the most specific directory rule\u201d doesn\u2019t appear to be explicitly stated and there didn\u2019t seem to be a restriction on the number of security.txt files in a filesystem.\u00a0 That is, multiple security.txt seem like they could apply.\u00a0 Assume: (1) /opt/foo/security.txt (2) /opt/foo/bar/security.txt Does security.txt (1) and (2) apply to /opt/foo/bar? How is one intended merge the contents of two files? -- Is the thinking that software publisher going to package a security.txt and put it in some install directory on an end-point (like a SWID)? Or is it more likely to go into a source tar ball or seen only when you \u201cgit clone\u201d a repo (like a  README.md )? -- If it will be in a package, is there an intent to relate any integrity protection of the overall package with the recommend openpgp practices described in this document?\u00a0 If one is signature is invalid does that say anything about the other? -- If it will be in a package, then is the guidance in Section 4.2 appropriate (File systems SHOULD place the \"security.txt\" file under the root directory; e.g., \"/security.txt\", \"C:\\security.txt\") unless we\u2019re assuming some container/chroot-like strategy? -- If an end-point maintainer wants to implement a different policy, is that maintainer supposed to modify/replace the file or put another instance of that file in an alternate directory? ** Section 3.5.2. Per \u201cThe purpose of this field is to allow a digital signature to be applied to the locations of the \"security.txt\" file\u201d, if a security.txt file is retrieved over https via \u201cURL-A\u201d, and the Canonical field does not contain URL-A, should this file be trusted?\u00a0 Same with a file system directory.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-13 07:42:28-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-01-20 16:45:40-08:00",
    "text": "(Updated)  ** The concept of operations for the file-based approach seems under-specified in a few ways: (After reviewing the other ballot positions of my peers, I believe this first item is the same issue as raise by Barry) -- Section 3.1 says: A \"security.txt\" file that is found in a file system MUST only apply to the folder in which it is located and that folder's subfolders. The file does not apply to any of the folder's parent or sibling folders. Unless I missed it, a \u201cuse the most specific directory rule\u201d doesn\u2019t appear to be explicitly stated and there didn\u2019t seem to be a restriction on the number of security.txt files in a filesystem.\u00a0 That is, multiple security.txt seem like they could apply.\u00a0 Assume: (1) /opt/foo/security.txt (2) /opt/foo/bar/security.txt Does security.txt (1) and (2) apply to /opt/foo/bar? How is one intended merge the contents of two files? -- Is the thinking that software publisher going to package a security.txt and put it in some install directory on an end-point (like a SWID)? Or is it more likely to go into a source tar ball or seen only when you \u201cgit clone\u201d a repo (like a  README.md )? -- If it will be in a package, is there an intent to relate any integrity protection of the overall package with the recommend openpgp practices described in this document?\u00a0 If one is signature is invalid does that say anything about the other? -- If it will be in a package, then is the guidance in Section 4.2 appropriate (File systems SHOULD place the \"security.txt\" file under the root directory; e.g., \"/security.txt\", \"C:\\security.txt\") unless we\u2019re assuming some container/chroot-like strategy? -- If an end-point maintainer wants to implement a different policy, is that maintainer supposed to modify/replace the file or put another instance of that file in an alternate directory? ** Section 3.5.2. Per \u201cThe purpose of this field is to allow a digital signature to be applied to the locations of the \"security.txt\" file\u201d, if a security.txt file is retrieved over https via \u201cURL-A\u201d, and the Canonical field does not contain URL-A, should this file be trusted?\u00a0 Same with a file system directory.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-05-24 10:54:32-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-13 07:42:28-07:00",
    "text": "(Updated for -11)  ** Section 3.5.2. Per \u201cThe purpose of this field is to allow a digital signature to be applied to the locations of the \"security.txt\" file\u201d, if a security.txt file is retrieved over https via \u201cURL-A\u201d, and the Canonical field does not contain URL-A, should this file be trusted?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-12-15 07:17:59-08:00",
    "end_reason": "position_updated",
    "start": "2022-12-13 06:54:03-08:00",
    "text": "Be ye not afraid -- see  https://www.ietf.org/about/groups/iesg/statements/handling-ballot-positions/  on handling ballots, especially DISCUSS ballots... Can the IETF actually deprecate / make a protocol historic? (as stated in \"Internet Key Exchange version 1 (IKEv1) has been deprecated\" and \"IKEv1 has been moved to Historic status.\") I agree that **making the documents that describe these** be historic is the right thing to do, and also that the IETF can strongly recommend that people don't use/deploy/whatever IKEv1, but I don't really know if we (or anyone) have the power to deprecate a protocol. We are not the protocol police, and we cannot instruct people to e.g deploy protocol foo, so I don't know if we can deprecate a protocol either -- but I suspect that this might be because I don't actually know what \"IKEv1 has been deprecated\" actually *means*. Again, I'm not trying to block what this document is attempting to *do*, but rather make it clear what it is actually doing.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-04-03 17:54:51-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-03 00:40:23-07:00",
    "text": "I haven't yet reviewed this document, but it is part of the multi-document problem I flag in my DISCUSS on  draft-ietf-mmusic-trickle-ice-sip , and needs to block on finding a solution to that issue.",
    "type": "Discuss"
  },
  {
    "ad": "Adam Roach",
    "end": "2018-05-01 15:50:42-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-03 17:54:51-07:00",
    "text": "This document is part of the multi-document problem I flag in my DISCUSS on  draft-ietf-mmusic-trickle-ice-sip , and needs to block on finding a solution to that issue.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-12-18 17:06:52-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-09 15:03:55-08:00",
    "text": "Thank you for engaging with the TSVART review. Despite the wordsmithing that has gone on, I am not sure that we have captured the correct text. The proposed change is: > I clarified: > The duration of the trial MUST include least 2 seconds in addition to the time > required to send and receive each burst of frames, to ensure that DUT buffers to > deplete. >  > and I'll add: > The upper search limit for the time to send each burst MUST be configurable as > high as 30 seconds (buffer time results reported at the configured upper limit are > likely invalid, and the test MUST be repeated with a higher search limit). But IIUC it's the additional time that needs to scale up. A layman's reading of the document, IMO, suggests that the burst length has a binary search but the 2 seconds of waiting can be fixed.",
    "type": "Discuss"
  },
  {
    "ad": "Jim Guichard",
    "end": "2023-05-10 12:40:24-07:00",
    "end_reason": "position_updated",
    "start": "2023-05-08 16:14:24-07:00",
    "text": "Section 2 \"Updates to  RFC2328 \" is missing reference to section 10.3. \"The Neighbor state machine\" of  RFC 2328 . Non-inclusive language is used for the \"State(s): Init, Event: 2-WayReceived\" and \"State(s): Exchange or greater, Event: SeqNumberMismatch\".",
    "type": "Discuss"
  },
  {
    "ad": "Murray Kucherawy",
    "end": "2022-05-04 21:41:29-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-06 22:54:27-07:00",
    "text": "Alvaro and Zahed pointed out concerns about the SHOULDs in Sections 6.1 and 6.2, and since all three of us tripped on the same text, I'd like to discuss them.\u00a0 My own angle is that they're SHOULDs but it's not clear to me why they aren't MUSTs.\u00a0  SHOULD offers the implementer a choice; if we're sure these need to be SHOULDs, then what advice might we provide to implementers that think they have legitimate reasons not to do what they say? For instance, if I'm coding a router that understands HBH but is configured not to honor this option, why might I not ignore the option and forward the packet?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-19 20:12:40-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-11 21:36:40-07:00",
    "text": "Thanks for producing this document, which fills a real need and is quite well-written, my comment about its length notwithstanding.\u00a0 Unfortunately, I do have one pretty small point that I think requires a little bit more discussion, to ensure that we produce a specification that is usable as written. Section 7.1 imposes a requirement that \"[i]terative resolvers [...] MUST be configured to behave for these names either: (a) [...], or (b) [...]\".\u00a0 There is no default choice given in the absence of configuration, and it is unclear who this requirement is binding on in any case.\u00a0 Do all iterative resolvers necessarily have a human operator that knows they are responsible for the configuration of the resolver? Is the software author responsible for providing \"default configuration\" to meet this requirement?\u00a0 Let's discuss how this requirement is intended to apply and whether that is achievable in practice.\u00a0 (One of the elided portions from the above quote is \"commplying with this specification\", so perhaps the iterative recursive resolver softwares in question would be implemented to ignore this specification in the absence of such a configuration, as strange as that might seem.)",
    "type": "Discuss"
  },
  {
    "ad": "Andrew Alston",
    "end": "2022-07-13 10:06:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 05:52:02-07:00",
    "text": "Thanks for the work on this document, Hopefully this discuss will be relatively easy to resolve - and may result from a lack of understanding - but -  \u00a0  Endpoints that receive the grease_quic_bit transport parameter from a \u00a0  peer SHOULD set the QUIC Bit to an unpredictable value unless another \u00a0  extension assigns specific meaning to the value of the bit. Now, this is in reference to a bit - which can only be 0 or 1 - and the document further goes on to clarify certain situations where this bit should be set or unset - so I am not at all sure what this paragraph really means and hoping this can be clarified because I'm not sure how this will be interpreted on implementation.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-07-01 02:05:06-07:00",
    "end_reason": "position_updated",
    "start": "2022-06-30 02:15:36-07:00",
    "text": "Hi, Sorry for the late DISCUSS, and hopefully not tricky to resolve, but there are two points that I think it would be helpful to clarify: (1) Ensuring the language is consistent with draft-ietf-quic-manageability. (2) Possibly whether a short Operational Considerations section could/should be added. Details in the comments. Regards, Rob",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2021-05-19 07:37:28-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-08 05:05:41-07:00",
    "text": "Hi, Hopefully not tricky to discuss/resolve, sorry for posting it close to the telechat! I would like to please see some more clarity or guidance about when TAG TBD112 should be used, given that there are two possible encodings of absolute OIDs below \"1.3.6.1.4.1\". Specifically, the questions that I have, that probably need to be clarified are:  - is a CBOR encoder allowed to optimize a TBD110 tag into a TBD112 tag?  - Should CBOR decoder clients always expect to be able to handle both TBD110 and TBD112 tags?  - Or, it the decision over whether to use TBD110 or TBD112 down to the application and the application needs to agree which is use.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-10-05 00:52:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-09-30 06:17:24-07:00",
    "text": "# GEN AD review of  draft-ietf-lsr-ospf-l2bundles-06 CC @larseggert Thanks to Paul Kyzivat for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/IqLhVi63YKAt6GINPOKUQ0sGt3g ). I'm raising Paul's review comment as a DISCUSS: ``` 2) MINOR: Section 2: Normative requirements on future documents While I don't fully understand all the document dependencies, the following normative requirement: \u00a0 ... Specifications that introduce new sub-TLVs of the Extended Link \u00a0 TLV MUST indicate their applicability for the L2 Bundle Member \u00a0 Attributes Sub-TLV.\u00a0 An implementation MUST ignore any sub-TLVs \u00a0 received that are not applicable in the context of the L2 Bundle \u00a0 Member Attribute Sub-TLV. looks to me like it may be imposing requirements on future work that may not itself be aware of or normatively linked to this document. The registry in question is defined only by  RFC7684 . Figure 2 further supports this point by effectively revising the format for the registry, adding an additional column. I suggest it would be appropriate to formally update the registry to reference this document to impose requirements on future registrations, and add a column indicating applicability in the context of the L2 Bundle Member Attribute Sub-TLV. The same logic applies to Figure 3 and the IANA OSPFv3 Extended-LSA Sub-TLVs registry. I suggest the same sort of fix for it. ```",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-09-27 17:10:12-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-09-23 01:45:11-07:00",
    "text": "(1) I think there may be some ambiguity we need to resolve, relating to per-AF router IDs and other per-AF lists: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  list router-id { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  key \"address-family\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Router-id per address family.\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  leaf address-family { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type identityref { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  base vpn-common:address-family; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  description \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Indicates the address family for which the \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Router-ID applies.\"; What actually gets used as the router-id for a given address family if both \"dual-stack\" and that address family are present in this list? There's some similar potential for amiguity in the \"redistribute-connected\" list for BGP routing, that is also keyed on an address-family identityref. (2) In a similar vein as Roman's Discuss (and perhaps obviated by it?), if we're going to allow raw keys to be specified, as a string type, we should be very clear about whether the string is hex-encoded, base64-encoded, etc., in light of deployed experience with devices that take the string and use it as the raw key (thereby eliminating a good chunk of the key space from potential use). (2.5) For raw keys, should we be using nacm:default-deny-all? (3) the ipsec authentication option for the various routing protocols uses a string to identify an (IKE, unspecified version thereof) SA.\u00a0  RFC 7296  doesn't have the concept of a name for an IKE SA itself, so I think we need to provide more details on what is being named and what the naming authority is.\u00a0 IKE does have identities for the peers, if the goal is to refer to the peer's identity for the SA. (4) I'd also like to have a discussion about the NTP configuration options; in particular, we currently have an enumeration to select between broadcast client and broadcast server, with no option apparent for symmetric or other NTP modes.\u00a0 Given the rigidity of YANG enumerations, I'd like to confirm that no other NTP modes could be appropriate on the network access before we lock in to this model.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-09-28 16:45:58-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-27 17:10:12-07:00",
    "text": "(3) the ipsec authentication option for the various routing protocols uses a string to identify an (IKE, unspecified version thereof) SA.\u00a0  RFC 7296  doesn't have the concept of a name for an IKE SA itself, so I think we need to provide more details on what is being named and what the naming authority is.\u00a0 IKE does have identities for the peers, if the goal is to refer to the peer's identity for the SA. [I'd like to see clarified that these human-readable names are administrator-assigned]",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-09-23 07:20:21-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 13:35:38-07:00",
    "text": "[general] * I'm sure there are plenty things I'm not understanding, and probably \u00a0 these things are easy to address.\u00a0 But in general I feel like there \u00a0 could be some tension between needing to specify/model the L3 \u00a0 attributes that are used to provision both the endpoint and the \u00a0 clients with a possibly somewhat cleaner separation for holding client \u00a0 IP provisioning info.\u00a0 At what point, for example, should there be \u00a0 something like a separate \"client-ip-provisioning-profile\" string \u00a0 that is referenced?\u00a0 I think some of the richness of what can be \u00a0 expressed in IPv6 RAs may be bringing these ideas up, some of which \u00a0 can be expressed in DHCP as well but operationally may be less common. \u00a0 The contents of RIOs in particular seem like a bit of client \u00a0 provisioning information that an endpoint might need to be aware \u00a0 of as well. [S7.6.2] * Provisioning IPv6 clients can be more rich than the DHCPv6/SLAAC \u00a0 model noted here (and much more so than IPv4/DHCPv4). \u00a0 Since you document how local-address/prefix-length becomes a PIO, \u00a0 should there be other related IP connectivity provisioning information \u00a0 in here, like: \u00a0 \u00a0 \u00a0 * more than just one PIO? (is this just repeated \u00a0 \u00a0 \u00a0 \u00a0 ip-connection/ipv6 entries, one for each on-link prefix?) \u00a0 \u00a0 \u00a0 * one or more RIOs that might need to be advertised to clients? \u00a0 \u00a0 \u00a0 * others (PVDIO, ...)? \u00a0 If this is \"out of scope\" for this document, where does it belong \u00a0 in the overall provisioning of an L3VPN service (out of curiosity, \u00a0 given that this document kinda models DHCP IP allocation ranges)? [S8] * Under provider DHCPv6 servers, the server definition has an \u00a0 \"address-assign\" choice of \"number\" with a \u00a0 \"number-of-dynamic-address\" (defaulting to \"1\"), but the description \u00a0 talks about the number of allocated prefixes.\u00a0 Should this value be \u00a0 \"number-of-dynamic-prefixes\" instead?  * Which of these elements describes whether or not DHCPv6 PD \u00a0  (Prefix Delegation) is enabled, and the prefix pools used?",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-10-04 05:21:11-07:00",
    "end_reason": "position_updated",
    "start": "2021-10-04 03:51:17-07:00",
    "text": "Thank you for the work on this document, and apologies for the delayed review. I have one DISCUSS point, a couple of comments. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. I have divided comments into \"minor\" (including the questions) and \"nits\". Neither require replies strictly speaking, please feel free to address as you see fit. I will appreciate answers to my questions, to improve my understanding. If any clarification comes out of it, I hope it will help improve the document. Francesca 1. ----- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  leaf holdtime { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  type uint32; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  units \"msec\"; FP: This might be me not finding the right reference (or little knowledge of YANG), but I was wondering if \"msec\" was defined somewhere as a unit (note that the description does not mention that the unit is milliseconds either). While doing my due diligence to see if I missed or misunderstood something, I researched the RFCs mentioned in the beginning of the YANG module: \u00a0  This module uses types defined in [ RFC6991 ] and [ RFC8343 ].\u00a0 It also \u00a0  uses groupings defined in [ RFC8519 ], [ RFC8177 ], and [ RFC8294 ]. And found no use of the \"msec\" unit. A quick google search shows that  RFC 8299  uses it, so there is precedence for it, but I couldn't find its definition from that document either. All the other leaves use \"milliseconds\" (which is defined in  RFC 8294 ), so my preference would be to have consistency, if \"msec\" was defined and I just missed it. (Note that a similar remark could be made for \"bps\" used, which does not appear in the description text, and is also used in  RFC 8466 , however there is no issue about consistency there).",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-09-27 10:20:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-19 10:55:15-07:00",
    "text": "(7.6.3) Is there a reason the TCP-AO model in this draft is different from the one in  draft-ietf-idr-bgp-model-11 ? That draft is using a model developed in the TCPM WG ( draft-ietf-tcpm-yang-tcp ) specifically for that purpose. If there is no compelling requirement for something different, or the TCPM modelling work can be stretched to cover this use case as well, it would be far better than rolling a totally separate TCP YANG model here.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2021-09-29 13:16:50-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-19 14:20:00-07:00",
    "text": "**  RFC8177  already defines a container to represent an individual key -- key-string \u2013 as both a string and hex format. Additionally, this representation has built in ACLs to protect it.\u00a0 This model appears to maximize flexibility by supporting both key-chains and an explicit key for protocols like BGP, RIP and ISIS.\u00a0 Is there a reason why this model does not (or perhaps cannot) reuse the key-string representation from  RFC8177  (the same way key-chain is)? And/or to not provide the flexibility for a hex encoded key?  ** Section 9.\u00a0 The text notes that \u2018vpn-service\u2019 is sensitive to write operations.\u00a0 Wouldn\u2019t \u2018vpn-profiles\u2019 be equally sensitive to alterations with similar consequences?\u00a0 For example, altering an encryption-profile-identifier could change the algorithm chosen or the key.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2021-09-27 04:53:00-07:00",
    "end_reason": "position_updated",
    "start": "2021-09-22 01:15:59-07:00",
    "text": "This specification refers to ietf-opsawg-vpn-common for qos related matching, hence I am raising similar discussion as I had for ietf-opsawg-vpn-common (see here  https://datatracker.ietf.org/doc/draft-ietf-opsawg-vpn-common/ ). This specification specifies qos classification based on L4 criteria and describes the procedure for TCP and UDP. It is possible that new L4 protocols (for example QUIC) use UDP as substrate hence can create ambiguity based of the procedure described in the specification. This specification should consider such potential substrate usage of L4 protocols (specially UDP) and hint on the potential augmentations (there might be several ways to do that) or scope it down to not support such cases.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-03 20:08:51-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-03 20:08:10-08:00",
    "text": "One fairly minor point to start: Section 4.3 says that we define a new mode (ICE-HIP-UDP) for the NAT_TRAVERSAL_MODE parameter type, but then goes on to say that \"the presence of the parameter in a HIP base exchange means that the end-host supports NAT traversal extensions defined in this document\".\u00a0 If I undrestand correctly, only the specific presence of the ICE-HIP-UDP mode of the NAT_TRAVERSAL_MODE parameter does so, and so to say that the present of \"the [NAT_TRAVERSAL_MODE] parameter\" indicates support for this document would be backwards incompatible with  RFC 5770 . I'd also like to delve a little further into the potential \"cross-protocol\" attack (same protocol, really, but the same attack) that Ekr raised, between RVS_HMAC and RELAY_HMAC.\u00a0 This is probably a \"discuss discuss\", so let's see where it leads... The semantics for either type of HMAC is that it is an HMAC over the HIP packet excluding itself and subsequent parameters.\u00a0 Pulling up the HIP packet format from  RFC 7401 , that looks like: \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  | Next Header\u00a0  | Header Length |0| Packet Type |Version| RES.|1| \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Checksum\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Controls\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Sender's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Receiver's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HIP Parameters\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The HMAC key is the integrity key for that direction of traffic between HITs, so the \"cross-protocol\" part can only come in by confusing the packet recipient into confusion as to whether it is processing an RVS_HMAC or a RELAY_HMAC (but any other entity will reject the packet by virtue of it using the wrong key).\u00a0 Modern best practices are to go through a key derivation step that incorporates as much information as possible about what the derived key will be used for, which would in this case include the TLV type of the HMAC parameter and presumably the HITs in question as well. In particular, the TLV type of the HMAC parameter is *not* input into the HMAC calculation (at least for RVS_HMAC), so the trivial discriminator is not present.\u00a0 The \"packet type\" in the header in the header is potentially going to differ across usages, so I think that's a good place to focus discussion.\u00a0 Unfortunately, Section 4.2.1 of  RFC 8004  suggests that RVS_HMAC is going to be present a lot of the time, so it's not really clear to me what packet types either RVS_HMAC and/or REPLAY_HMAC are expected to occur in.\u00a0 Could a HIP expert please jump in and help clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-15 18:32:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-03 20:08:51-08:00",
    "text": "One fairly minor point to start: Section 4.3 says that we define a new mode (ICE-HIP-UDP) for the NAT_TRAVERSAL_MODE parameter type, but then goes on to say that \"the presence of the parameter in a HIP base exchange means that the end-host supports NAT traversal extensions defined in this document\".\u00a0 If I undrestand correctly, only the specific presence of the ICE-HIP-UDP mode of the NAT_TRAVERSAL_MODE parameter does so, and so to say that the presence of \"the [NAT_TRAVERSAL_MODE] parameter\" indicates support for this document would be backwards incompatible with  RFC 5770 . I'd also like to delve a little further into the potential \"cross-protocol\" attack (same protocol, really, but the same attack) that Ekr raised, between RVS_HMAC and RELAY_HMAC.\u00a0 This is probably a \"discuss discuss\", so let's see where it leads... The semantics for either type of HMAC is that it is an HMAC over the HIP packet excluding itself and subsequent parameters.\u00a0 Pulling up the HIP packet format from  RFC 7401 , that looks like: \u00a0 \u00a0 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  3 \u00a0 \u00a0 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  | Next Header\u00a0  | Header Length |0| Packet Type |Version| RES.|1| \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Checksum\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Controls\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Sender's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Receiver's Host Identity Tag (HIT)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HIP Parameters\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  /\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  / \u00a0  |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  | \u00a0  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The HMAC key is the integrity key for that direction of traffic between HITs, so the \"cross-protocol\" part can only come in by confusing the packet recipient into confusion as to whether it is processing an RVS_HMAC or a RELAY_HMAC (but any other entity will reject the packet by virtue of it using the wrong key).\u00a0 Modern best practices are to go through a key derivation step that incorporates as much information as possible about what the derived key will be used for, which would in this case include the TLV type of the HMAC parameter and presumably the HITs in question as well. In particular, the TLV type of the HMAC parameter is *not* input into the HMAC calculation (at least for RVS_HMAC), so the trivial discriminator is not present.\u00a0 The \"packet type\" in the header in the header is potentially going to differ across usages, so I think that's a good place to focus discussion.\u00a0 Unfortunately, Section 4.2.1 of  RFC 8004  suggests that RVS_HMAC is going to be present a lot of the time, so it's not really clear to me what packet types either RVS_HMAC and/or REPLAY_HMAC are expected to occur in.\u00a0 Could a HIP expert please jump in and help clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-05-04 12:34:27-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3099 I am very familiar with ICE and yet I found this document extremely hard to follow. The problem is that it cherry-picks pieces of ICE and I'm just not sure that it's a complete specification when put all together. I have noted a number of places where I actually am not sure how to implement something, and fixing those will resolve this DISCUSS, but IMO you really should totally rewrite this document either (a) as a variant of ICE or (b) as an entirely new document not with a pile of new text and then references out to ICE sections. DETAIL S 4.2. >\u00a0 \u00a0 \u00a0 request type SHOULD NOT create any state at the Control Relay Server. >\u00a0   >\u00a0 \u00a0 \u00a0 ICE guidelines [ I-D.ietf-ice-rfc5245bis ] for candidate gathering are >\u00a0 \u00a0 \u00a0 followed here.\u00a0 A number of host candidates (loopback, anycast and >\u00a0 \u00a0 \u00a0 others) should be excluded as described in the ICE specification >\u00a0 \u00a0 \u00a0 [ I-D.ietf-ice-rfc5245bis ].\u00a0 Relayed candidates SHOULD be gathered in If you're going to normatively cherry-pick ICE, you need to note specific sections, I think. S 4.6.2. >\u00a0   >\u00a0 \u00a0 \u00a0 A host may receive a connectivity check before it has received the >\u00a0 \u00a0 \u00a0 candidates from its peer.\u00a0 In such a case, the host MUST immediately >\u00a0 \u00a0 \u00a0 generate a response, and then continue waiting for the candidates.\u00a0 A >\u00a0 \u00a0 \u00a0 host MUST NOT select a candidate pair until it has verified the pair >\u00a0 \u00a0 \u00a0 using a connectivity check as defined in Section 4.6.1. Are you supposed to put this on a TODO check list as with ICE? S 5.8. >\u00a0   >\u00a0  5.8.\u00a0 RELAY_HMAC Parameter >\u00a0   >\u00a0 \u00a0 \u00a0 As specified in Legacy ICE-HIP [ RFC5770 ], the RELAY_HMAC parameter >\u00a0 \u00a0 \u00a0 value has the TLV type 65520.\u00a0 It has the same semantics as RVS_HMAC >\u00a0 \u00a0 \u00a0 [ RFC8004 ]. What key is used for the HMAC?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-04 08:45:11-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 08:23:25-08:00",
    "text": "So this discuss should be relatively easy to address.  So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC 6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-05 02:55:03-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-04 08:45:11-08:00",
    "text": "So this discuss should be relatively easy to address.  1. So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC 6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information. 2. Secondly, as this solution is different from the  RFC 5770  should this solution have a different service name?  3. So I don't quite understand what the co-existance story are for the relay having an listener on port 10500? Is that port only used for UDP/HIPv1 ( RFC5770 ) and UDP/HIPv2 (This doc). And the listening stack can determine which version is used to determine which of the protocol is run. And the issue with multiplexing is only existing for the ports that one gathers?",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-05 03:08:02-08:00",
    "end_reason": "discuss_updated",
    "start": "2020-03-05 02:55:03-08:00",
    "text": "So this discuss should be relatively easy to address.  1. So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC  6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information. 2. Secondly, as this solution is different from the  RFC 5770  should this solution have a different service name? The reason I am asking is that it depends on how for example how an initiator determine which of the NAT traversal solution. If there is any intention to use DNS SRV for example different service name would make sense. This is primarily to verify that this has been considered.  3. So I don't quite understand what the co-existance story are for the relay having an listener on port 10500? Is that port only used for UDP/HIPv1 ( RFC5770 ) and UDP/HIPv2 (This doc). And the listening stack can determine which version is used to determine which of the protocol is run. And the issue with multiplexing is only existing for the ports that one gathers? Can you please add a paragraph or two somewhere in the document. I think it should be referenced by the port registration update.  4. MTU impact of NAT traversal.  Section 5.1 states\u00a0   \"It is worth noting that UDP encapsulation of HIP packets reduces the \u00a0  Maximum Transfer Unit (MTU) size of the control plane by 12 bytes.\" There is also a similar text in Section 5.11: \u00a0  It is worth noting that UDP encapsulation of ESP reduces the MTU size \u00a0  of data plane by 8 bytes. I think the document needs a discussion and impact on MTU which this NAT traversal has on the HIP packets being sent.  - First of all there appears to be more packet expansions happening in some cases, for example the RELAY_HMAC option expands packets on one leg. - Secondly, HIP requires IP fragementation support, however IP fragmentation through NAT is commonly not working. Thus an HIP packet being UDP encapsulated that results in packet exceeding MTU will likely end up in an MTU black hole on path.  The addition of the NAT traversal encapsulation actually increases the need for MTU discovery or care in MTU handling by the HIP initiator. I think there need to be discussion of that in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-07-28 07:44:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-03-05 03:08:02-08:00",
    "text": "So I think the below are important things that needs to be discussed before proceeding. However, I might have missed things as I didn't have time to read the whole document in detail. Several of the issues are pieces for discussion to ensure that the right thing really is done.  1. So this document recommends the usage of port 10500 as default listening port. A port registered by Ari and also used for  RFC 5770 . I get the impression that the port was registered separately from  RFC 5770 . So the port is assigned to Ari. Would Ari be willing to release the port for re-assignment to IESG control.  RFC  6335  has the recommendation for ports for IETF protocols that the assignee is IESG and the contact  chair@ietf.org . This to have the change control with IETF as body rather than with individuals.  If Ari agrees to this, I think it would be good to have the IANA section be updated to note the re-assignment and provide the necessary information. 2. Secondly, as this solution is different from the  RFC 5770  should this solution have a different service name? The reason I am asking is that it depends on how for example how an initiator determine which of the NAT traversal solution. If there is any intention to use DNS SRV for example different service name would make sense. This is primarily to verify that this has been considered.  3. So I don't quite understand what the co-existance story are for the relay having an listener on port 10500? Is that port only used for UDP/HIPv1 ( RFC5770 ) and UDP/HIPv2 (This doc). And the listening stack can determine which version is used to determine which of the protocol is run. And the issue with multiplexing is only existing for the ports that one gathers? Can you please add a paragraph or two somewhere in the document. I think it should be referenced by the port registration update.  4. MTU impact of NAT traversal.  Section 5.1 states\u00a0   \"It is worth noting that UDP encapsulation of HIP packets reduces the \u00a0  Maximum Transfer Unit (MTU) size of the control plane by 12 bytes.\" There is also a similar text in Section 5.11: \u00a0  It is worth noting that UDP encapsulation of ESP reduces the MTU size \u00a0  of data plane by 8 bytes. I think the document needs a discussion and impact on MTU which this NAT traversal has on the HIP packets being sent.  - First of all there appears to be more packet expansions happening in some cases, for example the RELAY_HMAC option expands packets on one leg. - Secondly, HIP requires IP fragementation support, however IP fragmentation through NAT is commonly not working. Thus an HIP packet being UDP encapsulated that results in packet exceeding MTU will likely end up in an MTU black hole on path.  The addition of the NAT traversal encapsulation actually increases the need for MTU discovery or care in MTU handling by the HIP initiator. I think there need to be discussion of that in the document.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-07-27 14:21:44-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-15 23:16:24-07:00",
    "text": "Sec 4.2 and 4.6.2 specify a minimum of RTO of 500ms. There\u2019s no way you would know this,\u00a0 but  draft-ietf-tcpm-rto-consider  is close to IESG approval and specifies a minimum of 1 second without more information about the path. I would prefer that we change these minimums but perhaps there\u2019s a compelling reason for 500ms?   RFC 5770  is a normative downref. I couldn\u2019t find indication the procedures in  RFC 3967  or 4897 were followed to address this. One solution would be to downgrade this document to Experimental.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-07-30 06:17:14-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-05-10 03:00:05-07:00",
    "text": "1) This document should also update the IANA port registry to add a reference to this RFC-to-be to the existing entry for port 10500 (eventually even with note that this RFC-to-be discusses how to distinguish the services using NAT_TRAVERSAL_MODE). 2) Sec 4.4: \"Hosts SHOULD NOT use values smaller than 5 ms for the minimum Ta,...\" In rfc5245bis this is a MUST. Why is this a SHOULD here? Also in sec 4.6.2.: \"If neither one of the hosts announced a minimum pacing value, a value of 50 ms SHOULD be used.\" This must be a MUST to be inline with sec 4.4. 3) Appendix A: \"Ta value so that only two connectivity check messages are sent on every RTT.\" Why two?  RFC8085  recommends (SHOULD) at may one packet per RTT for non-congestion control transmissions",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-02-21 04:38:15-08:00",
    "end_reason": "evaluation_closed",
    "start": "2019-07-30 06:17:14-07:00",
    "text": "1) This document should also update the IANA port registry to add a reference to this RFC-to-be to the existing entry for port 10500 (eventually even with note that this RFC-to-be discusses how to distinguish the services using NAT_TRAVERSAL_MODE). 2) Sec 4.4: \"Hosts SHOULD NOT use values smaller than 5 ms for the minimum Ta,...\" In rfc5245bis this is a MUST. Why is this a SHOULD here? Also in sec 4.6.2.: \"If neither one of the hosts announced a minimum pacing value, a value of 50 ms SHOULD be used.\" This must be a MUST to be inline with sec 4.4. 3) Appendix A: \"Ta value so that only two connectivity check messages are sent on every RTT.\" Why two?  RFC8085  recommends (SHOULD) at most one packet per RTT for non-congestion control transmissions",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2018-10-14 05:41:00-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-27 06:27:22-07:00",
    "text": "I have a list of smaller points that should be relatively easy to address. The two main ones: I believe [ I-D.ietf-lisp-sec ] needs to be a Normative Reference for this document. This will address some of the issues raised by Benjamin, but will also make description of various security bits meaningful. Similarly, in Section 5.6: \u00a0  I: This is the xTR-ID bit.\u00a0 When this bit is set, what is appended to \u00a0 \u00a0 \u00a0 the Map-Register is a 128-bit xTR router-ID and then a 64-bit \u00a0 \u00a0 \u00a0 site-ID.\u00a0 See LISP NAT-Traversal procedures in \u00a0 \u00a0 \u00a0 [ I-D.ermagan-lisp-nat-traversal ] for details. This description makes [ I-D.ermagan-lisp-nat-traversal ] a normative reference.",
    "type": "Discuss"
  },
  {
    "ad": "Alexey Melnikov",
    "end": "2019-02-07 03:21:29-08:00",
    "end_reason": "position_updated",
    "start": "2018-10-14 05:41:00-07:00",
    "text": "I have a list of smaller points that should be relatively easy to address. The two main ones: I believe [ I-D.ietf-lisp-sec ] needs to be a Normative Reference for this document. This will address some of the issues raised by Benjamin, but will also make description of various security bits meaningful.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-02-07 05:50:27-08:00",
    "end_reason": "discuss_updated",
    "start": "2018-09-26 21:51:32-07:00",
    "text": "See my ballot position on rfc6830bis for some more general notes. I did most of my review on the -15, though I attempted to note when the -16 has changed the text. I am concerned about the handling procedures for Map-Requests that are encapsulated with the 'S' bit present.\u00a0 In particular, the ITR is required to discard non-secure responses, which is necessary in order to avoid a downgrade attack (in the current architecture).\u00a0 However, it seems that ETRs are not required to enable security in their registrations, and Map-Servers are supposed to strip the security flag when forwarding Map-Requests to ETRs that do not register as supporting LISP-SEC, and the resulting Map-Reply messages would thus not be secured, and dropped by the initiating ITR.\u00a0 So support for LISP-SEC would need to be mandatory for all ETRs in order for any ITR to be able to enforce the downgrade-protection behavior, which is a pretty bad deployment story.\u00a0 Making LISP-SEC mandatory everywhere would, of course, avoid this issue. I do not understand the procedure for allocation of EIDs.\u00a0 In a global mapping database, there needs to be some authoritative procedure for determining what ETRs and/or Map-Servers are authoritative for a given subset of EID space.\u00a0 All I've seen so far to do this effectively boils down to manual configuration, whether explicitly on a Map-Server or just as a mapping of what keys are authorized to advertise which EIDs. A 64-bit (or in some cases 24-bit) nonce is used, apparently as a request/response correlator, but the actual (cryptographic?) properties required from the nonce in the protocol are not clearly covered.\u00a0 In some cryptographic contexts a 64-bit nonce may be too short; I do not believe that this is the case here, but without a clear picture of what the requirements are it's hard to say for sure.\u00a0 24 bits, on the other hand, is quite small. The layout of the document is somewhat confusing, in a way that could arguably lead to noninteroperable implemnetations.\u00a0 For example, the section on the Map-Register message format includes descriptions of the fields in the records and locators therein, and the section on Map-Notify reuses that portion of the structure, incorporating the field descriptions by reference.\u00a0 But the Map-Register section does not indicate that its descriptions are to apply in both cases, leading to confusing text that talks about values being set or cases that are not possible for a Map-Register (i.e., the section nominally being described).\u00a0 It would be most clear to have a dedicated subsection for the portion of the structure(s) that is being reused, which would allow for the per-field descriptions to clearly indicate in which scope they are defined.\u00a0 But the more minimal change of just indicating that the primary definition will be \"dual use\" would probably suffice as well. The Map-Reply record/locator descriptions are reused similarly; I made a comment on section 5.4 that lists a specific instance, though I believe the phenomenon is more general. Similarly, there are many instances (some noted in my Comment) where a bidirectional interaction between two xTRs is described, yet the peers are identified as \"ITR\" and \"ETR\".\u00a0 This is very confusing when the entity named as \"ITR\" is described as performing ETR functionality, or vice versa; pedagogically, it would be much better to use non-role-based names for the entities while describing these exchanges. While I see that there is an entire document dedicated to Map-Versioning and thus we do not need to fully cover everything here, I think it is critically important to be clear that there are consistency requirements attached to map versions, as relating to the stability of membership of RLOCs in a given record, etc.\u00a0 (I cannot be very clear hear since I am not entirely confident of the details of the consistency requirements yet.) The Map-Register message format field descriptions includes: \u00a0  Nonce:\u00a0 This 8-octet 'Nonce' field is set to 0 in Map-Register \u00a0 \u00a0 \u00a0 messages if no Map-Notify message is expected to acknowledge it. \u00a0 \u00a0 \u00a0 Since the Map-Register message is authenticated, the 'Nonce' field \u00a0 \u00a0 \u00a0 is not currently used for any security function but may be in the \u00a0 \u00a0 \u00a0 future as part of an anti-replay solution. Having the map registrations subject to replay seems like a critical flaw that would allow an attacker to disrupt any sort of mobility situation, even in the presence of LISP-SEC.\u00a0 I cannot see how this protocol could be suitable for Proposed Standard status with such a susceptibility to replay. I think we need more details on the expected Map-Register/Map-Notify and Map-Notify/Map-Notify-Ack message flows.\u00a0 In what cases is the ack not needed, and why? I think we need greater clarity on the 'E' and 'M' bits in the ECM format; more in the Comment section. I am concerned that the extensibility mechanism for ECM encapsulation is insufficiently well specified.\u00a0 Is a registry needed?\u00a0 Will new message types need to Update: this document to indicate the extension?\u00a0 What attributes make a message (un)suitable for encapsulation? Section 8.1 says: \u00a0  o\u00a0 A Negative Map-Reply, with action code of \"Natively-Forward\", from \u00a0 \u00a0 \u00a0 a Map-Server that is authoritative for an EID-Prefix that matches \u00a0 \u00a0 \u00a0 the requested EID but that does not have an actively registered, \u00a0 \u00a0 \u00a0 more-specific ID-prefix. This document provides no mechanism to establish that a Map-Server is authoritative for a given EID-Prefix, so this entire case is non-actionable. Section 8.2 says: \u00a0  An ETR publishes its EID-Prefixes on a Map-Server by sending LISP \u00a0  Map-Register messages.\u00a0 A Map-Register message includes \u00a0  authentication data, so prior to sending a Map-Register message, the \u00a0  ETR and Map-Server SHOULD be configured with a shared secret or other \u00a0  relevant authentication information. This cannot be a SHOULD if things are to work properly; it has to be MUST. Section 8.2 also says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 As developers \u00a0  and operators gain experience with the mapping system, additional, \u00a0  stronger security measures may be added to the registration process. This kind of language for forward-looking guidance indicates that the current security properties are not well-understood by the authors and is inconsistent with Proposed Standard status. Perhaps I am misunderstanding the desired behavior but when Section 8.4 says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  To do this, it forwards the unencapsulated Map-Request, \u00a0  with the original ITR RLOC as the source, to the mapping database \u00a0  system.\u00a0 [...] doesn't this carry substantial risk of running afoul of  BCP 38  filtering? I think the MUST and SHOULD requirements for implementing cryptographic primitives are generally swapped; the more-secure ones (e.g., HMAC-SHA-256-128) should be MUST, and the legacy algorithms needed for compatibility with existing deployments would be SHOULD. Section 9 currently states: \u00a0  [a]s noted in Section 8.2, a Map-Server SHOULD verify that all EID- \u00a0  Prefixes registered by an ETR match the configuration stored on the \u00a0  Map-Server. I think we need a MUST-level requirement for verifying authorization for a given EID-Prefix, with one way of satisfying the requirement being checking configuration, but allowing for other means as well. In the -15, Section 9 also stated: \u00a0  The currently defined authentication mechanism for Map-Register \u00a0  messages does not provide protection against \"replay\" attacks by a \u00a0  \"man-in-the-middle\".\u00a0 Additional work is needed in this area. I don't understand how this sort of statement can be present in a document targetting Proposed Standard status, in effect admitting that there are grave deficiencies in the security posture of the protocol.\u00a0 The -16 has gained some language indicating that LISP-SEC mitigates many attacks in this space, but that is hardly of much use when LISP-SEC is not a mandatory protocol feature. I'm disappointed that there is no Privacy Considerations section, though given that  RFC 7835  seems to attempt to disclaim privacy considerations entirely, perhaps I should not be surprised.\u00a0 Tying devices to persistent Endpoint IDentifiers and using them in mobility situations inherently raises privacy concerns.\u00a0 These are not necessarily fatal to a protocol, but they do need to be discussed and the benefits weighed against the costs.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-30 11:53:57-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-02-07 05:50:27-08:00",
    "text": "This document has normative dependencies on other WG drafts that are not yet mature (one could perhaps define this as having completed IETF LC).\u00a0 In particular, I believe there is a nontrivial chance that either or both of lisp-sec and 6834bis could require changes to this document in order to be fit for purpose, and thus that this document cannot safely be approved for publication until these normative dependencies are closer to publication. In particular, I have done a fairly full review of lisp-sec and have DISCUSS-worthy points with it (I have not done much review of 6834bis yet). This document includes a mechansism to use HMAC keyed by a pre-shared key to authenticate messages (Map-Register and Map-Notify*); it is directly using the long-term PSK as the HMAC key.\u00a0 This is not really consistent with current IETF best practices (e.g,.  BCP 107 ), which tend to not use the long-term key directly for keying messages, but rather to incorporate some form of key derivation step, to protect the long-term key from cryptanalysis and reduce the need to track long-term per-key data usage limits.\u00a0 It is probably not feasible to directly require all LISP implementations to switch keying strategy, but it seems quite advisable to define new algorithm ID types that include a key derivation step before the HMAC, and to begin efforts to convert the ecosystem to the more sustainable cryptographic usage.\u00a0 I would like to discuss what actions are reasonable to take at this time, on this front. As implied by my previous discuss ballot position, I think Section 5.4 should grow a statement (akin to the one added in Section 5.6) that the \"Record\" format is also used in the \"Map-Reply Record\" field of the Map-Request message, and that the field definitions are reused wholesale for the Map-Register message. In Section 5.6, this text seems internally inconsistent: \u00a0 \u00a0 \u00a0 can continue using an incrementing nonce.\u00a0 If the the ETR cannot \u00a0 \u00a0 \u00a0 support saving the nonce, then when it restarts it MUST use a new \u00a0 \u00a0 \u00a0 authentication key to register to the mapping system.\u00a0 A Map- \u00a0 \u00a0 \u00a0 Server MUST track and save in persistent storage the last nonce \u00a0 \u00a0 \u00a0 received for each ETR xTR-ID that registers to it.\u00a0 If a Map- \u00a0 \u00a0 \u00a0 Register is received with a nonce value that is not greater than \u00a0 \u00a0 \u00a0 the saved nonce, it drops the Map-Register message and logs the \u00a0 \u00a0 \u00a0 fact a replay attack could have occurred. In order for a new key to be useful as stated, the Map-Server must do the nonce tracking per\u00a0 pair and not just per xTR-ID. Also, guidance is needed on what scope of uniqueness is needed for the Key ID to function properly -- unique per Map-Server?\u00a0 Per  pair?\u00a0 Per LISP domain? Also in Section 5.6: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Implementations of this \u00a0 \u00a0 \u00a0 specification MUST include support for either HMAC-SHA-1-96 \u00a0 \u00a0 \u00a0 [ RFC2404 ] and HMAC-SHA-256-128 [ RFC4868 ] where the latter is \u00a0 \u00a0 \u00a0 RECOMMENDED. I don't think this sort of \"mandatory to choose\" is  BCP 201 -compliant. I think there needs to be more description of Site-ID usage and scoping in order to be fully interoperable (more in the COMMENT section). There are multiple places where we talk about message contents being copied from a corresponding request (e.g., from Map-Request to Map-Notify); we need to explicitly state that the authentication data is recomputed to match, e.g., the new message type.\u00a0 I've tried to note these occurrences in the COMMENT section. The condition for Map-Notify-Ack terminating Map-Notify retransmission seems incomplete (more in the COMMENT). In Section 8.2: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  A Map-Register message includes \u00a0  authentication data, so prior to sending a Map-Register message, the \u00a0  ETR and Map-Server SHOULD be configured with a shared secret or other \u00a0  relevant authentication information.\u00a0 [...] We require authentication for Map-Register and do not provide any alternative mechanism for key distribution, so why is this only a SHOULD? \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 As developers \u00a0  and operators gain experience with the mapping system, additional, \u00a0  stronger security measures may be added to the registration process. This text does not add confidence to the \"proposed standard\" label. In Section 9: \u00a0  A complete LISP threat analysis can be found in [ RFC7835 ].\u00a0 In what As I have stated previously, the threat analysis in  RFC 7835  is not complete and it should not be referred to as such. \u00a0  3.\u00a0 LISP-SEC [ I-D.ietf-lisp-sec ] MUST be implemented.\u00a0 Network \u00a0 \u00a0 \u00a0  operartors should carefully weight how the LISP-SEC threat model \u00a0 \u00a0 \u00a0  applies to their particular use case or deployment.\u00a0 If they \u00a0 \u00a0 \u00a0  decide to ignore a particular recommendation, they should make \u00a0 \u00a0 \u00a0  sure the risk associated with the corresponding threats is well \u00a0 \u00a0 \u00a0  understood. I'm concerned enough about the risk of having a \"ITR requests lisp-sec but ETR didn't use it\" case that causes complete breakage, that I want to talk about this a bit more.\u00a0 We currently in this document say that lisp-sec is mandatory to implement (which presumably covers at least ITRs, ETRs, Map-Resolvers, and Map-Servers).\u00a0 LISP-SEC itself says that \"and ETR that supports LISP-SEC MUST set the S bit in its Map-Register messages\".\u00a0 Is it possible that an ETR might \"implement\" but then not \"support\" LISP-SEC?\u00a0 If so, then we should consider the possibility that we need an authenticated signal (from the mapping system to the ITR) that downgrading from lisp-sec is allowed.\u00a0 There seem to be several possibilities for how one might construct such a signal; two that came to mind to me would be (1) to define a new ACT value for \"repeat without lisp-sec\" that could be returned as a negative Map-Response directly from the mapping system wherever the mapping system is able to discern that the ETR in question does not support lisp-sec (I don't actually know if this could happen at Map-Resolver or would need to be delayed until the final Map-Server) and (2) to have an optional Map-Request field that the ETR is required to copy unchanged to the Map-Reply; this could then include a message HMAC'd in the ITR-OTK that indicates lisp-sec non-support and binds to the nonce in the request. Whether these are workable ideas seems to depend on aspects of the mapping system to which I cannot speak. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The LISP-SEC \u00a0  protocol defines a mechanism for providing origin authentication, \u00a0  integrity, anti-replay, protection, and prevention of 'man-in-the- \u00a0  middle' and 'prefix overclaiming' attacks on the Map-Request/Map- \u00a0  Reply exchange.\u00a0 [...] Does LISP-SEC actually provide any additional anti-replay protection not present in the base protocol?\u00a0 I do not remember any such additional protection. \u00a0  A complete LISP threat analysis has been published in [ RFC7835 ]. \u00a0  Please refer to it for more detailed security related details. (1) you already said that above, (2) it's still not complete. Section 11 (\"Changes since  RFC 6833 \") is inaccurate (see COMMENT).\u00a0 I did not check whether it is complete, but someone needs to do so before final publication. The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. A 64-bit nonce is used, apparently as a request/response correlator, but the actual (cryptographic?) properties required from the nonce in the protocol are not clearly covered.\u00a0 In some cryptographic contexts a 64-bit nonce may be too short; I do not believe that this is the case here, but without a clear picture of what the requirements are it's hard to say for sure.\u00a0  [ed. there was some previous discussion about 24-bit nonces that has been removed from the text, but the core question of what properties the nonce is required to provide remains unaddressed in the document text.\u00a0 There is also a field called 'Nonce' that is used as a s equence number, the requirements for which are partially described in the new text.] The layout of the document is somewhat confusing, in a way that could arguably lead to noninteroperable implemnetations.\u00a0 For example, the section on the Map-Register message format includes descriptions of the fields in the records and locators therein, and the section on Map-Notify reuses that portion of the structure, incorporating the field descriptions by reference.\u00a0 But the Map-Register section does not indicate that its descriptions are to apply in both cases, leading to confusing text that talks about values being set or cases that are not possible for a Map-Register (i.e., the section nominally being described).\u00a0 It would be most clear to have a dedicated subsection for the portion of the structure(s) that is being reused, which would allow for the per-field descriptions to clearly indicate in which scope they are defined.\u00a0 But the more minimal change of just indicating that the primary definition will be \"dual use\" would probably suffice as well. The Map-Reply record/locator descriptions are reused similarly; I made a comment on section 5.4 that lists a specific instance, though I believe the phenomenon is more general. [ed. this was partially addressed, but the request to examine all data structure reuse (note that \"for example\" was used) was not heeded] Similarly, there are many instances (some noted in my Comment) where a bidirectional interaction between two xTRs is described, yet the peers are identified as \"ITR\" and \"ETR\".\u00a0 This is very confusing when the entity named as \"ITR\" is described as performing ETR functionality, or vice versa; pedagogically, it would be much better to use non-role-based names for the entities while describing these exchanges. [ed. there was some improvement here; I still note some potential sites for confusion in the COMMENT] While I see that there is an entire document dedicated to Map-Versioning and thus we do not need to fully cover everything here, I think it is critically important to be clear that there are consistency requirements attached to map versions, as relating to the stability of membership of RLOCs in a given record, etc.\u00a0 (I cannot be very clear hear since I am not entirely confident of the details of the consistency requirements yet.) I think we need greater clarity on the 'E' and 'M' bits in the ECM format; more in the Comment section. [ed. the reader will need to consult the original ballot's COMMENT section and not the current one] Section 8.1 says: \u00a0  o\u00a0 A Negative Map-Reply, with action code of \"Natively-Forward\", from \u00a0 \u00a0 \u00a0 a Map-Server that is authoritative for an EID-Prefix that matches \u00a0 \u00a0 \u00a0 the requested EID but that does not have an actively registered, \u00a0 \u00a0 \u00a0 more-specific ID-prefix. This document provides no mechanism to establish that a Map-Server is authoritative for a given EID-Prefix, so this entire case is non-actionable. [ed. I think there may have been some previous discussion on this (e.g., that might render it moot) but couldn't find it quickly] Section 8.2 says: \u00a0  An ETR publishes its EID-Prefixes on a Map-Server by sending LISP \u00a0  Map-Register messages.\u00a0 A Map-Register message includes \u00a0  authentication data, so prior to sending a Map-Register message, the \u00a0  ETR and Map-Server SHOULD be configured with a shared secret or other \u00a0  relevant authentication information. This cannot be a SHOULD if things are to work properly; it has to be MUST. Section 8.2 also says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 As developers \u00a0  and operators gain experience with the mapping system, additional, \u00a0  stronger security measures may be added to the registration process. This kind of language for forward-looking guidance indicates that the current security properties are not well-understood by the authors and is inconsistent with Proposed Standard status. I think the MUST and SHOULD requirements for implementing cryptographic primitives are generally swapped; the more-secure ones (e.g., HMAC-SHA-256-128) should be MUST, and the legacy algorithms needed for compatibility with existing deployments would be SHOULD. Section 9 currently states: \u00a0  [a]s noted in Section 8.2, a Map-Server SHOULD verify that all EID- \u00a0  Prefixes registered by an ETR match the configuration stored on the \u00a0  Map-Server. I think we need a MUST-level requirement for verifying authorization for a given EID-Prefix, with one way of satisfying the requirement being checking configuration, but allowing for other means as well.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-12-30 17:24:33-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-30 11:53:57-07:00",
    "text": "Updating for the -25 by removing points that are fully addressed but leaving points that I still want to have further discussion on.\u00a0 It may be most expedient to continue discussion on my -24 ballot thread.\u00a0 There are a couple of new items to the -25, that I attempt to call out as such (they appear right before the \"the following items were present in my original DISCUSS position\" section). Please also note that the COMMENT section was entirely refreshed for the -24, and I make some additions for the -25. This document has normative dependencies on other WG drafts that are not yet mature (one could perhaps define this as having completed IETF LC).\u00a0 In particular, I believe there is a nontrivial chance that either or both of lisp-sec and 6834bis could require changes to this document in order to be fit for purpose, and thus that this document cannot safely be approved for publication until these normative dependencies are closer to publication. In particular, I have done a fairly full review of lisp-sec and have DISCUSS-worthy points with it (I have not done much review of 6834bis yet). Also in Section 5.6: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  Implementations of this \u00a0 \u00a0 \u00a0 specification MUST include support for either HMAC-SHA-1-96 \u00a0 \u00a0 \u00a0 [ RFC2404 ] and HMAC-SHA-256-128 [ RFC4868 ] where the latter is \u00a0 \u00a0 \u00a0 RECOMMENDED. I don't think this sort of \"mandatory to choose\" is  BCP 201 -compliant, since we need to have at least one MTI, strong, algorithm, and this text did not pick one to be MTI.\u00a0 Now (-25) we're at \"SHOULD include support for HMAC-SHA256-128-HKDF-SHA256\", which is also not quite MTI (but is definitely strong).\u00a0 Of course, I personally won't complain if we just go with the new HKDF stuff, but I recognize that it would be a big change for implementations and deployments, and don't think we need to make the spec completely disjoint from reality just to check a box.\u00a0 So we could make HMAC-SHA-256-128 MTI and leave the new one as SHOULD, for example. I think there needs to be more description of Site-ID usage and scoping in order to be fully interoperable (more in the COMMENT section). [ed. Even focusing on the scoping while leaving the detailed usage as deployment-specific would be okay] There are multiple places where we talk about message contents being copied from a corresponding request (e.g., from Map-Request to Map-Notify); we need to explicitly state that the authentication data is recomputed to match, e.g., the new message type.\u00a0 I've tried to note these occurrences in the COMMENT section. [ed. I think just from Map-Notify to Map-Notify-Ack is all that's left] The condition for Map-Notify-Ack terminating Map-Notify retransmission seems incomplete.\u00a0 Specifically, we should only accept the Map-Notify-Ack to stop retransmission if the authentication data validates (and maybe that it uses the same Key-ID as the Map-Notify, though that might be overkill).\u00a0 So just \"a Map-Notify-Ack is received by the  Map-Server with the same nonce\" is not quite enough. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The LISP-SEC \u00a0  protocol defines a mechanism for providing origin authentication, \u00a0  integrity, anti-replay, protection, and prevention of 'man-in-the- \u00a0  middle' and 'prefix overclaiming' attacks on the Map-Request/Map- \u00a0  Reply exchange.\u00a0 [...] Does LISP-SEC actually provide any additional anti-replay protection not present in the base protocol?\u00a0 I do not remember any such additional protection. [ed. specifically, the nonce mechanism already in this document provides a decent level of replay protection, so I am trying to nail down how LISP-SEC does incrementally better than what's already here, for the specific case of an attacker literally recording a Map-Reply and replaying it, bit-for-bit, at a later time. Section 11 (\"Changes since  RFC 6833 \") is inaccurate (see COMMENT).\u00a0 I did not check whether it is complete, but someone needs to do so before final publication. [ed. Waiting to do this until all other changes are in is fine.] New in the -25, there's an internal inconsistency between Section 5.6's description of the Authentication Data procedure, that says implementations \"SHOULD include support for HMAC-SHA256-128+HKDF-SHA256\", and Section 9's \"[a]n implementation MUST support HMAC-SHA256-128+HKDF-SHA256\". Not new in the -25, but IIRC not previously discussed, how does a Map-Server pick a Nonce value for unsolicited Map-Notify messages? The following items were present in my original DISCUSS position and still have not been resolved.\u00a0 Note that I copy below the previous ballot text even for some issues that are described above already in different words. I think we need greater clarity on the 'E' and 'M' bits in the ECM format; more in the Comment section [of the ballot on -16], quoted here for clarity: >\u00a0  E:\u00a0 \u00a0 This is the to-ETR bit.\u00a0 When set to 1, the Map-Server's >\u00a0 \u00a0 \u00a0 \u00a0  intention is to forward the ECM to an authoritative ETR. > > I think this needs to say more about which message flows this bit is > defined for.\u00a0 Presumably the ITR will never use it for sending an > encapsulated Map-Request to a Map-Resolver, but there seem to be plenty of > places where ECM wrapping is used. > >\u00a0  M:\u00a0 \u00a0 This is the to-MS bit.\u00a0 When set to 1, a Map-Request is being >\u00a0 \u00a0 \u00a0 \u00a0  sent to a co-located Map-Resolver and Map-Server where the >\u00a0 \u00a0 \u00a0 \u00a0  message can be processed directly by the Map-Server versus the >\u00a0 \u00a0 \u00a0 \u00a0  Map-Resolver using the LISP-DDT procedures in [ RFC8111 ]. > > How does the sender know that its configured Map-Resolver is also a > Map-Server?\u00a0 It's unclear to me why this needs a bit in the message as > opposed to just happening based on the attributes of the receiving > Map-Server.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-07-08 21:25:47-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-30 17:24:33-08:00",
    "text": "It looks like an edit or two that was supposed to be in the -26 didn't make it by accident, so sorry for the repeat comments; hopefully the writing work in question will be easy to retrieve. Other than that we're down to just a few remaining points, two of which I believe should be trivial to resolve. In Section 5.6 we say that \"implementations of this spsecification SHOULD include support for HMAC-SHA256-128+HKDF-SHA256 but section 9 says \"implementation MUST support HMAC-SHA256-128+HKDF-SHA256\", which is internally inconsistent; my understanding from a previous discussion with the authors was that HMAC-SHA256-128+HKDF-SHA256 would be a SHOULD and it was HMAC-SHA256-128 that was MUST. The condition for Map-Notify-Ack terminating Map-Notify retransmission seems incomplete.\u00a0 Specifically, we should only accept the Map-Notify-Ack to stop retransmission if the authentication data validates (and maybe that it uses the same Key-ID as the Map-Notify, though that might be overkill).\u00a0 So just \"a Map-Notify-Ack is received by the  Map-Server with the same nonce\" is not quite enough; we'd want to say \"an authenticated Map-Notify-Ack is received by the Map-Server with the same nonce\". In Section 9: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The LISP-SEC \u00a0  protocol defines a mechanism for providing origin authentication, \u00a0  integrity, anti-replay, protection, and prevention of 'man-in-the- \u00a0  middle' and 'prefix overclaiming' attacks on the Map-Request/Map- \u00a0  Reply exchange.\u00a0 [...] I think this document provides anti-replay protection for the Map-Request/Map-Reply exchange (by virtue of the single-use nonce), so we should remove \"anti-replay\" from the list of features LISP-SEC provides for the Map-Request/Map-Reply exchange. I think we need greater clarity on the 'E' and 'M' bits in the ECM format; are we perhaps defining them now in anticipation of future usage by other documents (e.g., ones that define specific mapping system implementations)? in particular (with quotes from my ballot position on the -24 for context): >\u00a0  E:\u00a0 \u00a0 This is the to-ETR bit.\u00a0 When set to 1, the Map-Server's >\u00a0 \u00a0 \u00a0 \u00a0  intention is to forward the ECM to an authoritative ETR. > > I think this needs to say more about which message flows this bit is > defined for.\u00a0 Presumably the ITR will never use it for sending an > encapsulated Map-Request to a Map-Resolver, but there seem to be plenty of > places where ECM wrapping is used. IIUC, the main ECM-wrapped messages we consider in this document are ITR-to-Map-Resolver Map-Requests and Map-Server-to-ETR Map-Requests. Is it an invariant that the ECM 'E' and 'M' bits can never be set at the same time (as they are only defined to have meaning for the different flows I list)? In an off-list discussion I got a clarification that \"The ETR bit is used so the Map-Server knows that the entity registering is an xTR versus a SDN or other type of controller that is registering mappings but doesn\u2019t have a full LISP protocol engine implementation and can\u2019t send Map-Replies\" which sounds like it applies to a Map-Register (\"is registering mappings\") but I didn't think that Map-Register was defined as a possible LCM to be in an ECM.\u00a0 (Maybe I'm just confused about that.) The main thing I still don't understand here is: what entity is going to interpret the E-bit and change behavior depending on its value? > >\u00a0  M:\u00a0 \u00a0 This is the to-MS bit.\u00a0 When set to 1, a Map-Request is being >\u00a0 \u00a0 \u00a0 \u00a0  sent to a co-located Map-Resolver and Map-Server where the >\u00a0 \u00a0 \u00a0 \u00a0  message can be processed directly by the Map-Server versus the >\u00a0 \u00a0 \u00a0 \u00a0  Map-Resolver using the LISP-DDT procedures in [ RFC8111 ]. > > How does the sender know that its configured Map-Resolver is also a > Map-Server?\u00a0 It's unclear to me why this needs a bit in the message as > opposed to just happening based on the attributes of the receiving > Map-Server. It sounds like this is only useful when the ECM contains a Map-Request from ITR to Map-Resolver, but I don't know how an ITR would know to (not) set this bit or what entity is going to change behavior depending on the value of the bit.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-10-27 18:04:07-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-08 21:25:47-07:00",
    "text": "(1) The -27 brought back the \"MUST\" for HMAC-SHA256-128 in Section 5.6 per my ballot on the -26, but left unchanged section 9, so we still have a SHOULD vs. MUST inconsistency w.r.t. implementing HMAC-SHA256-128+HKDF-SHA256.\u00a0 (I would of course prefer the same resolution of the inconsistency that Roman does, but have forgotten to what extent we have to defer to the deployed reality.) (2) It looks like the update in Section 5.7 is attempting to address my point about only terminating Map-Notify retransmission when the authentication data of the Map-Notify-Ack validates, but the added text is either misplaced or malformed.\u00a0 Perhaps CURRENT: \u00a0  The Map-Notify-Ack message has the same contents as a Map-Notify \u00a0  message.\u00a0 It is used to acknowledge the receipt of a Map-Notify and \u00a0  for the sender to stop retransmitting a Map-Notify with the same \u00a0  nonce and the authentication data validates.\u00a0 [...] NEW: \u00a0  The Map-Notify-Ack message has the same contents as a Map-Notify \u00a0  message.\u00a0 It is used to acknowledge the receipt of a Map-Notify and, \u00a0  once the the authentication data is validated, allows for the \u00a0  Map-Notify sender to stop retransmitting a Map-Notify with the same \u00a0  nonce. [...] (3) I think that Eric Rescorla's concern about a misbehaving ETR being able to prevent an ITR from learning that the ETR is no longer the appropriate ETR for a given prefix remains unaddressed.\u00a0 I wrote up a longer description at https://mailarchive.ietf.org/arch/msg/lisp/O2ycn4CkWsPhFyqrZuB4ZJBNnl0/ but in short, we only require the ITR to send its Map-Request through the mapping system (vs. directly to the ETR) when SMR is sent from an address not in the current mapping data for that prefix -- if the SMR is sent from an address in the current mapping data, we allow sending Map-Request directly to the ETR, outside the mapping system.\u00a0 I don't see a mechanism that guarantees that such a \"revocation\" event is noticed by the ITR. (4) The specification of the MAC+KDF algorithms doesn't seem detailed enough to be implementable.\u00a0  RFC 4868  is attempted to be used as a reference for both HMAC-SHA256-128 (er, and the one-character-off HMAC-SHA-256-128) and HKDF-SHA2562 (note spurious final '2'), but I think it can only work as a reference for the MAC algorithm.\u00a0 Presumably we need  RFC 5869  or such for the KDF part (5) This is probably my fault, but we're missing a step with how we describe the Map-Notify/Map-Notify-Ack per-message authentication. Specifically, while we do say that the authentication data needs to be recomputed each time, we don't clearly state that this is because the correct per-message key is different, because we are using a different 's' input to the KDF function for the different messages.\u00a0 In line with the \"Map-Register Authentication\" used for Map-Register, this would presumably be \"Map-Notify Authentication\" and \"Map-Notify-Ack Authentication\", but neither of those strings appear in this document. We might be able to localize the change to Section 5.6, akin to OLD: \u00a0 \u00a0 \u00a0 4:\u00a0 The derived per-message key is computed as: per-msg- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 key=KDF(nonce+s+PSK[Key ID]).\u00a0 Where the nonce is the value in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the Nonce field of the Map-Register and 's' is a string equal \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 to \"Map-Register Authentication\".\u00a0 [...] NEW: \u00a0 \u00a0 \u00a0 4:\u00a0 The derived per-message key is computed as: per-msg- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 key=KDF(nonce+s+PSK[Key ID]).\u00a0 Where the nonce is the value in \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the Nonce field of the Map-Register and 's' is a string that \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 corresponds to the message type being authenticated.\u00a0 For \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Map-Register messages, it is equal to \"Map-Register \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Authentication\".\u00a0 Similarly, for Map-Notify and Map-Notify-Ack \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 messages, it is \"Map-Notify Authentication\" and \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Map-Notify-Ack Authentication\", respectively. However, I think the rhetoric would be more robust if we also modified Section 5.7 to mention the existence of the different 's' values (or, rather, the different per-message key) when we say that the authentication data is recomputed.\u00a0 Perhaps, s/is recomputed/is recomputed using the corresponding per-message key/ (twice).",
    "type": "Discuss"
  },
  {
    "ad": "Deborah Brungard",
    "end": "2018-11-30 12:41:00-08:00",
    "end_reason": "position_updated",
    "start": "2018-09-27 06:58:05-07:00",
    "text": "ANA has requested a Temporary Discuss related to issue with port assignments.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2019-03-29 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-27 05:14:42-07:00",
    "text": "This DISCUSS is somewhat arbitratrily on 6833bis, but many of the same issues apply to 6830bis. I concur with Ben's DISCUSS. I do not believe that these documents have adequate security to advance to Proposed Standard. I thought it might be helpful for me to lay out my starting assumptions and threat model and what I think the appropriate standard is here. That gives us an opportunity to discuss them prior to getting into the specific security issues I raise below. SYSTEM ARCHITECTURE Per offline discussion, I understand that despite some of the introductory material, LISP is not currently intended to be Internet scale but rather to run in what seem to be fairly tightly controlled environments. Thus, I am assuming the following facts about the system: - The Mapping Service itself is secure and trusted.\u00a0 For the purposed \u00a0 of this discussion, I'm modelling all the entities in the services \u00a0 as one trusted element. - The ETRs have a preconfigured relationship with the Mapping Service, \u00a0 which includes some sort of shared key and an ACL on the Mapping \u00a0 Service which tells it which EIDs anm ETR can advertise. How \u00a0 this gets established is out of scope of this discussion. Note that neither of these assumptions would be reasonable in an Internet scale system, but I'm assuming that the text about that in these documents will be removed. Because it's not in the document set before us, nor is it a normative reference, I am disregarding LISP-SEC and only analyzing the system as specified in these documents. THREAT MODEL I'm assuming the usual  RFC 3552  threat model, I.e., - All non-Map Server elements in the system (specifically, endpoints \u00a0 and the xTRs are potentially malicious). \u00a0  - Aside from the links between the Map Server elements, the network \u00a0 is controlled by the attacker. Against this background, my expectation is that the attacker should not be able to affect traffic in any fashion significantly more effective than tampering with the data plane. For instance, it's clearly the case that an on-path attacker between two xTRs can drop all the packets or forward them to some third xTR, but it should not be able to send a small number of packets which would then affect the routing of a large number of packets. I do not expect that the data plane should have better security than native (non-IPsec) traffic. Given the nature of LISP and the existence of a mapping system, it seems like it's kind of a missed opportunity to deploy a credentials system that would support IPsec-style data plane security, but given that this isn't a generally safe assumption for IP traffic, and therefore you need to provide some sort of transport or application security anyway, I don't think it's the right standard to hold LISP to. ATTACKS LISP appears to be vulnerable to a number of routing attacks that I claim above it should not be subject to. For example: 1. An on-path attacker can forge Map Replys to the ITR, \u00a0  thus redirecting traffic. 2. An ETR can perform an \"overclaiming\" attack in which it \u00a0  claims to be responsible for EIDs which it is not actually \u00a0  responsible for. 3. An off-path attacker can temporarily reroute traffic by exploiting \u00a0  the \"gleaning\" feature to cache poison an ITR. In addition, the \u00a0  \"echo noncing\" feature does not appear to have a sufficiently strong \u00a0  nonce to protect against forgery, and thus turning this into a \u00a0  long-term attack 4. An attacker may be able to perform a number of cache invalidation \u00a0  and contamination attacks by exploiting the Map-Version and \u00a0  Locator-Status bits. This may lead to DoS. 5. An attacker who was at time T responsible for an EID block \u00a0  can probably prolong its ability to respond for that block \u00a0  even after it is no longer responsible. \u00a0  6. A number of the components appear to be subject to various replay \u00a0  attacks. I note that many of these attacks are documented in the Security Considerations for these documents. Also, I doubt this list is exhaustive. As noted above, I have spent no time on the data plane protocol. DEFENSES When looking at attacks, it's important to determine whether there are plausible defenses. For most of these, I believe that the answer is \"yes\", at varying levels of cost. As noted above, LISP-SEC appears to be intended to address a number of these issues, so it's possible that requiring LISP-SEC would go a fair ways towards addressing these issues. A cursory look at LISP-SEC turns up some somewhat concerning design choices, so I would have to examine it more closely to give a real opinion. I do not believe that LISP-SEC will address the attacks that do not involve the Mapping Server. For instance, the gleaning contamination/nonce attacks (3) would not appear to be fixed by LISP-SEC. However, it's probably possible to fix them by lengthening the nonce. With that said, I tend to think that the overall authentication architecture here would benefit from a rethink. At a high level, the source of most of these problems is the \"non-transferability\" of the mapping information from the Map Server. If the Map Server instead had an asymmetric key pair which it used to sign mappings, then almost all of these attacks would not work. Specifically: - The map server could send signed Map Replys so forgery wouldn't work - Map Replys from ETRs would be signed, so you couldn't overclaim - Gleaning attacks would sort of work, but because the probe would \u00a0 elicit a Map Reply, you couldn't persist them - Map Versions could be tied to signed objects, so you couldn't do \u00a0 cache invalidation by version. You'd probably need some other \u00a0 approach for Locator Status bits. And so on. Detailed review below, with some duplication.... Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D4115 IMPORTANT S 5.2. >\u00a0 \u00a0 \u00a0 s: This is the SMR-invoked bit.\u00a0 This bit is set to 1 when an xTR is >\u00a0 \u00a0 \u00a0 \u00a0  sending a Map-Request in response to a received SMR-based Map- >\u00a0 \u00a0 \u00a0 \u00a0  Request. >\u00a0   >\u00a0 \u00a0 \u00a0 m: This is the LISP mobile-node m-bit.\u00a0 This bit is set by xTRs that >\u00a0 \u00a0 \u00a0 \u00a0  operate as a mobile node as defined in [ I-D.ietf-lisp-mn ]. This would appear to create a normative reference to this document. To avoid that, you need to specify how I behave if I receive it but I don't implement lisp-mn. S 5.2. >\u00a0 \u00a0 \u00a0 m: This is the LISP mobile-node m-bit.\u00a0 This bit is set by xTRs that >\u00a0 \u00a0 \u00a0 \u00a0  operate as a mobile node as defined in [ I-D.ietf-lisp-mn ]. >\u00a0   >\u00a0 \u00a0 \u00a0 I: This is the xTR-ID bit.\u00a0 When this bit is set, what is appended to >\u00a0 \u00a0 \u00a0 \u00a0  the Map-Request is a 128-bit xTR router-ID.\u00a0 See LISP PubSub usage >\u00a0 \u00a0 \u00a0 \u00a0  procedures in [ I-D.ietf-lisp-pubsub ] for details. here too you seem to be creating a normative reference. S 5.5. >\u00a0 \u00a0 \u00a0 \u00a0  is being mapped from a multicast destination EID. >\u00a0   >\u00a0  5.5.\u00a0 EID-to-RLOC UDP Map-Reply Message >\u00a0   >\u00a0 \u00a0 \u00a0 A Map-Reply returns an EID-Prefix with a prefix length that is less >\u00a0 \u00a0 \u00a0 than or equal to the EID being requested.\u00a0 The EID being requested is How do I behave if I receive an EID-Prefix that is less than any of my mappings. So, I might have mappings for 10.1.0.0/16 and 10.2.0.0/16 and someone asks me for 10.0.0.0/8? Also, when you talk about prefix length, I assume you mean the length fo the mask? S 5.6. >\u00a0 \u00a0 \u00a0 Authentication Data:\u00a0 This is the message digest used from the output >\u00a0 \u00a0 \u00a0 \u00a0  of the MAC algorithm.\u00a0 The entire Map-Register payload is >\u00a0 \u00a0 \u00a0 \u00a0  authenticated with this field preset to 0.\u00a0 After the MAC is >\u00a0 \u00a0 \u00a0 \u00a0  computed, it is placed in this field.\u00a0 Implementations of this >\u00a0 \u00a0 \u00a0 \u00a0  specification MUST include support for HMAC-SHA-1-96 [ RFC2404 ], >\u00a0 \u00a0 \u00a0 \u00a0  and support for HMAC-SHA-256-128 [ RFC4868 ] is RECOMMENDED. What prevents replay attacks here? I'm guessing it's the Map-Version- Number, but as I understand it, I can set this to 0. S 6.1. >\u00a0 \u00a0 \u00a0 receives an SMR-based Map-Request and the source is not in the >\u00a0 \u00a0 \u00a0 Locator-Set for the stored Map-Cache entry, then the responding Map- >\u00a0 \u00a0 \u00a0 Request MUST be sent with an EID destination to the mapping database >\u00a0 \u00a0 \u00a0 system.\u00a0 Since the mapping database system is a more secure way to >\u00a0 \u00a0 \u00a0 reach an authoritative ETR, it will deliver the Map-Request to the >\u00a0 \u00a0 \u00a0 authoritative source of the mapping data. If I'm understanding this correctly, this allows an ETR to prevent an ITR from learning that it is no longer the appropriate ETR for a prefix. The way this attack works is that before the topology shift, I send SMRs, thus causing Map-Requests, which, because my entry is cached, refresh the cache on the ITR past the topology shift. I can keep doing this indefinitely. Am I missing something S 8.2. >\u00a0 \u00a0 \u00a0 authentication data, so prior to sending a Map-Register message, the >\u00a0 \u00a0 \u00a0 ETR and Map-Server SHOULD be configured with a shared secret or other >\u00a0 \u00a0 \u00a0 relevant authentication information.\u00a0 A Map-Server's configuration >\u00a0 \u00a0 \u00a0 SHOULD also include a list of the EID-Prefixes for which each ETR is >\u00a0 \u00a0 \u00a0 authoritative.\u00a0 Upon receipt of a Map-Register from an ETR, a Map- >\u00a0 \u00a0 \u00a0 Server accepts only EID-Prefixes that are configured for that ETR. How does it know?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-11-06 13:29:59-08:00",
    "end_reason": "position_updated",
    "start": "2020-07-09 01:19:28-07:00",
    "text": "[ __all__ ] * Is there somewhere a broad prohibition for all IPv6 EID addresses and IPv6 \u00a0 EID prefixes that they MUST NOT be IPv6 link-local addresses? \u00a0 Related: are there any use cases for an IPv6 link-local RLOC?\u00a0 Perhaps in \u00a0 some IXP scenarios? [ section 5.5 ] * Are these example prefixes correct?\u00a0 2001:db8::/16 is really just 2001::/16, \u00a0 right? Similarly, I think /24 should be /48 and /32 should be /64, yes? \u00a0 I feel like I must be misunderstanding something important...",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-10-28 09:03:30-07:00",
    "end_reason": "discuss_updated",
    "start": "2020-07-06 15:51:22-07:00",
    "text": "Two issues rise to DISCUSS level, IMO: Sec 5.7. Is the intent that the Map-Notifies are only retransmitted if they are unsolicited? If not, repeated Map-Registers could result in a storm of Map-Notifies. Sec 7.1. I very well may have missed something, but it doesn't look like the Map-Request is authenticated. So how can the ETR safely update its Map Cache based on the information in the Map-Reply?",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2020-11-24 15:24:43-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-28 09:03:30-07:00",
    "text": "Two issues rise to DISCUSS level, IMO: Sec 5.7. Is the intent that the Map-Notifies are only retransmitted if they are unsolicited? If not, repeated Map-Registers could result in a storm of Map-Notifies. Thanks for addressing the second DISCUSS.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2018-09-11 08:01:43-07:00",
    "text": "1) Versioning and backward compatibility Section 5.2 says: \"Support for requesting multiple EIDs in a single Map-Request \u00a0 \u00a0 \u00a0 message will be specified in a future version of the protocol.\" However, there is no versioning mechanism for this protocol specified. How is versioning supposed to work? Further given there is no new version, I wonder if the changes as outlined in section 10 are all backward-compatible? Especially for the introduction of the Message-Notify-Ack message, I guess there is no problem if a server sends it, however, as the sender of the Message-Notify message might not know if the other end supports sending of the Message-Notify-Ack it can't rely on it. This should be further discussed in the doc! Or is there another strategy to achieve backward compatibility? 2) Size and MTU As outlined in the TSV-ART review (Thanks Colin!) this document does not discuss fragmentation or Path MTU discovery.  RFC8085  recommends to either perform Path MTU discovery or limit the message to 576 bytes for IPv4 or 1280 bytes for IPv6 (minus any static header). As this seems to be an appropriate size for LISP messages, I would recommend this approach. Relying on IP fragmentation (as indicated in the reply to the TSV-ART review) is not recommended by  RFC8085  as this would lead to IP packet without a UDP header, in the case of LISP, which can cause problem and loss when NATs are involved. In any case the chosen approach needs to be further discussed in the doc. 3) Rate-limiting and congestion control Sec 5.3: \"Map-Requests MUST be rate-limited.\u00a0 It is RECOMMENDED that a Map- \u00a0  Request for the same EID-Prefix be sent no more than once per second.\" As already noted by the TSV-ART review (Thanks Colin!),  RFC8085  actually recommends to not send more the one packet per 3 seconds, and that is a restriction for all traffic not on a per-receiver base, or implement congestion control. This limit is meant to not only protect the receiver but also the network from overloading. Why do you use a smaller interval here? Also if (appropriate) rate limiting is used, this should either be a MUST or more explanation when it is okay to use a smaller rate limit should be provided. However, after all, I don't think you those the right approach here for rate limiting. A Map-Request is always expected to be followed by some reply. For these kind of communication pattern,  RFC8085  recommends to limit the number of outstanding requests to 1 (see sec 3.1.1 of  RFC8085  recommending one packet per RTT), also for all traffic and not only per receiver. However, this would also require to implement some simple mechanism to detect a message as lost (see also further below in point 4). Similarly I'm not sure about the intent of this requirement in section 5.5: \"Map-Replies SHOULD be sent for an EID-Prefix no more often than once \u00a0  per second to the same requesting router. \" My understanding is that Replies are only sent when a request is received. Why is this additional rate limit needed? Again if used it should be 3 seconds for all traffic to be inline with  RFC8085 . Also again, why is that not a MUST? Further recommendation are needed here. Further section 6.1 say \"Both the SMR sender and the Map-Request responder MUST rate-limit \u00a0  these messages.\u00a0 Rate-limiting can be implemented as a global rate- \u00a0  limiter or one rate-limiter per SMR destination.\" This seems to be the same rate limit as mention above, or not...? It would probably make sense to rate limit the SMR even further. Please clarify and provide more guidance, e.g. what should the value of a potential additional rate limit for SMR be? Respectively the following sentence in section 6.1 is also unclear: \"The remote ITR MUST rate-limit the Map-Request until it gets a Map-Reply\" Why is the rate-limit as currently proposed depend on the fact if a Map-Reply is received? Is the ITR supposed to retransmit the Map-Request...?  And finally the Map-Register, Map-Notify and Map-Notify-Ack messages does not seem to have any rate-limits. Recommendations inline with  RFC8085  should be provided for the total traffic and not only for a few message types. Again, Map-Notify and Map-Notify-Ack messages should be send only once per RTT as there is a feedback mechanism. For Map-Register sec 8.2 say: \"Map-Register messages are sent periodically from an ETR to a Map- \u00a0  Server with a suggested interval between messages of one minute.\" However, this a rather a low bound than an upper bound. A required (MUST) rate limit is still needed. 4) Loss detection and retransmission As also mention by the TSV-ART review (Once more thanks to Colin!), this spec has an ACK mechanism for Map-Requests and now also for Map-Notify, however, it does not specify what to do if the ACK is not received (loss detection and retransmission scheduling). This makes the spec incomplete and needs to be further specified in the doc (and also has a relation to the point 3 above of course).",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-09-18 06:38:23-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-07 20:04:32-07:00",
    "text": "** The applicability statement in Section 1.1. notes that this will be used on the \u201cpublic Internet\u201d.\u00a0 Therefore, I think we need to consider the use of \u201csecure defaults\u201d.\u00a0 Making lisp-sec and a strong MAC-KDF mandatory to implement is helpful.\u00a0 However, it\u2019s use must also be normatively specified.\u00a0 Specifically, stronger guidance needs to be given when communicating over the public Internet.\u00a0 My thinking would be something like: -- lisp-sec SHOULD (MUST?) be used in for Map-Reply, Map-Notify, Map-Notify-Ack and ECM (i.e. SHOULD/MUST set S=1) -- Map-Register SHOULD (MUST?) use HMAC-SHA256-128+HKDF-SHA256 -- MUST NOT use Algorithm ID = 0 and 1",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-04-16 12:57:36-07:00",
    "end_reason": "discuss_updated",
    "start": "2018-04-16 10:38:17-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3382 DETAIL >\u00a0 \u00a0 \u00a0 When an offerer generates an offer, in which it wants to add a new >\u00a0 \u00a0 \u00a0 bundled \"m=\" section, the offerer MUST: >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 Assign the offerer BUNDLE address:port (previously selected >\u00a0 \u00a0 \u00a0 \u00a0  [Section 8.3.1] or newly suggested [Section 8.5.1]) to the added >\u00a0 \u00a0 \u00a0 \u00a0  \"m=\" section; or IMPORTANT: This doesn't sound right. You can't use the existing address:port, because if the peer rejects BUNDLE but accepts the m= section then it's broken. >\u00a0 \u00a0 \u00a0 o\u00a0 When the BUNDLE transport has been established, ICE connectivity >\u00a0 \u00a0 \u00a0 \u00a0  checks and keep-alives only need to be performed for the BUNDLE >\u00a0 \u00a0 \u00a0 \u00a0  transport, instead of per individual \"m=\" section within the >\u00a0 \u00a0 \u00a0 \u00a0  BUNDLE group. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 In an offer, if the offer assigns a unique address:port to one or IMPORTANT: This does not define how to interact with trickle ICE.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Rescorla",
    "end": "2018-05-19 13:18:20-07:00",
    "end_reason": "position_updated",
    "start": "2018-04-16 12:57:36-07:00",
    "text": "Rich version of this review at: https://mozphab-ietf.devsvcdev.mozaws.net/D3382 DETAIL >\u00a0 \u00a0 \u00a0 When an offerer generates an offer, in which it wants to add a new >\u00a0 \u00a0 \u00a0 bundled \"m=\" section, the offerer MUST: >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 Assign the offerer BUNDLE address:port (previously selected >\u00a0 \u00a0 \u00a0 \u00a0  [Section 8.3.1] or newly suggested [Section 8.5.1]) to the added >\u00a0 \u00a0 \u00a0 \u00a0  \"m=\" section; or IMPORTANT: This doesn't sound right. You can't use the existing address:port, because if the peer rejects BUNDLE but accepts the m= section then it's broken. >\u00a0 \u00a0 \u00a0 o\u00a0 When the BUNDLE transport has been established, ICE connectivity >\u00a0 \u00a0 \u00a0 \u00a0  checks and keep-alives only need to be performed for the BUNDLE >\u00a0 \u00a0 \u00a0 \u00a0  transport, instead of per individual \"m=\" section within the >\u00a0 \u00a0 \u00a0 \u00a0  BUNDLE group. >\u00a0   >\u00a0 \u00a0 \u00a0 o\u00a0 In an offer, if the offer assigns a unique address:port to one or IMPORTANT: This does not define how to interact with trickle ICE.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-02-01 23:52:48-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-01 03:00:09-08:00",
    "text": "Thank you for the work put into this document.  Please find below one blocking DISCUSS points (probably easy to address as I am not a YANG expert), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Please also have a look at Ted Lemon's INT directorate review at . I share Ted's concern about have three independent topics in a single document rather than in 3 documents. Special thanks to Valery Smyslov for the shepherd's write-up including the section about the WG consensus even if I had appreciated a justification for the PS status.  I hope that this helps to improve the document, Regards, -\u00e9ric ## Section 8.1.5 (and others) Please note that I am not a YANG expert, but it seems to me that \"attack-detail* [vendor-id attack-id]\" indicates that vendor-id & attack-id are the keys to attack-detail, i.e., there can only have one attack-detail per pair of vendor-id & attack-id. So, there is no way to have multiple sequential/simultaneous attacks, i.e., should the start-time be also part of the key? As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-03 01:54:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-01 04:30:41-08:00",
    "text": "Thank you for the work on this document, which I found particularly well written and easy to read despite its length. Many thanks to James Gruessing for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/MbTX3xfg6tMeG6mieAsT7hA3gXs/ , and to the authors for addressing James' comments.  I have an easy to fix DISCUSS concerning the examples, and a point about a MUST which should not be there IMO. I also have a number of comments and question that I hope will help improving the document (or my understanding of it). I support Roman's DISCUSS, see  https://trac.ietf.org/trac/art/wiki/TypicalARTAreaIssues#LanguageTags . To answer Ben's note - IMO the text about \"enterprise numbers\" and \"Private Enterprise Numbers\" is clear enough. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- \u00a0  JSON encoding of YANG-modeled data is used to illustrate the various \u00a0  telemetry operations. FP: There is an inconsistency between this text and the use of \"application/dots+cbor\" in the examples. Either the Content-Format should be changed, or all the examples should be adapted to JSON Content-Format (I am not sure about what Content-Format you should use then, you probably know better). My preference is to keep CBOR and keep the Content-Format. I went through all the examples and reported below the inconsistencies. Section 7.1.2, Figure 4, 5, FP: If in CBOR, the percentiles should be expressed with the tagged item Decimal fraction (represented as a tagged array). 2. ----- Section 7.2.1, Figure 11, 13, 15, 17 FP: Same comment as 1: unit and peak-g should be unsigned in CBOR. 3. ----- Section 7.3.1, Figure 19, 20 FP: Same comment as 1: capacity and unit should be unsigned in CBOR. 4. ----- Section 7.2.1, Figure 11, 13, 15, 17 FP: Same comment as 1: unit and peak-g should be unsigned in CBOR. 5. ----- Section 7.3.1, Figure 19, 20 FP: Same comment as 1: capacity and unit should be unsigned in CBOR. 6. ----- Figure 36, figure 43 FP: Same comment as 1: unit, mid-percentile-g, start-time and attack-severity should be unsigned in CBOR. 7. ----- Figure 45, 47 FP: attack-status, unit, mid-percentile-g, peak-g should be unsigned. I also note that some of the attributes defined in 9132 are used here and on previous examples and have for values the full spelled out meaning for readability, instead of the actual parameter (for example \"status\", that should have value 2 for \"attack-successfully-mitigated\"), and I think that should be at least noted in the text before the example, or if you want to be more precise the \"attack-successfully-mitigated\" could be a comment next to the value 2. 8. ----- Section 7.1.3 \u00a0  client, it MUST respond with a 4.04 (Not Found) error Response Code. FP: I have a preference to remove this MUST here - it is expected behavior that if a resource is not present the server responds with 4.04, so it is not necessary to add the requirement here, actually redefining the response code (although it is the expected one in this case) should be discouraged. I suggest replacing: s/it MUST respond/it responds. (Note that 7.1.4 has the text I would expect, describing the behavior but not adding any already existing requirements).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-02-03 07:26:06-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 01:54:20-08:00",
    "text": "Thank you for the work on this document, which I found particularly well written and easy to read despite its length. Many thanks to James Gruessing for the ART ART review:  https://mailarchive.ietf.org/arch/msg/art/MbTX3xfg6tMeG6mieAsT7hA3gXs/ , and to the authors for addressing James' comments.  To answer Ben's note - IMO the text about \"enterprise numbers\" and \"Private Enterprise Numbers\" is clear enough. I will keep this DISCUSS as a placeholder to discuss my concerns with the responsible AD during the telechat, but expect to remove it afterward, given that the additions in v-21 mostly address 1-7 and 8 has precedent for it in 9132. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-02-03 06:56:39-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-03 01:58:24-08:00",
    "text": "The protocol uses traffic capacities in various ways (for pipe, baseline and connection capacity, etc.) but doesn't indicate at what layer these capacities are to be interpreted? L2? L3? (L1??) Would the difference in header overhead cause issues when senders and receivers use different interpretations here?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-03 07:06:34-08:00",
    "end_reason": "position_updated",
    "start": "2022-01-31 12:37:57-08:00",
    "text": "** Sections 8.1.5 and 9.1. These sections describe a human readable text field, \u201cattack-description\u201d.\u00a0 Per Section 4.2 of  BCP 18 , \u201c[p]rotocols that transfer text MUST provide for carrying information about the language of that text.\u201d.\u00a0 Practically, can a field to list a language tag field ( RFC 5646  and  https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry ) be added in all places that \u201cattack-description\u201d is defined or at the top level?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-02-02 11:10:37-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-02 08:59:43-08:00",
    "text": "Please note: This really is just a DISCUSSion - I'm happy to be educated / wrong, but I do think that it is important enough that it gets addressed. The 'unit-class' and 'unit' enumerations seems like they add a large amount of complexity for (AFAICT) very little gain.  Do you really need: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Packets per second (pps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Bits per Second (bps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Bytes per second (Bps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Kilo packets per second (kpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Kilobits per second (kbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Kilobytes per second (kBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Mega packets per second (Mpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Megabytes per second (MBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Giga packets per second (Gpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Gigabits per second (Gbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Gigabytes per second (GBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Tera packets per second (Tpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Terabits per second (Tbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Terabytes per second (TBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Peta packets per second (Ppps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Petabits per second (Pbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Petabytes per second (PBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Exa packets per second (Epps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Exabits per second (Ebps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Exabytes per second (EBps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Zetta packets per second (Zpps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Zettabits per second (Zbps).\"; \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"Zettabytes per second (ZBps).\" when just Packets Per Second and Bits Per Second would work? Yes, you might have to have a really large number in BPS, but that seems much much less likely to lead to errors than having parsers have to deal with this. When a user enters a number their glass would presumably allow them to use a more convenient unit, but having it encoded and decoded into this seems needlessly complex. I did look through the document and list to try and find discussions on this point - I'm happy to be pointed at a place where it was discussed and agreed.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-06-01 07:05:08-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-30 13:00:58-07:00",
    "text": "Overall the document looks fine, although I wish it had copied less content and depended only on the references cited to avoid accidental errors. I think I checked most of these and they seem fine, but it is possible authors/reviewers up to now have made a mistake. My only DISCUSS item is on recommending PBKDF2. It is kind of showing it age, and we have a much better replacement with argon2 ( RFC 9106 ). Is there a reason why not to recommend some argon2 setting instead of PBKDF2 ?",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2015-10-14 14:55:10-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 06:46:27-08:00",
    "text": "The IANA Considerations are a bit confusing, as they appear to ask IANA to do things that were already done long ago.\u00a0 I understand that you want to leave the main text of the IANA Considerations intact, for posterity, and you've put in some \"Editorial note\" things.\u00a0 Maybe the best way to do this is to (1) change \"Editorial note\" to \"IANA note\" or \"Note to IANA\" throughout, (2) change the first IANA note (in the base Section 15) to clearly state that all *changes* that IANA is being asked to make are spelled out in \"IANA note\" items in the appropriate places, and (3) make sure that item 2 is true.\u00a0 And you do need to respond to Pearl Liang's IANA review from 2 March, and answer her questions.",
    "type": "Discuss"
  },
  {
    "ad": "Jari Arkko",
    "end": "2015-09-23 10:17:43-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 04:01:33-08:00",
    "text": "Thanks for the hard work on this protocol. I have some comments, based on a review by Suresh Krishnan, that I think should be addressed before final approval of the document. First, Section 5.1 should be clear that when used over a reliable transport, not only should the F flag be ignore but that the fragment fields (last four bytes) are not in the packet. Second, Section 6.2.3 should be clear that the header accompanies all fragments. As a result, the current formula for calculating the number of fragments is probably wrong. This too should be updated.",
    "type": "Discuss"
  },
  {
    "ad": "Kathleen Moriarty",
    "end": "2015-10-15 06:51:57-07:00",
    "end_reason": "position_updated",
    "start": "2015-03-05 07:21:58-08:00",
    "text": "Thanks for your work on this draft, it was very well written which is much appreciated. I just have one item I'd like to discuss that should be very easy to resolve.\u00a0  This should be considered with Spencer's question on what happens when the fragments are larger or smaller than the path MTU.\u00a0 It's important to state this to prevent fragmentation overlap attacks (unless you can explain why we don't need to worry about that). In the second sentence on page 42, adding the ending clause may be helpful: \u00a0 The size of each of these N messages MUST be \u00a0  smaller than the path MTU to help prevent fragmentation overlap attacks.",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-11-04 18:28:20-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-03-04 20:38:19-08:00",
    "text": "For the moment, I'm balloting a process Discuss, because I'm not seeing a response to Gorry Fairhurst's TSV-DIR review sent on March 2, at  https://www.ietf.org/mail-archive/web/ietf/current/msg92156.html . Did I miss it? During my review, I did not see a definition of \"transaction failure window\". I can guess what that means, but would love to know for sure. I'm understanding that in  RFC 4582 , the version number (1) was a version number, but in this draft, version 1 means \"reliable transport\" and version 2 means \"unreliable transport\". Is that right? If so, how does an  RFC 4582  TCP-only floor control server receive a message with a version field set to 2, which would have been sent over UDP? I'm also wondering whether overloading the version number field as a transport reliability indicator would cause a problem in the future. If you end up with a mandatory extension that applies to both reliable and unreliable transport, does that mean you'd use two version numbers (possibly 2 for reliable and 3 for unreliable)? Within Gorry's review, these are the points I thought were Discuss-worthy. It's probably best for you to reply to these in his e-mail, rather than try to juggle two sets of overlapping comments. I'm just pointing out what I think matters most. On the others, please do the right thing. - Gorry asked in Section 5: What is the security model when TLS/DTLS is not used? - has the protocol protection from off-path attacks, and how is this provided? I'm especially interested in this question when unreliable transport is used without DTLS. This is probably related to the question about randomizing Conference ID later in Gorry's review. -  Payload Length: - What happens when using a datagram format if the datagram length (e.g. UDP-Length) is less or more than the value specified within the BFCP? - Fragment Length: - What happens if the datagram length (e.g. UDP-Length) is less or more than the value specified within the BFCP?",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-11-04 18:30:50-08:00",
    "end_reason": "discuss_updated",
    "start": "2015-11-04 18:28:20-08:00",
    "text": "Thanks for working through my Discuss and Comments on -13. I'm mostly good (at the Discuss level), but have one remaining concern, on section 14.\u00a0 Security Considerations \u00a0  BFCP uses TLS/DTLS to provide mutual authentication between clients \u00a0  and servers.\u00a0 TLS/DTLS also provides replay and integrity protection \u00a0  and confidentiality.\u00a0 It is RECOMMENDED that TLS/DTLS with an \u00a0  encryption algorithm according to Section 7 always be used.\u00a0 In cases \u00a0  where signaling/control traffic is properly protected, as described \u00a0  in Section 9 it is REQUIRED to use a mandated encryption algorithm. \u00a0  BFCP entities MAY use other security mechanisms as long as they \u00a0  provide similar security properties. \u00a0   If I'm reading this text correctly (please correct me if I'm misunderstanding), it is still allowed to run BFCP over TCP/UDP without TLS/DTLS.  If you run a protocol over TCP without TLS, you're still vulnerable to on-path attackers, but off-path attackers have to insert attack packets with sequence numbers that are within the current window. That's not impossible, but it's not easy. So, I'm not happy that TLS isn't required when you run BFCP over TCP, but OK, fine. If you run a protocol over UDP without DTLS, off-path attackers don't have this constraint, so inserting attack packets off-path is much easier. That makes BFCP much more vulnerable to attack over UDP than it was over TCP.  Is that really OK? That seems quite odd to me, when said without a clear warning that if you do not use DTLS (or equivalent) security mechanisms the protocol is vulnerable to various attacks. I\u2019d have preferred section 7 to have said \u201cSHOULD use TLS or DTLS\u201d and then have gone on to explain - \u201creasons for not using DLTS include ... but when TLS or DTLS is not used the protocol becomes vulnerable to security attacks (e.g. ...).\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Spencer Dawkins",
    "end": "2015-11-13 13:17:04-08:00",
    "end_reason": "position_updated",
    "start": "2015-11-04 18:30:50-08:00",
    "text": "Thanks for working through my Discuss and Comments on -13. I'm mostly good (at the Discuss level), but have one remaining concern, on section 14.\u00a0 Security Considerations \u00a0  BFCP uses TLS/DTLS to provide mutual authentication between clients \u00a0  and servers.\u00a0 TLS/DTLS also provides replay and integrity protection \u00a0  and confidentiality.\u00a0 It is RECOMMENDED that TLS/DTLS with an \u00a0  encryption algorithm according to Section 7 always be used.\u00a0 In cases \u00a0  where signaling/control traffic is properly protected, as described \u00a0  in Section 9 it is REQUIRED to use a mandated encryption algorithm. \u00a0  BFCP entities MAY use other security mechanisms as long as they \u00a0  provide similar security properties. \u00a0   If I'm reading this text correctly (please correct me if I'm misunderstanding), it is still allowed to run BFCP over TCP/UDP without TLS/DTLS.  If you run a protocol over TCP without TLS, you're still vulnerable to on-path attackers, but off-path attackers have to insert attack packets with sequence numbers that are within the current window. That's not impossible, but it's not easy. So, I'm not happy that TLS isn't required when you run BFCP over TCP, but OK, fine. If you run a protocol over UDP without DTLS, off-path attackers don't have this constraint, so inserting attack packets off-path is much easier. That makes BFCP much more vulnerable to attack over UDP than it was over TCP.  Is that really OK? That seems quite odd to me, when said without a clear warning that if you do not use DTLS (or equivalent) security mechanisms the protocol is vulnerable to various attacks. I\u2019d have preferred section 7 to have said \u201cSHOULD use TLS or DTLS\u201d and then have gone on to explain - \u201creasons for not using DTLS include ... but when TLS or DTLS is not used the protocol becomes vulnerable to security attacks (e.g. ...).\u201d",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-08-05 09:25:55-07:00",
    "end_reason": "position_updated",
    "start": "2022-05-09 15:31:45-07:00",
    "text": "** Section 5.4.\u00a0  \u00a0  Ads may be inserted either with Client Side Ad Insertion (CSAI) or \u00a0  Server Side Ad Insertion (SSAI).\u00a0 In CSAI, the ABR manifest will \u00a0  generally include links to an external ad server for some segments of \u00a0  the media stream, while in SSAI the server will remain the same \u00a0  during advertisements, but will include media segments that contain \u00a0  the advertising.\u00a0 In SSAI, the media segments may or may not be \u00a0  sourced from an external ad server like with CSAI. \u00a0  \u00a0 \u00a0 \u00a0 \u00a0  \u2026 \u00a0  As a \u00a0  mitigation for concerns driven by those incidents, some SSPs have \u00a0  required the use of players with features like reporting of ad \u00a0  delivery, or providing information that can be used for user \u00a0  tracking.\u00a0 Some of these and other measures have raised privacy \u00a0  concerns for end users. Thanks for starting the discussion about privacy.\u00a0 The framing doesn\u2019t seem completely accurate.\u00a0 Whether there is ad fraud or not, user data of some kind is being sent off to ad exchanges (it\u2019s the basis of the bidding process), and network level tracking is being facilitated through connects to CSAIs.\u00a0 Please provide some editorial construct to suggest that practically any kind of targeted ads are going to entail some trade in privacy, and explain the risks specifically or with a reference.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-06-30 13:35:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-09 17:45:47-07:00",
    "text": "There seems to be an internal inconsistency about whether, when the API URL is available in a given network via multiple mechanisms, the URLs provided by the different mechanisms must be \"identical\" (Section 3) or merely \"equivalent\" (Section 2).\u00a0 I think we need to be consistent in the requirement, as it is possible for URLs to be equivalent but not identical just by virtue of mundane encoding tricks, even without getting to the question of semantic equivalence of pointed-to resources.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-06-25 00:57:25-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-11 06:54:46-07:00",
    "text": "IANA Section: As this document is obsoleting  RFC 7710  is the document that registered the options for DHCPv6 and RA. Why isn't this document updating the registrations to ensure that IANA has the current document as being owner of the codepoints?  In addition when it comes to BOOTP options code 160. What you have in this document appear to potentially lead to another future assignment end up in trouble? Wouldn't reserved be better status for this codepoint?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2022-03-17 10:42:41-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-15 09:58:55-08:00",
    "text": "I am balloting DISCUSS because the document underspecifies the use of Endpoint Behaviors. As a result, it is unclear when they should be checked, enforced,  or needed. Details follow. The descriptions of the TLVs in \u00a72 say (twice) that the \"SRv6 Endpoint  behaviors which MAY be encoded, but not limited to, are...etc.\" \u00a0  The text above ends with \"etc.\" which means there are other possible  \u00a0  behaviors. That's not a great use of normative language, even if optional.  \u00a0  My initial instinct was to ask you to be specific, BUT... \u00a0  The description of the SRv6 SID Information Sub-TLV (\u00a73.1) says that \"an \u00a0  unrecognized endpoint behavior MUST NOT be considered invalid\", which seems \u00a0  to mean that any behavior is ok, AND... \u00a0  There's no validation specified, except for the description of the SRv6 SID \u00a0  Structure Sub-Sub-TLV (\u00a73.2.1), where it says that the \"Argument length  \u00a0  MUST be set to 0 for SIDs where the Argument is not applicable\". AND... \u00a0  Several of the service descriptions in \u00a75/\u00a76 say that \"The SRv6 Endpoint \u00a0  behavior of the SRv6 SID is entirely up to the originator of the \u00a0  advertisement. In practice, the SRv6 Endpoint behavior is...\" The result is that any endpoint behavior (even unrecognized) can be used,  while also requiring a specific setting for the argument length in some cases. How can the argument length be validated if the endpoint behavior is unknown? Clearly (from looking at  rfc8986 ), not all endpoint behaviors apply to the services defined in this document. Should a receiver accept any endpoint behavior? What should a receiver do if a known but unrelated behavior (End,  for example) is received? What should the receiver do if the endpoint behavior is known and applicable, but the attribute length is not set correctly? For any specific service (IPv4 VPN Over SRv6 Core, for example, to pick one), should the behaviors used \"in practice\" be enforced? What if different behavior is advertised? Can it safely be ignored? Why is the Endpoint Behavior included in the Sub-TLV if (from the above) it looks like it doesn't matter?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-02-10 14:18:58-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-07 13:46:28-08:00",
    "text": "Thank you for the work put into this document. This protocol is important for scalable and deployable SRv6 services. Please find below some blocking DISCUSS points (easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education). Special thanks to Matthew Bocci for the shepherd's write-up including the section about the WG consensus and document history.  Please also expect an INT directorate review before the IESG telechat (I may update this ballot accordingly). I hope that this helps to improve the document, Regards, -\u00e9ric # DISCUSS As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion on the following topics: ## Section 3.1 \"IANA registry defined in section 9.2 of [ RFC8986 ]\" but there is no section 9.2 in  RFC 8986 . I guess it is section 10.2. Moreover, IANA registries are usually referred to via their name/URL, e.g.,  https://www.iana.org/assignments/segment-routing/segment-routing.xhtml , and not by a section of the RFC that created them. ## Section 3.2.1 Where is \"locator node\" defined ? \"locator block\" is defined in section 3.1 of  RFC 8986  but not the node (I can only guess that this is the \"N\" in the \"B:N\" notation used in  RFC 8986 ). ## Section 6 Section 9 of  draft-ietf-bess-evpn-igmp-mld-proxy-16  indeed defines route types 7 and 8 but it uses non IPv4-only wording. So, s/IGMP join sync route/Multicast Membership Report Synch Route/ + same for type 8.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2022-03-21 21:20:12-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 22:03:05-08:00",
    "text": "I have little to add to the DISCUSSes held by others beyond my support. However, I would like to discuss having SRv6 control plane information, i.e. SIDs and their behaviours etc., being isolated by associating it with a separate SAFI.\u00a0 Any other protocol element that needs to refer to such information can make reference to it through context-appropriate extensions. {AFI=IPv6, SAFI=unicast} is a valid way to advertise an SRv6 locator prefix, for example, as that's just IPv6 forwarding information.\u00a0 If SRv6-specific information where separately advertised as {AFI=IPv6, SAFI=SRv6} then I suspect it would be simpler to filter out that information, detect leaks, and generally help the SRv6 domain fail closed more easily. But I'm prepared to learn why this wouldn't work or would be somehow worse.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:34:23-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:33:55-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? \u2028\u2028(An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:34:43-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:34:23-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? \u2028\u2028(An obvious way of addressing this particular concern  (would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:34:57-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:34:43-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? \u2028\u2028(An obvious way of addressing this particular concern  (An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-02-16 13:38:37-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-16 13:34:57-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? (An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) Considering that the disagreement is amongst the authors and not just WG contributors at large, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2022-03-22 16:19:21-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-16 13:38:37-08:00",
    "text": "1. The shepherd writeup for this document says \u201cIt also received an RTG DIR review and cross-reviewed with the IDR working group\u201d. Searching in my IDR inbox and the IDR mailing list archives, I don\u2019t find any sign of the cross-review \u2014 can you please point me to it?\u2028 2. One area of concern I would have hoped IDR might have looked into is, the document makes a creative use of the MPLS Label field of the NLRI to carry the Function part of the SID. This means the SID is effectively split across the NLRI and the Prefix-SID attribute. What are the potential error modes if the Prefix-SID attribute should be lost from the route, while the NLRI is retained? (An obvious way of addressing this particular concern would be to define a new NLRI type with the desired semantics, instead of creatively repurposing fields within an existing NLRI type contrary to their definitions. Such an NLRI type would, for example, presumably state in its specification that if it was received without an accompanying Prefix-SID attribute, that would constitute an error.)\u2028 3. As Warren Kumari points out in his DISCUSS, \u201cleaks happen\u201d. Subsequent discussion turned quickly to the assertion that no, they don\u2019t, in VPN address families. Let\u2019s accept that claim for the sake of conversation. It\u2019s still the case that sometimes (often?) routes are distributed from VPN address families into the Global Internet table. When this is done, by default, all the path attributes come along for the ride. Anyone who thinks this is just a hypothetical case might want to look back to (for example) significant network outages that were caused around a decade ago by leakage of BGP Attribute 128 (ATTR_SET,  RFC 6368 ) into the global Internet.\u2028\u2028 The SIDs contained in these if-they-were-to-leak routes potentially give an attacker a means of directing packets into a VPN customer\u2019s internal network.\u2028 4. Speaking of Warren\u2019s DISCUSS, the shepherd\u2019s writeup indicates \u201csolid [WG] consensus\u201d; however, there doesn\u2019t seem to be consensus even amongst the authors as to whether Sections 5.3 and 5.4 are appropriate. This is a fairly fundamental disagreement! An illustration of the disagreement is  https://mailarchive.ietf.org/arch/msg/bess/K1JKxGn19BXALs3rUzUAaGTZi0Y/: \u2028\u2028 \u201cSo I can see why some people may have thought oh since transport in SRv6 comes for free let's load it with services in an attribute and be done. Yes I can see that flattening this make it potentially easier (one less SAFI to enable), *but I am not sure we have reached a broad agreement here.* This comes as a consequence of moving service prefixes from MP_REACH_NLRI (perhaps new format and new SAFI) to an attribute.\u201d\u2028\u2028 (Emphasis added.) It's of course possible for an author to be in the rough as regards consensus, just as any other WG contributor, but it's a little unusual, and this disagreement doesn't even seem to have been previously aired. For this reason, I have to question the strength of the consensus behind this document, and ask the WG chairs to weigh in regarding whether consensus on at least this point needs to be checked before we proceed forward.\u2028 5. Finally, I have to question the length of the author list. As I\u2019m sure you know, the guidance is to limit author lists to no more than five, other than under unusual circumstances. I would have expected to find an explanation of the circumstances around the author list of this document in the shepherd writeup; there is none. (It\u2019s a specific check item in Guidelines to Authors of Internet-Drafts,  https://www.ietf.org/how/ids/guidelines/ )\u2028\u2028 The easiest way to resolve this would be to trim the author list per the suggestions in  RFC 7322  \u00a74.1.1, of course.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-03-17 19:26:35-07:00",
    "end_reason": "position_updated",
    "start": "2022-02-22 17:32:34-08:00",
    "text": "(3.2.1) \"BGP speakers that do not support this specification may misinterpret, \u00a0  on the reception of an SRv6-based BGP service route update, the part \u00a0  of the SRv6 SID encoded in MPLS label field(s) as MPLS label values \u00a0  for MPLS-based services.\u00a0 Implementations supporting this \u00a0  specification MUST provide a mechanism to control the advertisement \u00a0  of SRv6-based BGP service routes on a per-neighbor and per-service \u00a0  basis.\u00a0 The details of deployment designs and implementation options \u00a0  are outside the scope of this document.\" The idea that BGP hosts are going to be made non-interoperable because you're re-purposing the MPLS label, and so hosts are just going to have to remember who it's OK to exchange this TLV with, sounds unsatisfactory to me. Is there no way to negotiate this? Perhaps the solution John Scudder proposes in his second DISCUSS would solve this problem too: just have a new type for these overloaded MPLS labels.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-02-11 15:03:04-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-02-11 14:55:43-08:00",
    "text": "The Security Considerations section says: \"The service flows between PE routers using SRv6 SIDs advertised via BGP are expected to be limited within the trusted SR domain (e.g., within a single AS or between multiple ASes within a single provider network).\u00a0 Precaution should be taken to ensure that the BGP service information (including associated SRv6 SID) advertised via BGP sessions are limited to peers within this trusted SR domain.\" This is related to (from  RFC8402 ): \"Therefore, by default, the explicit routing information MUST NOT be leaked through the boundaries of the administered domain.\" However, we all know that BGP leaks happen -- and when they do, the SID\u2019s contained in the leak will be logged by various systems and hence available to the public into perpetuity. While the document states that border filtering should protect against traffic injection, this does not cover the case of internal compromise. Sure, there is the argument that once there is an internally compromised system, all bets are off -- but with this, an attacker that knows the SIDs in use can perform injection attacks in addition to routing traffic however they like.  So, not only does an operator have to ensure that BGP leaks never occur, they have to then ensure that at no point can there be any filter lapses at any border node, and be able to guarantee the security of every device, server and machine within the domain in order for a secure posture to be maintained.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-03-07 12:54:53-08:00",
    "end_reason": "position_updated",
    "start": "2022-02-11 15:03:04-08:00",
    "text": "The Security Considerations section says: \"The service flows between PE routers using SRv6 SIDs advertised via BGP are expected to be limited within the trusted SR domain (e.g., within a single AS or between multiple ASes within a single provider network).\u00a0 Precaution should be taken to ensure that the BGP service information (including associated SRv6 SID) advertised via BGP sessions are limited to peers within this trusted SR domain.\" This is related to (from  RFC8402 ): \"Therefore, by default, the explicit routing information MUST NOT be leaked through the boundaries of the administered domain.\" However, we all know that BGP leaks happen -- and when they do, the SID\u2019s contained in the leak will be logged by various systems and hence available to the public into perpetuity. While the document states that border filtering should protect against traffic injection, this does not cover the case of internal compromise. Sure, there is the argument that once there is an internally compromised system, all bets are off -- but with this, an attacker that knows the SIDs in e.g inject traffic into a VPN. This seems to me to significantly expand the attack surface to include the customer's networks too.  Not only does an operator have to ensure that BGP leaks never occur, they have to then ensure that at no point can there be any filter lapses at any border node, and be able to guarantee the security of every device, server and machine within the domain in order for a secure posture to be maintained. Simply saying that precautions should be taken to make sure that route leak don't occur, when the consequences of doing so are a: severe and b: hard to recover from seems to not really cover it. In addition, it seems that the blast radius from a missing ACL seems much larger if it allows injections.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-12-20 16:58:21-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 21:04:23-08:00",
    "text": "These should all be trivial to resolve -- just some minor internal inconsistencies that need to be fixed before publication. The discussion of percentile statistical operator in \u00a72.2 is internally inconsistent -- if the percentile number must be an integer, then p99.9 is not valid. Also, the listing of \"cost-source\" values introduced by this document (in \u00a75.1) does not include \"nominal\", but we do also introduce \"nominal\". Similarly, in \u00a73.1.3 we refer to the \"-\" component of a cost metric string, that has been generalized to an arbitrary statistical operator.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-20 13:42:41-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-20 16:58:21-08:00",
    "text": "Thank you for addressing my previous discuss points with the -21 (and my apologies for the spurious one!); I'm glad to see that they were indeed easy to address. However, I have looked over the changes from -20 to -21 and seem to have found a couple more issues that should be addressed: (1) I can't replicate the Content-Length values in the examples (I only looked at Examples 1 and 2).\u00a0 Can you please share the methodology used to generate the values?\u00a0 My testing involved copy/paste from the htmlized version of the draft to a file, manually editing that file to remove the leading three spaces that come from the formatting of the draft, and using Unix wc(1) on the resulting file.\u00a0 It looks like the numbers reported in the -21 are computed as the overall number of characters in the file *minus* the number of lines in the file, but I think it should be the number of characters *plus* the number of lines, to accommodate the HTTP CRLF line endings.\u00a0 (My local temporary files contain standard Unix LF (0x0a) line endings, verified by hexdump(1).) (2) We seem to be inconsistent about what the \"cur\" statistical operator for the \"bw-utilized\" metric indicates -- in \u00a74.4.3 it is \"the current instantaneous sample\", but in \u00a74.4.4 it is somehow repurposed as \"The current (\"cur\") utilized bandwidth of a path is the maximum of the available bandwidth of all links on the path.\"",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2022-03-04 02:56:46-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-22 03:32:02-08:00",
    "text": "Thank you for the work put into this document. Please bear with my lack of knowledge about ALTO in general. Please find below one trivial blocking DISCUSS points (probably easy to address), some non-blocking COMMENT points (but replies would be appreciated even if only for my own education), and some nits. Special thanks to Jan Seedorf for the shepherd's write-up about the WG consensus (even if not using the usual template). I have appreciated the \"operational considerations\" section as it addresses many questions that popped up during reading the document; notably, how can the ALTO server measure any metric between the ALTO client and a resource. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == -- Section 4.1.3 -- A very trivial DISCUSS to fix: this document relies on  RFC 8312  to specify how TCP throughput is estimated but  RFC 8312  does not appear in the normative reference list (this will probably generate a down ref though).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2021-12-01 14:37:30-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 13:57:01-08:00",
    "text": "Thank you for the work on this document. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. I am holding a DISCUSS to make sure the examples are fixed before publication. Additionally, I agree with Christian that the line \"Content-Length: TBA\" in all the examples is not really helpful to the reader, and I suggest to either remove it or replace TBA with the actual content length for each example. Francesca 1. ----- { \u00a0 \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-metric\":\"hopcount\"} \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0  }, \u00a0 \u00a0 \u00a0 \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.89\"\u00a0  : 5, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:198.51.100.34\": 3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 } FP: JSON doesn't validate. There is one \"}\" too many after \"hopcount\". 2. ----- \u00a0  { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\":\"tput\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\"\u00a0  : 256000, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 128000 \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate. I believe there is 2 errors: after the second \"}\" after \"tput\" there is a missing \",\" , and it is also missing a final \"}\" at the end. 3. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\" { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-residual\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\" { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate - there is a bunch of missing \":\" all over. 4. ----- { \u00a0 \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\"}, \u00a0 \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0  \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0  \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\" 5. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\": { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"ipv4:192.0.2.2\"",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-01-05 10:49:09-08:00",
    "end_reason": "discuss_updated",
    "start": "2021-12-01 14:37:30-08:00",
    "text": "Thank you for the work on this document. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. I am holding a DISCUSS to make sure the examples are fixed before publication. Additionally, I agree with Christian that the line \"Content-Length: TBA\" in all the examples is not really helpful to the reader, and I suggest to either remove it or replace TBA with the actual content length for each example. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- { \u00a0 \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"cost-metric\":\"hopcount\"} \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 } \u00a0 \u00a0 \u00a0  }, \u00a0 \u00a0 \u00a0 \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:192.0.2.89\"\u00a0  : 5, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"ipv4:198.51.100.34\": 3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0 } FP: JSON doesn't validate. There is one \"}\" too many after \"hopcount\". 2. ----- \u00a0  { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0 \u00a0 \"cost type\": { \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\":\"tput\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\": { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\"\u00a0  : 256000, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 128000 \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate. I believe there is 2 errors: after the second \"}\" after \"tput\" there is a missing \",\" , and it is also missing a final \"}\" at the end. 3. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\" { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\": \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-residual\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\" { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate - there is a bunch of missing \":\" all over. 4. ----- { \u00a0 \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\"}, \u00a0 \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0  \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0  \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0  ] \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\" 5. ----- { \u00a0 \u00a0  \"meta\": { \u00a0 \u00a0 \u00a0  \"cost-type\": { \u00a0 \u00a0 \u00a0 \u00a0  \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-maxres\" \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  }, \u00a0 \u00a0  \"endpoint-cost-map\": { \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.2\" { \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\" :\u00a0 \u00a0 0, \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\": 2000 \u00a0 \u00a0 \u00a0  } \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"ipv4:192.0.2.2\"",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-04 00:59:05-08:00",
    "end_reason": "discuss_updated",
    "start": "2022-01-05 10:49:09-08:00",
    "text": "Thank you for the work on this document, and for addressing my previous DISCUSS points. I noticed two additional JSON issue, easy to fix, reported below. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion; I really think that the document would be improved with a change here, but can be convinced otherwise. Francesca 1. ----- Section 4.4.3 \u00a0  { \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-utilized\"}, \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0 \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0 ] \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\". 2. ----- Section 4.3.3. \u00a0  { \u00a0 \u00a0  \"cost-type\" { \"cost-mode\":\u00a0  \"numerical\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"cost-metric\": \"bw-available\"}, \u00a0 \u00a0  \"endpoints\":\u00a0 { \u00a0 \u00a0 \u00a0 \u00a0 \"srcs\": [ \"ipv4 : 192.0.2.2\" ], \u00a0 \u00a0 \u00a0 \u00a0 \"dsts\": [ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:192.0.2.89\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"ipv4:198.51.100.34\" \u00a0 \u00a0 \u00a0 \u00a0 ] \u00a0 \u00a0  } \u00a0  } FP: JSON doesn't validate: missing \":\" after \"cost-type\". (Minor note - is there a reason why the \"srcs\" address has whitespaces while other addresses don't? 3 occurrences in the text).",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-03-04 01:00:03-08:00",
    "end_reason": "position_updated",
    "start": "2022-03-04 00:59:05-08:00",
    "text": "Thank you for the work on this document, and for addressing my previous DISCUSS points. Many thanks to Christian Ams\u00fcss for his review:  https://mailarchive.ietf.org/arch/msg/art/owYhcoFnl1vEipZ2D62cWiiE-LA/  , and thanks to the authors for addressing it. Francesca",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-03-01 08:06:31-08:00",
    "end_reason": "position_updated",
    "start": "2021-11-29 05:09:48-08:00",
    "text": "This document needs to become much more formal about how it defines the metrics it wishes to use with ALTO. This could either be done either by identifying and normatively referencing existing metrics the IETF has defined, or by defining them here. When normatively referencing existing IETF metrics, it would need to explain why their use with ALTO makes sense. At the moment, the document informatively points to a somewhat arbitrary collection of prior IETF metrics (most of which are from IPPM, residual bandwidth from IS-IS TE, but then reservable bandwidth from OSPF TE?). But it only refers to them as \"examples\", without actually defining how exactly they are to be used with ALTO, or - if not those - which actual metrics are supposed to be used. Defining a mechanism for exposing metric information to clients isn't really useful unless the content of that information is much more clearly specified. Section 4.1.3. , paragraph 2, discuss: >\u00a0 \u00a0 Intended Semantics: To give the throughput of a TCP congestion- >\u00a0 \u00a0 control conforming flow from the specified source to the specified >\u00a0 \u00a0 destination; see [ RFC3649 , Section 5.1 of  RFC8312 ] on how TCP >\u00a0 \u00a0 throughput is estimated.\u00a0 The spatial aggregation level is specified >\u00a0 \u00a0 in the query context (e.g., PID to PID, or endpoint to endpoint). A TCP bandwidth estimate can only be meaningfully be derived for bulk TCP transfers under a set of pretty strict and simplistic assumptions, making this metric a meaningless at best and misleading at worst, given that the source of this information doesn't know what workload, congestion controller and network conditions the user of this information will use or see. Also,  RFC3649  is an Experimental RFC (from 2003!) and  RFC8312  is an Informational RFC. Since this document normatively refers to them, it needs to cite them, and this will cause DOWNREFs for PS document. I would argue that at least  RFC3649  is certainly not an appropriate DOWNREF. Why define this metric at all? The material you point to is the usual model-based throughput calculation based on RTT and loss rates; a client that intended to predict TCP performance could simply query ALTO for this and perform their own computation, which will likely be more accurate, since the client will hopefully know which congestion controller they will use for the given workload, and what the characteristics of that workload are.",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-03-17 01:14:41-07:00",
    "end_reason": "position_updated",
    "start": "2021-12-02 03:34:42-08:00",
    "text": "I perhaps understand the intention of extending the ALTO protocol so that the ALTO client and server have defined way of exchanging values for already defined metrics. However, I need to agree with my fellow AD colleagues that this document need to describe why those metrics are needed and describe the relationship with other RFCs those defines those metrics mostly for other contexts. To that end all the RFCs in the Table 1 in section 1 need to be normative references.",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2021-05-03 14:18:14-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-05 12:42:28-07:00",
    "text": "I am balloting DISCUSS because there are significant clarity issues.  (1) 4.2.\u00a0 Peer Flags \u00a0  In section 4.2 of [ RFC7854 ], the \"locally sourced routes\" comment \u00a0  under the L flag description is removed.\u00a0 If locally sourced routes \u00a0  are communicated using BMP, they MUST be conveyed using the Loc-RIB \u00a0  instance peer type. This change is bigger than simply removing a comment: it is changing the behavior.\u00a0 Note that \u00a78.2/rfc7854 also talks about the L flag.\u00a0 Do the same considerations apply?\u00a0  I would like to see a clearer treatment of the change related to locally sourced routes -- a separate section/sub-section seems appropriate. (2) \u00a74.2/8.2: Peer Flags \u00a74.2 defines a new Flag as follows: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 1 2 3 4 5 6 7 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+ \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  |F|\u00a0 Reserved\u00a0  | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  +-+-+-+-+-+-+-+-+ But it doesn't mention that this field is intended to be specific to the Loc-RIB peer-type.\u00a0 OTOH, \u00a78.2 (IANA Considerations) does:  \u00a0  This document defines a new flag (Section 4.2) and proposes that peer \u00a0  flags are specific to the peer type: The registry [1] shows that the early allocation was made in the \"generic\" (not per-peer-type) Peer Flags field.\u00a0 The flags defined in  rfc7854  and  rfc8671  both assume the same set of Flags for all peer types. [1]  https://www.iana.org/assignments/bmp-parameters/bmp-parameters.xhtml#peer-flags (3) \u00a75.4 (Route Monitoring)\u00a0 The implication in this section is that a BGP UPDATE includes the route information -- but the information in the Loc-RIB may not have come from BGP, so there is no BGP UPDATE to propagate.\u00a0 This clearly is a case where the UPDATE is fabricated.\u00a0 Please provide specific instructions on how this UPDATE is constructed, including any path attributes.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-08-25 01:05:45-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-24 04:10:56-07:00",
    "text": "he IANA review of this document seems to not have concluded yet; I am holdinga DISCUSS for IANA until it has.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-08-05 23:31:33-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-07 21:28:15-07:00",
    "text": "I have a couple points that might require a bit of discussion, but I expect to be pretty easy to resolve: (1) Can we double-check this text in Section 10.1: \u00a0  The Identity Association for Link-Layer Addresses option (IA_LL \u00a0  option) is used to carry one or more IA_LL options, the parameters \u00a0  associated with the IA_LL, and the address blocks associated with the \u00a0  IA_LL. I am pretty sure that the \"is used to carry one or more IA_LL options\" should actually be talking about IA_LLADDR options.\u00a0 But if I'm wrong, and this is saying that IA_LL can carry IA_LL, we should have a lot more discussion about this recursive structure and how to interpret it. (2) I'd also like to have a bit of discussion about the \"direct client mode scenario\" (Section 4.2).\u00a0 The current text implies that a device might use DHCPv6 on a single interface to request addresses for each local interface and then use the returned allocation from the one interface as link-layer addresses on the other interfaces.\u00a0 While we do say that this \"typically means one address per device\", we still talk about the more general case, and I'm not sure I understand when it makes sense.\u00a0 Given that (as Section 11 notes), \"[l]ink-layer addresses are typically specific to a link\", and a multi-interface client may not a priori know that any given set of its interfaces are on the same link, it seems like this scenario is introducing risk that we use an allocated address outside of the scope of authority from which it was allocated, risking collision.\u00a0 (While the security considerations rightly note that coping with collision is something that nodes need to be prepared to do anyway, we don't need to be encouraging it.) Without some discussion of (e.g.) a link aggregation scenario where a client is bonding multiple physical interfaces into a higher-capacity logical interface, I don't think we should mention this multi-interface scenario at all.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2020-09-02 07:01:50-07:00",
    "end_reason": "position_updated",
    "start": "2020-06-08 04:07:28-07:00",
    "text": "Hi, Thank you for this document.\u00a0 Mostly I found this document to be straight forward to read, but there are a few areas that were unclear to me, that could probably help being clarified. Hopefully none of these are too difficult to address, or they may turn out not to be issues at all ... Client SHOULD, server MUST ignore.\u00a0 In a couple of places in the document (sections 6, 10.1, 10.2), it states that the client SHOULD set 0.\u00a0 To allow the protocol to evolve in future, I believe that it would be better if the SHOULD is changed to a MUST. There doesn't appear to be any specification of how an OPTION_IA_LL should be handled if there are no IA_LL-options, or it contains an IA_LL-option that is not understood by the server.\u00a0 The text does also not specify if IA_LL-options can contain multiple options, and if so how those are encoded (presumably as an array/list of option values), perhaps this is already covered by the DHCPv6 spec?\u00a0 Similar comments also apply to the LLaddr-options field.  9. Releasing Addresses Once a block of addresses have been released, can they immediately be allocated to a different client?\u00a0 Or should they avoid being reused straight away if possible?\u00a0 Perhaps this consideration is already covered by DHCPv6, but it probably makes sense to say something about this, either in section 9, and/or maybe in the security considerations.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-06-02 13:43:46-07:00",
    "end_reason": "position_updated",
    "start": "2020-05-27 13:26:01-07:00",
    "text": "Be ye not afraid -- these should be easy to address. I have some concerns about this document -- much of my unease isn't specifically about the document itself, but rather the impact that deploying this on a wide scale may create. Much of my concerns can probably be addressed by sprinkling on some weasel-words / \"you could shoot yourself in the foot if not careful\" language.  Unless I've horribly misunderstood, in the direct client mode, a device comes up, connects to a switch and then changes its MAC address to the DHCP assigned one. This may interact poorly with: a: switches with small CAM tables (sometimes deployed in DCs) b: devices with configured maximum MACs per port, common in enterprises (e.g:  https://www.cisco.com/c/m/en_us/techdoc/dc/reference/cli/nxos/commands/l2/switchport-port-security-maximum.html  ) c: 802.1X (which is often configured to only allow a single MAC per interface / VLAN) d: switches which do things like DHCP snooping. Again, I do realize that most of these issues are not directly the result of this technique, but implementing / deploying this makes it more likely that devices will come up with a temp address and then pivot to an assigned one, and I'd like to see some operational warnings...",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-03-21 16:39:24-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-17 21:18:59-08:00",
    "text": "I think we need to be more explicit (whether inline or by reference) about what \"Secure joining and the Link-Layer security that it sets up\" (Section 7) entails in terms of ensuring that access to the LLN is only available to authenticated and authorized entities.\u00a0 It might be worth doing so as explicit assumptions or an applicability statement early in the document (e.g., the Introduction). Also, in Section 2.3 we refer to the datagram_tag plus layer-2 sender address as being \"a globally unique identifier for the datagram\", but I think this can only hold within some time-bounded window (e.g., the lifetime of the packet), since the tag space is finite and reuse somewhat inevitable.",
    "type": "Discuss"
  },
  {
    "ad": "Francesca Palombini",
    "end": "2022-04-13 05:43:28-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-12 06:05:19-07:00",
    "text": "Thanks for the work on this document. The DISCUSS comment is easy to fix (missing reference), but I also have a couple of minor comments - for the first one I'd like to see a response but the others are suggestions, please feel free to implement or disregard as you see fit. Francesca 1. ----- Missing Reference: 'RFC8665' is mentioned on line 123, but not defined",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-05-29 12:15:31-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-18 11:47:03-07:00",
    "text": "[1] This document could instruct IANA to rename \"240-254 Experimental Use\" to \"240-254 Private and Experimental Use\", since that is what this document states: \u00a0  If a BAR value is not specified in a RFC but only privately used for \u00a0  a deployment, it MUST be within the \"240-254 Experimental Use\" range \u00a0  of the registry. Furthermore, the statement implies there are two different allocation types here (\"RFC\" and \"privately used\"), but the IANA Registry shows 3 types: \u00a0  0-127 \tStandards Action \u00a0  128-239 \tSpecification Required \u00a0  240-254 \tExperimental Use The \"Specification Required\" could be a non-RFC specification. If this is done, the Abstract should mention the IANA Registry is updated and the IANA Considerations section should be updated. [2] \u00a0  When a BAR value is defined, the corresponding BA and BC semantics \u00a0  SHOULD be specified.\u00a0 For an IGP Algorithm to be used as a BIER IPA, \u00a0  its RA and RC semantics SHOULD be specified. \u00a0  None of the components of the BAR or IPA can be unknown. [...] Then why are these SHOULDs not MUSTs?",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-06-09 09:01:26-07:00",
    "end_reason": "position_updated",
    "start": "2022-04-19 10:58:06-07:00",
    "text": "** Section 2. \u00a0  If a BAR value is not specified in a RFC but only privately used for \u00a0  a deployment, it MUST be within the \"240-254 Experimental Use\" range \u00a0  of the registry. If this document is redefining \u201cexperimental use\u201d to be \u201cprivately used for a deployment\u201d please provide the appropriate applicability statement that bounds this \u201cdeployment\u201d.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-27 00:00:00+00:00",
    "end_reason": "ad_term_ended",
    "start": "2020-03-10 03:30:30-07:00",
    "text": "To be honest I don't fully understand the point of this document. It seem like this document is supposed to be the basis for more discussion, however, I thought that's what we have the wg for. So when and how do we come to a final decision if we want to implement the proposed changes? And what would we do in that case - take this document and republish? Why can't we make the decision first and then publish something? In short, I think it would be important that the document also describes what the next steps are and the triggers to move on!",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-08-22 09:54:54-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 14:44:44-07:00",
    "text": "Are the HMAC keys required to be the hash function's block size or its output size?\u00a0 Section 3.1 says just \"the length of each key is exactly the hash size of the associated HMAC algorithm\", and \"hash size\" conventionally refers to the output length.\u00a0 The referenced Section 2 of RFC 2104  concerns itself with the hash's compression function's block size B, which is generally different. Also in Section 3.1, if we are going to claim that a \"random string of sufficient length\" suffices to initialize a fresh index, we need to provide guidance on what constitutes \"sufficient length\" to achieve the needed property. Blake2s is a keyed MAC, but is not an HMAC construction.\u00a0 If we are to allow its usage for providing integrity protection of babel packets directly, we therefore cannot refer to the preotection scheme as \"HMAC\" generically.\u00a0 Fixing this will, unfortunately, be somewhat invasive to the document, since we mention HMAC all over the place.\u00a0 I believe that \"Keyed Message Authentication Code (Keyed MAC)\" is an appropriate replacement description. The suggestion that the large challenge nonce size admits storage of state in a secure \"cookie\" in the nonce is true, however, implementing this properly presents some subtleties, and it seems like something of an attractive nuisance to suggest that it is possible without giving adequate guidance at how to do it safely.\u00a0 Unfortunately, the best reference I can think of, offhand, is the obsoleted  RFC 5077 . Let's also have a discussion about whether 64 bits of randomness is always sufficient; I left a longer note down in the Comment since I don't expect this to end up being a blocking point.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-08-07 05:17:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 05:16:36-07:00",
    "text": "I would like to quickly discuss the following approach taken in section 4.3.1.1: \u00a0  \"Since a challenge may be prompted by a packet replayed by an \u00a0  attacker, a node MUST impose a rate limitation to the challenges it \u00a0  sends; the limit SHOULD default to one challenge request every 300ms, \u00a0  and MAY be configurable.\" While it is important to limit challenge message here, there might be a better approach than static rate-limiting given this is a request-response mechanism. Usually the approach is to only allow for one outstanding request (without) reply and apply some kind of loss detect/termination rule. In your case the easiest approach would be when the 30 sec timer is expired, or if the RTT is know or can be estimated than a value of e.g. 3xRTT could be appropriate as well. Please consider this alternative approach. May also see  RFC8085  for further guidance. Further Appendix A (Incremental deployment and key rotation) contains normative language and therefore should probably be moved into the body of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-20 08:51:07-08:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 05:17:53-07:00",
    "text": "I would like to quickly discuss the following approach taken in section 4.3.1.1: \u00a0  \"Since a challenge may be prompted by a packet replayed by an \u00a0  attacker, a node MUST impose a rate limitation to the challenges it \u00a0  sends; the limit SHOULD default to one challenge request every 300ms, \u00a0  and MAY be configurable.\" While it is important to limit challenge messages here, there might be a better approach than static rate-limiting given this is a request-response mechanism. Usually the approach is to only allow for one outstanding request (without reply) and apply some kind of loss detect/termination rule. In your case the easiest approach would be when the 30 sec timer is expired, or if the RTT is known (or can be estimated) then a value of e.g. 3xRTT could be appropriate as well. Please consider this alternative approach. Maybe also see  RFC8085  for further guidance. Further Appendix A (Incremental deployment and key rotation) contains normative language and therefore should probably be moved into the body of the document.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-08-07 12:34:53-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-08-07 12:34:11-07:00",
    "text": "A few minor clarifications needed for implementation/precision in the security claims: (1) Section 1.2.\u00a0 Per \u201cany packet accepted as authentic is the exactly copy of a packet originally sent\u201d, this text can be read two ways \u2013 packet as Babel packet or as an IP packet.\u00a0 I think\u00a0 mean the former.\u00a0 Recommend making this clearer as s/any packet/any Babel packet/ (2) Section 2, Per the paragraph, \u201cBy itself, this mechanism is safe against replay \u2026\u201d, please reiterate that for the attack by C to work: A and B must have both lost state; that C is replaying packets with PC previously sent by B (e.g., n+2). (3) Section 4.1.\u00a0 Per \u201cThe node takes the concatenation of the pseudo-header and the packet including the packet header but excluding the packet trailer (from octet 0 inclusive up to (Body Length + 4) exclusive)\u201d, as input for the HMAC.\u00a0 \u201cpacket\u201d is used to sometimes mean IP packet and sometimes a Babel packet carried in an IP packet.\u00a0 As such, the above sentence could be interpretation as: Option #1: HMAC(pseudo-header + the IP header + Babel packet header + Babel packet body \u2013 Babel trailer) Option #2: HMAC(pseudo-header + Babel packet header + Babel packet body) I believe it is option #2.\u00a0 Please be very clear in this text. Other items: (4) Section 2.\u00a0 This section suggests that \u201cone or more HMACs can be appended to the packet\u201d.\u00a0 Under what conditions would it be more than one?\u00a0 What happens if only some of the HMACs are valid?\u00a0 Is use of the same key assumed? (5) Section 4.1.\u00a0 The hash algorithm appears to be negotiated/set out of band (rather than negotiated). The text should explicitly state that somewhere. (6) Section 6.\u00a0 Per \u201cIn particular, reception of a packet with no correct HMAC creates no local state\u00a0 whatsoever\u00a0 (Section 4.3)\u201d, unless this HMAC verification is happening on the NIC, this doesn\u2019t seem sufficiently precise.\u00a0 The \u201cno local state\u201d claim is likely true only as it relates to the tables data structures describes in Section 3.\u00a0 However, the IP and DTLS stack certainly have to account for the packet.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-17 12:09:42-07:00",
    "end_reason": "position_updated",
    "start": "2019-08-07 12:34:53-07:00",
    "text": "A few minor clarifications needed for implementation/precision in the security claims: (1) Section 1.2.\u00a0 Per \u201cany packet accepted as authentic is the exactly copy of a packet originally sent\u201d, this text can be read two ways \u2013 packet as Babel packet or as an IP packet.\u00a0 I think\u00a0 mean the former.\u00a0 Recommend making this clearer as s/any packet/any Babel packet/ (2) Section 2, Per the paragraph, \u201cBy itself, this mechanism is safe against replay \u2026\u201d, please reiterate that for the attack by C to work: A and B must have both lost state; that C is replaying packets with PC previously sent by B (e.g., n+2). (3) Section 4.1.\u00a0 Per \u201cThe node takes the concatenation of the pseudo-header and the packet including the packet header but excluding the packet trailer (from octet 0 inclusive up to (Body Length + 4) exclusive)\u201d, as input for the HMAC.\u00a0 \u201cpacket\u201d is used to sometimes mean IP packet and sometimes a Babel packet carried in an IP packet.\u00a0 As such, the above sentence could be interpretation as: Option #1: HMAC(pseudo-header + the IP header + Babel packet header + Babel packet body) Option #2: HMAC(pseudo-header + Babel packet header + Babel packet body) I believe it is option #2.\u00a0 Please be very clear in this text. Other items: (4) Section 2.\u00a0 This section suggests that \u201cone or more HMACs can be appended to the packet\u201d.\u00a0 Under what conditions would it be more than one?\u00a0 What happens if only some of the HMACs are valid?\u00a0 Is use of the same key assumed? (5) Section 4.1.\u00a0 The hash algorithm appears to be negotiated/set out of band (rather than negotiated). The text should explicitly state that somewhere. (6) Section 6.\u00a0 Per \u201cIn particular, reception of a packet with no correct HMAC creates no local state\u00a0 whatsoever\u00a0 (Section 4.3)\u201d, unless this HMAC verification is happening on the NIC, this doesn\u2019t seem sufficiently precise.\u00a0 The \u201cno local state\u201d claim is likely true only as it relates to the tables data structures describes in Section 3.\u00a0 However, the IP and DTLS stack certainly have to account for the packet.",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2021-01-19 04:13:53-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-22 05:18:07-07:00",
    "text": "I think the topic should be fairly easily to resolve one way or another. However, even after having read the reply to Marin's comment I don't think this document is published with the right status.  - The document defines new CBOR attributes, that is standard track work as it comes out as consensus document from a IETF WG.  - It does not define or document crypto algorithm just refer to existing ones. - The charter item might have been reasonable as informational if existing attributes could have been used. With the choice to define new attributes I think this has entered standards track. - The status of the document I think will also affect the value that IANA might assign to these COSE Header Parameters.  If there are additional considerations I am happy to learn about them.  Else, I would propose a change of status to proposed standard and redo the IETF last call.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-12-31 13:17:42-08:00",
    "end_reason": "position_updated",
    "start": "2020-10-20 19:57:31-07:00",
    "text": "ection 2.\u00a0 Where is the uri (CCDL) syntax/format/data type (used by x5u and x5u-sender) defined?\u00a0 Is this covered by CBOR tag=32?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-06-17 09:38:15-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-17 09:56:33-08:00",
    "text": "I support Eric's DISCUSS point about the TTL, but I want to go a step further because this document contradicts  rfc5881 , which is clear about the TTL setting (from \u00a75): \u00a0  If BFD authentication is not in use on a session, all BFD Control \u00a0  packets for the session MUST be sent with a Time to Live (TTL) or Hop \u00a0  Limit value of 255.\u00a0 All received BFD Control packets that are \u00a0  demultiplexed to the session MUST be discarded if the received TTL or \u00a0  Hop Limit is not equal to 255.\u00a0 A discussion of this mechanism can be \u00a0  found in [GTSM]. \u00a0   \u00a0  If BFD authentication is in use on a session, all BFD Control packets \u00a0  MUST be sent with a TTL or Hop Limit value of 255.\u00a0 All received BFD \u00a0  Control packets that are demultiplexed to the session MAY be \u00a0  discarded if the received TTL or Hop Limit is not equal to 255.\u00a0 If \u00a0  the TTL/Hop Limit check is made, it MAY be done before any \u00a0  cryptographic authentication takes place if this will avoid \u00a0  unnecessary calculation that would be detrimental to the receiving \u00a0  system. OTOH, Section 4 of this document specifies:  \u00a0 \u00a0  TTL or Hop Limit: MUST be set to 1 to ensure that the BFD \u00a0 \u00a0  packet is not routed within the Layer 3 underlay network.\u00a0 This \u00a0 \u00a0  addresses the scenario when the inner IP destination address is \u00a0 \u00a0  of VXLAN gateway and there is a router in underlay which \u00a0 \u00a0  removes the VXLAN header, then it is possible to route the \u00a0 \u00a0  packet as VXLAN\u00a0 gateway address is routable address. Not wanting the packet to be routed in the underlay sounds like a reasonable justification -- but I couldn't find the specification in  rfc7348  about \"a router in underlay which removes the VXLAN header\".\u00a0 Maybe I missed it... Independent of VXLAN, the conflict with  rfc5881  remains -- given the text above, it seems to me that it would be ok if the TTL was set to 1 if authentication is is use, but this document doesn't talk about requiring authentication.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-09-29 13:31:06-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-16 15:43:02-08:00",
    "text": "I have a few points that I think merit IESG discussion. (1) I see that several directorate reviewers expressed unease at the destination (IP and) MAC address assignment procedure for the inner VXLAN headers, and appreciate that there was extensive on-list discussion (more than I could follow).\u00a0 That said, I failed to find a clear statement of why the current text is believed to be safe, and in fact my reading of the current text is that the described procedure is *not* safe.\u00a0 Pointers to key parts of the WG discusison would be more than welcome! To take something of a high-level view of my concerns, if we think of the VXLAN as being a tunnel between VTEPs that carry encapsulated tenant traffic, then what we're trying to do is roughly like BFD between VTEPs, but we want to get fault-detection over as broad a coverage as we can (the \"outermost part of the tunnel\"), so we want to have the option of per-VNI BFD instead of just endpoint-to-endpoint (VTEP-to-VTEP). However, we end up having to do this by trying to insert a thin filter into the tenant's address space (i.e., the inner VXLAN header) and pick out the specific stream of BFD traffic that we're introducing.\u00a0 This is, in some sense, a namespace grab in what is conceptually the tenant's namespace, and we have to be careful that what we do is either guaranteed to not impact the tenant or well-documented and compartmentalized (akin to the \"well-known URIs\"). I've made comments at several places in the document that are more directly tied to specific pieces of text, but in general, if we assume that the tenant can add/remove new addresses at will within their VXLAN abstration, then any attempt to preconfigure by mutual agreement the BFD addresses to use at the VTEPs or to use the VTEP's normal (outer) address as the sentinel value seems subject to the tenant coming in and subsequently trying to use that address, leading to (some of) the tenant's traffic getting silently filtered and interpreted by the VTEP. If we were using domain names as identifiers, we could allocate something under .arpa or similar, but I think our options are more limited when numerical addresses are used. The option suggested by the rtg-dir reviewer of always using the management VNI does not suffer from this namespacing issue, though I recognize that it does reduce the scope over which fault-detection is available, for the cases when different VNIs' traffic are routed or handled differently. (2) Section 6 says: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  The selection \u00a0  of the VNI number of the Management VNI MUST be controlled through \u00a0  management plane.\u00a0 An implementation MAY use VNI number 1 as the \u00a0  default value for the Management VNI.\u00a0 All VXLAN packets received on \u00a0  the Management VNI MUST be processed locally and MUST NOT be \u00a0  forwarded to a tenant. It seems like the management VNI concept is something that would apply to the entire VXLAN deployment and not just to the BFD-using portions; is this already defined somewhere (in which case we should reference it), or is it new with this document?\u00a0 In the latter case wouldn't it be an update to the core VXLAN spec?\u00a0 (I note that there are some procedural hoops to jump through for an IETF-stream document to update an ISE-stream document...)",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-07-14 00:22:10-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-17 00:51:29-08:00",
    "text": "Thank you for the work put into this document. I fully second Adam's COMMENT that should be fixed before publication (IMHO this is a DISCUSS). Answers to my COMMENTs below will be welcome, even if those COMMENTs are not blocking. As usual, an answer to the DISCUSS is required to clear my DISCUSS though. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == May be I am not familiar enough with BFD, but,  RFC 5881  (the one defining BFD) specifies the use of TTL = Hop Limit = 255.. Why this document uses a value of 1 ? -- Section 3 -- IPv4-mapped IPv6 addresses are only to be used inside a host and should never be transmitted in real packets (including packets inside a tunnel) see section 4.2 of  RFC 4038  (even if informational). As other IESG reviewers, I wonder why ::1/128 is not used? -- Section 8 -- The document specifies no IANA actions while the shepherd write-up talks about a IANA action. -- Section 9 -- This section is only about IPv4 (TTL and  RFC 1812 ). Please address IPv6 as well.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-07-22 05:28:04-07:00",
    "end_reason": "position_updated",
    "start": "2020-07-14 00:22:10-07:00",
    "text": "Thank you for the work put into this document and its update. I have cleared one of my DISCUSS point avout TTL = Hop Limit not being 255. All other DISCUSS points remain esp the use of IPv4-mapped IPv6 addresses rather than the IPv6 loopback ::1/128.  I hope that this helps to improve the document, Regards, -\u00e9ric -- Section 3 -- IPv4-mapped IPv6 addresses are only to be used inside a host and should never be transmitted in real packets (including packets inside a tunnel) see section 4.2 of  RFC 4038  (even if informational). As other IESG reviewers, I wonder why ::1/128 is not used? BTW, the right wording is \"IPv4-mapped IPv6 address\" and not \"IPv4-mapped IPv4 address\" as written twice in the document. -- Section 8 -- The document specifies no IANA actions while the shepherd write-up talks about a IANA action. ==> please update the shepherd's report accordingly.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-12-01 07:38:26-08:00",
    "end_reason": "position_updated",
    "start": "2022-11-30 11:54:07-08:00",
    "text": "Don't Panic! As noted in  https://www.ietf.org/blog/handling-iesg-ballot-positions/ , a DISCUSS ballot is a request to have a discussion... I'm assuming that I'm missing something really obvious here, but this *feels* like a bad idea to me... The document says: \"The use of logotypes will, in many cases, affect the users decision to trust and use a certificate.\" Yes, but that seems like a bad outcome... Random things on the Internet tell me that Microsoft has a well recognized logo. Seems plausible, let's use that as an example. When a user is trying to figure out if a certificate actually belongs to Microsoft they are likely to go \"Oh, yes, it's a square composed of other colored squares, this must really be Microsoft\", even if the CN is for  www.evil-attackers-r-us.net . Even without an attacker intentionally creating visually confusing logos, many are similar - for example,  https://icn.bg/  looks really similar to Microsoft's logo (and many things look very similar to the Pepsi logo -  https://yourmileagemayvary.net/2021/05/23/look-up-in-the-sky-its-a-coke-plane-its-a-pepsi-plane-its/  ). Here is an image with two logos:  https://cdn.mos.cms.futurecdn.net/hD95PaJgx5ZZVCFduTWhtg-1200-80.jpg.webp  One of these is for airbnb, and one is for a Japanese drive-in. Keeping in mind that, as a user, the logotype is likely to affect your decision to trust and use the cert, when entering your credit-card info to book your next vacation rental, do you know which of these you should expect? If you get the drive-in one, would you really recognize that? The document uses VISA and MasterCard as examples, but, without looking in your wallet to actually confirm what their logos look like, are you *sure* that you would be able to unambiguously identify them if placed next to logos made by an attacker?  Ok, so now that I've had my soapbox rant: This document updates  RFC 3709  and  RFC 6170 , which been around since 2004 and 2011 respectively. Apparently the sky hasn't actually fallen yet, and so I must be missing something. I did spend quite a while trying to find examples using  RFC3709 /RFC6170, so I could figure out what I'm missing, but failed. I *did* find a few CA certs with this, but they just had links to  http://logo.verisign.com/vslogo.gif  (which doesn't resolve). The only \"live\" cert was for  https://www.dtihost.cz/ , but it's not valid. Again, I'm probably missing something obvious, and so clue-bat appreciated...",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-03-14 17:50:09-07:00",
    "end_reason": "position_updated",
    "start": "2022-03-02 11:48:44-08:00",
    "text": "Since the downrefs that were omitted from the IETF Last Call announcement are to documents published on the ISE stream, I would like to ensure that the IESG specifically discusses that fact, as we determine whether or not an additional IETF LC (corrected to indicate the downrefs) is needed. If we knew that the referenced mechanisms already had IETF consensus, I would be much less concerned about having the IESG approve the downrefs without further community consultation. I'd also like to have the authors double-check the Content-Length in the HTTP response in Figure 10 (Section 7.2); my (admittedly hacky) methodology produces a length of 1246 in contrast to the listed length of 1349.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-18 12:18:25-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-03 11:52:34-08:00",
    "text": "Exciting to see this work progressing. Section 3.5 (and Section 7): \"Type (8 bits):\u00a0 Type indicating the format of the data contained in \u00a0 \u00a0 \u00a0 this option.\u00a0 Options are primarily designed to encourage future \u00a0 \u00a0 \u00a0 extensibility and innovation and so standardized forms of these \u00a0 \u00a0 \u00a0 options will be defined in a separate document.\" \u00a0 \u00a0  I'm a little confused about what is expected to happen with the option classes and types. Are all future option types in the 0x0000..0x00FF range expected to be specified in a single separate document? If not, that should be clarified. I also think there needs to be a normative requirement that such future specifications define all of the types associated with the option classes. In the registry defined in Section 7, I think the table needs a column for the document to reference for each option class definition. That way when option classes are defined in the 0x0000..0x00FF range, implementers and operators will be able to find the reference and understand the semantics of the types. For the vendor-specific options this can be optional, but still would be nice to list if such documentation exists.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2020-03-01 08:38:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 19:24:19-08:00",
    "text": "This will be trivial to address: \u2014 Section 1.2 \u2014 \u00a0  The NVO3 framework [ RFC7365 ] defines many of the concepts commonly \u00a0  used in network virtualization. Indeed, and it seems a critical normative reference here.\u00a0 So why is it in the informative section?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-27 17:30:05-07:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 16:36:32-08:00",
    "text": "This first point is a \"discuss discuss\" for which I'd like to get a sense of what the rest of the IESG feels.\u00a0 I've read the discussion at https://mailarchive.ietf.org/arch/msg/last-call/ywRKREnxWAlunHR7MSaTM4ScsDs but I'm left with a similar sense of uncertainty that Daniel has as to whether the question is fully resolved.\u00a0 Specifically, \"the question\" that I have in mind is to what extent the Geneve architecture includes support for middleboxes that inspect (but do not modify!) the Geneve header and inner payload, to what extent the Geneve architecture is intended to be applicable to scenarios where (end-to-end per-tunnel) underlay confidentiality protection is necessary, and whether those requirements are both strong enough to be deemed an internal inconsistency of requirements/applicability.\u00a0 \"Interposing advanced middleboxes\" and \"service interposition\" are conceived as possible uses for Geneve metadata in Sections 1 and 2.2 as a consideration for why structured tagging is needed on the data plane and not just the control plane, which to me suggests that such usage is considered a first-class use case for Geneve.\u00a0 Section 6.1.1 discusses encryption for traffic traversing untrusted links between geographically separated data centers (though perhaps in this case an encrypted tunnel would be used just for that untrusted transit and leaving the in-datacenter traffic visible to middleboxes), but Section 6.1 discusses cases where the tenant may expect the service provider to provide confidentiality as part of the service.\u00a0 Would this be above or below the Geneve encapsulation? Might some customers insist on one or the other?\u00a0 The consideration from Section 6.1 that the provider of the underlay and the provider of the overlay may not be the same could be taken to imply that the overlay provider itself wants (cryptographic) protection from the underlay provider.\u00a0 I don't have a clear picture of how these considerations interact.\u00a0 (I also note that, since DTLS is mentioned, DTLS 1.3 is going the way of TLS 1.3 and not defining any authentication-only ciphersuites, so if authentication-only service is desired, DTLS may not be the way of the future, leaving IPsec AH as the leading candidate.) Some other section-by-section discuss-level points follow, mostly self-contained/localized issues. Section 3.5.1 \u00a0  o\u00a0 Some options may be defined in such a way that the position in the \u00a0 \u00a0 \u00a0 option list is significant.\u00a0 Options MUST NOT be changed by \u00a0 \u00a0 \u00a0 transit devices. \u00a0  o\u00a0 An option SHOULD NOT be dependent upon any other option in the \u00a0 \u00a0 \u00a0 packet, i.e., options can be processed independently of one \u00a0 \u00a0 \u00a0 another.\u00a0 [...] As was already noted, I don't see how these two requirements are self-consistent. \u00a0  size.\u00a0 A particular option is specified to have either a fixed \u00a0  length, which is constant, or a variable length, which may change \u00a0  over time or for different use cases.\u00a0 This property is part of the \u00a0  definition of the option and conveyed by the 'Type'.\u00a0 For fixed This text is written as if this specification is going to specify further substructure for the \"Type\", with respect to certain types that have fixed length and others that may vary.\u00a0 Otherwise the property would be attached to the option value and not the type value, in my understanding.\u00a0 With the current way the registry is laid out it seems like we need to explicitly say that the entity allocating the option class value needs to specify the interpretation of the 'type' field when used with that option class. Section 4.3.1 \u00a0  2.\u00a0 If Geneve is used with zero UDP checksum over IPv6 then such \u00a0 \u00a0 \u00a0  tunnel endpoint implementation MUST meet all the requirements \u00a0 \u00a0 \u00a0  specified in section 4 of [ RFC6936 ] and requirements 1 as \u00a0 \u00a0 \u00a0  specified in section 5 of [ RFC6936 ]. This seems to implicitly be saying that the other numbered requirements in Section 5 of  RFC 6936  can be ignored, which is updating the behavior of a standards-track document.\u00a0 We need to either be explicit about the update or justify why (the rest of) that applicability statement is not applicable here.\u00a0 If, as the paragraph following the enumerated list says, the requirements specified in  RFC 6936  continue to apply in full, why do we need to call out a MUST-level requirement here? \u00a0  4.\u00a0 The Geneve tunnel endpoint that encapsulates the tunnel MAY use \u00a0 \u00a0 \u00a0  different IPv6 source addresses for each Geneve tunnel that uses \u00a0 \u00a0 \u00a0  Zero UDP checksum mode in order to strengthen the decapsulator's \u00a0 \u00a0 \u00a0  check of the IPv6 source address (i.e the same IPv6 source \u00a0 \u00a0 \u00a0  address is not to be used with more than one IPv6 destination \u00a0 \u00a0 \u00a0  address, irrespective of whether that destination address is a \u00a0 \u00a0 \u00a0  unicast or multicast address).\u00a0 When this is not possible, it is \u00a0 \u00a0 \u00a0  RECOMMENDED to use each source address for as few Geneve tunnels \u00a0 \u00a0 \u00a0  that use zero UDP checksum as is feasible. This functionality is not usable without some mechanism to signal from encapsulator to decapsulator that it is in use. \u00a0  The requirement to check the source IPv6 address in addition to the \u00a0  destination IPv6 address, [...] I do not see this specified as a requirement, only a MAY-level suggestion. Section 4.6 \u00a0  o\u00a0 When performing LSO, a NIC MUST replicate the entire Geneve header \u00a0 \u00a0 \u00a0 and all options, including those unknown to the device, onto each \u00a0 \u00a0 \u00a0 resulting segment.\u00a0 However, a given option definition may \u00a0 \u00a0 \u00a0 override this rule and specify different behavior in supporting \u00a0 \u00a0 \u00a0 devices.\u00a0 [...] This second sentence makes the MUST in the first no longer a MUST.",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2020-02-29 23:27:04-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 10:03:52-08:00",
    "text": "Thank you for the work put into this document. It solves an interesting problem and the document is easy to read. I have one DISCUSS that is **trivial to fix** and some COMMENTs, feel free to ignore my COMMENTs even if\u00a0 I would appreciate your answers to those COMMENTs. Regards, -\u00e9ric == DISCUSS == -- Section 3.3 -- Please use  RFC 8200  the 'new' IPv6 standard rather than  RFC 2460  ;-)",
    "type": "Discuss"
  },
  {
    "ad": "Magnus Westerlund",
    "end": "2020-03-02 06:52:36-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 06:16:23-08:00",
    "text": "I want to discuss the implications of the source port usage and if that needs a bit more consideration of failure cases and ICMP. So Section 3.3 says: \u00a0  Source port:\u00a0 A source port selected by the originating tunnel \u00a0 \u00a0 \u00a0 endpoint.\u00a0 This source port SHOULD be the same for all packets \u00a0 \u00a0 \u00a0 belonging to a single encapsulated flow to prevent reordering due \u00a0 \u00a0 \u00a0 to the use of different paths.\u00a0 To encourage an even distribution \u00a0 \u00a0 \u00a0 of flows across multiple links, the source port SHOULD be \u00a0 \u00a0 \u00a0 calculated using a hash of the encapsulated packet headers using, \u00a0 \u00a0 \u00a0 for example, a traditional 5-tuple.\u00a0 Since the port represents a \u00a0 \u00a0 \u00a0 flow identifier rather than a true UDP connection, the entire \u00a0 \u00a0 \u00a0 16-bit range MAY be used to maximize entropy. I think using the different source ports to enable flow hashing is a nice idea. However, I am a bit worried over the implications of using the full 16-bit range without caveats. Specifically in cases where a network error or other failure to forward the Geneve encapsulated packet and that result in any form a return traffic towards the tunnel ingress. Such as ICMP Packet Too Big messages or Port / Host unreachable. These messages needs to be consumed by the Geneve tunneling endpoint to affect the right response to them. However, if the source port is corresponding to any port where there exist a listenser or bi-directional server on the tunnel ingress host, such as SSH, Echo etc. the ICMP messages may be consumed by the wrong entity that only filter on source port and not the destination port.  I believe this issue may require at least a explicit consideration in the document. Otherwise thanks for thinking through many transport issues for tunnels.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2019-12-04 10:13:34-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-12-03 11:05:02-08:00",
    "text": "nline with RFC6335 the Assignee and Contact of the port entry should also be updated to IESG\u00a0 and IETF Chair\u00a0 respectively.",
    "type": "Discuss"
  },
  {
    "ad": "Mirja Kuhlewind",
    "end": "2020-03-04 01:29:20-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 10:13:34-08:00",
    "text": "Thanks for the really well written document that addresses all transport related question well (and thanks to David for the early TSV review!). I only have one minor process point that need to be addressed before publication: Inline with  RFC6335  the Assignee and Contact of the port entry should also be updated to IESG\u00a0 and IETF Chair\u00a0 respectively.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-03-03 06:36:46-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-04 18:03:42-08:00",
    "text": "(1) The threat model assumed by geneve appears to be expressed in conflicting ways.\u00a0 Section 4.1 notes that  RFC8085 \u2019s definition of \u201ccontrolled environment\u201d applies.\u00a0 However,  - Section 6 notes \u201cWhen crossing an untrusted link, such as the public Internet, \u2026\u201d - Section 6.1 notes \u201cGeneve data traffic between tenant systems across such separated networks should be protected from threats when traversing public networks. Any Geneve overlay data leaving the data center network beyond the operator's security domain SHOULD be secured by encryption mechanisms such as IPsec or other VPN mechanisms to protect the communications between the NVEs when they are geographically separated over untrusted network links.\u201d\u00a0  The advice provided in Section 6.x is sound.\u00a0 Nevertheless, it doesn\u2019t appear to describe a \u201ccontrolled environment\u201d. (2) Section 6.\u00a0 Per \u201cCompromised tunnel endpoints may also spoof identifiers in the tunnel header to gain access to networks owned by other tenants\u201d, couldn\u2019t compromised transit devices do the same? (3) Section 6.1.\u00a0 Similar to what is discussed in Section 6.2 (for integrity), please refer to the impact of a compromised node on confidentiality.\u00a0 For example (not verbatim) \u201cA compromised network node or a transit device within a data center may passively monitor Geneve packet data between NVEs; or route traffic for further inspection.\u201d (4) Section 6.1.\u00a0 Per \u201cDue to the nature of multi-tenancy in such environments, a tenant system may expect data confidentiality to ensure its packet data is not tampered with (active attack) in transit or a target of unauthorized monitoring (passive attack).\u201d, please provide additional precision on the confidentiality. It is only relative to other tenants, but not from the provider (who can engage in tampering and passive monitoring).",
    "type": "Discuss"
  },
  {
    "ad": "Suresh Krishnan",
    "end": "2020-03-01 10:28:27-08:00",
    "end_reason": "position_updated",
    "start": "2019-12-05 05:37:39-08:00",
    "text": "* Section 3.3. This might be an easy DISCUSS to resolve. Since the specification requires the Destination port to be configurable, it is not clear to me how the \"transit\" devices will identify Geneve packets being sent to a non-default port (i.e. not 6081). Can you please clarify?",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-04-24 12:10:14-07:00",
    "end_reason": "position_updated",
    "start": "2020-04-21 15:58:26-07:00",
    "text": "I think we may have to be more specific about updates to the  RFC 8445  state machine, namely whether we are specifying a new state for a checklist to be in (vs. keeping it somehow in the \"Running\" state and modifying the procedures for that state) and describing what happens in Section 7.2.5.4 when all candidate pairs in the checklist are Failed or Succeeded but the PAC timer has not expired.\u00a0 In other words, the combination of 8445 and this document need to be consistent about what the ICE state machine is. In contrast, Trickle is pretty clear about which conditions in which sections of [rfc5245bis] are updated and how, but we don't seem to provide the same level of detail.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2019-05-26 21:26:55-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-02 06:53:42-07:00",
    "text": "There are several internal inconsistencies that needs to be resolved before publication, specifically for: (1) the destination address of the IPv6-in-IPv6 tunnel used for flows from the Internet to a ~Raf -- Section 6.2.4 says addressed to the ~Raf, but Figure 7 says \"hop\". (2) the destination address of the IPv6-in-IPv6 tunnel used for flows from a ~Raf to a ~Raf -- Section 6.3.4 says addressed to the ~Raf, but Figure 7 says \"hop\" (3) Table 14 says \"(opt: RPI)\" which, though not defined, I take to mean as indicating that the insertion of the RPI is optional, but the body text in Section 7.1.2 is unconditional that the 6LBR inserts an RPI header (4) Section 7.2.1 does not mention adding v6-in-v6 encapsulation, but Figure 8 has a \"must\" in that column. (5) Section 7.3.1 only has descriptive text that \"[t]he originating node should put the RPI into an IPv6-in-IPv6 header\", but Figure 8 lists this behavior as \"must\" (though there would also be a second v6-in-v6 encapsulationi from root to destination, which is clearly a must). (Note that Section 7.3.2 covers essentially the same flow, but uses \"which must be in an IPv6-in-IPv6 header addressed to the root\".) (6) In Section 5, we say that the DODAG root \"SHOULD force [rank information] to zero\" but then that \"[t]he Internet will therefore not see any SenderRank information\", and a SHOULD-level requirement is not enough to guarantee this statement as fact. Additionally, there are some terminology inconsistencies in Figures 7 and 8 that need to be cleaned up or explained.\u00a0 For example, in Figure 7, what is the difference between \"Yes\" and \"must\" in the \"IPv6-in-IPv6\" column, and in the \"v6-in-v6 dst\" column, what does \"root\" mean? In Figure 8, what does \"Opt\" mean in the \"RPI\" column?",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2019-05-16 23:04:37-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-01 23:13:09-07:00",
    "text": "The document is interesting and is about an interesting twist of behavior in the light of  RFC 8200  new behavior with respect to Hop-by-hop extension header. But, I am balloting a DISCUSS for two reasons: 1) in section 3.1,\u00a0 I am failing to understand the link between  RFC8200  HbH behavior and why the RPI code needs to be changed to 0x23.\u00a0 => a clear explanation is required on why the option 0x23 is linked to  RFC 8200 : I fail to understand the authors' logic. At first sight, with the new  RFC8200  HbH handling, there is no need to change the RPI code from 0x63 as most routers will ignore HbH anyway. 2) the document deserves a better text as there are too many nits, unexpanded acronyms, ... the reader has hard time to understand the document. Again, the content is useful but need some more work.",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-01-25 21:42:20-08:00",
    "end_reason": "position_updated",
    "start": "2020-12-15 21:46:34-08:00",
    "text": "[ section 12 ] * Ignoring an invalid RH3 header by the end host (I'm assuming this \u00a0 means that segments left > 0) doesn't specify whether the packet \u00a0 should be processed (ignore the RH) or the whole packet should be \u00a0 ignored. \u00a0 I might recommend instead referring to  RFC 6554  S4.2 for how to handle \u00a0 RH3's if the node is also a RPL-aware router and say it MUST drop the \u00a0 packet if segments left is non-zero and it's not a RPL-aware router. \u00a0 Related: I'd also recommend: \u00a0 \"It should just be noted that an incoming RH3 must be fully consumed, or \u00a0  very carefully inspected.\" \u00a0 -> \u00a0 \"It should just be noted that an incoming RH3 MUST be fully consumed.\"",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-04-30 13:24:34-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-04-30 13:24:14-07:00",
    "text": "Per Section 11: \u00a0  [ RFC2473 ] suggests that tunnel entry and exit points can be secured, \u00a0  via the \"Use IPsec\".\u00a0 The suggested solution has all the problems \u00a0  that [ RFC5406 ] goes into.\u00a0 In an LLN such a solution would degenerate \u00a0  into every node having a tunnel with every other node.\u00a0 It would \u00a0  provide a small amount of origin address authentication at a very \u00a0  high cost; doing  BCP38  at every node (linking layer-3 addresses to \u00a0  layer-2 addresses, and to already present layer-2 cryptographic \u00a0  mechanisms) would be cheaper should RPL be run in an environment \u00a0  where hostile nodes are likely to be a part of the LLN. ** I having trouble understanding what recommendation this text was making.\u00a0 The first sentence seems to suggest IPSec, the second sentence seems to discount that advice; and the third seems to suggest  BCP38  as an alternative.\u00a0 Could you please clarify. ** Please be explicit on which challenges in  RFC5406  are being cited (e.g., which sections)",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-05-29 11:58:35-07:00",
    "end_reason": "position_updated",
    "start": "2019-04-30 13:24:34-07:00",
    "text": "Per Section 11: \u00a0  [ RFC2473 ] suggests that tunnel entry and exit points can be secured, \u00a0  via the \"Use IPsec\".\u00a0 The suggested solution has all the problems \u00a0  that [ RFC5406 ] goes into.\u00a0 In an LLN such a solution would degenerate \u00a0  into every node having a tunnel with every other node.\u00a0 It would \u00a0  provide a small amount of origin address authentication at a very \u00a0  high cost; doing  BCP38  at every node (linking layer-3 addresses to \u00a0  layer-2 addresses, and to already present layer-2 cryptographic \u00a0  mechanisms) would be cheaper should RPL be run in an environment \u00a0  where hostile nodes are likely to be a part of the LLN. ** I'm having trouble understanding what recommendation this text was making.\u00a0 The first sentence seems to suggest IPSec, the second sentence seems to discount that advice; and the third seems to suggest  BCP38  as an alternative.\u00a0 Could you please clarify. ** Please be explicit on which challenges in  RFC5406  are being cited (e.g., which sections)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2018-05-21 07:13:49-07:00",
    "end_reason": "position_updated",
    "start": "2018-05-09 08:14:07-07:00",
    "text": "There are a lot of places where the actual requirements seem (potentially) ambiguously written or incomplete, or the document is internally inconsistent.\u00a0 I expect that at least some of these are just confusion on my part, so hopefully someone can clue me in on where I'm going astray. Not exactly a DISCUSS, but is there a plan for resolving the normative reference to the expired draft-ietf-bess-evpn-inter-subnet-forwarding ? Does Section 3's \u00a0  [...] In case two or more NVEs are attached to \u00a0  different BDs of the same tenant, they MUST support RT-5 for the \u00a0  proper Inter-Subnet Forwarding operation of the tenant. apply even when there is a SBD between them in the topology, or does something in the SBD also need to support RT-5 in such cases? Section 3.2's \u00a0  o The ESI and GW IP fields may both be zero, however they MUST NOT \u00a0 \u00a0  both be non-zero at the same time. A route containing a non-zero GW \u00a0 \u00a0  IP and a non-zero ESI (at the same time) SHOULD be treat-as- \u00a0 \u00a0  withdraw [ RFC7606 ]. seems to say that ESI and GW IP cannot both be zero at the same time, but there seem to be entires in Table 1 that have that be the case.\u00a0 There are also potential combinations not included in Table 1 -- are we supposed to infer that anything not listed is an error condition (and thus treat-as-withdraw)? Section 4.4.1's \u00a0  Each RT-5 will be sent with a route-target identifying the tenant \u00a0  (IP-VRF) and two BGP extended communities: seems to say that there will always be these two extended communities, but there seems to be other text later implying that the \"Router's MAC\" extended community is not always present.",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-01-24 10:41:54-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 13:58:35-07:00",
    "text": "Section 7.6: \" The format type and schema parameters can be specified on this \u00a0 \u00a0 \u00a0 property and are RECOMMENDED for text or inline binary encoded \u00a0 \u00a0 \u00a0 content information.\" Doesn't this need to be REQUIRED rather than RECOMMENDED in order for it to improve rather than potentially worsen interoperability? Section 8.1: \"User agents MUST NOT include this information \u00a0 \u00a0 \u00a0 without informing the participant.\" This seems like it needs to say \"without the participant's express permission.\" (As in  https://www.w3.org/TR/geolocation-API ).",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2019-05-27 05:15:08-07:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-16 01:14:11-07:00",
    "text": "Thanks for the work in this document; I think there\u2019s useful stuff here, and I appreciate what it took to put it together.\u00a0 Two things at the DISCUSS level: \u2014 Sections 5.2, 7.1, and 8.1 \u2014 Please see  BCP 178  ( RFC 6648 ), and then remove x-name and x-prop.\u00a0 Thanks. \u2014 Section 10 \u2014 It\u2019s good to refer to  RFC 3986  for URI-related security considerations, and all of them do apply here. Something else that comes to mind that comes along with a set of new URIs is whether they actually point to what they say they do.\u00a0 I don\u2019t see that there\u2019s any way to verify that they do, and I\u2019m very skeptical about the effectiveness of warning an end user about this sort of thing, for many reasons.\u00a0 I can see why allowing URIs is convenient and compelling, but I\u2019m very heavily concerned about tracking and other privacy leaks, malicious and deceptive content, and other such problems, especially considering the prevalence of abusive calendar invitations these days. I\u2019m not sure what the answer is here, but let\u2019s have a discussion about it and see where we can go with it.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-01-04 13:55:29-08:00",
    "end_reason": "discuss_updated",
    "start": "2019-05-27 05:15:08-07:00",
    "text": "Thanks for the work in this document; I think there\u2019s useful stuff here, and I appreciate what it took to put it together.\u00a0 One thing at the DISCUSS level: \u2014 Section 10 \u2014 It\u2019s good to refer to  RFC 3986  for URI-related security considerations, and all of them do apply here. Something else that comes to mind that comes along with a set of new URIs is whether they actually point to what they say they do.\u00a0 I don\u2019t see that there\u2019s any way to verify that they do, and I\u2019m very skeptical about the effectiveness of warning an end user about this sort of thing, for many reasons.\u00a0 I can see why allowing URIs is convenient and compelling, but I\u2019m very heavily concerned about tracking and other privacy leaks, malicious and deceptive content, and other such problems, especially considering the prevalence of abusive calendar invitations these days. I\u2019m not sure what the answer is here, but let\u2019s have a discussion about it and see where we can go with it. Update: We will discuss this in the calext interim meeting, jointly with CalConnect.",
    "type": "Discuss"
  },
  {
    "ad": "Barry Leiba",
    "end": "2021-01-14 06:57:26-08:00",
    "end_reason": "position_updated",
    "start": "2021-01-04 13:55:29-08:00",
    "text": "Thanks very much for the changes in Section 9.1, and I think we're now at the best place we can reasonable be here.\u00a0 Well done. Thanks also for the changes to clarify the ABNF.\u00a0 They're mostly good, and we should be able to clean these last bits up pretty easily: \u2014 Section 6.6 \u2014 The new ABNF doesn\u2019t correctly specify what the old was trying to say.\u00a0 I think this is correct and concise, but please check it over: NEW sdataprop\u00a0 \u00a0 = \"STRUCTURED-DATA\" sdataparam \":\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  sdataval CRLF \u00a0 \u00a0 \u00a0 sdataparam\u00a0 \u00a0  = ; all parameter elements may appear in any order, \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ; and the order is not significant. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (sdataparamtext / sdataparambin / sdataparamuri) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *(\";\" other-param) \u00a0 \u00a0 \u00a0 sdataparamtext = \";VALUE=TEXT\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" fmttypeparam \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" schemaparam \u00a0 \u00a0 \u00a0 sdataparambin\u00a0 = \";VALUE=BINARY\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";ENCODING=BASE64\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" fmttypeparam \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \";\" schemaparam \u00a0 \u00a0 \u00a0 sdataparamuri\u00a0 = \";VALUE=URI\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [\";\" fmttypeparam] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  [\";\" schemaparam] \u00a0 \u00a0 \u00a0 sdataval\u00a0 \u00a0 \u00a0  = ( binary / text /uri ) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  ; value MUST match value type END \u2014 Section 7.1 \u2014 \u00a0 \u00a0 \u00a0 participantc = \"BEGIN\" \":\" \"PARTICIPANT\" CRLF \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  *( partprop / locationc / resourcec ) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \"END\" \":\" \"PARTICIPANT\" CRLF This allows multiple instances of partprop (or none), which is not what you mean.\u00a0 The \u201c*\u201d isn\u2019t right.\u00a0 Also, do you really mean to have locationc and resourcec here?\u00a0 Those are blocks that are peers of participantc within eventc, todoc, journalc, and freebusyc\u2026 are they also meant to be nested within participantc?\u00a0 If so, it would be good to have an example or two that shows that.\u00a0 In any case, that bit of ABNF still needs some work. \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (calendaraddress) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (created) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (description) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (dtstamp) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (geo) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (last-mod) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (priority) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (seq) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (status) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (summary) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  (url) All of these are meant to be optional, so they should be in square brackets, rather than in parentheses.\u00a0 The same is true in Sections 7.2 and 7.3.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2020-12-29 10:39:36-08:00",
    "end_reason": "position_updated",
    "start": "2019-05-28 17:08:42-07:00",
    "text": "I want to talk some about the redefinition of SOURCE.\u00a0 While I agree that the original definition's applicability is more narrow than it needs to be, that doesn't seem to be enough to convince me that there's enough justification to make it so broad as to provide vcard information about a participant or an event link-back, as opposed to just the canonical source of updates for a given object/component.\u00a0 I must apologize for having essentially not done a search of the WG discussion archives for this topic, and pointers into the archive could help to convince me that this redefinition is a stable, interoperable, and backwards-compatible choice. The example in Section 5.4: \u00a0 \u00a0  STRUCTURED-DATA;FMTTYPE=application/ld+json; \u00a0 \u00a0 \u00a0 SCHEMA=\" https://schema.org/FlightReservation \"; \u00a0 \u00a0 \u00a0 ENCODING=BASE64;VALUE=BINARY:Zm9vYmFy contains an inline value that doesn't seem to decode to a valid FlightReservation JSON object. Perhaps I'm misreading, but the ABNF in Section 7.6 does not seem to allow for an explicit VALUE=TEXT parameter to be given, and the description does not list TEXT as the default value type.\u00a0 (I note that the listed example does include VALUE=TEXT, causing this to rise to a Discuss-level internal inconsistency.) Similarly, the examples in Section 8.1 seem incomplete, since they omit the REQUIRED dtstamp and uid properties.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2019-10-16 16:22:16-07:00",
    "end_reason": "position_updated",
    "start": "2019-05-29 12:05:05-07:00",
    "text": "Per the Security Considerations section, [ RFC3986 ] and [W3C.REC-html51-20171003] were helpful. I was hoping to see cautionary text for the potentially danger of handling/parsing arbitrary binaries as allowed by STRUCTURED DATA.\u00a0 I didn\u2019t see it in downstream references. I also tried to find the referenced section suggested by \u201cSecurity considerations relating to the \u2018ATTACH\u2019 property, as described in [ RFC5545 ]\u201d but could not.\u00a0 It\u2019s not the explicit Security Considerations (Section 7 of [ RFC5545 ) or in the definition of Attachment (Section 3.8.1.1 of [ RFC5545 ]).\u00a0 Do you mean Section 3.1.3, Binary Content?\u00a0 Could you please make it clear which section you meant.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2022-02-06 11:17:12-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-15 13:21:56-08:00",
    "text": "Thanks for writing this document; it's an important topic and I look forward to seeing interoperability in this space. However, I don't think this document is quite ready for publication yet, as it has a number of internal inconsistencies (and at least one external inconsistency with IETF procedures) that would get in the way of interoperable implementation. (1) The procedure for substituting an entryPoint from the provider list into the OpenAPI interface description for obtaining configuration data appears to be incompatible with  BCP 190 .\u00a0 Though there's not quite enough detail for me to be able to tell exactly what behavior is intended, the procedure of \"replace localhost in the template with the value from provider discovery\" seems like it implies that the value from provider discovery is just a hostname, and that we are requiring the RUM services to be accessible via HTTP at path /rum/v1 on that machine.\u00a0 The URI path namespace is under control of the owner of the host, and we cannot assert that we will occupy that portion of the namespace.\u00a0 The current version of  BCP 190 ,  RFC 8820 , does allow us to say (effectively) \"delegate a subtree of the path namespace to the protocol\" by letting the owner of the host pick what base path to use for the protocol (even that would not have been allowed by its predecessor,  RFC 7320 ), but we do need to let that host-specific path prefix be indicated somehow, whether by URL template or allowing a base path to be indicated in the provider discovery process. (2) There are a lot of inconsistencies about the parameters and data format of the various API responses as specified in prose, OpenAPI description, and examples.\u00a0 In particular, we also fail to make a clear statement about whether the prose or the OpenAPI description is normative and takes precedence in case of disagreement. I'll list a bunch of things here; I made a fairly careful reading but am not willing to assert that this is a comprehensive listing.\u00a0 (A number of them also get comments in the section-by-section comments; sorry about that duplication.) Sections 9.2.1 and 9.2.2 list configuration data items in the \"configuration data for new user sign up and dial around\" and \"configuration data for the RUE\" configuration retrieval APIs, and per the note at the end of \u00a79.2 they include the REQUIRED data items. However, there are a couple data items that are mentioned elsewhere in the document as if they are always going to be present, but are not present in these lists of required configuration parameters.\u00a0 In particular we talk about the \"provider-domain\" as coming from the configuration, and it appears in examples, but is not mentioned in the prose or OpenAPI format description. The prose (and some examples) refer to an \"outbound-proxies\" RUE configuration element, but \u00a79.2.2 and the OpenAPI description list the singular \"outbound-proxy\" (and with the corresponding difference in format/structure). The prose mentions \"credentials\" from the configuration, but no parameter of that name appears (there is some mention of password under \"carddav\" but that seems insufficiently generic to match all instances; sip-password also exists). \"display-name\" appears in the example in Figure 5 but is not listed in \u00a79.2.2 The prose for the provider configuration resource indicates that the dialAround property is mandatory (it is not marked as \"(OPTIONAL)\"), but the OpenAPI specification does not list this property as required. The prose for the provider configuration's \"signup\" property says that it is an array of JSON objects, but the OpenAPI description says that it is just a single object (not an array).\u00a0 Likewise for \"dialAround\" and \"helpDesk\". The prose for \"phone-number\" specifies E.164 format, but the OpenAPI description does not. \"carddav\" is triply inconsistent: the prose says username, password, and domain name are separated by \"@\" (presumably, in a single string), but the example only shows username and domain name in user@domain form, and the OpenAPI description says it should be an object with separate properties for username/password/domain, as well as an additional \"sendLocationWithRegistration\" property that is probably not supposed to be a child of \"carddav\". (repeating from the previous), the \"sendLocationWithRegistration\" property is listed as belonging to the \"carddav\" object in the OpenAPI description, though the prose and example indicate it should be a property of the toplevel configuration object. The prose and OpenAPI description indicate that \"ice-servers\" is an array of strings, but the example has an array of objects that use the dictionary key to indicate whether each URI is a TURN or STUN server.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2022-01-24 12:51:42-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-07 10:00:07-08:00",
    "text": "Thanks to Bernard Adoba for the TSVART review. It largely informs my DISCUSS. 1. If I understand correctly, this draft is not at all about interoperating with a WebRTC endpoint, instead borrowing some requirements from that family of specs rather than re-inventing the wheel. That's great, but putting that explicitly in the intro would be helpful. 2. In particular, the statement that RUE is a \"non-browser endpoint\" is confusing if it's not actually meant to interoperate with WebRTC. I *think* you're attempting to distinguish between WebRTC's browser-only requirements and endpoint requirements, but I could be wrong here. 3. In Section 5.5, you require conformance with  RFC8835  with a few vaguely worded exceptions. It would be helpful to actually go through that document enumerate exactly which normative statements in 8835 do not apply. That said, I'm not sure I agree with Bernard that 8835 requires *use* of ICE, rather than support, but maybe we can clarify this in the TSVART thread. 4. As Bernard points out, this ambiguity extends to IPv4 and 6 support. The 8835 requirements are specific to browsers, so they might not apply. If you require support for both, but not necessarily on the same device, it would be good to say so. 5. In Sec. 6, it says \"This specification adopts the media specifications for WebRTC ([ RFC8825 ]).\" Is this a normative statement? Must RUEs comply with the entirety of that document, or is this an informative statement and the real requirements are in the subsections of Sec 6? From the discussion, it sounds like you want to include the requirements for WebRTC \"endpoints\", but not for WebRTC \"browsers\". It would help to clarify all this. It's also possible that my initial understanding is incorrect, in which case the later points don't make any sense and some explanatory text is needed.",
    "type": "Discuss"
  },
  {
    "ad": "Robert Wilton",
    "end": "2022-01-20 06:58:34-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-15 04:37:08-08:00",
    "text": "There are a couple of points related to versioning that I would like to see clarified, but I hope that it should be fairly easy to do so. 1. \u00a0  This means an implementation of a \u00a0  specific major version and minor version is backwards compatible with \u00a0  all minor versions of the major version. Is it actually compatible with all other minor versions, or only other minor versions with a greater minor version number.\u00a0 E.g., could an implementation be coded to use/expect a object added in a minor version but that is not present in preceding minor versions? 2. \u00a0  The configuration API also provides the same version mechanism as \u00a0  specified above in Section 9.1.\u00a0 The version of the configuration \u00a0  service MAY be different than the version of the provider list \u00a0  service. It wasn't obvious to me, that for a given provider, how this is communicated.\u00a0 I'm not that familiar with OpenAPI, but looks like the /Versions path is a top level API path, and the data that is contains seems to just be version numbers.\u00a0 Hence, how would a client know which versions apply to provider list service and/or which versions apply to the provide configuration service.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2022-02-07 13:13:12-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-15 14:07:32-08:00",
    "text": "** Is there a reason that credential re-use is being suggested as a fall back.\u00a0 It seems risky to reuse the credentials across services.\u00a0 This fall-back also appears to contradict the guidance in Section 5.1. which says \u201cThis username/password combination SHOULD NOT be the same as that used for other purposes, such as retrieving the RUE configuration\u201d.\u00a0 See: -- Section 7.1.\u00a0 Per access to the CardDAV server, \u201c[i]f no matching credentials are configured, the RUE MUST use the SIP credentials from the configuration.\u201d\u00a0  -- Section 9.2.2.\u00a0 sip-password says \u201cIf it was never supplied, the password used to authenticate to the configuration service is used for SIP, STUN and TURN.\u201d -- Section 9.2.2.\u00a0 carddav field says that \u201cIf username or password are not supplied, the main account credentials are used. \u201c ** Is there a reason that a minimum transport requirements of using HTTPS is not defined for accessing the SIP-supporting elements of this architecture. -- Section 7.1.\u00a0 Access to the CardDAV service?\u00a0 Does the guidance in Section 7.2 (The RUE stores/retrieves the contact list (address book) by issuing an HTTPS POST or GET request.) imply that? -- Section 9.\u00a0 Using the overall API? Does the guidance in Section 9.2 (A RUE device may retrieve a provider configuration the using a simple HTTPs web service) imply that? -- Section 9.2.1.\u00a0 For the URI configuration options noted in this section (e.g., the uri in signup)? ** Section 11.\u00a0 There are more than 10 20 normative SIP protocol references in this document.\u00a0 Which of their security considerations apply?",
    "type": "Discuss"
  },
  {
    "ad": "Zaheduzzaman Sarker",
    "end": "2022-01-20 01:50:10-08:00",
    "end_reason": "position_updated",
    "start": "2021-12-14 13:43:34-08:00",
    "text": "First of all thanks for working on this technology to make communication available and easy for special human beings. (I have worked with them to converter text to sign language in my bachelor hence had a special feeling while reading this specification).  I understood from the email discussions on the TSVART review ( https://mailarchive.ietf.org/arch/msg/tsv-art/Z_Ne5au4rCHwcig8bospMcLyzTc/ ) that in the system RUI is deployed, we will have gateway(s) with two legs - one with WebRTC (client <--> gateway) and one with RUI client communicating with RUI server (gateway <--> server). With this understanding I have some points which I believe worth discussing.  \u00a0 - WebRTC communication will be congestion and rate controlled. This will use RTCP feedbacks to make the rate control and congestion control happen in the WebRTC peers. On the WebRTC part of the leg, this RTCP feedbacks will be available according to the WebRTC specification. However, this specification does not discuss how those RTCP feedback will be converted from the RUI server to RUI client (i.e the gateway) direction and vice versa. This will require the gateway to have such conversion functions to actually work. what is the thinking here? has this been considered? as I am not sure how is the network looks like between the RUI client and RUI server, there might be the Internet connecting them hence need to have congestion controlled traffic. \u00a0 - Thanks to Bernard Aboba for a comprehensive TSVART review of this draft and I would like to bring some issues, identified in that review, here to make sure they are addressed- \u00a0 \u00a0 * clarification on the use of ICE \u00a0 \u00a0 * clarification on what is a WebRTC client, WebRTC server, gateway, RUI client and RUI server. I believe all four have been conceptually used in the specification without concretely defining their roles. for example - if server is mentioned it need to be distinguishable if it is WebRTC server or RUI server ( I noted that there are servers in this specification which are clearly understandable).",
    "type": "Discuss"
  },
  {
    "ad": "Eric Vyncke",
    "end": "2021-10-06 22:52:31-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-21 06:13:27-08:00",
    "text": "Thank you for the work put into this document. This system could indeed be very useful but I am afraid that this is a very complex system especially for IPv6 NDP.  Minor regret in the shepherd write-up as the WG summary did not include any comment on the WG consensus. Thanks to Jean-Michel Combes for its Internet directorate review at:  https://datatracker.ietf.org/doc/review-ietf-bess-evpn-proxy-arp-nd-11-intdir-telechat-combes-2021-01-20/ as Jean-Michel added some important comments, please review them as well as I support them especially those around DAD that should be a blocking DISCUSS point. I also second Erik Kline's DISCUSS points. Question to the authors and BESS WG chairs: was this document submitted to a 6MAN/V6OPS WGs review ? This is where all IPv6 experts live :-) Please find below some blocking DISCUSS points, some non-blocking COMMENT points (but replies would be appreciated), and some nits. I hope that this helps to improve the document, Regards, -\u00e9ric == DISCUSS == Would  RFC 8929  be enough to solve the problem ? -- Section 3 -- \"A Proxy-ARP/ND implementation MAY support all those sub-functions or only a subset of them.\", I am afraid that it is mandatory that the reply and duplicate-ip must be coupled: either both of them are active or none of them are active else the system allows for duplicate IP addresses. -- Section 3.1 -- \"A Proxy-ARP/ND implementation SHOULD support static, dynamic and EVPN-learned entries.\" why not a MUST ? Or at least for dynamic & EVPN-learned ? or at least one ? \"Upon receiving traffic from the CE... the PE will activate the IP->MAC and advertise it in EVPN\" it is unspecified how many bindings can be advertised in the case of multiple static MAC for one IP... only one or all ? -- Section 3.2 -- Why not flooding to all other PEs the ARP/NS with unknown options ? It would be safer. -- Section 3.6 -- This function MUST be a mandatory part of the list of functions of section 3. -- Section 5.2 -- An easy to fix: \"Any unknown source MAC->IP entries\" isn't it IP->MAC as in the rest of the document including the terminology section ? -- Section 5.4 -- \"traffic to unknown entries is discarded\" which traffic (section 5.5 is much better to this point suggest to copy the text)? The NDP/ARP or normal data plane traffic ? Where is this behavior specified in the 6 sub-functions of section 3 ?",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2021-07-18 20:17:46-07:00",
    "end_reason": "position_updated",
    "start": "2021-01-20 23:20:47-08:00",
    "text": "[ meta ] * I appreciate the attempt to explicitly discuss handling NS/NA messages with \u00a0 not-previously-seen options.\u00a0 Thank you for that. \u00a0 It seems to me, however, that the proposed approach to proceed with \u00a0 setting the current capabilities in concrete but point to things like \u00a0 \"unicast-forward\" as a relief valve, even though 3.2-f seems to say the \u00a0 multicast packets (i.e. on cache miss) should be discarded (implying the \u00a0 unicast mapping might never be learned in the first place?). [ general ] * When a PE reboots, should it do MLD (e.g. 2710, 3810, ...) of some kind to \u00a0 gather critical state so that it doesn't have to wait for CEs to have \u00a0 problems? [ section 3.1 ] * To my knowledge there is no concept in IPv6 of a link where anycast/O=0 \u00a0 NAs only propagate partway through a broadcast domain.\u00a0 In practice, if I \u00a0 understand the architecture correctly, O=0 NAs will propagate to all CEs \u00a0 \"behind\" a given PE but, if anycast=false, no further. \u00a0 This could lead to a difficult to debug scenario (though I admit this is \u00a0 probably quite rare). \u00a0 Note that 4861-7.2.4 implies that most nodes sending NAs for their own \u00a0 addresses will adhere to \"the Override flag SHOULD be set to one\".\u00a0 This \u00a0 is not a MUST, though.\u00a0 Dropping all O=0 NAs might affect some \u00a0 implementations that don't comply with this SHOULD.\u00a0 I have no idea how \u00a0 many implementations this might affect (in practice, I suspect none?), but... \u00a0 I think it might need to be considered. [ section 3.1.1/3.2 ] * I was not able to understand what the typical disposition of the O bit \u00a0 is supposed to be in these proxied NAs.\u00a0 Is the intent to default to O=0 so \u00a0 that local O=1 can be preferred (vis. 4861-7.2.4 and 4389)?\u00a0 Or will it \u00a0 more typically be set to O=1 (as if just replaying the NA that was learned \u00a0 by another PE)? [ section 3.2 ] * Item (f) as currently written would break Enhanced DAD ( RFC 7527 ), \u00a0 would it not? [ section 3.6 ] * \"Duplicate IP Detection for IPv6 SHOULD be disabled when IPv6 \u00a0  'anycast' is activated in a given EVI.\" \u00a0 This doesn't seem like the right response to me.\u00a0 It should be okay to keep \u00a0 doing DAD for O=1 addresses regardless of the setting of this 'anycast' \u00a0 option, I would have thought. [ section 5.5 ] * I think that recommending Reply Sub-Functions discard NS packets of \u00a0 unexpected for means, in practice, no new NS option or flag can ever really \u00a0 be made to work.\u00a0 The PE(s) serving the CE(s) that make \"new NS\" \u00a0 solicitations will all need to be upgraded, and it's not immediately clear \u00a0 to me that remote PEs wouldn't also need to be upgraded (to support a \u00a0 possible \"new NA\"in response). \u00a0 If this is in fact likely to be the operational reality then I think this \u00a0 limitation probably needs to be noted explicitly.",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-05-21 11:16:01-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-05 18:58:22-07:00",
    "text": "I have a concern about the MAX_PAYLOADS congestion-control parameter. In Section 7.2 it is stated that both endpoints only SHOULD have the same value.\u00a0 I don't see how this can be anything less than MUST, given that we attribute semantics to whether NUM modulo MAX_PAYLOADS is zero or non-zero in the processing of the Q-Block2 option.\u00a0 If the endpoints disagree on the value of MAX_PAYLOADS they will disagree on the semantics of Q-Block2 -- how can that be interoperable? (Being able to negotiate the value does not seem inherently problematic, but since it is relevant for protocol semantics it seems like the value must be identical on both endpoints.) This seems especially important to have clarity on given that the current specification allows for MAX_PAYLOADS to be decreased at runtime in response to congestion feedback over a 24-hour period, with no synchronization between peers provided (\"Note that the CoAP peer will not know about the MAX_PAYLOADS change until it is reconfigured\".)",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-05-19 14:41:55-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-05 17:39:33-07:00",
    "text": "For the most part I found this document relatively easy to follow, considering my complete lack of background in CoAP. However, despite a concerted effort I have not been able to nail down with confidence what the intended semantics of several of your timeouts are, notably NON_RECEIVE_TIMEOUT. Some of the text (for example, \u00a74.4) implies that the timeout is an upper bound on how long an implementation should wait before declaring a block to have been lost (\u201cThe client SHOULD wait for up to NON_RECEIVE_TIMEOUT\u201d). At the very least, this is imprecise because the timeout increases exponentially with repeated timeouts \u2014 but this is a relatively minor matter, discussed further in my comments. Later, in \u00a77.2, you say that expiry of the timeout is not the only trigger for a 4.08 response: \u00a0  It is likely that the client will start transmitting the next set of \u00a0  MAX_PAYLOADS payloads before the server times out on waiting for the \u00a0  last of the previous MAX_PAYLOADS payloads.\u00a0 On receipt of the first \u00a0  payload from the new set of MAX_PAYLOADS payloads, the server SHOULD \u00a0  send a 4.08 (Request Entity Incomplete) Response Code indicating any \u00a0  missing payloads from any previous MAX_PAYLOADS payloads.  It makes sense to me that you use this additional trigger. At this point in my reading of the spec, my understanding of the retransmission algorithm was that a 4.08 should be sent when either a payload is received from a new set of MAX_PAYLOADS, or NON_RECEIVE_TIMEOUT expires. But then I got to the example in 10.2.3, which shows the client waiting for the expiration of NON_RECEIVE_TIMEOUT even though it has received the first of a new set of MAX_PAYLOADS, and I concluded that either I\u2019ve missed something basic, or the document is internally inconsistent. As an aside, I\u2019m also unclear as to why the only trigger you specify for sending a 4.08 is the arrival of the first of a new MAX_PAYLOADS flight. Other possible triggers I noticed include a gap in the sequence, and reception of a payload with More=0. Some of these issues are repeated in my comments, below \u2014 I\u2019ve noted those in the comment. Possibly in addressing this DISCUSS we\u2019ll clear up some of those comments too.",
    "type": "Discuss"
  },
  {
    "ad": "John Scudder",
    "end": "2021-05-21 09:16:30-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-19 14:41:55-07:00",
    "text": "I am raising my comment #11 to a DISCUSS. I notice that  RFC 7252  jitters its timers, for example: \u00a0 counter.\u00a0 For a new Confirmable message, the initial timeout is set \u00a0 to a random duration (often not an integral number of seconds) \u00a0 between ACK_TIMEOUT and (ACK_TIMEOUT * ACK_RANDOM_FACTOR) (see \u00a0 Section 4.8) \u2026 \u00a0 ACK_RANDOM_FACTOR MUST NOT be decreased below 1.0, and it SHOULD have \u00a0 a value that is sufficiently different from 1.0 to provide some \u00a0 protection from synchronization effects. MAX_TRANSMIT_SPAN and MAX_TRANSMIT_WAIT are similarly jittered. A number of your introduced parameters  \u00a0 This document introduces new parameters MAX_PAYLOADS, NON_TIMEOUT, \u00a0 NON_RECEIVE_TIMEOUT, NON_MAX_RETRANSMIT, NON_PROBING_WAIT, and \u00a0 NON_PARTIAL_TIMEOUT primarily for use with NON (Table 3). appear at least superficially similar to the timers the authors of  RFC 7252  deemed important to jitter to prevent synchronization effects. Did you specifically consider jittering them, and decide that jitter was unnecessary? If so, can you explain what is different about your specification, compared to the base spec, that eliminates the concern? -- Version 12 resolves the concerns in the DISCUSS point below; I am retaining it for posterity only: For the most part I found this document relatively easy to follow, considering my complete lack of background in CoAP. However, despite a concerted effort I have not been able to nail down with confidence what the intended semantics of several of your timeouts are, notably NON_RECEIVE_TIMEOUT. Some of the text (for example, \u00a74.4) implies that the timeout is an upper bound on how long an implementation should wait before declaring a block to have been lost (\u201cThe client SHOULD wait for up to NON_RECEIVE_TIMEOUT\u201d). At the very least, this is imprecise because the timeout increases exponentially with repeated timeouts \u2014 but this is a relatively minor matter, discussed further in my comments. Later, in \u00a77.2, you say that expiry of the timeout is not the only trigger for a 4.08 response: \u00a0  It is likely that the client will start transmitting the next set of \u00a0  MAX_PAYLOADS payloads before the server times out on waiting for the \u00a0  last of the previous MAX_PAYLOADS payloads.\u00a0 On receipt of the first \u00a0  payload from the new set of MAX_PAYLOADS payloads, the server SHOULD \u00a0  send a 4.08 (Request Entity Incomplete) Response Code indicating any \u00a0  missing payloads from any previous MAX_PAYLOADS payloads.  It makes sense to me that you use this additional trigger. At this point in my reading of the spec, my understanding of the retransmission algorithm was that a 4.08 should be sent when either a payload is received from a new set of MAX_PAYLOADS, or NON_RECEIVE_TIMEOUT expires. But then I got to the example in 10.2.3, which shows the client waiting for the expiration of NON_RECEIVE_TIMEOUT even though it has received the first of a new set of MAX_PAYLOADS, and I concluded that either I\u2019ve missed something basic, or the document is internally inconsistent. As an aside, I\u2019m also unclear as to why the only trigger you specify for sending a 4.08 is the arrival of the first of a new MAX_PAYLOADS flight. Other possible triggers I noticed include a gap in the sequence, and reception of a payload with More=0. Some of these issues are repeated in my comments, below \u2014 I\u2019ve noted those in the comment. Possibly in addressing this DISCUSS we\u2019ll clear up some of those comments too.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-07 05:50:25-07:00",
    "end_reason": "discuss_updated",
    "start": "2021-05-05 00:59:46-07:00",
    "text": "The current CORE charter does not seem to cover the topic of this document. I also see no related milestone. Section 1, paragraph 4, discuss: >\u00a0 \u00a0 There is a requirement for these blocks of data to be transmitted at >\u00a0 \u00a0 higher rates under network conditions where there may be asymmetrical >\u00a0 \u00a0 transient packet loss (i.e., responses may get dropped).\u00a0 An example >\u00a0 \u00a0 is when a network is subject to a Distributed Denial of Service >\u00a0 \u00a0 (DDoS) attack and there is a need for DDoS mitigation agents relying >\u00a0 \u00a0 upon CoAP to communicate with each other (e.g., >\u00a0 \u00a0 [ RFC8782 ][ I-D.ietf-dots-telemetry ]).\u00a0 As a reminder, [ RFC7959 ] I understand that COAP was initially chosen to transport DOTS signaling messages due to their small size, support for structured messages and request/response semantics, as well as the ability to function over lossy paths such as found in IoT deployment, which COAP is architected for. DOTS now seems to desire to transport larger messages, and this document extends CORE to enable this functionality. However, this CORE extension seems to solely focus on Internet deployment scenarios, essentially attempting to re-architect COAP into a general Internet transport protocol for transmission over paths with high loss rates. I do not believe that the CORE WG is chartered to do this.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2021-05-18 00:49:26-07:00",
    "end_reason": "position_updated",
    "start": "2021-05-07 05:50:25-07:00",
    "text": "[Updating this DISCUSS based on the discussion during the May 6 telechat.] Section 1, paragraph 4, discuss: >\u00a0 \u00a0 There is a requirement for these blocks of data to be transmitted at >\u00a0 \u00a0 higher rates under network conditions where there may be asymmetrical >\u00a0 \u00a0 transient packet loss (i.e., responses may get dropped).\u00a0 An example >\u00a0 \u00a0 is when a network is subject to a Distributed Denial of Service >\u00a0 \u00a0 (DDoS) attack and there is a need for DDoS mitigation agents relying >\u00a0 \u00a0 upon CoAP to communicate with each other (e.g., >\u00a0 \u00a0 [ RFC8782 ][ I-D.ietf-dots-telemetry ]).\u00a0 As a reminder, [ RFC7959 ] I understand that COAP was initially chosen to transport DOTS signaling messages due to their small size, support for structured messages and request/response semantics, as well as the ability to function over lossy paths such as found in IoT deployment, which COAP is architected for. DOTS now seems to desire to transport larger messages, and this document extends CORE to enable this functionality. However, this CORE extension seems to solely focus on Internet deployment scenarios, essentially attempting to re-architect COAP into a general Internet transport protocol for transmission over paths with high loss rates. It's questionable whether \"maintenance of  RFC7959 \" part of the current CORE charter covers this document. The motivation for this new extension is apparently that  RFC7959  doesn't result in sufficient performance for the DOTS use case, i.e., timely delivery of larger amounts of data during periods of high random loss (i.e., under DDoS). This is a fundamentally hard problem, because in order to deliver data in a timely manner in such scenarios, the sender needs to be very aggressive, to send enough packets into the network so that enough arrive at the receiver to make steady progress; and at the same time the feedback channel is also severely degraded due to loss. The IETF TSV area currently has hence no known good solution for such use cases. This specification possibly describes such a solution, but I was not able to find any evaluation results that would show that this proposed mechanism actually delivers the desired performance improvements over  RFC7959  in the scenarios of interest. I was also not able to find any evaluation results of whether the proposed mechanism is safe to use in situations that might be easily confused with DDoS, such as high-load scenarios that are not of malicious origin, or if it even is safe when executing over normal Internet paths. If such evaluation results exists, would you mind pointing me at them? Without evaluation results that demonstrate that the proposed mechanism is effective and safe, I do not believe it should be published on the Standards Track. It could go forward as an Experimental RFC, supporting an experiment to perform such an evaluation.",
    "type": "Discuss"
  },
  {
    "ad": "Martin Duke",
    "end": "2021-05-05 09:00:54-07:00",
    "end_reason": "position_updated",
    "start": "2021-04-29 16:23:32-07:00",
    "text": "I am concerned about the convergence of three different provisions in this spec: - In (4.1), it says \"To reliably get a rejection message, it is therefore \u00a0  REQUIRED that clients use a Confirmable message for determining \u00a0  support for Q-Block1 and Q-Block2 Options.\" IIUC this mandates that at least one request will use CON. - (7.1): all the blocks of a single body over an \u00a0  unreliable transport MUST either all be Confirmable or all be Non- \u00a0  confirmable. - (7.2) However, the other CON congestion \u00a0  control parameters will need to be tuned to cover this change.\u00a0 This \u00a0  tuning is out of scope of this document as it is expected that all \u00a0  requests and responses using Q-Block1 and Q-Block2 will be Non- \u00a0  confirmable (Section 3.2). I can't reconcile (4.1) with the last sentence in (7.2). Moreover, if my reading of (4.1) is correct, it's not sufficient to declare congestion control guidance out of scope when it's a mandated part of the protocol.",
    "type": "Discuss"
  },
  {
    "ad": "Lars Eggert",
    "end": "2022-07-26 07:42:13-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-12 13:32:03-07:00",
    "text": "# GEN AD review of  draft-ietf-add-ddr-08 CC @larseggert Thanks to Robert Sparks for the General Area Review Team (Gen-ART) review ( https://mailarchive.ietf.org/arch/msg/gen-art/mHeRXL46i0vY3KUKqmxW7l4ZP_k ). ## Discuss ### IANA This document seems to have unresolved IANA issues. Holding a DISCUSS for IANA, so we can determine next steps during the telechat.",
    "type": "Discuss"
  },
  {
    "ad": "Paul Wouters",
    "end": "2022-08-08 14:40:56-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 17:49:31-07:00",
    "text": "# SEC AD comments for { draft-ietf-add-ddr-08 } CC @paulwouters ## Discuss See my discuss on  draft-ietf-add-ddr-11  for my generic ADD DNR/DDR concerns ### \u00a0  Clients MUST NOT automatically use a Designated \u00a0  Resolver without some sort of validation Why not? What is the alternative? Using unencrypted DNS to the party that told you how and where to contact these (unvalidated) Designated Resolvers. ### \u00a0  However, if a given Unencrypted Resolver designates a Designated \u00a0  Resolver that does not use a private or local IP address and can be \u00a0  verified using the mechanism described in Section 4.2, it MAY be used \u00a0  on different network connections so long as the subsequent \u00a0  connections over other networks can also be successfully verified \u00a0  using the mechanism described in Section 4.2. This seems to go against a lot of advise in the documents that networks must be treated independently. Also, the network _wants_ you to use their designated resolver, so to say it is okay to use a totally different Designated Resolvers seems to violate the whole DNR/DDR architecture. This will also cause failure if there is split-DNS or internal-only data. Also, using \"public IP\" is not a good trustworthy method to prove that these IPs are truly the same Designated Resolver used by both networks. I can easily use an internal only zone with  dns.nohats.ca . IN A 8.8.8.8 and get a valid ACME'd certificate with SAN= dns.nohats.ca . The user connecting to another network might now be switching from my private DNS on my stolen 8.8.8.8 IP to the real google DNS. ### \u00a0 \u00a0 \u00a0 2.\u00a0 The client MUST verify that the certificate contains the IP \u00a0 \u00a0 \u00a0  address of the designating Unencrypted Resolver in a \u00a0 \u00a0 \u00a0  subjectAltName extension. How feasible is it to get a certificate with SAN=ip from one of the generally accepted root store CA's? Can you give me one example where I can get a certificate for  nssec.nohats.ca  with SAN=193.110.157.123 ?\u00a0 I do not think this is currently possible or easy. If I am right, that means all of Section 4.2 is wishful thinking and not realistic to get rolled out. (I know we can see the cert for 1.1.1.1, so it is possible, but I know of no ACME supported CA that issues these) ### \u00a0  If these checks fail, the client MUST NOT automatically use the \u00a0  discovered Designated Resolver. This creates a strange policy when compared to DNR where if you get a DHCP or RA for the Designated Resolver, which is also not validatable, that you do end up using it? And section 6.5 states DNR trumps DDR. ### \u00a0  If the Designated Resolver and the Unencrypted Resolver share an IP \u00a0  address, clients MAY choose to opportunistically use the Designated \u00a0  Resolver even without this certificate check (Section 4.3). Why only when the IP is the same? Why not for when the IP is different? What's to lose, since the only fallback option is stick to using the unencrypted resolver? ### \u00a0  If resolving the name of a Designated Resolver from an SVCB record \u00a0  yields an IP address that was not presented in the Additional Answers \u00a0  section or ipv4hint or ipv6hint fields of the original SVCB query, \u00a0  the connection made to that IP address MUST pass the same TLS \u00a0  certificate checks before being allowed to replace a previously known \u00a0  and validated IP address for the same Designated Resolver name. How does the appearance of an (unsigned) Additional Answer entry convey any kind of real world trust/authentication? In other words, why should it not ALWAYS pass the same TLS certificate checks ? ### Opportunistic Discovery has the same \"same IP\" issue. As the alternative is to use unencrypted DNS, why not just use it anyway? ### \u00a0  A DNS client that already knows the name of an Encrypted Resolver can \u00a0  use DDR to discover details about all supported encrypted DNS \u00a0  protocols. It's a little odd to mention this as the DNR draft really tries hard to say to only use the network's offered encrypted DNS servers, so this option is in conflict with the DNR draft. ### \u00a0  A DNS forwarder SHOULD NOT forward queries for \" resolver.arpa \" upstream. Unfortunately, all currently deployed software does not know this, so it will be very common that this happens. ## \u00a0  DNS resolvers that support DDR by responding to queries for \u00a0  _dns.resolver.arpa SHOULD treat  resolver.arpa  as a locally served \u00a0  zone per [ RFC6303 ] Why is this not a MUST ? ### \u00a0  To limit the impact of discovery \u00a0  queries being dropped either maliciously or unintentionally, clients \u00a0  can re-send their SVCB queries periodically. I don't see how this would improve security for the client. It also mixes up behaviour of proper DNS clients that have their own retransmit logic for if they get no answer. ### \u00a0  Section 8.2 of [ I-D.ietf-add-svcb-dns ] describes a second downgrade \u00a0  attack where an attacker can block connections to the encrypted DNS \u00a0  server, and recommends that clients prevent it by switching to SVCB- \u00a0  reliant behavior once SVCB resolution does succeed.\u00a0 For DDR, this \u00a0  means that once a client discovers a compatible Designated Resolver, \u00a0  it SHOULD NOT use unencrypted DNS until the SVCB record expires I wonder which attacker can block encrypted DNS connections but not spoof (or block!) an unsigned SVCB record to the local client? And even if that is the case, this would be a denial of service attack if the DNS client cannot fallback to unencrypted DNS. Spoofing an SVCB to a bogus IP with an SVCB TTL of a few hours would be a very cheap 1 packet attack to keep the DNS client down for hours. This seems dangerous to implement. ### \u00a0  DoH resolvers that allow discovery using DNS SVCB answers over \u00a0  unencrypted DNS MUST NOT provide differentiated behavior based on the \u00a0  HTTP path alone, since an attacker could modify the \"dohpath\" \u00a0  parameter.\u00a0 For example, if a DoH resolver provides provides a \u00a0  filtering service for one URI path, and a non-filtered service for \u00a0  another URI path, [...] It seems likely that this advise will get ignored a lot, eg by people who have limited public IPs to use to spin up a DoH server, or who have to pay-per-IP. This advise seems more appropriate for local private IP DoH servers. So I would change this MUST NOT to SHOULD NOT for that reason. ### \u00a0  If the IP address of a Designated Resolver differs from that of an \u00a0  Unencrypted Resolver, clients applying Verified Discovery \u00a0  (Section 4.2) MUST validate that the IP address of the Unencrypted \u00a0  Resolver is covered by the SubjectAlternativeName of the Designated \u00a0  Resolver's TLS certificate. How would one obtain such a certificate via ACME? Since on the IP of the unencrypted resolver, there would be no HTTP server running? Additionally, if the client notices a failed verification of the Designated Resolver's TLS certificate, wouldn't it fallback to the Unencrypted Resolver? But now it may not? So this becomes a denial of service then ? ### \u00a0  Clients using Opportunistic Discovery (Section 4.3) MUST be limited \u00a0  to cases where the Unencrypted Resolver and Designated Resolver have \u00a0  the same IP address. Based on earlier text, this should read \"the same non-public IP address\". ### I kind of miss the mode of where there is no indication of DDR or DNR, and you use \"unilateral probing\" ( draft-ietf-dprive-unilateral-probing ) to just connect to the DoT or DoQ ports of the Unencrypted Resolver and see if you get anything back. It might be unauthenticated TLS but better than port 53? ### \u00a0  This document calls for the addition of \" resolver.arpa \" to the \u00a0  Special-Use Domain Names (SUDN) registry established by [ RFC6761 ]. Why not pick resolver.local? As .local is already handled to not be forwarded by DNS forwarders. It would also not require an addition to SUDN. Even if someone was already using resolver.local, it would not interfere with that usage because that usage would not be using SVCB records. ## Comments ### section 3 \u00a0  To avoid name lookup deadlock, Designated Resolvers SHOULD follow the \u00a0  guidance in Section 10 of [ RFC8484 ] regarding the avoidance of DNS- \u00a0  based references that block the completion of the TLS handshake. I find that reference to list more the issues than solutions that can be followed. The solution to use another DoH server is not really appropriate in most cases The client's other interface likely resides on other networks where its private DoH server cannot resolve the name of another network's private DoH server. It is also not easy to get an IP based certificate (eg SAN=ip) that is accepted by general webpki root stores. And things like OCSP stapling doesn't help if the target is malicious - they just would omit the stapling that proves against its malicious use. The only real advise usable from  RFC8484  is \"use the local unencrypted resolver to resolve the encrypted resolver\". Might as well say that and remove the 8484 reference. ### I would argue that  I-D.ietf-add-dnr  is not an informative but normative reference, as the protocol is mentioned throughout the document as interacting with this protocol. ### \u00a0 \u00a0 \u00a0 Clients that support SVCB will generally send out three queries \u00a0 \u00a0 \u00a0 when accessing web content on a dual-stack network: A, AAAA, and \u00a0 \u00a0 \u00a0 HTTPS queries.\u00a0 Discovering a Designated Resolver as part of one \u00a0 \u00a0 \u00a0 of these queries, without having to add yet another query, \u00a0 \u00a0 \u00a0 minimizes the total number of queries clients send. I don't understand this paragraph. Once clients can send SVCB queries for web content, they already have had to do all the DDR/DNR related queries, so I don't understand the argument of \"saving queries\" ? Also, it is adding queries for a specific target, eg  resolver.arpa , and this cannot be \"saved\" either? What am I misunderstanding here? ### NITS provides provides -> provides",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-07-13 20:07:07-07:00",
    "end_reason": "discuss_updated",
    "start": "2022-07-13 20:06:02-07:00",
    "text": "[ Apologies, I'm currently participating in the IEEE 802 Plenary meeting, and so was not able to perform as detailed (or timely!) review as normal ] Sec 8.1 - Special Use Domain Name \" resolver.arpa \" \"This document calls for the addition of \" resolver.arpa \" to the Special-Use Domain Names (SUDN) registry established by [ RFC6761 ].\" Unfortunately  RFC6761  Section 4 (Procedure) says: \"The specification MUST state how implementations determine that the special handling is required for any given name.\" and \"The specification also MUST state, in each of the seven \"Domain Name Reservation Considerations\" categories below, what special treatment, if any, is to be applied.\"  And  RFC6761  Section 5 (Domain Name Reservation Considerations) says: \"An IETF \"Standards Action\" or \"IESG Approval\" document specifying some new naming behaviour, which requires a Special-Use Domain Name be reserved to implement this desired new behaviour, needs to contain a subsection of the \"IANA Considerations\" section titled \"Domain Name Reservation Considerations\" giving answers in the seven categories listed below.\" (and lists the categories). I do not see a \"Domain Name Reservation Considerations\" section, nor answers to the 7 questions.",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2022-07-13 21:24:30-07:00",
    "end_reason": "position_updated",
    "start": "2022-07-13 20:07:07-07:00",
    "text": "[ Apologies, I'm currently participating in the IEEE 802 Plenary meeting, and so was not able to perform as detailed (or timely!) review as normal ] Sec 8.1 - Special Use Domain Name \" resolver.arpa \" \"This document calls for the addition of \" resolver.arpa \" to the Special-Use Domain Names (SUDN) registry established by [ RFC6761 ].\" Unfortunately  RFC6761  Section 4 (Procedure) says: \"The specification MUST state how implementations determine that the special handling is required for any given name.\" and \"The specification also MUST state, in each of the seven \"Domain Name Reservation Considerations\" categories below, what special treatment, if any, is to be applied.\"  And  RFC6761  Section 5 (Domain Name Reservation Considerations) says: \"An IETF \"Standards Action\" or \"IESG Approval\" document specifying some new naming behaviour, which requires a Special-Use Domain Name be reserved to implement this desired new behaviour, needs to contain a subsection of the \"IANA Considerations\" section titled \"Domain Name Reservation Considerations\" giving answers in the seven categories listed below.\" (and lists the categories). I do not see a \"Domain Name Reservation Considerations\" section, nor answers to the 7 questions. [ Apologies again for not being able to do a more in-depth review ]",
    "type": "Discuss"
  },
  {
    "ad": "Erik Kline",
    "end": "2020-08-11 18:02:19-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-10 16:59:27-07:00",
    "text": "[ section 4.1 ] * I don't quite understand this apparent reliance on IPv6 flows being routed or \u00a0 load-balanced by src/dst and flow label alone.\u00a0 I know of implementations \u00a0 where that is not the case at all, and in fact  RFC 6437  specifically advises \u00a0 that the flow label alone not be relied upon.\u00a0 Quoting section 2: \u00a0 o\u00a0 Forwarding nodes such as routers and load distributors MUST NOT \u00a0 \u00a0  depend only on Flow Label values being uniformly distributed.\u00a0 In \u00a0 \u00a0  any usage such as a hash key for load distribution, the Flow Label \u00a0 \u00a0  bits MUST be combined at least with bits from other sources within \u00a0 \u00a0  the packet, so as to produce a constant hash value for each flow \u00a0 \u00a0  and a suitable distribution of hash values across flows. \u00a0 \u00a0  Typically, the other fields used will be some or all components of \u00a0 \u00a0  the usual 5-tuple.\u00a0 In this way, load distribution will still \u00a0 \u00a0  occur even if the Flow Label values are poorly distributed. \u00a0 Perhaps I'm seriously misunderstanding something though... * In the bulleted list following the final paragraph, the IP identification \u00a0 field is an IPv4-only header field.\u00a0 What is the recommended mechanism for \u00a0 IPv6?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-08-20 07:59:17-07:00",
    "end_reason": "position_updated",
    "start": "2020-08-11 09:09:58-07:00",
    "text": "I have 2 DISCUSS points. I think that both should be easy to address...  1: \"While most of the routers perform load balancing on flows using Equal Cost Multiple Path (ECMP), a few still divide the workload through packet-based techniques.\u00a0 The former scenario is defined according to [ RFC2991 ], while the latter generates a round-robin scheme to deliver every new outgoing packet.\u00a0 ECMP uses a hashing function to ensure that every packet of a flow is delivered by the same path, and this avoids increasing the packet delay variation and possibly producing overwhelming packet reordering in TCP flows.\" Round-robin / \"per packet\" is a form ECMP, and  RFC2991  doesn't \"define\" just the former, it explains both, and recommends the flow based /\u00a0 hashed approach.  RFC 2991  describes a number of approaches (e.g Modulo-N Hash, Hash-Threshold, Highest Random Weight (HRW)) and makes some good suggestions, but the text as written isn't correct. 2: \"In IPv6, it is sufficient to be routed identically if the IP source and destination addresses and the FlowLabel are constant, see [ RFC6437 ].\" Many routers currently ignore the FlowLabel and use other header info, like port-numbers. The sentence might(?) be true in an idealized network, but in the real world isn't. Some additional text should solve this...",
    "type": "Discuss"
  },
  {
    "ad": "Alissa Cooper",
    "end": "2020-03-18 12:07:41-07:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 13:17:57-08:00",
    "text": "== Section 2 == \"If this field is not present, \u00a0 \u00a0 \u00a0 then IID is derived from the layer-2 address of the sender as per \u00a0 \u00a0 \u00a0 SLAAC ({? RFC4662 }).\" RFC 8064  recommends that the default IID generation scheme for use with SLAAC is not to use the layer-2 address, but to use the mechanism specified in  RFC 7217 . Is there a reason this specification is making a different recommendation?",
    "type": "Discuss"
  },
  {
    "ad": "Alvaro Retana",
    "end": "2020-02-25 09:02:29-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 15:12:01-08:00",
    "text": "I am balloting DISCUSS because the relationship between this document and RPL parent selection is not clear.\u00a0 I expect that the issues I point at will be easy to address, either by clarifying the text or my potential confusion. It is not clear to me what is the \"RPL status\" of an enrolled node.\u00a0 IOW, is an enrolled node to be considered one that has joined a DODAG already?\u00a0 This is then causing some confusion on how RPL parent selection and the new structure defined here are related.\u00a0 More details/questions below. (1) rank priority What is the relationship between the rank priority and parent selection as described in  rfc6550 ?\u00a0  The text says that \"it is to help enrolled devices only to compare different connection points\", but no details on the use are provided. The rank priority is described as \"an indication of how willing this 6LR is to serve as an RPL {? RFC6550 } parent\", which points directly at parent selection.\u00a0 The only mention (that I could find) in  rfc6550  of an indication of how \"willing to act as a parent\" a node may be shows up as a guideline when describing the DAO-ACK.\u00a0 The relative values (\"Lower values indicate more willing, and higher values indicate less willing.\") are aligned, but the size of the fields is different.\u00a0 How, if at all, are these values related? (2) What is the PANID?\u00a0 Is there a relationship with the DODAGID or the RPL Instance?\u00a0  (3) The text says that the pan priority \"typically is used by devices which have already enrolled...MAY consider this value when looking for an eligible parent device.\"\u00a0 As with the rank priority, there are no details about how a node may use this value during parent selection.",
    "type": "Discuss"
  },
  {
    "ad": "Roman Danyliw",
    "end": "2020-02-28 06:11:18-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-16 09:55:46-08:00",
    "text": "** Section 2.\u00a0 Rank Priority and Pan Priority.\u00a0 Can you please clarify whether a higher or lower number indicated an increased priority: -- Rank priority says \u201cLower values are better\u201d -- What does \u201cbetter\u201d mean?\u00a0 Is a lower number more or less willing this 6LR is to serve as the RPL parent? -- Pan priority doesn\u2019t include guidance on whether a higher or lower number indicate increased priority. ** Section 2.\u00a0 network id.\u00a0 Can you please clarify the computation of the default value using SHA-256. The text initially says that network id is a \u201cvariable length field, up to 16 bytes in size\u201d.\u00a0 Later it says that \u201cthe network ID can be constructed from a SHA256 hash of the prefix (/64) of the network.\u00a0 That is just a suggestion for a default value.\u201d\u00a0 However, a SHA256 hash has a 256 bit output which can\u2019t fit into a 16 byte field size.\u00a0 Is there a truncation?",
    "type": "Discuss"
  },
  {
    "ad": "Warren Kumari",
    "end": "2020-02-21 08:34:13-08:00",
    "end_reason": "position_updated",
    "start": "2020-02-19 14:10:40-08:00",
    "text": "[ Be ye not afraid - this should be easy to answer / address ] The Privacy Considerations says: \"The use of a network ID may reveal information about the network.\"  Good point - but it also goes on to say: \"The use of a SHA256 hash of the DODAGID, rather than using the DODAGID (which is usually derived from the LLN prefix) directly provides some privacy for the the addresses used within the network, as the DODAGID is usually the IPv6 address of the root of the RPL mesh.\" I don't know if this is an issue, but how much entropy is in a DODAGID? From what I could find, the DODAGID is often just an IP address - and subnets are not randomly distributed, nor are L2 addresses (inputs to address generation) - if I know that many of the nodes come from vendor_A, and I know their L2 / MAC range, can I enumerate this, and by extension the DODAGID, and so the hash? I will happily admit that I haven't fully researched this / thought it through, so \"Nah, won't work\" or \"Yes, will work, but we did say 'provides some privacy', not 'absolute privacy'\" or all acceptable answers :-)",
    "type": "Discuss"
  },
  {
    "ad": "Benjamin Kaduk",
    "end": "2021-10-12 12:37:13-07:00",
    "end_reason": "position_updated",
    "start": "2021-08-25 13:46:16-07:00",
    "text": "draft-ietf-httpbis-semantics  seems to require that in order to merge a trailer field into the header section, the field definition both explicitly permits the merging action \"and defines how trailer field values can be safely merged.\"\u00a0 The discussion in \u00a72 of this document about preserving ordering of trailer values relative to other intermediaries seems to imply that trailer fields will be merged into the header section (otherwise how could there be an order?), but I do not see a specification for how to safely perform the merge operation.\u00a0 Can we have more clarity on the expected behavior in this case?",
    "type": "Discuss"
  }
]